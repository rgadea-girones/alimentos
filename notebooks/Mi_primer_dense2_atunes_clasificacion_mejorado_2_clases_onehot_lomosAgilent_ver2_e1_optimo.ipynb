{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:\\nuevas_investigaciones_alimentos_2024\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM,Bidirectional,GRU\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import datetime\n",
    "import io\n",
    "import itertools\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Obtener la ruta del directorio actual\n",
    "os.chdir('..')\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "# Construir la ruta relativa al directorio que quieres agregar\n",
    "relative_dir = os.path.join(current_dir, 'mis_pkgs/')\n",
    "\n",
    "# Agregar la ruta relativa al sys.path\n",
    "sys.path.insert(0, relative_dir)\n",
    "\n",
    "from MIOPATIA_db import DB_management as db \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_muestras=401\n",
    "numero_clases=2\n",
    "entrada=slice(5,6)\n",
    "numero_entradas = entrada.stop - entrada.start\n",
    "numero_epochs=2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a quedarme con los 50 atunes P1 para obtener conjunto de training y validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Add, Activation, Concatenate, Conv2D, Dropout \n",
    "from tensorflow.keras.layers import Flatten, Input, GlobalAveragePooling2D, MaxPooling2D\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "__version__ = '0.0.1'\n",
    "\n",
    "\n",
    "def SqueezeNet(input_shape, nb_classes, use_bypass=False, dropout_rate=None, compression=1.0):\n",
    "    \"\"\"\n",
    "    Creating a SqueezeNet of version 1.0\n",
    "    \n",
    "    Arguments:\n",
    "        input_shape  : shape of the input images e.g. (224,224,3)\n",
    "        nb_classes   : number of classes\n",
    "        use_bypass   : if true, bypass connections will be created at fire module 3, 5, 7, and 9 (default: False)\n",
    "        dropout_rate : defines the dropout rate that is accomplished after last fire module (default: None)\n",
    "        compression  : reduce the number of feature-maps (default: 1.0)\n",
    "        \n",
    "    Returns:\n",
    "        Model        : Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(int(96*compression), (7,7), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "    x = create_fire_module(x, int(16*compression), name='fire3', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool4')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(32*compression), name='fire5', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "    x = create_fire_module(x, int(48*compression), name='fire7', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool8')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(64*compression), name='fire9', use_bypass=use_bypass)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        \n",
    "    x = output(x, nb_classes)\n",
    "\n",
    "    return Model(inputs=input_img, outputs=x)\n",
    "\n",
    "\n",
    "def SqueezeNet_11(input_shape, nb_classes, dropout_rate=None, compression=1.0):\n",
    "    \"\"\"\n",
    "    Creating a SqueezeNet of version 1.1\n",
    "    \n",
    "    2.4x less computation over SqueezeNet 1.0 implemented above.\n",
    "    \n",
    "    Arguments:\n",
    "        input_shape  : shape of the input images e.g. (224,224,3)\n",
    "        nb_classes   : number of classes\n",
    "        dropout_rate : defines the dropout rate that is accomplished after last fire module (default: None)\n",
    "        compression  : reduce the number of feature-maps\n",
    "        \n",
    "    Returns:\n",
    "        Model        : Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(int(64*compression), (3,3), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "    x = create_fire_module(x, int(16*compression), name='fire3')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool3')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "    x = create_fire_module(x, int(32*compression), name='fire5')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool5')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "    x = create_fire_module(x, int(48*compression), name='fire7')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire9')\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # Creating last conv10\n",
    "    x = output(x, nb_classes)\n",
    "\n",
    "    return Model(inputs=input_img, outputs=x)\n",
    "\n",
    "\n",
    "def output(x, nb_classes):\n",
    "    x = Conv2D(nb_classes, (1,1), strides=(1,1), padding='valid', name='conv10')(x)\n",
    "    x = GlobalAveragePooling2D(name='avgpool10')(x)\n",
    "    x = Activation(\"softmax\", name='softmax')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_fire_module(x, nb_squeeze_filter, name, use_bypass=False):\n",
    "    \"\"\"\n",
    "    Creates a fire module\n",
    "    \n",
    "    Arguments:\n",
    "        x                 : input\n",
    "        nb_squeeze_filter : number of filters of squeeze. The filtersize of expand is 4 times of squeeze\n",
    "        use_bypass        : if True then a bypass will be added\n",
    "        name              : name of module e.g. fire123\n",
    "    \n",
    "    Returns:\n",
    "        x                 : returns a fire module\n",
    "    \"\"\"\n",
    "    \n",
    "    nb_expand_filter = 4 * nb_squeeze_filter\n",
    "    squeeze    = Conv2D(nb_squeeze_filter,(1,1), activation='relu', padding='same', name='%s_squeeze'%name)(x)\n",
    "    expand_1x1 = Conv2D(nb_expand_filter, (1,1), activation='relu', padding='same', name='%s_expand_1x1'%name)(squeeze)\n",
    "    expand_3x3 = Conv2D(nb_expand_filter, (3,3), activation='relu', padding='same', name='%s_expand_3x3'%name)(squeeze)\n",
    "    \n",
    "    axis = get_axis()\n",
    "    x_ret = Concatenate(axis=axis, name='%s_concatenate'%name)([expand_1x1, expand_3x3])\n",
    "    \n",
    "    if use_bypass:\n",
    "        x_ret = Add(name='%s_concatenate_bypass'%name)([x_ret, x])\n",
    "        \n",
    "    return x_ret\n",
    "\n",
    "\n",
    "def get_axis():\n",
    "    axis = -1 if K.image_data_format() == 'channels_last' else 1\n",
    "    return axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2)\n"
     ]
    }
   ],
   "source": [
    "filename = \"COPIA_PANDAS\\hdf_lomosAgilent_trainval_filtrado_def_good_ampliado_the_best7.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    # p_e =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_train=np.zeros((pre_p_e1.shape[0],numero_muestras,numero_entradas))\n",
    "    y_train=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1:\n",
    "                target = 0\n",
    "            else:\n",
    "                target = 1\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_train[x]=pepito[:,entrada]\n",
    "        #X_train[x]=X_train[x].reshape(X_train[x].shape[0],-1)\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_train[x]=target\n",
    "        y_train_to_categorical = to_categorical(y_train)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_train_filtrado = X_train\n",
    "#y_train_filtrado = y_train\n",
    "y_train_filtrado = y_train_to_categorical\n",
    "\n",
    "# print(X_train_filtrado.shape)\n",
    "# print(y_train_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "scaler = StandardScaler()\n",
    "data_2d = X_train_filtrado.reshape(-1, X_train_filtrado.shape[-1])\n",
    "normalized_data_2d = scaler.fit_transform(data_2d)\n",
    "#para recurrentes\n",
    "#X_train_Normalizado=normalized_data_2d.reshape(X_train_filtrado.shape) #para recurrentes\n",
    "#para densas\n",
    "X_train_Normalizado=normalized_data_2d.reshape(X_train_filtrado.shape[0],-1)\n",
    "y_train_Normalizado=y_train_filtrado # los valores ya estaban normalizados\n",
    "print(y_train_Normalizado.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 401, 1)\n",
      "(39, 2)\n",
      "[ 1.03640337e+00  9.96570686e-01  9.60892550e-01  9.18754450e-01\n",
      "  8.69384321e-01  8.61496074e-01  7.84798119e-01  7.71729542e-01\n",
      "  7.37318226e-01  7.08749846e-01  6.82631811e-01  6.52316332e-01\n",
      "  6.03380907e-01  5.89283611e-01  5.75172217e-01  5.61100155e-01\n",
      "  5.30683280e-01  5.09660932e-01  4.87880948e-01  4.59951480e-01\n",
      "  4.36971100e-01  4.12926700e-01  3.96905222e-01  3.80000274e-01\n",
      "  3.61996752e-01  3.42480058e-01  3.24210220e-01  3.08116876e-01\n",
      "  2.91172275e-01  2.73698013e-01  2.57521769e-01  2.41042072e-01\n",
      "  2.26553542e-01  2.12371611e-01  1.97642158e-01  1.83788508e-01\n",
      "  1.70396303e-01  1.60276397e-01  1.50700858e-01  1.38428578e-01\n",
      "  1.30055834e-01  1.18641779e-01  1.08677228e-01  9.84703040e-02\n",
      "  8.91930534e-02  7.97435688e-02  7.17567115e-02  6.35553934e-02\n",
      "  5.24008426e-02  4.37238741e-02  3.57165076e-02  2.75539691e-02\n",
      "  2.00529264e-02  1.31677411e-02  5.59911993e-03  1.78467083e-04\n",
      " -3.69931548e-03 -1.09208764e-02 -1.52702319e-02 -2.23160401e-02\n",
      " -2.89085061e-02 -3.48425656e-02 -3.98137543e-02 -4.52553032e-02\n",
      " -4.98978722e-02 -5.52040677e-02 -5.95656199e-02 -6.27576832e-02\n",
      " -6.70812834e-02 -7.04537367e-02 -7.38114366e-02 -7.71336096e-02\n",
      " -8.05139827e-02 -8.22633014e-02 -8.57021917e-02 -8.77102987e-02\n",
      " -9.06402279e-02 -9.35751543e-02 -9.56286553e-02 -9.80384008e-02\n",
      " -9.96978588e-02 -1.02129282e-01 -1.05318742e-01 -1.06372774e-01\n",
      " -1.08168033e-01 -1.10574384e-01 -1.12240524e-01 -1.13994943e-01\n",
      " -1.15489991e-01 -1.17151710e-01 -1.18992569e-01 -1.20010989e-01\n",
      " -1.21528337e-01 -1.22719263e-01 -1.23902537e-01 -1.25013741e-01\n",
      " -1.26460458e-01 -1.27395234e-01 -1.28319210e-01 -1.29134908e-01\n",
      " -1.30390012e-01 -1.31225053e-01 -1.32155852e-01 -1.33279119e-01\n",
      " -1.34076734e-01 -1.34742374e-01 -1.35542988e-01 -1.36375303e-01\n",
      " -1.36966703e-01 -1.37987988e-01 -1.38559621e-01 -1.39348351e-01\n",
      " -1.40088726e-01 -1.40705171e-01 -1.41290982e-01 -1.41825758e-01\n",
      " -1.42408034e-01 -1.43101952e-01 -1.43530388e-01 -1.44070209e-01\n",
      " -1.44658848e-01 -1.45029134e-01 -1.45537506e-01 -1.45923005e-01\n",
      " -1.46321363e-01 -1.46739448e-01 -1.47191581e-01 -1.47426837e-01\n",
      " -1.47897566e-01 -1.48306364e-01 -1.48522285e-01 -1.48841593e-01\n",
      " -1.49252029e-01 -1.49667256e-01 -1.49908275e-01 -1.50102391e-01\n",
      " -1.50381674e-01 -1.50673705e-01 -1.50892552e-01 -1.51168415e-01\n",
      " -1.51435754e-01 -1.51734490e-01 -1.52032006e-01 -1.52278372e-01\n",
      " -1.52440433e-01 -1.52669201e-01 -1.52862218e-01 -1.53075493e-01\n",
      " -1.53116341e-01 -1.53374200e-01 -1.53553565e-01 -1.53738651e-01\n",
      " -1.53849654e-01 -1.53958927e-01 -1.54165476e-01 -1.54341730e-01\n",
      " -1.54450725e-01 -1.54574330e-01 -1.54814799e-01 -1.54858376e-01\n",
      " -1.54984531e-01 -1.55044765e-01 -1.55250687e-01 -1.55344235e-01\n",
      " -1.55512002e-01 -1.55607711e-01 -1.55692632e-01 -1.55779608e-01\n",
      " -1.55938848e-01 -1.56108900e-01 -1.56136800e-01 -1.56269983e-01\n",
      " -1.56428091e-01 -1.56478671e-01 -1.56545842e-01 -1.56688754e-01\n",
      " -1.56800306e-01 -1.56938256e-01 -1.57009161e-01 -1.57131862e-01\n",
      " -1.57289850e-01 -1.57406930e-01 -1.57580927e-01 -1.57680257e-01\n",
      " -1.57777509e-01 -1.57922950e-01 -1.58071127e-01 -1.58218731e-01\n",
      " -1.58335329e-01 -1.58463807e-01 -1.58617525e-01 -1.58773047e-01\n",
      " -1.58891307e-01 -1.59043579e-01 -1.59198462e-01 -1.59369822e-01\n",
      " -1.59537434e-01 -1.59728797e-01 -1.59914577e-01 -1.60118622e-01\n",
      " -1.60293591e-01 -1.60516007e-01 -1.60699839e-01 -1.60955941e-01\n",
      " -1.61208633e-01 -1.61422316e-01 -1.61701276e-01 -1.61961608e-01\n",
      " -1.62199850e-01 -1.62444846e-01 -1.62731915e-01 -1.63024650e-01\n",
      " -1.63313402e-01 -1.63627295e-01 -1.63949760e-01 -1.64233809e-01\n",
      " -1.64578671e-01 -1.64914664e-01 -1.65239663e-01 -1.65589538e-01\n",
      " -1.65964559e-01 -1.66355417e-01 -1.66727470e-01 -1.67133233e-01\n",
      " -1.67504913e-01 -1.67899025e-01 -1.68293374e-01 -1.68706542e-01\n",
      " -1.69110137e-01 -1.69540543e-01 -1.69966550e-01 -1.70394557e-01\n",
      " -1.70831333e-01 -1.71248799e-01 -1.71674156e-01 -1.72123023e-01\n",
      " -1.72567496e-01 -1.72991960e-01 -1.73433296e-01 -1.73857670e-01\n",
      " -1.74302888e-01 -1.74728534e-01 -1.75190686e-01 -1.75639539e-01\n",
      " -1.76070834e-01 -1.76510958e-01 -1.76951210e-01 -1.77351859e-01\n",
      " -1.77763660e-01 -1.78176114e-01 -1.78605681e-01 -1.78963283e-01\n",
      " -1.79374328e-01 -1.79758365e-01 -1.80119307e-01 -1.80499460e-01\n",
      " -1.80872329e-01 -1.81227995e-01 -1.81579347e-01 -1.81933182e-01\n",
      " -1.82263265e-01 -1.82590047e-01 -1.82905123e-01 -1.83223236e-01\n",
      " -1.83519514e-01 -1.83833186e-01 -1.84109437e-01 -1.84414734e-01\n",
      " -1.84679570e-01 -1.84935053e-01 -1.85189661e-01 -1.85442060e-01\n",
      " -1.85684181e-01 -1.85913215e-01 -1.86130633e-01 -1.86349084e-01\n",
      " -1.86560327e-01 -1.86755533e-01 -1.86957005e-01 -1.87146741e-01\n",
      " -1.87335722e-01 -1.87512723e-01 -1.87684505e-01 -1.87849856e-01\n",
      " -1.87998160e-01 -1.88153451e-01 -1.88294527e-01 -1.88420840e-01\n",
      " -1.88560021e-01 -1.88675568e-01 -1.88793969e-01 -1.88907409e-01\n",
      " -1.89005453e-01 -1.89111501e-01 -1.89210862e-01 -1.89294286e-01\n",
      " -1.89388391e-01 -1.89474617e-01 -1.89556832e-01 -1.89636008e-01\n",
      " -1.89713173e-01 -1.89789349e-01 -1.89855884e-01 -1.89916685e-01\n",
      " -1.89976292e-01 -1.90029233e-01 -1.90080726e-01 -1.90126009e-01\n",
      " -1.90176235e-01 -1.90217739e-01 -1.90258364e-01 -1.90302342e-01\n",
      " -1.90334672e-01 -1.90363877e-01 -1.90403748e-01 -1.90432435e-01\n",
      " -1.90460364e-01 -1.90481295e-01 -1.90523779e-01 -1.90543079e-01\n",
      " -1.90560296e-01 -1.90572808e-01 -1.90595370e-01 -1.90614993e-01\n",
      " -1.90630692e-01 -1.90644605e-01 -1.90657847e-01 -1.90669944e-01\n",
      " -1.90689253e-01 -1.90698878e-01 -1.90706273e-01 -1.90715433e-01\n",
      " -1.90722675e-01 -1.90731051e-01 -1.90740913e-01 -1.90745724e-01\n",
      " -1.90750497e-01 -1.90750950e-01 -1.90758901e-01 -1.90760185e-01\n",
      " -1.90758471e-01 -1.90761549e-01 -1.90765393e-01 -1.90764441e-01\n",
      " -1.90769720e-01 -1.90766154e-01 -1.90769038e-01 -1.90769368e-01\n",
      " -1.90767862e-01 -1.90770265e-01 -1.90770763e-01 -1.90766506e-01\n",
      " -1.90762345e-01 -1.90755408e-01 -1.90748855e-01 -1.90740783e-01\n",
      " -1.90741309e-01 -1.90742001e-01 -1.90739388e-01 -1.90737376e-01\n",
      " -1.90731509e-01 -1.90733899e-01 -1.90729029e-01 -1.90724623e-01\n",
      " -1.90722535e-01 -1.90721517e-01 -1.90716422e-01 -1.90714096e-01\n",
      " -1.90706556e-01 -1.90708663e-01 -1.90705161e-01 -1.90699299e-01\n",
      " -1.90699160e-01 -1.90693328e-01 -1.90686310e-01 -1.90680236e-01\n",
      " -1.90670232e-01 -1.90672217e-01 -1.90679176e-01 -1.90666589e-01\n",
      " -1.90663282e-01 -1.90663613e-01 -1.90650827e-01 -1.90650726e-01\n",
      " -1.90607120e-01 -1.90640095e-01 -1.90642095e-01 -1.90629399e-01\n",
      " -1.90627335e-01 -1.90625029e-01 -1.90619215e-01 -1.90612626e-01\n",
      " -1.90610821e-01 -1.90605314e-01 -1.90597807e-01 -1.90596009e-01\n",
      " -1.90592864e-01 -1.90585182e-01 -1.90579193e-01 -1.90572991e-01\n",
      " -1.90660035e-01]\n"
     ]
    }
   ],
   "source": [
    "filename = \"COPIA_PANDAS\\hdf_lomosAgilent_test_filtrado_def_good.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    pre_p_e1 =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_test=np.zeros((pre_p_e1.shape[0],numero_muestras,numero_entradas))\n",
    "    y_test=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1:\n",
    "                target = 0\n",
    "            else:\n",
    "                target = 1\n",
    "\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_test[x]=pepito[:,entrada]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_test[x]=target\n",
    "        y_test_to_categorical = to_categorical(y_test)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_test_filtrado = X_test\n",
    "#y_train_filtrado = y_train\n",
    "y_test_filtrado = y_test_to_categorical\n",
    "\n",
    "print(X_test_filtrado.shape)\n",
    "print(y_test_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "# concatenamos train y test\n",
    "#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\n",
    "data_2d_test = X_test_filtrado.reshape(-1, X_test_filtrado.shape[-1])\n",
    "normalized_data_2d_test = scaler.transform(data_2d_test)\n",
    "\n",
    "\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape[0],-1) \n",
    "# la alternativa es normalizar con el total\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "\n",
    "y_test_def=y_test_filtrado # los valores ya estaban normalizados\n",
    "print(X_test_def[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer los conjuntos de entrenamiento validacion y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide el dataset en entrenamiento y temporal (test+validación)\n",
    "# X_temp, X_test_def, y_temp, y_test_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.2, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Divide el dataset temporal en validación y test\n",
    "X_train_def, X_val_def, y_train_def, y_val_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.25, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Ahora, X_train, X_val y X_test contienen los datos de entrada para los conjuntos de entrenamiento, validación y prueba, respectivamente.\n",
    "# y_train, y_val y y_test contienen las clases correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 401)\n",
      "(14, 401)\n",
      "(39, 401)\n",
      "(39, 2)\n",
      "(14, 2)\n",
      "(39, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_def.shape)\n",
    "print(X_val_def.shape)\n",
    "print(X_test_def.shape)\n",
    "print(y_train_def.shape)\n",
    "print(y_val_def.shape)\n",
    "print(y_test_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "#%tensorboard --logdir logs\n",
    "#log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"\n",
    "    Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\n",
    "    \"\"\"\n",
    "    \n",
    "    buf = io.BytesIO()\n",
    "    \n",
    "    # Use plt.savefig to save the plot to a PNG in memory.\n",
    "    plt.savefig(buf, format='png')\n",
    "    \n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    \n",
    "    # Use tf.image.decode_png to convert the PNG buffer\n",
    "    # to a TF image. Make sure you use 4 channels.\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    \n",
    "    # Use tf.expand_dims to add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "       class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    \n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    # Normalize the confusion matrix.\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    \n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    threshold = 0.5\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"red\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_aprendizaje=0.001\n",
    "dimension_LSTM=50\n",
    "dimension_dense1=50\n",
    "dimension_dense2=20\n",
    "algoritmo='rmsprop'\n",
    "supermax=8*4\n",
    "lossfunction='categorical_crossentropy'\n",
    "def create_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    # model.add(Bidirectional(GRU(dimension_LSTM, return_sequences=True, recurrent_regularizer='L2'),input_shape=(401, 8)))\n",
    "    # # model.add(GRU(50, return_sequences=True))\n",
    "    # model.add(GRU(50, return_sequences=False))\n",
    "    model.add(Dense(dimension_dense1, activation='tanh'))\n",
    "    model.add(Dense(dimension_dense2, activation='tanh'))\n",
    "    model.add(Dense(numero_clases, activation='softmax'))\n",
    "    model.compile(loss=lossfunction, optimizer=algoritmo, metrics=['accuracy'])\n",
    "    model.optimizer.lr=(factor_aprendizaje)\n",
    "    return model\n",
    "\n",
    "model=create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar una lista de los números en el rango del slice\n",
    "numbers = list(range(entrada.start, entrada.stop))\n",
    "\n",
    "# Convertir la lista a un string con los números separados por guiones\n",
    "slice_str = \"-\".join(map(str, numbers))\n",
    "\n",
    "\n",
    "experimento=\"LOMOS_Agilent_entradas_{}_dense1_{}_dense2_{}_clases_{}_loss_{}_lr_{}_algoritmo_{}\".format(slice_str,dimension_dense1,dimension_dense2,numero_clases,lossfunction,factor_aprendizaje,algoritmo)\n",
    "logdir=\"./logs/defs/{}_{}\".format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if numero_clases==2:\n",
    "    class_names=['Buenos', 'Malos']\n",
    "else:\n",
    "    class_names=['A', 'B+', 'B', 'B-','C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    \n",
    "    # Use the model to predict the values from the test_images.\n",
    "    y_pred = model.predict(X_test_def)\n",
    "    #y_pred1=y_pred[:,-1]\n",
    "    y_pred2=y_pred.argmax(axis=1)\n",
    "    #y_pred2=np.where(y_pred>0,1,0)\n",
    "    #y_pred2=y_pred2[:,-1]\n",
    "    if numero_clases==2:\n",
    "        classes = [0, 1]    \n",
    "    else:\n",
    "\n",
    "        classes = [0, 1, 2, 3, 4] \n",
    "    #classes = [0, 1]\n",
    "    y_test_def2=np.argmax(y_test_def,axis=1)  \n",
    "    #y_test_def2=np.where(y_test_def>0,1,0)\n",
    "    cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    figura = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figura)\n",
    "    \n",
    "    # Log the confusion matrix as an image summary.\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2)\n",
      "(14, 2)\n"
     ]
    }
   ],
   "source": [
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "print(y_train_Normalizado.shape)\n",
    "print(y_val_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un callback para guardar los mejores pesos\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('best_weights.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/steposs: 0.6859 - accuracy: 0.56\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6859 - accuracy: 0.5641 - val_loss: 0.9953 - val_accuracy: 0.5000\n",
      "Epoch 2/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.9697 - accuracy: 0.51\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.9697 - accuracy: 0.5128 - val_loss: 0.8308 - val_accuracy: 0.5000\n",
      "Epoch 3/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.7016 - accuracy: 0.56\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.7016 - accuracy: 0.5641 - val_loss: 0.7368 - val_accuracy: 0.6429\n",
      "Epoch 4/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.6525 - accuracy: 0.58\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.6525 - accuracy: 0.5897 - val_loss: 0.7699 - val_accuracy: 0.5714\n",
      "Epoch 5/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.6277 - accuracy: 0.61\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.6277 - accuracy: 0.6154 - val_loss: 0.7396 - val_accuracy: 0.5714\n",
      "Epoch 6/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.6217 - accuracy: 0.61\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.6217 - accuracy: 0.6154 - val_loss: 0.7643 - val_accuracy: 0.5714\n",
      "Epoch 7/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.6173 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.6173 - accuracy: 0.6410 - val_loss: 0.7450 - val_accuracy: 0.5714\n",
      "Epoch 8/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.6151 - accuracy: 0.58\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.6151 - accuracy: 0.5897 - val_loss: 0.7648 - val_accuracy: 0.5000\n",
      "Epoch 9/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.6131 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.6131 - accuracy: 0.6410 - val_loss: 0.7432 - val_accuracy: 0.5714\n",
      "Epoch 10/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.6124 - accuracy: 0.61\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 0.6124 - accuracy: 0.6154 - val_loss: 0.7719 - val_accuracy: 0.5714\n",
      "Epoch 11/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.6120 - accuracy: 0.61\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.6120 - accuracy: 0.6154 - val_loss: 0.7408 - val_accuracy: 0.5714\n",
      "Epoch 12/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.6165 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.6165 - accuracy: 0.6410 - val_loss: 0.7928 - val_accuracy: 0.5000\n",
      "Epoch 13/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.6159 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.6159 - accuracy: 0.6923 - val_loss: 0.7414 - val_accuracy: 0.5714\n",
      "Epoch 14/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.6259 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.6259 - accuracy: 0.6410 - val_loss: 0.8196 - val_accuracy: 0.5000\n",
      "Epoch 15/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.6290 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.6290 - accuracy: 0.6410 - val_loss: 0.7470 - val_accuracy: 0.5714\n",
      "Epoch 16/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.6436 - accuracy: 0.61\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.6436 - accuracy: 0.6154 - val_loss: 0.8070 - val_accuracy: 0.5000\n",
      "Epoch 17/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.6207 - accuracy: 0.61\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.6207 - accuracy: 0.6154 - val_loss: 0.7448 - val_accuracy: 0.6429\n",
      "Epoch 18/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.6153 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.6153 - accuracy: 0.6667 - val_loss: 0.7858 - val_accuracy: 0.4286\n",
      "Epoch 19/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.6083 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.6083 - accuracy: 0.6667 - val_loss: 0.7428 - val_accuracy: 0.5714\n",
      "Epoch 20/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.6094 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.6094 - accuracy: 0.6410 - val_loss: 0.7855 - val_accuracy: 0.5714\n",
      "Epoch 21/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.6060 - accuracy: 0.61\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.6060 - accuracy: 0.6154 - val_loss: 0.7436 - val_accuracy: 0.5714\n",
      "Epoch 22/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.6105 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.6105 - accuracy: 0.6410 - val_loss: 0.7930 - val_accuracy: 0.4286\n",
      "Epoch 23/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.6057 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.6057 - accuracy: 0.6667 - val_loss: 0.7437 - val_accuracy: 0.6429\n",
      "Epoch 24/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.6098 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.6098 - accuracy: 0.6410 - val_loss: 0.8056 - val_accuracy: 0.5000\n",
      "Epoch 25/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.6116 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.6116 - accuracy: 0.6923 - val_loss: 0.7466 - val_accuracy: 0.5000\n",
      "Epoch 26/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.6256 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.6256 - accuracy: 0.6410 - val_loss: 0.8137 - val_accuracy: 0.5000\n",
      "Epoch 27/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.6137 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.6137 - accuracy: 0.6410 - val_loss: 0.7509 - val_accuracy: 0.6429\n",
      "Epoch 28/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.6116 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.6116 - accuracy: 0.6667 - val_loss: 0.8012 - val_accuracy: 0.5000\n",
      "Epoch 29/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.6050 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.6050 - accuracy: 0.6923 - val_loss: 0.7452 - val_accuracy: 0.6429\n",
      "Epoch 30/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.6073 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.6073 - accuracy: 0.6410 - val_loss: 0.7999 - val_accuracy: 0.5000\n",
      "Epoch 31/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.6038 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.6038 - accuracy: 0.6667 - val_loss: 0.7474 - val_accuracy: 0.6429\n",
      "Epoch 32/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.6122 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.6122 - accuracy: 0.6410 - val_loss: 0.8021 - val_accuracy: 0.5000\n",
      "Epoch 33/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.6021 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.6021 - accuracy: 0.6667 - val_loss: 0.7526 - val_accuracy: 0.6429\n",
      "Epoch 34/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.6017 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.6017 - accuracy: 0.6410 - val_loss: 0.7990 - val_accuracy: 0.5000\n",
      "Epoch 35/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5997 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5997 - accuracy: 0.6923 - val_loss: 0.7469 - val_accuracy: 0.6429\n",
      "Epoch 36/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.6031 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.6031 - accuracy: 0.6410 - val_loss: 0.8130 - val_accuracy: 0.5000\n",
      "Epoch 37/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.6096 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.6096 - accuracy: 0.6923 - val_loss: 0.7508 - val_accuracy: 0.5000\n",
      "Epoch 38/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.6279 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.6279 - accuracy: 0.6410 - val_loss: 0.8131 - val_accuracy: 0.5000\n",
      "Epoch 39/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.6110 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 0.6110 - accuracy: 0.6410 - val_loss: 0.7576 - val_accuracy: 0.6429\n",
      "Epoch 40/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.6053 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.6053 - accuracy: 0.6410 - val_loss: 0.8079 - val_accuracy: 0.5000\n",
      "Epoch 41/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5982 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.5982 - accuracy: 0.6667 - val_loss: 0.7532 - val_accuracy: 0.6429\n",
      "Epoch 42/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5966 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.5966 - accuracy: 0.6410 - val_loss: 0.7995 - val_accuracy: 0.4286\n",
      "Epoch 43/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.5951 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.5951 - accuracy: 0.6667 - val_loss: 0.7501 - val_accuracy: 0.6429\n",
      "Epoch 44/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5993 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.5993 - accuracy: 0.6410 - val_loss: 0.8063 - val_accuracy: 0.5000\n",
      "Epoch 45/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5955 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.5955 - accuracy: 0.6667 - val_loss: 0.7495 - val_accuracy: 0.6429\n",
      "Epoch 46/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.6010 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.6010 - accuracy: 0.6410 - val_loss: 0.8185 - val_accuracy: 0.5000\n",
      "Epoch 47/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.6006 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.6006 - accuracy: 0.6667 - val_loss: 0.7506 - val_accuracy: 0.6429\n",
      "Epoch 48/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.6119 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.6119 - accuracy: 0.6667 - val_loss: 0.8206 - val_accuracy: 0.5000\n",
      "Epoch 49/2000\n",
      "2/2 [==============================] - 0s 1ms/steposs: 0.6004 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.6004 - accuracy: 0.6410 - val_loss: 0.7554 - val_accuracy: 0.6429\n",
      "Epoch 50/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5988 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.5988 - accuracy: 0.6667 - val_loss: 0.8049 - val_accuracy: 0.5000\n",
      "Epoch 51/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5931 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.5931 - accuracy: 0.7179 - val_loss: 0.7515 - val_accuracy: 0.6429\n",
      "Epoch 52/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5930 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.5930 - accuracy: 0.6410 - val_loss: 0.8083 - val_accuracy: 0.4286\n",
      "Epoch 53/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5979 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.5979 - accuracy: 0.6410 - val_loss: 0.7535 - val_accuracy: 0.5714\n",
      "Epoch 54/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.6141 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.6141 - accuracy: 0.6410 - val_loss: 0.8115 - val_accuracy: 0.5000\n",
      "Epoch 55/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.6003 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.6003 - accuracy: 0.6410 - val_loss: 0.7631 - val_accuracy: 0.6429\n",
      "Epoch 56/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5963 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.5963 - accuracy: 0.6410 - val_loss: 0.8169 - val_accuracy: 0.5000\n",
      "Epoch 57/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5925 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.5925 - accuracy: 0.7179 - val_loss: 0.7550 - val_accuracy: 0.6429\n",
      "Epoch 58/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5925 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.5925 - accuracy: 0.6410 - val_loss: 0.8146 - val_accuracy: 0.5000\n",
      "Epoch 59/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5928 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.5928 - accuracy: 0.6923 - val_loss: 0.7511 - val_accuracy: 0.6429\n",
      "Epoch 60/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.6021 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.6021 - accuracy: 0.6410 - val_loss: 0.8168 - val_accuracy: 0.5000\n",
      "Epoch 61/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5923 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5923 - accuracy: 0.6410 - val_loss: 0.7581 - val_accuracy: 0.6429\n",
      "Epoch 62/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5919 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.5919 - accuracy: 0.6667 - val_loss: 0.8093 - val_accuracy: 0.5000\n",
      "Epoch 63/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5886 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.5886 - accuracy: 0.6923 - val_loss: 0.7541 - val_accuracy: 0.6429\n",
      "Epoch 64/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5886 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.5886 - accuracy: 0.6410 - val_loss: 0.8125 - val_accuracy: 0.5000\n",
      "Epoch 65/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5895 - accuracy: 0.66\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 0.5895 - accuracy: 0.6667 - val_loss: 0.7522 - val_accuracy: 0.5714\n",
      "Epoch 66/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.6038 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.6038 - accuracy: 0.6410 - val_loss: 0.8229 - val_accuracy: 0.5000\n",
      "Epoch 67/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5915 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.5915 - accuracy: 0.6410 - val_loss: 0.7591 - val_accuracy: 0.6429\n",
      "Epoch 68/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5903 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.5903 - accuracy: 0.6667 - val_loss: 0.8110 - val_accuracy: 0.5000\n",
      "Epoch 69/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5862 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5862 - accuracy: 0.6923 - val_loss: 0.7534 - val_accuracy: 0.6429\n",
      "Epoch 70/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5858 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.5858 - accuracy: 0.6410 - val_loss: 0.8155 - val_accuracy: 0.5000\n",
      "Epoch 71/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.5907 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.5907 - accuracy: 0.6667 - val_loss: 0.7554 - val_accuracy: 0.5714\n",
      "Epoch 72/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.6117 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.6117 - accuracy: 0.6410 - val_loss: 0.8207 - val_accuracy: 0.5000\n",
      "Epoch 73/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5959 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.5959 - accuracy: 0.6410 - val_loss: 0.7653 - val_accuracy: 0.6429\n",
      "Epoch 74/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5898 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.5898 - accuracy: 0.6410 - val_loss: 0.8204 - val_accuracy: 0.5000\n",
      "Epoch 75/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5850 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.5850 - accuracy: 0.6923 - val_loss: 0.7552 - val_accuracy: 0.6429\n",
      "Epoch 76/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5851 - accuracy: 0.64\n",
      "1/1 [==============================] - 1s 893ms/step - loss: 0.5851 - accuracy: 0.6410 - val_loss: 0.8173 - val_accuracy: 0.5000\n",
      "Epoch 77/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5866 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5866 - accuracy: 0.6667 - val_loss: 0.7543 - val_accuracy: 0.5714\n",
      "Epoch 78/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5993 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.5993 - accuracy: 0.6410 - val_loss: 0.8188 - val_accuracy: 0.5000\n",
      "Epoch 79/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5882 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.5882 - accuracy: 0.6410 - val_loss: 0.7663 - val_accuracy: 0.6429\n",
      "Epoch 80/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5847 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.5847 - accuracy: 0.6410 - val_loss: 0.8187 - val_accuracy: 0.5000\n",
      "Epoch 81/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5819 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.5819 - accuracy: 0.6667 - val_loss: 0.7537 - val_accuracy: 0.6429\n",
      "Epoch 82/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5836 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.5836 - accuracy: 0.6410 - val_loss: 0.8247 - val_accuracy: 0.5000\n",
      "Epoch 83/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5882 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.5882 - accuracy: 0.6410 - val_loss: 0.7534 - val_accuracy: 0.5714\n",
      "Epoch 84/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.6031 - accuracy: 0.64\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.6031 - accuracy: 0.6410 - val_loss: 0.8214 - val_accuracy: 0.5000\n",
      "Epoch 85/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5902 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.5902 - accuracy: 0.6410 - val_loss: 0.7650 - val_accuracy: 0.6429\n",
      "Epoch 86/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5843 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.5843 - accuracy: 0.6410 - val_loss: 0.8225 - val_accuracy: 0.5000\n",
      "Epoch 87/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.5802 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.5802 - accuracy: 0.6667 - val_loss: 0.7556 - val_accuracy: 0.6429\n",
      "Epoch 88/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5798 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.5798 - accuracy: 0.6667 - val_loss: 0.8183 - val_accuracy: 0.5000\n",
      "Epoch 89/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5805 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.5805 - accuracy: 0.6410 - val_loss: 0.7528 - val_accuracy: 0.6429\n",
      "Epoch 90/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5906 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5906 - accuracy: 0.6410 - val_loss: 0.8212 - val_accuracy: 0.5000\n",
      "Epoch 91/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5810 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.5810 - accuracy: 0.6410 - val_loss: 0.7649 - val_accuracy: 0.6429\n",
      "Epoch 92/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5799 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.5799 - accuracy: 0.6923 - val_loss: 0.8153 - val_accuracy: 0.5000\n",
      "Epoch 93/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5776 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.5776 - accuracy: 0.6410 - val_loss: 0.7588 - val_accuracy: 0.6429\n",
      "Epoch 94/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5775 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.5775 - accuracy: 0.6923 - val_loss: 0.8088 - val_accuracy: 0.5000\n",
      "Epoch 95/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5766 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5766 - accuracy: 0.6410 - val_loss: 0.7630 - val_accuracy: 0.6429\n",
      "Epoch 96/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5780 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.5780 - accuracy: 0.6667 - val_loss: 0.7953 - val_accuracy: 0.5000\n",
      "Epoch 97/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5847 - accuracy: 0.64\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 0.5847 - accuracy: 0.6410 - val_loss: 0.7618 - val_accuracy: 0.6429\n",
      "Epoch 98/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5739 - accuracy: 0.61\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.5739 - accuracy: 0.6154 - val_loss: 0.8341 - val_accuracy: 0.5000\n",
      "Epoch 99/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.5805 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.5805 - accuracy: 0.6410 - val_loss: 0.7484 - val_accuracy: 0.5714\n",
      "Epoch 100/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.6016 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.6016 - accuracy: 0.6667 - val_loss: 0.8354 - val_accuracy: 0.5000\n",
      "Epoch 101/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5898 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.5898 - accuracy: 0.6667 - val_loss: 0.7569 - val_accuracy: 0.6429\n",
      "Epoch 102/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5809 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.5809 - accuracy: 0.6667 - val_loss: 0.8192 - val_accuracy: 0.5000\n",
      "Epoch 103/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5735 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.5735 - accuracy: 0.6667 - val_loss: 0.7553 - val_accuracy: 0.6429\n",
      "Epoch 104/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5735 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.5735 - accuracy: 0.6667 - val_loss: 0.8184 - val_accuracy: 0.5000\n",
      "Epoch 105/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5737 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.5737 - accuracy: 0.6410 - val_loss: 0.7555 - val_accuracy: 0.5714\n",
      "Epoch 106/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.5852 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.5852 - accuracy: 0.6667 - val_loss: 0.8189 - val_accuracy: 0.5000\n",
      "Epoch 107/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5751 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.5751 - accuracy: 0.6410 - val_loss: 0.7680 - val_accuracy: 0.6429\n",
      "Epoch 108/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5718 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.5718 - accuracy: 0.6410 - val_loss: 0.8248 - val_accuracy: 0.5000\n",
      "Epoch 109/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5708 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.5708 - accuracy: 0.6667 - val_loss: 0.7524 - val_accuracy: 0.6429\n",
      "Epoch 110/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5737 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.5737 - accuracy: 0.6667 - val_loss: 0.8349 - val_accuracy: 0.5000\n",
      "Epoch 111/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5796 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.5796 - accuracy: 0.6923 - val_loss: 0.7520 - val_accuracy: 0.5714\n",
      "Epoch 112/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5947 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.5947 - accuracy: 0.6410 - val_loss: 0.8294 - val_accuracy: 0.5000\n",
      "Epoch 113/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5809 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.5809 - accuracy: 0.6923 - val_loss: 0.7662 - val_accuracy: 0.6429\n",
      "Epoch 114/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5729 - accuracy: 0.66\n",
      "1/1 [==============================] - 1s 695ms/step - loss: 0.5729 - accuracy: 0.6667 - val_loss: 0.8255 - val_accuracy: 0.5000\n",
      "Epoch 115/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5681 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.5681 - accuracy: 0.6667 - val_loss: 0.7571 - val_accuracy: 0.6429\n",
      "Epoch 116/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5673 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.5673 - accuracy: 0.6410 - val_loss: 0.8208 - val_accuracy: 0.5000\n",
      "Epoch 117/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5681 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.5681 - accuracy: 0.6667 - val_loss: 0.7533 - val_accuracy: 0.6429\n",
      "Epoch 118/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5782 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5782 - accuracy: 0.6667 - val_loss: 0.8244 - val_accuracy: 0.5000\n",
      "Epoch 119/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5690 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.5690 - accuracy: 0.6667 - val_loss: 0.7664 - val_accuracy: 0.6429\n",
      "Epoch 120/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5686 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 0.5686 - accuracy: 0.6923 - val_loss: 0.8201 - val_accuracy: 0.5000\n",
      "Epoch 121/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5678 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.5678 - accuracy: 0.7179 - val_loss: 0.7616 - val_accuracy: 0.6429\n",
      "Epoch 122/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5687 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.5687 - accuracy: 0.6923 - val_loss: 0.8114 - val_accuracy: 0.5000\n",
      "Epoch 123/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5709 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.5709 - accuracy: 0.7179 - val_loss: 0.7659 - val_accuracy: 0.6429\n",
      "Epoch 124/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5653 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.5653 - accuracy: 0.6923 - val_loss: 0.8088 - val_accuracy: 0.5000\n",
      "Epoch 125/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5657 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.5657 - accuracy: 0.7179 - val_loss: 0.7653 - val_accuracy: 0.6429\n",
      "Epoch 126/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5667 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 0.5667 - accuracy: 0.6410 - val_loss: 0.8003 - val_accuracy: 0.5000\n",
      "Epoch 127/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5746 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.5746 - accuracy: 0.6923 - val_loss: 0.7624 - val_accuracy: 0.6429\n",
      "Epoch 128/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5645 - accuracy: 0.61\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.5645 - accuracy: 0.6154 - val_loss: 0.8462 - val_accuracy: 0.5000\n",
      "Epoch 129/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5705 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.5705 - accuracy: 0.7179 - val_loss: 0.7453 - val_accuracy: 0.6429\n",
      "Epoch 130/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5875 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.5875 - accuracy: 0.6667 - val_loss: 0.8447 - val_accuracy: 0.5000\n",
      "Epoch 131/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5754 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.5754 - accuracy: 0.6410 - val_loss: 0.7558 - val_accuracy: 0.6429\n",
      "Epoch 132/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5692 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.5692 - accuracy: 0.6923 - val_loss: 0.8196 - val_accuracy: 0.5000\n",
      "Epoch 133/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5619 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.5619 - accuracy: 0.7179 - val_loss: 0.7641 - val_accuracy: 0.6429\n",
      "Epoch 134/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5585 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.5585 - accuracy: 0.6410 - val_loss: 0.8012 - val_accuracy: 0.5000\n",
      "Epoch 135/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5591 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5591 - accuracy: 0.6667 - val_loss: 0.7747 - val_accuracy: 0.7143\n",
      "Epoch 136/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5561 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.5561 - accuracy: 0.6667 - val_loss: 0.7906 - val_accuracy: 0.5714\n",
      "Epoch 137/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5644 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.5644 - accuracy: 0.6667 - val_loss: 0.7694 - val_accuracy: 0.7143\n",
      "Epoch 138/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5533 - accuracy: 0.66\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 0.5533 - accuracy: 0.6667 - val_loss: 0.8294 - val_accuracy: 0.5000\n",
      "Epoch 139/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5603 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.5603 - accuracy: 0.6667 - val_loss: 0.7530 - val_accuracy: 0.5714\n",
      "Epoch 140/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5848 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.5848 - accuracy: 0.6667 - val_loss: 0.8616 - val_accuracy: 0.5000\n",
      "Epoch 141/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5829 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.5829 - accuracy: 0.6410 - val_loss: 0.7631 - val_accuracy: 0.6429\n",
      "Epoch 142/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5747 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.5747 - accuracy: 0.6410 - val_loss: 0.8482 - val_accuracy: 0.5000\n",
      "Epoch 143/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5669 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.5669 - accuracy: 0.6923 - val_loss: 0.7541 - val_accuracy: 0.6429\n",
      "Epoch 144/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5688 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.5688 - accuracy: 0.6667 - val_loss: 0.8268 - val_accuracy: 0.5000\n",
      "Epoch 145/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5557 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.5557 - accuracy: 0.7436 - val_loss: 0.7652 - val_accuracy: 0.6429\n",
      "Epoch 146/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5526 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5526 - accuracy: 0.6410 - val_loss: 0.8185 - val_accuracy: 0.5000\n",
      "Epoch 147/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5526 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.5526 - accuracy: 0.6923 - val_loss: 0.7579 - val_accuracy: 0.6429\n",
      "Epoch 148/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5617 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.5617 - accuracy: 0.6667 - val_loss: 0.8301 - val_accuracy: 0.5000\n",
      "Epoch 149/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5536 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.5536 - accuracy: 0.7436 - val_loss: 0.7592 - val_accuracy: 0.6429\n",
      "Epoch 150/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5562 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.5562 - accuracy: 0.6667 - val_loss: 0.8445 - val_accuracy: 0.5000\n",
      "Epoch 151/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5679 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.5679 - accuracy: 0.7179 - val_loss: 0.7588 - val_accuracy: 0.5714\n",
      "Epoch 152/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5865 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.5865 - accuracy: 0.6410 - val_loss: 0.8430 - val_accuracy: 0.5000\n",
      "Epoch 153/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5737 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.5737 - accuracy: 0.6667 - val_loss: 0.7687 - val_accuracy: 0.6429\n",
      "Epoch 154/2000\n",
      "2/2 [==============================] - 0s 998us/steps: 0.5626 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.5626 - accuracy: 0.6667 - val_loss: 0.8404 - val_accuracy: 0.5000\n",
      "Epoch 155/2000\n",
      "2/2 [==============================] - 0s 1ms/steposs: 0.5560 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.5560 - accuracy: 0.7436 - val_loss: 0.7662 - val_accuracy: 0.6429\n",
      "Epoch 156/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5524 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.5524 - accuracy: 0.6667 - val_loss: 0.8273 - val_accuracy: 0.5000\n",
      "Epoch 157/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5515 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.5515 - accuracy: 0.7436 - val_loss: 0.7602 - val_accuracy: 0.6429\n",
      "Epoch 158/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5565 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.5565 - accuracy: 0.6667 - val_loss: 0.8334 - val_accuracy: 0.5000\n",
      "Epoch 159/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5511 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.5511 - accuracy: 0.7436 - val_loss: 0.7602 - val_accuracy: 0.6429\n",
      "Epoch 160/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5553 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.5553 - accuracy: 0.6923 - val_loss: 0.8453 - val_accuracy: 0.5000\n",
      "Epoch 161/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5590 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.5590 - accuracy: 0.7179 - val_loss: 0.7593 - val_accuracy: 0.5714\n",
      "Epoch 162/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5727 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.5727 - accuracy: 0.6667 - val_loss: 0.8442 - val_accuracy: 0.5000\n",
      "Epoch 163/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5621 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.5621 - accuracy: 0.6923 - val_loss: 0.7753 - val_accuracy: 0.6429\n",
      "Epoch 164/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.5560 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.5560 - accuracy: 0.6923 - val_loss: 0.8339 - val_accuracy: 0.5000\n",
      "Epoch 165/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5519 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.5519 - accuracy: 0.7179 - val_loss: 0.7716 - val_accuracy: 0.6429\n",
      "Epoch 166/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5496 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.5496 - accuracy: 0.7179 - val_loss: 0.8213 - val_accuracy: 0.5714\n",
      "Epoch 167/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5496 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.5496 - accuracy: 0.7179 - val_loss: 0.7776 - val_accuracy: 0.6429\n",
      "Epoch 168/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5506 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.5506 - accuracy: 0.6667 - val_loss: 0.8089 - val_accuracy: 0.5714\n",
      "Epoch 169/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5597 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.5597 - accuracy: 0.7179 - val_loss: 0.7705 - val_accuracy: 0.6429\n",
      "Epoch 170/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5490 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.5490 - accuracy: 0.6667 - val_loss: 0.8509 - val_accuracy: 0.5000\n",
      "Epoch 171/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5524 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.5524 - accuracy: 0.7179 - val_loss: 0.7567 - val_accuracy: 0.6429\n",
      "Epoch 172/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5670 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.5670 - accuracy: 0.6667 - val_loss: 0.8583 - val_accuracy: 0.5000\n",
      "Epoch 173/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.5592 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.5592 - accuracy: 0.6923 - val_loss: 0.7668 - val_accuracy: 0.6429\n",
      "Epoch 174/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5558 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.5558 - accuracy: 0.6923 - val_loss: 0.8444 - val_accuracy: 0.5000\n",
      "Epoch 175/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5513 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.5513 - accuracy: 0.7179 - val_loss: 0.7675 - val_accuracy: 0.6429\n",
      "Epoch 176/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5473 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.5473 - accuracy: 0.7179 - val_loss: 0.8381 - val_accuracy: 0.5714\n",
      "Epoch 177/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5471 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.5471 - accuracy: 0.7436 - val_loss: 0.7632 - val_accuracy: 0.6429\n",
      "Epoch 178/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5597 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 0.5597 - accuracy: 0.6923 - val_loss: 0.8458 - val_accuracy: 0.5714\n",
      "Epoch 179/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5466 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.5466 - accuracy: 0.7436 - val_loss: 0.7717 - val_accuracy: 0.6429\n",
      "Epoch 180/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5448 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.5448 - accuracy: 0.7179 - val_loss: 0.8423 - val_accuracy: 0.5714\n",
      "Epoch 181/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5463 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.5463 - accuracy: 0.7179 - val_loss: 0.7641 - val_accuracy: 0.6429\n",
      "Epoch 182/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5606 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.5606 - accuracy: 0.6923 - val_loss: 0.8555 - val_accuracy: 0.5000\n",
      "Epoch 183/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5483 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.5483 - accuracy: 0.7179 - val_loss: 0.7685 - val_accuracy: 0.6429\n",
      "Epoch 184/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5481 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.5481 - accuracy: 0.6923 - val_loss: 0.8569 - val_accuracy: 0.5714\n",
      "Epoch 185/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5622 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.5622 - accuracy: 0.6923 - val_loss: 0.7719 - val_accuracy: 0.6429\n",
      "Epoch 186/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5766 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.5766 - accuracy: 0.6667 - val_loss: 0.8435 - val_accuracy: 0.5714\n",
      "Epoch 187/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5622 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.5622 - accuracy: 0.6923 - val_loss: 0.7775 - val_accuracy: 0.6429\n",
      "Epoch 188/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5513 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.5513 - accuracy: 0.6667 - val_loss: 0.8460 - val_accuracy: 0.5714\n",
      "Epoch 189/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5441 - accuracy: 0.71\n",
      "1/1 [==============================] - 1s 626ms/step - loss: 0.5441 - accuracy: 0.7179 - val_loss: 0.7829 - val_accuracy: 0.6429\n",
      "Epoch 190/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5400 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.5400 - accuracy: 0.6667 - val_loss: 0.8366 - val_accuracy: 0.5714\n",
      "Epoch 191/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5388 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.5388 - accuracy: 0.7436 - val_loss: 0.7769 - val_accuracy: 0.6429\n",
      "Epoch 192/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5389 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.5389 - accuracy: 0.6667 - val_loss: 0.8455 - val_accuracy: 0.5714\n",
      "Epoch 193/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5423 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.5423 - accuracy: 0.7179 - val_loss: 0.7678 - val_accuracy: 0.6429\n",
      "Epoch 194/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5534 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.5534 - accuracy: 0.6923 - val_loss: 0.8656 - val_accuracy: 0.5714\n",
      "Epoch 195/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5484 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.5484 - accuracy: 0.6923 - val_loss: 0.7705 - val_accuracy: 0.6429\n",
      "Epoch 196/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5516 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.5516 - accuracy: 0.6923 - val_loss: 0.8698 - val_accuracy: 0.5714\n",
      "Epoch 197/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5563 - accuracy: 0.66\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.5563 - accuracy: 0.6667 - val_loss: 0.7722 - val_accuracy: 0.6429\n",
      "Epoch 198/2000\n",
      "2/2 [==============================] - 0s 7ms/steposs: 0.5664 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.5664 - accuracy: 0.6667 - val_loss: 0.8485 - val_accuracy: 0.5714\n",
      "Epoch 199/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5520 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.5520 - accuracy: 0.6923 - val_loss: 0.7866 - val_accuracy: 0.6429\n",
      "Epoch 200/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5408 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.5408 - accuracy: 0.6667 - val_loss: 0.8473 - val_accuracy: 0.5714\n",
      "Epoch 201/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5375 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.5375 - accuracy: 0.7436 - val_loss: 0.7782 - val_accuracy: 0.5714\n",
      "Epoch 202/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5371 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.5371 - accuracy: 0.6410 - val_loss: 0.8473 - val_accuracy: 0.5714\n",
      "Epoch 203/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5399 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.5399 - accuracy: 0.7179 - val_loss: 0.7728 - val_accuracy: 0.6429\n",
      "Epoch 204/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5523 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.5523 - accuracy: 0.6923 - val_loss: 0.8525 - val_accuracy: 0.5714\n",
      "Epoch 205/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5423 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.5423 - accuracy: 0.6923 - val_loss: 0.7896 - val_accuracy: 0.6429\n",
      "Epoch 206/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5426 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.5426 - accuracy: 0.7179 - val_loss: 0.8439 - val_accuracy: 0.5714\n",
      "Epoch 207/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5468 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.5468 - accuracy: 0.6667 - val_loss: 0.7864 - val_accuracy: 0.6429\n",
      "Epoch 208/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5405 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5405 - accuracy: 0.7179 - val_loss: 0.8481 - val_accuracy: 0.5714\n",
      "Epoch 209/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5413 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.5413 - accuracy: 0.6667 - val_loss: 0.7882 - val_accuracy: 0.6429\n",
      "Epoch 210/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.5409 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.5409 - accuracy: 0.6923 - val_loss: 0.8341 - val_accuracy: 0.5714\n",
      "Epoch 211/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5479 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.5479 - accuracy: 0.6667 - val_loss: 0.7849 - val_accuracy: 0.5714\n",
      "Epoch 212/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5357 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.5357 - accuracy: 0.6410 - val_loss: 0.8689 - val_accuracy: 0.5714\n",
      "Epoch 213/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5452 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.5452 - accuracy: 0.6923 - val_loss: 0.7738 - val_accuracy: 0.6429\n",
      "Epoch 214/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5664 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.5664 - accuracy: 0.6667 - val_loss: 0.8659 - val_accuracy: 0.5714\n",
      "Epoch 215/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5553 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.5553 - accuracy: 0.6667 - val_loss: 0.7824 - val_accuracy: 0.6429\n",
      "Epoch 216/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5412 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.5412 - accuracy: 0.6923 - val_loss: 0.8615 - val_accuracy: 0.5714\n",
      "Epoch 217/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5393 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.5393 - accuracy: 0.6923 - val_loss: 0.7769 - val_accuracy: 0.6429\n",
      "Epoch 218/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5437 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.5437 - accuracy: 0.6923 - val_loss: 0.8565 - val_accuracy: 0.5714\n",
      "Epoch 219/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5342 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.5342 - accuracy: 0.7179 - val_loss: 0.7839 - val_accuracy: 0.5714\n",
      "Epoch 220/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5325 - accuracy: 0.66\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 0.5325 - accuracy: 0.6667 - val_loss: 0.8548 - val_accuracy: 0.5714\n",
      "Epoch 221/2000\n",
      "2/2 [==============================] - 0s 997us/steps: 0.5356 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.5356 - accuracy: 0.6923 - val_loss: 0.7766 - val_accuracy: 0.7143\n",
      "Epoch 222/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5487 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.5487 - accuracy: 0.6923 - val_loss: 0.8648 - val_accuracy: 0.5714\n",
      "Epoch 223/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5381 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.5381 - accuracy: 0.6667 - val_loss: 0.7912 - val_accuracy: 0.6429\n",
      "Epoch 224/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5371 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.5371 - accuracy: 0.7179 - val_loss: 0.8494 - val_accuracy: 0.5714\n",
      "Epoch 225/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5396 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.5396 - accuracy: 0.6667 - val_loss: 0.7940 - val_accuracy: 0.6429\n",
      "Epoch 226/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5367 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.5367 - accuracy: 0.6667 - val_loss: 0.8367 - val_accuracy: 0.5714\n",
      "Epoch 227/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5443 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.5443 - accuracy: 0.6667 - val_loss: 0.7883 - val_accuracy: 0.5714\n",
      "Epoch 228/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5319 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.5319 - accuracy: 0.6410 - val_loss: 0.8738 - val_accuracy: 0.5714\n",
      "Epoch 229/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5421 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.5421 - accuracy: 0.6923 - val_loss: 0.7790 - val_accuracy: 0.6429\n",
      "Epoch 230/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5628 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.5628 - accuracy: 0.6667 - val_loss: 0.8709 - val_accuracy: 0.5714\n",
      "Epoch 231/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5529 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.5529 - accuracy: 0.6667 - val_loss: 0.7859 - val_accuracy: 0.7143\n",
      "Epoch 232/2000\n",
      "2/2 [==============================] - 0s 7ms/steposs: 0.5391 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.5391 - accuracy: 0.6923 - val_loss: 0.8695 - val_accuracy: 0.5714\n",
      "Epoch 233/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5365 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.5365 - accuracy: 0.6923 - val_loss: 0.7813 - val_accuracy: 0.6429\n",
      "Epoch 234/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.5395 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.5395 - accuracy: 0.6667 - val_loss: 0.8613 - val_accuracy: 0.5714\n",
      "Epoch 235/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5306 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.5306 - accuracy: 0.7179 - val_loss: 0.7877 - val_accuracy: 0.6429\n",
      "Epoch 236/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5289 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.5289 - accuracy: 0.6667 - val_loss: 0.8590 - val_accuracy: 0.5714\n",
      "Epoch 237/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5320 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.5320 - accuracy: 0.6923 - val_loss: 0.7806 - val_accuracy: 0.6429\n",
      "Epoch 238/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5444 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.5444 - accuracy: 0.6667 - val_loss: 0.8690 - val_accuracy: 0.5714\n",
      "Epoch 239/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5342 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.5342 - accuracy: 0.6667 - val_loss: 0.7949 - val_accuracy: 0.6429\n",
      "Epoch 240/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5331 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 0.5331 - accuracy: 0.6923 - val_loss: 0.8550 - val_accuracy: 0.5714\n",
      "Epoch 241/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5353 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.5353 - accuracy: 0.6667 - val_loss: 0.7975 - val_accuracy: 0.6429\n",
      "Epoch 242/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5342 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.5342 - accuracy: 0.6667 - val_loss: 0.8417 - val_accuracy: 0.5714\n",
      "Epoch 243/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5427 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.5427 - accuracy: 0.6667 - val_loss: 0.7907 - val_accuracy: 0.6429\n",
      "Epoch 244/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5304 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.5304 - accuracy: 0.6667 - val_loss: 0.8816 - val_accuracy: 0.5714\n",
      "Epoch 245/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5385 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.5385 - accuracy: 0.6667 - val_loss: 0.7810 - val_accuracy: 0.6429\n",
      "Epoch 246/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5569 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.5569 - accuracy: 0.6667 - val_loss: 0.8739 - val_accuracy: 0.5714\n",
      "Epoch 247/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5463 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.5463 - accuracy: 0.6667 - val_loss: 0.7902 - val_accuracy: 0.7143\n",
      "Epoch 248/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5331 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.5331 - accuracy: 0.7179 - val_loss: 0.8663 - val_accuracy: 0.5714\n",
      "Epoch 249/2000\n",
      "2/2 [==============================] - 0s 997us/steps: 0.5302 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.5302 - accuracy: 0.6923 - val_loss: 0.7855 - val_accuracy: 0.6429\n",
      "Epoch 250/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5310 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.5310 - accuracy: 0.6667 - val_loss: 0.8677 - val_accuracy: 0.5714\n",
      "Epoch 251/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5335 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5335 - accuracy: 0.6923 - val_loss: 0.7851 - val_accuracy: 0.6429\n",
      "Epoch 252/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5458 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.5458 - accuracy: 0.6410 - val_loss: 0.8650 - val_accuracy: 0.5714\n",
      "Epoch 253/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5353 - accuracy: 0.66\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 0.5353 - accuracy: 0.6667 - val_loss: 0.8004 - val_accuracy: 0.6429\n",
      "Epoch 254/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5273 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.5273 - accuracy: 0.6923 - val_loss: 0.8649 - val_accuracy: 0.5714\n",
      "Epoch 255/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5261 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.5261 - accuracy: 0.6923 - val_loss: 0.7904 - val_accuracy: 0.6429\n",
      "Epoch 256/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.5265 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.5265 - accuracy: 0.6667 - val_loss: 0.8749 - val_accuracy: 0.5714\n",
      "Epoch 257/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5343 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.5343 - accuracy: 0.6667 - val_loss: 0.7852 - val_accuracy: 0.6429\n",
      "Epoch 258/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5520 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.5520 - accuracy: 0.6667 - val_loss: 0.8771 - val_accuracy: 0.5714\n",
      "Epoch 259/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5410 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.5410 - accuracy: 0.6667 - val_loss: 0.8001 - val_accuracy: 0.6429\n",
      "Epoch 260/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5301 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.5301 - accuracy: 0.6923 - val_loss: 0.8695 - val_accuracy: 0.5714\n",
      "Epoch 261/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5268 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.5268 - accuracy: 0.6923 - val_loss: 0.7924 - val_accuracy: 0.6429\n",
      "Epoch 262/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5245 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.5245 - accuracy: 0.6923 - val_loss: 0.8693 - val_accuracy: 0.5714\n",
      "Epoch 263/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5281 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5281 - accuracy: 0.6667 - val_loss: 0.7853 - val_accuracy: 0.6429\n",
      "Epoch 264/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5440 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.5440 - accuracy: 0.6410 - val_loss: 0.8744 - val_accuracy: 0.5714\n",
      "Epoch 265/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5307 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.5307 - accuracy: 0.6667 - val_loss: 0.8037 - val_accuracy: 0.6429\n",
      "Epoch 266/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5283 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.5283 - accuracy: 0.6667 - val_loss: 0.8495 - val_accuracy: 0.5714\n",
      "Epoch 267/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5336 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.5336 - accuracy: 0.6667 - val_loss: 0.8005 - val_accuracy: 0.6429\n",
      "Epoch 268/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5212 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.5212 - accuracy: 0.6923 - val_loss: 0.8667 - val_accuracy: 0.5714\n",
      "Epoch 269/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5222 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.5222 - accuracy: 0.6923 - val_loss: 0.7866 - val_accuracy: 0.6429\n",
      "Epoch 270/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5288 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.5288 - accuracy: 0.6410 - val_loss: 0.8924 - val_accuracy: 0.5714\n",
      "Epoch 271/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5528 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.5528 - accuracy: 0.6667 - val_loss: 0.7924 - val_accuracy: 0.6429\n",
      "Epoch 272/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5651 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.5651 - accuracy: 0.6667 - val_loss: 0.8784 - val_accuracy: 0.5714\n",
      "Epoch 273/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5528 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.5528 - accuracy: 0.6667 - val_loss: 0.7907 - val_accuracy: 0.6429\n",
      "Epoch 274/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5384 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.5384 - accuracy: 0.6667 - val_loss: 0.8669 - val_accuracy: 0.5714\n",
      "Epoch 275/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5273 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.5273 - accuracy: 0.6923 - val_loss: 0.8033 - val_accuracy: 0.5714\n",
      "Epoch 276/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5196 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.5196 - accuracy: 0.6923 - val_loss: 0.8559 - val_accuracy: 0.5714\n",
      "Epoch 277/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5172 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.5172 - accuracy: 0.7179 - val_loss: 0.7994 - val_accuracy: 0.5714\n",
      "Epoch 278/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5161 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.5161 - accuracy: 0.6923 - val_loss: 0.8592 - val_accuracy: 0.5714\n",
      "Epoch 279/2000\n",
      "2/2 [==============================] - 0s 1ms/steposs: 0.5176 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.5176 - accuracy: 0.7179 - val_loss: 0.7916 - val_accuracy: 0.6429\n",
      "Epoch 280/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5225 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.5225 - accuracy: 0.6667 - val_loss: 0.8837 - val_accuracy: 0.5714\n",
      "Epoch 281/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5314 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.5314 - accuracy: 0.6667 - val_loss: 0.7883 - val_accuracy: 0.7143\n",
      "Epoch 282/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5494 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.5494 - accuracy: 0.6667 - val_loss: 0.8941 - val_accuracy: 0.5714\n",
      "Epoch 283/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5400 - accuracy: 0.66\n",
      "1/1 [==============================] - 1s 630ms/step - loss: 0.5400 - accuracy: 0.6667 - val_loss: 0.8041 - val_accuracy: 0.6429\n",
      "Epoch 284/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5297 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.5297 - accuracy: 0.7179 - val_loss: 0.8722 - val_accuracy: 0.5714\n",
      "Epoch 285/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5250 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.5250 - accuracy: 0.6667 - val_loss: 0.8037 - val_accuracy: 0.6429\n",
      "Epoch 286/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5204 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.5204 - accuracy: 0.6923 - val_loss: 0.8516 - val_accuracy: 0.5714\n",
      "Epoch 287/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5222 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.5222 - accuracy: 0.6667 - val_loss: 0.8086 - val_accuracy: 0.5714\n",
      "Epoch 288/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5167 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.5167 - accuracy: 0.6667 - val_loss: 0.8403 - val_accuracy: 0.5714\n",
      "Epoch 289/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5238 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.5238 - accuracy: 0.6667 - val_loss: 0.8052 - val_accuracy: 0.5714\n",
      "Epoch 290/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5127 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.5127 - accuracy: 0.7179 - val_loss: 0.8619 - val_accuracy: 0.5714\n",
      "Epoch 291/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5152 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.5152 - accuracy: 0.6923 - val_loss: 0.7966 - val_accuracy: 0.6429\n",
      "Epoch 292/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5196 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.5196 - accuracy: 0.6667 - val_loss: 0.8906 - val_accuracy: 0.5714\n",
      "Epoch 293/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5274 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.5274 - accuracy: 0.6923 - val_loss: 0.7891 - val_accuracy: 0.7143\n",
      "Epoch 294/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5376 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.5376 - accuracy: 0.6410 - val_loss: 0.9246 - val_accuracy: 0.5714\n",
      "Epoch 295/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5917 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 0.5917 - accuracy: 0.6667 - val_loss: 0.7986 - val_accuracy: 0.6429\n",
      "Epoch 296/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5694 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.5694 - accuracy: 0.6410 - val_loss: 0.8687 - val_accuracy: 0.5000\n",
      "Epoch 297/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5486 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.5486 - accuracy: 0.6667 - val_loss: 0.7913 - val_accuracy: 0.5714\n",
      "Epoch 298/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5324 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.5324 - accuracy: 0.6410 - val_loss: 0.8453 - val_accuracy: 0.5714\n",
      "Epoch 299/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5215 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.5215 - accuracy: 0.7179 - val_loss: 0.7989 - val_accuracy: 0.7143\n",
      "Epoch 300/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5124 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.5124 - accuracy: 0.7436 - val_loss: 0.8416 - val_accuracy: 0.5714\n",
      "Epoch 301/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5100 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5100 - accuracy: 0.7436 - val_loss: 0.7993 - val_accuracy: 0.6429\n",
      "Epoch 302/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5091 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.5091 - accuracy: 0.7436 - val_loss: 0.8468 - val_accuracy: 0.5714\n",
      "Epoch 303/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5097 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.5097 - accuracy: 0.7436 - val_loss: 0.7958 - val_accuracy: 0.5714\n",
      "Epoch 304/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5124 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.5124 - accuracy: 0.7179 - val_loss: 0.8708 - val_accuracy: 0.5714\n",
      "Epoch 305/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5185 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.5185 - accuracy: 0.6923 - val_loss: 0.7924 - val_accuracy: 0.6429\n",
      "Epoch 306/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5301 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.5301 - accuracy: 0.6667 - val_loss: 0.9098 - val_accuracy: 0.5714\n",
      "Epoch 307/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5368 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.5368 - accuracy: 0.6923 - val_loss: 0.7936 - val_accuracy: 0.7143\n",
      "Epoch 308/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5412 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.5412 - accuracy: 0.6410 - val_loss: 0.9027 - val_accuracy: 0.5714\n",
      "Epoch 309/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5311 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.5311 - accuracy: 0.6923 - val_loss: 0.7948 - val_accuracy: 0.6429\n",
      "Epoch 310/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5246 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.5246 - accuracy: 0.6410 - val_loss: 0.8785 - val_accuracy: 0.5714\n",
      "Epoch 311/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5198 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.5198 - accuracy: 0.6667 - val_loss: 0.7929 - val_accuracy: 0.5714\n",
      "Epoch 312/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5251 - accuracy: 0.66\n",
      "1/1 [==============================] - 1s 584ms/step - loss: 0.5251 - accuracy: 0.6667 - val_loss: 0.8685 - val_accuracy: 0.5714\n",
      "Epoch 313/2000\n",
      "2/2 [==============================] - 0s 6ms/steposs: 0.5112 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.5112 - accuracy: 0.6923 - val_loss: 0.8054 - val_accuracy: 0.5714\n",
      "Epoch 314/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5094 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5094 - accuracy: 0.7436 - val_loss: 0.8596 - val_accuracy: 0.5714\n",
      "Epoch 315/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5100 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.5100 - accuracy: 0.6923 - val_loss: 0.8048 - val_accuracy: 0.5714\n",
      "Epoch 316/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5125 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5125 - accuracy: 0.6923 - val_loss: 0.8600 - val_accuracy: 0.5714\n",
      "Epoch 317/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5229 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.5229 - accuracy: 0.6667 - val_loss: 0.8113 - val_accuracy: 0.6429\n",
      "Epoch 318/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5209 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.5209 - accuracy: 0.6667 - val_loss: 0.8561 - val_accuracy: 0.5714\n",
      "Epoch 319/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5356 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.5356 - accuracy: 0.6667 - val_loss: 0.7977 - val_accuracy: 0.6429\n",
      "Epoch 320/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5209 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.5209 - accuracy: 0.6410 - val_loss: 0.9076 - val_accuracy: 0.5714\n",
      "Epoch 321/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5340 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.5340 - accuracy: 0.6667 - val_loss: 0.7972 - val_accuracy: 0.5714\n",
      "Epoch 322/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5541 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.5541 - accuracy: 0.6667 - val_loss: 0.8900 - val_accuracy: 0.5714\n",
      "Epoch 323/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5396 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.5396 - accuracy: 0.6667 - val_loss: 0.8009 - val_accuracy: 0.6429\n",
      "Epoch 324/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5196 - accuracy: 0.66\n",
      "1/1 [==============================] - 1s 711ms/step - loss: 0.5196 - accuracy: 0.6667 - val_loss: 0.8801 - val_accuracy: 0.5714\n",
      "Epoch 325/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5149 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.5149 - accuracy: 0.6667 - val_loss: 0.7970 - val_accuracy: 0.5714\n",
      "Epoch 326/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5173 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.5173 - accuracy: 0.6923 - val_loss: 0.8730 - val_accuracy: 0.5714\n",
      "Epoch 327/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5102 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.5102 - accuracy: 0.6923 - val_loss: 0.7984 - val_accuracy: 0.5714\n",
      "Epoch 328/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5134 - accuracy: 0.71\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 0.5134 - accuracy: 0.7179 - val_loss: 0.8781 - val_accuracy: 0.5714\n",
      "Epoch 329/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5156 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.5156 - accuracy: 0.6667 - val_loss: 0.7940 - val_accuracy: 0.6429\n",
      "Epoch 330/2000\n",
      "2/2 [==============================] - 0s 1ms/steposs: 0.5299 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.5299 - accuracy: 0.6410 - val_loss: 0.8865 - val_accuracy: 0.5714\n",
      "Epoch 331/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5188 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.5188 - accuracy: 0.6667 - val_loss: 0.8109 - val_accuracy: 0.6429\n",
      "Epoch 332/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.5173 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 773ms/step - loss: 0.5173 - accuracy: 0.6923 - val_loss: 0.8715 - val_accuracy: 0.5714\n",
      "Epoch 333/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5203 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.5203 - accuracy: 0.6667 - val_loss: 0.8112 - val_accuracy: 0.6429\n",
      "Epoch 334/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5151 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.5151 - accuracy: 0.6410 - val_loss: 0.8635 - val_accuracy: 0.5714\n",
      "Epoch 335/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5202 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.5202 - accuracy: 0.6667 - val_loss: 0.8110 - val_accuracy: 0.5714\n",
      "Epoch 336/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5100 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.5100 - accuracy: 0.6923 - val_loss: 0.8691 - val_accuracy: 0.5714\n",
      "Epoch 337/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5118 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.5118 - accuracy: 0.6667 - val_loss: 0.8106 - val_accuracy: 0.6429\n",
      "Epoch 338/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5144 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.5144 - accuracy: 0.6410 - val_loss: 0.8561 - val_accuracy: 0.5714\n",
      "Epoch 339/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5271 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.5271 - accuracy: 0.6667 - val_loss: 0.8037 - val_accuracy: 0.5714\n",
      "Epoch 340/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5124 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5124 - accuracy: 0.6667 - val_loss: 0.9091 - val_accuracy: 0.5714\n",
      "Epoch 341/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5335 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.5335 - accuracy: 0.6667 - val_loss: 0.8007 - val_accuracy: 0.5000\n",
      "Epoch 342/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5578 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.5578 - accuracy: 0.6410 - val_loss: 0.8975 - val_accuracy: 0.5714\n",
      "Epoch 343/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5444 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 0.5444 - accuracy: 0.6923 - val_loss: 0.7978 - val_accuracy: 0.6429\n",
      "Epoch 344/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5233 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.5233 - accuracy: 0.6410 - val_loss: 0.8813 - val_accuracy: 0.5714\n",
      "Epoch 345/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5113 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.5113 - accuracy: 0.6923 - val_loss: 0.8040 - val_accuracy: 0.5714\n",
      "Epoch 346/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5064 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.5064 - accuracy: 0.7692 - val_loss: 0.8677 - val_accuracy: 0.5714\n",
      "Epoch 347/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5071 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.5071 - accuracy: 0.6667 - val_loss: 0.7977 - val_accuracy: 0.5714\n",
      "Epoch 348/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5149 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.5149 - accuracy: 0.6923 - val_loss: 0.8771 - val_accuracy: 0.5714\n",
      "Epoch 349/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5066 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.5066 - accuracy: 0.6923 - val_loss: 0.8020 - val_accuracy: 0.5714\n",
      "Epoch 350/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5089 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.5089 - accuracy: 0.6667 - val_loss: 0.8892 - val_accuracy: 0.5714\n",
      "Epoch 351/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5192 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.5192 - accuracy: 0.6667 - val_loss: 0.7968 - val_accuracy: 0.6429\n",
      "Epoch 352/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5389 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.5389 - accuracy: 0.6410 - val_loss: 0.8977 - val_accuracy: 0.5714\n",
      "Epoch 353/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5276 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.5276 - accuracy: 0.6923 - val_loss: 0.8130 - val_accuracy: 0.6429\n",
      "Epoch 354/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5151 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.5151 - accuracy: 0.6667 - val_loss: 0.8843 - val_accuracy: 0.5714\n",
      "Epoch 355/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5112 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.5112 - accuracy: 0.6923 - val_loss: 0.8079 - val_accuracy: 0.5714\n",
      "Epoch 356/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5072 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.5072 - accuracy: 0.6923 - val_loss: 0.8773 - val_accuracy: 0.5714\n",
      "Epoch 357/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5064 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.5064 - accuracy: 0.6923 - val_loss: 0.8023 - val_accuracy: 0.5714\n",
      "Epoch 358/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5067 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 0.5067 - accuracy: 0.6923 - val_loss: 0.8903 - val_accuracy: 0.5714\n",
      "Epoch 359/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5226 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.5226 - accuracy: 0.6667 - val_loss: 0.8017 - val_accuracy: 0.5714\n",
      "Epoch 360/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5472 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.5472 - accuracy: 0.6410 - val_loss: 0.8902 - val_accuracy: 0.5714\n",
      "Epoch 361/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5352 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.5352 - accuracy: 0.6923 - val_loss: 0.8052 - val_accuracy: 0.6429\n",
      "Epoch 362/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5182 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.5182 - accuracy: 0.6410 - val_loss: 0.8960 - val_accuracy: 0.5714\n",
      "Epoch 363/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5119 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.5119 - accuracy: 0.6923 - val_loss: 0.8012 - val_accuracy: 0.5714\n",
      "Epoch 364/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5114 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.5114 - accuracy: 0.6667 - val_loss: 0.8857 - val_accuracy: 0.5714\n",
      "Epoch 365/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5108 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.5108 - accuracy: 0.6667 - val_loss: 0.7970 - val_accuracy: 0.5714\n",
      "Epoch 366/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.5214 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.5214 - accuracy: 0.6667 - val_loss: 0.8832 - val_accuracy: 0.5714\n",
      "Epoch 367/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5079 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.5079 - accuracy: 0.6923 - val_loss: 0.8131 - val_accuracy: 0.5714\n",
      "Epoch 368/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5070 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.5070 - accuracy: 0.6923 - val_loss: 0.8689 - val_accuracy: 0.5714\n",
      "Epoch 369/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.5116 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.5116 - accuracy: 0.6667 - val_loss: 0.8156 - val_accuracy: 0.5714\n",
      "Epoch 370/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5090 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.5090 - accuracy: 0.6667 - val_loss: 0.8612 - val_accuracy: 0.5714\n",
      "Epoch 371/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5185 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.5185 - accuracy: 0.6667 - val_loss: 0.8111 - val_accuracy: 0.5714\n",
      "Epoch 372/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5045 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 0.5045 - accuracy: 0.6923 - val_loss: 0.8958 - val_accuracy: 0.5714\n",
      "Epoch 373/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5120 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.5120 - accuracy: 0.6667 - val_loss: 0.7944 - val_accuracy: 0.6429\n",
      "Epoch 374/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5338 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.5338 - accuracy: 0.6410 - val_loss: 0.9110 - val_accuracy: 0.5714\n",
      "Epoch 375/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5192 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.5192 - accuracy: 0.7179 - val_loss: 0.8080 - val_accuracy: 0.6429\n",
      "Epoch 376/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5120 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.5120 - accuracy: 0.6667 - val_loss: 0.8848 - val_accuracy: 0.5714\n",
      "Epoch 377/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5085 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.5085 - accuracy: 0.6923 - val_loss: 0.8109 - val_accuracy: 0.5714\n",
      "Epoch 378/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5047 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.5047 - accuracy: 0.6923 - val_loss: 0.8600 - val_accuracy: 0.5714\n",
      "Epoch 379/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5116 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.5116 - accuracy: 0.6667 - val_loss: 0.8203 - val_accuracy: 0.5714\n",
      "Epoch 380/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5015 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.5015 - accuracy: 0.7179 - val_loss: 0.8415 - val_accuracy: 0.6429\n",
      "Epoch 381/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5149 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.5149 - accuracy: 0.6667 - val_loss: 0.8098 - val_accuracy: 0.5714\n",
      "Epoch 382/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4961 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.4961 - accuracy: 0.7692 - val_loss: 0.8878 - val_accuracy: 0.5714\n",
      "Epoch 383/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5149 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.5149 - accuracy: 0.6667 - val_loss: 0.8016 - val_accuracy: 0.5714\n",
      "Epoch 384/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5489 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.5489 - accuracy: 0.6410 - val_loss: 0.9127 - val_accuracy: 0.5714\n",
      "Epoch 385/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5437 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5437 - accuracy: 0.6923 - val_loss: 0.8034 - val_accuracy: 0.6429\n",
      "Epoch 386/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5243 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5243 - accuracy: 0.6410 - val_loss: 0.9100 - val_accuracy: 0.5714\n",
      "Epoch 387/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5147 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5147 - accuracy: 0.6923 - val_loss: 0.8012 - val_accuracy: 0.5714\n",
      "Epoch 388/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5114 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.5114 - accuracy: 0.6667 - val_loss: 0.8872 - val_accuracy: 0.5714\n",
      "Epoch 389/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5061 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.5061 - accuracy: 0.6667 - val_loss: 0.7987 - val_accuracy: 0.5714\n",
      "Epoch 390/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5129 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.5129 - accuracy: 0.6667 - val_loss: 0.8812 - val_accuracy: 0.5714\n",
      "Epoch 391/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5002 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.5002 - accuracy: 0.6923 - val_loss: 0.8090 - val_accuracy: 0.5714\n",
      "Epoch 392/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4984 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.4984 - accuracy: 0.7179 - val_loss: 0.8793 - val_accuracy: 0.5714\n",
      "Epoch 393/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5015 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.5015 - accuracy: 0.6923 - val_loss: 0.7972 - val_accuracy: 0.5714\n",
      "Epoch 394/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5149 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.5149 - accuracy: 0.6667 - val_loss: 0.9020 - val_accuracy: 0.5714\n",
      "Epoch 395/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5100 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.5100 - accuracy: 0.6667 - val_loss: 0.7967 - val_accuracy: 0.6429\n",
      "Epoch 396/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5240 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.5240 - accuracy: 0.6410 - val_loss: 0.9071 - val_accuracy: 0.5714\n",
      "Epoch 397/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5118 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.5118 - accuracy: 0.7179 - val_loss: 0.8044 - val_accuracy: 0.6429\n",
      "Epoch 398/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5098 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5098 - accuracy: 0.6410 - val_loss: 0.8997 - val_accuracy: 0.5714\n",
      "Epoch 399/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5189 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.5189 - accuracy: 0.6667 - val_loss: 0.7997 - val_accuracy: 0.5714\n",
      "Epoch 400/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5339 - accuracy: 0.66\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 0.5339 - accuracy: 0.6667 - val_loss: 0.8810 - val_accuracy: 0.5714\n",
      "Epoch 401/2000\n",
      "2/2 [==============================] - 0s 999us/steps: 0.5187 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5187 - accuracy: 0.6667 - val_loss: 0.8149 - val_accuracy: 0.5714\n",
      "Epoch 402/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5027 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5027 - accuracy: 0.7179 - val_loss: 0.8878 - val_accuracy: 0.5714\n",
      "Epoch 403/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5012 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.5012 - accuracy: 0.6923 - val_loss: 0.8025 - val_accuracy: 0.5714\n",
      "Epoch 404/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5057 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.5057 - accuracy: 0.6667 - val_loss: 0.8896 - val_accuracy: 0.5714\n",
      "Epoch 405/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5035 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.5035 - accuracy: 0.6667 - val_loss: 0.7984 - val_accuracy: 0.5714\n",
      "Epoch 406/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5155 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5155 - accuracy: 0.6923 - val_loss: 0.8952 - val_accuracy: 0.5714\n",
      "Epoch 407/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5039 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.5039 - accuracy: 0.6923 - val_loss: 0.8118 - val_accuracy: 0.6429\n",
      "Epoch 408/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5038 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.5038 - accuracy: 0.6667 - val_loss: 0.8920 - val_accuracy: 0.5714\n",
      "Epoch 409/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5055 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.5055 - accuracy: 0.7179 - val_loss: 0.8101 - val_accuracy: 0.6429\n",
      "Epoch 410/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5045 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.5045 - accuracy: 0.6667 - val_loss: 0.8943 - val_accuracy: 0.5714\n",
      "Epoch 411/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5051 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.5051 - accuracy: 0.7179 - val_loss: 0.8077 - val_accuracy: 0.6429\n",
      "Epoch 412/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5031 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.5031 - accuracy: 0.6667 - val_loss: 0.8991 - val_accuracy: 0.5714\n",
      "Epoch 413/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5094 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.5094 - accuracy: 0.6923 - val_loss: 0.7995 - val_accuracy: 0.6429\n",
      "Epoch 414/2000\n",
      "2/2 [==============================] - 0s 12ms/stepss: 0.5365 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 0.5365 - accuracy: 0.6667 - val_loss: 0.8957 - val_accuracy: 0.5714\n",
      "Epoch 415/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5147 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.5147 - accuracy: 0.6667 - val_loss: 0.8247 - val_accuracy: 0.5714\n",
      "Epoch 416/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5046 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5046 - accuracy: 0.6923 - val_loss: 0.8531 - val_accuracy: 0.6429\n",
      "Epoch 417/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5130 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.5130 - accuracy: 0.6667 - val_loss: 0.8142 - val_accuracy: 0.6429\n",
      "Epoch 418/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4922 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.4922 - accuracy: 0.7692 - val_loss: 0.8835 - val_accuracy: 0.5714\n",
      "Epoch 419/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5030 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.5030 - accuracy: 0.6667 - val_loss: 0.7992 - val_accuracy: 0.5714\n",
      "Epoch 420/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5283 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.5283 - accuracy: 0.7179 - val_loss: 0.8909 - val_accuracy: 0.5714\n",
      "Epoch 421/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5173 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.5173 - accuracy: 0.6667 - val_loss: 0.8149 - val_accuracy: 0.6429\n",
      "Epoch 422/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5041 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.5041 - accuracy: 0.6667 - val_loss: 0.9034 - val_accuracy: 0.5714\n",
      "Epoch 423/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5058 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.5058 - accuracy: 0.6923 - val_loss: 0.8015 - val_accuracy: 0.6429\n",
      "Epoch 424/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5129 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.5129 - accuracy: 0.6410 - val_loss: 0.9078 - val_accuracy: 0.5714\n",
      "Epoch 425/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5100 - accuracy: 0.66\n",
      "1/1 [==============================] - 1s 631ms/step - loss: 0.5100 - accuracy: 0.6667 - val_loss: 0.7988 - val_accuracy: 0.5714\n",
      "Epoch 426/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5217 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.5217 - accuracy: 0.6667 - val_loss: 0.8968 - val_accuracy: 0.5714\n",
      "Epoch 427/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5041 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.5041 - accuracy: 0.6667 - val_loss: 0.8195 - val_accuracy: 0.5714\n",
      "Epoch 428/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4991 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.4991 - accuracy: 0.7179 - val_loss: 0.8675 - val_accuracy: 0.6429\n",
      "Epoch 429/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5019 - accuracy: 0.66\n",
      "1/1 [==============================] - 1s 956ms/step - loss: 0.5019 - accuracy: 0.6667 - val_loss: 0.8221 - val_accuracy: 0.5714\n",
      "Epoch 430/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4953 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.4953 - accuracy: 0.7179 - val_loss: 0.8558 - val_accuracy: 0.6429\n",
      "Epoch 431/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5038 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.5038 - accuracy: 0.6667 - val_loss: 0.8192 - val_accuracy: 0.5714\n",
      "Epoch 432/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4903 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.4903 - accuracy: 0.7436 - val_loss: 0.8786 - val_accuracy: 0.5714\n",
      "Epoch 433/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4929 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.4929 - accuracy: 0.6923 - val_loss: 0.8116 - val_accuracy: 0.5714\n",
      "Epoch 434/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4971 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.4971 - accuracy: 0.6923 - val_loss: 0.9035 - val_accuracy: 0.5714\n",
      "Epoch 435/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5046 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.5046 - accuracy: 0.7179 - val_loss: 0.8103 - val_accuracy: 0.6429\n",
      "Epoch 436/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5087 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.5087 - accuracy: 0.6923 - val_loss: 0.9217 - val_accuracy: 0.5714\n",
      "Epoch 437/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5132 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.5132 - accuracy: 0.7179 - val_loss: 0.7954 - val_accuracy: 0.6429\n",
      "Epoch 438/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5281 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.5281 - accuracy: 0.6410 - val_loss: 0.9239 - val_accuracy: 0.5714\n",
      "Epoch 439/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5291 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.5291 - accuracy: 0.6923 - val_loss: 0.8031 - val_accuracy: 0.5000\n",
      "Epoch 440/2000\n",
      "2/2 [==============================] - 0s 1ms/steposs: 0.5406 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.5406 - accuracy: 0.6667 - val_loss: 0.8769 - val_accuracy: 0.5714\n",
      "Epoch 441/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5216 - accuracy: 0.66\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.5216 - accuracy: 0.6667 - val_loss: 0.8082 - val_accuracy: 0.7143\n",
      "Epoch 442/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5034 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.5034 - accuracy: 0.7436 - val_loss: 0.8769 - val_accuracy: 0.5714\n",
      "Epoch 443/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4897 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.4897 - accuracy: 0.6923 - val_loss: 0.8217 - val_accuracy: 0.6429\n",
      "Epoch 444/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4861 - accuracy: 0.82\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.4861 - accuracy: 0.8205 - val_loss: 0.8646 - val_accuracy: 0.6429\n",
      "Epoch 445/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4852 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.4852 - accuracy: 0.6923 - val_loss: 0.8170 - val_accuracy: 0.6429\n",
      "Epoch 446/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4853 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.4853 - accuracy: 0.7692 - val_loss: 0.8722 - val_accuracy: 0.6429\n",
      "Epoch 447/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4879 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.4879 - accuracy: 0.6923 - val_loss: 0.8129 - val_accuracy: 0.5714\n",
      "Epoch 448/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4926 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.4926 - accuracy: 0.7179 - val_loss: 0.8957 - val_accuracy: 0.5714\n",
      "Epoch 449/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5022 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.5022 - accuracy: 0.7179 - val_loss: 0.8195 - val_accuracy: 0.6429\n",
      "Epoch 450/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5155 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.5155 - accuracy: 0.6410 - val_loss: 0.8818 - val_accuracy: 0.6429\n",
      "Epoch 451/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5343 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.5343 - accuracy: 0.7179 - val_loss: 0.8042 - val_accuracy: 0.6429\n",
      "Epoch 452/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5146 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.5146 - accuracy: 0.6410 - val_loss: 0.9317 - val_accuracy: 0.5714\n",
      "Epoch 453/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5170 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.5170 - accuracy: 0.6923 - val_loss: 0.7967 - val_accuracy: 0.6429\n",
      "Epoch 454/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5284 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.5284 - accuracy: 0.6410 - val_loss: 0.8958 - val_accuracy: 0.5714\n",
      "Epoch 455/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5036 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.5036 - accuracy: 0.6923 - val_loss: 0.8168 - val_accuracy: 0.5714\n",
      "Epoch 456/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4969 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.4969 - accuracy: 0.6923 - val_loss: 0.8557 - val_accuracy: 0.6429\n",
      "Epoch 457/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5011 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.5011 - accuracy: 0.6667 - val_loss: 0.8182 - val_accuracy: 0.7143\n",
      "Epoch 458/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4832 - accuracy: 0.82\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.4832 - accuracy: 0.8205 - val_loss: 0.8708 - val_accuracy: 0.6429\n",
      "Epoch 459/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4849 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.4849 - accuracy: 0.6923 - val_loss: 0.8018 - val_accuracy: 0.5714\n",
      "Epoch 460/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4979 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.4979 - accuracy: 0.6923 - val_loss: 0.9047 - val_accuracy: 0.5714\n",
      "Epoch 461/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5063 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5063 - accuracy: 0.6667 - val_loss: 0.7986 - val_accuracy: 0.6429\n",
      "Epoch 462/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5347 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.5347 - accuracy: 0.6410 - val_loss: 0.9139 - val_accuracy: 0.5714\n",
      "Epoch 463/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5224 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.5224 - accuracy: 0.6923 - val_loss: 0.8172 - val_accuracy: 0.6429\n",
      "Epoch 464/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5021 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.5021 - accuracy: 0.6667 - val_loss: 0.9005 - val_accuracy: 0.5714\n",
      "Epoch 465/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4976 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.4976 - accuracy: 0.7179 - val_loss: 0.8068 - val_accuracy: 0.5714\n",
      "Epoch 466/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4971 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.4971 - accuracy: 0.6923 - val_loss: 0.8973 - val_accuracy: 0.5714\n",
      "Epoch 467/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5026 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.5026 - accuracy: 0.6667 - val_loss: 0.7976 - val_accuracy: 0.5714\n",
      "Epoch 468/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5192 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.5192 - accuracy: 0.6923 - val_loss: 0.8859 - val_accuracy: 0.6429\n",
      "Epoch 469/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5026 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.5026 - accuracy: 0.6667 - val_loss: 0.8211 - val_accuracy: 0.5714\n",
      "Epoch 470/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4903 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.4903 - accuracy: 0.7179 - val_loss: 0.8813 - val_accuracy: 0.6429\n",
      "Epoch 471/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.4888 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.4888 - accuracy: 0.6923 - val_loss: 0.8162 - val_accuracy: 0.5714\n",
      "Epoch 472/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4879 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.4879 - accuracy: 0.6923 - val_loss: 0.8835 - val_accuracy: 0.6429\n",
      "Epoch 473/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4895 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.4895 - accuracy: 0.6923 - val_loss: 0.8144 - val_accuracy: 0.5714\n",
      "Epoch 474/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4912 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.4912 - accuracy: 0.7179 - val_loss: 0.8894 - val_accuracy: 0.6429\n",
      "Epoch 475/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4963 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.4963 - accuracy: 0.6923 - val_loss: 0.8209 - val_accuracy: 0.5714\n",
      "Epoch 476/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5057 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.5057 - accuracy: 0.6667 - val_loss: 0.8618 - val_accuracy: 0.6429\n",
      "Epoch 477/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5230 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.5230 - accuracy: 0.6923 - val_loss: 0.8014 - val_accuracy: 0.5714\n",
      "Epoch 478/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5070 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.5070 - accuracy: 0.6923 - val_loss: 0.9181 - val_accuracy: 0.5714\n",
      "Epoch 479/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5009 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.5009 - accuracy: 0.7179 - val_loss: 0.8008 - val_accuracy: 0.6429\n",
      "Epoch 480/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5079 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.5079 - accuracy: 0.6667 - val_loss: 0.9228 - val_accuracy: 0.5714\n",
      "Epoch 481/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.5170 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.5170 - accuracy: 0.6923 - val_loss: 0.7969 - val_accuracy: 0.6429\n",
      "Epoch 482/2000\n",
      "2/2 [==============================] - 0s 6ms/steposs: 0.5305 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.5305 - accuracy: 0.6667 - val_loss: 0.8935 - val_accuracy: 0.5714\n",
      "Epoch 483/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5103 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.5103 - accuracy: 0.6923 - val_loss: 0.8168 - val_accuracy: 0.5714\n",
      "Epoch 484/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4893 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.4893 - accuracy: 0.7179 - val_loss: 0.8844 - val_accuracy: 0.6429\n",
      "Epoch 485/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4870 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.4870 - accuracy: 0.6923 - val_loss: 0.8066 - val_accuracy: 0.5714\n",
      "Epoch 486/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4903 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.4903 - accuracy: 0.7179 - val_loss: 0.8897 - val_accuracy: 0.6429\n",
      "Epoch 487/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4930 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.4930 - accuracy: 0.6667 - val_loss: 0.7963 - val_accuracy: 0.5714\n",
      "Epoch 488/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5102 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.5102 - accuracy: 0.6923 - val_loss: 0.8951 - val_accuracy: 0.6429\n",
      "Epoch 489/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4945 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 658ms/step - loss: 0.4945 - accuracy: 0.6923 - val_loss: 0.8202 - val_accuracy: 0.5714\n",
      "Epoch 490/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4929 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.4929 - accuracy: 0.7179 - val_loss: 0.8813 - val_accuracy: 0.6429\n",
      "Epoch 491/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4963 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.4963 - accuracy: 0.6923 - val_loss: 0.8216 - val_accuracy: 0.5714\n",
      "Epoch 492/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4932 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.4932 - accuracy: 0.6923 - val_loss: 0.8694 - val_accuracy: 0.6429\n",
      "Epoch 493/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5014 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.5014 - accuracy: 0.6923 - val_loss: 0.8190 - val_accuracy: 0.5714\n",
      "Epoch 494/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4865 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.4865 - accuracy: 0.6923 - val_loss: 0.8897 - val_accuracy: 0.6429\n",
      "Epoch 495/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4884 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.4884 - accuracy: 0.7179 - val_loss: 0.8130 - val_accuracy: 0.5714\n",
      "Epoch 496/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4902 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.4902 - accuracy: 0.7179 - val_loss: 0.9063 - val_accuracy: 0.6429\n",
      "Epoch 497/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4947 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.4947 - accuracy: 0.7179 - val_loss: 0.8019 - val_accuracy: 0.6429\n",
      "Epoch 498/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5039 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.5039 - accuracy: 0.6410 - val_loss: 0.9368 - val_accuracy: 0.5714\n",
      "Epoch 499/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5549 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.5549 - accuracy: 0.6667 - val_loss: 0.8012 - val_accuracy: 0.5000\n",
      "Epoch 500/2000\n",
      "2/2 [==============================] - 0s 6ms/steposs: 0.5484 - accuracy: 0.61\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.5484 - accuracy: 0.6154 - val_loss: 0.8839 - val_accuracy: 0.6429\n",
      "Epoch 501/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5262 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.5262 - accuracy: 0.6923 - val_loss: 0.7986 - val_accuracy: 0.5714\n",
      "Epoch 502/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5061 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.5061 - accuracy: 0.6923 - val_loss: 0.8683 - val_accuracy: 0.6429\n",
      "Epoch 503/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4898 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.4898 - accuracy: 0.6667 - val_loss: 0.8162 - val_accuracy: 0.7143\n",
      "Epoch 504/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4800 - accuracy: 0.82\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.4800 - accuracy: 0.8205 - val_loss: 0.8614 - val_accuracy: 0.6429\n",
      "Epoch 505/2000\n",
      "2/2 [==============================] - 0s 998us/steps: 0.4781 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.4781 - accuracy: 0.6923 - val_loss: 0.8143 - val_accuracy: 0.6429\n",
      "Epoch 506/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4773 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.4773 - accuracy: 0.7949 - val_loss: 0.8664 - val_accuracy: 0.6429\n",
      "Epoch 507/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4784 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.4784 - accuracy: 0.6923 - val_loss: 0.8091 - val_accuracy: 0.5714\n",
      "Epoch 508/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4815 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.4815 - accuracy: 0.7179 - val_loss: 0.8929 - val_accuracy: 0.6429\n",
      "Epoch 509/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4898 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.4898 - accuracy: 0.7179 - val_loss: 0.8019 - val_accuracy: 0.6429\n",
      "Epoch 510/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5056 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5056 - accuracy: 0.6410 - val_loss: 0.9380 - val_accuracy: 0.5714\n",
      "Epoch 511/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.5210 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5210 - accuracy: 0.7179 - val_loss: 0.7978 - val_accuracy: 0.5714\n",
      "Epoch 512/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5345 - accuracy: 0.61\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.5345 - accuracy: 0.6154 - val_loss: 0.9106 - val_accuracy: 0.6429\n",
      "Epoch 513/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5083 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.5083 - accuracy: 0.6923 - val_loss: 0.8219 - val_accuracy: 0.5714\n",
      "Epoch 514/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4888 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.4888 - accuracy: 0.7179 - val_loss: 0.8740 - val_accuracy: 0.6429\n",
      "Epoch 515/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4834 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.4834 - accuracy: 0.6923 - val_loss: 0.8239 - val_accuracy: 0.6429\n",
      "Epoch 516/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4799 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.4799 - accuracy: 0.7436 - val_loss: 0.8525 - val_accuracy: 0.6429\n",
      "Epoch 517/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4848 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.4848 - accuracy: 0.6667 - val_loss: 0.8263 - val_accuracy: 0.7143\n",
      "Epoch 518/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4772 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.4772 - accuracy: 0.7949 - val_loss: 0.8463 - val_accuracy: 0.6429\n",
      "Epoch 519/2000\n",
      "2/2 [==============================] - 0s 7ms/steposs: 0.4866 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.4866 - accuracy: 0.6667 - val_loss: 0.8226 - val_accuracy: 0.6429\n",
      "Epoch 520/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4762 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.4762 - accuracy: 0.7949 - val_loss: 0.8612 - val_accuracy: 0.6429\n",
      "Epoch 521/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4855 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.4855 - accuracy: 0.6667 - val_loss: 0.8200 - val_accuracy: 0.5714\n",
      "Epoch 522/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4902 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.4902 - accuracy: 0.6923 - val_loss: 0.8744 - val_accuracy: 0.6429\n",
      "Epoch 523/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.5121 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.5121 - accuracy: 0.6923 - val_loss: 0.8089 - val_accuracy: 0.6429\n",
      "Epoch 524/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5007 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.5007 - accuracy: 0.6923 - val_loss: 0.9606 - val_accuracy: 0.5714\n",
      "Epoch 525/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5331 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5331 - accuracy: 0.7179 - val_loss: 0.7964 - val_accuracy: 0.5714\n",
      "Epoch 526/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.5508 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.5508 - accuracy: 0.6410 - val_loss: 0.9040 - val_accuracy: 0.6429\n",
      "Epoch 527/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5193 - accuracy: 0.71\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.5193 - accuracy: 0.7179 - val_loss: 0.8086 - val_accuracy: 0.5714\n",
      "Epoch 528/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4866 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.4866 - accuracy: 0.6923 - val_loss: 0.8803 - val_accuracy: 0.6429\n",
      "Epoch 529/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4815 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.4815 - accuracy: 0.6667 - val_loss: 0.8052 - val_accuracy: 0.6429\n",
      "Epoch 530/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4840 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.4840 - accuracy: 0.7179 - val_loss: 0.8754 - val_accuracy: 0.6429\n",
      "Epoch 531/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4777 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.4777 - accuracy: 0.6923 - val_loss: 0.8037 - val_accuracy: 0.6429\n",
      "Epoch 532/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4844 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.4844 - accuracy: 0.7179 - val_loss: 0.8848 - val_accuracy: 0.6429\n",
      "Epoch 533/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.4820 - accuracy: 0.66\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 0.4820 - accuracy: 0.6667 - val_loss: 0.7976 - val_accuracy: 0.5714\n",
      "Epoch 534/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4961 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.4961 - accuracy: 0.6667 - val_loss: 0.9057 - val_accuracy: 0.6429\n",
      "Epoch 535/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4890 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.4890 - accuracy: 0.7179 - val_loss: 0.8039 - val_accuracy: 0.5714\n",
      "Epoch 536/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4970 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.4970 - accuracy: 0.6923 - val_loss: 0.9225 - val_accuracy: 0.6429\n",
      "Epoch 537/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5066 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.5066 - accuracy: 0.6923 - val_loss: 0.7936 - val_accuracy: 0.6429\n",
      "Epoch 538/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5215 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.5215 - accuracy: 0.6410 - val_loss: 0.9055 - val_accuracy: 0.6429\n",
      "Epoch 539/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4986 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.4986 - accuracy: 0.6923 - val_loss: 0.8222 - val_accuracy: 0.5714\n",
      "Epoch 540/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4873 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.4873 - accuracy: 0.7179 - val_loss: 0.8740 - val_accuracy: 0.6429\n",
      "Epoch 541/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4851 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.4851 - accuracy: 0.6923 - val_loss: 0.8242 - val_accuracy: 0.6429\n",
      "Epoch 542/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4801 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.4801 - accuracy: 0.7179 - val_loss: 0.8552 - val_accuracy: 0.6429\n",
      "Epoch 543/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4863 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 0.4863 - accuracy: 0.6667 - val_loss: 0.8234 - val_accuracy: 0.6429\n",
      "Epoch 544/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4743 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.4743 - accuracy: 0.7692 - val_loss: 0.8629 - val_accuracy: 0.6429\n",
      "Epoch 545/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4786 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.4786 - accuracy: 0.6667 - val_loss: 0.8223 - val_accuracy: 0.5714\n",
      "Epoch 546/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4829 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.4829 - accuracy: 0.7179 - val_loss: 0.8542 - val_accuracy: 0.6429\n",
      "Epoch 547/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5003 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.5003 - accuracy: 0.6923 - val_loss: 0.8085 - val_accuracy: 0.5714\n",
      "Epoch 548/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4841 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.4841 - accuracy: 0.7179 - val_loss: 0.9346 - val_accuracy: 0.6429\n",
      "Epoch 549/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5095 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.5095 - accuracy: 0.6923 - val_loss: 0.7918 - val_accuracy: 0.5714\n",
      "Epoch 550/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5442 - accuracy: 0.64\n",
      "1/1 [==============================] - 1s 967ms/step - loss: 0.5442 - accuracy: 0.6410 - val_loss: 0.9280 - val_accuracy: 0.6429\n",
      "Epoch 551/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5185 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.5185 - accuracy: 0.7179 - val_loss: 0.8140 - val_accuracy: 0.5714\n",
      "Epoch 552/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4892 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.4892 - accuracy: 0.7179 - val_loss: 0.8836 - val_accuracy: 0.6429\n",
      "Epoch 553/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4799 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.4799 - accuracy: 0.7179 - val_loss: 0.8168 - val_accuracy: 0.6429\n",
      "Epoch 554/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4738 - accuracy: 0.74\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 0.4738 - accuracy: 0.7436 - val_loss: 0.8646 - val_accuracy: 0.6429\n",
      "Epoch 555/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4722 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.4722 - accuracy: 0.6923 - val_loss: 0.8211 - val_accuracy: 0.6429\n",
      "Epoch 556/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4734 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.4734 - accuracy: 0.7436 - val_loss: 0.8441 - val_accuracy: 0.6429\n",
      "Epoch 557/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4863 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.4863 - accuracy: 0.6667 - val_loss: 0.8231 - val_accuracy: 0.7143\n",
      "Epoch 558/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4691 - accuracy: 0.82\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.4691 - accuracy: 0.8205 - val_loss: 0.8631 - val_accuracy: 0.6429\n",
      "Epoch 559/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4739 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.4739 - accuracy: 0.6667 - val_loss: 0.8208 - val_accuracy: 0.5714\n",
      "Epoch 560/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4859 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.4859 - accuracy: 0.6667 - val_loss: 0.8549 - val_accuracy: 0.6429\n",
      "Epoch 561/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5106 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.5106 - accuracy: 0.6923 - val_loss: 0.7974 - val_accuracy: 0.5714\n",
      "Epoch 562/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4997 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.4997 - accuracy: 0.7179 - val_loss: 0.9646 - val_accuracy: 0.5714\n",
      "Epoch 563/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5230 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.5230 - accuracy: 0.7179 - val_loss: 0.7927 - val_accuracy: 0.5714\n",
      "Epoch 564/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5439 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.5439 - accuracy: 0.6410 - val_loss: 0.9235 - val_accuracy: 0.6429\n",
      "Epoch 565/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5083 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.5083 - accuracy: 0.7179 - val_loss: 0.8147 - val_accuracy: 0.5714\n",
      "Epoch 566/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4838 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.4838 - accuracy: 0.7179 - val_loss: 0.8680 - val_accuracy: 0.6429\n",
      "Epoch 567/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4775 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.4775 - accuracy: 0.6667 - val_loss: 0.8231 - val_accuracy: 0.7143\n",
      "Epoch 568/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4717 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.4717 - accuracy: 0.7436 - val_loss: 0.8427 - val_accuracy: 0.6429\n",
      "Epoch 569/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4770 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.4770 - accuracy: 0.6667 - val_loss: 0.8271 - val_accuracy: 0.5714\n",
      "Epoch 570/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4663 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.4663 - accuracy: 0.7949 - val_loss: 0.8389 - val_accuracy: 0.6429\n",
      "Epoch 571/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4724 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.4724 - accuracy: 0.6667 - val_loss: 0.8273 - val_accuracy: 0.6429\n",
      "Epoch 572/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4696 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.4696 - accuracy: 0.7692 - val_loss: 0.8283 - val_accuracy: 0.6429\n",
      "Epoch 573/2000\n",
      "2/2 [==============================] - 0s 1ms/steposs: 0.4848 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.4848 - accuracy: 0.6667 - val_loss: 0.8146 - val_accuracy: 0.7143\n",
      "Epoch 574/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4657 - accuracy: 0.82\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.4657 - accuracy: 0.8205 - val_loss: 0.8931 - val_accuracy: 0.6429\n",
      "Epoch 575/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4790 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.4790 - accuracy: 0.7179 - val_loss: 0.7921 - val_accuracy: 0.5714\n",
      "Epoch 576/2000\n",
      "2/2 [==============================] - 0s 6ms/steposs: 0.5255 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.5255 - accuracy: 0.6410 - val_loss: 0.9994 - val_accuracy: 0.5714\n",
      "Epoch 577/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5448 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5448 - accuracy: 0.7179 - val_loss: 0.7947 - val_accuracy: 0.5714\n",
      "Epoch 578/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5411 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.5411 - accuracy: 0.6410 - val_loss: 0.9182 - val_accuracy: 0.6429\n",
      "Epoch 579/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4963 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.4963 - accuracy: 0.7436 - val_loss: 0.8182 - val_accuracy: 0.5714\n",
      "Epoch 580/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4760 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.4760 - accuracy: 0.7179 - val_loss: 0.8630 - val_accuracy: 0.6429\n",
      "Epoch 581/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4707 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.4707 - accuracy: 0.6667 - val_loss: 0.8270 - val_accuracy: 0.6429\n",
      "Epoch 582/2000\n",
      "2/2 [==============================] - 0s 6ms/steposs: 0.4698 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.4698 - accuracy: 0.7949 - val_loss: 0.8313 - val_accuracy: 0.6429\n",
      "Epoch 583/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4815 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.4815 - accuracy: 0.6667 - val_loss: 0.8275 - val_accuracy: 0.5714\n",
      "Epoch 584/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4608 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.4608 - accuracy: 0.7692 - val_loss: 0.8526 - val_accuracy: 0.6429\n",
      "Epoch 585/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4604 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.4604 - accuracy: 0.7179 - val_loss: 0.8147 - val_accuracy: 0.7143\n",
      "Epoch 586/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4616 - accuracy: 0.79\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 0.4616 - accuracy: 0.7949 - val_loss: 0.8735 - val_accuracy: 0.6429\n",
      "Epoch 587/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4674 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.4674 - accuracy: 0.6923 - val_loss: 0.7919 - val_accuracy: 0.5714\n",
      "Epoch 588/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4930 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.4930 - accuracy: 0.7179 - val_loss: 0.9694 - val_accuracy: 0.5714\n",
      "Epoch 589/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5577 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.5577 - accuracy: 0.7179 - val_loss: 0.7979 - val_accuracy: 0.5000\n",
      "Epoch 590/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5696 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.5696 - accuracy: 0.6410 - val_loss: 0.9138 - val_accuracy: 0.6429\n",
      "Epoch 591/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5371 - accuracy: 0.71\n",
      "1/1 [==============================] - 1s 740ms/step - loss: 0.5371 - accuracy: 0.7179 - val_loss: 0.7961 - val_accuracy: 0.5714\n",
      "Epoch 592/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.4978 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.4978 - accuracy: 0.6923 - val_loss: 0.8789 - val_accuracy: 0.6429\n",
      "Epoch 593/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4754 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.4754 - accuracy: 0.6923 - val_loss: 0.8158 - val_accuracy: 0.7143\n",
      "Epoch 594/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4682 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.4682 - accuracy: 0.7692 - val_loss: 0.8604 - val_accuracy: 0.6429\n",
      "Epoch 595/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4651 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 0.4651 - accuracy: 0.6923 - val_loss: 0.8170 - val_accuracy: 0.7143\n",
      "Epoch 596/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4634 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.4634 - accuracy: 0.7949 - val_loss: 0.8597 - val_accuracy: 0.6429\n",
      "Epoch 597/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4632 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.4632 - accuracy: 0.6923 - val_loss: 0.8131 - val_accuracy: 0.6429\n",
      "Epoch 598/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4642 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.4642 - accuracy: 0.7692 - val_loss: 0.8748 - val_accuracy: 0.6429\n",
      "Epoch 599/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4680 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.4680 - accuracy: 0.7179 - val_loss: 0.8063 - val_accuracy: 0.5714\n",
      "Epoch 600/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4756 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.4756 - accuracy: 0.6923 - val_loss: 0.9219 - val_accuracy: 0.6429\n",
      "Epoch 601/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4936 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.4936 - accuracy: 0.6923 - val_loss: 0.7946 - val_accuracy: 0.5714\n",
      "Epoch 602/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5266 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.5266 - accuracy: 0.6410 - val_loss: 0.9490 - val_accuracy: 0.6429\n",
      "Epoch 603/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5037 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.5037 - accuracy: 0.7436 - val_loss: 0.8067 - val_accuracy: 0.6429\n",
      "Epoch 604/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4924 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.4924 - accuracy: 0.6667 - val_loss: 0.9137 - val_accuracy: 0.6429\n",
      "Epoch 605/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4986 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.4986 - accuracy: 0.6923 - val_loss: 0.7901 - val_accuracy: 0.5714\n",
      "Epoch 606/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5124 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.5124 - accuracy: 0.6667 - val_loss: 0.8744 - val_accuracy: 0.6429\n",
      "Epoch 607/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4874 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.4874 - accuracy: 0.6923 - val_loss: 0.8227 - val_accuracy: 0.6429\n",
      "Epoch 608/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4681 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.4681 - accuracy: 0.7692 - val_loss: 0.8769 - val_accuracy: 0.6429\n",
      "Epoch 609/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4658 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.4658 - accuracy: 0.6923 - val_loss: 0.8175 - val_accuracy: 0.6429\n",
      "Epoch 610/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4650 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.4650 - accuracy: 0.7692 - val_loss: 0.8823 - val_accuracy: 0.6429\n",
      "Epoch 611/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4672 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.4672 - accuracy: 0.7179 - val_loss: 0.8056 - val_accuracy: 0.5714\n",
      "Epoch 612/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4751 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.4751 - accuracy: 0.6667 - val_loss: 0.9183 - val_accuracy: 0.6429\n",
      "Epoch 613/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5016 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.5016 - accuracy: 0.6923 - val_loss: 0.7885 - val_accuracy: 0.5714\n",
      "Epoch 614/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5320 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.5320 - accuracy: 0.6667 - val_loss: 0.9111 - val_accuracy: 0.6429\n",
      "Epoch 615/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5136 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.5136 - accuracy: 0.7179 - val_loss: 0.8133 - val_accuracy: 0.5714\n",
      "Epoch 616/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4858 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.4858 - accuracy: 0.6923 - val_loss: 0.9078 - val_accuracy: 0.6429\n",
      "Epoch 617/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4805 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.4805 - accuracy: 0.7179 - val_loss: 0.8070 - val_accuracy: 0.5714\n",
      "Epoch 618/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4787 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.4787 - accuracy: 0.6667 - val_loss: 0.8986 - val_accuracy: 0.6429\n",
      "Epoch 619/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4781 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.4781 - accuracy: 0.6923 - val_loss: 0.7969 - val_accuracy: 0.5714\n",
      "Epoch 620/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4899 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.4899 - accuracy: 0.7179 - val_loss: 0.8952 - val_accuracy: 0.6429\n",
      "Epoch 621/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4708 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.4708 - accuracy: 0.7179 - val_loss: 0.8150 - val_accuracy: 0.5714\n",
      "Epoch 622/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4702 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.4702 - accuracy: 0.6923 - val_loss: 0.8976 - val_accuracy: 0.6429\n",
      "Epoch 623/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4736 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.4736 - accuracy: 0.7179 - val_loss: 0.8028 - val_accuracy: 0.5714\n",
      "Epoch 624/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4837 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.4837 - accuracy: 0.6923 - val_loss: 0.9222 - val_accuracy: 0.6429\n",
      "Epoch 625/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4969 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.4969 - accuracy: 0.6923 - val_loss: 0.7886 - val_accuracy: 0.5000\n",
      "Epoch 626/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5192 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.5192 - accuracy: 0.6923 - val_loss: 0.9046 - val_accuracy: 0.6429\n",
      "Epoch 627/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4961 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.4961 - accuracy: 0.6923 - val_loss: 0.8220 - val_accuracy: 0.5714\n",
      "Epoch 628/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4786 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.4786 - accuracy: 0.7179 - val_loss: 0.8933 - val_accuracy: 0.6429\n",
      "Epoch 629/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4740 - accuracy: 0.71\n",
      "1/1 [==============================] - 1s 720ms/step - loss: 0.4740 - accuracy: 0.7179 - val_loss: 0.8229 - val_accuracy: 0.6429\n",
      "Epoch 630/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4699 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.4699 - accuracy: 0.6923 - val_loss: 0.8787 - val_accuracy: 0.6429\n",
      "Epoch 631/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4704 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 634ms/step - loss: 0.4704 - accuracy: 0.6923 - val_loss: 0.8273 - val_accuracy: 0.6429\n",
      "Epoch 632/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4724 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.4724 - accuracy: 0.7179 - val_loss: 0.8555 - val_accuracy: 0.6429\n",
      "Epoch 633/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4861 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.4861 - accuracy: 0.6923 - val_loss: 0.8207 - val_accuracy: 0.6429\n",
      "Epoch 634/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4641 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.4641 - accuracy: 0.7692 - val_loss: 0.8978 - val_accuracy: 0.6429\n",
      "Epoch 635/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4694 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.4694 - accuracy: 0.7179 - val_loss: 0.8019 - val_accuracy: 0.5714\n",
      "Epoch 636/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4848 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.4848 - accuracy: 0.7179 - val_loss: 0.9501 - val_accuracy: 0.6429\n",
      "Epoch 637/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5218 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.5218 - accuracy: 0.6923 - val_loss: 0.7892 - val_accuracy: 0.5714\n",
      "Epoch 638/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5417 - accuracy: 0.61\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.5417 - accuracy: 0.6154 - val_loss: 0.9088 - val_accuracy: 0.6429\n",
      "Epoch 639/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5139 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.5139 - accuracy: 0.7179 - val_loss: 0.8087 - val_accuracy: 0.5714\n",
      "Epoch 640/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4803 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 0.4803 - accuracy: 0.6923 - val_loss: 0.8949 - val_accuracy: 0.6429\n",
      "Epoch 641/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4714 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.4714 - accuracy: 0.7179 - val_loss: 0.8126 - val_accuracy: 0.6429\n",
      "Epoch 642/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4675 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.4675 - accuracy: 0.7436 - val_loss: 0.8851 - val_accuracy: 0.6429\n",
      "Epoch 643/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4666 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.4666 - accuracy: 0.6923 - val_loss: 0.8062 - val_accuracy: 0.6429\n",
      "Epoch 644/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4724 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.4724 - accuracy: 0.7436 - val_loss: 0.8941 - val_accuracy: 0.6429\n",
      "Epoch 645/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4701 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.4701 - accuracy: 0.6923 - val_loss: 0.7999 - val_accuracy: 0.5714\n",
      "Epoch 646/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4828 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.4828 - accuracy: 0.6923 - val_loss: 0.9129 - val_accuracy: 0.6429\n",
      "Epoch 647/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4770 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.4770 - accuracy: 0.7179 - val_loss: 0.8032 - val_accuracy: 0.5714\n",
      "Epoch 648/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4877 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.4877 - accuracy: 0.7179 - val_loss: 0.9297 - val_accuracy: 0.6429\n",
      "Epoch 649/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4903 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.4903 - accuracy: 0.6923 - val_loss: 0.7965 - val_accuracy: 0.5000\n",
      "Epoch 650/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5021 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.5021 - accuracy: 0.6923 - val_loss: 0.9195 - val_accuracy: 0.6429\n",
      "Epoch 651/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4799 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.4799 - accuracy: 0.7179 - val_loss: 0.8175 - val_accuracy: 0.5714\n",
      "Epoch 652/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4733 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.4733 - accuracy: 0.7179 - val_loss: 0.9013 - val_accuracy: 0.6429\n",
      "Epoch 653/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4710 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.4710 - accuracy: 0.7179 - val_loss: 0.8096 - val_accuracy: 0.5714\n",
      "Epoch 654/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4725 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.4725 - accuracy: 0.6667 - val_loss: 0.9079 - val_accuracy: 0.6429\n",
      "Epoch 655/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4844 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.4844 - accuracy: 0.6923 - val_loss: 0.7887 - val_accuracy: 0.5714\n",
      "Epoch 656/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5073 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.5073 - accuracy: 0.6667 - val_loss: 0.8944 - val_accuracy: 0.6429\n",
      "Epoch 657/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4834 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.4834 - accuracy: 0.6923 - val_loss: 0.8259 - val_accuracy: 0.5714\n",
      "Epoch 658/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4727 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.4727 - accuracy: 0.6923 - val_loss: 0.8919 - val_accuracy: 0.6429\n",
      "Epoch 659/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4722 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.4722 - accuracy: 0.7179 - val_loss: 0.8268 - val_accuracy: 0.5714\n",
      "Epoch 660/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4710 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.4710 - accuracy: 0.6923 - val_loss: 0.8808 - val_accuracy: 0.6429\n",
      "Epoch 661/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4760 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.4760 - accuracy: 0.6923 - val_loss: 0.8292 - val_accuracy: 0.6429\n",
      "Epoch 662/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4713 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.4713 - accuracy: 0.6667 - val_loss: 0.8693 - val_accuracy: 0.6429\n",
      "Epoch 663/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4814 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.4814 - accuracy: 0.6923 - val_loss: 0.8242 - val_accuracy: 0.6429\n",
      "Epoch 664/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4653 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.4653 - accuracy: 0.7436 - val_loss: 0.8935 - val_accuracy: 0.6429\n",
      "Epoch 665/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4693 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.4693 - accuracy: 0.7179 - val_loss: 0.8234 - val_accuracy: 0.5714\n",
      "Epoch 666/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4740 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.4740 - accuracy: 0.6923 - val_loss: 0.8909 - val_accuracy: 0.6429\n",
      "Epoch 667/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4863 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.4863 - accuracy: 0.6923 - val_loss: 0.8272 - val_accuracy: 0.5714\n",
      "Epoch 668/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4768 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.4768 - accuracy: 0.6923 - val_loss: 0.8798 - val_accuracy: 0.6429\n",
      "Epoch 669/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4873 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.4873 - accuracy: 0.6923 - val_loss: 0.8213 - val_accuracy: 0.5714\n",
      "Epoch 670/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4689 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.4689 - accuracy: 0.6923 - val_loss: 0.8936 - val_accuracy: 0.6429\n",
      "Epoch 671/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4727 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.4727 - accuracy: 0.6923 - val_loss: 0.8263 - val_accuracy: 0.5714\n",
      "Epoch 672/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4753 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.4753 - accuracy: 0.6667 - val_loss: 0.8577 - val_accuracy: 0.6429\n",
      "Epoch 673/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4911 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.4911 - accuracy: 0.6923 - val_loss: 0.8112 - val_accuracy: 0.6429\n",
      "Epoch 674/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4637 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.4637 - accuracy: 0.7692 - val_loss: 0.9280 - val_accuracy: 0.6429\n",
      "Epoch 675/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4866 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.4866 - accuracy: 0.6923 - val_loss: 0.7811 - val_accuracy: 0.5714\n",
      "Epoch 676/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5292 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.5292 - accuracy: 0.6410 - val_loss: 0.9373 - val_accuracy: 0.6429\n",
      "Epoch 677/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5006 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.5006 - accuracy: 0.7179 - val_loss: 0.8164 - val_accuracy: 0.5714\n",
      "Epoch 678/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4769 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.4769 - accuracy: 0.7179 - val_loss: 0.8917 - val_accuracy: 0.6429\n",
      "Epoch 679/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4675 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.4675 - accuracy: 0.7179 - val_loss: 0.8233 - val_accuracy: 0.6429\n",
      "Epoch 680/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4609 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.4609 - accuracy: 0.7692 - val_loss: 0.8671 - val_accuracy: 0.6429\n",
      "Epoch 681/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4617 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.4617 - accuracy: 0.6923 - val_loss: 0.8325 - val_accuracy: 0.6429\n",
      "Epoch 682/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4631 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.4631 - accuracy: 0.7949 - val_loss: 0.8336 - val_accuracy: 0.6429\n",
      "Epoch 683/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4792 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.4792 - accuracy: 0.6923 - val_loss: 0.8232 - val_accuracy: 0.5714\n",
      "Epoch 684/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4522 - accuracy: 0.84\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.4522 - accuracy: 0.8462 - val_loss: 0.8877 - val_accuracy: 0.6429\n",
      "Epoch 685/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4609 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.4609 - accuracy: 0.6667 - val_loss: 0.7851 - val_accuracy: 0.5714\n",
      "Epoch 686/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4942 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.4942 - accuracy: 0.6667 - val_loss: 0.9605 - val_accuracy: 0.6429\n",
      "Epoch 687/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4966 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.4966 - accuracy: 0.7436 - val_loss: 0.8026 - val_accuracy: 0.5714\n",
      "Epoch 688/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5136 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.5136 - accuracy: 0.6410 - val_loss: 0.9612 - val_accuracy: 0.6429\n",
      "Epoch 689/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5105 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.5105 - accuracy: 0.7179 - val_loss: 0.7891 - val_accuracy: 0.5000\n",
      "Epoch 690/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5084 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5084 - accuracy: 0.6923 - val_loss: 0.8982 - val_accuracy: 0.6429\n",
      "Epoch 691/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4724 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.4724 - accuracy: 0.6923 - val_loss: 0.8273 - val_accuracy: 0.6429\n",
      "Epoch 692/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4604 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.4604 - accuracy: 0.7692 - val_loss: 0.8715 - val_accuracy: 0.6429\n",
      "Epoch 693/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4561 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 806ms/step - loss: 0.4561 - accuracy: 0.6923 - val_loss: 0.8311 - val_accuracy: 0.6429\n",
      "Epoch 694/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4544 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.4544 - accuracy: 0.7949 - val_loss: 0.8575 - val_accuracy: 0.6429\n",
      "Epoch 695/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4579 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.4579 - accuracy: 0.6923 - val_loss: 0.8352 - val_accuracy: 0.6429\n",
      "Epoch 696/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4600 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.4600 - accuracy: 0.7949 - val_loss: 0.8361 - val_accuracy: 0.6429\n",
      "Epoch 697/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4762 - accuracy: 0.71\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4762 - accuracy: 0.7179 - val_loss: 0.8209 - val_accuracy: 0.6429\n",
      "Epoch 698/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4523 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.4523 - accuracy: 0.7949 - val_loss: 0.8985 - val_accuracy: 0.6429\n",
      "Epoch 699/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4619 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.4619 - accuracy: 0.7179 - val_loss: 0.7937 - val_accuracy: 0.5000\n",
      "Epoch 700/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4931 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.4931 - accuracy: 0.6410 - val_loss: 0.9864 - val_accuracy: 0.6429\n",
      "Epoch 701/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5221 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.5221 - accuracy: 0.7179 - val_loss: 0.7898 - val_accuracy: 0.5714\n",
      "Epoch 702/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5396 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.5396 - accuracy: 0.6410 - val_loss: 0.9303 - val_accuracy: 0.6429\n",
      "Epoch 703/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4951 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.4951 - accuracy: 0.7179 - val_loss: 0.8235 - val_accuracy: 0.5714\n",
      "Epoch 704/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4680 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.4680 - accuracy: 0.6923 - val_loss: 0.8823 - val_accuracy: 0.6429\n",
      "Epoch 705/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4584 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.4584 - accuracy: 0.7179 - val_loss: 0.8296 - val_accuracy: 0.6429\n",
      "Epoch 706/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4536 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.4536 - accuracy: 0.7949 - val_loss: 0.8644 - val_accuracy: 0.6429\n",
      "Epoch 707/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4533 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.4533 - accuracy: 0.7179 - val_loss: 0.8351 - val_accuracy: 0.5714\n",
      "Epoch 708/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4556 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.4556 - accuracy: 0.7949 - val_loss: 0.8403 - val_accuracy: 0.6429\n",
      "Epoch 709/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4697 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.4697 - accuracy: 0.6923 - val_loss: 0.8310 - val_accuracy: 0.5714\n",
      "Epoch 710/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4486 - accuracy: 0.84\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.4486 - accuracy: 0.8462 - val_loss: 0.8693 - val_accuracy: 0.6429\n",
      "Epoch 711/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4516 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.4516 - accuracy: 0.7179 - val_loss: 0.8223 - val_accuracy: 0.6429\n",
      "Epoch 712/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4600 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.4600 - accuracy: 0.7692 - val_loss: 0.8896 - val_accuracy: 0.6429\n",
      "Epoch 713/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4830 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.4830 - accuracy: 0.6923 - val_loss: 0.8255 - val_accuracy: 0.6429\n",
      "Epoch 714/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4872 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.4872 - accuracy: 0.6923 - val_loss: 0.9211 - val_accuracy: 0.6429\n",
      "Epoch 715/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5068 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.5068 - accuracy: 0.7179 - val_loss: 0.8210 - val_accuracy: 0.5714\n",
      "Epoch 716/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4820 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.4820 - accuracy: 0.6923 - val_loss: 0.9313 - val_accuracy: 0.6429\n",
      "Epoch 717/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4757 - accuracy: 0.74\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.4757 - accuracy: 0.7436 - val_loss: 0.8116 - val_accuracy: 0.5714\n",
      "Epoch 718/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4686 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.4686 - accuracy: 0.7436 - val_loss: 0.9311 - val_accuracy: 0.6429\n",
      "Epoch 719/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4901 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.4901 - accuracy: 0.6923 - val_loss: 0.7802 - val_accuracy: 0.5000\n",
      "Epoch 720/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5231 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.5231 - accuracy: 0.6410 - val_loss: 0.8958 - val_accuracy: 0.6429\n",
      "Epoch 721/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4917 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.4917 - accuracy: 0.6923 - val_loss: 0.8143 - val_accuracy: 0.6429\n",
      "Epoch 722/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4611 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.4611 - accuracy: 0.7692 - val_loss: 0.8938 - val_accuracy: 0.6429\n",
      "Epoch 723/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4584 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.4584 - accuracy: 0.7179 - val_loss: 0.8096 - val_accuracy: 0.6429\n",
      "Epoch 724/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4608 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.4608 - accuracy: 0.7692 - val_loss: 0.9010 - val_accuracy: 0.6429\n",
      "Epoch 725/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4664 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 0.4664 - accuracy: 0.6923 - val_loss: 0.7935 - val_accuracy: 0.6429\n",
      "Epoch 726/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4849 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.4849 - accuracy: 0.7179 - val_loss: 0.9134 - val_accuracy: 0.6429\n",
      "Epoch 727/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4647 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.4647 - accuracy: 0.7179 - val_loss: 0.8168 - val_accuracy: 0.5714\n",
      "Epoch 728/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4646 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.4646 - accuracy: 0.6923 - val_loss: 0.9185 - val_accuracy: 0.6429\n",
      "Epoch 729/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4683 - accuracy: 0.71\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.4683 - accuracy: 0.7179 - val_loss: 0.8036 - val_accuracy: 0.5714\n",
      "Epoch 730/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4787 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.4787 - accuracy: 0.7179 - val_loss: 0.9352 - val_accuracy: 0.6429\n",
      "Epoch 731/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.4878 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.4878 - accuracy: 0.6923 - val_loss: 0.7876 - val_accuracy: 0.5000\n",
      "Epoch 732/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5070 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.5070 - accuracy: 0.6923 - val_loss: 0.9111 - val_accuracy: 0.6429\n",
      "Epoch 733/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4759 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 0.4759 - accuracy: 0.6923 - val_loss: 0.8282 - val_accuracy: 0.6429\n",
      "Epoch 734/2000\n",
      "2/2 [==============================] - 0s 6ms/steposs: 0.4638 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.4638 - accuracy: 0.7179 - val_loss: 0.8900 - val_accuracy: 0.6429\n",
      "Epoch 735/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4596 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.4596 - accuracy: 0.7179 - val_loss: 0.8308 - val_accuracy: 0.6429\n",
      "Epoch 736/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4565 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.4565 - accuracy: 0.7692 - val_loss: 0.8765 - val_accuracy: 0.6429\n",
      "Epoch 737/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4590 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.4590 - accuracy: 0.6923 - val_loss: 0.8343 - val_accuracy: 0.6429\n",
      "Epoch 738/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4594 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.4594 - accuracy: 0.7692 - val_loss: 0.8582 - val_accuracy: 0.6429\n",
      "Epoch 739/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4726 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.4726 - accuracy: 0.6923 - val_loss: 0.8255 - val_accuracy: 0.6429\n",
      "Epoch 740/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4523 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.4523 - accuracy: 0.7692 - val_loss: 0.9014 - val_accuracy: 0.6429\n",
      "Epoch 741/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4579 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.4579 - accuracy: 0.7179 - val_loss: 0.8162 - val_accuracy: 0.5714\n",
      "Epoch 742/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4671 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.4671 - accuracy: 0.7436 - val_loss: 0.9504 - val_accuracy: 0.6429\n",
      "Epoch 743/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4819 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.4819 - accuracy: 0.7436 - val_loss: 0.7965 - val_accuracy: 0.5714\n",
      "Epoch 744/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5073 - accuracy: 0.61\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.5073 - accuracy: 0.6154 - val_loss: 0.9656 - val_accuracy: 0.6429\n",
      "Epoch 745/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5092 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.5092 - accuracy: 0.7179 - val_loss: 0.7842 - val_accuracy: 0.5000\n",
      "Epoch 746/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5166 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.5166 - accuracy: 0.6667 - val_loss: 0.8953 - val_accuracy: 0.6429\n",
      "Epoch 747/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4788 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 0.4788 - accuracy: 0.6923 - val_loss: 0.8259 - val_accuracy: 0.7143\n",
      "Epoch 748/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4551 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 0.4551 - accuracy: 0.7692 - val_loss: 0.8839 - val_accuracy: 0.6429\n",
      "Epoch 749/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4501 - accuracy: 0.71\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 0.4501 - accuracy: 0.7179 - val_loss: 0.8278 - val_accuracy: 0.6429\n",
      "Epoch 750/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4475 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.4475 - accuracy: 0.7949 - val_loss: 0.8826 - val_accuracy: 0.6429\n",
      "Epoch 751/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4471 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.4471 - accuracy: 0.7179 - val_loss: 0.8197 - val_accuracy: 0.6429\n",
      "Epoch 752/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4495 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.4495 - accuracy: 0.7949 - val_loss: 0.9060 - val_accuracy: 0.6429\n",
      "Epoch 753/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4618 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.4618 - accuracy: 0.6923 - val_loss: 0.7890 - val_accuracy: 0.5000\n",
      "Epoch 754/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4970 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.4970 - accuracy: 0.6667 - val_loss: 0.9450 - val_accuracy: 0.6429\n",
      "Epoch 755/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4761 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.4761 - accuracy: 0.7436 - val_loss: 0.8220 - val_accuracy: 0.5714\n",
      "Epoch 756/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4756 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.4756 - accuracy: 0.7179 - val_loss: 0.9360 - val_accuracy: 0.6429\n",
      "Epoch 757/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4732 - accuracy: 0.74\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.4732 - accuracy: 0.7436 - val_loss: 0.8104 - val_accuracy: 0.5714\n",
      "Epoch 758/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4730 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.4730 - accuracy: 0.7179 - val_loss: 0.9317 - val_accuracy: 0.6429\n",
      "Epoch 759/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4929 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.4929 - accuracy: 0.6923 - val_loss: 0.7857 - val_accuracy: 0.5000\n",
      "Epoch 760/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5094 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.5094 - accuracy: 0.6667 - val_loss: 0.8897 - val_accuracy: 0.6429\n",
      "Epoch 761/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.4805 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.4805 - accuracy: 0.6923 - val_loss: 0.8226 - val_accuracy: 0.6429\n",
      "Epoch 762/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4565 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.4565 - accuracy: 0.7692 - val_loss: 0.8983 - val_accuracy: 0.6429\n",
      "Epoch 763/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4540 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.4540 - accuracy: 0.7179 - val_loss: 0.8212 - val_accuracy: 0.6429\n",
      "Epoch 764/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4532 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.4532 - accuracy: 0.7949 - val_loss: 0.9054 - val_accuracy: 0.6429\n",
      "Epoch 765/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4564 - accuracy: 0.71\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 0.4564 - accuracy: 0.7179 - val_loss: 0.8084 - val_accuracy: 0.6429\n",
      "Epoch 766/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.4678 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.4678 - accuracy: 0.7179 - val_loss: 0.9311 - val_accuracy: 0.6429\n",
      "Epoch 767/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4734 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.4734 - accuracy: 0.6923 - val_loss: 0.7948 - val_accuracy: 0.5000\n",
      "Epoch 768/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4943 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.4943 - accuracy: 0.6923 - val_loss: 0.9333 - val_accuracy: 0.6429\n",
      "Epoch 769/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4696 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.4696 - accuracy: 0.7179 - val_loss: 0.8247 - val_accuracy: 0.5714\n",
      "Epoch 770/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4650 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.4650 - accuracy: 0.7436 - val_loss: 0.9166 - val_accuracy: 0.6429\n",
      "Epoch 771/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4612 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.4612 - accuracy: 0.7179 - val_loss: 0.8231 - val_accuracy: 0.6429\n",
      "Epoch 772/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4572 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.4572 - accuracy: 0.7179 - val_loss: 0.9128 - val_accuracy: 0.6429\n",
      "Epoch 773/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4573 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.4573 - accuracy: 0.7179 - val_loss: 0.8083 - val_accuracy: 0.6429\n",
      "Epoch 774/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4690 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.4690 - accuracy: 0.7179 - val_loss: 0.9315 - val_accuracy: 0.6429\n",
      "Epoch 775/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4847 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.4847 - accuracy: 0.6923 - val_loss: 0.7864 - val_accuracy: 0.5000\n",
      "Epoch 776/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5083 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.5083 - accuracy: 0.6667 - val_loss: 0.9070 - val_accuracy: 0.6429\n",
      "Epoch 777/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4803 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.4803 - accuracy: 0.6923 - val_loss: 0.8267 - val_accuracy: 0.6429\n",
      "Epoch 778/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.4612 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.4612 - accuracy: 0.7179 - val_loss: 0.9094 - val_accuracy: 0.6429\n",
      "Epoch 779/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4577 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.4577 - accuracy: 0.7179 - val_loss: 0.8273 - val_accuracy: 0.6429\n",
      "Epoch 780/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4543 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.4543 - accuracy: 0.7436 - val_loss: 0.9078 - val_accuracy: 0.6429\n",
      "Epoch 781/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4534 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 0.4534 - accuracy: 0.7179 - val_loss: 0.8233 - val_accuracy: 0.6429\n",
      "Epoch 782/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4540 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.4540 - accuracy: 0.7436 - val_loss: 0.9216 - val_accuracy: 0.6429\n",
      "Epoch 783/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4609 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.4609 - accuracy: 0.7179 - val_loss: 0.8002 - val_accuracy: 0.5714\n",
      "Epoch 784/2000\n",
      "2/2 [==============================] - 0s 6ms/steposs: 0.4850 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.4850 - accuracy: 0.6923 - val_loss: 0.9436 - val_accuracy: 0.6429\n",
      "Epoch 785/2000\n",
      "2/2 [==============================] - 0s 1000us/step: 0.4719 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.4719 - accuracy: 0.6923 - val_loss: 0.8011 - val_accuracy: 0.5000\n",
      "Epoch 786/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4889 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.4889 - accuracy: 0.6923 - val_loss: 0.9355 - val_accuracy: 0.6429\n",
      "Epoch 787/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4660 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.4660 - accuracy: 0.7179 - val_loss: 0.8142 - val_accuracy: 0.6429\n",
      "Epoch 788/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4672 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 0.4672 - accuracy: 0.6923 - val_loss: 0.9251 - val_accuracy: 0.6429\n",
      "Epoch 789/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4693 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.4693 - accuracy: 0.6923 - val_loss: 0.7974 - val_accuracy: 0.6429\n",
      "Epoch 790/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4857 - accuracy: 0.74\n",
      "1/1 [==============================] - 1s 762ms/step - loss: 0.4857 - accuracy: 0.7436 - val_loss: 0.9101 - val_accuracy: 0.6429\n",
      "Epoch 791/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4555 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.4555 - accuracy: 0.7179 - val_loss: 0.8349 - val_accuracy: 0.6429\n",
      "Epoch 792/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4542 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.4542 - accuracy: 0.7692 - val_loss: 0.8994 - val_accuracy: 0.6429\n",
      "Epoch 793/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4554 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.4554 - accuracy: 0.7179 - val_loss: 0.8376 - val_accuracy: 0.6429\n",
      "Epoch 794/2000\n",
      "2/2 [==============================] - 0s 6ms/steposs: 0.4583 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.4583 - accuracy: 0.7436 - val_loss: 0.8835 - val_accuracy: 0.6429\n",
      "Epoch 795/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4696 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 0.4696 - accuracy: 0.6923 - val_loss: 0.8370 - val_accuracy: 0.6429\n",
      "Epoch 796/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4546 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.4546 - accuracy: 0.7692 - val_loss: 0.8934 - val_accuracy: 0.6429\n",
      "Epoch 797/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4612 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.4612 - accuracy: 0.6923 - val_loss: 0.8371 - val_accuracy: 0.6429\n",
      "Epoch 798/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4614 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.4614 - accuracy: 0.7179 - val_loss: 0.8809 - val_accuracy: 0.6429\n",
      "Epoch 799/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4750 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.4750 - accuracy: 0.6923 - val_loss: 0.8274 - val_accuracy: 0.6429\n",
      "Epoch 800/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4537 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.4537 - accuracy: 0.7436 - val_loss: 0.9280 - val_accuracy: 0.6429\n",
      "Epoch 801/2000\n",
      "2/2 [==============================] - 0s 8ms/steposs: 0.4592 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.4592 - accuracy: 0.7179 - val_loss: 0.8162 - val_accuracy: 0.5000\n",
      "Epoch 802/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4673 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.4673 - accuracy: 0.6923 - val_loss: 0.9660 - val_accuracy: 0.6429\n",
      "Epoch 803/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4928 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.4928 - accuracy: 0.7179 - val_loss: 0.7844 - val_accuracy: 0.5000\n",
      "Epoch 804/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5242 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.5242 - accuracy: 0.6410 - val_loss: 0.9251 - val_accuracy: 0.6429\n",
      "Epoch 805/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4814 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.4814 - accuracy: 0.7179 - val_loss: 0.8305 - val_accuracy: 0.6429\n",
      "Epoch 806/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4551 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.4551 - accuracy: 0.7692 - val_loss: 0.8950 - val_accuracy: 0.6429\n",
      "Epoch 807/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4472 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.4472 - accuracy: 0.7179 - val_loss: 0.8358 - val_accuracy: 0.6429\n",
      "Epoch 808/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4432 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.4432 - accuracy: 0.7949 - val_loss: 0.8843 - val_accuracy: 0.6429\n",
      "Epoch 809/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4419 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.4419 - accuracy: 0.7436 - val_loss: 0.8381 - val_accuracy: 0.5714\n",
      "Epoch 810/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4432 - accuracy: 0.79\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 0.4432 - accuracy: 0.7949 - val_loss: 0.8747 - val_accuracy: 0.6429\n",
      "Epoch 811/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4523 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.4523 - accuracy: 0.7179 - val_loss: 0.8438 - val_accuracy: 0.6429\n",
      "Epoch 812/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4580 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.4580 - accuracy: 0.7692 - val_loss: 0.8504 - val_accuracy: 0.6429\n",
      "Epoch 813/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4797 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.4797 - accuracy: 0.7179 - val_loss: 0.8141 - val_accuracy: 0.6429\n",
      "Epoch 814/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4530 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.4530 - accuracy: 0.7692 - val_loss: 0.9536 - val_accuracy: 0.6429\n",
      "Epoch 815/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4762 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.4762 - accuracy: 0.6923 - val_loss: 0.7944 - val_accuracy: 0.5714\n",
      "Epoch 816/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5170 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.5170 - accuracy: 0.6410 - val_loss: 0.9845 - val_accuracy: 0.6429\n",
      "Epoch 817/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4931 - accuracy: 0.74\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.4931 - accuracy: 0.7436 - val_loss: 0.8152 - val_accuracy: 0.5000\n",
      "Epoch 818/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4724 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.4724 - accuracy: 0.6923 - val_loss: 0.9259 - val_accuracy: 0.6429\n",
      "Epoch 819/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4640 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.4640 - accuracy: 0.6923 - val_loss: 0.8047 - val_accuracy: 0.6429\n",
      "Epoch 820/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4714 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.4714 - accuracy: 0.7949 - val_loss: 0.9067 - val_accuracy: 0.6429\n",
      "Epoch 821/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4464 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.4464 - accuracy: 0.7179 - val_loss: 0.8264 - val_accuracy: 0.6429\n",
      "Epoch 822/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4450 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.4450 - accuracy: 0.7949 - val_loss: 0.9053 - val_accuracy: 0.6429\n",
      "Epoch 823/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4487 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.4487 - accuracy: 0.6923 - val_loss: 0.8058 - val_accuracy: 0.6429\n",
      "Epoch 824/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4654 - accuracy: 0.79\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 0.4654 - accuracy: 0.7949 - val_loss: 0.9242 - val_accuracy: 0.6429\n",
      "Epoch 825/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4551 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.4551 - accuracy: 0.7179 - val_loss: 0.8055 - val_accuracy: 0.6429\n",
      "Epoch 826/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.4705 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.4705 - accuracy: 0.6923 - val_loss: 0.9449 - val_accuracy: 0.6429\n",
      "Epoch 827/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4691 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.4691 - accuracy: 0.6923 - val_loss: 0.8013 - val_accuracy: 0.5000\n",
      "Epoch 828/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4834 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.4834 - accuracy: 0.6410 - val_loss: 0.9431 - val_accuracy: 0.6429\n",
      "Epoch 829/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4656 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.4656 - accuracy: 0.7179 - val_loss: 0.8156 - val_accuracy: 0.5714\n",
      "Epoch 830/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4639 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.4639 - accuracy: 0.6923 - val_loss: 0.9296 - val_accuracy: 0.6429\n",
      "Epoch 831/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4623 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 0.4623 - accuracy: 0.6923 - val_loss: 0.8038 - val_accuracy: 0.6429\n",
      "Epoch 832/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4729 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.4729 - accuracy: 0.7692 - val_loss: 0.9198 - val_accuracy: 0.6429\n",
      "Epoch 833/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4508 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.4508 - accuracy: 0.7179 - val_loss: 0.8233 - val_accuracy: 0.6429\n",
      "Epoch 834/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4510 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.4510 - accuracy: 0.7949 - val_loss: 0.9218 - val_accuracy: 0.6429\n",
      "Epoch 835/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4550 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.4550 - accuracy: 0.6923 - val_loss: 0.8046 - val_accuracy: 0.6429\n",
      "Epoch 836/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4709 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.4709 - accuracy: 0.7692 - val_loss: 0.9329 - val_accuracy: 0.6429\n",
      "Epoch 837/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4576 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.4576 - accuracy: 0.7179 - val_loss: 0.8111 - val_accuracy: 0.6429\n",
      "Epoch 838/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4672 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.4672 - accuracy: 0.6923 - val_loss: 0.9404 - val_accuracy: 0.6429\n",
      "Epoch 839/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4655 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.4655 - accuracy: 0.6923 - val_loss: 0.8029 - val_accuracy: 0.6429\n",
      "Epoch 840/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4780 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 0.4780 - accuracy: 0.6923 - val_loss: 0.9338 - val_accuracy: 0.6429\n",
      "Epoch 841/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4573 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.4573 - accuracy: 0.7179 - val_loss: 0.8239 - val_accuracy: 0.6429\n",
      "Epoch 842/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4563 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.4563 - accuracy: 0.7436 - val_loss: 0.9295 - val_accuracy: 0.6429\n",
      "Epoch 843/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4572 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.4572 - accuracy: 0.7179 - val_loss: 0.8107 - val_accuracy: 0.6429\n",
      "Epoch 844/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.4668 - accuracy: 0.74\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.4668 - accuracy: 0.7436 - val_loss: 0.9325 - val_accuracy: 0.6429\n",
      "Epoch 845/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4592 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.4592 - accuracy: 0.6923 - val_loss: 0.8044 - val_accuracy: 0.6429\n",
      "Epoch 846/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4731 - accuracy: 0.76\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.4731 - accuracy: 0.7692 - val_loss: 0.9261 - val_accuracy: 0.6429\n",
      "Epoch 847/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4510 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.4510 - accuracy: 0.7179 - val_loss: 0.8262 - val_accuracy: 0.6429\n",
      "Epoch 848/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4524 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.4524 - accuracy: 0.7949 - val_loss: 0.9308 - val_accuracy: 0.6429\n",
      "Epoch 849/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4564 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.4564 - accuracy: 0.7179 - val_loss: 0.8121 - val_accuracy: 0.6429\n",
      "Epoch 850/2000\n",
      "2/2 [==============================] - 0s 1ms/steposs: 0.4679 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.4679 - accuracy: 0.7179 - val_loss: 0.9439 - val_accuracy: 0.6429\n",
      "Epoch 851/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4664 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.4664 - accuracy: 0.6923 - val_loss: 0.7997 - val_accuracy: 0.5714\n",
      "Epoch 852/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4832 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.4832 - accuracy: 0.6923 - val_loss: 0.9284 - val_accuracy: 0.6429\n",
      "Epoch 853/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4532 - accuracy: 0.71\n",
      "1/1 [==============================] - 1s 627ms/step - loss: 0.4532 - accuracy: 0.7179 - val_loss: 0.8368 - val_accuracy: 0.6429\n",
      "Epoch 854/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4523 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.4523 - accuracy: 0.7179 - val_loss: 0.9184 - val_accuracy: 0.6429\n",
      "Epoch 855/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4518 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.4518 - accuracy: 0.7179 - val_loss: 0.8402 - val_accuracy: 0.6429\n",
      "Epoch 856/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4520 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.4520 - accuracy: 0.7692 - val_loss: 0.9025 - val_accuracy: 0.6429\n",
      "Epoch 857/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4582 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.4582 - accuracy: 0.6923 - val_loss: 0.8496 - val_accuracy: 0.6429\n",
      "Epoch 858/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4587 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.4587 - accuracy: 0.7692 - val_loss: 0.8665 - val_accuracy: 0.6429\n",
      "Epoch 859/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4733 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.4733 - accuracy: 0.7179 - val_loss: 0.8300 - val_accuracy: 0.6429\n",
      "Epoch 860/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4423 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.4423 - accuracy: 0.7949 - val_loss: 0.9275 - val_accuracy: 0.6429\n",
      "Epoch 861/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4500 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.4500 - accuracy: 0.7179 - val_loss: 0.8052 - val_accuracy: 0.5714\n",
      "Epoch 862/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4713 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.4713 - accuracy: 0.6667 - val_loss: 0.9700 - val_accuracy: 0.6429\n",
      "Epoch 863/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4773 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.4773 - accuracy: 0.7179 - val_loss: 0.7984 - val_accuracy: 0.5000\n",
      "Epoch 864/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4955 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.4955 - accuracy: 0.6410 - val_loss: 0.9516 - val_accuracy: 0.6429\n",
      "Epoch 865/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4638 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.4638 - accuracy: 0.7436 - val_loss: 0.8282 - val_accuracy: 0.6429\n",
      "Epoch 866/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4528 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.4528 - accuracy: 0.7436 - val_loss: 0.9209 - val_accuracy: 0.6429\n",
      "Epoch 867/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4474 - accuracy: 0.71\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 0.4474 - accuracy: 0.7179 - val_loss: 0.8218 - val_accuracy: 0.6429\n",
      "Epoch 868/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4510 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.4510 - accuracy: 0.7949 - val_loss: 0.9237 - val_accuracy: 0.6429\n",
      "Epoch 869/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4563 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.4563 - accuracy: 0.6923 - val_loss: 0.7995 - val_accuracy: 0.6429\n",
      "Epoch 870/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4775 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.4775 - accuracy: 0.7949 - val_loss: 0.9212 - val_accuracy: 0.6429\n",
      "Epoch 871/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.4484 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.4484 - accuracy: 0.7179 - val_loss: 0.8380 - val_accuracy: 0.6429\n",
      "Epoch 872/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4485 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.4485 - accuracy: 0.7692 - val_loss: 0.9221 - val_accuracy: 0.6429\n",
      "Epoch 873/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4500 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.4500 - accuracy: 0.7179 - val_loss: 0.8376 - val_accuracy: 0.6429\n",
      "Epoch 874/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4509 - accuracy: 0.76\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 0.4509 - accuracy: 0.7692 - val_loss: 0.9230 - val_accuracy: 0.6429\n",
      "Epoch 875/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4527 - accuracy: 0.71\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4527 - accuracy: 0.7179 - val_loss: 0.8438 - val_accuracy: 0.6429\n",
      "Epoch 876/2000\n",
      "2/2 [==============================] - 0s 1ms/steposs: 0.4558 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.4558 - accuracy: 0.7436 - val_loss: 0.8923 - val_accuracy: 0.6429\n",
      "Epoch 877/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4689 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.4689 - accuracy: 0.7179 - val_loss: 0.8442 - val_accuracy: 0.5714\n",
      "Epoch 878/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4442 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.4442 - accuracy: 0.7949 - val_loss: 0.9050 - val_accuracy: 0.6429\n",
      "Epoch 879/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4470 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.4470 - accuracy: 0.7179 - val_loss: 0.8455 - val_accuracy: 0.6429\n",
      "Epoch 880/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4523 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.4523 - accuracy: 0.7692 - val_loss: 0.8743 - val_accuracy: 0.6429\n",
      "Epoch 881/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4700 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.4700 - accuracy: 0.7179 - val_loss: 0.8308 - val_accuracy: 0.5714\n",
      "Epoch 882/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4413 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.4413 - accuracy: 0.7949 - val_loss: 0.9403 - val_accuracy: 0.6429\n",
      "Epoch 883/2000\n",
      "2/2 [==============================] - 0s 6ms/steposs: 0.4514 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.4514 - accuracy: 0.7179 - val_loss: 0.8042 - val_accuracy: 0.5000\n",
      "Epoch 884/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4775 - accuracy: 0.64\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.4775 - accuracy: 0.6410 - val_loss: 0.9955 - val_accuracy: 0.6429\n",
      "Epoch 885/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5074 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.5074 - accuracy: 0.7179 - val_loss: 0.7855 - val_accuracy: 0.5000\n",
      "Epoch 886/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5176 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.5176 - accuracy: 0.6410 - val_loss: 0.9246 - val_accuracy: 0.6429\n",
      "Epoch 887/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4689 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 0.4689 - accuracy: 0.7179 - val_loss: 0.8336 - val_accuracy: 0.6429\n",
      "Epoch 888/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4450 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.4450 - accuracy: 0.7949 - val_loss: 0.8998 - val_accuracy: 0.6429\n",
      "Epoch 889/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4375 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.4375 - accuracy: 0.7436 - val_loss: 0.8401 - val_accuracy: 0.5714\n",
      "Epoch 890/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4340 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.4340 - accuracy: 0.7949 - val_loss: 0.8966 - val_accuracy: 0.6429\n",
      "Epoch 891/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4329 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.4329 - accuracy: 0.7436 - val_loss: 0.8348 - val_accuracy: 0.5714\n",
      "Epoch 892/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4341 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.4341 - accuracy: 0.7949 - val_loss: 0.9148 - val_accuracy: 0.6429\n",
      "Epoch 893/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4407 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.4407 - accuracy: 0.7436 - val_loss: 0.8090 - val_accuracy: 0.6429\n",
      "Epoch 894/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4636 - accuracy: 0.79\n",
      "1/1 [==============================] - 1s 539ms/step - loss: 0.4636 - accuracy: 0.7949 - val_loss: 0.9662 - val_accuracy: 0.6429\n",
      "Epoch 895/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4737 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.4737 - accuracy: 0.6923 - val_loss: 0.7956 - val_accuracy: 0.5000\n",
      "Epoch 896/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.5032 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.5032 - accuracy: 0.6410 - val_loss: 0.9616 - val_accuracy: 0.6429\n",
      "Epoch 897/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4676 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.4676 - accuracy: 0.7436 - val_loss: 0.8355 - val_accuracy: 0.6429\n",
      "Epoch 898/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4538 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.4538 - accuracy: 0.7436 - val_loss: 0.9209 - val_accuracy: 0.6429\n",
      "Epoch 899/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4436 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.4436 - accuracy: 0.7179 - val_loss: 0.8402 - val_accuracy: 0.6429\n",
      "Epoch 900/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4378 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 0.4378 - accuracy: 0.7949 - val_loss: 0.9069 - val_accuracy: 0.6429\n",
      "Epoch 901/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4348 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.4348 - accuracy: 0.7436 - val_loss: 0.8404 - val_accuracy: 0.5714\n",
      "Epoch 902/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4341 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.4341 - accuracy: 0.7949 - val_loss: 0.9106 - val_accuracy: 0.6429\n",
      "Epoch 903/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.4352 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.4352 - accuracy: 0.7436 - val_loss: 0.8342 - val_accuracy: 0.6429\n",
      "Epoch 904/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4387 - accuracy: 0.82\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.4387 - accuracy: 0.8205 - val_loss: 0.9355 - val_accuracy: 0.6429\n",
      "Epoch 905/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4458 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.4458 - accuracy: 0.7179 - val_loss: 0.8159 - val_accuracy: 0.5000\n",
      "Epoch 906/2000\n",
      "2/2 [==============================] - 0s 1ms/steposs: 0.4646 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.4646 - accuracy: 0.6667 - val_loss: 0.9887 - val_accuracy: 0.6429\n",
      "Epoch 907/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.5524 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.5524 - accuracy: 0.6923 - val_loss: 0.7875 - val_accuracy: 0.5000\n",
      "Epoch 908/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.5306 - accuracy: 0.64\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.5306 - accuracy: 0.6410 - val_loss: 0.9096 - val_accuracy: 0.6429\n",
      "Epoch 909/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4891 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.4891 - accuracy: 0.7179 - val_loss: 0.8188 - val_accuracy: 0.6429\n",
      "Epoch 910/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4510 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.4510 - accuracy: 0.7692 - val_loss: 0.9023 - val_accuracy: 0.6429\n",
      "Epoch 911/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4392 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.4392 - accuracy: 0.7436 - val_loss: 0.8319 - val_accuracy: 0.5714\n",
      "Epoch 912/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4349 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.4349 - accuracy: 0.7949 - val_loss: 0.8946 - val_accuracy: 0.6429\n",
      "Epoch 913/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4330 - accuracy: 0.74\n",
      "1/1 [==============================] - 1s 536ms/step - loss: 0.4330 - accuracy: 0.7436 - val_loss: 0.8317 - val_accuracy: 0.5714\n",
      "Epoch 914/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4331 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.4331 - accuracy: 0.7949 - val_loss: 0.9045 - val_accuracy: 0.6429\n",
      "Epoch 915/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4355 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.4355 - accuracy: 0.7436 - val_loss: 0.8233 - val_accuracy: 0.5714\n",
      "Epoch 916/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4417 - accuracy: 0.82\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.4417 - accuracy: 0.8205 - val_loss: 0.9372 - val_accuracy: 0.6429\n",
      "Epoch 917/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4538 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.4538 - accuracy: 0.7179 - val_loss: 0.8109 - val_accuracy: 0.5000\n",
      "Epoch 918/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4746 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.4746 - accuracy: 0.6667 - val_loss: 0.9682 - val_accuracy: 0.6429\n",
      "Epoch 919/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4701 - accuracy: 0.71\n",
      "1/1 [==============================] - 1s 536ms/step - loss: 0.4701 - accuracy: 0.7179 - val_loss: 0.8139 - val_accuracy: 0.5000\n",
      "Epoch 920/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4752 - accuracy: 0.64\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.4752 - accuracy: 0.6410 - val_loss: 0.9462 - val_accuracy: 0.6429\n",
      "Epoch 921/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4545 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.4545 - accuracy: 0.7179 - val_loss: 0.8228 - val_accuracy: 0.6429\n",
      "Epoch 922/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4525 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.4525 - accuracy: 0.7949 - val_loss: 0.9271 - val_accuracy: 0.6429\n",
      "Epoch 923/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4454 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.4454 - accuracy: 0.6923 - val_loss: 0.8213 - val_accuracy: 0.5714\n",
      "Epoch 924/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4514 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.4514 - accuracy: 0.7949 - val_loss: 0.9245 - val_accuracy: 0.6429\n",
      "Epoch 925/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4416 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.4416 - accuracy: 0.7436 - val_loss: 0.8218 - val_accuracy: 0.5714\n",
      "Epoch 926/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4492 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.4492 - accuracy: 0.7949 - val_loss: 0.9340 - val_accuracy: 0.6429\n",
      "Epoch 927/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4467 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.4467 - accuracy: 0.6923 - val_loss: 0.8158 - val_accuracy: 0.6429\n",
      "Epoch 928/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4589 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.4589 - accuracy: 0.7949 - val_loss: 0.9499 - val_accuracy: 0.6429\n",
      "Epoch 929/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4540 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.4540 - accuracy: 0.7179 - val_loss: 0.8176 - val_accuracy: 0.5714\n",
      "Epoch 930/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4629 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.4629 - accuracy: 0.6923 - val_loss: 0.9549 - val_accuracy: 0.6429\n",
      "Epoch 931/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4579 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.4579 - accuracy: 0.7436 - val_loss: 0.8177 - val_accuracy: 0.5714\n",
      "Epoch 932/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4621 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.4621 - accuracy: 0.6667 - val_loss: 0.9438 - val_accuracy: 0.6429\n",
      "Epoch 933/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4508 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.4508 - accuracy: 0.7179 - val_loss: 0.8210 - val_accuracy: 0.6429\n",
      "Epoch 934/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4537 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.4537 - accuracy: 0.7949 - val_loss: 0.9346 - val_accuracy: 0.6429\n",
      "Epoch 935/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.4455 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.4455 - accuracy: 0.7179 - val_loss: 0.8201 - val_accuracy: 0.5714\n",
      "Epoch 936/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4520 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.4520 - accuracy: 0.7949 - val_loss: 0.9338 - val_accuracy: 0.6429\n",
      "Epoch 937/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4442 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.4442 - accuracy: 0.7179 - val_loss: 0.8194 - val_accuracy: 0.6429\n",
      "Epoch 938/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4524 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.4524 - accuracy: 0.7949 - val_loss: 0.9414 - val_accuracy: 0.6429\n",
      "Epoch 939/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4479 - accuracy: 0.71\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 0.4479 - accuracy: 0.7179 - val_loss: 0.8174 - val_accuracy: 0.6429\n",
      "Epoch 940/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4577 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.4577 - accuracy: 0.7692 - val_loss: 0.9512 - val_accuracy: 0.6429\n",
      "Epoch 941/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4530 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.4530 - accuracy: 0.7179 - val_loss: 0.8193 - val_accuracy: 0.6429\n",
      "Epoch 942/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4600 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.4600 - accuracy: 0.6667 - val_loss: 0.9523 - val_accuracy: 0.6429\n",
      "Epoch 943/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4537 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.4537 - accuracy: 0.7179 - val_loss: 0.8202 - val_accuracy: 0.6429\n",
      "Epoch 944/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4577 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.4577 - accuracy: 0.7436 - val_loss: 0.9439 - val_accuracy: 0.6429\n",
      "Epoch 945/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4486 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.4486 - accuracy: 0.7179 - val_loss: 0.8213 - val_accuracy: 0.6429\n",
      "Epoch 946/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4532 - accuracy: 0.79\n",
      "1/1 [==============================] - 1s 549ms/step - loss: 0.4532 - accuracy: 0.7949 - val_loss: 0.9378 - val_accuracy: 0.6429\n",
      "Epoch 947/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4445 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.4445 - accuracy: 0.7179 - val_loss: 0.8207 - val_accuracy: 0.5714\n",
      "Epoch 948/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4513 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.4513 - accuracy: 0.7949 - val_loss: 0.9374 - val_accuracy: 0.6429\n",
      "Epoch 949/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4437 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.4437 - accuracy: 0.7179 - val_loss: 0.8206 - val_accuracy: 0.6429\n",
      "Epoch 950/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4520 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.4520 - accuracy: 0.7949 - val_loss: 0.9461 - val_accuracy: 0.6429\n",
      "Epoch 951/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4479 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.4479 - accuracy: 0.7179 - val_loss: 0.8192 - val_accuracy: 0.6429\n",
      "Epoch 952/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4573 - accuracy: 0.71\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 0.4573 - accuracy: 0.7179 - val_loss: 0.9549 - val_accuracy: 0.6429\n",
      "Epoch 953/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4529 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.4529 - accuracy: 0.7179 - val_loss: 0.8230 - val_accuracy: 0.5714\n",
      "Epoch 954/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4587 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.4587 - accuracy: 0.6667 - val_loss: 0.9549 - val_accuracy: 0.6429\n",
      "Epoch 955/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.4526 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.4526 - accuracy: 0.7179 - val_loss: 0.8221 - val_accuracy: 0.6429\n",
      "Epoch 956/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4561 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.4561 - accuracy: 0.7692 - val_loss: 0.9438 - val_accuracy: 0.6429\n",
      "Epoch 957/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4463 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.4463 - accuracy: 0.7179 - val_loss: 0.8233 - val_accuracy: 0.6429\n",
      "Epoch 958/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4514 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.4514 - accuracy: 0.7949 - val_loss: 0.9378 - val_accuracy: 0.6429\n",
      "Epoch 959/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4416 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 0.4416 - accuracy: 0.7179 - val_loss: 0.8226 - val_accuracy: 0.5000\n",
      "Epoch 960/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4490 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.4490 - accuracy: 0.7949 - val_loss: 0.9380 - val_accuracy: 0.6429\n",
      "Epoch 961/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4414 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.4414 - accuracy: 0.7179 - val_loss: 0.8225 - val_accuracy: 0.5714\n",
      "Epoch 962/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4502 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.4502 - accuracy: 0.7949 - val_loss: 0.9510 - val_accuracy: 0.6429\n",
      "Epoch 963/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4483 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.4483 - accuracy: 0.7179 - val_loss: 0.8214 - val_accuracy: 0.5714\n",
      "Epoch 964/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4588 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.4588 - accuracy: 0.6667 - val_loss: 0.9638 - val_accuracy: 0.6429\n",
      "Epoch 965/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4556 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.4556 - accuracy: 0.7436 - val_loss: 0.8258 - val_accuracy: 0.5714\n",
      "Epoch 966/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4593 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 0.4593 - accuracy: 0.6923 - val_loss: 0.9568 - val_accuracy: 0.6429\n",
      "Epoch 967/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4514 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.4514 - accuracy: 0.7179 - val_loss: 0.8250 - val_accuracy: 0.6429\n",
      "Epoch 968/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4536 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.4536 - accuracy: 0.7692 - val_loss: 0.9419 - val_accuracy: 0.6429\n",
      "Epoch 969/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4426 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.4426 - accuracy: 0.7179 - val_loss: 0.8249 - val_accuracy: 0.5000\n",
      "Epoch 970/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4487 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.4487 - accuracy: 0.7949 - val_loss: 0.9337 - val_accuracy: 0.6429\n",
      "Epoch 971/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.4370 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.4370 - accuracy: 0.7436 - val_loss: 0.8269 - val_accuracy: 0.5714\n",
      "Epoch 972/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4438 - accuracy: 0.79\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.4438 - accuracy: 0.7949 - val_loss: 0.9395 - val_accuracy: 0.6429\n",
      "Epoch 973/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4403 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.4403 - accuracy: 0.7436 - val_loss: 0.8209 - val_accuracy: 0.5714\n",
      "Epoch 974/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4522 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.4522 - accuracy: 0.7949 - val_loss: 0.9591 - val_accuracy: 0.6429\n",
      "Epoch 975/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4500 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.4500 - accuracy: 0.7179 - val_loss: 0.8255 - val_accuracy: 0.5714\n",
      "Epoch 976/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4603 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.4603 - accuracy: 0.6923 - val_loss: 0.9720 - val_accuracy: 0.6429\n",
      "Epoch 977/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4588 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.4588 - accuracy: 0.7436 - val_loss: 0.8274 - val_accuracy: 0.5714\n",
      "Epoch 978/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4592 - accuracy: 0.69\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.4592 - accuracy: 0.6923 - val_loss: 0.9553 - val_accuracy: 0.6429\n",
      "Epoch 979/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4485 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.4485 - accuracy: 0.7179 - val_loss: 0.8264 - val_accuracy: 0.5714\n",
      "Epoch 980/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4513 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.4513 - accuracy: 0.7692 - val_loss: 0.9378 - val_accuracy: 0.6429\n",
      "Epoch 981/2000\n",
      "2/2 [==============================] - 0s 4ms/steposs: 0.4373 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.4373 - accuracy: 0.7436 - val_loss: 0.8301 - val_accuracy: 0.5714\n",
      "Epoch 982/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4425 - accuracy: 0.79\n",
      "1/1 [==============================] - 1s 640ms/step - loss: 0.4425 - accuracy: 0.7949 - val_loss: 0.9326 - val_accuracy: 0.6429\n",
      "Epoch 983/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4352 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.4352 - accuracy: 0.7436 - val_loss: 0.8262 - val_accuracy: 0.5714\n",
      "Epoch 984/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.4444 - accuracy: 0.79\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.4444 - accuracy: 0.7949 - val_loss: 0.9439 - val_accuracy: 0.6429\n",
      "Epoch 985/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4396 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.4396 - accuracy: 0.7436 - val_loss: 0.8237 - val_accuracy: 0.6429\n",
      "Epoch 986/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4517 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.4517 - accuracy: 0.7436 - val_loss: 0.9693 - val_accuracy: 0.6429\n",
      "Epoch 987/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4546 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.4546 - accuracy: 0.7436 - val_loss: 0.8258 - val_accuracy: 0.5714\n",
      "Epoch 988/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4643 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.4643 - accuracy: 0.6923 - val_loss: 0.9739 - val_accuracy: 0.6429\n",
      "Epoch 989/2000\n",
      "2/2 [==============================] - 0s 6ms/steposs: 0.4575 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.4575 - accuracy: 0.7436 - val_loss: 0.8297 - val_accuracy: 0.5714\n",
      "Epoch 990/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4551 - accuracy: 0.71\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.4551 - accuracy: 0.7179 - val_loss: 0.9509 - val_accuracy: 0.6429\n",
      "Epoch 991/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4436 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.4436 - accuracy: 0.7179 - val_loss: 0.8286 - val_accuracy: 0.5714\n",
      "Epoch 992/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4473 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.4473 - accuracy: 0.7949 - val_loss: 0.9352 - val_accuracy: 0.6429\n",
      "Epoch 993/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4339 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.4339 - accuracy: 0.7436 - val_loss: 0.8328 - val_accuracy: 0.5714\n",
      "Epoch 994/2000\n",
      "2/2 [==============================] - 0s 5ms/steposs: 0.4392 - accuracy: 0.79\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.4392 - accuracy: 0.7949 - val_loss: 0.9354 - val_accuracy: 0.6429\n",
      "Epoch 995/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4347 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.4347 - accuracy: 0.7436 - val_loss: 0.8250 - val_accuracy: 0.5714\n",
      "Epoch 996/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4458 - accuracy: 0.79\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 0.4458 - accuracy: 0.7949 - val_loss: 0.9513 - val_accuracy: 0.6429\n",
      "Epoch 997/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4408 - accuracy: 0.71\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.4408 - accuracy: 0.7179 - val_loss: 0.8263 - val_accuracy: 0.6429\n",
      "Epoch 998/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4531 - accuracy: 0.69\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.4531 - accuracy: 0.6923 - val_loss: 0.9771 - val_accuracy: 0.6429\n",
      "Epoch 999/2000\n",
      "2/2 [==============================] - 0s 2ms/steposs: 0.4579 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.4579 - accuracy: 0.7436 - val_loss: 0.8279 - val_accuracy: 0.5714\n",
      "Epoch 1000/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4637 - accuracy: 0.66\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 0.4637 - accuracy: 0.6667 - val_loss: 0.9706 - val_accuracy: 0.6429\n",
      "Epoch 1001/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4532 - accuracy: 0.74\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.4532 - accuracy: 0.7436 - val_loss: 0.8301 - val_accuracy: 0.6429\n",
      "Epoch 1002/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4514 - accuracy: 0.76\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 0.4514 - accuracy: 0.7692 - val_loss: 0.9466 - val_accuracy: 0.6429\n",
      "Epoch 1003/2000\n",
      "2/2 [==============================] - 0s 3ms/steposs: 0.4387 - accuracy: 0.74\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.4387 - accuracy: 0.7436 - val_loss: 0.8315 - val_accuracy: 0.5714\n",
      "Epoch 1003: early stopping\n",
      "Accuracy: 35.90%\n"
     ]
    }
   ],
   "source": [
    "early_stop=tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1000, verbose=2, mode='auto', baseline=None, restore_best_weights=True)\n",
    "model.fit(X_train_def, y_train_def, epochs=numero_epochs, batch_size=100, callbacks=[tensorboard_callback,cm_callback,early_stop], validation_data=(X_val_def, y_val_def))\n",
    "# Final evaluation of the model \n",
    "scores = model.evaluate(X_test_def, y_test_def, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "(39, 2)\n",
      "(39,)\n",
      "(39,)\n",
      "[1 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "#y_pred2=np.where(y_pred>0,1,0)\n",
    "#y_pred2=y_pred2[:,-1]\n",
    "y_test_def2=np.argmax(y_test_def,axis=1)\n",
    "#y_test_def2=np.where(y_test_def>0,1,0)\n",
    "print(y_pred.shape)\n",
    "print(y_pred2.shape)\n",
    "print(y_test_def2.shape)\n",
    "#print(y_test_def[25])\n",
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#docs_infra: no_execute\n",
    "if numero_clases==2:\n",
    "    classes = [0, 1]\n",
    "else:   \n",
    "    classes = [0, 1, 2, 3, 4]\n",
    "#classes = [0, 1]\n",
    "cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Buenos     0.7500    0.2069    0.3243        29\n",
      "       Malos     0.2581    0.8000    0.3902        10\n",
      "\n",
      "    accuracy                         0.3590        39\n",
      "   macro avg     0.5040    0.5034    0.3573        39\n",
      "weighted avg     0.6239    0.3590    0.3412        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "if numero_clases==2:\n",
    "    target_names = ['Buenos', 'Malos']\n",
    "else:   \n",
    "    target_names = ['A', 'B+', 'B', 'B-','C']\n",
    "print(classification_report(y_test_def2, y_pred2, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('modelos/modelote1203_200')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('idea.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "model.save('modelos\\modelo_perfecto_{}_{}.h5'.format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "\n",
    "existing_file='RESULTADOS_EXCEL\\clasificacion_39_AGILENT_def.xlsx'\n",
    "\n",
    "# Verifica si el archivo existe y si está vacío\n",
    "if not os.path.exists(existing_file) or os.path.getsize(existing_file) == 0:\n",
    "    df_inicial=pd.DataFrame(y_test_def2, columns=[\"target\"])\n",
    "    df_inicial.to_excel(existing_file, index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'RESULTADOS_EXCEL\\\\clasificacion_39_AGILENT_def.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m df_combined\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mconcat([df_existing, df_new], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Guarda los DataFrames en archivos Excel\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mdf_combined\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexisting_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\pandas\\core\\generic.py:2345\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   2332\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2334\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2335\u001b[0m     df,\n\u001b[0;32m   2336\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2343\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2344\u001b[0m )\n\u001b[1;32m-> 2345\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2347\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2354\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\pandas\\io\\formats\\excel.py:946\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    942\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;66;03m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001b[39;00m\n\u001b[0;32m    945\u001b[0m     \u001b[38;5;66;03m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[abstract]\u001b[39;49;00m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    952\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:61\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[0;32m     59\u001b[0m engine_kwargs \u001b[38;5;241m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# ExcelWriter replaced \"a\" by \"r+\" to allow us to first read the excel file from\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# the file and later write to it\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode:  \u001b[38;5;66;03m# Load from existing workbook\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1263\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m   1260\u001b[0m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m   1261\u001b[0m )\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m date_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\pandas\\io\\common.py:872\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    873\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'RESULTADOS_EXCEL\\\\clasificacion_39_AGILENT_def.xlsx'"
     ]
    }
   ],
   "source": [
    "# Convierte los arrays a DataFrames\n",
    "df_new = pd.DataFrame(y_pred2, columns=[experimento])\n",
    "# Read existing data\n",
    "df_existing = pd.read_excel(existing_file)\n",
    "# Append new data\n",
    "df_combined=pd.concat([df_existing, df_new], axis=1)\n",
    "\n",
    "# Guarda los DataFrames en archivos Excel\n",
    "df_combined.to_excel(existing_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#este modo de guardar no funciona en esta version de tensorflow\n",
    "#model.save('modelos\\modelo_perfecto_{}_{}'.format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step\n",
      "[0 1 1 0 0 1 0 0 0]\n",
      "[0 1 1 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "n = len(y_pred2)\n",
    "reshaped = y_pred2[:n//4*4].reshape(-1, 4)\n",
    "mean_values = reshaped.mean(axis=1)\n",
    "\n",
    "mean_values = np.round(mean_values)\n",
    "mean_values = np.clip(mean_values, 0, 4)\n",
    "mean_values = mean_values.astype(int)\n",
    "print(mean_values)\n",
    "\n",
    "mode_values = stats.mode(reshaped, axis=1)[0]\n",
    "print(mode_values)\n",
    "\n",
    "# Convierte los arrays a DataFrames\n",
    "mean_df = pd.DataFrame(mean_values, columns=['mean'])\n",
    "mode_df = pd.DataFrame(mode_values, columns=['mode'])\n",
    "\n",
    "# Guarda los DataFrames en archivos Excel\n",
    "mean_df.to_excel(\"excels_borrar\\clasificacion_P1P2_mean_best7.xlsx\", index=False)\n",
    "mode_df.to_excel(\"excels_borrar\\clasificacion_P1_mode_best7.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1\n",
      " 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 220, 8)\n",
      "(200, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 8 features, but StandardScaler is expecting 1 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 57\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# print(X_train_filtrado[0][:,:])\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# # # Vamos a normalizar o escalar los datos\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# concatenamos train y test\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m#scaler = MinMaxScaler(feature_range=(0, 1))\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\u001b[39;00m\n\u001b[0;32m     56\u001b[0m data_2d_test \u001b[38;5;241m=\u001b[39m X_test2_filtrado\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, X_test2_filtrado\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 57\u001b[0m normalized_data_2d_test \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_2d_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m X_test2_def\u001b[38;5;241m=\u001b[39mnormalized_data_2d_test\u001b[38;5;241m.\u001b[39mreshape(X_test2_filtrado\u001b[38;5;241m.\u001b[39mshape) \n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# la alternativa es normalizar con el total\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1004\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1001\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1003\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1004\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\sklearn\\base.py:625\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 625\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\sklearn\\base.py:414\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 8 features, but StandardScaler is expecting 1 features as input."
     ]
    }
   ],
   "source": [
    "filename5 = \"COPIA_PANDAS\\lomosP1_20240430_clasificado_experto.hdf\"\n",
    "with pd.HDFStore(filename5,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e2  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e2 = pre_p_e2.loc[pre_p_e2['Pollo'] != 0]\n",
    "    pre_p_e2 =pre_p_e2.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_test2=np.zeros((pre_p_e2.shape[0],220,8))\n",
    "    y_test2=np.zeros((pre_p_e2.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e2.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1:\n",
    "                target = 0 \n",
    "            else:\n",
    "                target = 1\n",
    "\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_test2[x]=pepito[:,3:4]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_test2[x]=target\n",
    "        y_test2_to_categorical = to_categorical(y_test2)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_test2_filtrado = X_test2\n",
    "#y_train_filtrado = y_train\n",
    "y_test2_filtrado = y_test2_to_categorical\n",
    "\n",
    "print(X_test2_filtrado.shape)\n",
    "print(y_test2_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "# concatenamos train y test\n",
    "#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\n",
    "data_2d_test = X_test2_filtrado.reshape(-1, X_test2_filtrado.shape[-1])\n",
    "normalized_data_2d_test = scaler.transform(data_2d_test)\n",
    "\n",
    "\n",
    "X_test2_def=normalized_data_2d_test.reshape(X_test2_filtrado.shape) \n",
    "# la alternativa es normalizar con el total\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "\n",
    "y_test2_def=y_test2_filtrado # los valores ya estaban normalizados\n",
    "\n",
    "print(y_test2_def.shape)\n",
    "\n",
    "print(y_test2_filtrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# # Crear un nuevo modelo con la misma arquitectura\n",
    "# best_val_model = create_model()  # Reemplaza esto con la función que usaste para crear el modelo original\n",
    "\n",
    "# # Cargar los mejores pesos\n",
    "# best_val_model.load_weights('best_weights.h5')\n",
    "\n",
    "y_pred = model.predict(X_test2_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "n = len(y_pred2)\n",
    "print(n)\n",
    "reshaped = y_pred2[:n//4*4].reshape(-1, 4)\n",
    "mean_values = reshaped.mean(axis=1)\n",
    "\n",
    "mean_values = np.round(mean_values)\n",
    "mean_values = np.clip(mean_values, 0, 4)\n",
    "mean_values = mean_values.astype(int)\n",
    "print(mean_values.shape)\n",
    "\n",
    "mode_values = stats.mode(reshaped, axis=1)[0]\n",
    "print(mode_values.shape)\n",
    "\n",
    "n = len(y_test2_def)\n",
    "y_test2_def2=np.argmax(y_test2_def,axis=1)\n",
    "print(y_test_def2.shape)\n",
    "print(n)\n",
    "reshaped2 = y_test2_def2[:n//4*4].reshape(-1, 4)\n",
    "target_mean_values = reshaped2.mean(axis=1)\n",
    "\n",
    "target_mean_values = np.round(target_mean_values)\n",
    "target_mean_values = np.clip(target_mean_values, 0, 4)\n",
    "target_mean_values = target_mean_values.astype(int)\n",
    "print(target_mean_values.shape)\n",
    "\n",
    "target_mode_values = stats.mode(reshaped2, axis=1)[0]\n",
    "print(target_mode_values.shape)\n",
    "print(reshaped)\n",
    "print(mode_values)\n",
    "print(target_mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs_infra: no_execute\n",
    "if numero_clases==2:\n",
    "    classes = [0, 1]    \n",
    "else:\n",
    "\n",
    "    classes = [0, 1, 2, 3, 4]\n",
    "#classes = [0, 1]\n",
    "cm=confusion_matrix(target_mode_values, mode_values,labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm.diagonal()/cm.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if numero_clases==2:\n",
    "    target_names= ['Buenos', 'Malos']\n",
    "else:\n",
    "    target_names= ['A', 'B+', 'B', 'B-','C']\n",
    "print(classification_report(target_mode_values, mode_values, target_names=target_names, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
