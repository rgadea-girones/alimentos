{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 16:56:14.102825: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-16 16:56:14.102888: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-16 16:56:14.105428: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-16 16:56:14.118921: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-16 16:56:14.931380: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rgadea/experimentos_software_2024\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM,Bidirectional,GRU\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import datetime\n",
    "import io\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Obtener la ruta del directorio actual\n",
    "os.chdir('/home/rgadea/experimentos_software_2024')\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "# Construir la ruta relativa al directorio que quieres agregar\n",
    "relative_dir = os.path.join(current_dir, 'mis_pkgs/')\n",
    "\n",
    "# Agregar la ruta relativa al sys.path\n",
    "sys.path.insert(0, relative_dir)\n",
    "\n",
    "from MIOPATIA_db import DB_management as db \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a quedarme con los 50 atunes P1 para obtener conjunto de training y validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rgadea/experimentos_software_2024\n"
     ]
    }
   ],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5907, 2)\n"
     ]
    }
   ],
   "source": [
    "filename = \"hdf_lomosP1P2_trainval_filtrado_def_good_ampliado_the_best7.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    # p_e =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_train=np.zeros((pre_p_e1.shape[0],220,8))\n",
    "    y_train=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if estado == 0 or estado== 1:\n",
    "            target = 1\n",
    "        else:\n",
    "            target = 0\n",
    "        #target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_train[x]=pepito[:,3:11]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_train[x]=target\n",
    "        y_train_to_categorical = to_categorical(y_train)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_train_filtrado = X_train\n",
    "#y_train_filtrado = y_train\n",
    "y_train_filtrado = y_train_to_categorical\n",
    "\n",
    "# print(X_train_filtrado.shape)\n",
    "# print(y_train_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_2d = X_train_filtrado.reshape(-1, X_train_filtrado.shape[-1])\n",
    "normalized_data_2d = scaler.fit_transform(data_2d)\n",
    "X_train_Normalizado=normalized_data_2d.reshape(X_train_filtrado.shape)\n",
    "y_train_Normalizado=y_train_filtrado # los valores ya estaban normalizados\n",
    "print(y_train_Normalizado.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176, 220, 8)\n",
      "(176, 2)\n",
      "[[3.73764140e-01 4.22950163e-01 2.73004947e-02 ... 5.77049837e-01\n",
      "  3.73756468e-01 6.65796904e-01]\n",
      " [3.77897166e-01 4.15326043e-01 2.72960089e-02 ... 5.84673957e-01\n",
      "  3.77887879e-01 6.53769355e-01]\n",
      " [3.71094548e-01 4.10647567e-01 2.73000169e-02 ... 5.89352433e-01\n",
      "  3.71084466e-01 6.51193263e-01]\n",
      " ...\n",
      " [3.34509932e-04 3.16651268e-01 2.62077453e-02 ... 6.83348732e-01\n",
      "  3.34478182e-04 8.46134111e-01]\n",
      " [3.20346260e-04 3.12631829e-01 2.62088742e-02 ... 6.87368171e-01\n",
      "  3.20314636e-04 8.46141503e-01]\n",
      " [3.06488290e-04 3.10423025e-01 2.62093514e-02 ... 6.89576975e-01\n",
      "  3.06457393e-04 8.46151049e-01]]\n"
     ]
    }
   ],
   "source": [
    "filename = \"hdf_lomosP1P2_test_filtrado_def_good.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    pre_p_e1 =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_test=np.zeros((pre_p_e1.shape[0],220,8))\n",
    "    y_test=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if estado == 0 or estado== 1:\n",
    "           target = 1\n",
    "        else:\n",
    "           target = 0\n",
    "        #target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_test[x]=pepito[:,3:11]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_test[x]=target\n",
    "        y_test_to_categorical = to_categorical(y_test)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_test_filtrado = X_test\n",
    "#y_train_filtrado = y_train\n",
    "y_test_filtrado = y_test_to_categorical\n",
    "\n",
    "print(X_test_filtrado.shape)\n",
    "print(y_test_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "# concatenamos train y test\n",
    "#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\n",
    "data_2d_test = X_test_filtrado.reshape(-1, X_test_filtrado.shape[-1])\n",
    "normalized_data_2d_test = scaler.transform(data_2d_test)\n",
    "\n",
    "\n",
    "X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "# la alternativa es normalizar con el total\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "\n",
    "y_test_def=y_test_filtrado # los valores ya estaban normalizados\n",
    "print(X_test_def[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer los conjuntos de entrenamiento validacion y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide el dataset en entrenamiento y temporal (test+validación)\n",
    "# X_temp, X_test_def, y_temp, y_test_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.2, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Divide el dataset temporal en validación y test\n",
    "X_train_def, X_val_def, y_train_def, y_val_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.25, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Ahora, X_train, X_val y X_test contienen los datos de entrada para los conjuntos de entrenamiento, validación y prueba, respectivamente.\n",
    "# y_train, y_val y y_test contienen las clases correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4430, 220, 8)\n",
      "(1477, 220, 8)\n",
      "(176, 220, 8)\n",
      "(4430, 2)\n",
      "(1477, 2)\n",
      "(176, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_def.shape)\n",
    "print(X_val_def.shape)\n",
    "print(X_test_def.shape)\n",
    "print(y_train_def.shape)\n",
    "print(y_val_def.shape)\n",
    "print(y_test_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "#%tensorboard --logdir logs\n",
    "#log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"\n",
    "    Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\n",
    "    \"\"\"\n",
    "    \n",
    "    buf = io.BytesIO()\n",
    "    \n",
    "    # Use plt.savefig to save the plot to a PNG in memory.\n",
    "    plt.savefig(buf, format='png')\n",
    "    \n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    \n",
    "    # Use tf.image.decode_png to convert the PNG buffer\n",
    "    # to a TF image. Make sure you use 4 channels.\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    \n",
    "    # Use tf.expand_dims to add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "       class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    \n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    # Normalize the confusion matrix.\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    \n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    threshold = 0.5\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"red\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 16:56:20.461623: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2024-05-16 16:56:20.461838: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: nodofpga-2024.novalocal\n",
      "2024-05-16 16:56:20.461880: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: nodofpga-2024.novalocal\n",
      "2024-05-16 16:56:20.462424: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 535.161.7\n",
      "2024-05-16 16:56:20.462690: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 535.161.7\n",
      "2024-05-16 16:56:20.462736: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 535.161.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 50)                9000      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11652 (45.52 KB)\n",
      "Trainable params: 11652 (45.52 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "algoritmo='RMSprop'\n",
    "supermax=8*4\n",
    "lossfunction='categorical_crossentropy'\n",
    "factor_aprendizaje=0.001\n",
    "dimension_LSTM=50\n",
    "dimension_dense=50\n",
    "model = Sequential()\n",
    "model.add(GRU(dimension_LSTM, return_sequences=False,input_shape=(220, 8)))\n",
    "#model.add(Bidirectional(LSTM(50, return_sequences=True)))\n",
    "#model.add(Bidirectional(LSTM(50, return_sequences=True)))\n",
    "#model.add(Bidirectional(LSTM(50, return_sequences=False)))\n",
    "model.add(Dense(dimension_dense, activation='tanh'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss=lossfunction, optimizer=algoritmo, metrics=['accuracy'])\n",
    "model.optimizer.lr=(factor_aprendizaje)\n",
    "print(model.summary())\n",
    "\n",
    "experimento=\"LOMOS_P2yP1_GRU2_2_clasesfiltrado_{}_dense_onehot_{}_loss_{}_lr_{}_algoritmo_{}\".format(dimension_LSTM,dimension_dense,lossfunction,factor_aprendizaje,algoritmo)\n",
    "logdir=\"./logs/defs/{}_{}\".format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=[\"Buenos\",\"Malos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    \n",
    "    # Use the model to predict the values from the test_images.\n",
    "    y_pred = model.predict(X_test_def)\n",
    "    #y_pred1=y_pred[:,-1]\n",
    "    y_pred2=y_pred.argmax(axis=1)\n",
    "    #y_pred2=np.where(y_pred>0,1,0)\n",
    "    #y_pred2=y_pred2[:,-1]\n",
    "    #classes = [0, 1, 2, 3, 4] \n",
    "    classes = [0, 1]\n",
    "    y_test_def2=np.argmax(y_test_def,axis=1)  \n",
    "    #y_test_def2=np.where(y_test_def>0,1,0)\n",
    "    cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    figura = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figura)\n",
    "    \n",
    "    # Log the confusion matrix as an image summary.\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5907, 2)\n",
      "(1477, 2)\n"
     ]
    }
   ],
   "source": [
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "print(y_train_Normalizado.shape)\n",
    "print(y_val_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "6/6 [==============================] - 1s 25ms/step- loss: 0.6934 - accuracy: \n",
      "296/296 [==============================] - 28s 88ms/step - loss: 0.6934 - accuracy: 0.5167 - val_loss: 0.6921 - val_accuracy: 0.5159\n",
      "Epoch 2/400\n",
      "6/6 [==============================] - 0s 26ms/step- loss: 0.6917 - accuracy: \n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.6917 - accuracy: 0.5236 - val_loss: 0.6901 - val_accuracy: 0.5328\n",
      "Epoch 3/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.6899 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6899 - accuracy: 0.5265 - val_loss: 0.6919 - val_accuracy: 0.5234\n",
      "Epoch 4/400\n",
      "6/6 [==============================] - 0s 17ms/step- loss: 0.6901 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.6901 - accuracy: 0.5331 - val_loss: 0.6952 - val_accuracy: 0.5159\n",
      "Epoch 5/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6900 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.6900 - accuracy: 0.5317 - val_loss: 0.6960 - val_accuracy: 0.4976\n",
      "Epoch 6/400\n",
      "6/6 [==============================] - 0s 29ms/step- loss: 0.6896 - accuracy: \n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6896 - accuracy: 0.5319 - val_loss: 0.6900 - val_accuracy: 0.5281\n",
      "Epoch 7/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.6892 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.6892 - accuracy: 0.5309 - val_loss: 0.6898 - val_accuracy: 0.5295\n",
      "Epoch 8/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6896 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 86ms/step - loss: 0.6896 - accuracy: 0.5328 - val_loss: 0.6899 - val_accuracy: 0.5227\n",
      "Epoch 9/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.6893 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.6893 - accuracy: 0.5277 - val_loss: 0.6900 - val_accuracy: 0.5559\n",
      "Epoch 10/400\n",
      "6/6 [==============================] - 0s 27ms/step- loss: 0.6888 - accuracy: \n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.6888 - accuracy: 0.5382 - val_loss: 0.6894 - val_accuracy: 0.5552\n",
      "Epoch 11/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6891 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.6891 - accuracy: 0.5351 - val_loss: 0.6897 - val_accuracy: 0.5206\n",
      "Epoch 12/400\n",
      "6/6 [==============================] - 0s 26ms/step- loss: 0.6885 - accuracy: \n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.6885 - accuracy: 0.5299 - val_loss: 0.6889 - val_accuracy: 0.5281\n",
      "Epoch 13/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.6880 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.6880 - accuracy: 0.5380 - val_loss: 0.6855 - val_accuracy: 0.5457\n",
      "Epoch 14/400\n",
      "6/6 [==============================] - 0s 25ms/step- loss: 0.6862 - accuracy: \n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.6862 - accuracy: 0.5499 - val_loss: 0.6838 - val_accuracy: 0.5599\n",
      "Epoch 15/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.6855 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.6855 - accuracy: 0.5431 - val_loss: 0.6851 - val_accuracy: 0.5383\n",
      "Epoch 16/400\n",
      "6/6 [==============================] - 0s 23ms/step- loss: 0.6854 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.6854 - accuracy: 0.5451 - val_loss: 0.6869 - val_accuracy: 0.5335\n",
      "Epoch 17/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.6836 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6836 - accuracy: 0.5438 - val_loss: 0.6788 - val_accuracy: 0.5680\n",
      "Epoch 18/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.6816 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.6816 - accuracy: 0.5536 - val_loss: 0.6760 - val_accuracy: 0.5829\n",
      "Epoch 19/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6777 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 89ms/step - loss: 0.6777 - accuracy: 0.5544 - val_loss: 0.6781 - val_accuracy: 0.5768\n",
      "Epoch 20/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6767 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.6767 - accuracy: 0.5593 - val_loss: 0.6957 - val_accuracy: 0.5315\n",
      "Epoch 21/400\n",
      "6/6 [==============================] - 0s 28ms/step- loss: 0.6763 - accuracy: \n",
      "296/296 [==============================] - 26s 88ms/step - loss: 0.6763 - accuracy: 0.5715 - val_loss: 0.6643 - val_accuracy: 0.5944\n",
      "Epoch 22/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.6716 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.6716 - accuracy: 0.5776 - val_loss: 0.6607 - val_accuracy: 0.5931\n",
      "Epoch 23/400\n",
      "6/6 [==============================] - 0s 25ms/step- loss: 0.6683 - accuracy: \n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.6683 - accuracy: 0.5797 - val_loss: 0.6634 - val_accuracy: 0.5694\n",
      "Epoch 24/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.6726 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.6726 - accuracy: 0.5759 - val_loss: 0.6795 - val_accuracy: 0.5782\n",
      "Epoch 25/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6702 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6702 - accuracy: 0.5885 - val_loss: 0.6547 - val_accuracy: 0.6378\n",
      "Epoch 26/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6729 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 86ms/step - loss: 0.6729 - accuracy: 0.5695 - val_loss: 0.7011 - val_accuracy: 0.5619\n",
      "Epoch 27/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6663 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.6663 - accuracy: 0.5984 - val_loss: 0.6734 - val_accuracy: 0.5850\n",
      "Epoch 28/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6644 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.6644 - accuracy: 0.5957 - val_loss: 0.6602 - val_accuracy: 0.5606\n",
      "Epoch 29/400\n",
      "6/6 [==============================] - 0s 27ms/step- loss: 0.6601 - accuracy: \n",
      "296/296 [==============================] - 26s 88ms/step - loss: 0.6601 - accuracy: 0.5998 - val_loss: 0.6563 - val_accuracy: 0.6398\n",
      "Epoch 30/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.6687 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6687 - accuracy: 0.5913 - val_loss: 0.6571 - val_accuracy: 0.5992\n",
      "Epoch 31/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6597 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.6597 - accuracy: 0.6118 - val_loss: 0.6571 - val_accuracy: 0.6236\n",
      "Epoch 32/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6574 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6574 - accuracy: 0.6035 - val_loss: 0.6595 - val_accuracy: 0.6236\n",
      "Epoch 33/400\n",
      "6/6 [==============================] - 0s 16ms/step- loss: 0.6617 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.6617 - accuracy: 0.5984 - val_loss: 0.6724 - val_accuracy: 0.6148\n",
      "Epoch 34/400\n",
      "6/6 [==============================] - 0s 15ms/step- loss: 0.6579 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.6579 - accuracy: 0.6037 - val_loss: 0.7442 - val_accuracy: 0.5836\n",
      "Epoch 35/400\n",
      "6/6 [==============================] - 0s 26ms/step- loss: 0.6619 - accuracy: \n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6619 - accuracy: 0.6138 - val_loss: 0.6440 - val_accuracy: 0.6290\n",
      "Epoch 36/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6715 - accuracy: \n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.6715 - accuracy: 0.5951 - val_loss: 0.6648 - val_accuracy: 0.5877\n",
      "Epoch 37/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6592 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.6592 - accuracy: 0.6130 - val_loss: 0.6535 - val_accuracy: 0.6249\n",
      "Epoch 38/400\n",
      "6/6 [==============================] - 0s 24ms/step- loss: 0.6637 - accuracy: 0.\n",
      "296/296 [==============================] - 23s 79ms/step - loss: 0.6637 - accuracy: 0.6003 - val_loss: 0.8707 - val_accuracy: 0.5240\n",
      "Epoch 39/400\n",
      "6/6 [==============================] - 0s 24ms/step- loss: 0.7063 - accuracy: \n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.7063 - accuracy: 0.5299 - val_loss: 0.7760 - val_accuracy: 0.5342\n",
      "Epoch 40/400\n",
      "6/6 [==============================] - 0s 25ms/step- loss: 0.6868 - accuracy: \n",
      "296/296 [==============================] - 24s 81ms/step - loss: 0.6868 - accuracy: 0.5434 - val_loss: 0.6870 - val_accuracy: 0.5450\n",
      "Epoch 41/400\n",
      "6/6 [==============================] - 0s 16ms/step- loss: 0.6707 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.6707 - accuracy: 0.5832 - val_loss: 0.7039 - val_accuracy: 0.5484\n",
      "Epoch 42/400\n",
      "6/6 [==============================] - 0s 25ms/step- loss: 0.6560 - accuracy: \n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.6560 - accuracy: 0.6113 - val_loss: 0.6334 - val_accuracy: 0.6378\n",
      "Epoch 43/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6580 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.6580 - accuracy: 0.6057 - val_loss: 0.6517 - val_accuracy: 0.5931\n",
      "Epoch 44/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6465 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 81ms/step - loss: 0.6465 - accuracy: 0.6220 - val_loss: 0.6312 - val_accuracy: 0.6466\n",
      "Epoch 45/400\n",
      "6/6 [==============================] - 0s 23ms/step- loss: 0.6478 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.6478 - accuracy: 0.6166 - val_loss: 0.6401 - val_accuracy: 0.6175\n",
      "Epoch 46/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6416 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 81ms/step - loss: 0.6416 - accuracy: 0.6313 - val_loss: 0.6426 - val_accuracy: 0.6439\n",
      "Epoch 47/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6488 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.6488 - accuracy: 0.6166 - val_loss: 0.6313 - val_accuracy: 0.6229\n",
      "Epoch 48/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6413 - accuracy: \n",
      "296/296 [==============================] - 26s 88ms/step - loss: 0.6413 - accuracy: 0.6287 - val_loss: 0.6382 - val_accuracy: 0.6547\n",
      "Epoch 49/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6432 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6432 - accuracy: 0.6247 - val_loss: 0.6421 - val_accuracy: 0.6141\n",
      "Epoch 50/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6665 - accuracy: \n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.6665 - accuracy: 0.6000 - val_loss: 0.6998 - val_accuracy: 0.5972\n",
      "Epoch 51/400\n",
      "6/6 [==============================] - 0s 25ms/step- loss: 0.7018 - accuracy: \n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.7018 - accuracy: 0.5236 - val_loss: 0.7135 - val_accuracy: 0.5748\n",
      "Epoch 52/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6996 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.6996 - accuracy: 0.5358 - val_loss: 0.6987 - val_accuracy: 0.5322\n",
      "Epoch 53/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6903 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.6903 - accuracy: 0.5367 - val_loss: 0.6903 - val_accuracy: 0.4902\n",
      "Epoch 54/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6907 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.6907 - accuracy: 0.5299 - val_loss: 0.6841 - val_accuracy: 0.5146\n",
      "Epoch 55/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6780 - accuracy: 0.\n",
      "296/296 [==============================] - 27s 90ms/step - loss: 0.6780 - accuracy: 0.5544 - val_loss: 0.7391 - val_accuracy: 0.4848\n",
      "Epoch 56/400\n",
      "6/6 [==============================] - 0s 26ms/step- loss: 0.6780 - accuracy: \n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.6780 - accuracy: 0.5670 - val_loss: 0.6937 - val_accuracy: 0.5416\n",
      "Epoch 57/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6679 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 88ms/step - loss: 0.6679 - accuracy: 0.5509 - val_loss: 0.6762 - val_accuracy: 0.5376\n",
      "Epoch 58/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6824 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6824 - accuracy: 0.5602 - val_loss: 0.6784 - val_accuracy: 0.5633\n",
      "Epoch 59/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6879 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.6879 - accuracy: 0.5400 - val_loss: 0.7250 - val_accuracy: 0.5159\n",
      "Epoch 60/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6896 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 88ms/step - loss: 0.6896 - accuracy: 0.5365 - val_loss: 0.6958 - val_accuracy: 0.5017\n",
      "Epoch 61/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6876 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6876 - accuracy: 0.5328 - val_loss: 0.6926 - val_accuracy: 0.5518\n",
      "Epoch 62/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.6797 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.6797 - accuracy: 0.5620 - val_loss: 0.6865 - val_accuracy: 0.5802\n",
      "Epoch 63/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6764 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6764 - accuracy: 0.5812 - val_loss: 0.6906 - val_accuracy: 0.5396\n",
      "Epoch 64/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6821 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.6821 - accuracy: 0.5526 - val_loss: 0.6851 - val_accuracy: 0.5504\n",
      "Epoch 65/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6764 - accuracy: \n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6764 - accuracy: 0.5793 - val_loss: 0.6840 - val_accuracy: 0.5430\n",
      "Epoch 66/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.6722 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.6722 - accuracy: 0.5768 - val_loss: 0.7011 - val_accuracy: 0.5457\n",
      "Epoch 67/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6682 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.6682 - accuracy: 0.5803 - val_loss: 0.6740 - val_accuracy: 0.5572\n",
      "Epoch 68/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6598 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.6598 - accuracy: 0.5929 - val_loss: 0.6714 - val_accuracy: 0.5471\n",
      "Epoch 69/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6498 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6498 - accuracy: 0.6135 - val_loss: 0.6527 - val_accuracy: 0.5586\n",
      "Epoch 70/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6424 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.6424 - accuracy: 0.6208 - val_loss: 0.6554 - val_accuracy: 0.6066\n",
      "Epoch 71/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6753 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6753 - accuracy: 0.5849 - val_loss: 0.7118 - val_accuracy: 0.5328\n",
      "Epoch 72/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.6761 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6761 - accuracy: 0.5708 - val_loss: 0.6817 - val_accuracy: 0.5403\n",
      "Epoch 73/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6527 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.6527 - accuracy: 0.6027 - val_loss: 0.6980 - val_accuracy: 0.5958\n",
      "Epoch 74/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6589 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6589 - accuracy: 0.5874 - val_loss: 0.6678 - val_accuracy: 0.5850\n",
      "Epoch 75/400\n",
      "6/6 [==============================] - 0s 27ms/step- loss: 0.6532 - accuracy: \n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.6532 - accuracy: 0.5984 - val_loss: 0.6637 - val_accuracy: 0.5843\n",
      "Epoch 76/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6499 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.6499 - accuracy: 0.5951 - val_loss: 0.6595 - val_accuracy: 0.6026\n",
      "Epoch 77/400\n",
      "6/6 [==============================] - 0s 26ms/step- loss: 0.6455 - accuracy: \n",
      "296/296 [==============================] - 24s 81ms/step - loss: 0.6455 - accuracy: 0.6061 - val_loss: 0.6746 - val_accuracy: 0.5856\n",
      "Epoch 78/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.6411 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 86ms/step - loss: 0.6411 - accuracy: 0.6093 - val_loss: 0.6638 - val_accuracy: 0.5768\n",
      "Epoch 79/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6392 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 83ms/step - loss: 0.6392 - accuracy: 0.6162 - val_loss: 0.6398 - val_accuracy: 0.5897\n",
      "Epoch 80/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6549 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6549 - accuracy: 0.6000 - val_loss: 0.6621 - val_accuracy: 0.6019\n",
      "Epoch 81/400\n",
      "6/6 [==============================] - 0s 27ms/step- loss: 0.6576 - accuracy: \n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6576 - accuracy: 0.5900 - val_loss: 0.6468 - val_accuracy: 0.6513\n",
      "Epoch 82/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6367 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.6367 - accuracy: 0.6118 - val_loss: 0.6507 - val_accuracy: 0.5809\n",
      "Epoch 83/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6389 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.6389 - accuracy: 0.6135 - val_loss: 0.6610 - val_accuracy: 0.6100\n",
      "Epoch 84/400\n",
      "6/6 [==============================] - 0s 26ms/step- loss: 0.6552 - accuracy: \n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.6552 - accuracy: 0.5923 - val_loss: 0.6880 - val_accuracy: 0.5599\n",
      "Epoch 85/400\n",
      "6/6 [==============================] - 0s 27ms/step- loss: 0.6529 - accuracy: \n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6529 - accuracy: 0.5988 - val_loss: 0.6789 - val_accuracy: 0.5653\n",
      "Epoch 86/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6431 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6431 - accuracy: 0.6040 - val_loss: 0.7212 - val_accuracy: 0.6161\n",
      "Epoch 87/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.6516 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 83ms/step - loss: 0.6516 - accuracy: 0.5967 - val_loss: 0.6701 - val_accuracy: 0.6053\n",
      "Epoch 88/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.6735 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6735 - accuracy: 0.5719 - val_loss: 0.7076 - val_accuracy: 0.5606\n",
      "Epoch 89/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6551 - accuracy: \n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6551 - accuracy: 0.5990 - val_loss: 0.6442 - val_accuracy: 0.5924\n",
      "Epoch 90/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6378 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 86ms/step - loss: 0.6378 - accuracy: 0.6123 - val_loss: 0.6945 - val_accuracy: 0.5687\n",
      "Epoch 91/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.6325 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6325 - accuracy: 0.6083 - val_loss: 0.6600 - val_accuracy: 0.6107\n",
      "Epoch 92/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6402 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.6402 - accuracy: 0.6047 - val_loss: 0.6331 - val_accuracy: 0.6060\n",
      "Epoch 93/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.6410 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.6410 - accuracy: 0.6128 - val_loss: 0.6397 - val_accuracy: 0.5863\n",
      "Epoch 94/400\n",
      "6/6 [==============================] - 0s 23ms/step- loss: 0.6224 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.6224 - accuracy: 0.6149 - val_loss: 0.6271 - val_accuracy: 0.5904\n",
      "Epoch 95/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.6131 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.6131 - accuracy: 0.6265 - val_loss: 0.6802 - val_accuracy: 0.6303\n",
      "Epoch 96/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.6202 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.6202 - accuracy: 0.6293 - val_loss: 0.6144 - val_accuracy: 0.6737\n",
      "Epoch 97/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.5982 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.5982 - accuracy: 0.6421 - val_loss: 0.6452 - val_accuracy: 0.6107\n",
      "Epoch 98/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6112 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.6112 - accuracy: 0.6372 - val_loss: 0.6235 - val_accuracy: 0.6547\n",
      "Epoch 99/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.5916 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.5916 - accuracy: 0.6582 - val_loss: 0.5944 - val_accuracy: 0.6452\n",
      "Epoch 100/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.5787 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.5787 - accuracy: 0.6643 - val_loss: 0.6007 - val_accuracy: 0.6689\n",
      "Epoch 101/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.6224 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.6224 - accuracy: 0.6335 - val_loss: 0.6093 - val_accuracy: 0.6520\n",
      "Epoch 102/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.5984 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.5984 - accuracy: 0.6464 - val_loss: 0.6053 - val_accuracy: 0.6141\n",
      "Epoch 103/400\n",
      "6/6 [==============================] - 0s 28ms/step- loss: 0.5694 - accuracy: \n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.5694 - accuracy: 0.6633 - val_loss: 0.5561 - val_accuracy: 0.6838\n",
      "Epoch 104/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.5397 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.5397 - accuracy: 0.7068 - val_loss: 0.5638 - val_accuracy: 0.6716\n",
      "Epoch 105/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.5474 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.5474 - accuracy: 0.6880 - val_loss: 0.5838 - val_accuracy: 0.6493\n",
      "Epoch 106/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.5393 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.5393 - accuracy: 0.6948 - val_loss: 0.6224 - val_accuracy: 0.6425\n",
      "Epoch 107/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.5352 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 86ms/step - loss: 0.5352 - accuracy: 0.7002 - val_loss: 0.5801 - val_accuracy: 0.6730\n",
      "Epoch 108/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.5456 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.5456 - accuracy: 0.6868 - val_loss: 0.5601 - val_accuracy: 0.6574\n",
      "Epoch 109/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.5352 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 88ms/step - loss: 0.5352 - accuracy: 0.6910 - val_loss: 0.5447 - val_accuracy: 0.6886\n",
      "Epoch 110/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.5717 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.5717 - accuracy: 0.6755 - val_loss: 0.5525 - val_accuracy: 0.6676\n",
      "Epoch 111/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.5068 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.5068 - accuracy: 0.7244 - val_loss: 0.5373 - val_accuracy: 0.7244\n",
      "Epoch 112/400\n",
      "6/6 [==============================] - 0s 28ms/step- loss: 0.4740 - accuracy: \n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.4740 - accuracy: 0.7478 - val_loss: 0.5261 - val_accuracy: 0.7102\n",
      "Epoch 113/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.4637 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.4637 - accuracy: 0.7576 - val_loss: 0.4538 - val_accuracy: 0.7583\n",
      "Epoch 114/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.4517 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.4517 - accuracy: 0.7555 - val_loss: 0.4133 - val_accuracy: 0.7657\n",
      "Epoch 115/400\n",
      "6/6 [==============================] - 0s 24ms/step- loss: 0.4974 - accuracy: \n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.4974 - accuracy: 0.7153 - val_loss: 0.5517 - val_accuracy: 0.6290\n",
      "Epoch 116/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.5032 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.5032 - accuracy: 0.7063 - val_loss: 0.4789 - val_accuracy: 0.6913\n",
      "Epoch 117/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.4785 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.4785 - accuracy: 0.7227 - val_loss: 0.5088 - val_accuracy: 0.6798\n",
      "Epoch 118/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.5210 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.5210 - accuracy: 0.6838 - val_loss: 0.5058 - val_accuracy: 0.7224\n",
      "Epoch 119/400\n",
      "6/6 [==============================] - 0s 23ms/step- loss: 0.4949 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.4949 - accuracy: 0.7110 - val_loss: 0.4854 - val_accuracy: 0.7129\n",
      "Epoch 120/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.4366 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.4366 - accuracy: 0.7489 - val_loss: 0.4289 - val_accuracy: 0.7651\n",
      "Epoch 121/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.4516 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 88ms/step - loss: 0.4516 - accuracy: 0.7508 - val_loss: 0.4706 - val_accuracy: 0.7244\n",
      "Epoch 122/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.4275 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 88ms/step - loss: 0.4275 - accuracy: 0.7608 - val_loss: 0.4109 - val_accuracy: 0.8023\n",
      "Epoch 123/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.4240 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.4240 - accuracy: 0.7718 - val_loss: 0.4502 - val_accuracy: 0.7116\n",
      "Epoch 124/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.4517 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.4517 - accuracy: 0.7530 - val_loss: 0.5215 - val_accuracy: 0.6608\n",
      "Epoch 125/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.4128 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.4128 - accuracy: 0.7792 - val_loss: 0.3321 - val_accuracy: 0.8111\n",
      "Epoch 126/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.4074 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.4074 - accuracy: 0.7869 - val_loss: 0.3613 - val_accuracy: 0.7969\n",
      "Epoch 127/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.4145 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.4145 - accuracy: 0.7808 - val_loss: 0.6000 - val_accuracy: 0.6892\n",
      "Epoch 128/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.3733 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.3733 - accuracy: 0.8013 - val_loss: 0.3698 - val_accuracy: 0.8362\n",
      "Epoch 129/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.3743 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.3743 - accuracy: 0.8043 - val_loss: 0.3949 - val_accuracy: 0.7786\n",
      "Epoch 130/400\n",
      "6/6 [==============================] - 0s 23ms/step- loss: 0.3952 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 86ms/step - loss: 0.3952 - accuracy: 0.7977 - val_loss: 0.4016 - val_accuracy: 0.7921\n",
      "Epoch 131/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.3658 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.3658 - accuracy: 0.8101 - val_loss: 0.5580 - val_accuracy: 0.7529\n",
      "Epoch 132/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.3818 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.3818 - accuracy: 0.8077 - val_loss: 0.6235 - val_accuracy: 0.7258\n",
      "Epoch 133/400\n",
      "6/6 [==============================] - 0s 24ms/step- loss: 0.3592 - accuracy: \n",
      "296/296 [==============================] - 26s 88ms/step - loss: 0.3592 - accuracy: 0.8156 - val_loss: 0.5855 - val_accuracy: 0.7549\n",
      "Epoch 134/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.3751 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.3751 - accuracy: 0.8146 - val_loss: 0.4019 - val_accuracy: 0.7901\n",
      "Epoch 135/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.3583 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.3583 - accuracy: 0.8207 - val_loss: 0.5050 - val_accuracy: 0.7251\n",
      "Epoch 136/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.3528 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.3528 - accuracy: 0.8195 - val_loss: 0.4170 - val_accuracy: 0.7745\n",
      "Epoch 137/400\n",
      "6/6 [==============================] - 0s 27ms/step- loss: 0.3617 - accuracy: \n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.3617 - accuracy: 0.8184 - val_loss: 0.2998 - val_accuracy: 0.8348\n",
      "Epoch 138/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.3393 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.3393 - accuracy: 0.8300 - val_loss: 0.4042 - val_accuracy: 0.7773\n",
      "Epoch 139/400\n",
      "6/6 [==============================] - 0s 18ms/step- loss: 0.3364 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.3364 - accuracy: 0.8327 - val_loss: 0.4044 - val_accuracy: 0.8070\n",
      "Epoch 140/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.3658 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.3658 - accuracy: 0.8207 - val_loss: 0.3355 - val_accuracy: 0.8274\n",
      "Epoch 141/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.3432 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 88ms/step - loss: 0.3432 - accuracy: 0.8322 - val_loss: 0.3710 - val_accuracy: 0.8158\n",
      "Epoch 142/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.3528 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 88ms/step - loss: 0.3528 - accuracy: 0.8224 - val_loss: 0.3731 - val_accuracy: 0.8064\n",
      "Epoch 143/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.3229 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.3229 - accuracy: 0.8454 - val_loss: 0.3247 - val_accuracy: 0.8287\n",
      "Epoch 144/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.3544 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.3544 - accuracy: 0.8187 - val_loss: 0.3190 - val_accuracy: 0.8253\n",
      "Epoch 145/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.3409 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.3409 - accuracy: 0.8294 - val_loss: 0.4486 - val_accuracy: 0.7874\n",
      "Epoch 146/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.3069 - accuracy: 0.\n",
      "296/296 [==============================] - 27s 90ms/step - loss: 0.3069 - accuracy: 0.8498 - val_loss: 0.4359 - val_accuracy: 0.8253\n",
      "Epoch 147/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.3315 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.3315 - accuracy: 0.8390 - val_loss: 0.3225 - val_accuracy: 0.8382\n",
      "Epoch 148/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.3422 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 89ms/step - loss: 0.3422 - accuracy: 0.8294 - val_loss: 0.4494 - val_accuracy: 0.7800\n",
      "Epoch 149/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.3226 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.3226 - accuracy: 0.8424 - val_loss: 0.3377 - val_accuracy: 0.8213\n",
      "Epoch 150/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.3182 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.3182 - accuracy: 0.8390 - val_loss: 0.3734 - val_accuracy: 0.7908\n",
      "Epoch 151/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.3499 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.3499 - accuracy: 0.8265 - val_loss: 0.3596 - val_accuracy: 0.7921\n",
      "Epoch 152/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.3397 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.3397 - accuracy: 0.8419 - val_loss: 0.3399 - val_accuracy: 0.8226\n",
      "Epoch 153/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.3097 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.3097 - accuracy: 0.8571 - val_loss: 0.3339 - val_accuracy: 0.8199\n",
      "Epoch 154/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.2913 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.2913 - accuracy: 0.8646 - val_loss: 0.2486 - val_accuracy: 0.8937\n",
      "Epoch 155/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.3925 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.3925 - accuracy: 0.8060 - val_loss: 0.3881 - val_accuracy: 0.7854\n",
      "Epoch 156/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.3394 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 81ms/step - loss: 0.3394 - accuracy: 0.8341 - val_loss: 0.3574 - val_accuracy: 0.8158\n",
      "Epoch 157/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.2968 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.2968 - accuracy: 0.8571 - val_loss: 0.2967 - val_accuracy: 0.8585\n",
      "Epoch 158/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.2870 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.2870 - accuracy: 0.8566 - val_loss: 0.2978 - val_accuracy: 0.8463\n",
      "Epoch 159/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.2918 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.2918 - accuracy: 0.8698 - val_loss: 0.2821 - val_accuracy: 0.8849\n",
      "Epoch 160/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.3003 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.3003 - accuracy: 0.8644 - val_loss: 0.4285 - val_accuracy: 0.7779\n",
      "Epoch 161/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.2935 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.2935 - accuracy: 0.8700 - val_loss: 0.4551 - val_accuracy: 0.7908\n",
      "Epoch 162/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.2824 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.2824 - accuracy: 0.8659 - val_loss: 0.2338 - val_accuracy: 0.9066\n",
      "Epoch 163/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.2732 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.2732 - accuracy: 0.8820 - val_loss: 0.5005 - val_accuracy: 0.7603\n",
      "Epoch 164/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.2604 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.2604 - accuracy: 0.8791 - val_loss: 0.3030 - val_accuracy: 0.8592\n",
      "Epoch 165/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.2965 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.2965 - accuracy: 0.8617 - val_loss: 0.3480 - val_accuracy: 0.8274\n",
      "Epoch 166/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.2732 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.2732 - accuracy: 0.8735 - val_loss: 0.2712 - val_accuracy: 0.8592\n",
      "Epoch 167/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.2684 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.2684 - accuracy: 0.8776 - val_loss: 0.2026 - val_accuracy: 0.9025\n",
      "Epoch 168/400\n",
      "6/6 [==============================] - 0s 23ms/step- loss: 0.2543 - accuracy: \n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.2543 - accuracy: 0.8864 - val_loss: 0.2225 - val_accuracy: 0.9079\n",
      "Epoch 169/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.2389 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.2389 - accuracy: 0.8918 - val_loss: 0.3726 - val_accuracy: 0.8382\n",
      "Epoch 170/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.2413 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 81ms/step - loss: 0.2413 - accuracy: 0.8867 - val_loss: 0.2041 - val_accuracy: 0.9100\n",
      "Epoch 171/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.2328 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.2328 - accuracy: 0.8928 - val_loss: 0.2212 - val_accuracy: 0.9120\n",
      "Epoch 172/400\n",
      "6/6 [==============================] - 0s 25ms/step- loss: 0.2303 - accuracy: \n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.2303 - accuracy: 0.8927 - val_loss: 0.2313 - val_accuracy: 0.8957\n",
      "Epoch 173/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.2311 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.2311 - accuracy: 0.8910 - val_loss: 0.1990 - val_accuracy: 0.9086\n",
      "Epoch 174/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.2222 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 89ms/step - loss: 0.2222 - accuracy: 0.8979 - val_loss: 0.1827 - val_accuracy: 0.9357\n",
      "Epoch 175/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.2160 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.2160 - accuracy: 0.9042 - val_loss: 0.1697 - val_accuracy: 0.9289\n",
      "Epoch 176/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.2721 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.2721 - accuracy: 0.8751 - val_loss: 0.3114 - val_accuracy: 0.8531\n",
      "Epoch 177/400\n",
      "6/6 [==============================] - 0s 17ms/step- loss: 0.2436 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.2436 - accuracy: 0.8873 - val_loss: 0.1850 - val_accuracy: 0.9133\n",
      "Epoch 178/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.2892 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 83ms/step - loss: 0.2892 - accuracy: 0.8756 - val_loss: 0.2921 - val_accuracy: 0.8490\n",
      "Epoch 179/400\n",
      "6/6 [==============================] - 0s 23ms/step- loss: 0.2553 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.2553 - accuracy: 0.8884 - val_loss: 0.1850 - val_accuracy: 0.9242\n",
      "Epoch 180/400\n",
      "6/6 [==============================] - 0s 23ms/step- loss: 0.2157 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.2157 - accuracy: 0.9040 - val_loss: 0.2119 - val_accuracy: 0.9248\n",
      "Epoch 181/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.2357 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.2357 - accuracy: 0.8917 - val_loss: 0.2145 - val_accuracy: 0.9100\n",
      "Epoch 182/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.2418 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.2418 - accuracy: 0.8942 - val_loss: 0.2007 - val_accuracy: 0.9106\n",
      "Epoch 183/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.1989 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.1989 - accuracy: 0.9143 - val_loss: 0.2006 - val_accuracy: 0.9066\n",
      "Epoch 184/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1834 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1834 - accuracy: 0.9228 - val_loss: 0.1659 - val_accuracy: 0.9276\n",
      "Epoch 185/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.2383 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 89ms/step - loss: 0.2383 - accuracy: 0.8996 - val_loss: 0.1848 - val_accuracy: 0.9248\n",
      "Epoch 186/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.2037 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.2037 - accuracy: 0.9088 - val_loss: 0.2169 - val_accuracy: 0.9194\n",
      "Epoch 187/400\n",
      "6/6 [==============================] - 0s 16ms/step- loss: 0.2352 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.2352 - accuracy: 0.8962 - val_loss: 0.3122 - val_accuracy: 0.8646\n",
      "Epoch 188/400\n",
      "6/6 [==============================] - 0s 26ms/step- loss: 0.2073 - accuracy: \n",
      "296/296 [==============================] - 24s 81ms/step - loss: 0.2073 - accuracy: 0.9115 - val_loss: 0.2378 - val_accuracy: 0.8876\n",
      "Epoch 189/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.2501 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.2501 - accuracy: 0.8954 - val_loss: 0.1896 - val_accuracy: 0.9194\n",
      "Epoch 190/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.2020 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.2020 - accuracy: 0.9091 - val_loss: 0.1780 - val_accuracy: 0.8991\n",
      "Epoch 191/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1901 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.1901 - accuracy: 0.9103 - val_loss: 0.2069 - val_accuracy: 0.9174\n",
      "Epoch 192/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.1852 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.1852 - accuracy: 0.9203 - val_loss: 0.1948 - val_accuracy: 0.9133\n",
      "Epoch 193/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.1906 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.1906 - accuracy: 0.9192 - val_loss: 0.2019 - val_accuracy: 0.9296\n",
      "Epoch 194/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.2350 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.2350 - accuracy: 0.8966 - val_loss: 0.3634 - val_accuracy: 0.8267\n",
      "Epoch 195/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.2056 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.2056 - accuracy: 0.9103 - val_loss: 0.2564 - val_accuracy: 0.8741\n",
      "Epoch 196/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.2056 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.2056 - accuracy: 0.9084 - val_loss: 0.1851 - val_accuracy: 0.9208\n",
      "Epoch 197/400\n",
      "6/6 [==============================] - 0s 26ms/step- loss: 0.2249 - accuracy: \n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.2249 - accuracy: 0.9077 - val_loss: 0.2191 - val_accuracy: 0.9147\n",
      "Epoch 198/400\n",
      "6/6 [==============================] - 0s 26ms/step- loss: 0.2091 - accuracy: \n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.2091 - accuracy: 0.9132 - val_loss: 0.1848 - val_accuracy: 0.9248\n",
      "Epoch 199/400\n",
      "6/6 [==============================] - 0s 23ms/step- loss: 0.1849 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.1849 - accuracy: 0.9216 - val_loss: 0.1893 - val_accuracy: 0.9276\n",
      "Epoch 200/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.2111 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.2111 - accuracy: 0.9108 - val_loss: 0.1780 - val_accuracy: 0.9262\n",
      "Epoch 201/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.2521 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.2521 - accuracy: 0.8808 - val_loss: 0.1722 - val_accuracy: 0.9167\n",
      "Epoch 202/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1783 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1783 - accuracy: 0.9196 - val_loss: 0.2169 - val_accuracy: 0.8951\n",
      "Epoch 203/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1570 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1570 - accuracy: 0.9291 - val_loss: 0.1743 - val_accuracy: 0.9147\n",
      "Epoch 204/400\n",
      "6/6 [==============================] - 0s 25ms/step- loss: 0.1969 - accuracy: \n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.1969 - accuracy: 0.9157 - val_loss: 0.1382 - val_accuracy: 0.9411\n",
      "Epoch 205/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.1476 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.1476 - accuracy: 0.9328 - val_loss: 0.3438 - val_accuracy: 0.8910\n",
      "Epoch 206/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.1715 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.1715 - accuracy: 0.9274 - val_loss: 0.1612 - val_accuracy: 0.9269\n",
      "Epoch 207/400\n",
      "6/6 [==============================] - 0s 30ms/step- loss: 0.1808 - accuracy: \n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1808 - accuracy: 0.9231 - val_loss: 0.2484 - val_accuracy: 0.8775\n",
      "Epoch 208/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.1694 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.1694 - accuracy: 0.9238 - val_loss: 0.2846 - val_accuracy: 0.8795\n",
      "Epoch 209/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.2136 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.2136 - accuracy: 0.9028 - val_loss: 0.2078 - val_accuracy: 0.9303\n",
      "Epoch 210/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1849 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1849 - accuracy: 0.9196 - val_loss: 0.2163 - val_accuracy: 0.9235\n",
      "Epoch 211/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1547 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1547 - accuracy: 0.9362 - val_loss: 0.1128 - val_accuracy: 0.9513\n",
      "Epoch 212/400\n",
      "6/6 [==============================] - 0s 23ms/step- loss: 0.1561 - accuracy: \n",
      "296/296 [==============================] - 27s 90ms/step - loss: 0.1561 - accuracy: 0.9355 - val_loss: 0.1314 - val_accuracy: 0.9377\n",
      "Epoch 213/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.1454 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1454 - accuracy: 0.9401 - val_loss: 0.4082 - val_accuracy: 0.8727\n",
      "Epoch 214/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1921 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1921 - accuracy: 0.9296 - val_loss: 0.3245 - val_accuracy: 0.8747\n",
      "Epoch 215/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.2178 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.2178 - accuracy: 0.9155 - val_loss: 0.2690 - val_accuracy: 0.8890\n",
      "Epoch 216/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1646 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 86ms/step - loss: 0.1646 - accuracy: 0.9314 - val_loss: 0.1649 - val_accuracy: 0.9235\n",
      "Epoch 217/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1874 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1874 - accuracy: 0.9211 - val_loss: 0.2449 - val_accuracy: 0.8829\n",
      "Epoch 218/400\n",
      "6/6 [==============================] - 0s 26ms/step- loss: 0.1686 - accuracy: \n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.1686 - accuracy: 0.9299 - val_loss: 0.2652 - val_accuracy: 0.9079\n",
      "Epoch 219/400\n",
      "6/6 [==============================] - 0s 28ms/step- loss: 0.1804 - accuracy: \n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.1804 - accuracy: 0.9211 - val_loss: 0.2061 - val_accuracy: 0.8944\n",
      "Epoch 220/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1796 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.1796 - accuracy: 0.9267 - val_loss: 0.1230 - val_accuracy: 0.9452\n",
      "Epoch 221/400\n",
      "6/6 [==============================] - 0s 25ms/step- loss: 0.1416 - accuracy: \n",
      "296/296 [==============================] - 24s 83ms/step - loss: 0.1416 - accuracy: 0.9397 - val_loss: 0.1981 - val_accuracy: 0.9106\n",
      "Epoch 222/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1330 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1330 - accuracy: 0.9407 - val_loss: 0.0927 - val_accuracy: 0.9580\n",
      "Epoch 223/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.1594 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1594 - accuracy: 0.9353 - val_loss: 0.1361 - val_accuracy: 0.9431\n",
      "Epoch 224/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.1254 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.1254 - accuracy: 0.9479 - val_loss: 0.1054 - val_accuracy: 0.9587\n",
      "Epoch 225/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.1498 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 88ms/step - loss: 0.1498 - accuracy: 0.9399 - val_loss: 0.1731 - val_accuracy: 0.9452\n",
      "Epoch 226/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1278 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.1278 - accuracy: 0.9504 - val_loss: 0.0823 - val_accuracy: 0.9736\n",
      "Epoch 227/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1460 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.1460 - accuracy: 0.9421 - val_loss: 0.1997 - val_accuracy: 0.9032\n",
      "Epoch 228/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1252 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.1252 - accuracy: 0.9457 - val_loss: 0.1111 - val_accuracy: 0.9533\n",
      "Epoch 229/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1403 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.1403 - accuracy: 0.9409 - val_loss: 0.0807 - val_accuracy: 0.9716\n",
      "Epoch 230/400\n",
      "6/6 [==============================] - 0s 23ms/step- loss: 0.1142 - accuracy: \n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.1142 - accuracy: 0.9507 - val_loss: 0.2063 - val_accuracy: 0.9397\n",
      "Epoch 231/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1366 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.1366 - accuracy: 0.9460 - val_loss: 0.1180 - val_accuracy: 0.9370\n",
      "Epoch 232/400\n",
      "6/6 [==============================] - 0s 23ms/step- loss: 0.1274 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1274 - accuracy: 0.9470 - val_loss: 0.1184 - val_accuracy: 0.9485\n",
      "Epoch 233/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1152 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1152 - accuracy: 0.9489 - val_loss: 0.1579 - val_accuracy: 0.9262\n",
      "Epoch 234/400\n",
      "6/6 [==============================] - 0s 23ms/step- loss: 0.1296 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1296 - accuracy: 0.9431 - val_loss: 0.4459 - val_accuracy: 0.8795\n",
      "Epoch 235/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1341 - accuracy: \n",
      "296/296 [==============================] - 26s 86ms/step - loss: 0.1341 - accuracy: 0.9496 - val_loss: 0.0749 - val_accuracy: 0.9770\n",
      "Epoch 236/400\n",
      "6/6 [==============================] - 0s 25ms/step- loss: 0.1341 - accuracy: \n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.1341 - accuracy: 0.9441 - val_loss: 0.1225 - val_accuracy: 0.9418\n",
      "Epoch 237/400\n",
      "6/6 [==============================] - 0s 28ms/step- loss: 0.1338 - accuracy: \n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.1338 - accuracy: 0.9423 - val_loss: 0.1184 - val_accuracy: 0.9553\n",
      "Epoch 238/400\n",
      "6/6 [==============================] - 0s 23ms/step- loss: 0.1354 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 90ms/step - loss: 0.1354 - accuracy: 0.9460 - val_loss: 0.2455 - val_accuracy: 0.9188\n",
      "Epoch 239/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1058 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1058 - accuracy: 0.9540 - val_loss: 0.1029 - val_accuracy: 0.9580\n",
      "Epoch 240/400\n",
      "6/6 [==============================] - 0s 24ms/step- loss: 0.0995 - accuracy: \n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.0995 - accuracy: 0.9595 - val_loss: 0.1027 - val_accuracy: 0.9560\n",
      "Epoch 241/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1081 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1081 - accuracy: 0.9563 - val_loss: 0.0846 - val_accuracy: 0.9668\n",
      "Epoch 242/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.1312 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.1312 - accuracy: 0.9487 - val_loss: 0.1892 - val_accuracy: 0.9242\n",
      "Epoch 243/400\n",
      "6/6 [==============================] - 0s 24ms/step- loss: 0.1218 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.1218 - accuracy: 0.9494 - val_loss: 0.1337 - val_accuracy: 0.9397\n",
      "Epoch 244/400\n",
      "6/6 [==============================] - 0s 17ms/step- loss: 0.1054 - accuracy: 0.\n",
      "296/296 [==============================] - 23s 78ms/step - loss: 0.1054 - accuracy: 0.9568 - val_loss: 0.0978 - val_accuracy: 0.9546\n",
      "Epoch 245/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1043 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 80ms/step - loss: 0.1043 - accuracy: 0.9578 - val_loss: 0.1805 - val_accuracy: 0.9248\n",
      "Epoch 246/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1026 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.1026 - accuracy: 0.9609 - val_loss: 0.1293 - val_accuracy: 0.9404\n",
      "Epoch 247/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1322 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.1322 - accuracy: 0.9524 - val_loss: 0.1410 - val_accuracy: 0.9465\n",
      "Epoch 248/400\n",
      "6/6 [==============================] - 0s 25ms/step- loss: 0.0850 - accuracy: \n",
      "296/296 [==============================] - 27s 90ms/step - loss: 0.0850 - accuracy: 0.9689 - val_loss: 0.0476 - val_accuracy: 0.9770\n",
      "Epoch 249/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0924 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.0924 - accuracy: 0.9658 - val_loss: 0.0610 - val_accuracy: 0.9749\n",
      "Epoch 250/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.1050 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1050 - accuracy: 0.9609 - val_loss: 0.2385 - val_accuracy: 0.9296\n",
      "Epoch 251/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0858 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.0858 - accuracy: 0.9670 - val_loss: 0.0410 - val_accuracy: 0.9892\n",
      "Epoch 252/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.0944 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 86ms/step - loss: 0.0944 - accuracy: 0.9636 - val_loss: 0.0689 - val_accuracy: 0.9736\n",
      "Epoch 253/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.0834 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.0834 - accuracy: 0.9663 - val_loss: 0.0222 - val_accuracy: 0.9926\n",
      "Epoch 254/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.0729 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.0729 - accuracy: 0.9746 - val_loss: 0.0912 - val_accuracy: 0.9634\n",
      "Epoch 255/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0850 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.0850 - accuracy: 0.9694 - val_loss: 0.0549 - val_accuracy: 0.9783\n",
      "Epoch 256/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.1045 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.1045 - accuracy: 0.9604 - val_loss: 0.1392 - val_accuracy: 0.9391\n",
      "Epoch 257/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.0897 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.0897 - accuracy: 0.9648 - val_loss: 0.1025 - val_accuracy: 0.9567\n",
      "Epoch 258/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1113 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.1113 - accuracy: 0.9602 - val_loss: 0.0502 - val_accuracy: 0.9810\n",
      "Epoch 259/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.0899 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.0899 - accuracy: 0.9656 - val_loss: 0.1142 - val_accuracy: 0.9661\n",
      "Epoch 260/400\n",
      "6/6 [==============================] - 0s 23ms/step- loss: 0.1030 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 86ms/step - loss: 0.1030 - accuracy: 0.9602 - val_loss: 0.1316 - val_accuracy: 0.9418\n",
      "Epoch 261/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.1084 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.1084 - accuracy: 0.9607 - val_loss: 0.2233 - val_accuracy: 0.9336\n",
      "Epoch 262/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1553 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.1553 - accuracy: 0.9382 - val_loss: 0.0786 - val_accuracy: 0.9783\n",
      "Epoch 263/400\n",
      "6/6 [==============================] - 0s 25ms/step- loss: 0.0918 - accuracy: \n",
      "296/296 [==============================] - 26s 89ms/step - loss: 0.0918 - accuracy: 0.9660 - val_loss: 0.1223 - val_accuracy: 0.9607\n",
      "Epoch 264/400\n",
      "6/6 [==============================] - 0s 25ms/step- loss: 0.0740 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.0740 - accuracy: 0.9729 - val_loss: 0.2110 - val_accuracy: 0.9147\n",
      "Epoch 265/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.1133 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.1133 - accuracy: 0.9563 - val_loss: 0.1864 - val_accuracy: 0.9350\n",
      "Epoch 266/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0859 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.0859 - accuracy: 0.9680 - val_loss: 0.0342 - val_accuracy: 0.9898\n",
      "Epoch 267/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.0922 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 83ms/step - loss: 0.0922 - accuracy: 0.9690 - val_loss: 0.0765 - val_accuracy: 0.9601\n",
      "Epoch 268/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0725 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.0725 - accuracy: 0.9741 - val_loss: 0.0715 - val_accuracy: 0.9763\n",
      "Epoch 269/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.0822 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.0822 - accuracy: 0.9724 - val_loss: 0.1842 - val_accuracy: 0.9391\n",
      "Epoch 270/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.1065 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1065 - accuracy: 0.9629 - val_loss: 0.2708 - val_accuracy: 0.9147\n",
      "Epoch 271/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0768 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.0768 - accuracy: 0.9768 - val_loss: 0.0429 - val_accuracy: 0.9851\n",
      "Epoch 272/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.0785 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.0785 - accuracy: 0.9744 - val_loss: 0.2134 - val_accuracy: 0.9343\n",
      "Epoch 273/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0906 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 89ms/step - loss: 0.0906 - accuracy: 0.9712 - val_loss: 0.1007 - val_accuracy: 0.9621\n",
      "Epoch 274/400\n",
      "6/6 [==============================] - 0s 23ms/step- loss: 0.1169 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.1169 - accuracy: 0.9592 - val_loss: 0.0782 - val_accuracy: 0.9783\n",
      "Epoch 275/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1447 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.1447 - accuracy: 0.9468 - val_loss: 0.1651 - val_accuracy: 0.9133\n",
      "Epoch 276/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1098 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.1098 - accuracy: 0.9556 - val_loss: 0.1508 - val_accuracy: 0.9316\n",
      "Epoch 277/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1151 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.1151 - accuracy: 0.9568 - val_loss: 0.0366 - val_accuracy: 0.9851\n",
      "Epoch 278/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0617 - accuracy: 0.\n",
      "296/296 [==============================] - 27s 90ms/step - loss: 0.0617 - accuracy: 0.9766 - val_loss: 0.2770 - val_accuracy: 0.9160\n",
      "Epoch 279/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.0906 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.0906 - accuracy: 0.9741 - val_loss: 0.0586 - val_accuracy: 0.9838\n",
      "Epoch 280/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1513 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.1513 - accuracy: 0.9446 - val_loss: 0.1305 - val_accuracy: 0.9506\n",
      "Epoch 281/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1100 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.1100 - accuracy: 0.9590 - val_loss: 0.0586 - val_accuracy: 0.9810\n",
      "Epoch 282/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1757 - accuracy: \n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.1757 - accuracy: 0.9411 - val_loss: 0.4165 - val_accuracy: 0.8260\n",
      "Epoch 283/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.1614 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.1614 - accuracy: 0.9389 - val_loss: 0.6478 - val_accuracy: 0.7678\n",
      "Epoch 284/400\n",
      "6/6 [==============================] - 0s 23ms/step- loss: 0.1399 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.1399 - accuracy: 0.9462 - val_loss: 0.0492 - val_accuracy: 0.9858\n",
      "Epoch 285/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0786 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.0786 - accuracy: 0.9731 - val_loss: 0.0630 - val_accuracy: 0.9729\n",
      "Epoch 286/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1175 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 81ms/step - loss: 0.1175 - accuracy: 0.9562 - val_loss: 0.1221 - val_accuracy: 0.9485\n",
      "Epoch 287/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.1789 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.1789 - accuracy: 0.9260 - val_loss: 0.1239 - val_accuracy: 0.9492\n",
      "Epoch 288/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1631 - accuracy: 0.\n",
      "296/296 [==============================] - 23s 78ms/step - loss: 0.1631 - accuracy: 0.9308 - val_loss: 0.2050 - val_accuracy: 0.8957\n",
      "Epoch 289/400\n",
      "6/6 [==============================] - 0s 24ms/step- loss: 0.1598 - accuracy: \n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.1598 - accuracy: 0.9313 - val_loss: 0.1573 - val_accuracy: 0.9485\n",
      "Epoch 290/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.1800 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.1800 - accuracy: 0.9252 - val_loss: 0.2015 - val_accuracy: 0.9242\n",
      "Epoch 291/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1632 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.1632 - accuracy: 0.9375 - val_loss: 0.6658 - val_accuracy: 0.7915\n",
      "Epoch 292/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.2436 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 81ms/step - loss: 0.2436 - accuracy: 0.9091 - val_loss: 0.1753 - val_accuracy: 0.9404\n",
      "Epoch 293/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.1307 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.1307 - accuracy: 0.9487 - val_loss: 0.1437 - val_accuracy: 0.9404\n",
      "Epoch 294/400\n",
      "6/6 [==============================] - 0s 25ms/step- loss: 0.1262 - accuracy: \n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.1262 - accuracy: 0.9462 - val_loss: 0.1493 - val_accuracy: 0.9248\n",
      "Epoch 295/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1341 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.1341 - accuracy: 0.9528 - val_loss: 0.0994 - val_accuracy: 0.9695\n",
      "Epoch 296/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.1108 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1108 - accuracy: 0.9587 - val_loss: 0.0790 - val_accuracy: 0.9770\n",
      "Epoch 297/400\n",
      "6/6 [==============================] - 0s 28ms/step- loss: 0.1053 - accuracy: \n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.1053 - accuracy: 0.9677 - val_loss: 0.0982 - val_accuracy: 0.9628\n",
      "Epoch 298/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.0899 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.0899 - accuracy: 0.9690 - val_loss: 0.1021 - val_accuracy: 0.9668\n",
      "Epoch 299/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0918 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.0918 - accuracy: 0.9660 - val_loss: 0.3059 - val_accuracy: 0.8747\n",
      "Epoch 300/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1211 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 83ms/step - loss: 0.1211 - accuracy: 0.9533 - val_loss: 0.1781 - val_accuracy: 0.9384\n",
      "Epoch 301/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1443 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 88ms/step - loss: 0.1443 - accuracy: 0.9480 - val_loss: 0.1151 - val_accuracy: 0.9655\n",
      "Epoch 302/400\n",
      "6/6 [==============================] - 0s 30ms/step- loss: 0.1497 - accuracy: \n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.1497 - accuracy: 0.9460 - val_loss: 0.2180 - val_accuracy: 0.9100\n",
      "Epoch 303/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.2021 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.2021 - accuracy: 0.9181 - val_loss: 0.0905 - val_accuracy: 0.9736\n",
      "Epoch 304/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.2146 - accuracy: \n",
      "296/296 [==============================] - 26s 89ms/step - loss: 0.2146 - accuracy: 0.9098 - val_loss: 0.2886 - val_accuracy: 0.8896\n",
      "Epoch 305/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1522 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 88ms/step - loss: 0.1522 - accuracy: 0.9394 - val_loss: 0.1391 - val_accuracy: 0.9418\n",
      "Epoch 306/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1724 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.1724 - accuracy: 0.9331 - val_loss: 0.2073 - val_accuracy: 0.9106\n",
      "Epoch 307/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1167 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.1167 - accuracy: 0.9585 - val_loss: 0.1136 - val_accuracy: 0.9601\n",
      "Epoch 308/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.1608 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.1608 - accuracy: 0.9347 - val_loss: 0.1382 - val_accuracy: 0.9452\n",
      "Epoch 309/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1881 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.1881 - accuracy: 0.9262 - val_loss: 0.1757 - val_accuracy: 0.9201\n",
      "Epoch 310/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1369 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1369 - accuracy: 0.9497 - val_loss: 0.1813 - val_accuracy: 0.9465\n",
      "Epoch 311/400\n",
      "6/6 [==============================] - 0s 18ms/step- loss: 0.1210 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 83ms/step - loss: 0.1210 - accuracy: 0.9563 - val_loss: 0.0726 - val_accuracy: 0.9743\n",
      "Epoch 312/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.1112 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.1112 - accuracy: 0.9587 - val_loss: 0.0452 - val_accuracy: 0.9858\n",
      "Epoch 313/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0684 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.0684 - accuracy: 0.9792 - val_loss: 0.3692 - val_accuracy: 0.8761\n",
      "Epoch 314/400\n",
      "6/6 [==============================] - 0s 27ms/step- loss: 0.1860 - accuracy: \n",
      "296/296 [==============================] - 26s 88ms/step - loss: 0.1860 - accuracy: 0.9282 - val_loss: 0.1480 - val_accuracy: 0.9282\n",
      "Epoch 315/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1268 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 86ms/step - loss: 0.1268 - accuracy: 0.9440 - val_loss: 0.0951 - val_accuracy: 0.9546\n",
      "Epoch 316/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1317 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 89ms/step - loss: 0.1317 - accuracy: 0.9450 - val_loss: 0.1667 - val_accuracy: 0.9201\n",
      "Epoch 317/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.1032 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.1032 - accuracy: 0.9621 - val_loss: 0.1548 - val_accuracy: 0.9513\n",
      "Epoch 318/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.0803 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.0803 - accuracy: 0.9734 - val_loss: 0.1663 - val_accuracy: 0.9350\n",
      "Epoch 319/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.0706 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.0706 - accuracy: 0.9778 - val_loss: 0.0679 - val_accuracy: 0.9797\n",
      "Epoch 320/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.0792 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.0792 - accuracy: 0.9733 - val_loss: 0.0609 - val_accuracy: 0.9804\n",
      "Epoch 321/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0942 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.0942 - accuracy: 0.9656 - val_loss: 0.1310 - val_accuracy: 0.9560\n",
      "Epoch 322/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.1210 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.1210 - accuracy: 0.9639 - val_loss: 0.2107 - val_accuracy: 0.9425\n",
      "Epoch 323/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1014 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.1014 - accuracy: 0.9651 - val_loss: 0.0945 - val_accuracy: 0.9682\n",
      "Epoch 324/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1347 - accuracy: 0.\n",
      "296/296 [==============================] - 28s 95ms/step - loss: 0.1347 - accuracy: 0.9555 - val_loss: 0.1956 - val_accuracy: 0.9357\n",
      "Epoch 325/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.0960 - accuracy: \n",
      "296/296 [==============================] - 26s 89ms/step - loss: 0.0960 - accuracy: 0.9692 - val_loss: 0.0563 - val_accuracy: 0.9865\n",
      "Epoch 326/400\n",
      "6/6 [==============================] - 0s 26ms/step- loss: 0.1538 - accuracy: \n",
      "296/296 [==============================] - 27s 91ms/step - loss: 0.1538 - accuracy: 0.9502 - val_loss: 0.0912 - val_accuracy: 0.9709\n",
      "Epoch 327/400\n",
      "6/6 [==============================] - 0s 25ms/step- loss: 0.0700 - accuracy: \n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.0700 - accuracy: 0.9751 - val_loss: 0.0557 - val_accuracy: 0.9790\n",
      "Epoch 328/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.1464 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 88ms/step - loss: 0.1464 - accuracy: 0.9502 - val_loss: 0.0270 - val_accuracy: 0.9939\n",
      "Epoch 329/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1001 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.1001 - accuracy: 0.9673 - val_loss: 0.0665 - val_accuracy: 0.9804\n",
      "Epoch 330/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0826 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.0826 - accuracy: 0.9726 - val_loss: 0.0263 - val_accuracy: 0.9939\n",
      "Epoch 331/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.0628 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.0628 - accuracy: 0.9809 - val_loss: 0.1017 - val_accuracy: 0.9634\n",
      "Epoch 332/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1570 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.1570 - accuracy: 0.9468 - val_loss: 0.2379 - val_accuracy: 0.9072\n",
      "Epoch 333/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.1468 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.1468 - accuracy: 0.9433 - val_loss: 0.4801 - val_accuracy: 0.8524\n",
      "Epoch 334/400\n",
      "6/6 [==============================] - 0s 24ms/step- loss: 0.1850 - accuracy: \n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1850 - accuracy: 0.9253 - val_loss: 0.0915 - val_accuracy: 0.9601\n",
      "Epoch 335/400\n",
      "6/6 [==============================] - 0s 23ms/step- loss: 0.0887 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.0887 - accuracy: 0.9683 - val_loss: 0.1920 - val_accuracy: 0.9181\n",
      "Epoch 336/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1141 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1141 - accuracy: 0.9555 - val_loss: 0.1287 - val_accuracy: 0.9601\n",
      "Epoch 337/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1057 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.1057 - accuracy: 0.9619 - val_loss: 0.1104 - val_accuracy: 0.9655\n",
      "Epoch 338/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1239 - accuracy: \n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1239 - accuracy: 0.9572 - val_loss: 0.0342 - val_accuracy: 0.9892\n",
      "Epoch 339/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.0981 - accuracy: \n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.0981 - accuracy: 0.9661 - val_loss: 0.0548 - val_accuracy: 0.9804\n",
      "Epoch 340/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.0923 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.0923 - accuracy: 0.9675 - val_loss: 0.1814 - val_accuracy: 0.9336\n",
      "Epoch 341/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.0732 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.0732 - accuracy: 0.9773 - val_loss: 0.1144 - val_accuracy: 0.9587\n",
      "Epoch 342/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0872 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.0872 - accuracy: 0.9656 - val_loss: 0.0473 - val_accuracy: 0.9777\n",
      "Epoch 343/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.0701 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.0701 - accuracy: 0.9739 - val_loss: 0.0861 - val_accuracy: 0.9695\n",
      "Epoch 344/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1076 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.1076 - accuracy: 0.9621 - val_loss: 0.0850 - val_accuracy: 0.9655\n",
      "Epoch 345/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0879 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.0879 - accuracy: 0.9658 - val_loss: 0.0282 - val_accuracy: 0.9926\n",
      "Epoch 346/400\n",
      "6/6 [==============================] - 0s 23ms/step- loss: 0.0792 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.0792 - accuracy: 0.9721 - val_loss: 0.1029 - val_accuracy: 0.9648\n",
      "Epoch 347/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.0971 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.0971 - accuracy: 0.9590 - val_loss: 0.2131 - val_accuracy: 0.9221\n",
      "Epoch 348/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0604 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.0604 - accuracy: 0.9775 - val_loss: 0.0670 - val_accuracy: 0.9770\n",
      "Epoch 349/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.0834 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.0834 - accuracy: 0.9673 - val_loss: 0.0546 - val_accuracy: 0.9810\n",
      "Epoch 350/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0840 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 83ms/step - loss: 0.0840 - accuracy: 0.9682 - val_loss: 0.1729 - val_accuracy: 0.9411\n",
      "Epoch 351/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.0933 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.0933 - accuracy: 0.9655 - val_loss: 0.0731 - val_accuracy: 0.9641\n",
      "Epoch 352/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.0993 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 86ms/step - loss: 0.0993 - accuracy: 0.9643 - val_loss: 0.0364 - val_accuracy: 0.9871\n",
      "Epoch 353/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.0652 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.0652 - accuracy: 0.9773 - val_loss: 0.0895 - val_accuracy: 0.9682\n",
      "Epoch 354/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.0615 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.0615 - accuracy: 0.9775 - val_loss: 0.1736 - val_accuracy: 0.9364\n",
      "Epoch 355/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.0805 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 83ms/step - loss: 0.0805 - accuracy: 0.9717 - val_loss: 0.0249 - val_accuracy: 0.9898\n",
      "Epoch 356/400\n",
      "6/6 [==============================] - 0s 23ms/step- loss: 0.0566 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.0566 - accuracy: 0.9822 - val_loss: 0.0721 - val_accuracy: 0.9668\n",
      "Epoch 357/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.0700 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.0700 - accuracy: 0.9751 - val_loss: 0.0222 - val_accuracy: 0.9912\n",
      "Epoch 358/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0652 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.0652 - accuracy: 0.9790 - val_loss: 0.0213 - val_accuracy: 0.9905\n",
      "Epoch 359/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0548 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 89ms/step - loss: 0.0548 - accuracy: 0.9815 - val_loss: 0.0281 - val_accuracy: 0.9926\n",
      "Epoch 360/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0706 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.0706 - accuracy: 0.9746 - val_loss: 0.0271 - val_accuracy: 0.9912\n",
      "Epoch 361/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.0736 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 81ms/step - loss: 0.0736 - accuracy: 0.9748 - val_loss: 0.0265 - val_accuracy: 0.9865\n",
      "Epoch 362/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.0487 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.0487 - accuracy: 0.9829 - val_loss: 0.0754 - val_accuracy: 0.9709\n",
      "Epoch 363/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.0467 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.0467 - accuracy: 0.9837 - val_loss: 0.0167 - val_accuracy: 0.9932\n",
      "Epoch 364/400\n",
      "6/6 [==============================] - 0s 26ms/step- loss: 0.0541 - accuracy: \n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.0541 - accuracy: 0.9821 - val_loss: 0.0188 - val_accuracy: 0.9919\n",
      "Epoch 365/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.0457 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.0457 - accuracy: 0.9843 - val_loss: 0.0194 - val_accuracy: 0.9912\n",
      "Epoch 366/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0429 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.0429 - accuracy: 0.9849 - val_loss: 0.0281 - val_accuracy: 0.9878\n",
      "Epoch 367/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.0453 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.0453 - accuracy: 0.9853 - val_loss: 0.0226 - val_accuracy: 0.9919\n",
      "Epoch 368/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.0478 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.0478 - accuracy: 0.9836 - val_loss: 0.0683 - val_accuracy: 0.9661\n",
      "Epoch 369/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.1320 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1320 - accuracy: 0.9567 - val_loss: 0.1351 - val_accuracy: 0.9641\n",
      "Epoch 370/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0955 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.0955 - accuracy: 0.9614 - val_loss: 0.0513 - val_accuracy: 0.9831\n",
      "Epoch 371/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0681 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.0681 - accuracy: 0.9758 - val_loss: 0.0956 - val_accuracy: 0.9689\n",
      "Epoch 372/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.0952 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 88ms/step - loss: 0.0952 - accuracy: 0.9660 - val_loss: 0.0588 - val_accuracy: 0.9716\n",
      "Epoch 373/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0669 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.0669 - accuracy: 0.9780 - val_loss: 0.0939 - val_accuracy: 0.9621\n",
      "Epoch 374/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.0490 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.0490 - accuracy: 0.9812 - val_loss: 0.0235 - val_accuracy: 0.9919\n",
      "Epoch 375/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.0948 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.0948 - accuracy: 0.9670 - val_loss: 0.0471 - val_accuracy: 0.9926\n",
      "Epoch 376/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.0645 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.0645 - accuracy: 0.9760 - val_loss: 0.0684 - val_accuracy: 0.9790\n",
      "Epoch 377/400\n",
      "6/6 [==============================] - 0s 25ms/step- loss: 0.1355 - accuracy: \n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.1355 - accuracy: 0.9397 - val_loss: 0.1185 - val_accuracy: 0.9418\n",
      "Epoch 378/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1351 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1351 - accuracy: 0.9397 - val_loss: 0.1836 - val_accuracy: 0.9093\n",
      "Epoch 379/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1229 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.1229 - accuracy: 0.9394 - val_loss: 0.1260 - val_accuracy: 0.9289\n",
      "Epoch 380/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.1123 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1123 - accuracy: 0.9458 - val_loss: 0.1072 - val_accuracy: 0.9397\n",
      "Epoch 381/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.1374 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.1374 - accuracy: 0.9436 - val_loss: 0.1183 - val_accuracy: 0.9397\n",
      "Epoch 382/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0775 - accuracy: \n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.0775 - accuracy: 0.9695 - val_loss: 0.0202 - val_accuracy: 0.9953\n",
      "Epoch 383/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0916 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.0916 - accuracy: 0.9707 - val_loss: 0.1499 - val_accuracy: 0.9560\n",
      "Epoch 384/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.0460 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 83ms/step - loss: 0.0460 - accuracy: 0.9834 - val_loss: 0.0233 - val_accuracy: 0.9905\n",
      "Epoch 385/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.0782 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.0782 - accuracy: 0.9709 - val_loss: 0.0599 - val_accuracy: 0.9810\n",
      "Epoch 386/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.0574 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.0574 - accuracy: 0.9809 - val_loss: 0.0230 - val_accuracy: 0.9932\n",
      "Epoch 387/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.0464 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.0464 - accuracy: 0.9822 - val_loss: 0.0382 - val_accuracy: 0.9865\n",
      "Epoch 388/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.0474 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 83ms/step - loss: 0.0474 - accuracy: 0.9837 - val_loss: 0.0935 - val_accuracy: 0.9824\n",
      "Epoch 389/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.4229 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 88ms/step - loss: 0.4229 - accuracy: 0.8527 - val_loss: 0.6815 - val_accuracy: 0.7481\n",
      "Epoch 390/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.3663 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 83ms/step - loss: 0.3663 - accuracy: 0.8344 - val_loss: 0.3844 - val_accuracy: 0.8328\n",
      "Epoch 391/400\n",
      "6/6 [==============================] - 0s 25ms/step- loss: 0.3043 - accuracy: \n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.3043 - accuracy: 0.8564 - val_loss: 0.2926 - val_accuracy: 0.8612\n",
      "Epoch 392/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.2652 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 86ms/step - loss: 0.2652 - accuracy: 0.8783 - val_loss: 0.2386 - val_accuracy: 0.8781\n",
      "Epoch 393/400\n",
      "6/6 [==============================] - 0s 22ms/step- loss: 0.2118 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 86ms/step - loss: 0.2118 - accuracy: 0.8988 - val_loss: 0.2984 - val_accuracy: 0.8571\n",
      "Epoch 394/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.2113 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 84ms/step - loss: 0.2113 - accuracy: 0.8993 - val_loss: 0.1548 - val_accuracy: 0.9343\n",
      "Epoch 395/400\n",
      "6/6 [==============================] - 0s 19ms/step- loss: 0.1670 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.1670 - accuracy: 0.9281 - val_loss: 0.1259 - val_accuracy: 0.9323\n",
      "Epoch 396/400\n",
      "6/6 [==============================] - 0s 23ms/step- loss: 0.2845 - accuracy: 0.\n",
      "296/296 [==============================] - 25s 85ms/step - loss: 0.2845 - accuracy: 0.8634 - val_loss: 0.3316 - val_accuracy: 0.8158\n",
      "Epoch 397/400\n",
      "6/6 [==============================] - 0s 21ms/step- loss: 0.3345 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 82ms/step - loss: 0.3345 - accuracy: 0.8327 - val_loss: 0.5208 - val_accuracy: 0.7603\n",
      "Epoch 398/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.3258 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.3258 - accuracy: 0.8283 - val_loss: 0.2855 - val_accuracy: 0.8639\n",
      "Epoch 399/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.1865 - accuracy: 0.\n",
      "296/296 [==============================] - 26s 87ms/step - loss: 0.1865 - accuracy: 0.9148 - val_loss: 0.1622 - val_accuracy: 0.9499\n",
      "Epoch 400/400\n",
      "6/6 [==============================] - 0s 20ms/step- loss: 0.1978 - accuracy: 0.\n",
      "296/296 [==============================] - 24s 81ms/step - loss: 0.1978 - accuracy: 0.9214 - val_loss: 0.2168 - val_accuracy: 0.9066\n",
      "Accuracy: 49.43%\n"
     ]
    }
   ],
   "source": [
    "early_stop=tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=500, verbose=2, mode='auto', baseline=None, restore_best_weights=True)\n",
    "model.fit(X_train_Normalizado, y_train_Normalizado, epochs=400, batch_size=20, callbacks=[tensorboard_callback,cm_callback, early_stop], validation_data=(X_val_def, y_val_def))\n",
    "# Final evaluation of the model \n",
    "scores = model.evaluate(X_test_def, y_test_def, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 21ms/step\n",
      "(176, 2)\n",
      "(176,)\n",
      "(176,)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "#y_pred2=np.where(y_pred>0,1,0)\n",
    "#y_pred2=y_pred2[:,-1]\n",
    "y_test_def2=np.argmax(y_test_def,axis=1)\n",
    "#y_test_def2=np.where(y_test_def>0,1,0)\n",
    "print(y_pred.shape)\n",
    "print(y_pred2.shape)\n",
    "print(y_test_def2.shape)\n",
    "#print(y_test_def[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#docs_infra: no_execute\n",
    "classes = [0, 1, 2, 3, 4]\n",
    "classes = [0, 1]\n",
    "cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.5395    0.4316    0.4795        95\n",
      "     class 1     0.4600    0.5679    0.5083        81\n",
      "\n",
      "    accuracy                         0.4943       176\n",
      "   macro avg     0.4997    0.4997    0.4939       176\n",
      "weighted avg     0.5029    0.4943    0.4928       176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test_def2, y_pred2, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('modelos/modelote1203_200')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modelos/modelo_perfecto_LOMOS_P2yP1_GRU2_2_clasesfiltrado_50_dense_onehot_50_loss_categorical_crossentropy_lr_0.001_algoritmo_RMSprop_20240516-194351/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modelos/modelo_perfecto_LOMOS_P2yP1_GRU2_2_clasesfiltrado_50_dense_onehot_50_loss_categorical_crossentropy_lr_0.001_algoritmo_RMSprop_20240516-194351/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('modelos/modelo_perfecto_{}_{}'.format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 21ms/step\n",
      "[0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 1 1\n",
      " 1 1 0 1 1 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 1 1\n",
      " 1 1 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "n = len(y_pred2)\n",
    "reshaped = y_pred2[:n//4*4].reshape(-1, 4)\n",
    "mean_values = reshaped.mean(axis=1)\n",
    "\n",
    "mean_values = np.round(mean_values)\n",
    "mean_values = np.clip(mean_values, 0, 4)\n",
    "mean_values = mean_values.astype(int)\n",
    "print(mean_values)\n",
    "\n",
    "mode_values = stats.mode(reshaped, axis=1)[0]\n",
    "print(mode_values)\n",
    "\n",
    "# Convierte los arrays a DataFrames\n",
    "mean_df = pd.DataFrame(mean_values, columns=['mean'])\n",
    "mode_df = pd.DataFrame(mode_values, columns=['mode'])\n",
    "\n",
    "# Guarda los DataFrames en archivos Excel\n",
    "mean_df.to_excel(\"clasificacion_P1P2_mean_best7.xlsx\", index=False)\n",
    "mode_df.to_excel(\"clasificacion_P1_mode_best7.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1 1 1 0 0 0 1 0 0 1 0 1 0 1 0 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 1 1 1 1 0 0 1 1 0 0 1 0\n",
      " 0 1 1 0 1 1 1 1 1 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 1 1 1 0 1 1 0 0 0 1 0 1 1\n",
      " 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176, 220, 8)\n",
      "(176, 2)\n",
      "[[3.73764140e-01 4.22950163e-01 2.73004947e-02 ... 5.77049837e-01\n",
      "  3.73756468e-01 6.65796904e-01]\n",
      " [3.77897166e-01 4.15326043e-01 2.72960089e-02 ... 5.84673957e-01\n",
      "  3.77887879e-01 6.53769355e-01]\n",
      " [3.71094548e-01 4.10647567e-01 2.73000169e-02 ... 5.89352433e-01\n",
      "  3.71084466e-01 6.51193263e-01]\n",
      " ...\n",
      " [3.34509932e-04 3.16651268e-01 2.62077453e-02 ... 6.83348732e-01\n",
      "  3.34478182e-04 8.46134111e-01]\n",
      " [3.20346260e-04 3.12631829e-01 2.62088742e-02 ... 6.87368171e-01\n",
      "  3.20314636e-04 8.46141503e-01]\n",
      " [3.06488290e-04 3.10423025e-01 2.62093514e-02 ... 6.89576975e-01\n",
      "  3.06457393e-04 8.46151049e-01]]\n"
     ]
    }
   ],
   "source": [
    "filename = \"hdf_lomosP1P2_test_def.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e2  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e2 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    pre_p_e2 =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_test=np.zeros((pre_p_e2.shape[0],220,8))\n",
    "    y_test=np.zeros((pre_p_e2.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if estado == 0 or estado== 1:\n",
    "           target = 1\n",
    "        else:\n",
    "           target = 0\n",
    "        #target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_test[x]=pepito[:,3:11]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_test[x]=target\n",
    "        y_test_to_categorical = to_categorical(y_test)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_test_filtrado = X_test\n",
    "#y_train_filtrado = y_train\n",
    "y_test_filtrado = y_test_to_categorical\n",
    "\n",
    "print(X_test_filtrado.shape)\n",
    "print(y_test_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "# concatenamos train y test\n",
    "#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\n",
    "data_2d_test = X_test_filtrado.reshape(-1, X_test_filtrado.shape[-1])\n",
    "normalized_data_2d_test = scaler.transform(data_2d_test)\n",
    "\n",
    "\n",
    "X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "# la alternativa es normalizar con el total\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "\n",
    "y_test_def=y_test_filtrado # los valores ya estaban normalizados\n",
    "print(X_test_def[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 22ms/step\n",
      "176\n",
      "(44,)\n",
      "(44,)\n",
      "(176,)\n",
      "176\n",
      "(44,)\n",
      "(44,)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "n = len(y_pred2)\n",
    "print(n)\n",
    "reshaped = y_pred2[:n//4*4].reshape(-1, 4)\n",
    "mean_values = reshaped.mean(axis=1)\n",
    "\n",
    "mean_values = np.round(mean_values)\n",
    "mean_values = np.clip(mean_values, 0, 4)\n",
    "mean_values = mean_values.astype(int)\n",
    "print(mean_values.shape)\n",
    "\n",
    "mode_values = stats.mode(reshaped, axis=1)[0]\n",
    "print(mode_values.shape)\n",
    "\n",
    "n = len(y_test_def)\n",
    "y_test_def2=np.argmax(y_test_def,axis=1)\n",
    "print(y_test_def2.shape)\n",
    "print(n)\n",
    "reshaped2 = y_test_def2[:n//4*4].reshape(-1, 4)\n",
    "target_mean_values = reshaped2.mean(axis=1)\n",
    "\n",
    "target_mean_values = np.round(target_mean_values)\n",
    "target_mean_values = np.clip(target_mean_values, 0, 4)\n",
    "target_mean_values = target_mean_values.astype(int)\n",
    "print(target_mean_values.shape)\n",
    "\n",
    "target_mode_values = stats.mode(reshaped2, axis=1)[0]\n",
    "print(target_mode_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#docs_infra: no_execute\n",
    "classes = [0, 1, 2, 3, 4]\n",
    "classes = [0, 1]\n",
    "cm=confusion_matrix(target_mean_values, mean_values,labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59259259 0.29411765]\n"
     ]
    }
   ],
   "source": [
    "print(cm.diagonal()/cm.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.5714    0.5926    0.5818        27\n",
      "     class 1     0.3125    0.2941    0.3030        17\n",
      "\n",
      "    accuracy                         0.4773        44\n",
      "   macro avg     0.4420    0.4434    0.4424        44\n",
      "weighted avg     0.4714    0.4773    0.4741        44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(target_mean_values, mean_values, target_names=target_names, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow_2024_GPU)",
   "language": "python",
   "name": "tensorflow_2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
