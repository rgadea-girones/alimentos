{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 15:35:12.104422: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-27 15:35:12.104482: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-27 15:35:12.106076: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-27 15:35:12.116048: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rgadea/experimentos_software_2024\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM,Bidirectional,GRU\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import datetime\n",
    "import io\n",
    "import itertools\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Obtener la ruta del directorio actual\n",
    "os.chdir('/home/rgadea/experimentos_software_2024')\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "# Construir la ruta relativa al directorio que quieres agregar\n",
    "relative_dir = os.path.join(current_dir, 'mis_pkgs/')\n",
    "\n",
    "# Agregar la ruta relativa al sys.path\n",
    "sys.path.insert(0, relative_dir)\n",
    "\n",
    "from MIOPATIA_db import DB_management as db \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_muestras=401\n",
    "numero_clases=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a quedarme con los 50 atunes P1 para obtener conjunto de training y validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Add, Activation, Concatenate, Conv2D, Dropout \n",
    "from tensorflow.keras.layers import Flatten, Input, GlobalAveragePooling2D, MaxPooling2D\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "__version__ = '0.0.1'\n",
    "\n",
    "\n",
    "def SqueezeNet(input_shape, nb_classes, use_bypass=False, dropout_rate=None, compression=1.0):\n",
    "    \"\"\"\n",
    "    Creating a SqueezeNet of version 1.0\n",
    "    \n",
    "    Arguments:\n",
    "        input_shape  : shape of the input images e.g. (224,224,3)\n",
    "        nb_classes   : number of classes\n",
    "        use_bypass   : if true, bypass connections will be created at fire module 3, 5, 7, and 9 (default: False)\n",
    "        dropout_rate : defines the dropout rate that is accomplished after last fire module (default: None)\n",
    "        compression  : reduce the number of feature-maps (default: 1.0)\n",
    "        \n",
    "    Returns:\n",
    "        Model        : Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(int(96*compression), (7,7), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "    x = create_fire_module(x, int(16*compression), name='fire3', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool4')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(32*compression), name='fire5', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "    x = create_fire_module(x, int(48*compression), name='fire7', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool8')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(64*compression), name='fire9', use_bypass=use_bypass)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        \n",
    "    x = output(x, nb_classes)\n",
    "\n",
    "    return Model(inputs=input_img, outputs=x)\n",
    "\n",
    "\n",
    "def SqueezeNet_11(input_shape, nb_classes, dropout_rate=None, compression=1.0):\n",
    "    \"\"\"\n",
    "    Creating a SqueezeNet of version 1.1\n",
    "    \n",
    "    2.4x less computation over SqueezeNet 1.0 implemented above.\n",
    "    \n",
    "    Arguments:\n",
    "        input_shape  : shape of the input images e.g. (224,224,3)\n",
    "        nb_classes   : number of classes\n",
    "        dropout_rate : defines the dropout rate that is accomplished after last fire module (default: None)\n",
    "        compression  : reduce the number of feature-maps\n",
    "        \n",
    "    Returns:\n",
    "        Model        : Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(int(64*compression), (3,3), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "    x = create_fire_module(x, int(16*compression), name='fire3')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool3')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "    x = create_fire_module(x, int(32*compression), name='fire5')\n",
    "    \n",
    "    #x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool5')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "    x = create_fire_module(x, int(48*compression), name='fire7')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire9')\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # Creating last conv10\n",
    "    x = output(x, nb_classes)\n",
    "\n",
    "    return Model(inputs=input_img, outputs=x)\n",
    "\n",
    "\n",
    "def output(x, nb_classes):\n",
    "    x = Conv2D(nb_classes, (1,1), strides=(1,1), padding='valid', name='conv10')(x)\n",
    "    x = GlobalAveragePooling2D(name='avgpool10')(x)\n",
    "    x = Activation(\"softmax\", name='softmax')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_fire_module(x, nb_squeeze_filter, name, use_bypass=False):\n",
    "    \"\"\"\n",
    "    Creates a fire module\n",
    "    \n",
    "    Arguments:\n",
    "        x                 : input\n",
    "        nb_squeeze_filter : number of filters of squeeze. The filtersize of expand is 4 times of squeeze\n",
    "        use_bypass        : if True then a bypass will be added\n",
    "        name              : name of module e.g. fire123\n",
    "    \n",
    "    Returns:\n",
    "        x                 : returns a fire module\n",
    "    \"\"\"\n",
    "    \n",
    "    nb_expand_filter = 4 * nb_squeeze_filter\n",
    "    squeeze    = Conv2D(nb_squeeze_filter,(1,1), activation='relu', padding='same', name='%s_squeeze'%name)(x)\n",
    "    expand_1x1 = Conv2D(nb_expand_filter, (1,1), activation='relu', padding='same', name='%s_expand_1x1'%name)(squeeze)\n",
    "    expand_3x3 = Conv2D(nb_expand_filter, (3,3), activation='relu', padding='same', name='%s_expand_3x3'%name)(squeeze)\n",
    "    \n",
    "    axis = get_axis()\n",
    "    x_ret = Concatenate(axis=axis, name='%s_concatenate'%name)([expand_1x1, expand_3x3])\n",
    "    \n",
    "    if use_bypass:\n",
    "        x_ret = Add(name='%s_concatenate_bypass'%name)([x_ret, x])\n",
    "        \n",
    "    return x_ret\n",
    "\n",
    "\n",
    "def get_axis():\n",
    "    axis = -1 if K.image_data_format() == 'channels_last' else 1\n",
    "    return axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1749, 2)\n"
     ]
    }
   ],
   "source": [
    "filename = \"COPIA_PANDAS/hdf_lomosAgilent_trainval_filtrado_def_good_ampliado_the_best7.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    # p_e =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_train=np.zeros((pre_p_e1.shape[0],numero_muestras-1,3))\n",
    "    y_train=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1:\n",
    "                target = 0\n",
    "            else:\n",
    "                target = 1\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        #print(pepito[:400,3:6].shape)\n",
    "        X_train[x]=pepito[:400,3:6]\n",
    "        #X_train[x]=X_train[x].reshape(X_train[x].shape[0],-1)\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_train[x]=target\n",
    "        y_train_to_categorical = to_categorical(y_train)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_train_filtrado = X_train\n",
    "#y_train_filtrado = y_train\n",
    "y_train_filtrado = y_train_to_categorical\n",
    "\n",
    "# print(X_train_filtrado.shape)\n",
    "# print(y_train_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "scaler = StandardScaler()\n",
    "data_2d = X_train_filtrado.reshape(-1, X_train_filtrado.shape[-1])\n",
    "normalized_data_2d = scaler.fit_transform(data_2d)\n",
    "#para recurrentes\n",
    "#X_train_Normalizado=normalized_data_2d.reshape(X_train_filtrado.shape) #para recurrentes\n",
    "#para densas\n",
    "X_train_Normalizado=normalized_data_2d.reshape(X_train_filtrado.shape[0],20,20,-1)\n",
    "y_train_Normalizado=y_train_filtrado # los valores ya estaban normalizados\n",
    "print(y_train_Normalizado.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 400, 3)\n",
      "(39, 2)\n",
      "[[[-0.27891126  1.13050149  1.03264984]\n",
      "  [-0.28881369  1.14346961  0.99292245]\n",
      "  [-0.29811964  1.15455963  0.95733861]\n",
      "  ...\n",
      "  [-0.36834858  1.26374737  0.50729965]\n",
      "  [-0.37143897  1.26847744  0.48557723]\n",
      "  [-0.37409913  1.27640586  0.45772158]]\n",
      "\n",
      " [[-0.3766553   1.2820431   0.43480194]\n",
      "  [-0.37882457  1.28831946  0.41082109]\n",
      "  [-0.38075351  1.29032537  0.39484196]\n",
      "  ...\n",
      "  [-0.39728021  1.34270327  0.15883857]\n",
      "  [-0.39759712  1.34351094  0.14928834]\n",
      "  [-0.39835475  1.34705596  0.1370485 ]]\n",
      "\n",
      " [[-0.39820631  1.34701771  0.12869788]\n",
      "  [-0.39930719  1.3506445   0.117314  ]\n",
      "  [-0.39965575  1.35279505  0.10737578]\n",
      "  ...\n",
      "  [-0.40466835  1.38700842 -0.01190621]\n",
      "  [-0.4041513   1.38641947 -0.01624407]\n",
      "  [-0.40590236  1.39093202 -0.02327126]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.65033168 -0.10230045 -0.19126848]\n",
      "  [-0.65121624 -0.13403051 -0.19127155]\n",
      "  [-0.65211728 -0.165582   -0.19127538]\n",
      "  ...\n",
      "  [-0.67040366 -0.68591693 -0.19125205]\n",
      "  [-0.67173875 -0.72277861 -0.19124945]\n",
      "  [-0.67307596 -0.75941173 -0.19124744]]\n",
      "\n",
      " [[-0.67459001 -0.79627129 -0.19124159]\n",
      "  [-0.67596543 -0.82882063 -0.19124397]\n",
      "  [-0.67748064 -0.86512977 -0.19123911]\n",
      "  ...\n",
      "  [-0.70045041 -1.38884094 -0.19118245]\n",
      "  [-0.7017676  -1.41746432 -0.19118939]\n",
      "  [-0.70332365 -1.45930429 -0.19117684]]\n",
      "\n",
      " [[-0.70491085 -1.48969462 -0.19117354]\n",
      "  [-0.70644554 -1.51726645 -0.19117387]\n",
      "  [-0.70802319 -1.55728088 -0.19116112]\n",
      "  ...\n",
      "  [-0.72960655 -2.0091732  -0.19109565]\n",
      "  [-0.73096112 -2.03744594 -0.19108967]\n",
      "  [-0.73227969 -2.06672456 -0.19108349]]]\n"
     ]
    }
   ],
   "source": [
    "filename = \"COPIA_PANDAS/hdf_lomosAgilent_test_filtrado_def_good.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    pre_p_e1 =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_test=np.zeros((pre_p_e1.shape[0],numero_muestras-1,3))\n",
    "    y_test=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1:\n",
    "                target = 0\n",
    "            else:\n",
    "                target = 1\n",
    "\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_test[x]=pepito[:400,3:6]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_test[x]=target\n",
    "        y_test_to_categorical = to_categorical(y_test)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_test_filtrado = X_test\n",
    "#y_train_filtrado = y_train\n",
    "y_test_filtrado = y_test_to_categorical\n",
    "\n",
    "print(X_test_filtrado.shape)\n",
    "print(y_test_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "# concatenamos train y test\n",
    "#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\n",
    "data_2d_test = X_test_filtrado.reshape(-1, X_test_filtrado.shape[-1])\n",
    "normalized_data_2d_test = scaler.transform(data_2d_test)\n",
    "\n",
    "\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape[0],20,20,-1) \n",
    "# la alternativa es normalizar con el total\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "\n",
    "y_test_def=y_test_filtrado # los valores ya estaban normalizados\n",
    "print(X_test_def[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer los conjuntos de entrenamiento validacion y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide el dataset en entrenamiento y temporal (test+validación)\n",
    "# X_temp, X_test_def, y_temp, y_test_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.2, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Divide el dataset temporal en validación y test\n",
    "X_train_def, X_val_def, y_train_def, y_val_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.25, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Ahora, X_train, X_val y X_test contienen los datos de entrada para los conjuntos de entrenamiento, validación y prueba, respectivamente.\n",
    "# y_train, y_val y y_test contienen las clases correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1311, 20, 20, 3)\n",
      "(438, 20, 20, 3)\n",
      "(39, 20, 20, 3)\n",
      "(1311, 2)\n",
      "(438, 2)\n",
      "(39, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_def.shape)\n",
    "print(X_val_def.shape)\n",
    "print(X_test_def.shape)\n",
    "print(y_train_def.shape)\n",
    "print(y_val_def.shape)\n",
    "print(y_test_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "\n",
    "#%tensorboard --logdir logs\n",
    "#log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"\n",
    "    Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\n",
    "    \"\"\"\n",
    "    \n",
    "    buf = io.BytesIO()\n",
    "    \n",
    "    # Use plt.savefig to save the plot to a PNG in memory.\n",
    "    plt.savefig(buf, format='png')\n",
    "    \n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    \n",
    "    # Use tf.image.decode_png to convert the PNG buffer\n",
    "    # to a TF image. Make sure you use 4 channels.\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    \n",
    "    # Use tf.expand_dims to add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "       class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    \n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    # Normalize the confusion matrix.\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    \n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    threshold = 0.5\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"red\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 15:35:16.331759: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2024-05-27 15:35:16.331991: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: nodofpga-2024.novalocal\n",
      "2024-05-27 15:35:16.332040: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: nodofpga-2024.novalocal\n",
      "2024-05-27 15:35:16.332297: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 550.54.15\n",
      "2024-05-27 15:35:16.332516: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 550.54.15\n",
      "2024-05-27 15:35:16.332556: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 550.54.15\n"
     ]
    }
   ],
   "source": [
    "factor_aprendizaje=0.001\n",
    "dimension_LSTM=50\n",
    "dimension_dense1=50\n",
    "dimension_dense2=20\n",
    "algoritmo='rmsprop'\n",
    "supermax=8*4\n",
    "lossfunction='categorical_crossentropy'\n",
    "def create_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    # model.add(Bidirectional(GRU(dimension_LSTM, return_sequences=True, recurrent_regularizer='L2'),input_shape=(401, 8)))\n",
    "    # # model.add(GRU(50, return_sequences=True))\n",
    "    # model.add(GRU(50, return_sequences=False))\n",
    "    # model.add(Dense(dimension_dense1, activation='tanh'))\n",
    "    # model.add(Dense(dimension_dense2, activation='tanh'))\n",
    "    # model.add(Dense(numero_clases, activation='softmax'))\n",
    "    model.add(SqueezeNet_11(input_shape=(20,20, 3), nb_classes=numero_clases, dropout_rate=0.5, compression=1.0))\n",
    "\n",
    "    model.compile(loss=lossfunction, optimizer=algoritmo, metrics=['accuracy'])\n",
    "    model.optimizer.lr=(factor_aprendizaje)\n",
    "    return model\n",
    "\n",
    "model=create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "experimento=\"LOMOS_Agilent_{}_clases_dense1_{}_dense2_{}_loss_{}_lr_{}_algoritmo_{}\".format(numero_clases,dimension_LSTM,dimension_dense1,dimension_dense2,lossfunction,factor_aprendizaje,algoritmo)\n",
    "logdir=\"./logs/defs/{}_{}\".format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if numero_clases==2:\n",
    "    class_names=['Buenos', 'Malos']\n",
    "else:\n",
    "    class_names=['A', 'B+', 'B', 'B-','C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    \n",
    "    # Use the model to predict the values from the test_images.\n",
    "    y_pred = model.predict(X_test_def)\n",
    "    #y_pred1=y_pred[:,-1]\n",
    "    y_pred2=y_pred.argmax(axis=1)\n",
    "    #y_pred2=np.where(y_pred>0,1,0)\n",
    "    #y_pred2=y_pred2[:,-1]\n",
    "    if numero_clases==2:\n",
    "        classes = [0, 1]    \n",
    "    else:\n",
    "\n",
    "        classes = [0, 1, 2, 3, 4] \n",
    "    #classes = [0, 1]\n",
    "    y_test_def2=np.argmax(y_test_def,axis=1)  \n",
    "    #y_test_def2=np.where(y_test_def>0,1,0)\n",
    "    cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    figura = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figura)\n",
    "    \n",
    "    # Log the confusion matrix as an image summary.\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1749, 2)\n",
      "(438, 2)\n"
     ]
    }
   ],
   "source": [
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "print(y_train_Normalizado.shape)\n",
    "print(y_val_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un callback para guardar los mejores pesos\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('best_weights.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.6932 - accuracy: 0.50\n",
      "14/14 [==============================] - 4s 163ms/step - loss: 0.6934 - accuracy: 0.5019 - val_loss: 0.6931 - val_accuracy: 0.5091\n",
      "Epoch 2/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.6932 - accuracy: 0.49\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6930 - val_accuracy: 0.5091\n",
      "Epoch 3/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.6934 - accuracy: 0.49\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.6933 - accuracy: 0.4981 - val_loss: 0.6931 - val_accuracy: 0.5091\n",
      "Epoch 4/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.6935 - accuracy: 0.50\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.6934 - accuracy: 0.5095 - val_loss: 0.6934 - val_accuracy: 0.5091\n",
      "Epoch 5/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.6939 - accuracy: 0.50\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.6934 - accuracy: 0.5095 - val_loss: 0.6939 - val_accuracy: 0.5091\n",
      "Epoch 6/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.6941 - accuracy: 0.50\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.6939 - accuracy: 0.5095 - val_loss: 0.6940 - val_accuracy: 0.5091\n",
      "Epoch 7/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.6935 - accuracy: 0.50\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.6933 - accuracy: 0.5095 - val_loss: 0.6920 - val_accuracy: 0.5091\n",
      "Epoch 8/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.6841 - accuracy: 0.51\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.6802 - accuracy: 0.5217 - val_loss: 0.8283 - val_accuracy: 0.5091\n",
      "Epoch 9/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.6777 - accuracy: 0.56\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.6751 - accuracy: 0.5706 - val_loss: 0.7488 - val_accuracy: 0.5913\n",
      "Epoch 10/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.6621 - accuracy: 0.61\n",
      "14/14 [==============================] - 1s 92ms/step - loss: 0.6617 - accuracy: 0.6117 - val_loss: 0.6891 - val_accuracy: 0.5936\n",
      "Epoch 11/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.6426 - accuracy: 0.62\n",
      "14/14 [==============================] - 1s 92ms/step - loss: 0.6422 - accuracy: 0.6247 - val_loss: 0.7307 - val_accuracy: 0.5662\n",
      "Epoch 12/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.6461 - accuracy: 0.60\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.6458 - accuracy: 0.6064 - val_loss: 0.6631 - val_accuracy: 0.5594\n",
      "Epoch 13/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.6457 - accuracy: 0.61\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.6457 - accuracy: 0.6133 - val_loss: 0.6598 - val_accuracy: 0.5799\n",
      "Epoch 14/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.6154 - accuracy: 0.63\n",
      "14/14 [==============================] - 1s 111ms/step - loss: 0.6145 - accuracy: 0.6331 - val_loss: 0.7223 - val_accuracy: 0.5799\n",
      "Epoch 15/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.6245 - accuracy: 0.61\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 0.6245 - accuracy: 0.6178 - val_loss: 0.6454 - val_accuracy: 0.5890\n",
      "Epoch 16/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.6498 - accuracy: 0.60\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.6487 - accuracy: 0.6079 - val_loss: 0.6719 - val_accuracy: 0.5982\n",
      "Epoch 17/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.6064 - accuracy: 0.64\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.6105 - accuracy: 0.6362 - val_loss: 0.6440 - val_accuracy: 0.5799\n",
      "Epoch 18/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5992 - accuracy: 0.63\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 0.5978 - accuracy: 0.6369 - val_loss: 0.8749 - val_accuracy: 0.5685\n",
      "Epoch 19/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.6275 - accuracy: 0.61\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.6271 - accuracy: 0.6194 - val_loss: 0.6663 - val_accuracy: 0.6005\n",
      "Epoch 20/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.6055 - accuracy: 0.63\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.6058 - accuracy: 0.6384 - val_loss: 0.8224 - val_accuracy: 0.5571\n",
      "Epoch 21/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.6047 - accuracy: 0.64\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.6037 - accuracy: 0.6438 - val_loss: 0.6757 - val_accuracy: 0.5479\n",
      "Epoch 22/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.6040 - accuracy: 0.63\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.6032 - accuracy: 0.6392 - val_loss: 0.6688 - val_accuracy: 0.5845\n",
      "Epoch 23/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5876 - accuracy: 0.65\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.5841 - accuracy: 0.6583 - val_loss: 0.6111 - val_accuracy: 0.6005\n",
      "Epoch 24/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.5958 - accuracy: 0.65\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.5968 - accuracy: 0.6468 - val_loss: 0.6101 - val_accuracy: 0.6005\n",
      "Epoch 25/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5830 - accuracy: 0.64\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.5894 - accuracy: 0.6415 - val_loss: 0.6534 - val_accuracy: 0.5525\n",
      "Epoch 26/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.5825 - accuracy: 0.64\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.5826 - accuracy: 0.6476 - val_loss: 0.8691 - val_accuracy: 0.5685\n",
      "Epoch 27/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.5948 - accuracy: 0.64\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.5949 - accuracy: 0.6484 - val_loss: 0.6066 - val_accuracy: 0.6256\n",
      "Epoch 28/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.5821 - accuracy: 0.65\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.5820 - accuracy: 0.6598 - val_loss: 0.6470 - val_accuracy: 0.6005\n",
      "Epoch 29/600\n",
      "2/2 [==============================] - 0s 8ms/step loss: 0.5855 - accuracy: 0.64\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.5863 - accuracy: 0.6476 - val_loss: 0.6021 - val_accuracy: 0.6256\n",
      "Epoch 30/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5724 - accuracy: 0.65\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.5726 - accuracy: 0.6552 - val_loss: 0.5917 - val_accuracy: 0.6256\n",
      "Epoch 31/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5704 - accuracy: 0.65\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.5697 - accuracy: 0.6575 - val_loss: 0.6142 - val_accuracy: 0.5982\n",
      "Epoch 32/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5772 - accuracy: 0.65\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.5769 - accuracy: 0.6598 - val_loss: 0.5933 - val_accuracy: 0.6142\n",
      "Epoch 33/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5568 - accuracy: 0.66\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.5568 - accuracy: 0.6674 - val_loss: 0.5924 - val_accuracy: 0.6256\n",
      "Epoch 34/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5756 - accuracy: 0.65\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.5818 - accuracy: 0.6552 - val_loss: 0.6485 - val_accuracy: 0.5845\n",
      "Epoch 35/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.5700 - accuracy: 0.66\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.5688 - accuracy: 0.6674 - val_loss: 0.6084 - val_accuracy: 0.6164\n",
      "Epoch 36/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.5500 - accuracy: 0.67\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.5504 - accuracy: 0.6789 - val_loss: 0.6291 - val_accuracy: 0.6233\n",
      "Epoch 37/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5575 - accuracy: 0.66\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.5615 - accuracy: 0.6674 - val_loss: 0.5897 - val_accuracy: 0.6347\n",
      "Epoch 38/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5554 - accuracy: 0.66\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.5555 - accuracy: 0.6690 - val_loss: 0.5906 - val_accuracy: 0.6279\n",
      "Epoch 39/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.6200 - accuracy: 0.65\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.6200 - accuracy: 0.6575 - val_loss: 0.6011 - val_accuracy: 0.6301\n",
      "Epoch 40/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5580 - accuracy: 0.66\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.5580 - accuracy: 0.6697 - val_loss: 0.5950 - val_accuracy: 0.6301\n",
      "Epoch 41/600\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.5571 - accuracy: 0.67\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.5574 - accuracy: 0.6697 - val_loss: 0.6796 - val_accuracy: 0.5479\n",
      "Epoch 42/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5949 - accuracy: 0.63\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.5961 - accuracy: 0.6308 - val_loss: 0.6017 - val_accuracy: 0.6005\n",
      "Epoch 43/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5987 - accuracy: 0.62\n",
      "14/14 [==============================] - 2s 117ms/step - loss: 0.5967 - accuracy: 0.6247 - val_loss: 0.6313 - val_accuracy: 0.5822\n",
      "Epoch 44/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.5682 - accuracy: 0.66\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.5693 - accuracy: 0.6606 - val_loss: 0.5909 - val_accuracy: 0.6279\n",
      "Epoch 45/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5505 - accuracy: 0.67\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.5525 - accuracy: 0.6712 - val_loss: 0.8449 - val_accuracy: 0.6187\n",
      "Epoch 46/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.5849 - accuracy: 0.66\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.5850 - accuracy: 0.6636 - val_loss: 0.6260 - val_accuracy: 0.6005\n",
      "Epoch 47/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5615 - accuracy: 0.66\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.5579 - accuracy: 0.6690 - val_loss: 0.5905 - val_accuracy: 0.6279\n",
      "Epoch 48/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.6152 - accuracy: 0.65\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 0.6142 - accuracy: 0.6529 - val_loss: 0.5937 - val_accuracy: 0.6279\n",
      "Epoch 49/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.5533 - accuracy: 0.67\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.5533 - accuracy: 0.6720 - val_loss: 0.7457 - val_accuracy: 0.5822\n",
      "Epoch 50/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5677 - accuracy: 0.66\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.5669 - accuracy: 0.6712 - val_loss: 0.5839 - val_accuracy: 0.6461\n",
      "Epoch 51/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.5635 - accuracy: 0.67\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.5632 - accuracy: 0.6720 - val_loss: 0.5973 - val_accuracy: 0.6279\n",
      "Epoch 52/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5594 - accuracy: 0.67\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.5584 - accuracy: 0.6766 - val_loss: 0.6088 - val_accuracy: 0.6233\n",
      "Epoch 53/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5843 - accuracy: 0.67\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.5832 - accuracy: 0.6712 - val_loss: 0.6211 - val_accuracy: 0.6050\n",
      "Epoch 54/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.5453 - accuracy: 0.68\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.5458 - accuracy: 0.6827 - val_loss: 0.5695 - val_accuracy: 0.6621\n",
      "Epoch 55/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.5351 - accuracy: 0.71\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.5343 - accuracy: 0.7147 - val_loss: 0.5377 - val_accuracy: 0.6872\n",
      "Epoch 56/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.5013 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 0.5022 - accuracy: 0.7285 - val_loss: 0.5381 - val_accuracy: 0.6872\n",
      "Epoch 57/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5089 - accuracy: 0.71\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 0.5099 - accuracy: 0.7178 - val_loss: 0.5355 - val_accuracy: 0.6895\n",
      "Epoch 58/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5513 - accuracy: 0.71\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.5507 - accuracy: 0.7132 - val_loss: 0.5373 - val_accuracy: 0.6895\n",
      "Epoch 59/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.5022 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.5005 - accuracy: 0.7262 - val_loss: 0.5376 - val_accuracy: 0.6895\n",
      "Epoch 60/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.5005 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.5003 - accuracy: 0.7262 - val_loss: 0.5388 - val_accuracy: 0.6895\n",
      "Epoch 61/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5222 - accuracy: 0.71\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.5198 - accuracy: 0.7178 - val_loss: 0.5391 - val_accuracy: 0.6849\n",
      "Epoch 62/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.5079 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.5085 - accuracy: 0.7216 - val_loss: 0.5359 - val_accuracy: 0.6895\n",
      "Epoch 63/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.5000 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.4997 - accuracy: 0.7262 - val_loss: 0.5366 - val_accuracy: 0.6895\n",
      "Epoch 64/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.5015 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.4983 - accuracy: 0.7262 - val_loss: 0.5377 - val_accuracy: 0.6895\n",
      "Epoch 65/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5051 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.5001 - accuracy: 0.7262 - val_loss: 0.5362 - val_accuracy: 0.6895\n",
      "Epoch 66/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.5985 - accuracy: 0.71\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.5985 - accuracy: 0.7147 - val_loss: 0.5976 - val_accuracy: 0.6393\n",
      "Epoch 67/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.5006 - accuracy: 0.73\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.4992 - accuracy: 0.7338 - val_loss: 0.5352 - val_accuracy: 0.7078\n",
      "Epoch 68/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4919 - accuracy: 0.73\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 0.4919 - accuracy: 0.7391 - val_loss: 0.5196 - val_accuracy: 0.7100\n",
      "Epoch 69/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4814 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.4826 - accuracy: 0.7445 - val_loss: 0.5175 - val_accuracy: 0.7100\n",
      "Epoch 70/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5139 - accuracy: 0.71\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.5134 - accuracy: 0.7185 - val_loss: 0.5382 - val_accuracy: 0.6895\n",
      "Epoch 71/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5133 - accuracy: 0.71\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.5119 - accuracy: 0.7140 - val_loss: 0.5368 - val_accuracy: 0.6895\n",
      "Epoch 72/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5087 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.5083 - accuracy: 0.7223 - val_loss: 0.5161 - val_accuracy: 0.7100\n",
      "Epoch 73/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4970 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.4971 - accuracy: 0.7285 - val_loss: 0.5373 - val_accuracy: 0.6895\n",
      "Epoch 74/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.5024 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.4995 - accuracy: 0.7262 - val_loss: 0.5391 - val_accuracy: 0.6895\n",
      "Epoch 75/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.5017 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.5011 - accuracy: 0.7262 - val_loss: 0.5370 - val_accuracy: 0.6895\n",
      "Epoch 76/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4992 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 0.4990 - accuracy: 0.7262 - val_loss: 0.5364 - val_accuracy: 0.6895\n",
      "Epoch 77/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4986 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.4986 - accuracy: 0.7262 - val_loss: 0.5372 - val_accuracy: 0.6895\n",
      "Epoch 78/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4985 - accuracy: 0.72\n",
      "14/14 [==============================] - 2s 125ms/step - loss: 0.4996 - accuracy: 0.7262 - val_loss: 0.5363 - val_accuracy: 0.6895\n",
      "Epoch 79/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4972 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.4982 - accuracy: 0.7262 - val_loss: 0.5365 - val_accuracy: 0.6895\n",
      "Epoch 80/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.5386 - accuracy: 0.69\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.5359 - accuracy: 0.7010 - val_loss: 0.5265 - val_accuracy: 0.7055\n",
      "Epoch 81/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4861 - accuracy: 0.73\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.4863 - accuracy: 0.7384 - val_loss: 0.5163 - val_accuracy: 0.7100\n",
      "Epoch 82/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4845 - accuracy: 0.73\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.4792 - accuracy: 0.7445 - val_loss: 0.5167 - val_accuracy: 0.7100\n",
      "Epoch 83/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4868 - accuracy: 0.73\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 0.4814 - accuracy: 0.7445 - val_loss: 0.5160 - val_accuracy: 0.7100\n",
      "Epoch 84/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4813 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.4808 - accuracy: 0.7445 - val_loss: 0.5233 - val_accuracy: 0.6963\n",
      "Epoch 85/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5913 - accuracy: 0.71\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.5905 - accuracy: 0.7162 - val_loss: 0.5362 - val_accuracy: 0.6895\n",
      "Epoch 86/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4996 - accuracy: 0.73\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.4994 - accuracy: 0.7376 - val_loss: 0.5165 - val_accuracy: 0.7100\n",
      "Epoch 87/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4978 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.4980 - accuracy: 0.7407 - val_loss: 0.5167 - val_accuracy: 0.7100\n",
      "Epoch 88/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4782 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 0.4827 - accuracy: 0.7422 - val_loss: 0.5362 - val_accuracy: 0.6895\n",
      "Epoch 89/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4827 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.4843 - accuracy: 0.7399 - val_loss: 0.5153 - val_accuracy: 0.7100\n",
      "Epoch 90/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.4780 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.4908 - accuracy: 0.7437 - val_loss: 0.5189 - val_accuracy: 0.7100\n",
      "Epoch 91/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4917 - accuracy: 0.73\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.4888 - accuracy: 0.7422 - val_loss: 0.5172 - val_accuracy: 0.7100\n",
      "Epoch 92/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4808 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.4808 - accuracy: 0.7445 - val_loss: 0.5173 - val_accuracy: 0.7100\n",
      "Epoch 93/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.4823 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.4870 - accuracy: 0.7437 - val_loss: 0.5447 - val_accuracy: 0.6895\n",
      "Epoch 94/600\n",
      "2/2 [==============================] - 0s 8ms/step loss: 0.4918 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.4902 - accuracy: 0.7452 - val_loss: 0.5183 - val_accuracy: 0.7100\n",
      "Epoch 95/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4788 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.4793 - accuracy: 0.7445 - val_loss: 0.5159 - val_accuracy: 0.7100\n",
      "Epoch 96/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4822 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 103ms/step - loss: 0.4812 - accuracy: 0.7437 - val_loss: 0.5173 - val_accuracy: 0.7100\n",
      "Epoch 97/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4809 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.4815 - accuracy: 0.7445 - val_loss: 0.5160 - val_accuracy: 0.7100\n",
      "Epoch 98/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5181 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.5167 - accuracy: 0.7254 - val_loss: 0.5505 - val_accuracy: 0.6895\n",
      "Epoch 99/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4721 - accuracy: 0.75\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.4756 - accuracy: 0.7513 - val_loss: 0.5016 - val_accuracy: 0.7283\n",
      "Epoch 100/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4785 - accuracy: 0.75\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 0.4841 - accuracy: 0.7452 - val_loss: 0.5163 - val_accuracy: 0.7100\n",
      "Epoch 101/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4801 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.4805 - accuracy: 0.7445 - val_loss: 0.5162 - val_accuracy: 0.7100\n",
      "Epoch 102/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.5036 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.5140 - accuracy: 0.7231 - val_loss: 0.5686 - val_accuracy: 0.6667\n",
      "Epoch 103/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5041 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 0.5034 - accuracy: 0.7300 - val_loss: 0.5104 - val_accuracy: 0.7283\n",
      "Epoch 104/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4747 - accuracy: 0.75\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 0.4726 - accuracy: 0.7597 - val_loss: 0.5125 - val_accuracy: 0.7078\n",
      "Epoch 105/600\n",
      "2/2 [==============================] - 0s 9ms/step loss: 0.4760 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.4756 - accuracy: 0.7483 - val_loss: 0.5191 - val_accuracy: 0.7100\n",
      "Epoch 106/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4798 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.4805 - accuracy: 0.7445 - val_loss: 0.5178 - val_accuracy: 0.7078\n",
      "Epoch 107/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.5031 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.5031 - accuracy: 0.7277 - val_loss: 0.5367 - val_accuracy: 0.6895\n",
      "Epoch 108/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5115 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 0.5076 - accuracy: 0.7300 - val_loss: 0.5173 - val_accuracy: 0.7100\n",
      "Epoch 109/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4787 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.4798 - accuracy: 0.7445 - val_loss: 0.5174 - val_accuracy: 0.7100\n",
      "Epoch 110/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4859 - accuracy: 0.73\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.4858 - accuracy: 0.7384 - val_loss: 0.6485 - val_accuracy: 0.5913\n",
      "Epoch 111/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.5535 - accuracy: 0.67\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.5537 - accuracy: 0.6751 - val_loss: 0.5153 - val_accuracy: 0.7100\n",
      "Epoch 112/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4800 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.4808 - accuracy: 0.7445 - val_loss: 0.5154 - val_accuracy: 0.7100\n",
      "Epoch 113/600\n",
      "2/2 [==============================] - 0s 8ms/step loss: 0.4801 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.4800 - accuracy: 0.7445 - val_loss: 0.5158 - val_accuracy: 0.7100\n",
      "Epoch 114/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4808 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 103ms/step - loss: 0.4808 - accuracy: 0.7445 - val_loss: 0.5153 - val_accuracy: 0.7100\n",
      "Epoch 115/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4791 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.4806 - accuracy: 0.7445 - val_loss: 0.5155 - val_accuracy: 0.7100\n",
      "Epoch 116/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4793 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.4800 - accuracy: 0.7445 - val_loss: 0.5154 - val_accuracy: 0.7100\n",
      "Epoch 117/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.4808 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.4799 - accuracy: 0.7445 - val_loss: 0.5167 - val_accuracy: 0.7100\n",
      "Epoch 118/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4804 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.4798 - accuracy: 0.7445 - val_loss: 0.5160 - val_accuracy: 0.7100\n",
      "Epoch 119/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4799 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 0.4795 - accuracy: 0.7445 - val_loss: 0.5167 - val_accuracy: 0.7100\n",
      "Epoch 120/600\n",
      "2/2 [==============================] - 0s 8ms/step loss: 0.4809 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.4792 - accuracy: 0.7445 - val_loss: 0.5179 - val_accuracy: 0.7100\n",
      "Epoch 121/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5083 - accuracy: 0.72\n",
      "14/14 [==============================] - 2s 128ms/step - loss: 0.5086 - accuracy: 0.7201 - val_loss: 0.5616 - val_accuracy: 0.6758\n",
      "Epoch 122/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5182 - accuracy: 0.73\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.5166 - accuracy: 0.7315 - val_loss: 0.5164 - val_accuracy: 0.7100\n",
      "Epoch 123/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4776 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 109ms/step - loss: 0.4788 - accuracy: 0.7445 - val_loss: 0.5155 - val_accuracy: 0.7100\n",
      "Epoch 124/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4803 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.4800 - accuracy: 0.7445 - val_loss: 0.5163 - val_accuracy: 0.7100\n",
      "Epoch 125/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.5117 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.5117 - accuracy: 0.7239 - val_loss: 0.5504 - val_accuracy: 0.6758\n",
      "Epoch 126/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4882 - accuracy: 0.73\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.4900 - accuracy: 0.7338 - val_loss: 0.5158 - val_accuracy: 0.7100\n",
      "Epoch 127/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4769 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.4802 - accuracy: 0.7445 - val_loss: 0.5152 - val_accuracy: 0.7100\n",
      "Epoch 128/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4797 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.4803 - accuracy: 0.7445 - val_loss: 0.5158 - val_accuracy: 0.7100\n",
      "Epoch 129/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.4818 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.4817 - accuracy: 0.7445 - val_loss: 0.5166 - val_accuracy: 0.7100\n",
      "Epoch 130/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4793 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.4808 - accuracy: 0.7445 - val_loss: 0.5159 - val_accuracy: 0.7100\n",
      "Epoch 131/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4806 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.4798 - accuracy: 0.7445 - val_loss: 0.5167 - val_accuracy: 0.7100\n",
      "Epoch 132/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4959 - accuracy: 0.73\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.4959 - accuracy: 0.7300 - val_loss: 0.5365 - val_accuracy: 0.6895\n",
      "Epoch 133/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5292 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.5293 - accuracy: 0.7193 - val_loss: 0.5162 - val_accuracy: 0.7100\n",
      "Epoch 134/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4804 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.4807 - accuracy: 0.7445 - val_loss: 0.5158 - val_accuracy: 0.7100\n",
      "Epoch 135/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4793 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.4804 - accuracy: 0.7445 - val_loss: 0.5158 - val_accuracy: 0.7100\n",
      "Epoch 136/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4828 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.4811 - accuracy: 0.7445 - val_loss: 0.5176 - val_accuracy: 0.7100\n",
      "Epoch 137/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4807 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.4813 - accuracy: 0.7445 - val_loss: 0.5163 - val_accuracy: 0.7100\n",
      "Epoch 138/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.4863 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.4862 - accuracy: 0.7407 - val_loss: 0.5451 - val_accuracy: 0.7078\n",
      "Epoch 139/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.4808 - accuracy: 0.76\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.4819 - accuracy: 0.7544 - val_loss: 0.5206 - val_accuracy: 0.7078\n",
      "Epoch 140/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4900 - accuracy: 0.73\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.4904 - accuracy: 0.7368 - val_loss: 0.5157 - val_accuracy: 0.7100\n",
      "Epoch 141/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4758 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.4758 - accuracy: 0.7490 - val_loss: 0.5328 - val_accuracy: 0.6941\n",
      "Epoch 142/600\n",
      "2/2 [==============================] - 0s 8ms/step loss: 0.4853 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.4834 - accuracy: 0.7429 - val_loss: 0.5159 - val_accuracy: 0.7100\n",
      "Epoch 143/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4798 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.4795 - accuracy: 0.7445 - val_loss: 0.5173 - val_accuracy: 0.7100\n",
      "Epoch 144/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4806 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 0.4808 - accuracy: 0.7445 - val_loss: 0.5170 - val_accuracy: 0.7100\n",
      "Epoch 145/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4819 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.4818 - accuracy: 0.7452 - val_loss: 0.5176 - val_accuracy: 0.7100\n",
      "Epoch 146/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.5271 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.5270 - accuracy: 0.7452 - val_loss: 0.5191 - val_accuracy: 0.7100\n",
      "Epoch 147/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4674 - accuracy: 0.76\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.4689 - accuracy: 0.7605 - val_loss: 0.5178 - val_accuracy: 0.7100\n",
      "Epoch 148/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4809 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.4808 - accuracy: 0.7445 - val_loss: 0.5169 - val_accuracy: 0.7100\n",
      "Epoch 149/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4809 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.4807 - accuracy: 0.7445 - val_loss: 0.5160 - val_accuracy: 0.7100\n",
      "Epoch 150/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4805 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.4800 - accuracy: 0.7445 - val_loss: 0.5166 - val_accuracy: 0.7100\n",
      "Epoch 151/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4783 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.4790 - accuracy: 0.7445 - val_loss: 0.5158 - val_accuracy: 0.7100\n",
      "Epoch 152/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4800 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.4845 - accuracy: 0.7429 - val_loss: 0.5479 - val_accuracy: 0.6872\n",
      "Epoch 153/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4939 - accuracy: 0.73\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.4937 - accuracy: 0.7376 - val_loss: 0.5222 - val_accuracy: 0.7078\n",
      "Epoch 154/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4990 - accuracy: 0.73\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.4990 - accuracy: 0.7315 - val_loss: 0.5603 - val_accuracy: 0.6895\n",
      "Epoch 155/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4778 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.4788 - accuracy: 0.7475 - val_loss: 0.5038 - val_accuracy: 0.7169\n",
      "Epoch 156/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4797 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.4797 - accuracy: 0.7437 - val_loss: 0.5169 - val_accuracy: 0.7100\n",
      "Epoch 157/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4787 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.4803 - accuracy: 0.7445 - val_loss: 0.5161 - val_accuracy: 0.7100\n",
      "Epoch 158/600\n",
      "2/2 [==============================] - 0s 8ms/step loss: 0.4785 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.4785 - accuracy: 0.7445 - val_loss: 0.5160 - val_accuracy: 0.7100\n",
      "Epoch 159/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.4953 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.4965 - accuracy: 0.7429 - val_loss: 0.5162 - val_accuracy: 0.7100\n",
      "Epoch 160/600\n",
      "2/2 [==============================] - 0s 8ms/step loss: 0.4929 - accuracy: 0.73\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.4882 - accuracy: 0.7407 - val_loss: 0.5266 - val_accuracy: 0.7100\n",
      "Epoch 161/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4771 - accuracy: 0.75\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.4814 - accuracy: 0.7445 - val_loss: 0.5167 - val_accuracy: 0.7100\n",
      "Epoch 162/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4823 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.4821 - accuracy: 0.7437 - val_loss: 0.5168 - val_accuracy: 0.7100\n",
      "Epoch 163/600\n",
      "2/2 [==============================] - 0s 8ms/step loss: 0.4721 - accuracy: 0.75\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.4753 - accuracy: 0.7506 - val_loss: 0.5119 - val_accuracy: 0.7078\n",
      "Epoch 164/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4819 - accuracy: 0.74\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.4811 - accuracy: 0.7452 - val_loss: 0.5115 - val_accuracy: 0.7100\n",
      "Epoch 165/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4920 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.4870 - accuracy: 0.7277 - val_loss: 0.4921 - val_accuracy: 0.7146\n",
      "Epoch 166/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4229 - accuracy: 0.77\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.4251 - accuracy: 0.7765 - val_loss: 0.4867 - val_accuracy: 0.7032\n",
      "Epoch 167/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.3966 - accuracy: 0.80\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.3972 - accuracy: 0.8047 - val_loss: 0.6196 - val_accuracy: 0.5868\n",
      "Epoch 168/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.4025 - accuracy: 0.77\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.4018 - accuracy: 0.7750 - val_loss: 0.5350 - val_accuracy: 0.6187\n",
      "Epoch 169/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.3391 - accuracy: 0.80\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.3377 - accuracy: 0.8063 - val_loss: 0.2486 - val_accuracy: 0.9064\n",
      "Epoch 170/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.3586 - accuracy: 0.87\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.3576 - accuracy: 0.8703 - val_loss: 0.2455 - val_accuracy: 0.9018\n",
      "Epoch 171/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.2297 - accuracy: 0.90\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.2311 - accuracy: 0.8993 - val_loss: 0.5153 - val_accuracy: 0.7740\n",
      "Epoch 172/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.2576 - accuracy: 0.87\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.2562 - accuracy: 0.8719 - val_loss: 0.2165 - val_accuracy: 0.8973\n",
      "Epoch 173/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.3257 - accuracy: 0.84\n",
      "14/14 [==============================] - 2s 137ms/step - loss: 0.3246 - accuracy: 0.8467 - val_loss: 0.3807 - val_accuracy: 0.8858\n",
      "Epoch 174/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.2238 - accuracy: 0.90\n",
      "14/14 [==============================] - 1s 92ms/step - loss: 0.2274 - accuracy: 0.9062 - val_loss: 0.2601 - val_accuracy: 0.8836\n",
      "Epoch 175/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.2000 - accuracy: 0.92\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.2036 - accuracy: 0.9176 - val_loss: 0.2105 - val_accuracy: 0.9315\n",
      "Epoch 176/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.2816 - accuracy: 0.89\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.2830 - accuracy: 0.8909 - val_loss: 0.2964 - val_accuracy: 0.8721\n",
      "Epoch 177/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.2239 - accuracy: 0.90\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.2233 - accuracy: 0.9031 - val_loss: 0.1789 - val_accuracy: 0.9406\n",
      "Epoch 178/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.2223 - accuracy: 0.90\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 0.2234 - accuracy: 0.9077 - val_loss: 0.2392 - val_accuracy: 0.8950\n",
      "Epoch 179/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.1982 - accuracy: 0.92\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.1996 - accuracy: 0.9230 - val_loss: 0.2248 - val_accuracy: 0.9018\n",
      "Epoch 180/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.2367 - accuracy: 0.90\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.2369 - accuracy: 0.9001 - val_loss: 0.6059 - val_accuracy: 0.7443\n",
      "Epoch 181/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.2008 - accuracy: 0.92\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.1995 - accuracy: 0.9207 - val_loss: 0.1668 - val_accuracy: 0.9384\n",
      "Epoch 182/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.2468 - accuracy: 0.90\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.2457 - accuracy: 0.9054 - val_loss: 0.2443 - val_accuracy: 0.8904\n",
      "Epoch 183/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.1509 - accuracy: 0.94\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.1535 - accuracy: 0.9443 - val_loss: 0.4574 - val_accuracy: 0.7877\n",
      "Epoch 184/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.2018 - accuracy: 0.91\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.2025 - accuracy: 0.9153 - val_loss: 0.4610 - val_accuracy: 0.7580\n",
      "Epoch 185/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.2685 - accuracy: 0.87\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.2665 - accuracy: 0.8741 - val_loss: 0.2353 - val_accuracy: 0.9041\n",
      "Epoch 186/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.1785 - accuracy: 0.93\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.1780 - accuracy: 0.9298 - val_loss: 0.1650 - val_accuracy: 0.9406\n",
      "Epoch 187/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.1978 - accuracy: 0.92\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.1995 - accuracy: 0.9184 - val_loss: 0.7103 - val_accuracy: 0.8014\n",
      "Epoch 188/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.2179 - accuracy: 0.91\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.2183 - accuracy: 0.9191 - val_loss: 0.1631 - val_accuracy: 0.9406\n",
      "Epoch 189/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.1542 - accuracy: 0.94\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.1559 - accuracy: 0.9397 - val_loss: 0.1903 - val_accuracy: 0.9224\n",
      "Epoch 190/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.3026 - accuracy: 0.88\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.2865 - accuracy: 0.8917 - val_loss: 0.1448 - val_accuracy: 0.9543\n",
      "Epoch 191/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.1588 - accuracy: 0.94\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.1591 - accuracy: 0.9451 - val_loss: 0.4729 - val_accuracy: 0.7443\n",
      "Epoch 192/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.2973 - accuracy: 0.85\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 0.2807 - accuracy: 0.8696 - val_loss: 0.1607 - val_accuracy: 0.9475\n",
      "Epoch 193/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.1801 - accuracy: 0.93\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.1791 - accuracy: 0.9390 - val_loss: 0.1716 - val_accuracy: 0.9361\n",
      "Epoch 194/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.1446 - accuracy: 0.94\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.1502 - accuracy: 0.9481 - val_loss: 0.1604 - val_accuracy: 0.9498\n",
      "Epoch 195/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.1490 - accuracy: 0.94\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.1482 - accuracy: 0.9436 - val_loss: 0.0910 - val_accuracy: 0.9749\n",
      "Epoch 196/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.1203 - accuracy: 0.95\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.1196 - accuracy: 0.9580 - val_loss: 0.8330 - val_accuracy: 0.7968\n",
      "Epoch 197/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.2263 - accuracy: 0.94\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.2098 - accuracy: 0.9474 - val_loss: 0.0909 - val_accuracy: 0.9749\n",
      "Epoch 198/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.1424 - accuracy: 0.94\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.1412 - accuracy: 0.9497 - val_loss: 0.1431 - val_accuracy: 0.9498\n",
      "Epoch 199/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.0866 - accuracy: 0.97\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.0897 - accuracy: 0.9733 - val_loss: 0.2780 - val_accuracy: 0.8995\n",
      "Epoch 200/600\n",
      "2/2 [==============================] - 0s 9ms/step loss: 0.2108 - accuracy: 0.91\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.2116 - accuracy: 0.9184 - val_loss: 0.1672 - val_accuracy: 0.9361\n",
      "Epoch 201/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.1689 - accuracy: 0.93\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.1807 - accuracy: 0.9291 - val_loss: 0.1645 - val_accuracy: 0.9406\n",
      "Epoch 202/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.1475 - accuracy: 0.94\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.1456 - accuracy: 0.9443 - val_loss: 0.1597 - val_accuracy: 0.9406\n",
      "Epoch 203/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.2194 - accuracy: 0.92\n",
      "14/14 [==============================] - 1s 92ms/step - loss: 0.2182 - accuracy: 0.9283 - val_loss: 0.1962 - val_accuracy: 0.9155\n",
      "Epoch 204/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.1561 - accuracy: 0.94\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.1550 - accuracy: 0.9489 - val_loss: 0.1013 - val_accuracy: 0.9726\n",
      "Epoch 205/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.1258 - accuracy: 0.96\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.1251 - accuracy: 0.9626 - val_loss: 0.1655 - val_accuracy: 0.9384\n",
      "Epoch 206/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.1912 - accuracy: 0.94\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.1899 - accuracy: 0.9451 - val_loss: 0.1485 - val_accuracy: 0.9406\n",
      "Epoch 207/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.1044 - accuracy: 0.96\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.1037 - accuracy: 0.9680 - val_loss: 0.0883 - val_accuracy: 0.9749\n",
      "Epoch 208/600\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.0975 - accuracy: 0.96\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.1001 - accuracy: 0.9641 - val_loss: 0.3753 - val_accuracy: 0.8151\n",
      "Epoch 209/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.0985 - accuracy: 0.96\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 0.0977 - accuracy: 0.9641 - val_loss: 0.0571 - val_accuracy: 0.9749\n",
      "Epoch 210/600\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.1335 - accuracy: 0.95\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.1327 - accuracy: 0.9550 - val_loss: 0.0889 - val_accuracy: 0.9703\n",
      "Epoch 211/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.0768 - accuracy: 0.97\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.0763 - accuracy: 0.9733 - val_loss: 0.0489 - val_accuracy: 0.9817\n",
      "Epoch 212/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.0802 - accuracy: 0.96\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.0796 - accuracy: 0.9664 - val_loss: 0.2184 - val_accuracy: 0.9315\n",
      "Epoch 213/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.2146 - accuracy: 0.94\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.2143 - accuracy: 0.9466 - val_loss: 0.1542 - val_accuracy: 0.9635\n",
      "Epoch 214/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.0386 - accuracy: 0.99\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.0383 - accuracy: 0.9931 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
      "Epoch 215/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.1204 - accuracy: 0.94\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.1206 - accuracy: 0.9420 - val_loss: 0.1339 - val_accuracy: 0.9566\n",
      "Epoch 216/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.0691 - accuracy: 0.97\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.0636 - accuracy: 0.9794 - val_loss: 0.0740 - val_accuracy: 0.9795\n",
      "Epoch 217/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.0357 - accuracy: 0.98\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.0354 - accuracy: 0.9817 - val_loss: 0.0294 - val_accuracy: 0.9817\n",
      "Epoch 218/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.1623 - accuracy: 0.95\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.1615 - accuracy: 0.9565 - val_loss: 0.1616 - val_accuracy: 0.9795\n",
      "Epoch 219/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.0747 - accuracy: 0.97\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.0741 - accuracy: 0.9771 - val_loss: 0.0295 - val_accuracy: 0.9977\n",
      "Epoch 220/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.0173 - accuracy: 0.99\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.0165 - accuracy: 0.9969 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 221/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.0160 - accuracy: 0.99\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.0159 - accuracy: 0.9977 - val_loss: 0.0688 - val_accuracy: 0.9749\n",
      "Epoch 222/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.1226 - accuracy: 0.95\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.1216 - accuracy: 0.9550 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 223/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.0075 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 224/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.0024 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 225/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.1436 - accuracy: 0.9631\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.1429 - accuracy: 0.9634 - val_loss: 0.1861 - val_accuracy: 0.8950\n",
      "Epoch 226/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.0536 - accuracy: 0.97\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.0531 - accuracy: 0.9741 - val_loss: 0.1383 - val_accuracy: 0.9452\n",
      "Epoch 227/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.1063 - accuracy: 0.96\n",
      "14/14 [==============================] - 1s 103ms/step - loss: 0.1066 - accuracy: 0.9603 - val_loss: 0.0321 - val_accuracy: 0.9817\n",
      "Epoch 228/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.0291 - accuracy: 0.98\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.0300 - accuracy: 0.9809 - val_loss: 0.0300 - val_accuracy: 0.9795\n",
      "Epoch 229/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.0367 - accuracy: 0.97\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.0364 - accuracy: 0.9748 - val_loss: 0.0278 - val_accuracy: 0.9817\n",
      "Epoch 230/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.0249 - accuracy: 0.98\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.0266 - accuracy: 0.9817 - val_loss: 0.0269 - val_accuracy: 0.9795\n",
      "Epoch 231/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.0287 - accuracy: 0.98\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.0300 - accuracy: 0.9825 - val_loss: 0.4778 - val_accuracy: 0.8927\n",
      "Epoch 232/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.1117 - accuracy: 0.97\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.1113 - accuracy: 0.9756 - val_loss: 1.4053 - val_accuracy: 0.8059\n",
      "Epoch 233/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.1159 - accuracy: 0.97\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.1150 - accuracy: 0.9741 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 234/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.0067 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 235/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.1118 - accuracy: 0.98\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.1090 - accuracy: 0.9870 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 236/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.0123 - accuracy: 0.99\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.0164 - accuracy: 0.9969 - val_loss: 0.4293 - val_accuracy: 0.8516\n",
      "Epoch 237/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.0912 - accuracy: 0.96\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.0949 - accuracy: 0.9641 - val_loss: 0.3443 - val_accuracy: 0.8653\n",
      "Epoch 238/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.0993 - accuracy: 0.96\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.0988 - accuracy: 0.9672 - val_loss: 0.0660 - val_accuracy: 0.9772\n",
      "Epoch 239/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.0589 - accuracy: 0.98\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.0585 - accuracy: 0.9847 - val_loss: 0.0524 - val_accuracy: 0.9749\n",
      "Epoch 240/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.1125 - accuracy: 0.94\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.1060 - accuracy: 0.9481 - val_loss: 0.0676 - val_accuracy: 0.9406\n",
      "Epoch 241/600\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.1942 - accuracy: 0.93\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 0.1849 - accuracy: 0.9352 - val_loss: 0.0718 - val_accuracy: 0.9635\n",
      "Epoch 242/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.0461 - accuracy: 0.98\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.0457 - accuracy: 0.9840 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 243/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.0091 - accuracy: 0.99\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.1934 - val_accuracy: 0.9795\n",
      "Epoch 244/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.1236 - accuracy: 0.96\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 0.1226 - accuracy: 0.9687 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 245/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.0428 - accuracy: 0.99\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.0427 - accuracy: 0.9924 - val_loss: 0.0765 - val_accuracy: 0.9817\n",
      "Epoch 246/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 0.0554 - accuracy: 0.98\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.0560 - accuracy: 0.9840 - val_loss: 0.0212 - val_accuracy: 0.9977\n",
      "Epoch 247/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.0127 - accuracy: 0.99\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.0246 - accuracy: 0.9962 - val_loss: 0.0188 - val_accuracy: 0.9954\n",
      "Epoch 248/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 0.0030 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 6.9730e-04 - val_accuracy: 1.0000\n",
      "Epoch 249/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 3.9568e-04 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 3.7180e-04 - accuracy: 1.0000 - val_loss: 2.4357e-04 - val_accuracy: 1.0000\n",
      "Epoch 250/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.5074e-04 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 1.5106e-04 - accuracy: 1.0000 - val_loss: 8.5051e-05 - val_accuracy: 1.0000\n",
      "Epoch 251/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 8.4042e-05 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 8.3287e-05 - accuracy: 1.0000 - val_loss: 3.3053e-05 - val_accuracy: 1.0000\n",
      "Epoch 252/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.7722e-05 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 2.7055e-05 - accuracy: 1.0000 - val_loss: 2.1125e-05 - val_accuracy: 1.0000\n",
      "Epoch 253/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.0288e-05 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 2.0185e-05 - accuracy: 1.0000 - val_loss: 1.2092e-05 - val_accuracy: 1.0000\n",
      "Epoch 254/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.4048e-05 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 1.3995e-05 - accuracy: 1.0000 - val_loss: 1.1397e-05 - val_accuracy: 1.0000\n",
      "Epoch 255/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.0507e-05 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 1.0324e-05 - accuracy: 1.0000 - val_loss: 5.7550e-06 - val_accuracy: 1.0000\n",
      "Epoch 256/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 6.5603e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 6.5310e-06 - accuracy: 1.0000 - val_loss: 4.5543e-06 - val_accuracy: 1.0000\n",
      "Epoch 257/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 5.9207e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 5.9437e-06 - accuracy: 1.0000 - val_loss: 3.9642e-06 - val_accuracy: 1.0000\n",
      "Epoch 258/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 5.1329e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 5.0984e-06 - accuracy: 1.0000 - val_loss: 3.4670e-06 - val_accuracy: 1.0000\n",
      "Epoch 259/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 3.9389e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 4.3431e-06 - accuracy: 1.0000 - val_loss: 2.7464e-06 - val_accuracy: 1.0000\n",
      "Epoch 260/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 4.8087e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 4.6493e-06 - accuracy: 1.0000 - val_loss: 2.1547e-06 - val_accuracy: 1.0000\n",
      "Epoch 261/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 3.2899e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 3.3141e-06 - accuracy: 1.0000 - val_loss: 1.8975e-06 - val_accuracy: 1.0000\n",
      "Epoch 262/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.7135e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 2.7135e-06 - accuracy: 1.0000 - val_loss: 1.7457e-06 - val_accuracy: 1.0000\n",
      "Epoch 263/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 2.8626e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 2.8410e-06 - accuracy: 1.0000 - val_loss: 1.6292e-06 - val_accuracy: 1.0000\n",
      "Epoch 264/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.2662e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 2.2567e-06 - accuracy: 1.0000 - val_loss: 1.4474e-06 - val_accuracy: 1.0000\n",
      "Epoch 265/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.9904e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 2.9658e-06 - accuracy: 1.0000 - val_loss: 1.3393e-06 - val_accuracy: 1.0000\n",
      "Epoch 266/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 1.6676e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 1.6553e-06 - accuracy: 1.0000 - val_loss: 1.2631e-06 - val_accuracy: 1.0000\n",
      "Epoch 267/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.7720e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 1.8418e-06 - accuracy: 1.0000 - val_loss: 2.5273e-06 - val_accuracy: 1.0000\n",
      "Epoch 268/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 2.9211e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 2.8973e-06 - accuracy: 1.0000 - val_loss: 1.0585e-06 - val_accuracy: 1.0000\n",
      "Epoch 269/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.6438e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 1.6322e-06 - accuracy: 1.0000 - val_loss: 9.6183e-07 - val_accuracy: 1.0000\n",
      "Epoch 270/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.5602e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 1.5581e-06 - accuracy: 1.0000 - val_loss: 9.1611e-07 - val_accuracy: 1.0000\n",
      "Epoch 271/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 2.3878e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 2.3686e-06 - accuracy: 1.0000 - val_loss: 8.5106e-07 - val_accuracy: 1.0000\n",
      "Epoch 272/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.5201e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.5076e-06 - accuracy: 1.0000 - val_loss: 8.0207e-07 - val_accuracy: 1.0000\n",
      "Epoch 273/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.2705e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 1.2896e-06 - accuracy: 1.0000 - val_loss: 7.6615e-07 - val_accuracy: 1.0000\n",
      "Epoch 274/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 1.3376e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 1.3181e-06 - accuracy: 1.0000 - val_loss: 7.2723e-07 - val_accuracy: 1.0000\n",
      "Epoch 275/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.4439e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.4338e-06 - accuracy: 1.0000 - val_loss: 7.3294e-07 - val_accuracy: 1.0000\n",
      "Epoch 276/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.4141e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 2.3995e-06 - accuracy: 1.0000 - val_loss: 9.5557e-07 - val_accuracy: 1.0000\n",
      "Epoch 277/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.0835e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 1.2155e-06 - accuracy: 1.0000 - val_loss: 6.9810e-07 - val_accuracy: 1.0000\n",
      "Epoch 278/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.1249e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 1.1249e-06 - accuracy: 1.0000 - val_loss: 5.6311e-07 - val_accuracy: 1.0000\n",
      "Epoch 279/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.2800e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 1.2714e-06 - accuracy: 1.0000 - val_loss: 5.2882e-07 - val_accuracy: 1.0000\n",
      "Epoch 280/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 9.2303e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 9.3920e-07 - accuracy: 1.0000 - val_loss: 5.1303e-07 - val_accuracy: 1.0000\n",
      "Epoch 281/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.0333e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.0299e-06 - accuracy: 1.0000 - val_loss: 4.9371e-07 - val_accuracy: 1.0000\n",
      "Epoch 282/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 7.6375e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 7.6135e-07 - accuracy: 1.0000 - val_loss: 4.7765e-07 - val_accuracy: 1.0000\n",
      "Epoch 283/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 1.0106e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 9.9329e-07 - accuracy: 1.0000 - val_loss: 4.5887e-07 - val_accuracy: 1.0000\n",
      "Epoch 284/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.0683e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 1.0626e-06 - accuracy: 1.0000 - val_loss: 4.4799e-07 - val_accuracy: 1.0000\n",
      "Epoch 285/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.0408e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 1.0581e-06 - accuracy: 1.0000 - val_loss: 4.2050e-07 - val_accuracy: 1.0000\n",
      "Epoch 286/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 8.4867e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 8.4164e-07 - accuracy: 1.0000 - val_loss: 4.1097e-07 - val_accuracy: 1.0000\n",
      "Epoch 287/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 9.9106e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 9.8429e-07 - accuracy: 1.0000 - val_loss: 3.8893e-07 - val_accuracy: 1.0000\n",
      "Epoch 288/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 6.7681e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 7.1834e-07 - accuracy: 1.0000 - val_loss: 3.8512e-07 - val_accuracy: 1.0000\n",
      "Epoch 289/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 7.0263e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 7.1243e-07 - accuracy: 1.0000 - val_loss: 3.6688e-07 - val_accuracy: 1.0000\n",
      "Epoch 290/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 9.4896e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 9.4291e-07 - accuracy: 1.0000 - val_loss: 3.6851e-07 - val_accuracy: 1.0000\n",
      "Epoch 291/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 5.8690e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 5.9886e-07 - accuracy: 1.0000 - val_loss: 3.5735e-07 - val_accuracy: 1.0000\n",
      "Epoch 292/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 9.6126e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 9.2179e-07 - accuracy: 1.0000 - val_loss: 3.2796e-07 - val_accuracy: 1.0000\n",
      "Epoch 293/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 5.7568e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 5.7240e-07 - accuracy: 1.0000 - val_loss: 3.2061e-07 - val_accuracy: 1.0000\n",
      "Epoch 294/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 6.8700e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 7.2825e-07 - accuracy: 1.0000 - val_loss: 3.1571e-07 - val_accuracy: 1.0000\n",
      "Epoch 295/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 6.6316e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 6.5814e-07 - accuracy: 1.0000 - val_loss: 3.0864e-07 - val_accuracy: 1.0000\n",
      "Epoch 296/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.0543e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 1.0791e-06 - accuracy: 1.0000 - val_loss: 2.8360e-07 - val_accuracy: 1.0000\n",
      "Epoch 297/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 5.2147e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 5.2147e-07 - accuracy: 1.0000 - val_loss: 2.7598e-07 - val_accuracy: 1.0000\n",
      "Epoch 298/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 7.6471e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 7.5179e-07 - accuracy: 1.0000 - val_loss: 2.7053e-07 - val_accuracy: 1.0000\n",
      "Epoch 299/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 6.2941e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 6.2531e-07 - accuracy: 1.0000 - val_loss: 2.6182e-07 - val_accuracy: 1.0000\n",
      "Epoch 300/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 6.8314e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 6.8441e-07 - accuracy: 1.0000 - val_loss: 2.5203e-07 - val_accuracy: 1.0000\n",
      "Epoch 301/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 5.8809e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 5.6894e-07 - accuracy: 1.0000 - val_loss: 2.4658e-07 - val_accuracy: 1.0000\n",
      "Epoch 302/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 8.2932e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 7.9102e-07 - accuracy: 1.0000 - val_loss: 2.3842e-07 - val_accuracy: 1.0000\n",
      "Epoch 303/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 4.9838e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 4.9466e-07 - accuracy: 1.0000 - val_loss: 2.3434e-07 - val_accuracy: 1.0000\n",
      "Epoch 304/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 1.0141e-06 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 1.0740e-06 - accuracy: 1.0000 - val_loss: 2.3570e-07 - val_accuracy: 1.0000\n",
      "Epoch 305/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 4.1429e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 4.1227e-07 - accuracy: 1.0000 - val_loss: 2.2127e-07 - val_accuracy: 1.0000\n",
      "Epoch 306/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 4.8573e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 5.0711e-07 - accuracy: 1.0000 - val_loss: 2.1202e-07 - val_accuracy: 1.0000\n",
      "Epoch 307/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 4.4694e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 4.4628e-07 - accuracy: 1.0000 - val_loss: 2.0739e-07 - val_accuracy: 1.0000\n",
      "Epoch 308/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 3.8186e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 4.0091e-07 - accuracy: 1.0000 - val_loss: 2.0440e-07 - val_accuracy: 1.0000\n",
      "Epoch 309/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 3.2425e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 3.2171e-07 - accuracy: 1.0000 - val_loss: 2.0249e-07 - val_accuracy: 1.0000\n",
      "Epoch 310/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 4.2309e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 4.2964e-07 - accuracy: 1.0000 - val_loss: 2.1038e-07 - val_accuracy: 1.0000\n",
      "Epoch 311/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 4.3832e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 4.3501e-07 - accuracy: 1.0000 - val_loss: 1.9814e-07 - val_accuracy: 1.0000\n",
      "Epoch 312/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 3.8472e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 3.8472e-07 - accuracy: 1.0000 - val_loss: 1.8943e-07 - val_accuracy: 1.0000\n",
      "Epoch 313/600\n",
      "2/2 [==============================] - 0s 4ms/step loss: 6.0768e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 6.0285e-07 - accuracy: 1.0000 - val_loss: 1.8099e-07 - val_accuracy: 1.0000\n",
      "Epoch 314/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 4.0494e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 4.0173e-07 - accuracy: 1.0000 - val_loss: 1.7773e-07 - val_accuracy: 1.0000\n",
      "Epoch 315/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 3.1610e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 3.1016e-07 - accuracy: 1.0000 - val_loss: 1.7500e-07 - val_accuracy: 1.0000\n",
      "Epoch 316/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 3.4332e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 3.4480e-07 - accuracy: 1.0000 - val_loss: 1.7255e-07 - val_accuracy: 1.0000\n",
      "Epoch 317/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 4.8565e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 4.8565e-07 - accuracy: 1.0000 - val_loss: 1.7065e-07 - val_accuracy: 1.0000\n",
      "Epoch 318/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 3.8091e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 3.7799e-07 - accuracy: 1.0000 - val_loss: 1.6902e-07 - val_accuracy: 1.0000\n",
      "Epoch 319/600\n",
      "2/2 [==============================] - 0s 8ms/step loss: 3.7275e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 3.7226e-07 - accuracy: 1.0000 - val_loss: 1.6521e-07 - val_accuracy: 1.0000\n",
      "Epoch 320/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 4.0054e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 4.0054e-07 - accuracy: 1.0000 - val_loss: 1.6384e-07 - val_accuracy: 1.0000\n",
      "Epoch 321/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.3768e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 2s 163ms/step - loss: 2.3578e-07 - accuracy: 1.0000 - val_loss: 1.6303e-07 - val_accuracy: 1.0000\n",
      "Epoch 322/600\n",
      "2/2 [==============================] - 0s 8ms/step loss: 3.7065e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 3.6881e-07 - accuracy: 1.0000 - val_loss: 1.6031e-07 - val_accuracy: 1.0000\n",
      "Epoch 323/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 3.0132e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 3.0089e-07 - accuracy: 1.0000 - val_loss: 1.5813e-07 - val_accuracy: 1.0000\n",
      "Epoch 324/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 2.3415e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 2.3096e-07 - accuracy: 1.0000 - val_loss: 1.5704e-07 - val_accuracy: 1.0000\n",
      "Epoch 325/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.6822e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 2.6606e-07 - accuracy: 1.0000 - val_loss: 1.5595e-07 - val_accuracy: 1.0000\n",
      "Epoch 326/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 3.1407e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 3.1152e-07 - accuracy: 1.0000 - val_loss: 1.5132e-07 - val_accuracy: 1.0000\n",
      "Epoch 327/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 3.8027e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 3.7736e-07 - accuracy: 1.0000 - val_loss: 1.5105e-07 - val_accuracy: 1.0000\n",
      "Epoch 328/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 3.8017e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 3.7816e-07 - accuracy: 1.0000 - val_loss: 1.4751e-07 - val_accuracy: 1.0000\n",
      "Epoch 329/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 4.6170e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 4.6519e-07 - accuracy: 1.0000 - val_loss: 1.4234e-07 - val_accuracy: 1.0000\n",
      "Epoch 330/600\n",
      "2/2 [==============================] - 0s 8ms/step loss: 5.1269e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 4.8346e-07 - accuracy: 1.0000 - val_loss: 1.4098e-07 - val_accuracy: 1.0000\n",
      "Epoch 331/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 3.8293e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 3.8054e-07 - accuracy: 1.0000 - val_loss: 1.4098e-07 - val_accuracy: 1.0000\n",
      "Epoch 332/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 3.4928e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 3.4644e-07 - accuracy: 1.0000 - val_loss: 1.3853e-07 - val_accuracy: 1.0000\n",
      "Epoch 333/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.9078e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 2.8961e-07 - accuracy: 1.0000 - val_loss: 1.3717e-07 - val_accuracy: 1.0000\n",
      "Epoch 334/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.8711e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 2.8506e-07 - accuracy: 1.0000 - val_loss: 1.3554e-07 - val_accuracy: 1.0000\n",
      "Epoch 335/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 3.8742e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 3.8726e-07 - accuracy: 1.0000 - val_loss: 1.3037e-07 - val_accuracy: 1.0000\n",
      "Epoch 336/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 3.1077e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 3.1134e-07 - accuracy: 1.0000 - val_loss: 1.2955e-07 - val_accuracy: 1.0000\n",
      "Epoch 337/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 2.5584e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 2.5424e-07 - accuracy: 1.0000 - val_loss: 1.2737e-07 - val_accuracy: 1.0000\n",
      "Epoch 338/600\n",
      "2/2 [==============================] - 0s 4ms/step loss: 3.4378e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 3.4126e-07 - accuracy: 1.0000 - val_loss: 1.2465e-07 - val_accuracy: 1.0000\n",
      "Epoch 339/600\n",
      "2/2 [==============================] - 0s 8ms/step loss: 3.1517e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 3.2398e-07 - accuracy: 1.0000 - val_loss: 1.2520e-07 - val_accuracy: 1.0000\n",
      "Epoch 340/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 2.4144e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 2.3960e-07 - accuracy: 1.0000 - val_loss: 1.2384e-07 - val_accuracy: 1.0000\n",
      "Epoch 341/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.6556e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 2.6497e-07 - accuracy: 1.0000 - val_loss: 1.1839e-07 - val_accuracy: 1.0000\n",
      "Epoch 342/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 2.6987e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 2.6952e-07 - accuracy: 1.0000 - val_loss: 1.1730e-07 - val_accuracy: 1.0000\n",
      "Epoch 343/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.4905e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 2.4742e-07 - accuracy: 1.0000 - val_loss: 1.1649e-07 - val_accuracy: 1.0000\n",
      "Epoch 344/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 3.3427e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 3.2516e-07 - accuracy: 1.0000 - val_loss: 1.1622e-07 - val_accuracy: 1.0000\n",
      "Epoch 345/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 3.1461e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 3.1461e-07 - accuracy: 1.0000 - val_loss: 1.1431e-07 - val_accuracy: 1.0000\n",
      "Epoch 346/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 2.9912e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 2.9743e-07 - accuracy: 1.0000 - val_loss: 1.1377e-07 - val_accuracy: 1.0000\n",
      "Epoch 347/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 2.6852e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 2.7524e-07 - accuracy: 1.0000 - val_loss: 1.1268e-07 - val_accuracy: 1.0000\n",
      "Epoch 348/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.7872e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.7749e-07 - accuracy: 1.0000 - val_loss: 1.0914e-07 - val_accuracy: 1.0000\n",
      "Epoch 349/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 4.6899e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 4.6614e-07 - accuracy: 1.0000 - val_loss: 1.2111e-07 - val_accuracy: 1.0000\n",
      "Epoch 350/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.0395e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 2.3505e-07 - accuracy: 1.0000 - val_loss: 1.1431e-07 - val_accuracy: 1.0000\n",
      "Epoch 351/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.3612e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 2.3651e-07 - accuracy: 1.0000 - val_loss: 1.1023e-07 - val_accuracy: 1.0000\n",
      "Epoch 352/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 2.7620e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 2.7397e-07 - accuracy: 1.0000 - val_loss: 1.0615e-07 - val_accuracy: 1.0000\n",
      "Epoch 353/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 3.0178e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 2.9925e-07 - accuracy: 1.0000 - val_loss: 1.0451e-07 - val_accuracy: 1.0000\n",
      "Epoch 354/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 2.6006e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 103ms/step - loss: 2.6542e-07 - accuracy: 1.0000 - val_loss: 1.0261e-07 - val_accuracy: 1.0000\n",
      "Epoch 355/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 2.8552e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 2.8552e-07 - accuracy: 1.0000 - val_loss: 1.0125e-07 - val_accuracy: 1.0000\n",
      "Epoch 356/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.2173e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 2.2232e-07 - accuracy: 1.0000 - val_loss: 9.9885e-08 - val_accuracy: 1.0000\n",
      "Epoch 357/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 3.5946e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 3.5662e-07 - accuracy: 1.0000 - val_loss: 9.9613e-08 - val_accuracy: 1.0000\n",
      "Epoch 358/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 2.7252e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 2.7252e-07 - accuracy: 1.0000 - val_loss: 9.9341e-08 - val_accuracy: 1.0000\n",
      "Epoch 359/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.9097e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 2.7561e-07 - accuracy: 1.0000 - val_loss: 9.7164e-08 - val_accuracy: 1.0000\n",
      "Epoch 360/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.2073e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 2.1214e-07 - accuracy: 1.0000 - val_loss: 9.7436e-08 - val_accuracy: 1.0000\n",
      "Epoch 361/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.4474e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 2.4742e-07 - accuracy: 1.0000 - val_loss: 9.5258e-08 - val_accuracy: 1.0000\n",
      "Epoch 362/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 2.1494e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 2.1341e-07 - accuracy: 1.0000 - val_loss: 9.6075e-08 - val_accuracy: 1.0000\n",
      "Epoch 363/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 2.7840e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 2.7606e-07 - accuracy: 1.0000 - val_loss: 9.5531e-08 - val_accuracy: 1.0000\n",
      "Epoch 364/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.8322e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.8322e-07 - accuracy: 1.0000 - val_loss: 9.5531e-08 - val_accuracy: 1.0000\n",
      "Epoch 365/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 2.7491e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 108ms/step - loss: 2.7361e-07 - accuracy: 1.0000 - val_loss: 9.3081e-08 - val_accuracy: 1.0000\n",
      "Epoch 366/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.0421e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 2.0277e-07 - accuracy: 1.0000 - val_loss: 9.1448e-08 - val_accuracy: 1.0000\n",
      "Epoch 367/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.9807e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 1.9723e-07 - accuracy: 1.0000 - val_loss: 9.0632e-08 - val_accuracy: 1.0000\n",
      "Epoch 368/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.7204e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 1.7204e-07 - accuracy: 1.0000 - val_loss: 9.0359e-08 - val_accuracy: 1.0000\n",
      "Epoch 369/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 2.5749e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 2.5651e-07 - accuracy: 1.0000 - val_loss: 8.8999e-08 - val_accuracy: 1.0000\n",
      "Epoch 370/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.2925e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 2.2832e-07 - accuracy: 1.0000 - val_loss: 8.7093e-08 - val_accuracy: 1.0000\n",
      "Epoch 371/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.2679e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 2.5087e-07 - accuracy: 1.0000 - val_loss: 8.7093e-08 - val_accuracy: 1.0000\n",
      "Epoch 372/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 3.1892e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 3.1625e-07 - accuracy: 1.0000 - val_loss: 8.5733e-08 - val_accuracy: 1.0000\n",
      "Epoch 373/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.8798e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 2.1432e-07 - accuracy: 1.0000 - val_loss: 8.3827e-08 - val_accuracy: 1.0000\n",
      "Epoch 374/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 3.3084e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 3.2834e-07 - accuracy: 1.0000 - val_loss: 8.4100e-08 - val_accuracy: 1.0000\n",
      "Epoch 375/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 2.2338e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 2.2478e-07 - accuracy: 1.0000 - val_loss: 8.2739e-08 - val_accuracy: 1.0000\n",
      "Epoch 376/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 2.0057e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 1.8868e-07 - accuracy: 1.0000 - val_loss: 8.1650e-08 - val_accuracy: 1.0000\n",
      "Epoch 377/600\n",
      "2/2 [==============================] - 0s 8ms/step loss: 2.2054e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 2.1896e-07 - accuracy: 1.0000 - val_loss: 8.0561e-08 - val_accuracy: 1.0000\n",
      "Epoch 378/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 1.8266e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 92ms/step - loss: 1.8113e-07 - accuracy: 1.0000 - val_loss: 8.0017e-08 - val_accuracy: 1.0000\n",
      "Epoch 379/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.8587e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 1.8831e-07 - accuracy: 1.0000 - val_loss: 7.9745e-08 - val_accuracy: 1.0000\n",
      "Epoch 380/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 1.5360e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 1.5240e-07 - accuracy: 1.0000 - val_loss: 7.9201e-08 - val_accuracy: 1.0000\n",
      "Epoch 381/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 2.4721e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 2.4532e-07 - accuracy: 1.0000 - val_loss: 7.7023e-08 - val_accuracy: 1.0000\n",
      "Epoch 382/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 2.7500e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 2.7288e-07 - accuracy: 1.0000 - val_loss: 7.7023e-08 - val_accuracy: 1.0000\n",
      "Epoch 383/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.5726e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 1.5667e-07 - accuracy: 1.0000 - val_loss: 7.5662e-08 - val_accuracy: 1.0000\n",
      "Epoch 384/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.2655e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 1.2621e-07 - accuracy: 1.0000 - val_loss: 7.5935e-08 - val_accuracy: 1.0000\n",
      "Epoch 385/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.9550e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.9595e-07 - accuracy: 1.0000 - val_loss: 7.5390e-08 - val_accuracy: 1.0000\n",
      "Epoch 386/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 1.7359e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 1.7213e-07 - accuracy: 1.0000 - val_loss: 7.5118e-08 - val_accuracy: 1.0000\n",
      "Epoch 387/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.2352e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 1.2457e-07 - accuracy: 1.0000 - val_loss: 7.4846e-08 - val_accuracy: 1.0000\n",
      "Epoch 388/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.6971e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 2.6015e-07 - accuracy: 1.0000 - val_loss: 7.3213e-08 - val_accuracy: 1.0000\n",
      "Epoch 389/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.4736e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 1.4712e-07 - accuracy: 1.0000 - val_loss: 7.2941e-08 - val_accuracy: 1.0000\n",
      "Epoch 390/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.5708e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 1.5594e-07 - accuracy: 1.0000 - val_loss: 7.2669e-08 - val_accuracy: 1.0000\n",
      "Epoch 391/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.4961e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.5158e-07 - accuracy: 1.0000 - val_loss: 7.2396e-08 - val_accuracy: 1.0000\n",
      "Epoch 392/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.1166e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.2476e-07 - accuracy: 1.0000 - val_loss: 7.1308e-08 - val_accuracy: 1.0000\n",
      "Epoch 393/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.9086e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 2.8942e-07 - accuracy: 1.0000 - val_loss: 7.3213e-08 - val_accuracy: 1.0000\n",
      "Epoch 394/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.5415e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.5431e-07 - accuracy: 1.0000 - val_loss: 7.1580e-08 - val_accuracy: 1.0000\n",
      "Epoch 395/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 6.6411e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 6.5900e-07 - accuracy: 1.0000 - val_loss: 6.9675e-08 - val_accuracy: 1.0000\n",
      "Epoch 396/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.7666e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 4.0499e-07 - accuracy: 1.0000 - val_loss: 6.9403e-08 - val_accuracy: 1.0000\n",
      "Epoch 397/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.1549e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 2.1396e-07 - accuracy: 1.0000 - val_loss: 6.8042e-08 - val_accuracy: 1.0000\n",
      "Epoch 398/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 1.9034e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.9013e-07 - accuracy: 1.0000 - val_loss: 6.7497e-08 - val_accuracy: 1.0000\n",
      "Epoch 399/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.5884e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 1.5231e-07 - accuracy: 1.0000 - val_loss: 6.7225e-08 - val_accuracy: 1.0000\n",
      "Epoch 400/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.5169e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 1.5222e-07 - accuracy: 1.0000 - val_loss: 6.6953e-08 - val_accuracy: 1.0000\n",
      "Epoch 401/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 2.0375e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 2.0214e-07 - accuracy: 1.0000 - val_loss: 6.7497e-08 - val_accuracy: 1.0000\n",
      "Epoch 402/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.7921e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 103ms/step - loss: 1.7268e-07 - accuracy: 1.0000 - val_loss: 6.7497e-08 - val_accuracy: 1.0000\n",
      "Epoch 403/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.3856e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 1.4012e-07 - accuracy: 1.0000 - val_loss: 6.6681e-08 - val_accuracy: 1.0000\n",
      "Epoch 404/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.4454e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 1.4867e-07 - accuracy: 1.0000 - val_loss: 6.5048e-08 - val_accuracy: 1.0000\n",
      "Epoch 405/600\n",
      "2/2 [==============================] - 0s 8ms/step loss: 2.2164e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 2.1987e-07 - accuracy: 1.0000 - val_loss: 6.3687e-08 - val_accuracy: 1.0000\n",
      "Epoch 406/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.6469e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 1.6358e-07 - accuracy: 1.0000 - val_loss: 6.3687e-08 - val_accuracy: 1.0000\n",
      "Epoch 407/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.7166e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 1.7022e-07 - accuracy: 1.0000 - val_loss: 6.3687e-08 - val_accuracy: 1.0000\n",
      "Epoch 408/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.1417e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 1.1394e-07 - accuracy: 1.0000 - val_loss: 6.2598e-08 - val_accuracy: 1.0000\n",
      "Epoch 409/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.4562e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 1.4985e-07 - accuracy: 1.0000 - val_loss: 6.2054e-08 - val_accuracy: 1.0000\n",
      "Epoch 410/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.5855e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 1.4949e-07 - accuracy: 1.0000 - val_loss: 6.2054e-08 - val_accuracy: 1.0000\n",
      "Epoch 411/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.4947e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 1.4858e-07 - accuracy: 1.0000 - val_loss: 6.1782e-08 - val_accuracy: 1.0000\n",
      "Epoch 412/600\n",
      "2/2 [==============================] - 0s 8ms/step loss: 1.3599e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 1.3494e-07 - accuracy: 1.0000 - val_loss: 6.1782e-08 - val_accuracy: 1.0000\n",
      "Epoch 413/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.0646e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 1.0630e-07 - accuracy: 1.0000 - val_loss: 6.1238e-08 - val_accuracy: 1.0000\n",
      "Epoch 414/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.1737e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.1794e-07 - accuracy: 1.0000 - val_loss: 6.0693e-08 - val_accuracy: 1.0000\n",
      "Epoch 415/600\n",
      "2/2 [==============================] - 0s 8ms/step loss: 1.3183e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 1.2839e-07 - accuracy: 1.0000 - val_loss: 6.0693e-08 - val_accuracy: 1.0000\n",
      "Epoch 416/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.5470e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 2s 121ms/step - loss: 1.5340e-07 - accuracy: 1.0000 - val_loss: 6.0421e-08 - val_accuracy: 1.0000\n",
      "Epoch 417/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.6938e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.6713e-07 - accuracy: 1.0000 - val_loss: 5.9605e-08 - val_accuracy: 1.0000\n",
      "Epoch 418/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.7404e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.7558e-07 - accuracy: 1.0000 - val_loss: 5.8516e-08 - val_accuracy: 1.0000\n",
      "Epoch 419/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 9.4634e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 1.0639e-07 - accuracy: 1.0000 - val_loss: 5.9060e-08 - val_accuracy: 1.0000\n",
      "Epoch 420/600\n",
      "2/2 [==============================] - 0s 4ms/step loss: 1.3645e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 1.3867e-07 - accuracy: 1.0000 - val_loss: 5.8516e-08 - val_accuracy: 1.0000\n",
      "Epoch 421/600\n",
      "2/2 [==============================] - 0s 8ms/step loss: 1.0564e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 92ms/step - loss: 1.0548e-07 - accuracy: 1.0000 - val_loss: 5.8516e-08 - val_accuracy: 1.0000\n",
      "Epoch 422/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.8826e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 1.8777e-07 - accuracy: 1.0000 - val_loss: 5.8788e-08 - val_accuracy: 1.0000\n",
      "Epoch 423/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.2425e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 2s 181ms/step - loss: 1.2357e-07 - accuracy: 1.0000 - val_loss: 5.7699e-08 - val_accuracy: 1.0000\n",
      "Epoch 424/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.1820e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 1.1894e-07 - accuracy: 1.0000 - val_loss: 5.7155e-08 - val_accuracy: 1.0000\n",
      "Epoch 425/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.3938e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 2.7860e-07 - accuracy: 1.0000 - val_loss: 3.6307e-07 - val_accuracy: 1.0000\n",
      "Epoch 426/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 3.3369e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 3.3180e-07 - accuracy: 1.0000 - val_loss: 2.3325e-07 - val_accuracy: 1.0000\n",
      "Epoch 427/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 3.6258e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 3.3797e-07 - accuracy: 1.0000 - val_loss: 1.5241e-07 - val_accuracy: 1.0000\n",
      "Epoch 428/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 3.8663e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 3.7262e-07 - accuracy: 1.0000 - val_loss: 1.0778e-07 - val_accuracy: 1.0000\n",
      "Epoch 429/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 2.1687e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 2.1505e-07 - accuracy: 1.0000 - val_loss: 9.2537e-08 - val_accuracy: 1.0000\n",
      "Epoch 430/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 2.5162e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 2.4960e-07 - accuracy: 1.0000 - val_loss: 7.8656e-08 - val_accuracy: 1.0000\n",
      "Epoch 431/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 2.9132e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 2.8906e-07 - accuracy: 1.0000 - val_loss: 6.5592e-08 - val_accuracy: 1.0000\n",
      "Epoch 432/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.8917e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 1.8813e-07 - accuracy: 1.0000 - val_loss: 6.0149e-08 - val_accuracy: 1.0000\n",
      "Epoch 433/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 1.6167e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 1.6040e-07 - accuracy: 1.0000 - val_loss: 5.7699e-08 - val_accuracy: 1.0000\n",
      "Epoch 434/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.8497e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 2.8497e-07 - accuracy: 1.0000 - val_loss: 5.4433e-08 - val_accuracy: 1.0000\n",
      "Epoch 435/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.3461e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.3348e-07 - accuracy: 1.0000 - val_loss: 5.3345e-08 - val_accuracy: 1.0000\n",
      "Epoch 436/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.8954e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 1.8850e-07 - accuracy: 1.0000 - val_loss: 5.0623e-08 - val_accuracy: 1.0000\n",
      "Epoch 437/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.2755e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 1.2748e-07 - accuracy: 1.0000 - val_loss: 4.8174e-08 - val_accuracy: 1.0000\n",
      "Epoch 438/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 1.2939e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 1.2894e-07 - accuracy: 1.0000 - val_loss: 4.7901e-08 - val_accuracy: 1.0000\n",
      "Epoch 439/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.3269e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 1.3158e-07 - accuracy: 1.0000 - val_loss: 4.7085e-08 - val_accuracy: 1.0000\n",
      "Epoch 440/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.3324e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 1.3276e-07 - accuracy: 1.0000 - val_loss: 4.5180e-08 - val_accuracy: 1.0000\n",
      "Epoch 441/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.1948e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 1.1875e-07 - accuracy: 1.0000 - val_loss: 4.4363e-08 - val_accuracy: 1.0000\n",
      "Epoch 442/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 6.9967e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 7.0925e-08 - accuracy: 1.0000 - val_loss: 4.4091e-08 - val_accuracy: 1.0000\n",
      "Epoch 443/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.4718e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 1.4740e-07 - accuracy: 1.0000 - val_loss: 4.3002e-08 - val_accuracy: 1.0000\n",
      "Epoch 444/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 2.9563e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 2.9314e-07 - accuracy: 1.0000 - val_loss: 4.2458e-08 - val_accuracy: 1.0000\n",
      "Epoch 445/600\n",
      "2/2 [==============================] - 0s 8ms/step loss: 1.6202e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 1.6213e-07 - accuracy: 1.0000 - val_loss: 4.1914e-08 - val_accuracy: 1.0000\n",
      "Epoch 446/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.1355e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 1.1293e-07 - accuracy: 1.0000 - val_loss: 4.1642e-08 - val_accuracy: 1.0000\n",
      "Epoch 447/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.1783e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 1.1703e-07 - accuracy: 1.0000 - val_loss: 4.1369e-08 - val_accuracy: 1.0000\n",
      "Epoch 448/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 9.0400e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 1.1830e-07 - accuracy: 1.0000 - val_loss: 4.1097e-08 - val_accuracy: 1.0000\n",
      "Epoch 449/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 1.0463e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 1.0393e-07 - accuracy: 1.0000 - val_loss: 4.0553e-08 - val_accuracy: 1.0000\n",
      "Epoch 450/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 3.3357e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 3.3368e-07 - accuracy: 1.0000 - val_loss: 4.0009e-08 - val_accuracy: 1.0000\n",
      "Epoch 451/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.0995e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.0912e-07 - accuracy: 1.0000 - val_loss: 4.0009e-08 - val_accuracy: 1.0000\n",
      "Epoch 452/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 9.3658e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 9.3658e-08 - accuracy: 1.0000 - val_loss: 4.0281e-08 - val_accuracy: 1.0000\n",
      "Epoch 453/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.1176e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 1.0712e-07 - accuracy: 1.0000 - val_loss: 4.0009e-08 - val_accuracy: 1.0000\n",
      "Epoch 454/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.0729e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 1.0639e-07 - accuracy: 1.0000 - val_loss: 4.0009e-08 - val_accuracy: 1.0000\n",
      "Epoch 455/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.1820e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 1.1766e-07 - accuracy: 1.0000 - val_loss: 3.9192e-08 - val_accuracy: 1.0000\n",
      "Epoch 456/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 8.9506e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 9.1384e-08 - accuracy: 1.0000 - val_loss: 3.9192e-08 - val_accuracy: 1.0000\n",
      "Epoch 457/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.0649e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.0875e-07 - accuracy: 1.0000 - val_loss: 3.9192e-08 - val_accuracy: 1.0000\n",
      "Epoch 458/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.3452e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 1.3467e-07 - accuracy: 1.0000 - val_loss: 3.8920e-08 - val_accuracy: 1.0000\n",
      "Epoch 459/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.3133e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 103ms/step - loss: 1.2867e-07 - accuracy: 1.0000 - val_loss: 3.8920e-08 - val_accuracy: 1.0000\n",
      "Epoch 460/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.1682e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.1648e-07 - accuracy: 1.0000 - val_loss: 3.8920e-08 - val_accuracy: 1.0000\n",
      "Epoch 461/600\n",
      "2/2 [==============================] - 0s 4ms/step loss: 1.0820e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 1.0984e-07 - accuracy: 1.0000 - val_loss: 3.8376e-08 - val_accuracy: 1.0000\n",
      "Epoch 462/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.0674e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 1.0602e-07 - accuracy: 1.0000 - val_loss: 3.7831e-08 - val_accuracy: 1.0000\n",
      "Epoch 463/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 9.4909e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 9.4203e-08 - accuracy: 1.0000 - val_loss: 3.7559e-08 - val_accuracy: 1.0000\n",
      "Epoch 464/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.4369e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 1.4276e-07 - accuracy: 1.0000 - val_loss: 3.8376e-08 - val_accuracy: 1.0000\n",
      "Epoch 465/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.2199e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 1.2357e-07 - accuracy: 1.0000 - val_loss: 3.8103e-08 - val_accuracy: 1.0000\n",
      "Epoch 466/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 9.0782e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 9.0021e-08 - accuracy: 1.0000 - val_loss: 3.7831e-08 - val_accuracy: 1.0000\n",
      "Epoch 467/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.1812e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 1.1148e-07 - accuracy: 1.0000 - val_loss: 3.7287e-08 - val_accuracy: 1.0000\n",
      "Epoch 468/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 9.5112e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 9.5112e-08 - accuracy: 1.0000 - val_loss: 3.7559e-08 - val_accuracy: 1.0000\n",
      "Epoch 469/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.1169e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 1.1321e-07 - accuracy: 1.0000 - val_loss: 3.7015e-08 - val_accuracy: 1.0000\n",
      "Epoch 470/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.0518e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 92ms/step - loss: 1.0439e-07 - accuracy: 1.0000 - val_loss: 3.6743e-08 - val_accuracy: 1.0000\n",
      "Epoch 471/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 9.4374e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 9.3294e-08 - accuracy: 1.0000 - val_loss: 3.5926e-08 - val_accuracy: 1.0000\n",
      "Epoch 472/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.4903e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.4903e-07 - accuracy: 1.0000 - val_loss: 3.4837e-08 - val_accuracy: 1.0000\n",
      "Epoch 473/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.3103e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 1.2230e-07 - accuracy: 1.0000 - val_loss: 3.5110e-08 - val_accuracy: 1.0000\n",
      "Epoch 474/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.0600e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 1.0548e-07 - accuracy: 1.0000 - val_loss: 3.5654e-08 - val_accuracy: 1.0000\n",
      "Epoch 475/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.8275e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 1.8131e-07 - accuracy: 1.0000 - val_loss: 3.4837e-08 - val_accuracy: 1.0000\n",
      "Epoch 476/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 6.0559e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 6.0559e-08 - accuracy: 1.0000 - val_loss: 3.4837e-08 - val_accuracy: 1.0000\n",
      "Epoch 477/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 9.0996e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 9.0839e-08 - accuracy: 1.0000 - val_loss: 3.5382e-08 - val_accuracy: 1.0000\n",
      "Epoch 478/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 7.0058e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 6.9743e-08 - accuracy: 1.0000 - val_loss: 3.5382e-08 - val_accuracy: 1.0000\n",
      "Epoch 479/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 9.2158e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 9.2385e-08 - accuracy: 1.0000 - val_loss: 3.5382e-08 - val_accuracy: 1.0000\n",
      "Epoch 480/600\n",
      "2/2 [==============================] - 0s 9ms/step loss: 1.1563e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 1.1466e-07 - accuracy: 1.0000 - val_loss: 3.5110e-08 - val_accuracy: 1.0000\n",
      "Epoch 481/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 6.7750e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 6.9470e-08 - accuracy: 1.0000 - val_loss: 3.5110e-08 - val_accuracy: 1.0000\n",
      "Epoch 482/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 8.3538e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 8.4565e-08 - accuracy: 1.0000 - val_loss: 3.5110e-08 - val_accuracy: 1.0000\n",
      "Epoch 483/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.7881e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 1.7768e-07 - accuracy: 1.0000 - val_loss: 3.5110e-08 - val_accuracy: 1.0000\n",
      "Epoch 484/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 7.1426e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 7.0198e-08 - accuracy: 1.0000 - val_loss: 3.4565e-08 - val_accuracy: 1.0000\n",
      "Epoch 485/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.7881e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.7740e-07 - accuracy: 1.0000 - val_loss: 3.4021e-08 - val_accuracy: 1.0000\n",
      "Epoch 486/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 7.4276e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 7.3835e-08 - accuracy: 1.0000 - val_loss: 3.3204e-08 - val_accuracy: 1.0000\n",
      "Epoch 487/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 9.0507e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 9.1294e-08 - accuracy: 1.0000 - val_loss: 3.3204e-08 - val_accuracy: 1.0000\n",
      "Epoch 488/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.0719e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 1.0193e-07 - accuracy: 1.0000 - val_loss: 3.2932e-08 - val_accuracy: 1.0000\n",
      "Epoch 489/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 9.8668e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 9.7840e-08 - accuracy: 1.0000 - val_loss: 3.2660e-08 - val_accuracy: 1.0000\n",
      "Epoch 490/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 9.1791e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 103ms/step - loss: 9.0202e-08 - accuracy: 1.0000 - val_loss: 3.2388e-08 - val_accuracy: 1.0000\n",
      "Epoch 491/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 9.7476e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 9.8568e-08 - accuracy: 1.0000 - val_loss: 3.2660e-08 - val_accuracy: 1.0000\n",
      "Epoch 492/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 9.0324e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 9.0930e-08 - accuracy: 1.0000 - val_loss: 3.2388e-08 - val_accuracy: 1.0000\n",
      "Epoch 493/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 7.6477e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 7.6199e-08 - accuracy: 1.0000 - val_loss: 3.2388e-08 - val_accuracy: 1.0000\n",
      "Epoch 494/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 9.4634e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 9.8750e-08 - accuracy: 1.0000 - val_loss: 3.1571e-08 - val_accuracy: 1.0000\n",
      "Epoch 495/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.0710e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 1.0630e-07 - accuracy: 1.0000 - val_loss: 3.1299e-08 - val_accuracy: 1.0000\n",
      "Epoch 496/600\n",
      "2/2 [==============================] - 0s 4ms/step loss: 1.1453e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 1.1366e-07 - accuracy: 1.0000 - val_loss: 3.1027e-08 - val_accuracy: 1.0000\n",
      "Epoch 497/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 6.8408e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 6.7834e-08 - accuracy: 1.0000 - val_loss: 3.0755e-08 - val_accuracy: 1.0000\n",
      "Epoch 498/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 9.3976e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 9.6113e-08 - accuracy: 1.0000 - val_loss: 3.0483e-08 - val_accuracy: 1.0000\n",
      "Epoch 499/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 7.6477e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 7.7290e-08 - accuracy: 1.0000 - val_loss: 3.0483e-08 - val_accuracy: 1.0000\n",
      "Epoch 500/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 9.0049e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 8.9384e-08 - accuracy: 1.0000 - val_loss: 3.0483e-08 - val_accuracy: 1.0000\n",
      "Epoch 501/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 8.6839e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 8.6383e-08 - accuracy: 1.0000 - val_loss: 3.0483e-08 - val_accuracy: 1.0000\n",
      "Epoch 502/600\n",
      "2/2 [==============================] - 0s 4ms/step loss: 1.2737e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 1.2630e-07 - accuracy: 1.0000 - val_loss: 3.0755e-08 - val_accuracy: 1.0000\n",
      "Epoch 503/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 7.3359e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 7.6927e-08 - accuracy: 1.0000 - val_loss: 3.0755e-08 - val_accuracy: 1.0000\n",
      "Epoch 504/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 7.8219e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 7.8291e-08 - accuracy: 1.0000 - val_loss: 3.1027e-08 - val_accuracy: 1.0000\n",
      "Epoch 505/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 7.2626e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 7.4472e-08 - accuracy: 1.0000 - val_loss: 3.0483e-08 - val_accuracy: 1.0000\n",
      "Epoch 506/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.0361e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.0084e-07 - accuracy: 1.0000 - val_loss: 3.0755e-08 - val_accuracy: 1.0000\n",
      "Epoch 507/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 9.8760e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 9.9750e-08 - accuracy: 1.0000 - val_loss: 3.0755e-08 - val_accuracy: 1.0000\n",
      "Epoch 508/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 6.5932e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 6.5470e-08 - accuracy: 1.0000 - val_loss: 3.0483e-08 - val_accuracy: 1.0000\n",
      "Epoch 509/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 8.7817e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 8.6202e-08 - accuracy: 1.0000 - val_loss: 3.0211e-08 - val_accuracy: 1.0000\n",
      "Epoch 510/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 7.4827e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 7.4199e-08 - accuracy: 1.0000 - val_loss: 3.0211e-08 - val_accuracy: 1.0000\n",
      "Epoch 511/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 9.3976e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.0020e-07 - accuracy: 1.0000 - val_loss: 3.0211e-08 - val_accuracy: 1.0000\n",
      "Epoch 512/600\n",
      "2/2 [==============================] - 0s 8ms/step loss: 1.5745e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 1.5613e-07 - accuracy: 1.0000 - val_loss: 2.9938e-08 - val_accuracy: 1.0000\n",
      "Epoch 513/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 7.5560e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 7.5563e-08 - accuracy: 1.0000 - val_loss: 2.9938e-08 - val_accuracy: 1.0000\n",
      "Epoch 514/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.4333e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 1.4212e-07 - accuracy: 1.0000 - val_loss: 2.9394e-08 - val_accuracy: 1.0000\n",
      "Epoch 515/600\n",
      "2/2 [==============================] - 0s 8ms/step loss: 5.5631e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 5.9014e-08 - accuracy: 1.0000 - val_loss: 2.9666e-08 - val_accuracy: 1.0000\n",
      "Epoch 516/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 7.0241e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 6.9743e-08 - accuracy: 1.0000 - val_loss: 2.9122e-08 - val_accuracy: 1.0000\n",
      "Epoch 517/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 9.8760e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 9.8022e-08 - accuracy: 1.0000 - val_loss: 2.9122e-08 - val_accuracy: 1.0000\n",
      "Epoch 518/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 9.3625e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 9.5022e-08 - accuracy: 1.0000 - val_loss: 2.8578e-08 - val_accuracy: 1.0000\n",
      "Epoch 519/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 4.6033e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 4.5647e-08 - accuracy: 1.0000 - val_loss: 2.8850e-08 - val_accuracy: 1.0000\n",
      "Epoch 520/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 6.5863e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 6.8834e-08 - accuracy: 1.0000 - val_loss: 2.8850e-08 - val_accuracy: 1.0000\n",
      "Epoch 521/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 8.7481e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 9.5476e-08 - accuracy: 1.0000 - val_loss: 2.8850e-08 - val_accuracy: 1.0000\n",
      "Epoch 522/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 7.1227e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 6.9561e-08 - accuracy: 1.0000 - val_loss: 2.9122e-08 - val_accuracy: 1.0000\n",
      "Epoch 523/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 7.1709e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 7.1107e-08 - accuracy: 1.0000 - val_loss: 2.8850e-08 - val_accuracy: 1.0000\n",
      "Epoch 524/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 8.9040e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 8.8747e-08 - accuracy: 1.0000 - val_loss: 2.9122e-08 - val_accuracy: 1.0000\n",
      "Epoch 525/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 9.4267e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 9.3476e-08 - accuracy: 1.0000 - val_loss: 2.9122e-08 - val_accuracy: 1.0000\n",
      "Epoch 526/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 6.6574e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 6.6015e-08 - accuracy: 1.0000 - val_loss: 2.9122e-08 - val_accuracy: 1.0000\n",
      "Epoch 527/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 7.6492e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 7.9655e-08 - accuracy: 1.0000 - val_loss: 2.9122e-08 - val_accuracy: 1.0000\n",
      "Epoch 528/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.0866e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.0821e-07 - accuracy: 1.0000 - val_loss: 2.8578e-08 - val_accuracy: 1.0000\n",
      "Epoch 529/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 8.6472e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 8.5928e-08 - accuracy: 1.0000 - val_loss: 2.8578e-08 - val_accuracy: 1.0000\n",
      "Epoch 530/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.5665e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 1.5330e-07 - accuracy: 1.0000 - val_loss: 2.8850e-08 - val_accuracy: 1.0000\n",
      "Epoch 531/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 6.5015e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 6.4833e-08 - accuracy: 1.0000 - val_loss: 2.8850e-08 - val_accuracy: 1.0000\n",
      "Epoch 532/600\n",
      "2/2 [==============================] - 0s 8ms/step loss: 6.1194e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 6.3469e-08 - accuracy: 1.0000 - val_loss: 2.8578e-08 - val_accuracy: 1.0000\n",
      "Epoch 533/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.0325e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 1.0284e-07 - accuracy: 1.0000 - val_loss: 2.8305e-08 - val_accuracy: 1.0000\n",
      "Epoch 534/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.0490e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 1.0402e-07 - accuracy: 1.0000 - val_loss: 2.7761e-08 - val_accuracy: 1.0000\n",
      "Epoch 535/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 6.8774e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 6.8197e-08 - accuracy: 1.0000 - val_loss: 2.7761e-08 - val_accuracy: 1.0000\n",
      "Epoch 536/600\n",
      "2/2 [==============================] - 0s 4ms/step loss: 7.7119e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 7.6563e-08 - accuracy: 1.0000 - val_loss: 2.7489e-08 - val_accuracy: 1.0000\n",
      "Epoch 537/600\n",
      "2/2 [==============================] - 0s 4ms/step loss: 9.9769e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 9.9113e-08 - accuracy: 1.0000 - val_loss: 2.7761e-08 - val_accuracy: 1.0000\n",
      "Epoch 538/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 7.1250e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 7.0653e-08 - accuracy: 1.0000 - val_loss: 2.7761e-08 - val_accuracy: 1.0000\n",
      "Epoch 539/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 7.1617e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 103ms/step - loss: 7.1016e-08 - accuracy: 1.0000 - val_loss: 2.7761e-08 - val_accuracy: 1.0000\n",
      "Epoch 540/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 6.8591e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 6.8561e-08 - accuracy: 1.0000 - val_loss: 2.7489e-08 - val_accuracy: 1.0000\n",
      "Epoch 541/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 9.2066e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 9.1384e-08 - accuracy: 1.0000 - val_loss: 2.6945e-08 - val_accuracy: 1.0000\n",
      "Epoch 542/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 7.3910e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 7.3380e-08 - accuracy: 1.0000 - val_loss: 2.6945e-08 - val_accuracy: 1.0000\n",
      "Epoch 543/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.5103e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 1.5058e-07 - accuracy: 1.0000 - val_loss: 2.6945e-08 - val_accuracy: 1.0000\n",
      "Epoch 544/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 7.8678e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 7.8018e-08 - accuracy: 1.0000 - val_loss: 2.6945e-08 - val_accuracy: 1.0000\n",
      "Epoch 545/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.0417e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 1.0457e-07 - accuracy: 1.0000 - val_loss: 2.6672e-08 - val_accuracy: 1.0000\n",
      "Epoch 546/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 5.8468e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 5.8468e-08 - accuracy: 1.0000 - val_loss: 2.6672e-08 - val_accuracy: 1.0000\n",
      "Epoch 547/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.4323e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 109ms/step - loss: 1.4276e-07 - accuracy: 1.0000 - val_loss: 2.6945e-08 - val_accuracy: 1.0000\n",
      "Epoch 548/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 9.1607e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 9.0839e-08 - accuracy: 1.0000 - val_loss: 2.6945e-08 - val_accuracy: 1.0000\n",
      "Epoch 549/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.2616e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.1848e-07 - accuracy: 1.0000 - val_loss: 2.6672e-08 - val_accuracy: 1.0000\n",
      "Epoch 550/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 7.7883e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 3s 197ms/step - loss: 7.3744e-08 - accuracy: 1.0000 - val_loss: 2.6672e-08 - val_accuracy: 1.0000\n",
      "Epoch 551/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 6.6757e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 6.6379e-08 - accuracy: 1.0000 - val_loss: 2.6128e-08 - val_accuracy: 1.0000\n",
      "Epoch 552/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 8.9682e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 8.8929e-08 - accuracy: 1.0000 - val_loss: 2.6400e-08 - val_accuracy: 1.0000\n",
      "Epoch 553/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 8.4822e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 8.4110e-08 - accuracy: 1.0000 - val_loss: 2.6400e-08 - val_accuracy: 1.0000\n",
      "Epoch 554/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 2.6671e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 2s 116ms/step - loss: 2.4458e-07 - accuracy: 1.0000 - val_loss: 2.7761e-08 - val_accuracy: 1.0000\n",
      "Epoch 555/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 9.6062e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 1.1739e-07 - accuracy: 1.0000 - val_loss: 2.8305e-08 - val_accuracy: 1.0000\n",
      "Epoch 556/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 9.0324e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 9.3112e-08 - accuracy: 1.0000 - val_loss: 2.7489e-08 - val_accuracy: 1.0000\n",
      "Epoch 557/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 9.3717e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 9.4021e-08 - accuracy: 1.0000 - val_loss: 2.6128e-08 - val_accuracy: 1.0000\n",
      "Epoch 558/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 8.5110e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 8.5110e-08 - accuracy: 1.0000 - val_loss: 2.6128e-08 - val_accuracy: 1.0000\n",
      "Epoch 559/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 7.4001e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 7.3562e-08 - accuracy: 1.0000 - val_loss: 2.6128e-08 - val_accuracy: 1.0000\n",
      "Epoch 560/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 6.0995e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 6.5833e-08 - accuracy: 1.0000 - val_loss: 2.5856e-08 - val_accuracy: 1.0000\n",
      "Epoch 561/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 5.2911e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 5.2830e-08 - accuracy: 1.0000 - val_loss: 2.6128e-08 - val_accuracy: 1.0000\n",
      "Epoch 562/600\n",
      "2/2 [==============================] - 0s 4ms/step loss: 7.7761e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 7.7472e-08 - accuracy: 1.0000 - val_loss: 2.5856e-08 - val_accuracy: 1.0000\n",
      "Epoch 563/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 6.2906e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 6.8106e-08 - accuracy: 1.0000 - val_loss: 2.5039e-08 - val_accuracy: 1.0000\n",
      "Epoch 564/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 7.4460e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 7.4926e-08 - accuracy: 1.0000 - val_loss: 2.4767e-08 - val_accuracy: 1.0000\n",
      "Epoch 565/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.1123e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.1066e-07 - accuracy: 1.0000 - val_loss: 2.4767e-08 - val_accuracy: 1.0000\n",
      "Epoch 566/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 8.7848e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 8.8020e-08 - accuracy: 1.0000 - val_loss: 2.4767e-08 - val_accuracy: 1.0000\n",
      "Epoch 567/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.0710e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 1.0657e-07 - accuracy: 1.0000 - val_loss: 2.4223e-08 - val_accuracy: 1.0000\n",
      "Epoch 568/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 6.1163e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 6.0741e-08 - accuracy: 1.0000 - val_loss: 2.3679e-08 - val_accuracy: 1.0000\n",
      "Epoch 569/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 1.2348e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 1.2230e-07 - accuracy: 1.0000 - val_loss: 2.3951e-08 - val_accuracy: 1.0000\n",
      "Epoch 570/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 7.0700e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 7.0198e-08 - accuracy: 1.0000 - val_loss: 2.3951e-08 - val_accuracy: 1.0000\n",
      "Epoch 571/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 7.2817e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 7.2653e-08 - accuracy: 1.0000 - val_loss: 2.3951e-08 - val_accuracy: 1.0000\n",
      "Epoch 572/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 1.1847e-07 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 1.1939e-07 - accuracy: 1.0000 - val_loss: 2.4223e-08 - val_accuracy: 1.0000\n",
      "Epoch 573/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 7.2618e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 6.9198e-08 - accuracy: 1.0000 - val_loss: 2.3951e-08 - val_accuracy: 1.0000\n",
      "Epoch 574/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 5.3919e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 5.5104e-08 - accuracy: 1.0000 - val_loss: 2.3951e-08 - val_accuracy: 1.0000\n",
      "Epoch 575/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 8.3347e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 7.7654e-08 - accuracy: 1.0000 - val_loss: 2.3951e-08 - val_accuracy: 1.0000\n",
      "Epoch 576/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 9.1882e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 9.1111e-08 - accuracy: 1.0000 - val_loss: 2.3951e-08 - val_accuracy: 1.0000\n",
      "Epoch 577/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 6.3823e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 6.3469e-08 - accuracy: 1.0000 - val_loss: 2.4223e-08 - val_accuracy: 1.0000\n",
      "Epoch 578/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 9.9218e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 9.8477e-08 - accuracy: 1.0000 - val_loss: 2.4223e-08 - val_accuracy: 1.0000\n",
      "Epoch 579/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 7.5927e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 7.5381e-08 - accuracy: 1.0000 - val_loss: 2.3951e-08 - val_accuracy: 1.0000\n",
      "Epoch 580/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 5.9421e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 5.8923e-08 - accuracy: 1.0000 - val_loss: 2.4223e-08 - val_accuracy: 1.0000\n",
      "Epoch 581/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 7.3084e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 7.3289e-08 - accuracy: 1.0000 - val_loss: 2.3951e-08 - val_accuracy: 1.0000\n",
      "Epoch 582/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 4.8601e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 4.8193e-08 - accuracy: 1.0000 - val_loss: 2.3951e-08 - val_accuracy: 1.0000\n",
      "Epoch 583/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 4.3282e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 4.2919e-08 - accuracy: 1.0000 - val_loss: 2.3951e-08 - val_accuracy: 1.0000\n",
      "Epoch 584/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 8.3655e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 8.3655e-08 - accuracy: 1.0000 - val_loss: 2.4223e-08 - val_accuracy: 1.0000\n",
      "Epoch 585/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 8.0328e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 8.0745e-08 - accuracy: 1.0000 - val_loss: 2.3406e-08 - val_accuracy: 1.0000\n",
      "Epoch 586/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 9.7751e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 9.7385e-08 - accuracy: 1.0000 - val_loss: 2.3134e-08 - val_accuracy: 1.0000\n",
      "Epoch 587/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 7.7486e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 7.6836e-08 - accuracy: 1.0000 - val_loss: 2.3134e-08 - val_accuracy: 1.0000\n",
      "Epoch 588/600\n",
      "2/2 [==============================] - 0s 8ms/step loss: 5.4011e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 5.3558e-08 - accuracy: 1.0000 - val_loss: 2.3134e-08 - val_accuracy: 1.0000\n",
      "Epoch 589/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 8.4638e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 8.4019e-08 - accuracy: 1.0000 - val_loss: 2.3134e-08 - val_accuracy: 1.0000\n",
      "Epoch 590/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 8.3813e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 8.5656e-08 - accuracy: 1.0000 - val_loss: 2.3134e-08 - val_accuracy: 1.0000\n",
      "Epoch 591/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 4.5758e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 4.5556e-08 - accuracy: 1.0000 - val_loss: 2.3134e-08 - val_accuracy: 1.0000\n",
      "Epoch 592/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 8.5647e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 8.4929e-08 - accuracy: 1.0000 - val_loss: 2.3134e-08 - val_accuracy: 1.0000\n",
      "Epoch 593/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 9.4266e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 9.6839e-08 - accuracy: 1.0000 - val_loss: 2.2590e-08 - val_accuracy: 1.0000\n",
      "Epoch 594/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 5.9329e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 5.8923e-08 - accuracy: 1.0000 - val_loss: 2.2862e-08 - val_accuracy: 1.0000\n",
      "Epoch 595/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 8.5555e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 8.5019e-08 - accuracy: 1.0000 - val_loss: 2.2862e-08 - val_accuracy: 1.0000\n",
      "Epoch 596/600\n",
      "2/2 [==============================] - 0s 7ms/step loss: 5.4744e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 5.4558e-08 - accuracy: 1.0000 - val_loss: 2.2862e-08 - val_accuracy: 1.0000\n",
      "Epoch 597/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 8.3446e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 7.8836e-08 - accuracy: 1.0000 - val_loss: 2.2590e-08 - val_accuracy: 1.0000\n",
      "Epoch 598/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 5.9421e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 5.9195e-08 - accuracy: 1.0000 - val_loss: 2.2590e-08 - val_accuracy: 1.0000\n",
      "Epoch 599/600\n",
      "2/2 [==============================] - 0s 5ms/step loss: 6.0155e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 6.0286e-08 - accuracy: 1.0000 - val_loss: 2.2318e-08 - val_accuracy: 1.0000\n",
      "Epoch 600/600\n",
      "2/2 [==============================] - 0s 6ms/step loss: 7.5927e-08 - accuracy: 1.00\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 7.5290e-08 - accuracy: 1.0000 - val_loss: 2.2590e-08 - val_accuracy: 1.0000\n",
      "Accuracy: 43.59%\n"
     ]
    }
   ],
   "source": [
    "early_stop=tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=300, verbose=2, mode='auto', baseline=None, restore_best_weights=True)\n",
    "model.fit(X_train_def, y_train_def, epochs=600, batch_size=100, callbacks=[tensorboard_callback,cm_callback,early_stop], validation_data=(X_val_def, y_val_def))\n",
    "# Final evaluation of the model \n",
    "scores = model.evaluate(X_test_def, y_test_def, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step\n",
      "(39, 2)\n",
      "(39,)\n",
      "(39,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 0\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "#y_pred2=np.where(y_pred>0,1,0)\n",
    "#y_pred2=y_pred2[:,-1]\n",
    "y_test_def2=np.argmax(y_test_def,axis=1)\n",
    "#y_test_def2=np.where(y_test_def>0,1,0)\n",
    "print(y_pred.shape)\n",
    "print(y_pred2.shape)\n",
    "print(y_test_def2.shape)\n",
    "#print(y_test_def[25])\n",
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#docs_infra: no_execute\n",
    "if numero_clases==2:\n",
    "    classes = [0, 1]\n",
    "else:   \n",
    "    classes = [0, 1, 2, 3, 4]\n",
    "#classes = [0, 1]\n",
    "cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Buenos     0.6522    0.5172    0.5769        29\n",
      "       Malos     0.1250    0.2000    0.1538        10\n",
      "\n",
      "    accuracy                         0.4359        39\n",
      "   macro avg     0.3886    0.3586    0.3654        39\n",
      "weighted avg     0.5170    0.4359    0.4684        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "if numero_clases==2:\n",
    "    target_names = ['Buenos', 'Malos']\n",
    "else:   \n",
    "    target_names = ['A', 'B+', 'B', 'B-','C']\n",
    "print(classification_report(y_test_def2, y_pred2, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('modelos/modelote1203_200')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea/experimentos_software_2024/envs/tensorflow_2024/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "#model.save('idea.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "model.save('modelos\\modelo_perfecto_{}_{}.h5'.format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#este modo de guardar no funciona en esta version de tensorflow\n",
    "#model.save('modelos\\modelo_perfecto_{}_{}'.format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step\n",
      "[0 0 0 0 1 0 0 0 1]\n",
      "[0 0 0 0 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "n = len(y_pred2)\n",
    "reshaped = y_pred2[:n//4*4].reshape(-1, 4)\n",
    "mean_values = reshaped.mean(axis=1)\n",
    "\n",
    "mean_values = np.round(mean_values)\n",
    "mean_values = np.clip(mean_values, 0, 4)\n",
    "mean_values = mean_values.astype(int)\n",
    "print(mean_values)\n",
    "\n",
    "mode_values = stats.mode(reshaped, axis=1)[0]\n",
    "print(mode_values)\n",
    "\n",
    "# Convierte los arrays a DataFrames\n",
    "mean_df = pd.DataFrame(mean_values, columns=['mean'])\n",
    "mode_df = pd.DataFrame(mode_values, columns=['mode'])\n",
    "\n",
    "# Guarda los DataFrames en archivos Excel\n",
    "mean_df.to_excel(\"excels_borrar\\clasificacion_P1P2_mean_best7.xlsx\", index=False)\n",
    "mode_df.to_excel(\"excels_borrar\\clasificacion_P1_mode_best7.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 0\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'No object named data/pollos_estado in the file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m filename5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOPIA_PANDAS\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlomosP1_20240430_clasificado_experto.hdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mHDFStore(filename5,complib\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzlib\u001b[39m\u001b[38;5;124m\"\u001b[39m,complevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m hdf_db:\n\u001b[0;32m----> 3\u001b[0m     pre_p_e2  \u001b[38;5;241m=\u001b[39m \u001b[43mhdf_db\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/pollos_estado\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     pre_p_e2 \u001b[38;5;241m=\u001b[39m pre_p_e2\u001b[38;5;241m.\u001b[39mloc[pre_p_e2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPollo\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m     pre_p_e2 \u001b[38;5;241m=\u001b[39mpre_p_e2\u001b[38;5;241m.\u001b[39mdrop_duplicates(subset \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPollo\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedida\u001b[39m\u001b[38;5;124m'\u001b[39m],  keep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/experimentos_software_2024/envs/tensorflow_2024/lib/python3.11/site-packages/pandas/io/pytables.py:812\u001b[0m, in \u001b[0;36mHDFStore.get\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    810\u001b[0m group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_node(key)\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo object named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in the file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_group(group)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'No object named data/pollos_estado in the file'"
     ]
    }
   ],
   "source": [
    "filename5 = \"COPIA_PANDAS\\lomosP1_20240430_clasificado_experto.hdf\"\n",
    "with pd.HDFStore(filename5,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e2  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e2 = pre_p_e2.loc[pre_p_e2['Pollo'] != 0]\n",
    "    pre_p_e2 =pre_p_e2.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_test2=np.zeros((pre_p_e2.shape[0],220,8))\n",
    "    y_test2=np.zeros((pre_p_e2.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e2.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1:\n",
    "                target = 0 \n",
    "            else:\n",
    "                target = 1\n",
    "\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_test2[x]=pepito[:,3:11]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_test2[x]=target\n",
    "        y_test2_to_categorical = to_categorical(y_test2)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_test2_filtrado = X_test2\n",
    "#y_train_filtrado = y_train\n",
    "y_test2_filtrado = y_test2_to_categorical\n",
    "\n",
    "print(X_test2_filtrado.shape)\n",
    "print(y_test2_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "# concatenamos train y test\n",
    "#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\n",
    "data_2d_test = X_test2_filtrado.reshape(-1, X_test2_filtrado.shape[-1])\n",
    "normalized_data_2d_test = scaler.transform(data_2d_test)\n",
    "\n",
    "\n",
    "X_test2_def=normalized_data_2d_test.reshape(X_test2_filtrado.shape) \n",
    "# la alternativa es normalizar con el total\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "\n",
    "y_test2_def=y_test2_filtrado # los valores ya estaban normalizados\n",
    "\n",
    "print(y_test2_def.shape)\n",
    "\n",
    "print(y_test2_filtrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# # Crear un nuevo modelo con la misma arquitectura\n",
    "# best_val_model = create_model()  # Reemplaza esto con la función que usaste para crear el modelo original\n",
    "\n",
    "# # Cargar los mejores pesos\n",
    "# best_val_model.load_weights('best_weights.h5')\n",
    "\n",
    "y_pred = model.predict(X_test2_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "n = len(y_pred2)\n",
    "print(n)\n",
    "reshaped = y_pred2[:n//4*4].reshape(-1, 4)\n",
    "mean_values = reshaped.mean(axis=1)\n",
    "\n",
    "mean_values = np.round(mean_values)\n",
    "mean_values = np.clip(mean_values, 0, 4)\n",
    "mean_values = mean_values.astype(int)\n",
    "print(mean_values.shape)\n",
    "\n",
    "mode_values = stats.mode(reshaped, axis=1)[0]\n",
    "print(mode_values.shape)\n",
    "\n",
    "n = len(y_test2_def)\n",
    "y_test2_def2=np.argmax(y_test2_def,axis=1)\n",
    "print(y_test_def2.shape)\n",
    "print(n)\n",
    "reshaped2 = y_test2_def2[:n//4*4].reshape(-1, 4)\n",
    "target_mean_values = reshaped2.mean(axis=1)\n",
    "\n",
    "target_mean_values = np.round(target_mean_values)\n",
    "target_mean_values = np.clip(target_mean_values, 0, 4)\n",
    "target_mean_values = target_mean_values.astype(int)\n",
    "print(target_mean_values.shape)\n",
    "\n",
    "target_mode_values = stats.mode(reshaped2, axis=1)[0]\n",
    "print(target_mode_values.shape)\n",
    "print(reshaped)\n",
    "print(mode_values)\n",
    "print(target_mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs_infra: no_execute\n",
    "if numero_clases==2:\n",
    "    classes = [0, 1]    \n",
    "else:\n",
    "\n",
    "    classes = [0, 1, 2, 3, 4]\n",
    "#classes = [0, 1]\n",
    "cm=confusion_matrix(target_mode_values, mode_values,labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm.diagonal()/cm.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if numero_clases==2:\n",
    "    target_names= ['Buenos', 'Malos']\n",
    "else:\n",
    "    target_names= ['A', 'B+', 'B', 'B-','C']\n",
    "print(classification_report(target_mode_values, mode_values, target_names=target_names, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow_2024_GPU)",
   "language": "python",
   "name": "tensorflow_2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
