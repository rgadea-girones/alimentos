{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:\\nuevas_investigaciones_alimentos_2024\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM,Bidirectional,GRU\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import datetime\n",
    "import io\n",
    "import itertools\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Obtener la ruta del directorio actual\n",
    "os.chdir('..')\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "# Construir la ruta relativa al directorio que quieres agregar\n",
    "relative_dir = os.path.join(current_dir, 'mis_pkgs/')\n",
    "\n",
    "# Agregar la ruta relativa al sys.path\n",
    "sys.path.insert(0, relative_dir)\n",
    "\n",
    "from MIOPATIA_db import DB_management as db \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_muestras=401\n",
    "numero_clases=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a quedarme con los 50 atunes P1 para obtener conjunto de training y validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Add, Activation, Concatenate, Conv2D, Dropout \n",
    "from tensorflow.keras.layers import Flatten, Input, GlobalAveragePooling2D, MaxPooling2D\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "__version__ = '0.0.1'\n",
    "\n",
    "\n",
    "def SqueezeNet(input_shape, nb_classes, use_bypass=False, dropout_rate=None, compression=1.0):\n",
    "    \"\"\"\n",
    "    Creating a SqueezeNet of version 1.0\n",
    "    \n",
    "    Arguments:\n",
    "        input_shape  : shape of the input images e.g. (224,224,3)\n",
    "        nb_classes   : number of classes\n",
    "        use_bypass   : if true, bypass connections will be created at fire module 3, 5, 7, and 9 (default: False)\n",
    "        dropout_rate : defines the dropout rate that is accomplished after last fire module (default: None)\n",
    "        compression  : reduce the number of feature-maps (default: 1.0)\n",
    "        \n",
    "    Returns:\n",
    "        Model        : Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(int(96*compression), (7,7), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "    x = create_fire_module(x, int(16*compression), name='fire3', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool4')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(32*compression), name='fire5', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "    x = create_fire_module(x, int(48*compression), name='fire7', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool8')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(64*compression), name='fire9', use_bypass=use_bypass)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        \n",
    "    x = output(x, nb_classes)\n",
    "\n",
    "    return Model(inputs=input_img, outputs=x)\n",
    "\n",
    "\n",
    "def SqueezeNet_11(input_shape, nb_classes, dropout_rate=None, compression=1.0):\n",
    "    \"\"\"\n",
    "    Creating a SqueezeNet of version 1.1\n",
    "    \n",
    "    2.4x less computation over SqueezeNet 1.0 implemented above.\n",
    "    \n",
    "    Arguments:\n",
    "        input_shape  : shape of the input images e.g. (224,224,3)\n",
    "        nb_classes   : number of classes\n",
    "        dropout_rate : defines the dropout rate that is accomplished after last fire module (default: None)\n",
    "        compression  : reduce the number of feature-maps\n",
    "        \n",
    "    Returns:\n",
    "        Model        : Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(int(64*compression), (3,3), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "    x = create_fire_module(x, int(16*compression), name='fire3')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool3')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "    x = create_fire_module(x, int(32*compression), name='fire5')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool5')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "    x = create_fire_module(x, int(48*compression), name='fire7')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire9')\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # Creating last conv10\n",
    "    x = output(x, nb_classes)\n",
    "\n",
    "    return Model(inputs=input_img, outputs=x)\n",
    "\n",
    "\n",
    "def output(x, nb_classes):\n",
    "    x = Conv2D(nb_classes, (1,1), strides=(1,1), padding='valid', name='conv10')(x)\n",
    "    x = GlobalAveragePooling2D(name='avgpool10')(x)\n",
    "    x = Activation(\"softmax\", name='softmax')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_fire_module(x, nb_squeeze_filter, name, use_bypass=False):\n",
    "    \"\"\"\n",
    "    Creates a fire module\n",
    "    \n",
    "    Arguments:\n",
    "        x                 : input\n",
    "        nb_squeeze_filter : number of filters of squeeze. The filtersize of expand is 4 times of squeeze\n",
    "        use_bypass        : if True then a bypass will be added\n",
    "        name              : name of module e.g. fire123\n",
    "    \n",
    "    Returns:\n",
    "        x                 : returns a fire module\n",
    "    \"\"\"\n",
    "    \n",
    "    nb_expand_filter = 4 * nb_squeeze_filter\n",
    "    squeeze    = Conv2D(nb_squeeze_filter,(1,1), activation='relu', padding='same', name='%s_squeeze'%name)(x)\n",
    "    expand_1x1 = Conv2D(nb_expand_filter, (1,1), activation='relu', padding='same', name='%s_expand_1x1'%name)(squeeze)\n",
    "    expand_3x3 = Conv2D(nb_expand_filter, (3,3), activation='relu', padding='same', name='%s_expand_3x3'%name)(squeeze)\n",
    "    \n",
    "    axis = get_axis()\n",
    "    x_ret = Concatenate(axis=axis, name='%s_concatenate'%name)([expand_1x1, expand_3x3])\n",
    "    \n",
    "    if use_bypass:\n",
    "        x_ret = Add(name='%s_concatenate_bypass'%name)([x_ret, x])\n",
    "        \n",
    "    return x_ret\n",
    "\n",
    "\n",
    "def get_axis():\n",
    "    axis = -1 if K.image_data_format() == 'channels_last' else 1\n",
    "    return axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1749, 2)\n"
     ]
    }
   ],
   "source": [
    "filename = \"COPIA_PANDAS\\hdf_28_06_atunes_agilent_clasificados.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    # p_e =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_train=np.zeros((pre_p_e1.shape[0],numero_muestras,8))\n",
    "    y_train=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1:\n",
    "                target = 0\n",
    "            else:\n",
    "                target = 1\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_train[x]=pepito[:,3:11]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_train[x]=target\n",
    "        y_train_to_categorical = to_categorical(y_train)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_train_filtrado = X_train\n",
    "#y_train_filtrado = y_train\n",
    "y_train_filtrado = y_train_to_categorical\n",
    "\n",
    "# print(X_train_filtrado.shape)\n",
    "# print(y_train_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_2d = X_train_filtrado.reshape(-1, X_train_filtrado.shape[-1])\n",
    "normalized_data_2d = scaler.fit_transform(data_2d)\n",
    "X_train_Normalizado=normalized_data_2d.reshape(X_train_filtrado.shape)\n",
    "y_train_Normalizado=y_train_filtrado # los valores ya estaban normalizados\n",
    "print(y_train_Normalizado.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 401, 8)\n",
      "(39, 2)\n",
      "[[0.02751472 0.686453   0.09733038 ... 0.313547   0.02751487 0.77267285]\n",
      " [0.02696422 0.68872074 0.09559278 ... 0.31127926 0.02696437 0.77285158]\n",
      " [0.02644687 0.69066005 0.09403642 ... 0.30933995 0.02644702 0.77300734]\n",
      " ...\n",
      " [0.00238395 0.13247365 0.04380656 ... 0.86752635 0.00238336 0.77274724]\n",
      " [0.00231064 0.1273537  0.04380684 ... 0.8726463  0.00231006 0.77279176]\n",
      " [0.00232807 0.12738025 0.04380304 ... 0.87261975 0.00232748 0.77277392]]\n"
     ]
    }
   ],
   "source": [
    "filename = \"COPIA_PANDAS\\hdf_lomosAgilent_test_filtrado_def_good.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    pre_p_e1 =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_test=np.zeros((pre_p_e1.shape[0],numero_muestras,8))\n",
    "    y_test=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1:\n",
    "                target = 0\n",
    "            else:\n",
    "                target = 1\n",
    "\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_test[x]=pepito[:,3:11]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_test[x]=target\n",
    "        y_test_to_categorical = to_categorical(y_test)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_test_filtrado = X_test\n",
    "#y_train_filtrado = y_train\n",
    "y_test_filtrado = y_test_to_categorical\n",
    "\n",
    "print(X_test_filtrado.shape)\n",
    "print(y_test_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "# concatenamos train y test\n",
    "#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\n",
    "data_2d_test = X_test_filtrado.reshape(-1, X_test_filtrado.shape[-1])\n",
    "normalized_data_2d_test = scaler.transform(data_2d_test)\n",
    "\n",
    "\n",
    "X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "# la alternativa es normalizar con el total\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "\n",
    "y_test_def=y_test_filtrado # los valores ya estaban normalizados\n",
    "print(X_test_def[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer los conjuntos de entrenamiento validacion y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide el dataset en entrenamiento y temporal (test+validación)\n",
    "# X_temp, X_test_def, y_temp, y_test_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.2, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Divide el dataset temporal en validación y test\n",
    "X_train_def, X_val_def, y_train_def, y_val_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.25, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Ahora, X_train, X_val y X_test contienen los datos de entrada para los conjuntos de entrenamiento, validación y prueba, respectivamente.\n",
    "# y_train, y_val y y_test contienen las clases correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1311, 401, 8)\n",
      "(438, 401, 8)\n",
      "(39, 401, 8)\n",
      "(1311, 2)\n",
      "(438, 2)\n",
      "(39, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_def.shape)\n",
    "print(X_val_def.shape)\n",
    "print(X_test_def.shape)\n",
    "print(y_train_def.shape)\n",
    "print(y_val_def.shape)\n",
    "print(y_test_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "\n",
    "#%tensorboard --logdir logs\n",
    "#log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"\n",
    "    Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\n",
    "    \"\"\"\n",
    "    \n",
    "    buf = io.BytesIO()\n",
    "    \n",
    "    # Use plt.savefig to save the plot to a PNG in memory.\n",
    "    plt.savefig(buf, format='png')\n",
    "    \n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    \n",
    "    # Use tf.image.decode_png to convert the PNG buffer\n",
    "    # to a TF image. Make sure you use 4 channels.\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    \n",
    "    # Use tf.expand_dims to add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "       class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    \n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    # Normalize the confusion matrix.\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    \n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    threshold = 0.5\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"red\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_aprendizaje=0.001\n",
    "dimension_LSTM=50\n",
    "dimension_dense1=200\n",
    "dimension_dense2=20\n",
    "algoritmo='rmsprop'\n",
    "supermax=8*4\n",
    "lossfunction='categorical_crossentropy'\n",
    "def create_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(GRU(dimension_LSTM, return_sequences=True,input_shape=(numero_muestras, 8)))\n",
    "    # model.add(GRU(50, return_sequences=True))\n",
    "    model.add(GRU(50, return_sequences=False))\n",
    "    model.add(Dense(dimension_dense1, activation='tanh'))\n",
    "    model.add(Dense(dimension_dense2, activation='tanh'))\n",
    "    model.add(Dense(numero_clases, activation='softmax'))\n",
    "    model.compile(loss=lossfunction, optimizer=algoritmo, metrics=['accuracy'])\n",
    "    model.optimizer.lr=(factor_aprendizaje)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "experimento=\"LOMOS_Agilent_5clases_GRU2_{}_dense1_{}_dense2_{}_loss_{}_lr_{}_algoritmo_{}\".format(dimension_LSTM,dimension_dense1,dimension_dense2,lossfunction,factor_aprendizaje,algoritmo)\n",
    "logdir=\"./logs/defs/{}_{}\".format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if numero_clases==2:\n",
    "    class_names=['Buenos', 'Malos']\n",
    "else:\n",
    "    class_names=['A', 'B+', 'B', 'B-','C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    \n",
    "    # Use the model to predict the values from the test_images.\n",
    "    y_pred = model.predict(X_test_def)\n",
    "    #y_pred1=y_pred[:,-1]\n",
    "    y_pred2=y_pred.argmax(axis=1)\n",
    "    #y_pred2=np.where(y_pred>0,1,0)\n",
    "    #y_pred2=y_pred2[:,-1]\n",
    "    if numero_clases==2:\n",
    "        classes = [0, 1]    \n",
    "    else:\n",
    "\n",
    "        classes = [0, 1, 2, 3, 4] \n",
    "    #classes = [0, 1]\n",
    "    y_test_def2=np.argmax(y_test_def,axis=1)  \n",
    "    #y_test_def2=np.where(y_test_def>0,1,0)\n",
    "    cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    figura = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figura)\n",
    "    \n",
    "    # Log the confusion matrix as an image summary.\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1749, 2)\n",
      "(438, 2)\n"
     ]
    }
   ],
   "source": [
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "print(y_train_Normalizado.shape)\n",
    "print(y_val_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un callback para guardar los mejores pesos\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('best_weights.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/400\n",
      "9/9 [==============================] - 4s 50ms/step - loss: 0.7130 - accuracy: 0.5412\n",
      "Epoch 2/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.6838 - accuracy: 0.5412\n",
      "Epoch 3/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.6636 - accuracy: 0.5870\n",
      "Epoch 4/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.6690 - accuracy: 0.6110\n",
      "Epoch 5/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.6473 - accuracy: 0.6316\n",
      "Epoch 6/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.6692 - accuracy: 0.5973\n",
      "Epoch 7/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.6478 - accuracy: 0.6350\n",
      "Epoch 8/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.6415 - accuracy: 0.6224\n",
      "Epoch 9/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.6546 - accuracy: 0.6293\n",
      "Epoch 10/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.6455 - accuracy: 0.6201\n",
      "Epoch 11/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.6468 - accuracy: 0.6178\n",
      "Epoch 12/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.6399 - accuracy: 0.6293\n",
      "Epoch 13/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.6573 - accuracy: 0.6339\n",
      "Epoch 14/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.6456 - accuracy: 0.6259\n",
      "Epoch 15/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.6431 - accuracy: 0.6316\n",
      "Epoch 16/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.6400 - accuracy: 0.6430\n",
      "Epoch 17/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.6446 - accuracy: 0.6316\n",
      "Epoch 18/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.6396 - accuracy: 0.6327\n",
      "Epoch 19/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.6397 - accuracy: 0.6476\n",
      "Epoch 20/400\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.6394 - accuracy: 0.6362\n",
      "Epoch 21/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.6412 - accuracy: 0.6327\n",
      "Epoch 22/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.6476 - accuracy: 0.6430\n",
      "Epoch 23/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.6292 - accuracy: 0.6384\n",
      "Epoch 24/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.6319 - accuracy: 0.6327\n",
      "Epoch 25/400\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.6379 - accuracy: 0.6373\n",
      "Epoch 26/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.6310 - accuracy: 0.6304\n",
      "Epoch 27/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.6317 - accuracy: 0.6407\n",
      "Epoch 28/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.6396 - accuracy: 0.6396\n",
      "Epoch 29/400\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.6285 - accuracy: 0.6350\n",
      "Epoch 30/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.6272 - accuracy: 0.6442\n",
      "Epoch 31/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.6265 - accuracy: 0.6407\n",
      "Epoch 32/400\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.6386 - accuracy: 0.6327\n",
      "Epoch 33/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.6247 - accuracy: 0.6339\n",
      "Epoch 34/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.6241 - accuracy: 0.6339\n",
      "Epoch 35/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.6180 - accuracy: 0.6533\n",
      "Epoch 36/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.6124 - accuracy: 0.6487\n",
      "Epoch 37/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.6216 - accuracy: 0.6327\n",
      "Epoch 38/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.6134 - accuracy: 0.6339\n",
      "Epoch 39/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.6039 - accuracy: 0.6579\n",
      "Epoch 40/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5997 - accuracy: 0.6693\n",
      "Epoch 41/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.6267 - accuracy: 0.6339\n",
      "Epoch 42/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.6115 - accuracy: 0.6396\n",
      "Epoch 43/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.6077 - accuracy: 0.6670\n",
      "Epoch 44/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5979 - accuracy: 0.6556\n",
      "Epoch 45/400\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.5981 - accuracy: 0.6613\n",
      "Epoch 46/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5890 - accuracy: 0.6476\n",
      "Epoch 47/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.6222 - accuracy: 0.6201\n",
      "Epoch 48/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5980 - accuracy: 0.6625\n",
      "Epoch 49/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.6007 - accuracy: 0.6327\n",
      "Epoch 50/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.6007 - accuracy: 0.6602\n",
      "Epoch 51/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5983 - accuracy: 0.6442\n",
      "Epoch 52/400\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.5965 - accuracy: 0.6476\n",
      "Epoch 53/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5952 - accuracy: 0.6613\n",
      "Epoch 54/400\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.5921 - accuracy: 0.6522\n",
      "Epoch 55/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.6002 - accuracy: 0.6476\n",
      "Epoch 56/400\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.5768 - accuracy: 0.6590\n",
      "Epoch 57/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5986 - accuracy: 0.6465\n",
      "Epoch 58/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5922 - accuracy: 0.6465\n",
      "Epoch 59/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.5872 - accuracy: 0.6465\n",
      "Epoch 60/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.6013 - accuracy: 0.6304\n",
      "Epoch 61/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5822 - accuracy: 0.6682\n",
      "Epoch 62/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.6079 - accuracy: 0.6362\n",
      "Epoch 63/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5861 - accuracy: 0.6373\n",
      "Epoch 64/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5858 - accuracy: 0.6522\n",
      "Epoch 65/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5849 - accuracy: 0.6613\n",
      "Epoch 66/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5927 - accuracy: 0.6533\n",
      "Epoch 67/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5730 - accuracy: 0.6636\n",
      "Epoch 68/400\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.5921 - accuracy: 0.6453\n",
      "Epoch 69/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5928 - accuracy: 0.6465\n",
      "Epoch 70/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5832 - accuracy: 0.6613\n",
      "Epoch 71/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5712 - accuracy: 0.6579\n",
      "Epoch 72/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5858 - accuracy: 0.6659\n",
      "Epoch 73/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5869 - accuracy: 0.6533\n",
      "Epoch 74/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5887 - accuracy: 0.6476\n",
      "Epoch 75/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5849 - accuracy: 0.6568\n",
      "Epoch 76/400\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.5719 - accuracy: 0.6522\n",
      "Epoch 77/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5887 - accuracy: 0.6602\n",
      "Epoch 78/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5775 - accuracy: 0.6476\n",
      "Epoch 79/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5774 - accuracy: 0.6442\n",
      "Epoch 80/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5724 - accuracy: 0.6648\n",
      "Epoch 81/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.5798 - accuracy: 0.6487\n",
      "Epoch 82/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5827 - accuracy: 0.6442\n",
      "Epoch 83/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5809 - accuracy: 0.6602\n",
      "Epoch 84/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5889 - accuracy: 0.6442\n",
      "Epoch 85/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5676 - accuracy: 0.6579\n",
      "Epoch 86/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5951 - accuracy: 0.6568\n",
      "Epoch 87/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5713 - accuracy: 0.6659\n",
      "Epoch 88/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5994 - accuracy: 0.6579\n",
      "Epoch 89/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5681 - accuracy: 0.6648\n",
      "Epoch 90/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.5851 - accuracy: 0.6487\n",
      "Epoch 91/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5671 - accuracy: 0.6522\n",
      "Epoch 92/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5889 - accuracy: 0.6373\n",
      "Epoch 93/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5716 - accuracy: 0.6590\n",
      "Epoch 94/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5689 - accuracy: 0.6590\n",
      "Epoch 95/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5609 - accuracy: 0.6728\n",
      "Epoch 96/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5796 - accuracy: 0.6339\n",
      "Epoch 97/400\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.5524 - accuracy: 0.6613\n",
      "Epoch 98/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5918 - accuracy: 0.6384\n",
      "Epoch 99/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.5704 - accuracy: 0.6602\n",
      "Epoch 100/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5711 - accuracy: 0.6556\n",
      "Epoch 101/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5728 - accuracy: 0.6396\n",
      "Epoch 102/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5632 - accuracy: 0.6682\n",
      "Epoch 103/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5741 - accuracy: 0.6533\n",
      "Epoch 104/400\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.5610 - accuracy: 0.6533\n",
      "Epoch 105/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5752 - accuracy: 0.6419\n",
      "Epoch 106/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.5608 - accuracy: 0.6739\n",
      "Epoch 107/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5636 - accuracy: 0.6579\n",
      "Epoch 108/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5752 - accuracy: 0.6705\n",
      "Epoch 109/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5585 - accuracy: 0.6533\n",
      "Epoch 110/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5835 - accuracy: 0.6362\n",
      "Epoch 111/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5623 - accuracy: 0.6705\n",
      "Epoch 112/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5762 - accuracy: 0.6442\n",
      "Epoch 113/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.5737 - accuracy: 0.6625\n",
      "Epoch 114/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5716 - accuracy: 0.6499\n",
      "Epoch 115/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5512 - accuracy: 0.6636\n",
      "Epoch 116/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5772 - accuracy: 0.6522\n",
      "Epoch 117/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5552 - accuracy: 0.6625\n",
      "Epoch 118/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5783 - accuracy: 0.6590\n",
      "Epoch 119/400\n",
      "9/9 [==============================] - 1s 56ms/step - loss: 0.5649 - accuracy: 0.6510\n",
      "Epoch 120/400\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.5669 - accuracy: 0.6499\n",
      "Epoch 121/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5532 - accuracy: 0.6670\n",
      "Epoch 122/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5524 - accuracy: 0.6659\n",
      "Epoch 123/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5640 - accuracy: 0.6716\n",
      "Epoch 124/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5602 - accuracy: 0.6590\n",
      "Epoch 125/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5555 - accuracy: 0.6579\n",
      "Epoch 126/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5597 - accuracy: 0.6670\n",
      "Epoch 127/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5619 - accuracy: 0.6545\n",
      "Epoch 128/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.5538 - accuracy: 0.6613\n",
      "Epoch 129/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5361 - accuracy: 0.6819\n",
      "Epoch 130/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5759 - accuracy: 0.6510\n",
      "Epoch 131/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5461 - accuracy: 0.6613\n",
      "Epoch 132/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5374 - accuracy: 0.6648\n",
      "Epoch 133/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5407 - accuracy: 0.6590\n",
      "Epoch 134/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5506 - accuracy: 0.6522\n",
      "Epoch 135/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5730 - accuracy: 0.6384\n",
      "Epoch 136/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.5356 - accuracy: 0.6751\n",
      "Epoch 137/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5668 - accuracy: 0.6522\n",
      "Epoch 138/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.5404 - accuracy: 0.6693\n",
      "Epoch 139/400\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.5606 - accuracy: 0.6728\n",
      "Epoch 140/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5286 - accuracy: 0.6945\n",
      "Epoch 141/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5342 - accuracy: 0.6865\n",
      "Epoch 142/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5483 - accuracy: 0.6728\n",
      "Epoch 143/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5365 - accuracy: 0.6773\n",
      "Epoch 144/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.5367 - accuracy: 0.6648\n",
      "Epoch 145/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5455 - accuracy: 0.6648\n",
      "Epoch 146/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.5343 - accuracy: 0.6922\n",
      "Epoch 147/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5424 - accuracy: 0.6922\n",
      "Epoch 148/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5589 - accuracy: 0.6545\n",
      "Epoch 149/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5334 - accuracy: 0.7002\n",
      "Epoch 150/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5423 - accuracy: 0.6968\n",
      "Epoch 151/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5240 - accuracy: 0.6991\n",
      "Epoch 152/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5134 - accuracy: 0.7082\n",
      "Epoch 153/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5778 - accuracy: 0.6785\n",
      "Epoch 154/400\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.5242 - accuracy: 0.6785\n",
      "Epoch 155/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5175 - accuracy: 0.7197\n",
      "Epoch 156/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5661 - accuracy: 0.6602\n",
      "Epoch 157/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5345 - accuracy: 0.6899\n",
      "Epoch 158/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.5171 - accuracy: 0.6911\n",
      "Epoch 159/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5138 - accuracy: 0.7025\n",
      "Epoch 160/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5474 - accuracy: 0.6842\n",
      "Epoch 161/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5149 - accuracy: 0.6899\n",
      "Epoch 162/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5150 - accuracy: 0.7014\n",
      "Epoch 163/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5183 - accuracy: 0.7105\n",
      "Epoch 164/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5710 - accuracy: 0.6556\n",
      "Epoch 165/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5060 - accuracy: 0.6854\n",
      "Epoch 166/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5261 - accuracy: 0.6533\n",
      "Epoch 167/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5043 - accuracy: 0.6922\n",
      "Epoch 168/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5368 - accuracy: 0.6819\n",
      "Epoch 169/400\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.4994 - accuracy: 0.7197\n",
      "Epoch 170/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5078 - accuracy: 0.6819\n",
      "Epoch 171/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5402 - accuracy: 0.6716\n",
      "Epoch 172/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4946 - accuracy: 0.7208\n",
      "Epoch 173/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5049 - accuracy: 0.7048\n",
      "Epoch 174/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5068 - accuracy: 0.7140\n",
      "Epoch 175/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5053 - accuracy: 0.6865\n",
      "Epoch 176/400\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.5177 - accuracy: 0.6957\n",
      "Epoch 177/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5027 - accuracy: 0.6968\n",
      "Epoch 178/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5113 - accuracy: 0.6957\n",
      "Epoch 179/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4849 - accuracy: 0.7357\n",
      "Epoch 180/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4889 - accuracy: 0.7185\n",
      "Epoch 181/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5044 - accuracy: 0.7220\n",
      "Epoch 182/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5244 - accuracy: 0.7174\n",
      "Epoch 183/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4863 - accuracy: 0.7311\n",
      "Epoch 184/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4880 - accuracy: 0.7334\n",
      "Epoch 185/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5223 - accuracy: 0.7208\n",
      "Epoch 186/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4915 - accuracy: 0.7346\n",
      "Epoch 187/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5007 - accuracy: 0.7334\n",
      "Epoch 188/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5172 - accuracy: 0.7368\n",
      "Epoch 189/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4949 - accuracy: 0.7140\n",
      "Epoch 190/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.4938 - accuracy: 0.7197\n",
      "Epoch 191/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.4898 - accuracy: 0.7231\n",
      "Epoch 192/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5099 - accuracy: 0.7323\n",
      "Epoch 193/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4817 - accuracy: 0.7311\n",
      "Epoch 194/400\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.4833 - accuracy: 0.7426\n",
      "Epoch 195/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.4658 - accuracy: 0.7529\n",
      "Epoch 196/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4805 - accuracy: 0.7197\n",
      "Epoch 197/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.4951 - accuracy: 0.7380\n",
      "Epoch 198/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4946 - accuracy: 0.7243\n",
      "Epoch 199/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.4853 - accuracy: 0.7288\n",
      "Epoch 200/400\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.4679 - accuracy: 0.7506\n",
      "Epoch 201/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4996 - accuracy: 0.7288\n",
      "Epoch 202/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4774 - accuracy: 0.7311\n",
      "Epoch 203/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.4774 - accuracy: 0.7403\n",
      "Epoch 204/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.4983 - accuracy: 0.7185\n",
      "Epoch 205/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4658 - accuracy: 0.7586\n",
      "Epoch 206/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4914 - accuracy: 0.7311\n",
      "Epoch 207/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5029 - accuracy: 0.7174\n",
      "Epoch 208/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4786 - accuracy: 0.7334\n",
      "Epoch 209/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4716 - accuracy: 0.7483\n",
      "Epoch 210/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4665 - accuracy: 0.7311\n",
      "Epoch 211/400\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.4750 - accuracy: 0.7483\n",
      "Epoch 212/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4918 - accuracy: 0.7346\n",
      "Epoch 213/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4607 - accuracy: 0.7517\n",
      "Epoch 214/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.4527 - accuracy: 0.7506\n",
      "Epoch 215/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.4782 - accuracy: 0.7597\n",
      "Epoch 216/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4767 - accuracy: 0.7300\n",
      "Epoch 217/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4701 - accuracy: 0.7265\n",
      "Epoch 218/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4980 - accuracy: 0.7265\n",
      "Epoch 219/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.4575 - accuracy: 0.7563\n",
      "Epoch 220/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.4632 - accuracy: 0.7597\n",
      "Epoch 221/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4437 - accuracy: 0.7643\n",
      "Epoch 222/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.5103 - accuracy: 0.7208\n",
      "Epoch 223/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4499 - accuracy: 0.7643\n",
      "Epoch 224/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4942 - accuracy: 0.7220\n",
      "Epoch 225/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4463 - accuracy: 0.7666\n",
      "Epoch 226/400\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.4677 - accuracy: 0.7471\n",
      "Epoch 227/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4725 - accuracy: 0.7300\n",
      "Epoch 228/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4815 - accuracy: 0.7265\n",
      "Epoch 229/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4648 - accuracy: 0.7460\n",
      "Epoch 230/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.4557 - accuracy: 0.7540\n",
      "Epoch 231/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4775 - accuracy: 0.7254\n",
      "Epoch 232/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4441 - accuracy: 0.7551\n",
      "Epoch 233/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.4477 - accuracy: 0.7551\n",
      "Epoch 234/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5171 - accuracy: 0.7048\n",
      "Epoch 235/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.4456 - accuracy: 0.7609\n",
      "Epoch 236/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.4702 - accuracy: 0.7597\n",
      "Epoch 237/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.4798 - accuracy: 0.7231\n",
      "Epoch 238/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4364 - accuracy: 0.7654\n",
      "Epoch 239/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.4779 - accuracy: 0.7414\n",
      "Epoch 240/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.4827 - accuracy: 0.7231\n",
      "Epoch 241/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4477 - accuracy: 0.7403\n",
      "Epoch 242/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4804 - accuracy: 0.7380\n",
      "Epoch 243/400\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.4664 - accuracy: 0.7437\n",
      "Epoch 244/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4486 - accuracy: 0.7597\n",
      "Epoch 245/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4337 - accuracy: 0.7632\n",
      "Epoch 246/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.4739 - accuracy: 0.7151\n",
      "Epoch 247/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4589 - accuracy: 0.7517\n",
      "Epoch 248/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.4939 - accuracy: 0.7414\n",
      "Epoch 249/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.4369 - accuracy: 0.7632\n",
      "Epoch 250/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4463 - accuracy: 0.7597\n",
      "Epoch 251/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4538 - accuracy: 0.7597\n",
      "Epoch 252/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4808 - accuracy: 0.7449\n",
      "Epoch 253/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4357 - accuracy: 0.7803\n",
      "Epoch 254/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.4851 - accuracy: 0.7551\n",
      "Epoch 255/400\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.5120 - accuracy: 0.7334\n",
      "Epoch 256/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4548 - accuracy: 0.7712\n",
      "Epoch 257/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5118 - accuracy: 0.7311\n",
      "Epoch 258/400\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.4769 - accuracy: 0.7288\n",
      "Epoch 259/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4789 - accuracy: 0.7334\n",
      "Epoch 260/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.4717 - accuracy: 0.7426\n",
      "Epoch 261/400\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.4793 - accuracy: 0.7643\n",
      "Epoch 262/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4719 - accuracy: 0.7483\n",
      "Epoch 263/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4796 - accuracy: 0.7323\n",
      "Epoch 264/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5011 - accuracy: 0.7551\n",
      "Epoch 265/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4753 - accuracy: 0.7220\n",
      "Epoch 266/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4568 - accuracy: 0.7517\n",
      "Epoch 267/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.4689 - accuracy: 0.7563\n",
      "Epoch 268/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4693 - accuracy: 0.7414\n",
      "Epoch 269/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4515 - accuracy: 0.7723\n",
      "Epoch 270/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.4712 - accuracy: 0.7563\n",
      "Epoch 271/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.4441 - accuracy: 0.7792\n",
      "Epoch 272/400\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.4713 - accuracy: 0.7586\n",
      "Epoch 273/400\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.4549 - accuracy: 0.7632\n",
      "Epoch 274/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4350 - accuracy: 0.7792\n",
      "Epoch 275/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4955 - accuracy: 0.7597\n",
      "Epoch 276/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4676 - accuracy: 0.7506\n",
      "Epoch 277/400\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.4314 - accuracy: 0.7918\n",
      "Epoch 278/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4391 - accuracy: 0.7666\n",
      "Epoch 279/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.4391 - accuracy: 0.7712\n",
      "Epoch 280/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.4632 - accuracy: 0.7666\n",
      "Epoch 281/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4626 - accuracy: 0.7700\n",
      "Epoch 282/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.4293 - accuracy: 0.7792\n",
      "Epoch 283/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4337 - accuracy: 0.7838\n",
      "Epoch 284/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4545 - accuracy: 0.7654\n",
      "Epoch 285/400\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.4281 - accuracy: 0.7815\n",
      "Epoch 286/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4291 - accuracy: 0.7838\n",
      "Epoch 287/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.4536 - accuracy: 0.7643\n",
      "Epoch 288/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4235 - accuracy: 0.7941\n",
      "Epoch 289/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4300 - accuracy: 0.7803\n",
      "Epoch 290/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.4548 - accuracy: 0.7780\n",
      "Epoch 291/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4086 - accuracy: 0.8112\n",
      "Epoch 292/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4831 - accuracy: 0.7517\n",
      "Epoch 293/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4078 - accuracy: 0.8043\n",
      "Epoch 294/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4363 - accuracy: 0.7792\n",
      "Epoch 295/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4173 - accuracy: 0.7918\n",
      "Epoch 296/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4266 - accuracy: 0.7792\n",
      "Epoch 297/400\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.4401 - accuracy: 0.7712\n",
      "Epoch 298/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4003 - accuracy: 0.8112\n",
      "Epoch 299/400\n",
      "9/9 [==============================] - 1s 56ms/step - loss: 0.4190 - accuracy: 0.7872\n",
      "Epoch 300/400\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.4340 - accuracy: 0.7746\n",
      "Epoch 301/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4481 - accuracy: 0.7769\n",
      "Epoch 302/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.4347 - accuracy: 0.7643\n",
      "Epoch 303/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4048 - accuracy: 0.8101\n",
      "Epoch 304/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4078 - accuracy: 0.8078\n",
      "Epoch 305/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.4315 - accuracy: 0.7803\n",
      "Epoch 306/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.4130 - accuracy: 0.7872\n",
      "Epoch 307/400\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.3965 - accuracy: 0.8043\n",
      "Epoch 308/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.4016 - accuracy: 0.7963\n",
      "Epoch 309/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4153 - accuracy: 0.8066\n",
      "Epoch 310/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4326 - accuracy: 0.7792\n",
      "Epoch 311/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4257 - accuracy: 0.7769\n",
      "Epoch 312/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.3949 - accuracy: 0.7975\n",
      "Epoch 313/400\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.4357 - accuracy: 0.7815\n",
      "Epoch 314/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.4087 - accuracy: 0.8021\n",
      "Epoch 315/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.4005 - accuracy: 0.7849\n",
      "Epoch 316/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.4277 - accuracy: 0.8021\n",
      "Epoch 317/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.3799 - accuracy: 0.8146\n",
      "Epoch 318/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.3943 - accuracy: 0.7895\n",
      "Epoch 319/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.4146 - accuracy: 0.7998\n",
      "Epoch 320/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.4167 - accuracy: 0.7815\n",
      "Epoch 321/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.4198 - accuracy: 0.7826\n",
      "Epoch 322/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.3735 - accuracy: 0.8089\n",
      "Epoch 323/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.4134 - accuracy: 0.7849\n",
      "Epoch 324/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.3982 - accuracy: 0.8112\n",
      "Epoch 325/400\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.3902 - accuracy: 0.8021\n",
      "Epoch 326/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.3901 - accuracy: 0.7963\n",
      "Epoch 327/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.3731 - accuracy: 0.8158\n",
      "Epoch 328/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.4252 - accuracy: 0.7849\n",
      "Epoch 329/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.3530 - accuracy: 0.8238\n",
      "Epoch 330/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4175 - accuracy: 0.7963\n",
      "Epoch 331/400\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.4119 - accuracy: 0.7975\n",
      "Epoch 332/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.3750 - accuracy: 0.8181\n",
      "Epoch 333/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4127 - accuracy: 0.7918\n",
      "Epoch 334/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.3813 - accuracy: 0.8032\n",
      "Epoch 335/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3796 - accuracy: 0.8135\n",
      "Epoch 336/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4162 - accuracy: 0.7872\n",
      "Epoch 337/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.3416 - accuracy: 0.8410\n",
      "Epoch 338/400\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.4356 - accuracy: 0.7952\n",
      "Epoch 339/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3868 - accuracy: 0.8112\n",
      "Epoch 340/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.3957 - accuracy: 0.7929\n",
      "Epoch 341/400\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.4055 - accuracy: 0.7929\n",
      "Epoch 342/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.3427 - accuracy: 0.8181\n",
      "Epoch 343/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4285 - accuracy: 0.7712\n",
      "Epoch 344/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.3509 - accuracy: 0.8284\n",
      "Epoch 345/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4183 - accuracy: 0.7757\n",
      "Epoch 346/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.3414 - accuracy: 0.8295\n",
      "Epoch 347/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.3987 - accuracy: 0.8124\n",
      "Epoch 348/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3821 - accuracy: 0.7872\n",
      "Epoch 349/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.3715 - accuracy: 0.8009\n",
      "Epoch 350/400\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.3527 - accuracy: 0.8204\n",
      "Epoch 351/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4239 - accuracy: 0.7963\n",
      "Epoch 352/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.3443 - accuracy: 0.8295\n",
      "Epoch 353/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3602 - accuracy: 0.8192\n",
      "Epoch 354/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.3738 - accuracy: 0.8169\n",
      "Epoch 355/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.3498 - accuracy: 0.8284\n",
      "Epoch 356/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.3921 - accuracy: 0.8089\n",
      "Epoch 357/400\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.3304 - accuracy: 0.8421\n",
      "Epoch 358/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.3971 - accuracy: 0.7906\n",
      "Epoch 359/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.3612 - accuracy: 0.8158\n",
      "Epoch 360/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3634 - accuracy: 0.8215\n",
      "Epoch 361/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3738 - accuracy: 0.8169\n",
      "Epoch 362/400\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.3539 - accuracy: 0.8204\n",
      "Epoch 363/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3412 - accuracy: 0.8352\n",
      "Epoch 364/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3455 - accuracy: 0.8192\n",
      "Epoch 365/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3389 - accuracy: 0.8135\n",
      "Epoch 366/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3525 - accuracy: 0.8146\n",
      "Epoch 367/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.3880 - accuracy: 0.8032\n",
      "Epoch 368/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4486 - accuracy: 0.7780\n",
      "Epoch 369/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.3338 - accuracy: 0.8341\n",
      "Epoch 370/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3930 - accuracy: 0.8341\n",
      "Epoch 371/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.3371 - accuracy: 0.8364\n",
      "Epoch 372/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.3549 - accuracy: 0.8169\n",
      "Epoch 373/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4203 - accuracy: 0.7860\n",
      "Epoch 374/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3184 - accuracy: 0.8341\n",
      "Epoch 375/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.3498 - accuracy: 0.8330\n",
      "Epoch 376/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4106 - accuracy: 0.8078\n",
      "Epoch 377/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.3476 - accuracy: 0.8284\n",
      "Epoch 378/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.3497 - accuracy: 0.8261\n",
      "Epoch 379/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.3578 - accuracy: 0.8158\n",
      "Epoch 380/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.3435 - accuracy: 0.8375\n",
      "Epoch 381/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.3984 - accuracy: 0.7941\n",
      "Epoch 382/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.3351 - accuracy: 0.8227\n",
      "Epoch 383/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.3191 - accuracy: 0.8513\n",
      "Epoch 384/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.3402 - accuracy: 0.8272\n",
      "Epoch 385/400\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.3486 - accuracy: 0.8169\n",
      "Epoch 386/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3706 - accuracy: 0.8101\n",
      "Epoch 387/400\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.3591 - accuracy: 0.8215\n",
      "Epoch 388/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.4016 - accuracy: 0.8066\n",
      "Epoch 389/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3749 - accuracy: 0.8410\n",
      "Epoch 390/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3743 - accuracy: 0.8032\n",
      "Epoch 391/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.3610 - accuracy: 0.8364\n",
      "Epoch 392/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.3456 - accuracy: 0.8398\n",
      "Epoch 393/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4301 - accuracy: 0.7975\n",
      "Epoch 394/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.3826 - accuracy: 0.8318\n",
      "Epoch 395/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.3511 - accuracy: 0.8249\n",
      "Epoch 396/400\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.3791 - accuracy: 0.8192\n",
      "Epoch 397/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3415 - accuracy: 0.8421\n",
      "Epoch 398/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.3752 - accuracy: 0.8181\n",
      "Epoch 399/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.2994 - accuracy: 0.8673\n",
      "Epoch 400/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.3392 - accuracy: 0.8467\n",
      "Score for fold 1: loss of 0.33354198932647705; accuracy of 86.40000224113464%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/400\n",
      "9/9 [==============================] - 3s 52ms/step - loss: 0.7126 - accuracy: 0.5269\n",
      "Epoch 2/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.6779 - accuracy: 0.5863\n",
      "Epoch 3/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.6711 - accuracy: 0.5931\n",
      "Epoch 4/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.6688 - accuracy: 0.5977\n",
      "Epoch 5/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.6595 - accuracy: 0.6240\n",
      "Epoch 6/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.6620 - accuracy: 0.6251\n",
      "Epoch 7/400\n",
      "9/9 [==============================] - 1s 56ms/step - loss: 0.6569 - accuracy: 0.6217\n",
      "Epoch 8/400\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.6573 - accuracy: 0.6297\n",
      "Epoch 9/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.6570 - accuracy: 0.6389\n",
      "Epoch 10/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.6512 - accuracy: 0.6366\n",
      "Epoch 11/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.6591 - accuracy: 0.6297\n",
      "Epoch 12/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.6548 - accuracy: 0.6309\n",
      "Epoch 13/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.6528 - accuracy: 0.6274\n",
      "Epoch 14/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.6560 - accuracy: 0.6469\n",
      "Epoch 15/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.6432 - accuracy: 0.6434\n",
      "Epoch 16/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.6426 - accuracy: 0.6377\n",
      "Epoch 17/400\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.6504 - accuracy: 0.6286\n",
      "Epoch 18/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.6476 - accuracy: 0.6194\n",
      "Epoch 19/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.6336 - accuracy: 0.6366\n",
      "Epoch 20/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.6390 - accuracy: 0.6331\n",
      "Epoch 21/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.6287 - accuracy: 0.6389\n",
      "Epoch 22/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.6181 - accuracy: 0.6469\n",
      "Epoch 23/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.6107 - accuracy: 0.6606\n",
      "Epoch 24/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.6448 - accuracy: 0.6251\n",
      "Epoch 25/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.6077 - accuracy: 0.6549\n",
      "Epoch 26/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.6011 - accuracy: 0.6583\n",
      "Epoch 27/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.6302 - accuracy: 0.6126\n",
      "Epoch 28/400\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.6179 - accuracy: 0.6423\n",
      "Epoch 29/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5945 - accuracy: 0.6651\n",
      "Epoch 30/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.6141 - accuracy: 0.6469\n",
      "Epoch 31/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5977 - accuracy: 0.6743\n",
      "Epoch 32/400\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.5986 - accuracy: 0.6651\n",
      "Epoch 33/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.6041 - accuracy: 0.6469\n",
      "Epoch 34/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.6006 - accuracy: 0.6549\n",
      "Epoch 35/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5998 - accuracy: 0.6674\n",
      "Epoch 36/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.6019 - accuracy: 0.6617\n",
      "Epoch 37/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.6028 - accuracy: 0.6537\n",
      "Epoch 38/400\n",
      "9/9 [==============================] - 1s 50ms/step - loss: 0.5956 - accuracy: 0.6606\n",
      "Epoch 39/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5997 - accuracy: 0.6491\n",
      "Epoch 40/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5907 - accuracy: 0.6434\n",
      "Epoch 41/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5862 - accuracy: 0.6686\n",
      "Epoch 42/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5977 - accuracy: 0.6446\n",
      "Epoch 43/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5850 - accuracy: 0.6514\n",
      "Epoch 44/400\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.5816 - accuracy: 0.6514\n",
      "Epoch 45/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.6095 - accuracy: 0.6491\n",
      "Epoch 46/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5890 - accuracy: 0.6514\n",
      "Epoch 47/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.5859 - accuracy: 0.6571\n",
      "Epoch 48/400\n",
      "9/9 [==============================] - 1s 54ms/step - loss: 0.6054 - accuracy: 0.6537\n",
      "Epoch 49/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.5812 - accuracy: 0.6686\n",
      "Epoch 50/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5818 - accuracy: 0.6629\n",
      "Epoch 51/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5957 - accuracy: 0.6629\n",
      "Epoch 52/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5826 - accuracy: 0.6754\n",
      "Epoch 53/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5969 - accuracy: 0.6434\n",
      "Epoch 54/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5996 - accuracy: 0.6617\n",
      "Epoch 55/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5807 - accuracy: 0.6663\n",
      "Epoch 56/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.5889 - accuracy: 0.6469\n",
      "Epoch 57/400\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.5747 - accuracy: 0.6697\n",
      "Epoch 58/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.5928 - accuracy: 0.6560\n",
      "Epoch 59/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5906 - accuracy: 0.6400\n",
      "Epoch 60/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5779 - accuracy: 0.6629\n",
      "Epoch 61/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.6055 - accuracy: 0.6377\n",
      "Epoch 62/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5728 - accuracy: 0.6697\n",
      "Epoch 63/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5767 - accuracy: 0.6583\n",
      "Epoch 64/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.5964 - accuracy: 0.6560\n",
      "Epoch 65/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5805 - accuracy: 0.6743\n",
      "Epoch 66/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5831 - accuracy: 0.6617\n",
      "Epoch 67/400\n",
      "9/9 [==============================] - 1s 49ms/step - loss: 0.5750 - accuracy: 0.6640\n",
      "Epoch 68/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.6004 - accuracy: 0.6457\n",
      "Epoch 69/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.5724 - accuracy: 0.6651\n",
      "Epoch 70/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5845 - accuracy: 0.6674\n",
      "Epoch 71/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5758 - accuracy: 0.6686\n",
      "Epoch 72/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.5992 - accuracy: 0.6640\n",
      "Epoch 73/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5721 - accuracy: 0.6571\n",
      "Epoch 74/400\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.5785 - accuracy: 0.6583\n",
      "Epoch 75/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5739 - accuracy: 0.6697\n",
      "Epoch 76/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5932 - accuracy: 0.6377\n",
      "Epoch 77/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5772 - accuracy: 0.6674\n",
      "Epoch 78/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.5760 - accuracy: 0.6640\n",
      "Epoch 79/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5809 - accuracy: 0.6663\n",
      "Epoch 80/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5920 - accuracy: 0.6640\n",
      "Epoch 81/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5778 - accuracy: 0.6709\n",
      "Epoch 82/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5757 - accuracy: 0.6457\n",
      "Epoch 83/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.5737 - accuracy: 0.6560\n",
      "Epoch 84/400\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.5876 - accuracy: 0.6617\n",
      "Epoch 85/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5737 - accuracy: 0.6640\n",
      "Epoch 86/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.5747 - accuracy: 0.6571\n",
      "Epoch 87/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5933 - accuracy: 0.6560\n",
      "Epoch 88/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5703 - accuracy: 0.6640\n",
      "Epoch 89/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5683 - accuracy: 0.6720\n",
      "Epoch 90/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5670 - accuracy: 0.6560\n",
      "Epoch 91/400\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5916 - accuracy: 0.6549\n",
      "Epoch 92/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.5634 - accuracy: 0.6709\n",
      "Epoch 93/400\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.5766 - accuracy: 0.6629\n",
      "Epoch 94/400\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.5659 - accuracy: 0.6834\n",
      "Epoch 95/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5924 - accuracy: 0.6526\n",
      "Epoch 96/400\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.5747 - accuracy: 0.6629\n",
      "Epoch 97/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5620 - accuracy: 0.6846\n",
      "Epoch 98/400\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5775 - accuracy: 0.6663\n",
      "Epoch 99/400\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5718 - accuracy: 0.6560\n",
      "Epoch 100/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.5725 - accuracy: 0.6686\n",
      "Epoch 101/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5831 - accuracy: 0.6663\n",
      "Epoch 102/400\n",
      "5/9 [===============>..............] - ETA: 0s - loss: 0.5637 - accuracy: 0.6700"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining for fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#early_stop=tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=500, verbose=2, mode='auto', baseline=None, restore_best_weights=True)\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m history\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_Normalizado\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_Normalizado\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Final evaluation of the model \u001b[39;00m\n\u001b[0;32m     18\u001b[0m scores \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_train_Normalizado[test], y_train_Normalizado[test], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "num_folds=2\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(X_train_Normalizado, y_train_Normalizado):\n",
    "    model=create_model()\n",
    "      # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    #early_stop=tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=500, verbose=2, mode='auto', baseline=None, restore_best_weights=True)\n",
    "    history=model.fit(X_train_Normalizado[train], y_train_Normalizado[train], epochs=400, batch_size=100)\n",
    "    # Final evaluation of the model \n",
    "    scores = model.evaluate(X_train_Normalizado[test], y_train_Normalizado[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "  # == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "#y_pred2=np.where(y_pred>0,1,0)\n",
    "#y_pred2=y_pred2[:,-1]\n",
    "y_test_def2=np.argmax(y_test_def,axis=1)\n",
    "#y_test_def2=np.where(y_test_def>0,1,0)\n",
    "print(y_pred.shape)\n",
    "print(y_pred2.shape)\n",
    "print(y_test_def2.shape)\n",
    "#print(y_test_def[25])\n",
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs_infra: no_execute\n",
    "if numero_clases==2:\n",
    "    classes = [0, 1]\n",
    "else:   \n",
    "    classes = [0, 1, 2, 3, 4]\n",
    "#classes = [0, 1]\n",
    "cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "if numero_clases==2:\n",
    "    target_names = ['Buenos', 'Malos']\n",
    "else:   \n",
    "    target_names = ['A', 'B+', 'B', 'B-','C']\n",
    "print(classification_report(y_test_def2, y_pred2, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('modelos/modelote1203_200')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('idea.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "model.save('modelos\\modelo_perfecto_{}_{}.h5'.format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#este modo de guardar no funciona en esta version de tensorflow\n",
    "#model.save('modelos\\modelo_perfecto_{}_{}'.format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "n = len(y_pred2)\n",
    "reshaped = y_pred2[:n//4*4].reshape(-1, 4)\n",
    "mean_values = reshaped.mean(axis=1)\n",
    "\n",
    "mean_values = np.round(mean_values)\n",
    "mean_values = np.clip(mean_values, 0, 4)\n",
    "mean_values = mean_values.astype(int)\n",
    "print(mean_values)\n",
    "\n",
    "mode_values = stats.mode(reshaped, axis=1)[0]\n",
    "print(mode_values)\n",
    "\n",
    "# Convierte los arrays a DataFrames\n",
    "mean_df = pd.DataFrame(mean_values, columns=['mean'])\n",
    "mode_df = pd.DataFrame(mode_values, columns=['mode'])\n",
    "\n",
    "# Guarda los DataFrames en archivos Excel\n",
    "mean_df.to_excel(\"excels_borrar\\clasificacion_P1P2_mean_best7.xlsx\", index=False)\n",
    "mode_df.to_excel(\"excels_borrar\\clasificacion_P1_mode_best7.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename5 = \"COPIA_PANDAS\\lomosP1_20240430_clasificado_experto.hdf\"\n",
    "with pd.HDFStore(filename5,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e2  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e2 = pre_p_e2.loc[pre_p_e2['Pollo'] != 0]\n",
    "    pre_p_e2 =pre_p_e2.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_test2=np.zeros((pre_p_e2.shape[0],220,8))\n",
    "    y_test2=np.zeros((pre_p_e2.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e2.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1:\n",
    "                target = 0 \n",
    "            else:\n",
    "                target = 1\n",
    "\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_test2[x]=pepito[:,3:11]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_test2[x]=target\n",
    "        y_test2_to_categorical = to_categorical(y_test2)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_test2_filtrado = X_test2\n",
    "#y_train_filtrado = y_train\n",
    "y_test2_filtrado = y_test2_to_categorical\n",
    "\n",
    "print(X_test2_filtrado.shape)\n",
    "print(y_test2_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "# concatenamos train y test\n",
    "#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\n",
    "data_2d_test = X_test2_filtrado.reshape(-1, X_test2_filtrado.shape[-1])\n",
    "normalized_data_2d_test = scaler.transform(data_2d_test)\n",
    "\n",
    "\n",
    "X_test2_def=normalized_data_2d_test.reshape(X_test2_filtrado.shape) \n",
    "# la alternativa es normalizar con el total\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "\n",
    "y_test2_def=y_test2_filtrado # los valores ya estaban normalizados\n",
    "\n",
    "print(y_test2_def.shape)\n",
    "\n",
    "print(y_test2_filtrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# # Crear un nuevo modelo con la misma arquitectura\n",
    "# best_val_model = create_model()  # Reemplaza esto con la función que usaste para crear el modelo original\n",
    "\n",
    "# # Cargar los mejores pesos\n",
    "# best_val_model.load_weights('best_weights.h5')\n",
    "\n",
    "y_pred = model.predict(X_test2_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "n = len(y_pred2)\n",
    "print(n)\n",
    "reshaped = y_pred2[:n//4*4].reshape(-1, 4)\n",
    "mean_values = reshaped.mean(axis=1)\n",
    "\n",
    "mean_values = np.round(mean_values)\n",
    "mean_values = np.clip(mean_values, 0, 4)\n",
    "mean_values = mean_values.astype(int)\n",
    "print(mean_values.shape)\n",
    "\n",
    "mode_values = stats.mode(reshaped, axis=1)[0]\n",
    "print(mode_values.shape)\n",
    "\n",
    "n = len(y_test2_def)\n",
    "y_test2_def2=np.argmax(y_test2_def,axis=1)\n",
    "print(y_test_def2.shape)\n",
    "print(n)\n",
    "reshaped2 = y_test2_def2[:n//4*4].reshape(-1, 4)\n",
    "target_mean_values = reshaped2.mean(axis=1)\n",
    "\n",
    "target_mean_values = np.round(target_mean_values)\n",
    "target_mean_values = np.clip(target_mean_values, 0, 4)\n",
    "target_mean_values = target_mean_values.astype(int)\n",
    "print(target_mean_values.shape)\n",
    "\n",
    "target_mode_values = stats.mode(reshaped2, axis=1)[0]\n",
    "print(target_mode_values.shape)\n",
    "print(reshaped)\n",
    "print(mode_values)\n",
    "print(target_mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs_infra: no_execute\n",
    "if numero_clases==2:\n",
    "    classes = [0, 1]    \n",
    "else:\n",
    "\n",
    "    classes = [0, 1, 2, 3, 4]\n",
    "#classes = [0, 1]\n",
    "cm=confusion_matrix(target_mode_values, mode_values,labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm.diagonal()/cm.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if numero_clases==2:\n",
    "    target_names= ['Buenos', 'Malos']\n",
    "else:\n",
    "    target_names= ['A', 'B+', 'B', 'B-','C']\n",
    "print(classification_report(target_mode_values, mode_values, target_names=target_names, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
