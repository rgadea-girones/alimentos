{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:\\nuevas_investigaciones_alimentos_2024\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM,Bidirectional,GRU\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import datetime\n",
    "import io\n",
    "import itertools\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Obtener la ruta del directorio actual\n",
    "os.chdir('..')\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "# Construir la ruta relativa al directorio que quieres agregar\n",
    "relative_dir = os.path.join(current_dir, 'mis_pkgs/')\n",
    "\n",
    "# Agregar la ruta relativa al sys.path\n",
    "sys.path.insert(0, relative_dir)\n",
    "\n",
    "from MIOPATIA_db import DB_management as db \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a quedarme con los 50 atunes P1 para obtener conjunto de training y validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Add, Activation, Concatenate, Conv2D, Dropout \n",
    "from tensorflow.keras.layers import Flatten, Input, GlobalAveragePooling2D, MaxPooling2D\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "__version__ = '0.0.1'\n",
    "\n",
    "\n",
    "def SqueezeNet(input_shape, nb_classes, use_bypass=False, dropout_rate=None, compression=1.0):\n",
    "    \"\"\"\n",
    "    Creating a SqueezeNet of version 1.0\n",
    "    \n",
    "    Arguments:\n",
    "        input_shape  : shape of the input images e.g. (224,224,3)\n",
    "        nb_classes   : number of classes\n",
    "        use_bypass   : if true, bypass connections will be created at fire module 3, 5, 7, and 9 (default: False)\n",
    "        dropout_rate : defines the dropout rate that is accomplished after last fire module (default: None)\n",
    "        compression  : reduce the number of feature-maps (default: 1.0)\n",
    "        \n",
    "    Returns:\n",
    "        Model        : Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(int(96*compression), (7,7), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "    x = create_fire_module(x, int(16*compression), name='fire3', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool4')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(32*compression), name='fire5', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "    x = create_fire_module(x, int(48*compression), name='fire7', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool8')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(64*compression), name='fire9', use_bypass=use_bypass)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        \n",
    "    x = output(x, nb_classes)\n",
    "\n",
    "    return Model(inputs=input_img, outputs=x)\n",
    "\n",
    "\n",
    "def SqueezeNet_11(input_shape, nb_classes, dropout_rate=None, compression=1.0):\n",
    "    \"\"\"\n",
    "    Creating a SqueezeNet of version 1.1\n",
    "    \n",
    "    2.4x less computation over SqueezeNet 1.0 implemented above.\n",
    "    \n",
    "    Arguments:\n",
    "        input_shape  : shape of the input images e.g. (224,224,3)\n",
    "        nb_classes   : number of classes\n",
    "        dropout_rate : defines the dropout rate that is accomplished after last fire module (default: None)\n",
    "        compression  : reduce the number of feature-maps\n",
    "        \n",
    "    Returns:\n",
    "        Model        : Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(int(64*compression), (3,3), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "    x = create_fire_module(x, int(16*compression), name='fire3')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool3')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "    x = create_fire_module(x, int(32*compression), name='fire5')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool5')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "    x = create_fire_module(x, int(48*compression), name='fire7')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire9')\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # Creating last conv10\n",
    "    x = output(x, nb_classes)\n",
    "\n",
    "    return Model(inputs=input_img, outputs=x)\n",
    "\n",
    "\n",
    "def output(x, nb_classes):\n",
    "    x = Conv2D(nb_classes, (1,1), strides=(1,1), padding='valid', name='conv10')(x)\n",
    "    x = GlobalAveragePooling2D(name='avgpool10')(x)\n",
    "    x = Activation(\"softmax\", name='softmax')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_fire_module(x, nb_squeeze_filter, name, use_bypass=False):\n",
    "    \"\"\"\n",
    "    Creates a fire module\n",
    "    \n",
    "    Arguments:\n",
    "        x                 : input\n",
    "        nb_squeeze_filter : number of filters of squeeze. The filtersize of expand is 4 times of squeeze\n",
    "        use_bypass        : if True then a bypass will be added\n",
    "        name              : name of module e.g. fire123\n",
    "    \n",
    "    Returns:\n",
    "        x                 : returns a fire module\n",
    "    \"\"\"\n",
    "    \n",
    "    nb_expand_filter = 4 * nb_squeeze_filter\n",
    "    squeeze    = Conv2D(nb_squeeze_filter,(1,1), activation='relu', padding='same', name='%s_squeeze'%name)(x)\n",
    "    expand_1x1 = Conv2D(nb_expand_filter, (1,1), activation='relu', padding='same', name='%s_expand_1x1'%name)(squeeze)\n",
    "    expand_3x3 = Conv2D(nb_expand_filter, (3,3), activation='relu', padding='same', name='%s_expand_3x3'%name)(squeeze)\n",
    "    \n",
    "    axis = get_axis()\n",
    "    x_ret = Concatenate(axis=axis, name='%s_concatenate'%name)([expand_1x1, expand_3x3])\n",
    "    \n",
    "    if use_bypass:\n",
    "        x_ret = Add(name='%s_concatenate_bypass'%name)([x_ret, x])\n",
    "        \n",
    "    return x_ret\n",
    "\n",
    "\n",
    "def get_axis():\n",
    "    axis = -1 if K.image_data_format() == 'channels_last' else 1\n",
    "    return axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3168, 5)\n"
     ]
    }
   ],
   "source": [
    "filename = \"COPIA_PANDAS\\hdf_lomosP2_trainval_filtrado_def_good_ampliado_the_best7.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    # p_e =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_train=np.zeros((pre_p_e1.shape[0],220,8))\n",
    "    y_train=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if estado == 0 or estado== 1:\n",
    "            target = 1\n",
    "        else:\n",
    "            target = 0\n",
    "        target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_train[x]=pepito[:,3:11]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_train[x]=target\n",
    "        y_train_to_categorical = to_categorical(y_train)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_train_filtrado = X_train\n",
    "#y_train_filtrado = y_train\n",
    "y_train_filtrado = y_train_to_categorical\n",
    "\n",
    "# print(X_train_filtrado.shape)\n",
    "# print(y_train_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_2d = X_train_filtrado.reshape(-1, X_train_filtrado.shape[-1])\n",
    "normalized_data_2d = scaler.fit_transform(data_2d)\n",
    "X_train_Normalizado=normalized_data_2d.reshape(X_train_filtrado.shape)\n",
    "y_train_Normalizado=y_train_filtrado # los valores ya estaban normalizados\n",
    "print(y_train_Normalizado.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89, 220, 8)\n",
      "(89, 5)\n",
      "[[1.45375657e-01 4.74795267e-01 2.80281244e-02 ... 5.25204733e-01\n",
      "  1.45375842e-01 6.87729402e-01]\n",
      " [1.04024516e-01 4.57433188e-01 2.91808316e-02 ... 5.42566812e-01\n",
      "  1.04024006e-01 6.97578524e-01]\n",
      " [8.71835342e-02 4.33210717e-01 3.04208802e-02 ... 5.66789283e-01\n",
      "  8.71821912e-02 6.95625305e-01]\n",
      " ...\n",
      " [2.02802467e-04 3.24435285e-01 2.62623498e-02 ... 6.75564715e-01\n",
      "  2.02784951e-04 7.57016975e-01]\n",
      " [1.94554576e-04 3.21521964e-01 2.62630472e-02 ... 6.78478036e-01\n",
      "  1.94537255e-04 7.57024384e-01]\n",
      " [1.86099353e-04 3.17958187e-01 2.62645389e-02 ... 6.82041813e-01\n",
      "  1.86082165e-04 7.57031614e-01]]\n"
     ]
    }
   ],
   "source": [
    "filename = \"COPIA_PANDAS\\hdf_lomosP2_test_filtrado_def_good.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    pre_p_e1 =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_test=np.zeros((pre_p_e1.shape[0],220,8))\n",
    "    y_test=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if estado == 0 or estado== 1:\n",
    "           target = 1\n",
    "        else:\n",
    "           target = 0\n",
    "        target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_test[x]=pepito[:,3:11]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_test[x]=target\n",
    "        y_test_to_categorical = to_categorical(y_test)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_test_filtrado = X_test\n",
    "#y_train_filtrado = y_train\n",
    "y_test_filtrado = y_test_to_categorical\n",
    "\n",
    "print(X_test_filtrado.shape)\n",
    "print(y_test_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "# concatenamos train y test\n",
    "#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\n",
    "data_2d_test = X_test_filtrado.reshape(-1, X_test_filtrado.shape[-1])\n",
    "normalized_data_2d_test = scaler.transform(data_2d_test)\n",
    "\n",
    "\n",
    "X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "# la alternativa es normalizar con el total\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "\n",
    "y_test_def=y_test_filtrado # los valores ya estaban normalizados\n",
    "print(X_test_def[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer los conjuntos de entrenamiento validacion y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide el dataset en entrenamiento y temporal (test+validación)\n",
    "# X_temp, X_test_def, y_temp, y_test_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.2, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Divide el dataset temporal en validación y test\n",
    "X_train_def, X_val_def, y_train_def, y_val_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.25, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Ahora, X_train, X_val y X_test contienen los datos de entrada para los conjuntos de entrenamiento, validación y prueba, respectivamente.\n",
    "# y_train, y_val y y_test contienen las clases correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2376, 220, 8)\n",
      "(792, 220, 8)\n",
      "(89, 220, 8)\n",
      "(2376, 5)\n",
      "(792, 5)\n",
      "(89, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_def.shape)\n",
    "print(X_val_def.shape)\n",
    "print(X_test_def.shape)\n",
    "print(y_train_def.shape)\n",
    "print(y_val_def.shape)\n",
    "print(y_test_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "\n",
    "#%tensorboard --logdir logs\n",
    "#log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"\n",
    "    Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\n",
    "    \"\"\"\n",
    "    \n",
    "    buf = io.BytesIO()\n",
    "    \n",
    "    # Use plt.savefig to save the plot to a PNG in memory.\n",
    "    plt.savefig(buf, format='png')\n",
    "    \n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    \n",
    "    # Use tf.image.decode_png to convert the PNG buffer\n",
    "    # to a TF image. Make sure you use 4 channels.\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    \n",
    "    # Use tf.expand_dims to add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "       class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    \n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    # Normalize the confusion matrix.\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    \n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    threshold = 0.5\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"red\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_aprendizaje=0.01\n",
    "dimension_LSTM=50\n",
    "dimension_dense=50\n",
    "algoritmo='adam'\n",
    "supermax=8*4\n",
    "lossfunction='categorical_crossentropy'\n",
    "def create_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(GRU(dimension_LSTM, return_sequences=True,input_shape=(220, 8)))\n",
    "    model.add(GRU(50, return_sequences=True))\n",
    "    model.add(GRU(50, return_sequences=True))\n",
    "    model.add(GRU(50, return_sequences=False))\n",
    "    model.add(Dense(dimension_dense, activation='tanh'))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    model.compile(loss=lossfunction, optimizer=algoritmo, metrics=['accuracy'])\n",
    "    model.optimizer.lr=(factor_aprendizaje)\n",
    "    return model\n",
    "\n",
    "model=create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "experimento=\"LOMOS_P2_GRU4_5_clasesfiltrado_{}_dense_onehot_{}_loss_{}_lr_{}_algoritmo_{}\".format(dimension_LSTM,dimension_dense,lossfunction,factor_aprendizaje,algoritmo)\n",
    "logdir=\"./logs/defs/{}_{}\".format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=['A', 'B+', 'B', 'B-','C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    \n",
    "    # Use the model to predict the values from the test_images.\n",
    "    y_pred = model.predict(X_test_def)\n",
    "    #y_pred1=y_pred[:,-1]\n",
    "    y_pred2=y_pred.argmax(axis=1)\n",
    "    #y_pred2=np.where(y_pred>0,1,0)\n",
    "    #y_pred2=y_pred2[:,-1]\n",
    "    classes = [0, 1, 2, 3, 4] \n",
    "    #classes = [0, 1]\n",
    "    y_test_def2=np.argmax(y_test_def,axis=1)  \n",
    "    #y_test_def2=np.where(y_test_def>0,1,0)\n",
    "    cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    figura = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figura)\n",
    "    \n",
    "    # Log the confusion matrix as an image summary.\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3168, 5)\n",
      "(792, 5)\n"
     ]
    }
   ],
   "source": [
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "print(y_train_Normalizado.shape)\n",
    "print(y_val_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un callback para guardar los mejores pesos\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('best_weights.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "3/3 [==============================] - 1s 23ms/steploss: 1.4185 - accuracy: 0.41\n",
      "32/32 [==============================] - 11s 167ms/step - loss: 1.4185 - accuracy: 0.4110 - val_loss: 1.3562 - val_accuracy: 0.4482\n",
      "Epoch 2/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 1.3607 - accuracy: 0.44\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 1.3607 - accuracy: 0.4479 - val_loss: 1.3533 - val_accuracy: 0.4482\n",
      "Epoch 3/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 1.3526 - accuracy: 0.44\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 1.3526 - accuracy: 0.4473 - val_loss: 1.3518 - val_accuracy: 0.4482\n",
      "Epoch 4/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 1.3521 - accuracy: 0.45\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 1.3523 - accuracy: 0.4504 - val_loss: 1.3463 - val_accuracy: 0.4482\n",
      "Epoch 5/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 1.3500 - accuracy: 0.44\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 1.3510 - accuracy: 0.4457 - val_loss: 1.3922 - val_accuracy: 0.4255\n",
      "Epoch 6/4000\n",
      "3/3 [==============================] - 0s 45ms/steploss: 1.3623 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 1.3623 - accuracy: 0.4400 - val_loss: 1.3534 - val_accuracy: 0.4419\n",
      "Epoch 7/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 1.3464 - accuracy: 0.44\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 1.3464 - accuracy: 0.4495 - val_loss: 1.3269 - val_accuracy: 0.4533\n",
      "Epoch 8/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 1.3112 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 1.3112 - accuracy: 0.4628 - val_loss: 1.3057 - val_accuracy: 0.4293\n",
      "Epoch 9/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 1.3091 - accuracy: 0.46\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 1.3091 - accuracy: 0.4669 - val_loss: 1.2878 - val_accuracy: 0.4558\n",
      "Epoch 10/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 1.2712 - accuracy: 0.46\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 1.2683 - accuracy: 0.4684 - val_loss: 1.2187 - val_accuracy: 0.4697\n",
      "Epoch 11/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 1.2015 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 1.2015 - accuracy: 0.4776 - val_loss: 1.1536 - val_accuracy: 0.4558\n",
      "Epoch 12/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 1.1574 - accuracy: 0.50\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 1.1574 - accuracy: 0.5006 - val_loss: 1.1255 - val_accuracy: 0.5000\n",
      "Epoch 13/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 1.1259 - accuracy: 0.51\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 1.1259 - accuracy: 0.5110 - val_loss: 1.1448 - val_accuracy: 0.4444\n",
      "Epoch 14/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 1.0994 - accuracy: 0.50\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 1.0994 - accuracy: 0.5079 - val_loss: 0.9681 - val_accuracy: 0.5896\n",
      "Epoch 15/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 1.0582 - accuracy: 0.54\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 1.0565 - accuracy: 0.5442 - val_loss: 0.9864 - val_accuracy: 0.5884\n",
      "Epoch 16/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.9775 - accuracy: 0.56\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.9775 - accuracy: 0.5698 - val_loss: 1.0555 - val_accuracy: 0.4823\n",
      "Epoch 17/4000\n",
      "3/3 [==============================] - 0s 40ms/steploss: 0.8958 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.8958 - accuracy: 0.6023 - val_loss: 0.9194 - val_accuracy: 0.6073\n",
      "Epoch 18/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.8092 - accuracy: 0.64\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.8092 - accuracy: 0.6458 - val_loss: 0.7637 - val_accuracy: 0.6667\n",
      "Epoch 19/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.7968 - accuracy: 0.66\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.7968 - accuracy: 0.6629 - val_loss: 0.6634 - val_accuracy: 0.6970\n",
      "Epoch 20/4000\n",
      "3/3 [==============================] - 0s 32ms/steploss: 0.7271 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.7271 - accuracy: 0.7004 - val_loss: 0.7657 - val_accuracy: 0.7071\n",
      "Epoch 21/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.6524 - accuracy: 0.73\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.6524 - accuracy: 0.7317 - val_loss: 0.5123 - val_accuracy: 0.7891\n",
      "Epoch 22/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.5956 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.5956 - accuracy: 0.7667 - val_loss: 0.9270 - val_accuracy: 0.7083\n",
      "Epoch 23/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 1.4700 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 1.4648 - accuracy: 0.4593 - val_loss: 1.3667 - val_accuracy: 0.4482\n",
      "Epoch 24/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 1.3377 - accuracy: 0.42\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 1.3377 - accuracy: 0.4252 - val_loss: 1.3385 - val_accuracy: 0.4482\n",
      "Epoch 25/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 1.3401 - accuracy: 0.44\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 1.3401 - accuracy: 0.4403 - val_loss: 1.3445 - val_accuracy: 0.4482\n",
      "Epoch 26/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 1.3266 - accuracy: 0.43\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 1.3266 - accuracy: 0.4309 - val_loss: 1.3724 - val_accuracy: 0.3548\n",
      "Epoch 27/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 1.3451 - accuracy: 0.42\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 1.3451 - accuracy: 0.4239 - val_loss: 1.3262 - val_accuracy: 0.4482\n",
      "Epoch 28/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 1.3113 - accuracy: 0.42\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 1.3113 - accuracy: 0.4255 - val_loss: 1.3220 - val_accuracy: 0.4482\n",
      "Epoch 29/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 1.3210 - accuracy: 0.43\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 1.3210 - accuracy: 0.4334 - val_loss: 1.3023 - val_accuracy: 0.4482\n",
      "Epoch 30/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 1.2998 - accuracy: 0.43\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 1.2998 - accuracy: 0.4378 - val_loss: 1.3178 - val_accuracy: 0.4482\n",
      "Epoch 31/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 1.3114 - accuracy: 0.44\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 1.3114 - accuracy: 0.4444 - val_loss: 1.3339 - val_accuracy: 0.3965\n",
      "Epoch 32/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 1.3033 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 1.3033 - accuracy: 0.4470 - val_loss: 1.3060 - val_accuracy: 0.4583\n",
      "Epoch 33/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 1.3027 - accuracy: 0.45\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 1.3027 - accuracy: 0.4596 - val_loss: 1.3826 - val_accuracy: 0.4583\n",
      "Epoch 34/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 1.3007 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 1.3007 - accuracy: 0.4467 - val_loss: 1.3088 - val_accuracy: 0.3497\n",
      "Epoch 35/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 1.2889 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 1.2889 - accuracy: 0.4375 - val_loss: 1.2697 - val_accuracy: 0.4697\n",
      "Epoch 36/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 1.2687 - accuracy: 0.45\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 1.2687 - accuracy: 0.4564 - val_loss: 1.2767 - val_accuracy: 0.4634\n",
      "Epoch 37/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 1.2686 - accuracy: 0.44\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 1.2686 - accuracy: 0.4479 - val_loss: 1.2994 - val_accuracy: 0.4735\n",
      "Epoch 38/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 1.2563 - accuracy: 0.45\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 1.2563 - accuracy: 0.4533 - val_loss: 1.2424 - val_accuracy: 0.5038\n",
      "Epoch 39/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 1.2302 - accuracy: 0.47\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 1.2304 - accuracy: 0.4713 - val_loss: 1.2642 - val_accuracy: 0.4369\n",
      "Epoch 40/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 1.2642 - accuracy: 0.45\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 1.2616 - accuracy: 0.4549 - val_loss: 1.2050 - val_accuracy: 0.4848\n",
      "Epoch 41/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 1.2274 - accuracy: 0.47\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 1.2274 - accuracy: 0.4700 - val_loss: 1.2131 - val_accuracy: 0.4545\n",
      "Epoch 42/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 1.2411 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 1.2411 - accuracy: 0.4643 - val_loss: 1.2194 - val_accuracy: 0.4760\n",
      "Epoch 43/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 1.2085 - accuracy: 0.46\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 1.2085 - accuracy: 0.4634 - val_loss: 1.2082 - val_accuracy: 0.4811\n",
      "Epoch 44/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 1.2400 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 1.2400 - accuracy: 0.4568 - val_loss: 1.2457 - val_accuracy: 0.4646\n",
      "Epoch 45/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 1.2264 - accuracy: 0.45\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 1.2236 - accuracy: 0.4552 - val_loss: 1.2551 - val_accuracy: 0.4343\n",
      "Epoch 46/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 1.2577 - accuracy: 0.45\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 1.2577 - accuracy: 0.4549 - val_loss: 1.1936 - val_accuracy: 0.4798\n",
      "Epoch 47/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 1.1694 - accuracy: 0.48\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 1.1670 - accuracy: 0.4880 - val_loss: 1.2999 - val_accuracy: 0.4167\n",
      "Epoch 48/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 1.2292 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 1.2292 - accuracy: 0.4583 - val_loss: 1.1883 - val_accuracy: 0.4874\n",
      "Epoch 49/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 1.2010 - accuracy: 0.49\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 1.2010 - accuracy: 0.4918 - val_loss: 1.1646 - val_accuracy: 0.4861\n",
      "Epoch 50/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 1.1082 - accuracy: 0.52\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 1.1082 - accuracy: 0.5246 - val_loss: 1.1636 - val_accuracy: 0.4924\n",
      "Epoch 51/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 1.1346 - accuracy: 0.49\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 1.1346 - accuracy: 0.4946 - val_loss: 1.0478 - val_accuracy: 0.5884\n",
      "Epoch 52/4000\n",
      "3/3 [==============================] - 0s 28ms/steploss: 1.0783 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 1.0789 - accuracy: 0.5401 - val_loss: 0.9846 - val_accuracy: 0.6124\n",
      "Epoch 53/4000\n",
      "3/3 [==============================] - 0s 28ms/steploss: 0.9983 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.9995 - accuracy: 0.5953 - val_loss: 0.9718 - val_accuracy: 0.5581\n",
      "Epoch 54/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.9708 - accuracy: 0.58\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.9708 - accuracy: 0.5887 - val_loss: 0.9409 - val_accuracy: 0.5997\n",
      "Epoch 55/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.9897 - accuracy: 0.59\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.9869 - accuracy: 0.5925 - val_loss: 0.8636 - val_accuracy: 0.6376\n",
      "Epoch 56/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.8958 - accuracy: 0.62\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.8958 - accuracy: 0.6215 - val_loss: 0.7876 - val_accuracy: 0.6957\n",
      "Epoch 57/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.8135 - accuracy: 0.66\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.8135 - accuracy: 0.6654 - val_loss: 0.8688 - val_accuracy: 0.6806\n",
      "Epoch 58/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.8622 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 84ms/step - loss: 0.8622 - accuracy: 0.6588 - val_loss: 1.0249 - val_accuracy: 0.5455\n",
      "Epoch 59/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.9086 - accuracy: 0.63\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.9086 - accuracy: 0.6360 - val_loss: 0.8298 - val_accuracy: 0.6427\n",
      "Epoch 60/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.7707 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.7707 - accuracy: 0.6818 - val_loss: 0.6503 - val_accuracy: 0.7538\n",
      "Epoch 61/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.6445 - accuracy: 0.74\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.6445 - accuracy: 0.7462 - val_loss: 0.6235 - val_accuracy: 0.7551\n",
      "Epoch 62/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.7718 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.7718 - accuracy: 0.6774 - val_loss: 0.6467 - val_accuracy: 0.7677\n",
      "Epoch 63/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.6157 - accuracy: 0.74\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.6157 - accuracy: 0.7459 - val_loss: 0.5336 - val_accuracy: 0.8018\n",
      "Epoch 64/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.5346 - accuracy: 0.77\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.5346 - accuracy: 0.7737 - val_loss: 0.5121 - val_accuracy: 0.7891\n",
      "Epoch 65/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.5182 - accuracy: 0.78\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.5182 - accuracy: 0.7816 - val_loss: 0.4518 - val_accuracy: 0.7992\n",
      "Epoch 66/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.5662 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.5684 - accuracy: 0.7753 - val_loss: 0.6573 - val_accuracy: 0.7008\n",
      "Epoch 67/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.5253 - accuracy: 0.77\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.5253 - accuracy: 0.7787 - val_loss: 0.3414 - val_accuracy: 0.8662\n",
      "Epoch 68/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.5622 - accuracy: 0.76\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.5622 - accuracy: 0.7648 - val_loss: 0.6762 - val_accuracy: 0.7020\n",
      "Epoch 69/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.8051 - accuracy: 0.67\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.8051 - accuracy: 0.6711 - val_loss: 0.7270 - val_accuracy: 0.7033\n",
      "Epoch 70/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.5869 - accuracy: 0.77\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.5829 - accuracy: 0.7746 - val_loss: 0.3985 - val_accuracy: 0.8763\n",
      "Epoch 71/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.3844 - accuracy: 0.85\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.3844 - accuracy: 0.8504 - val_loss: 0.3032 - val_accuracy: 0.8699\n",
      "Epoch 72/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3312 - accuracy: 0.85\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3312 - accuracy: 0.8583 - val_loss: 0.3047 - val_accuracy: 0.8801\n",
      "Epoch 73/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.3278 - accuracy: 0.86\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.3288 - accuracy: 0.8640 - val_loss: 0.3924 - val_accuracy: 0.8548\n",
      "Epoch 74/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.3374 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.3374 - accuracy: 0.8655 - val_loss: 0.4500 - val_accuracy: 0.8182\n",
      "Epoch 75/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3282 - accuracy: 0.85\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3277 - accuracy: 0.8602 - val_loss: 0.3789 - val_accuracy: 0.8510\n",
      "Epoch 76/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.4940 - accuracy: 0.80\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.4940 - accuracy: 0.8087 - val_loss: 0.3653 - val_accuracy: 0.8561\n",
      "Epoch 77/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.3581 - accuracy: 0.85\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.3572 - accuracy: 0.8554 - val_loss: 0.2666 - val_accuracy: 0.8889\n",
      "Epoch 78/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.5365 - accuracy: 0.79\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.5365 - accuracy: 0.7986 - val_loss: 0.9314 - val_accuracy: 0.6225\n",
      "Epoch 79/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.6198 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.6156 - accuracy: 0.7405 - val_loss: 0.4714 - val_accuracy: 0.7904\n",
      "Epoch 80/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3508 - accuracy: 0.85\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.3508 - accuracy: 0.8598 - val_loss: 0.4874 - val_accuracy: 0.8081\n",
      "Epoch 81/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.3289 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.3289 - accuracy: 0.8712 - val_loss: 0.1959 - val_accuracy: 0.9583\n",
      "Epoch 82/4000\n",
      "3/3 [==============================] - 0s 19ms/steploss: 0.3676 - accuracy: 0.85\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.3676 - accuracy: 0.8586 - val_loss: 0.2836 - val_accuracy: 0.9003\n",
      "Epoch 83/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.3521 - accuracy: 0.86\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.3521 - accuracy: 0.8611 - val_loss: 0.3711 - val_accuracy: 0.8523\n",
      "Epoch 84/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2449 - accuracy: 0.90\n",
      "32/32 [==============================] - 3s 82ms/step - loss: 0.2449 - accuracy: 0.9059 - val_loss: 0.1947 - val_accuracy: 0.9255\n",
      "Epoch 85/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.1740 - accuracy: 0.94\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1740 - accuracy: 0.9432 - val_loss: 0.2213 - val_accuracy: 0.9116\n",
      "Epoch 86/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2396 - accuracy: 0.90\n",
      "32/32 [==============================] - 2s 79ms/step - loss: 0.2396 - accuracy: 0.9018 - val_loss: 0.2513 - val_accuracy: 0.9003\n",
      "Epoch 87/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.1859 - accuracy: 0.93\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.1859 - accuracy: 0.9381 - val_loss: 0.1364 - val_accuracy: 0.9571\n",
      "Epoch 88/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.3218 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3218 - accuracy: 0.8763 - val_loss: 0.3072 - val_accuracy: 0.8586\n",
      "Epoch 89/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.1550 - accuracy: 0.94\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1550 - accuracy: 0.9422 - val_loss: 0.2474 - val_accuracy: 0.8914\n",
      "Epoch 90/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.1497 - accuracy: 0.94\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1497 - accuracy: 0.9444 - val_loss: 0.2229 - val_accuracy: 0.9078\n",
      "Epoch 91/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.1335 - accuracy: 0.95\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.1335 - accuracy: 0.9517 - val_loss: 0.0841 - val_accuracy: 0.9811\n",
      "Epoch 92/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.1067 - accuracy: 0.96\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1071 - accuracy: 0.9596 - val_loss: 0.1828 - val_accuracy: 0.9179\n",
      "Epoch 93/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2247 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2247 - accuracy: 0.9107 - val_loss: 0.2567 - val_accuracy: 0.8801\n",
      "Epoch 94/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2343 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2310 - accuracy: 0.9192 - val_loss: 0.1461 - val_accuracy: 0.9495\n",
      "Epoch 95/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.1822 - accuracy: 0.93\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1847 - accuracy: 0.9328 - val_loss: 0.3297 - val_accuracy: 0.8573\n",
      "Epoch 96/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.2427 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2409 - accuracy: 0.8952 - val_loss: 0.1739 - val_accuracy: 0.9394\n",
      "Epoch 97/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.1621 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1621 - accuracy: 0.9375 - val_loss: 0.0838 - val_accuracy: 0.9722\n",
      "Epoch 98/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.1274 - accuracy: 0.95\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1274 - accuracy: 0.9568 - val_loss: 0.2875 - val_accuracy: 0.8876\n",
      "Epoch 99/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.3348 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 73ms/step - loss: 0.3348 - accuracy: 0.8725 - val_loss: 0.3616 - val_accuracy: 0.8851\n",
      "Epoch 100/4000\n",
      "3/3 [==============================] - 0s 19ms/steploss: 0.5414 - accuracy: 0.80\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.5414 - accuracy: 0.8049 - val_loss: 0.3871 - val_accuracy: 0.8371\n",
      "Epoch 101/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2425 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2388 - accuracy: 0.8968 - val_loss: 0.1066 - val_accuracy: 0.9848\n",
      "Epoch 102/4000\n",
      "3/3 [==============================] - 0s 19ms/steploss: 0.1239 - accuracy: 0.95\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.1231 - accuracy: 0.9527 - val_loss: 0.1122 - val_accuracy: 0.9659\n",
      "Epoch 103/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.0878 - accuracy: 0.96\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.0878 - accuracy: 0.9672 - val_loss: 0.0612 - val_accuracy: 0.9874\n",
      "Epoch 104/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.0793 - accuracy: 0.97\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.0793 - accuracy: 0.9713 - val_loss: 0.0980 - val_accuracy: 0.9571\n",
      "Epoch 105/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.1265 - accuracy: 0.95\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1302 - accuracy: 0.9549 - val_loss: 0.1888 - val_accuracy: 0.9381\n",
      "Epoch 106/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.1714 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.1721 - accuracy: 0.9274 - val_loss: 0.1381 - val_accuracy: 0.9381\n",
      "Epoch 107/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.1881 - accuracy: 0.93\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.1881 - accuracy: 0.9337 - val_loss: 0.6582 - val_accuracy: 0.7588\n",
      "Epoch 108/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.7491 - accuracy: 0.75\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.7491 - accuracy: 0.7566 - val_loss: 0.9631 - val_accuracy: 0.6528\n",
      "Epoch 109/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.4928 - accuracy: 0.80\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.4928 - accuracy: 0.8049 - val_loss: 0.2456 - val_accuracy: 0.8826\n",
      "Epoch 110/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.1857 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1855 - accuracy: 0.9296 - val_loss: 0.1768 - val_accuracy: 0.9520\n",
      "Epoch 111/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.1593 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1593 - accuracy: 0.9400 - val_loss: 0.0928 - val_accuracy: 0.9659\n",
      "Epoch 112/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.1647 - accuracy: 0.93\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1661 - accuracy: 0.9328 - val_loss: 0.1640 - val_accuracy: 0.9369\n",
      "Epoch 113/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.0965 - accuracy: 0.96\n",
      "32/32 [==============================] - 2s 73ms/step - loss: 0.0980 - accuracy: 0.9672 - val_loss: 0.1115 - val_accuracy: 0.9596\n",
      "Epoch 114/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.1482 - accuracy: 0.94\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.1475 - accuracy: 0.9451 - val_loss: 0.2494 - val_accuracy: 0.9205\n",
      "Epoch 115/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.1651 - accuracy: 0.95\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1651 - accuracy: 0.9580 - val_loss: 0.0933 - val_accuracy: 0.9520\n",
      "Epoch 116/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.1911 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1911 - accuracy: 0.9268 - val_loss: 0.2772 - val_accuracy: 0.8573\n",
      "Epoch 117/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.4766 - accuracy: 0.82\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.4813 - accuracy: 0.8194 - val_loss: 0.8638 - val_accuracy: 0.7109\n",
      "Epoch 118/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.5751 - accuracy: 0.78\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.5687 - accuracy: 0.7885 - val_loss: 0.3569 - val_accuracy: 0.8472\n",
      "Epoch 119/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2376 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2376 - accuracy: 0.9179 - val_loss: 0.3098 - val_accuracy: 0.8725\n",
      "Epoch 120/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2596 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2560 - accuracy: 0.9012 - val_loss: 0.1851 - val_accuracy: 0.9545\n",
      "Epoch 121/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.1158 - accuracy: 0.96\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.1158 - accuracy: 0.9609 - val_loss: 0.0771 - val_accuracy: 0.9798\n",
      "Epoch 122/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.1082 - accuracy: 0.96\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.1102 - accuracy: 0.9631 - val_loss: 0.0880 - val_accuracy: 0.9684\n",
      "Epoch 123/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.1114 - accuracy: 0.95\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1114 - accuracy: 0.9523 - val_loss: 0.0667 - val_accuracy: 0.9722\n",
      "Epoch 124/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.0716 - accuracy: 0.97\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.0716 - accuracy: 0.9766 - val_loss: 0.0918 - val_accuracy: 0.9634\n",
      "Epoch 125/4000\n",
      "3/3 [==============================] - 0s 19ms/steploss: 0.1889 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1889 - accuracy: 0.9255 - val_loss: 0.2346 - val_accuracy: 0.8838\n",
      "Epoch 126/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.1595 - accuracy: 0.93\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.1595 - accuracy: 0.9378 - val_loss: 0.0964 - val_accuracy: 0.9533\n",
      "Epoch 127/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.0858 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.0858 - accuracy: 0.9612 - val_loss: 0.0664 - val_accuracy: 0.9697\n",
      "Epoch 128/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.1060 - accuracy: 0.95\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.1060 - accuracy: 0.9596 - val_loss: 0.2167 - val_accuracy: 0.9293\n",
      "Epoch 129/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.1033 - accuracy: 0.95\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.1028 - accuracy: 0.9599 - val_loss: 0.0907 - val_accuracy: 0.9634\n",
      "Epoch 130/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.1160 - accuracy: 0.95\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.1160 - accuracy: 0.9511 - val_loss: 0.2503 - val_accuracy: 0.8864\n",
      "Epoch 131/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.1553 - accuracy: 0.94\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.1553 - accuracy: 0.9407 - val_loss: 0.1996 - val_accuracy: 0.9242\n",
      "Epoch 132/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2156 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.2156 - accuracy: 0.9242 - val_loss: 1.4784 - val_accuracy: 0.6641\n",
      "Epoch 133/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.8694 - accuracy: 0.71\n",
      "32/32 [==============================] - 2s 73ms/step - loss: 0.8694 - accuracy: 0.7150 - val_loss: 0.8045 - val_accuracy: 0.7058\n",
      "Epoch 134/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.3951 - accuracy: 0.83\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.3951 - accuracy: 0.8368 - val_loss: 0.2660 - val_accuracy: 0.8636\n",
      "Epoch 135/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.3666 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.3666 - accuracy: 0.8668 - val_loss: 0.2655 - val_accuracy: 0.9154\n",
      "Epoch 136/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.1542 - accuracy: 0.95\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1535 - accuracy: 0.9508 - val_loss: 0.1032 - val_accuracy: 0.9634\n",
      "Epoch 137/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.1179 - accuracy: 0.95\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.1179 - accuracy: 0.9545 - val_loss: 0.1332 - val_accuracy: 0.9369\n",
      "Epoch 138/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.1756 - accuracy: 0.92\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.1756 - accuracy: 0.9252 - val_loss: 0.0939 - val_accuracy: 0.9722\n",
      "Epoch 139/4000\n",
      "3/3 [==============================] - 0s 28ms/steploss: 0.1222 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.1222 - accuracy: 0.9523 - val_loss: 0.1323 - val_accuracy: 0.9583\n",
      "Epoch 140/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.1177 - accuracy: 0.95\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.1177 - accuracy: 0.9568 - val_loss: 0.1390 - val_accuracy: 0.9508\n",
      "Epoch 141/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.1380 - accuracy: 0.94\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.1360 - accuracy: 0.9444 - val_loss: 0.0963 - val_accuracy: 0.9684\n",
      "Epoch 142/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.1036 - accuracy: 0.96\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.1036 - accuracy: 0.9624 - val_loss: 0.0869 - val_accuracy: 0.9646\n",
      "Epoch 143/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.1081 - accuracy: 0.95\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1081 - accuracy: 0.9583 - val_loss: 0.1029 - val_accuracy: 0.9470\n",
      "Epoch 144/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.0779 - accuracy: 0.97\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.0779 - accuracy: 0.9706 - val_loss: 0.0587 - val_accuracy: 0.9697\n",
      "Epoch 145/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3262 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.3262 - accuracy: 0.8883 - val_loss: 0.2577 - val_accuracy: 0.8889\n",
      "Epoch 146/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2640 - accuracy: 0.90\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.2640 - accuracy: 0.9028 - val_loss: 0.1360 - val_accuracy: 0.9369\n",
      "Epoch 147/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.0895 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.0895 - accuracy: 0.9653 - val_loss: 0.2107 - val_accuracy: 0.9091\n",
      "Epoch 148/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.1694 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1694 - accuracy: 0.9337 - val_loss: 0.4754 - val_accuracy: 0.8497\n",
      "Epoch 149/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.3420 - accuracy: 0.86\n",
      "32/32 [==============================] - 3s 91ms/step - loss: 0.3420 - accuracy: 0.8681 - val_loss: 0.2164 - val_accuracy: 0.9192\n",
      "Epoch 150/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.1841 - accuracy: 0.93\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.1858 - accuracy: 0.9321 - val_loss: 0.1907 - val_accuracy: 0.9192\n",
      "Epoch 151/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.1460 - accuracy: 0.94\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.1460 - accuracy: 0.9438 - val_loss: 0.0961 - val_accuracy: 0.9571\n",
      "Epoch 152/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.0730 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.0730 - accuracy: 0.9751 - val_loss: 0.0502 - val_accuracy: 0.9811\n",
      "Epoch 153/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.0372 - accuracy: 0.98\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.0372 - accuracy: 0.9864 - val_loss: 0.0297 - val_accuracy: 0.9899\n",
      "Epoch 154/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.0569 - accuracy: 0.97\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.0569 - accuracy: 0.9757 - val_loss: 0.1368 - val_accuracy: 0.9470\n",
      "Epoch 155/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.1284 - accuracy: 0.94\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1317 - accuracy: 0.9476 - val_loss: 0.1716 - val_accuracy: 0.9419\n",
      "Epoch 156/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.3236 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.3247 - accuracy: 0.8924 - val_loss: 0.4343 - val_accuracy: 0.8346\n",
      "Epoch 157/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.2273 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 84ms/step - loss: 0.2273 - accuracy: 0.9261 - val_loss: 0.0875 - val_accuracy: 0.9621\n",
      "Epoch 158/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.1040 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.1023 - accuracy: 0.9580 - val_loss: 0.0659 - val_accuracy: 0.9659\n",
      "Epoch 159/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.0636 - accuracy: 0.97\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.0630 - accuracy: 0.9710 - val_loss: 0.0641 - val_accuracy: 0.9710\n",
      "Epoch 160/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.0472 - accuracy: 0.97\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.0470 - accuracy: 0.9747 - val_loss: 0.0536 - val_accuracy: 0.9785\n",
      "Epoch 161/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.0393 - accuracy: 0.98\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.0403 - accuracy: 0.9820 - val_loss: 0.0652 - val_accuracy: 0.9773\n",
      "Epoch 162/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.1479 - accuracy: 0.95\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.1489 - accuracy: 0.9495 - val_loss: 0.2391 - val_accuracy: 0.8990\n",
      "Epoch 163/4000\n",
      "3/3 [==============================] - 0s 29ms/steploss: 0.1460 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1460 - accuracy: 0.9410 - val_loss: 0.0582 - val_accuracy: 0.9798\n",
      "Epoch 164/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.1434 - accuracy: 0.94\n",
      "32/32 [==============================] - 3s 93ms/step - loss: 0.1434 - accuracy: 0.9454 - val_loss: 0.4214 - val_accuracy: 0.8510\n",
      "Epoch 165/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2935 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2896 - accuracy: 0.8801 - val_loss: 0.3614 - val_accuracy: 0.8801\n",
      "Epoch 166/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.1795 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1818 - accuracy: 0.9277 - val_loss: 0.0923 - val_accuracy: 0.9558\n",
      "Epoch 167/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.2921 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 73ms/step - loss: 0.2921 - accuracy: 0.8835 - val_loss: 0.3265 - val_accuracy: 0.9003\n",
      "Epoch 168/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.1810 - accuracy: 0.93\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.1810 - accuracy: 0.9356 - val_loss: 0.0786 - val_accuracy: 0.9697\n",
      "Epoch 169/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.0644 - accuracy: 0.97\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.0647 - accuracy: 0.9703 - val_loss: 0.1290 - val_accuracy: 0.9482\n",
      "Epoch 170/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.0777 - accuracy: 0.96\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.0771 - accuracy: 0.9681 - val_loss: 0.0572 - val_accuracy: 0.9735\n",
      "Epoch 171/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.1079 - accuracy: 0.95\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1079 - accuracy: 0.9561 - val_loss: 0.0963 - val_accuracy: 0.9583\n",
      "Epoch 172/4000\n",
      "3/3 [==============================] - 0s 28ms/steploss: 0.2905 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.2905 - accuracy: 0.8902 - val_loss: 0.2432 - val_accuracy: 0.8965\n",
      "Epoch 173/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.1906 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.1906 - accuracy: 0.9208 - val_loss: 0.1241 - val_accuracy: 0.9306\n",
      "Epoch 174/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.0984 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.0984 - accuracy: 0.9634 - val_loss: 0.1765 - val_accuracy: 0.9293\n",
      "Epoch 175/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.1411 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 79ms/step - loss: 0.1411 - accuracy: 0.9457 - val_loss: 0.0959 - val_accuracy: 0.9659\n",
      "Epoch 176/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.1104 - accuracy: 0.96\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.1090 - accuracy: 0.9624 - val_loss: 0.0995 - val_accuracy: 0.9583\n",
      "Epoch 177/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.0633 - accuracy: 0.97\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.0631 - accuracy: 0.9757 - val_loss: 0.0454 - val_accuracy: 0.9785\n",
      "Epoch 178/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.0378 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.0382 - accuracy: 0.9845 - val_loss: 0.0366 - val_accuracy: 0.9861\n",
      "Epoch 179/4000\n",
      "3/3 [==============================] - 0s 28ms/steploss: 0.0309 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.0309 - accuracy: 0.9855 - val_loss: 0.0301 - val_accuracy: 0.9798\n",
      "Epoch 180/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.1078 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.1078 - accuracy: 0.9530 - val_loss: 0.0806 - val_accuracy: 0.9684\n",
      "Epoch 181/4000\n",
      "3/3 [==============================] - 0s 30ms/steploss: 0.4040 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.4113 - accuracy: 0.8759 - val_loss: 0.7125 - val_accuracy: 0.7513\n",
      "Epoch 182/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3404 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.3404 - accuracy: 0.8706 - val_loss: 0.1407 - val_accuracy: 0.9545\n",
      "Epoch 183/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.0870 - accuracy: 0.96\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.0857 - accuracy: 0.9700 - val_loss: 0.0695 - val_accuracy: 0.9836\n",
      "Epoch 184/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.0537 - accuracy: 0.97\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.0537 - accuracy: 0.9782 - val_loss: 0.0447 - val_accuracy: 0.9823\n",
      "Epoch 185/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.0370 - accuracy: 0.98\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.0370 - accuracy: 0.9842 - val_loss: 0.0303 - val_accuracy: 0.9912\n",
      "Epoch 186/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.0753 - accuracy: 0.97\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.0761 - accuracy: 0.9719 - val_loss: 0.1084 - val_accuracy: 0.9482\n",
      "Epoch 187/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.1753 - accuracy: 0.93\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.1753 - accuracy: 0.9334 - val_loss: 0.1155 - val_accuracy: 0.9621\n",
      "Epoch 188/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.1137 - accuracy: 0.95\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1137 - accuracy: 0.9552 - val_loss: 0.0591 - val_accuracy: 0.9735\n",
      "Epoch 189/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.0492 - accuracy: 0.98\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.0493 - accuracy: 0.9814 - val_loss: 0.0409 - val_accuracy: 0.9886\n",
      "Epoch 190/4000\n",
      "3/3 [==============================] - 0s 32ms/steploss: 0.0281 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.0281 - accuracy: 0.9861 - val_loss: 0.0238 - val_accuracy: 0.9912\n",
      "Epoch 191/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.1535 - accuracy: 0.94\n",
      "32/32 [==============================] - 2s 79ms/step - loss: 0.1535 - accuracy: 0.9460 - val_loss: 0.7123 - val_accuracy: 0.8018\n",
      "Epoch 192/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.7808 - accuracy: 0.72\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.7808 - accuracy: 0.7222 - val_loss: 0.5284 - val_accuracy: 0.8119\n",
      "Epoch 193/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.3570 - accuracy: 0.85\n",
      "32/32 [==============================] - 3s 83ms/step - loss: 0.3570 - accuracy: 0.8539 - val_loss: 0.3067 - val_accuracy: 0.8977\n",
      "Epoch 194/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2450 - accuracy: 0.90\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2450 - accuracy: 0.9066 - val_loss: 0.5235 - val_accuracy: 0.8043\n",
      "Epoch 195/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.2846 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2846 - accuracy: 0.8883 - val_loss: 0.1851 - val_accuracy: 0.9407\n",
      "Epoch 196/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.1317 - accuracy: 0.96\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1317 - accuracy: 0.9634 - val_loss: 0.0993 - val_accuracy: 0.9747\n",
      "Epoch 197/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.1161 - accuracy: 0.95\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1161 - accuracy: 0.9571 - val_loss: 0.0803 - val_accuracy: 0.9697\n",
      "Epoch 198/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.1091 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1091 - accuracy: 0.9545 - val_loss: 0.0677 - val_accuracy: 0.9760\n",
      "Epoch 199/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.0843 - accuracy: 0.96\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.0843 - accuracy: 0.9675 - val_loss: 0.2467 - val_accuracy: 0.9078\n",
      "Epoch 200/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.0912 - accuracy: 0.96\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.0912 - accuracy: 0.9643 - val_loss: 0.1077 - val_accuracy: 0.9710\n",
      "Epoch 201/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.0752 - accuracy: 0.97\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.0752 - accuracy: 0.9713 - val_loss: 0.0591 - val_accuracy: 0.9710\n",
      "Epoch 202/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.0578 - accuracy: 0.97\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.0578 - accuracy: 0.9757 - val_loss: 0.0455 - val_accuracy: 0.9785\n",
      "Epoch 203/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.0961 - accuracy: 0.96\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.0961 - accuracy: 0.9634 - val_loss: 0.0575 - val_accuracy: 0.9747\n",
      "Epoch 204/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.1544 - accuracy: 0.94\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1544 - accuracy: 0.9419 - val_loss: 0.1258 - val_accuracy: 0.9482\n",
      "Epoch 205/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.0931 - accuracy: 0.96\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.0927 - accuracy: 0.9621 - val_loss: 0.0649 - val_accuracy: 0.9735\n",
      "Epoch 206/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.0728 - accuracy: 0.97\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.0726 - accuracy: 0.9741 - val_loss: 0.0473 - val_accuracy: 0.9811\n",
      "Epoch 207/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2026 - accuracy: 0.93\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2008 - accuracy: 0.9337 - val_loss: 0.1637 - val_accuracy: 0.9457\n",
      "Epoch 208/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.1043 - accuracy: 0.95\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.1028 - accuracy: 0.9590 - val_loss: 0.0498 - val_accuracy: 0.9899\n",
      "Epoch 209/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.0540 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.0540 - accuracy: 0.9801 - val_loss: 0.0342 - val_accuracy: 0.9874\n",
      "Epoch 210/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.0478 - accuracy: 0.98\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.0478 - accuracy: 0.9801 - val_loss: 0.0313 - val_accuracy: 0.9886\n",
      "Epoch 211/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.0849 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.0860 - accuracy: 0.9675 - val_loss: 0.2808 - val_accuracy: 0.9242\n",
      "Epoch 212/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.1005 - accuracy: 0.96\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1023 - accuracy: 0.9675 - val_loss: 0.0610 - val_accuracy: 0.9747\n",
      "Epoch 213/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.1440 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.1440 - accuracy: 0.9460 - val_loss: 0.2792 - val_accuracy: 0.8838\n",
      "Epoch 214/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.4318 - accuracy: 0.85\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.4402 - accuracy: 0.8551 - val_loss: 0.5007 - val_accuracy: 0.8434\n",
      "Epoch 215/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.4152 - accuracy: 0.85\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.4152 - accuracy: 0.8583 - val_loss: 0.1871 - val_accuracy: 0.9129\n",
      "Epoch 216/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.1316 - accuracy: 0.95\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.1316 - accuracy: 0.9533 - val_loss: 0.0825 - val_accuracy: 0.9760\n",
      "Epoch 217/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.2268 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2255 - accuracy: 0.9214 - val_loss: 0.3586 - val_accuracy: 0.8801\n",
      "Epoch 218/4000\n",
      "3/3 [==============================] - 0s 28ms/steploss: 0.2242 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2242 - accuracy: 0.9182 - val_loss: 0.4641 - val_accuracy: 0.8573\n",
      "Epoch 219/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2215 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2215 - accuracy: 0.9148 - val_loss: 0.1485 - val_accuracy: 0.9343\n",
      "Epoch 220/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.1293 - accuracy: 0.95\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1277 - accuracy: 0.9514 - val_loss: 0.0496 - val_accuracy: 0.9848\n",
      "Epoch 221/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.0605 - accuracy: 0.97\n",
      "32/32 [==============================] - 3s 82ms/step - loss: 0.0605 - accuracy: 0.9782 - val_loss: 0.0552 - val_accuracy: 0.9722\n",
      "Epoch 222/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.0550 - accuracy: 0.97\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.0542 - accuracy: 0.9792 - val_loss: 0.0321 - val_accuracy: 0.9912\n",
      "Epoch 223/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.0526 - accuracy: 0.97\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.0522 - accuracy: 0.9798 - val_loss: 0.2861 - val_accuracy: 0.8990\n",
      "Epoch 224/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2374 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.2374 - accuracy: 0.9223 - val_loss: 0.1007 - val_accuracy: 0.9533\n",
      "Epoch 225/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.1144 - accuracy: 0.95\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.1144 - accuracy: 0.9583 - val_loss: 0.0495 - val_accuracy: 0.9861\n",
      "Epoch 226/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.0501 - accuracy: 0.98\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.0501 - accuracy: 0.9817 - val_loss: 0.0370 - val_accuracy: 0.9811\n",
      "Epoch 227/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.0828 - accuracy: 0.96\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.0828 - accuracy: 0.9681 - val_loss: 0.1520 - val_accuracy: 0.9583\n",
      "Epoch 228/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3015 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3015 - accuracy: 0.8943 - val_loss: 0.5586 - val_accuracy: 0.8258\n",
      "Epoch 229/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.6886 - accuracy: 0.78\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.6886 - accuracy: 0.7803 - val_loss: 0.5740 - val_accuracy: 0.7803\n",
      "Epoch 230/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.4754 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.4754 - accuracy: 0.8125 - val_loss: 0.5809 - val_accuracy: 0.7967\n",
      "Epoch 231/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3990 - accuracy: 0.85\n",
      "32/32 [==============================] - 3s 84ms/step - loss: 0.3990 - accuracy: 0.8539 - val_loss: 0.2558 - val_accuracy: 0.8687\n",
      "Epoch 232/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.6731 - accuracy: 0.80\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.7265 - accuracy: 0.7964 - val_loss: 2.7977 - val_accuracy: 0.4040\n",
      "Epoch 233/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 1.5545 - accuracy: 0.47\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 1.5545 - accuracy: 0.4795 - val_loss: 1.1411 - val_accuracy: 0.5455\n",
      "Epoch 234/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 1.0598 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 1.0598 - accuracy: 0.5944 - val_loss: 0.8978 - val_accuracy: 0.6843\n",
      "Epoch 235/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.8904 - accuracy: 0.66\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.8955 - accuracy: 0.6641 - val_loss: 0.8880 - val_accuracy: 0.6553\n",
      "Epoch 236/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.8593 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.8593 - accuracy: 0.6749 - val_loss: 0.8007 - val_accuracy: 0.6982\n",
      "Epoch 237/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.7904 - accuracy: 0.69\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.7904 - accuracy: 0.6910 - val_loss: 0.6920 - val_accuracy: 0.7601\n",
      "Epoch 238/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.7064 - accuracy: 0.73\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.7069 - accuracy: 0.7383 - val_loss: 0.6741 - val_accuracy: 0.7551\n",
      "Epoch 239/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.7853 - accuracy: 0.70\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.7853 - accuracy: 0.7039 - val_loss: 0.7313 - val_accuracy: 0.7475\n",
      "Epoch 240/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.6344 - accuracy: 0.77\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.6312 - accuracy: 0.7771 - val_loss: 0.5986 - val_accuracy: 0.7702\n",
      "Epoch 241/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.6859 - accuracy: 0.74\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.6859 - accuracy: 0.7494 - val_loss: 0.6739 - val_accuracy: 0.7323\n",
      "Epoch 242/4000\n",
      "3/3 [==============================] - 0s 28ms/steploss: 0.6366 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.6336 - accuracy: 0.7607 - val_loss: 0.6156 - val_accuracy: 0.7386\n",
      "Epoch 243/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.6021 - accuracy: 0.76\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.6021 - accuracy: 0.7652 - val_loss: 0.5898 - val_accuracy: 0.7525\n",
      "Epoch 244/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.5730 - accuracy: 0.77\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.5724 - accuracy: 0.7737 - val_loss: 0.5774 - val_accuracy: 0.7677\n",
      "Epoch 245/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.5929 - accuracy: 0.75\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.5929 - accuracy: 0.7569 - val_loss: 0.5705 - val_accuracy: 0.7652\n",
      "Epoch 246/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.5878 - accuracy: 0.76\n",
      "32/32 [==============================] - 3s 84ms/step - loss: 0.5878 - accuracy: 0.7648 - val_loss: 0.7916 - val_accuracy: 0.7210\n",
      "Epoch 247/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.6403 - accuracy: 0.73\n",
      "32/32 [==============================] - 2s 73ms/step - loss: 0.6403 - accuracy: 0.7345 - val_loss: 0.6114 - val_accuracy: 0.7285\n",
      "Epoch 248/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.5683 - accuracy: 0.74\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.5723 - accuracy: 0.7443 - val_loss: 0.4926 - val_accuracy: 0.7778\n",
      "Epoch 249/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.4757 - accuracy: 0.79\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.4766 - accuracy: 0.7923 - val_loss: 0.4574 - val_accuracy: 0.7967\n",
      "Epoch 250/4000\n",
      "3/3 [==============================] - 0s 19ms/steploss: 0.4960 - accuracy: 0.78\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.4960 - accuracy: 0.7860 - val_loss: 0.4847 - val_accuracy: 0.8220\n",
      "Epoch 251/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.5177 - accuracy: 0.77\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.5138 - accuracy: 0.7787 - val_loss: 0.4698 - val_accuracy: 0.7929\n",
      "Epoch 252/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.4657 - accuracy: 0.79\n",
      "32/32 [==============================] - 2s 79ms/step - loss: 0.4657 - accuracy: 0.7986 - val_loss: 0.4177 - val_accuracy: 0.8308\n",
      "Epoch 253/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.4295 - accuracy: 0.81\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.4295 - accuracy: 0.8147 - val_loss: 0.4083 - val_accuracy: 0.8409\n",
      "Epoch 254/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.4863 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.4863 - accuracy: 0.7910 - val_loss: 0.5023 - val_accuracy: 0.7437\n",
      "Epoch 255/4000\n",
      "3/3 [==============================] - 0s 28ms/steploss: 0.4738 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.4736 - accuracy: 0.7882 - val_loss: 0.4544 - val_accuracy: 0.7828\n",
      "Epoch 256/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.4388 - accuracy: 0.80\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.4388 - accuracy: 0.8052 - val_loss: 0.6460 - val_accuracy: 0.7020\n",
      "Epoch 257/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.5864 - accuracy: 0.74\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.5864 - accuracy: 0.7408 - val_loss: 0.5696 - val_accuracy: 0.7689\n",
      "Epoch 258/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.5129 - accuracy: 0.77\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.5124 - accuracy: 0.7721 - val_loss: 0.4900 - val_accuracy: 0.7816\n",
      "Epoch 259/4000\n",
      "3/3 [==============================] - 0s 19ms/steploss: 0.4685 - accuracy: 0.79\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.4675 - accuracy: 0.7948 - val_loss: 0.4355 - val_accuracy: 0.7816\n",
      "Epoch 260/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.4409 - accuracy: 0.79\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.4409 - accuracy: 0.7961 - val_loss: 0.4057 - val_accuracy: 0.8081\n",
      "Epoch 261/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.4292 - accuracy: 0.81\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.4292 - accuracy: 0.8100 - val_loss: 0.3712 - val_accuracy: 0.8245\n",
      "Epoch 262/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.3856 - accuracy: 0.83\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3856 - accuracy: 0.8343 - val_loss: 0.3749 - val_accuracy: 0.8270\n",
      "Epoch 263/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.3669 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3669 - accuracy: 0.8415 - val_loss: 0.3455 - val_accuracy: 0.8359\n",
      "Epoch 264/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3444 - accuracy: 0.84\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3444 - accuracy: 0.8475 - val_loss: 0.3472 - val_accuracy: 0.8573\n",
      "Epoch 265/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.3401 - accuracy: 0.84\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.3401 - accuracy: 0.8444 - val_loss: 0.3211 - val_accuracy: 0.8321\n",
      "Epoch 266/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.3428 - accuracy: 0.83\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.3428 - accuracy: 0.8396 - val_loss: 0.3920 - val_accuracy: 0.8295\n",
      "Epoch 267/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.3748 - accuracy: 0.84\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3723 - accuracy: 0.8441 - val_loss: 0.3422 - val_accuracy: 0.8384\n",
      "Epoch 268/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.3202 - accuracy: 0.85\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.3202 - accuracy: 0.8554 - val_loss: 0.2874 - val_accuracy: 0.8813\n",
      "Epoch 269/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.2976 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.2960 - accuracy: 0.8630 - val_loss: 0.5295 - val_accuracy: 0.7449\n",
      "Epoch 270/4000\n",
      "3/3 [==============================] - 0s 29ms/steploss: 0.4153 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.4153 - accuracy: 0.8138 - val_loss: 0.3759 - val_accuracy: 0.8359\n",
      "Epoch 271/4000\n",
      "3/3 [==============================] - 0s 29ms/steploss: 0.4849 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 84ms/step - loss: 0.4849 - accuracy: 0.8109 - val_loss: 0.3830 - val_accuracy: 0.8371\n",
      "Epoch 272/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.3785 - accuracy: 0.83\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.3785 - accuracy: 0.8324 - val_loss: 0.3097 - val_accuracy: 0.8699\n",
      "Epoch 273/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3076 - accuracy: 0.86\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3076 - accuracy: 0.8617 - val_loss: 0.2755 - val_accuracy: 0.8876\n",
      "Epoch 274/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2839 - accuracy: 0.86\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.2839 - accuracy: 0.8690 - val_loss: 0.2887 - val_accuracy: 0.8788\n",
      "Epoch 275/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.2653 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2635 - accuracy: 0.8920 - val_loss: 0.2639 - val_accuracy: 0.8838\n",
      "Epoch 276/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2791 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2830 - accuracy: 0.8769 - val_loss: 0.3357 - val_accuracy: 0.8649\n",
      "Epoch 277/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.4151 - accuracy: 0.81\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.4151 - accuracy: 0.8176 - val_loss: 0.3155 - val_accuracy: 0.8422\n",
      "Epoch 278/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2825 - accuracy: 0.87\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.2825 - accuracy: 0.8753 - val_loss: 0.2771 - val_accuracy: 0.8561\n",
      "Epoch 279/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2412 - accuracy: 0.89\n",
      "32/32 [==============================] - 3s 83ms/step - loss: 0.2412 - accuracy: 0.8971 - val_loss: 0.2482 - val_accuracy: 0.8851\n",
      "Epoch 280/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.2380 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2380 - accuracy: 0.8984 - val_loss: 0.2097 - val_accuracy: 0.9205\n",
      "Epoch 281/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2198 - accuracy: 0.90\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.2193 - accuracy: 0.9018 - val_loss: 0.2375 - val_accuracy: 0.8876\n",
      "Epoch 282/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.2201 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2201 - accuracy: 0.9069 - val_loss: 0.2289 - val_accuracy: 0.9015\n",
      "Epoch 283/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2230 - accuracy: 0.90\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2240 - accuracy: 0.9062 - val_loss: 0.2953 - val_accuracy: 0.8510\n",
      "Epoch 284/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.4493 - accuracy: 0.82\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.4493 - accuracy: 0.8273 - val_loss: 0.4083 - val_accuracy: 0.8131\n",
      "Epoch 285/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.5763 - accuracy: 0.78\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.5763 - accuracy: 0.7831 - val_loss: 0.7234 - val_accuracy: 0.7083\n",
      "Epoch 286/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.9238 - accuracy: 0.68\n",
      "32/32 [==============================] - 2s 73ms/step - loss: 0.9238 - accuracy: 0.6824 - val_loss: 0.8042 - val_accuracy: 0.6629\n",
      "Epoch 287/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.7411 - accuracy: 0.70\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.7411 - accuracy: 0.7052 - val_loss: 0.6453 - val_accuracy: 0.7159\n",
      "Epoch 288/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.5664 - accuracy: 0.75\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.5645 - accuracy: 0.7509 - val_loss: 0.4707 - val_accuracy: 0.7816\n",
      "Epoch 289/4000\n",
      "3/3 [==============================] - 0s 28ms/steploss: 0.4330 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.4330 - accuracy: 0.8040 - val_loss: 0.3442 - val_accuracy: 0.8548\n",
      "Epoch 290/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.3461 - accuracy: 0.85\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.3438 - accuracy: 0.8545 - val_loss: 0.3441 - val_accuracy: 0.8649\n",
      "Epoch 291/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3241 - accuracy: 0.86\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3241 - accuracy: 0.8681 - val_loss: 0.3163 - val_accuracy: 0.8876\n",
      "Epoch 292/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.3578 - accuracy: 0.84\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3559 - accuracy: 0.8450 - val_loss: 0.2942 - val_accuracy: 0.8889\n",
      "Epoch 293/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2948 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2926 - accuracy: 0.8734 - val_loss: 0.2591 - val_accuracy: 0.8965\n",
      "Epoch 294/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2639 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2639 - accuracy: 0.8911 - val_loss: 0.3642 - val_accuracy: 0.8409\n",
      "Epoch 295/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.3079 - accuracy: 0.86\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.3104 - accuracy: 0.8649 - val_loss: 0.4948 - val_accuracy: 0.7677\n",
      "Epoch 296/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.3547 - accuracy: 0.84\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3547 - accuracy: 0.8447 - val_loss: 0.3624 - val_accuracy: 0.8396\n",
      "Epoch 297/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2829 - accuracy: 0.88\n",
      "32/32 [==============================] - 3s 93ms/step - loss: 0.2829 - accuracy: 0.8854 - val_loss: 0.2523 - val_accuracy: 0.8838\n",
      "Epoch 298/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2548 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2612 - accuracy: 0.8905 - val_loss: 0.4868 - val_accuracy: 0.8472\n",
      "Epoch 299/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.8562 - accuracy: 0.69\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.8562 - accuracy: 0.6973 - val_loss: 0.6657 - val_accuracy: 0.7626\n",
      "Epoch 300/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.4389 - accuracy: 0.81\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.4389 - accuracy: 0.8179 - val_loss: 0.2859 - val_accuracy: 0.8939\n",
      "Epoch 301/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2950 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.2950 - accuracy: 0.8851 - val_loss: 0.2999 - val_accuracy: 0.8813\n",
      "Epoch 302/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2457 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2457 - accuracy: 0.8955 - val_loss: 0.2778 - val_accuracy: 0.9066\n",
      "Epoch 303/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2325 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2325 - accuracy: 0.9110 - val_loss: 0.2183 - val_accuracy: 0.9091\n",
      "Epoch 304/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.1917 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1917 - accuracy: 0.9233 - val_loss: 0.1747 - val_accuracy: 0.9343\n",
      "Epoch 305/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2120 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2120 - accuracy: 0.9151 - val_loss: 0.2157 - val_accuracy: 0.9205\n",
      "Epoch 306/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2141 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2141 - accuracy: 0.9201 - val_loss: 0.2240 - val_accuracy: 0.9028\n",
      "Epoch 307/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2802 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2802 - accuracy: 0.8813 - val_loss: 0.5565 - val_accuracy: 0.8043\n",
      "Epoch 308/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.3522 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3513 - accuracy: 0.8507 - val_loss: 0.2520 - val_accuracy: 0.8902\n",
      "Epoch 309/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.2621 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.2621 - accuracy: 0.8911 - val_loss: 0.1951 - val_accuracy: 0.9141\n",
      "Epoch 310/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.1889 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.1889 - accuracy: 0.9230 - val_loss: 0.1706 - val_accuracy: 0.9369\n",
      "Epoch 311/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.1706 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1706 - accuracy: 0.9217 - val_loss: 0.1743 - val_accuracy: 0.9078\n",
      "Epoch 312/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.1609 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1609 - accuracy: 0.9283 - val_loss: 0.1588 - val_accuracy: 0.9242\n",
      "Epoch 313/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.3288 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.3305 - accuracy: 0.8829 - val_loss: 0.3271 - val_accuracy: 0.8523\n",
      "Epoch 314/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.3689 - accuracy: 0.85\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.3689 - accuracy: 0.8523 - val_loss: 0.3420 - val_accuracy: 0.8510\n",
      "Epoch 315/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2855 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2855 - accuracy: 0.8772 - val_loss: 0.1996 - val_accuracy: 0.9167\n",
      "Epoch 316/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2994 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3140 - accuracy: 0.8819 - val_loss: 0.6906 - val_accuracy: 0.7652\n",
      "Epoch 317/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 1.5410 - accuracy: 0.56\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 1.5410 - accuracy: 0.5679 - val_loss: 0.9815 - val_accuracy: 0.6351\n",
      "Epoch 318/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.8901 - accuracy: 0.65\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.8835 - accuracy: 0.6613 - val_loss: 0.7551 - val_accuracy: 0.7121\n",
      "Epoch 319/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.6456 - accuracy: 0.72\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.6443 - accuracy: 0.7232 - val_loss: 0.5285 - val_accuracy: 0.7639\n",
      "Epoch 320/4000\n",
      "3/3 [==============================] - 0s 29ms/steploss: 0.5362 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.5362 - accuracy: 0.7702 - val_loss: 0.5291 - val_accuracy: 0.7677\n",
      "Epoch 321/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.4912 - accuracy: 0.78\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.4895 - accuracy: 0.7857 - val_loss: 0.4608 - val_accuracy: 0.7917\n",
      "Epoch 322/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.4679 - accuracy: 0.80\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.4679 - accuracy: 0.8033 - val_loss: 0.5668 - val_accuracy: 0.7551\n",
      "Epoch 323/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.4917 - accuracy: 0.78\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.4942 - accuracy: 0.7876 - val_loss: 0.5812 - val_accuracy: 0.7311\n",
      "Epoch 324/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.4841 - accuracy: 0.79\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.4841 - accuracy: 0.7961 - val_loss: 0.4510 - val_accuracy: 0.8093\n",
      "Epoch 325/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.4154 - accuracy: 0.82\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.4154 - accuracy: 0.8254 - val_loss: 0.3744 - val_accuracy: 0.8308\n",
      "Epoch 326/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3502 - accuracy: 0.86\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.3502 - accuracy: 0.8602 - val_loss: 0.3093 - val_accuracy: 0.8699\n",
      "Epoch 327/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.3153 - accuracy: 0.86\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.3153 - accuracy: 0.8677 - val_loss: 0.2922 - val_accuracy: 0.8561\n",
      "Epoch 328/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.3254 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.3242 - accuracy: 0.8598 - val_loss: 0.3471 - val_accuracy: 0.8422\n",
      "Epoch 329/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.3087 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.3087 - accuracy: 0.8709 - val_loss: 0.2819 - val_accuracy: 0.8914\n",
      "Epoch 330/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2729 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2729 - accuracy: 0.8832 - val_loss: 0.2523 - val_accuracy: 0.8801\n",
      "Epoch 331/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2514 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2517 - accuracy: 0.8851 - val_loss: 0.2538 - val_accuracy: 0.8801\n",
      "Epoch 332/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2597 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2613 - accuracy: 0.8823 - val_loss: 0.2228 - val_accuracy: 0.9003\n",
      "Epoch 333/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2558 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2567 - accuracy: 0.8883 - val_loss: 0.2998 - val_accuracy: 0.8586\n",
      "Epoch 334/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.3088 - accuracy: 0.85\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3088 - accuracy: 0.8523 - val_loss: 0.3644 - val_accuracy: 0.8005\n",
      "Epoch 335/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.5043 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 73ms/step - loss: 0.5043 - accuracy: 0.7771 - val_loss: 0.5806 - val_accuracy: 0.7727\n",
      "Epoch 336/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.4277 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.4277 - accuracy: 0.8150 - val_loss: 0.3940 - val_accuracy: 0.8106\n",
      "Epoch 337/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.3378 - accuracy: 0.84\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.3378 - accuracy: 0.8425 - val_loss: 0.4595 - val_accuracy: 0.8131\n",
      "Epoch 338/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.3114 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3086 - accuracy: 0.8744 - val_loss: 0.2637 - val_accuracy: 0.8699\n",
      "Epoch 339/4000\n",
      "3/3 [==============================] - 0s 29ms/steploss: 0.6078 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.6078 - accuracy: 0.7910 - val_loss: 0.6390 - val_accuracy: 0.7399\n",
      "Epoch 340/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.4846 - accuracy: 0.79\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.4846 - accuracy: 0.7973 - val_loss: 0.3852 - val_accuracy: 0.8157\n",
      "Epoch 341/4000\n",
      "3/3 [==============================] - 0s 28ms/steploss: 0.4334 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.4307 - accuracy: 0.8365 - val_loss: 0.4186 - val_accuracy: 0.8333\n",
      "Epoch 342/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.3655 - accuracy: 0.86\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3655 - accuracy: 0.8665 - val_loss: 0.3199 - val_accuracy: 0.8939\n",
      "Epoch 343/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.3185 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.3152 - accuracy: 0.8782 - val_loss: 0.2559 - val_accuracy: 0.8889\n",
      "Epoch 344/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.3104 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3104 - accuracy: 0.8753 - val_loss: 0.3849 - val_accuracy: 0.8624\n",
      "Epoch 345/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.3881 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3881 - accuracy: 0.8343 - val_loss: 0.3222 - val_accuracy: 0.8573\n",
      "Epoch 346/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2388 - accuracy: 0.90\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.2388 - accuracy: 0.9047 - val_loss: 0.1945 - val_accuracy: 0.9192\n",
      "Epoch 347/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.1838 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1838 - accuracy: 0.9302 - val_loss: 0.1752 - val_accuracy: 0.9508\n",
      "Epoch 348/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.1880 - accuracy: 0.93\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.1880 - accuracy: 0.9321 - val_loss: 0.1938 - val_accuracy: 0.9116\n",
      "Epoch 349/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.1605 - accuracy: 0.94\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1610 - accuracy: 0.9416 - val_loss: 0.2093 - val_accuracy: 0.9028\n",
      "Epoch 350/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.3891 - accuracy: 0.84\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.3891 - accuracy: 0.8406 - val_loss: 0.4832 - val_accuracy: 0.7929\n",
      "Epoch 351/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.3869 - accuracy: 0.84\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.3855 - accuracy: 0.8482 - val_loss: 0.2325 - val_accuracy: 0.9116\n",
      "Epoch 352/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2462 - accuracy: 0.90\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2462 - accuracy: 0.9037 - val_loss: 0.1796 - val_accuracy: 0.9230\n",
      "Epoch 353/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.1814 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1814 - accuracy: 0.9246 - val_loss: 0.1811 - val_accuracy: 0.9230\n",
      "Epoch 354/4000\n",
      "3/3 [==============================] - 0s 29ms/steploss: 0.1854 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.1854 - accuracy: 0.9268 - val_loss: 0.3122 - val_accuracy: 0.9104\n",
      "Epoch 355/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2823 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.2823 - accuracy: 0.9104 - val_loss: 0.3401 - val_accuracy: 0.8624\n",
      "Epoch 356/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2592 - accuracy: 0.90\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2592 - accuracy: 0.9009 - val_loss: 0.2099 - val_accuracy: 0.9217\n",
      "Epoch 357/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.1965 - accuracy: 0.93\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1965 - accuracy: 0.9309 - val_loss: 0.2084 - val_accuracy: 0.9028\n",
      "Epoch 358/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2155 - accuracy: 0.90\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.2144 - accuracy: 0.9104 - val_loss: 0.1768 - val_accuracy: 0.9306\n",
      "Epoch 359/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.1934 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.1934 - accuracy: 0.9186 - val_loss: 0.1410 - val_accuracy: 0.9407\n",
      "Epoch 360/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.1257 - accuracy: 0.95\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1253 - accuracy: 0.9549 - val_loss: 0.1383 - val_accuracy: 0.9394\n",
      "Epoch 361/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2069 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2069 - accuracy: 0.9227 - val_loss: 0.1140 - val_accuracy: 0.9558\n",
      "Epoch 362/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2150 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.2128 - accuracy: 0.9148 - val_loss: 0.2417 - val_accuracy: 0.9154\n",
      "Epoch 363/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.1608 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1608 - accuracy: 0.9337 - val_loss: 0.1907 - val_accuracy: 0.9242\n",
      "Epoch 364/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.3337 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3385 - accuracy: 0.8845 - val_loss: 0.5565 - val_accuracy: 0.7980\n",
      "Epoch 365/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.3256 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3216 - accuracy: 0.8753 - val_loss: 0.1788 - val_accuracy: 0.9293\n",
      "Epoch 366/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2140 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2140 - accuracy: 0.9129 - val_loss: 0.3707 - val_accuracy: 0.8131\n",
      "Epoch 367/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2660 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2660 - accuracy: 0.8816 - val_loss: 0.1842 - val_accuracy: 0.9154\n",
      "Epoch 368/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.3133 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.3133 - accuracy: 0.8725 - val_loss: 0.3403 - val_accuracy: 0.8485\n",
      "Epoch 369/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.4839 - accuracy: 0.83\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.4839 - accuracy: 0.8374 - val_loss: 0.6732 - val_accuracy: 0.7992\n",
      "Epoch 370/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.3891 - accuracy: 0.85\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3891 - accuracy: 0.8554 - val_loss: 0.2639 - val_accuracy: 0.9129\n",
      "Epoch 371/4000\n",
      "3/3 [==============================] - 0s 28ms/steploss: 0.2985 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2985 - accuracy: 0.8987 - val_loss: 0.3821 - val_accuracy: 0.8775\n",
      "Epoch 372/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2620 - accuracy: 0.90\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2620 - accuracy: 0.9028 - val_loss: 0.2918 - val_accuracy: 0.8838\n",
      "Epoch 373/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 1.1764 - accuracy: 0.65\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 1.1832 - accuracy: 0.6559 - val_loss: 1.2467 - val_accuracy: 0.5379\n",
      "Epoch 374/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.7796 - accuracy: 0.69\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.7796 - accuracy: 0.6944 - val_loss: 0.8347 - val_accuracy: 0.7210\n",
      "Epoch 375/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 1.0964 - accuracy: 0.60\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 1.0877 - accuracy: 0.6108 - val_loss: 0.9097 - val_accuracy: 0.6162\n",
      "Epoch 376/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.7873 - accuracy: 0.69\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.7868 - accuracy: 0.6888 - val_loss: 0.7245 - val_accuracy: 0.7475\n",
      "Epoch 377/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.6437 - accuracy: 0.73\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.6437 - accuracy: 0.7333 - val_loss: 0.6615 - val_accuracy: 0.7437\n",
      "Epoch 378/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.4323 - accuracy: 0.83\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.4323 - accuracy: 0.8324 - val_loss: 0.2875 - val_accuracy: 0.9116\n",
      "Epoch 379/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2532 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2532 - accuracy: 0.9132 - val_loss: 0.2374 - val_accuracy: 0.9205\n",
      "Epoch 380/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.1986 - accuracy: 0.93\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.1981 - accuracy: 0.9309 - val_loss: 0.2194 - val_accuracy: 0.9217\n",
      "Epoch 381/4000\n",
      "3/3 [==============================] - 0s 34ms/steploss: 0.1995 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 0.1995 - accuracy: 0.9306 - val_loss: 0.2154 - val_accuracy: 0.9268\n",
      "Epoch 382/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.1835 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 82ms/step - loss: 0.1835 - accuracy: 0.9318 - val_loss: 0.2203 - val_accuracy: 0.9040\n",
      "Epoch 383/4000\n",
      "3/3 [==============================] - 0s 28ms/steploss: 0.1889 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1889 - accuracy: 0.9274 - val_loss: 0.1984 - val_accuracy: 0.9192\n",
      "Epoch 384/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.1870 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1870 - accuracy: 0.9236 - val_loss: 0.1669 - val_accuracy: 0.9407\n",
      "Epoch 385/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2425 - accuracy: 0.90\n",
      "32/32 [==============================] - 3s 98ms/step - loss: 0.2425 - accuracy: 0.9059 - val_loss: 0.2672 - val_accuracy: 0.8801\n",
      "Epoch 386/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2166 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2166 - accuracy: 0.9167 - val_loss: 0.1993 - val_accuracy: 0.9091\n",
      "Epoch 387/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2071 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2071 - accuracy: 0.9242 - val_loss: 0.2757 - val_accuracy: 0.9104\n",
      "Epoch 388/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2154 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2154 - accuracy: 0.9192 - val_loss: 0.2004 - val_accuracy: 0.9116\n",
      "Epoch 389/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.1565 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.1565 - accuracy: 0.9419 - val_loss: 0.2023 - val_accuracy: 0.9116\n",
      "Epoch 390/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2944 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2956 - accuracy: 0.8902 - val_loss: 0.3142 - val_accuracy: 0.8636\n",
      "Epoch 391/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2047 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2047 - accuracy: 0.9154 - val_loss: 0.1859 - val_accuracy: 0.9217\n",
      "Epoch 392/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3574 - accuracy: 0.86\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3574 - accuracy: 0.8681 - val_loss: 0.2741 - val_accuracy: 0.8737\n",
      "Epoch 393/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.2696 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2685 - accuracy: 0.8924 - val_loss: 0.2114 - val_accuracy: 0.9104\n",
      "Epoch 394/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.1956 - accuracy: 0.92\n",
      "32/32 [==============================] - 3s 82ms/step - loss: 0.1956 - accuracy: 0.9223 - val_loss: 0.1371 - val_accuracy: 0.9545\n",
      "Epoch 395/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.1442 - accuracy: 0.95\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1442 - accuracy: 0.9501 - val_loss: 0.1634 - val_accuracy: 0.9394\n",
      "Epoch 396/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2721 - accuracy: 0.89\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.2721 - accuracy: 0.8946 - val_loss: 0.2634 - val_accuracy: 0.9091\n",
      "Epoch 397/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.2668 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2668 - accuracy: 0.9047 - val_loss: 0.3890 - val_accuracy: 0.8586\n",
      "Epoch 398/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2553 - accuracy: 0.90\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2556 - accuracy: 0.9078 - val_loss: 0.1856 - val_accuracy: 0.9419\n",
      "Epoch 399/4000\n",
      "3/3 [==============================] - 0s 28ms/steploss: 0.1847 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 79ms/step - loss: 0.1847 - accuracy: 0.9299 - val_loss: 0.1899 - val_accuracy: 0.9306\n",
      "Epoch 400/4000\n",
      "3/3 [==============================] - 0s 28ms/steploss: 0.5301 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.5254 - accuracy: 0.8169 - val_loss: 0.2558 - val_accuracy: 0.8927\n",
      "Epoch 401/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2458 - accuracy: 0.90\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2493 - accuracy: 0.9018 - val_loss: 0.2116 - val_accuracy: 0.9356\n",
      "Epoch 402/4000\n",
      "3/3 [==============================] - 0s 29ms/steploss: 0.2500 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.2500 - accuracy: 0.9085 - val_loss: 0.2108 - val_accuracy: 0.9318\n",
      "Epoch 403/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.1815 - accuracy: 0.93\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.1815 - accuracy: 0.9315 - val_loss: 0.1633 - val_accuracy: 0.9343\n",
      "Epoch 404/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.1443 - accuracy: 0.94\n",
      "32/32 [==============================] - 3s 78ms/step - loss: 0.1443 - accuracy: 0.9416 - val_loss: 0.1408 - val_accuracy: 0.9520\n",
      "Epoch 405/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.2612 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2612 - accuracy: 0.9050 - val_loss: 0.2217 - val_accuracy: 0.9053\n",
      "Epoch 406/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2034 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2034 - accuracy: 0.9252 - val_loss: 0.1506 - val_accuracy: 0.9381\n",
      "Epoch 407/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.1546 - accuracy: 0.93\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1546 - accuracy: 0.9347 - val_loss: 0.2289 - val_accuracy: 0.9306\n",
      "Epoch 408/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.1602 - accuracy: 0.93\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1602 - accuracy: 0.9353 - val_loss: 0.1371 - val_accuracy: 0.9280\n",
      "Epoch 409/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.1638 - accuracy: 0.93\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1638 - accuracy: 0.9343 - val_loss: 0.1608 - val_accuracy: 0.9318\n",
      "Epoch 410/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.1449 - accuracy: 0.93\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1439 - accuracy: 0.9397 - val_loss: 0.1377 - val_accuracy: 0.9381\n",
      "Epoch 411/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.1304 - accuracy: 0.94\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.1304 - accuracy: 0.9416 - val_loss: 0.1285 - val_accuracy: 0.9356\n",
      "Epoch 412/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.1832 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1832 - accuracy: 0.9198 - val_loss: 0.2630 - val_accuracy: 0.8876\n",
      "Epoch 413/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.3903 - accuracy: 0.85\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3903 - accuracy: 0.8510 - val_loss: 0.2191 - val_accuracy: 0.9242\n",
      "Epoch 414/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2420 - accuracy: 0.90\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2409 - accuracy: 0.9056 - val_loss: 0.1958 - val_accuracy: 0.9179\n",
      "Epoch 415/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.1421 - accuracy: 0.93\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.1423 - accuracy: 0.9384 - val_loss: 0.1329 - val_accuracy: 0.9280\n",
      "Epoch 416/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.1860 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1860 - accuracy: 0.9280 - val_loss: 0.1490 - val_accuracy: 0.9356\n",
      "Epoch 417/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.1832 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1832 - accuracy: 0.9223 - val_loss: 0.3754 - val_accuracy: 0.8851\n",
      "Epoch 418/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.5607 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 79ms/step - loss: 0.5607 - accuracy: 0.8150 - val_loss: 0.4938 - val_accuracy: 0.7955\n",
      "Epoch 419/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.5202 - accuracy: 0.80\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.5202 - accuracy: 0.8002 - val_loss: 1.4961 - val_accuracy: 0.6086\n",
      "Epoch 420/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.9938 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.9938 - accuracy: 0.6783 - val_loss: 0.6932 - val_accuracy: 0.7487\n",
      "Epoch 421/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.4418 - accuracy: 0.81\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.4371 - accuracy: 0.8166 - val_loss: 0.3180 - val_accuracy: 0.8422\n",
      "Epoch 422/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2678 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2687 - accuracy: 0.8797 - val_loss: 0.2334 - val_accuracy: 0.9078\n",
      "Epoch 423/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2138 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2151 - accuracy: 0.9148 - val_loss: 0.2046 - val_accuracy: 0.9230\n",
      "Epoch 424/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.2254 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2254 - accuracy: 0.9126 - val_loss: 0.2577 - val_accuracy: 0.9268\n",
      "Epoch 425/4000\n",
      "3/3 [==============================] - 0s 31ms/steploss: 0.1621 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1621 - accuracy: 0.9473 - val_loss: 0.1810 - val_accuracy: 0.9255\n",
      "Epoch 426/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.1445 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.1445 - accuracy: 0.9463 - val_loss: 0.1542 - val_accuracy: 0.9508\n",
      "Epoch 427/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.1492 - accuracy: 0.94\n",
      "32/32 [==============================] - 3s 107ms/step - loss: 0.1492 - accuracy: 0.9441 - val_loss: 0.1251 - val_accuracy: 0.9444\n",
      "Epoch 428/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.1437 - accuracy: 0.94\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.1437 - accuracy: 0.9473 - val_loss: 0.1898 - val_accuracy: 0.9280\n",
      "Epoch 429/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2418 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2418 - accuracy: 0.8987 - val_loss: 0.2724 - val_accuracy: 0.9003\n",
      "Epoch 430/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2005 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2005 - accuracy: 0.9164 - val_loss: 0.1595 - val_accuracy: 0.9331\n",
      "Epoch 431/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.1391 - accuracy: 0.93\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.1391 - accuracy: 0.9378 - val_loss: 0.1368 - val_accuracy: 0.9672\n",
      "Epoch 432/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.1443 - accuracy: 0.94\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1458 - accuracy: 0.9403 - val_loss: 0.1435 - val_accuracy: 0.9444\n",
      "Epoch 433/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2576 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2586 - accuracy: 0.9113 - val_loss: 0.7261 - val_accuracy: 0.8043\n",
      "Epoch 434/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3638 - accuracy: 0.86\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.3604 - accuracy: 0.8693 - val_loss: 0.2067 - val_accuracy: 0.9205\n",
      "Epoch 435/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.1634 - accuracy: 0.93\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.1631 - accuracy: 0.9356 - val_loss: 0.2204 - val_accuracy: 0.9078\n",
      "Epoch 436/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.1568 - accuracy: 0.94\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1568 - accuracy: 0.9435 - val_loss: 0.1119 - val_accuracy: 0.9583\n",
      "Epoch 437/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.1124 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1124 - accuracy: 0.9612 - val_loss: 0.1112 - val_accuracy: 0.9545\n",
      "Epoch 438/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.1085 - accuracy: 0.95\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.1076 - accuracy: 0.9558 - val_loss: 0.1339 - val_accuracy: 0.9457\n",
      "Epoch 439/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.0979 - accuracy: 0.96\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.0979 - accuracy: 0.9631 - val_loss: 0.1481 - val_accuracy: 0.9583\n",
      "Epoch 440/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.7381 - accuracy: 0.78\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.7381 - accuracy: 0.7828 - val_loss: 1.0842 - val_accuracy: 0.6250\n",
      "Epoch 441/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.8100 - accuracy: 0.66\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.8100 - accuracy: 0.6689 - val_loss: 0.6271 - val_accuracy: 0.7020\n",
      "Epoch 442/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.5585 - accuracy: 0.74\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.5585 - accuracy: 0.7449 - val_loss: 0.4636 - val_accuracy: 0.7576\n",
      "Epoch 443/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.4829 - accuracy: 0.78\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.4829 - accuracy: 0.7876 - val_loss: 0.3597 - val_accuracy: 0.8662\n",
      "Epoch 444/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.3400 - accuracy: 0.86\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.3400 - accuracy: 0.8627 - val_loss: 0.3346 - val_accuracy: 0.8561\n",
      "Epoch 445/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3667 - accuracy: 0.83\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3664 - accuracy: 0.8371 - val_loss: 0.3606 - val_accuracy: 0.8283\n",
      "Epoch 446/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3859 - accuracy: 0.84\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3859 - accuracy: 0.8456 - val_loss: 0.5339 - val_accuracy: 0.7917\n",
      "Epoch 447/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.4113 - accuracy: 0.82\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.4113 - accuracy: 0.8280 - val_loss: 0.3396 - val_accuracy: 0.8485\n",
      "Epoch 448/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2744 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2744 - accuracy: 0.8845 - val_loss: 0.2472 - val_accuracy: 0.8826\n",
      "Epoch 449/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2585 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2585 - accuracy: 0.8895 - val_loss: 0.2303 - val_accuracy: 0.9003\n",
      "Epoch 450/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2318 - accuracy: 0.90\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2318 - accuracy: 0.9034 - val_loss: 0.2624 - val_accuracy: 0.8864\n",
      "Epoch 451/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.2361 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.2352 - accuracy: 0.8898 - val_loss: 0.2275 - val_accuracy: 0.8939\n",
      "Epoch 452/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2480 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2480 - accuracy: 0.8911 - val_loss: 0.3097 - val_accuracy: 0.8535\n",
      "Epoch 453/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2299 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2284 - accuracy: 0.8933 - val_loss: 0.2266 - val_accuracy: 0.8889\n",
      "Epoch 454/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2102 - accuracy: 0.90\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2100 - accuracy: 0.9031 - val_loss: 0.2701 - val_accuracy: 0.8636\n",
      "Epoch 455/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2293 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2293 - accuracy: 0.8924 - val_loss: 0.2227 - val_accuracy: 0.8902\n",
      "Epoch 456/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.1952 - accuracy: 0.90\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1952 - accuracy: 0.9091 - val_loss: 0.2282 - val_accuracy: 0.8838\n",
      "Epoch 457/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.2196 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2196 - accuracy: 0.8993 - val_loss: 0.3042 - val_accuracy: 0.8561\n",
      "Epoch 458/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.3031 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.3031 - accuracy: 0.8731 - val_loss: 0.4259 - val_accuracy: 0.7980\n",
      "Epoch 459/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.4208 - accuracy: 0.82\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.4175 - accuracy: 0.8213 - val_loss: 0.3435 - val_accuracy: 0.8207\n",
      "Epoch 460/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.2655 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2655 - accuracy: 0.8763 - val_loss: 0.2277 - val_accuracy: 0.9116\n",
      "Epoch 461/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.2257 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2257 - accuracy: 0.9015 - val_loss: 0.2268 - val_accuracy: 0.8914\n",
      "Epoch 462/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2138 - accuracy: 0.90\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2138 - accuracy: 0.9081 - val_loss: 0.2362 - val_accuracy: 0.8889\n",
      "Epoch 463/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.4025 - accuracy: 0.84\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.4025 - accuracy: 0.8431 - val_loss: 0.3105 - val_accuracy: 0.8396\n",
      "Epoch 464/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2835 - accuracy: 0.85\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2835 - accuracy: 0.8589 - val_loss: 0.3096 - val_accuracy: 0.8207\n",
      "Epoch 465/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2817 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2817 - accuracy: 0.8838 - val_loss: 0.3354 - val_accuracy: 0.8485\n",
      "Epoch 466/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2364 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2364 - accuracy: 0.8943 - val_loss: 0.2233 - val_accuracy: 0.9015\n",
      "Epoch 467/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.1822 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1824 - accuracy: 0.9157 - val_loss: 0.2128 - val_accuracy: 0.8889\n",
      "Epoch 468/4000\n",
      "3/3 [==============================] - 0s 32ms/steploss: 0.1789 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 82ms/step - loss: 0.1789 - accuracy: 0.9201 - val_loss: 0.2080 - val_accuracy: 0.8813\n",
      "Epoch 469/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.1821 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.1837 - accuracy: 0.9072 - val_loss: 0.2164 - val_accuracy: 0.8914\n",
      "Epoch 470/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.1917 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1915 - accuracy: 0.9100 - val_loss: 0.2106 - val_accuracy: 0.8914\n",
      "Epoch 471/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.1689 - accuracy: 0.92\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.1689 - accuracy: 0.9227 - val_loss: 0.1927 - val_accuracy: 0.8927\n",
      "Epoch 472/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.1812 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1812 - accuracy: 0.9173 - val_loss: 0.2050 - val_accuracy: 0.8826\n",
      "Epoch 473/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2236 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2236 - accuracy: 0.8974 - val_loss: 0.2967 - val_accuracy: 0.8561\n",
      "Epoch 474/4000\n",
      "3/3 [==============================] - 0s 28ms/steploss: 0.3094 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.3094 - accuracy: 0.8611 - val_loss: 0.2530 - val_accuracy: 0.8851\n",
      "Epoch 475/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.2681 - accuracy: 0.86\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2681 - accuracy: 0.8687 - val_loss: 0.2989 - val_accuracy: 0.8359\n",
      "Epoch 476/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3694 - accuracy: 0.84\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3694 - accuracy: 0.8409 - val_loss: 0.4183 - val_accuracy: 0.8207\n",
      "Epoch 477/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2554 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2554 - accuracy: 0.8816 - val_loss: 0.2697 - val_accuracy: 0.8763\n",
      "Epoch 478/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2076 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 79ms/step - loss: 0.2076 - accuracy: 0.8993 - val_loss: 0.2079 - val_accuracy: 0.9078\n",
      "Epoch 479/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.1827 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.1831 - accuracy: 0.9110 - val_loss: 0.1854 - val_accuracy: 0.9205\n",
      "Epoch 480/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.2029 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2054 - accuracy: 0.9151 - val_loss: 0.2622 - val_accuracy: 0.8636\n",
      "Epoch 481/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.4580 - accuracy: 0.84\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.4612 - accuracy: 0.8400 - val_loss: 0.6235 - val_accuracy: 0.7765\n",
      "Epoch 482/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.4472 - accuracy: 0.82\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.4440 - accuracy: 0.8283 - val_loss: 0.3257 - val_accuracy: 0.8220\n",
      "Epoch 483/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.3531 - accuracy: 0.84\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.3531 - accuracy: 0.8463 - val_loss: 0.3534 - val_accuracy: 0.8371\n",
      "Epoch 484/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.3749 - accuracy: 0.84\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3749 - accuracy: 0.8425 - val_loss: 0.7497 - val_accuracy: 0.7689\n",
      "Epoch 485/4000\n",
      "3/3 [==============================] - 0s 33ms/steploss: 0.9488 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 82ms/step - loss: 0.9488 - accuracy: 0.7039 - val_loss: 0.6516 - val_accuracy: 0.7449\n",
      "Epoch 486/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.5235 - accuracy: 0.79\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.5236 - accuracy: 0.7923 - val_loss: 0.6738 - val_accuracy: 0.7652\n",
      "Epoch 487/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.6724 - accuracy: 0.73\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.6724 - accuracy: 0.7371 - val_loss: 0.4771 - val_accuracy: 0.7816\n",
      "Epoch 488/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.3758 - accuracy: 0.82\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.3749 - accuracy: 0.8283 - val_loss: 0.3291 - val_accuracy: 0.8510\n",
      "Epoch 489/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2985 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2991 - accuracy: 0.8718 - val_loss: 0.3944 - val_accuracy: 0.8510\n",
      "Epoch 490/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2878 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2871 - accuracy: 0.8801 - val_loss: 0.2771 - val_accuracy: 0.8788\n",
      "Epoch 491/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.2309 - accuracy: 0.90\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2309 - accuracy: 0.9062 - val_loss: 0.2408 - val_accuracy: 0.8864\n",
      "Epoch 492/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.2141 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.2142 - accuracy: 0.9053 - val_loss: 0.2171 - val_accuracy: 0.9091\n",
      "Epoch 493/4000\n",
      "3/3 [==============================] - 0s 28ms/steploss: 0.2282 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.2282 - accuracy: 0.9047 - val_loss: 0.3675 - val_accuracy: 0.8801\n",
      "Epoch 494/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.3644 - accuracy: 0.85\n",
      "32/32 [==============================] - 2s 79ms/step - loss: 0.3644 - accuracy: 0.8554 - val_loss: 0.3946 - val_accuracy: 0.8371\n",
      "Epoch 495/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.3756 - accuracy: 0.84\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3756 - accuracy: 0.8438 - val_loss: 0.3099 - val_accuracy: 0.8548\n",
      "Epoch 496/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2838 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2838 - accuracy: 0.8766 - val_loss: 0.2666 - val_accuracy: 0.8927\n",
      "Epoch 497/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2585 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2585 - accuracy: 0.8860 - val_loss: 0.2457 - val_accuracy: 0.9028\n",
      "Epoch 498/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.2408 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2441 - accuracy: 0.8936 - val_loss: 0.2516 - val_accuracy: 0.8977\n",
      "Epoch 499/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.2028 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.2028 - accuracy: 0.9205 - val_loss: 0.2414 - val_accuracy: 0.8902\n",
      "Epoch 500/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.1865 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.1865 - accuracy: 0.9246 - val_loss: 0.2176 - val_accuracy: 0.9053\n",
      "Epoch 501/4000\n",
      "3/3 [==============================] - 0s 19ms/steploss: 0.1843 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.1843 - accuracy: 0.9201 - val_loss: 0.1955 - val_accuracy: 0.9129\n",
      "Epoch 502/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.1807 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1791 - accuracy: 0.9223 - val_loss: 0.1844 - val_accuracy: 0.9179\n",
      "Epoch 503/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.2337 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2337 - accuracy: 0.8980 - val_loss: 0.3106 - val_accuracy: 0.8763\n",
      "Epoch 504/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2584 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2584 - accuracy: 0.8845 - val_loss: 0.2990 - val_accuracy: 0.8788\n",
      "Epoch 505/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2029 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2029 - accuracy: 0.9122 - val_loss: 0.1990 - val_accuracy: 0.9217\n",
      "Epoch 506/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2030 - accuracy: 0.90\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2030 - accuracy: 0.9094 - val_loss: 0.2572 - val_accuracy: 0.8914\n",
      "Epoch 507/4000\n",
      "3/3 [==============================] - 0s 31ms/steploss: 0.2654 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2654 - accuracy: 0.8905 - val_loss: 0.2506 - val_accuracy: 0.8927\n",
      "Epoch 508/4000\n",
      "3/3 [==============================] - 0s 29ms/steploss: 0.2510 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 91ms/step - loss: 0.2510 - accuracy: 0.8889 - val_loss: 0.3336 - val_accuracy: 0.8737\n",
      "Epoch 509/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.3298 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3298 - accuracy: 0.8677 - val_loss: 0.5043 - val_accuracy: 0.7929\n",
      "Epoch 510/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 1.0543 - accuracy: 0.67\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 1.0543 - accuracy: 0.6780 - val_loss: 0.7261 - val_accuracy: 0.7323\n",
      "Epoch 511/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.5949 - accuracy: 0.75\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.5949 - accuracy: 0.7560 - val_loss: 0.5530 - val_accuracy: 0.7753\n",
      "Epoch 512/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.3831 - accuracy: 0.84\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3853 - accuracy: 0.8425 - val_loss: 0.2985 - val_accuracy: 0.8763\n",
      "Epoch 513/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.3085 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3077 - accuracy: 0.8731 - val_loss: 0.2486 - val_accuracy: 0.8939\n",
      "Epoch 514/4000\n",
      "3/3 [==============================] - 0s 28ms/steploss: 0.2312 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.2312 - accuracy: 0.9034 - val_loss: 0.2730 - val_accuracy: 0.8813\n",
      "Epoch 515/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.1927 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1927 - accuracy: 0.9230 - val_loss: 0.2250 - val_accuracy: 0.9040\n",
      "Epoch 516/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2024 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2024 - accuracy: 0.9217 - val_loss: 0.2625 - val_accuracy: 0.8801\n",
      "Epoch 517/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2037 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2036 - accuracy: 0.9182 - val_loss: 0.2049 - val_accuracy: 0.9040\n",
      "Epoch 518/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.6602 - accuracy: 0.76\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.6590 - accuracy: 0.7626 - val_loss: 0.5139 - val_accuracy: 0.7841\n",
      "Epoch 519/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.7439 - accuracy: 0.72\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.7439 - accuracy: 0.7235 - val_loss: 0.4858 - val_accuracy: 0.7992\n",
      "Epoch 520/4000\n",
      "3/3 [==============================] - 0s 29ms/steploss: 0.3950 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3942 - accuracy: 0.8362 - val_loss: 0.3476 - val_accuracy: 0.8460\n",
      "Epoch 521/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.3603 - accuracy: 0.84\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.3606 - accuracy: 0.8463 - val_loss: 0.3890 - val_accuracy: 0.8194\n",
      "Epoch 522/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3543 - accuracy: 0.85\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.3543 - accuracy: 0.8529 - val_loss: 0.3571 - val_accuracy: 0.8649\n",
      "Epoch 523/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.2798 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 94ms/step - loss: 0.2798 - accuracy: 0.8807 - val_loss: 0.2814 - val_accuracy: 0.8699\n",
      "Epoch 524/4000\n",
      "3/3 [==============================] - 0s 28ms/steploss: 0.2567 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.2607 - accuracy: 0.8829 - val_loss: 0.2775 - val_accuracy: 0.8624\n",
      "Epoch 525/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2621 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2621 - accuracy: 0.8756 - val_loss: 0.2695 - val_accuracy: 0.8725\n",
      "Epoch 526/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2397 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2397 - accuracy: 0.8886 - val_loss: 0.2671 - val_accuracy: 0.8699\n",
      "Epoch 527/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.2349 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2349 - accuracy: 0.8886 - val_loss: 0.2672 - val_accuracy: 0.8636\n",
      "Epoch 528/4000\n",
      "3/3 [==============================] - 0s 28ms/steploss: 0.2236 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2236 - accuracy: 0.9003 - val_loss: 0.2360 - val_accuracy: 0.8889\n",
      "Epoch 529/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2199 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2199 - accuracy: 0.8987 - val_loss: 0.2289 - val_accuracy: 0.8914\n",
      "Epoch 530/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2506 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2488 - accuracy: 0.8886 - val_loss: 0.2900 - val_accuracy: 0.8750\n",
      "Epoch 531/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2740 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2740 - accuracy: 0.8876 - val_loss: 0.2919 - val_accuracy: 0.8712\n",
      "Epoch 532/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2099 - accuracy: 0.90\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.2099 - accuracy: 0.9075 - val_loss: 0.2118 - val_accuracy: 0.9116\n",
      "Epoch 533/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.1798 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.1798 - accuracy: 0.9252 - val_loss: 0.1978 - val_accuracy: 0.9306\n",
      "Epoch 534/4000\n",
      "3/3 [==============================] - 0s 35ms/steploss: 0.1879 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1879 - accuracy: 0.9173 - val_loss: 0.2250 - val_accuracy: 0.9066\n",
      "Epoch 535/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.1819 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1819 - accuracy: 0.9246 - val_loss: 0.1907 - val_accuracy: 0.9255\n",
      "Epoch 536/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.1718 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1718 - accuracy: 0.9293 - val_loss: 0.1827 - val_accuracy: 0.9217\n",
      "Epoch 537/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.1724 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1735 - accuracy: 0.9271 - val_loss: 0.1856 - val_accuracy: 0.9255\n",
      "Epoch 538/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.2163 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2163 - accuracy: 0.9182 - val_loss: 0.2681 - val_accuracy: 0.8775\n",
      "Epoch 539/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.2786 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.2786 - accuracy: 0.8842 - val_loss: 0.2466 - val_accuracy: 0.8952\n",
      "Epoch 540/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2326 - accuracy: 0.89\n",
      "32/32 [==============================] - 3s 95ms/step - loss: 0.2326 - accuracy: 0.8990 - val_loss: 0.2474 - val_accuracy: 0.8737\n",
      "Epoch 541/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.3372 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.3372 - accuracy: 0.8684 - val_loss: 0.3885 - val_accuracy: 0.8535\n",
      "Epoch 542/4000\n",
      "3/3 [==============================] - 0s 32ms/steploss: 0.2978 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2978 - accuracy: 0.8655 - val_loss: 0.3159 - val_accuracy: 0.8535\n",
      "Epoch 543/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2632 - accuracy: 0.88\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.2632 - accuracy: 0.8819 - val_loss: 0.2403 - val_accuracy: 0.9040\n",
      "Epoch 544/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.3091 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3091 - accuracy: 0.8718 - val_loss: 0.4976 - val_accuracy: 0.8106\n",
      "Epoch 545/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.3360 - accuracy: 0.86\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.3360 - accuracy: 0.8649 - val_loss: 0.2605 - val_accuracy: 0.8813\n",
      "Epoch 546/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2591 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2591 - accuracy: 0.8958 - val_loss: 0.2754 - val_accuracy: 0.8927\n",
      "Epoch 547/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.3134 - accuracy: 0.86\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3134 - accuracy: 0.8674 - val_loss: 0.2924 - val_accuracy: 0.8725\n",
      "Epoch 548/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.4610 - accuracy: 0.82\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.4610 - accuracy: 0.8248 - val_loss: 0.4708 - val_accuracy: 0.7891\n",
      "Epoch 549/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.2812 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2812 - accuracy: 0.8823 - val_loss: 0.2079 - val_accuracy: 0.9091\n",
      "Epoch 550/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2236 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2236 - accuracy: 0.9205 - val_loss: 0.3851 - val_accuracy: 0.8194\n",
      "Epoch 551/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.5818 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.5818 - accuracy: 0.7809 - val_loss: 0.5972 - val_accuracy: 0.7500\n",
      "Epoch 552/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.5017 - accuracy: 0.79\n",
      "32/32 [==============================] - 2s 79ms/step - loss: 0.5017 - accuracy: 0.7936 - val_loss: 0.4489 - val_accuracy: 0.8308\n",
      "Epoch 553/4000\n",
      "3/3 [==============================] - 0s 30ms/steploss: 0.3587 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3587 - accuracy: 0.8396 - val_loss: 0.3806 - val_accuracy: 0.8333\n",
      "Epoch 554/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2922 - accuracy: 0.85\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2922 - accuracy: 0.8535 - val_loss: 0.2600 - val_accuracy: 0.8636\n",
      "Epoch 555/4000\n",
      "3/3 [==============================] - 0s 30ms/steploss: 0.2372 - accuracy: 0.\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 0.2372 - accuracy: 0.8867 - val_loss: 0.2511 - val_accuracy: 0.8826\n",
      "Epoch 556/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2403 - accuracy: 0.88\n",
      "32/32 [==============================] - 3s 95ms/step - loss: 0.2423 - accuracy: 0.8848 - val_loss: 0.3006 - val_accuracy: 0.8510\n",
      "Epoch 557/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.2479 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2479 - accuracy: 0.8791 - val_loss: 0.2500 - val_accuracy: 0.8561\n",
      "Epoch 558/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.2597 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.2597 - accuracy: 0.8794 - val_loss: 0.3304 - val_accuracy: 0.8523\n",
      "Epoch 559/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.3522 - accuracy: 0.83\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3481 - accuracy: 0.8362 - val_loss: 0.2394 - val_accuracy: 0.8699\n",
      "Epoch 560/4000\n",
      "3/3 [==============================] - 0s 28ms/steploss: 0.2103 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.2103 - accuracy: 0.9119 - val_loss: 0.2533 - val_accuracy: 0.8662\n",
      "Epoch 561/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2109 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2109 - accuracy: 0.9110 - val_loss: 0.2134 - val_accuracy: 0.9053\n",
      "Epoch 562/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.2288 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 79ms/step - loss: 0.2288 - accuracy: 0.9066 - val_loss: 0.7325 - val_accuracy: 0.7765\n",
      "Epoch 563/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.8028 - accuracy: 0.74\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.8028 - accuracy: 0.7497 - val_loss: 0.5772 - val_accuracy: 0.7247\n",
      "Epoch 564/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.6397 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.6397 - accuracy: 0.7642 - val_loss: 0.4909 - val_accuracy: 0.7803\n",
      "Epoch 565/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.4415 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.4415 - accuracy: 0.8138 - val_loss: 0.4466 - val_accuracy: 0.8005\n",
      "Epoch 566/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.8730 - accuracy: 0.70\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.8730 - accuracy: 0.7023 - val_loss: 0.6868 - val_accuracy: 0.7134\n",
      "Epoch 567/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.6048 - accuracy: 0.74\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.6025 - accuracy: 0.7478 - val_loss: 0.5088 - val_accuracy: 0.7727\n",
      "Epoch 568/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.4148 - accuracy: 0.82\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.4140 - accuracy: 0.8261 - val_loss: 0.3592 - val_accuracy: 0.8649\n",
      "Epoch 569/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3559 - accuracy: 0.85\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3559 - accuracy: 0.8545 - val_loss: 0.3453 - val_accuracy: 0.8687\n",
      "Epoch 570/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.3360 - accuracy: 0.86\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.3360 - accuracy: 0.8677 - val_loss: 0.3988 - val_accuracy: 0.8586\n",
      "Epoch 571/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3336 - accuracy: 0.86\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3336 - accuracy: 0.8649 - val_loss: 0.2915 - val_accuracy: 0.8801\n",
      "Epoch 572/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2642 - accuracy: 0.90\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2642 - accuracy: 0.9031 - val_loss: 0.2758 - val_accuracy: 0.8876\n",
      "Epoch 573/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2236 - accuracy: 0.92\n",
      "32/32 [==============================] - 2s 79ms/step - loss: 0.2236 - accuracy: 0.9220 - val_loss: 0.2218 - val_accuracy: 0.9141\n",
      "Epoch 574/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2184 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2184 - accuracy: 0.9182 - val_loss: 0.2426 - val_accuracy: 0.9040\n",
      "Epoch 575/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2290 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.2290 - accuracy: 0.9148 - val_loss: 0.2572 - val_accuracy: 0.9116\n",
      "Epoch 576/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2072 - accuracy: 0.92\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.2072 - accuracy: 0.9249 - val_loss: 0.2080 - val_accuracy: 0.9268\n",
      "Epoch 577/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.6039 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.6008 - accuracy: 0.8116 - val_loss: 0.7135 - val_accuracy: 0.7222\n",
      "Epoch 578/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.6780 - accuracy: 0.71\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.6780 - accuracy: 0.7115 - val_loss: 0.6887 - val_accuracy: 0.6944\n",
      "Epoch 579/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.4716 - accuracy: 0.79\n",
      "32/32 [==============================] - 3s 82ms/step - loss: 0.4711 - accuracy: 0.7977 - val_loss: 0.3674 - val_accuracy: 0.8573\n",
      "Epoch 580/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.3229 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3229 - accuracy: 0.8734 - val_loss: 0.3060 - val_accuracy: 0.8750\n",
      "Epoch 581/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2830 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2830 - accuracy: 0.8832 - val_loss: 0.2856 - val_accuracy: 0.8687\n",
      "Epoch 582/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2634 - accuracy: 0.88\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.2634 - accuracy: 0.8857 - val_loss: 0.2611 - val_accuracy: 0.8914\n",
      "Epoch 583/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2368 - accuracy: 0.89\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.2368 - accuracy: 0.8990 - val_loss: 0.2426 - val_accuracy: 0.8851\n",
      "Epoch 584/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2888 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 79ms/step - loss: 0.2888 - accuracy: 0.8791 - val_loss: 0.2731 - val_accuracy: 0.8889\n",
      "Epoch 585/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3050 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3050 - accuracy: 0.8772 - val_loss: 0.4343 - val_accuracy: 0.8245\n",
      "Epoch 586/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.4262 - accuracy: 0.82\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.4262 - accuracy: 0.8273 - val_loss: 0.3928 - val_accuracy: 0.8371\n",
      "Epoch 587/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.3690 - accuracy: 0.83\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.3690 - accuracy: 0.8381 - val_loss: 0.3803 - val_accuracy: 0.8232\n",
      "Epoch 588/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.4113 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.4113 - accuracy: 0.8349 - val_loss: 0.3956 - val_accuracy: 0.8119\n",
      "Epoch 589/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.4812 - accuracy: 0.79\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.4942 - accuracy: 0.7936 - val_loss: 0.7490 - val_accuracy: 0.7033\n",
      "Epoch 590/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.5190 - accuracy: 0.78\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.5190 - accuracy: 0.7809 - val_loss: 0.4962 - val_accuracy: 0.7879\n",
      "Epoch 591/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.3847 - accuracy: 0.83\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.3847 - accuracy: 0.8371 - val_loss: 0.3627 - val_accuracy: 0.8169\n",
      "Epoch 592/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.3250 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.3250 - accuracy: 0.8576 - val_loss: 0.2922 - val_accuracy: 0.8611\n",
      "Epoch 593/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.2640 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2661 - accuracy: 0.8873 - val_loss: 0.3034 - val_accuracy: 0.8725\n",
      "Epoch 594/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2392 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2392 - accuracy: 0.8990 - val_loss: 0.2488 - val_accuracy: 0.8965\n",
      "Epoch 595/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.2525 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.2525 - accuracy: 0.8980 - val_loss: 0.5525 - val_accuracy: 0.8220\n",
      "Epoch 596/4000\n",
      "3/3 [==============================] - 0s 40ms/steploss: 0.3741 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.3741 - accuracy: 0.8479 - val_loss: 0.4223 - val_accuracy: 0.8295\n",
      "Epoch 597/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2729 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.2729 - accuracy: 0.8857 - val_loss: 0.2405 - val_accuracy: 0.9053\n",
      "Epoch 598/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2078 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2078 - accuracy: 0.9186 - val_loss: 0.2025 - val_accuracy: 0.9015\n",
      "Epoch 599/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.1873 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 79ms/step - loss: 0.1873 - accuracy: 0.9173 - val_loss: 0.3049 - val_accuracy: 0.8914\n",
      "Epoch 600/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2191 - accuracy: 0.90\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2215 - accuracy: 0.8996 - val_loss: 0.3028 - val_accuracy: 0.8864\n",
      "Epoch 601/4000\n",
      "3/3 [==============================] - 0s 32ms/steploss: 0.3679 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.3648 - accuracy: 0.8466 - val_loss: 0.6530 - val_accuracy: 0.7778\n",
      "Epoch 602/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.6154 - accuracy: 0.77\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.6154 - accuracy: 0.7746 - val_loss: 0.4506 - val_accuracy: 0.8624\n",
      "Epoch 603/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.4460 - accuracy: 0.84\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.4496 - accuracy: 0.8393 - val_loss: 0.4724 - val_accuracy: 0.8068\n",
      "Epoch 604/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.3035 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3035 - accuracy: 0.8712 - val_loss: 0.2574 - val_accuracy: 0.9028\n",
      "Epoch 605/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2279 - accuracy: 0.90\n",
      "32/32 [==============================] - 2s 79ms/step - loss: 0.2279 - accuracy: 0.9053 - val_loss: 0.2095 - val_accuracy: 0.9040\n",
      "Epoch 606/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2829 - accuracy: 0.88\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.2829 - accuracy: 0.8857 - val_loss: 0.3412 - val_accuracy: 0.8548\n",
      "Epoch 607/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.3045 - accuracy: 0.86\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3045 - accuracy: 0.8649 - val_loss: 0.2599 - val_accuracy: 0.9078\n",
      "Epoch 608/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2474 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2474 - accuracy: 0.8870 - val_loss: 0.2733 - val_accuracy: 0.8813\n",
      "Epoch 609/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.7589 - accuracy: 0.74\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.7509 - accuracy: 0.7421 - val_loss: 0.7629 - val_accuracy: 0.6793\n",
      "Epoch 610/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 1.2397 - accuracy: 0.62\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 1.2347 - accuracy: 0.6212 - val_loss: 0.8985 - val_accuracy: 0.6818\n",
      "Epoch 611/4000\n",
      "3/3 [==============================] - 0s 31ms/steploss: 0.6052 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 79ms/step - loss: 0.6052 - accuracy: 0.7532 - val_loss: 0.4593 - val_accuracy: 0.8056\n",
      "Epoch 612/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.3935 - accuracy: 0.84\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3935 - accuracy: 0.8463 - val_loss: 0.3546 - val_accuracy: 0.8611\n",
      "Epoch 613/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.3680 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3680 - accuracy: 0.8485 - val_loss: 0.3214 - val_accuracy: 0.8674\n",
      "Epoch 614/4000\n",
      "3/3 [==============================] - 0s 30ms/steploss: 0.3594 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.3594 - accuracy: 0.8561 - val_loss: 0.3886 - val_accuracy: 0.8308\n",
      "Epoch 615/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.3364 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3357 - accuracy: 0.8703 - val_loss: 0.3182 - val_accuracy: 0.8687\n",
      "Epoch 616/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2886 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 79ms/step - loss: 0.2886 - accuracy: 0.8819 - val_loss: 0.2944 - val_accuracy: 0.8851\n",
      "Epoch 617/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2975 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2975 - accuracy: 0.8838 - val_loss: 0.3208 - val_accuracy: 0.8523\n",
      "Epoch 618/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2844 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 79ms/step - loss: 0.2850 - accuracy: 0.8848 - val_loss: 0.2843 - val_accuracy: 0.8826\n",
      "Epoch 619/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.2537 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 79ms/step - loss: 0.2537 - accuracy: 0.8933 - val_loss: 0.2989 - val_accuracy: 0.8725\n",
      "Epoch 620/4000\n",
      "3/3 [==============================] - 0s 29ms/steploss: 0.2780 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.2780 - accuracy: 0.8838 - val_loss: 0.3340 - val_accuracy: 0.8523\n",
      "Epoch 621/4000\n",
      "3/3 [==============================] - 0s 19ms/steploss: 0.6295 - accuracy: 0.75\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.6295 - accuracy: 0.7579 - val_loss: 0.5805 - val_accuracy: 0.7399\n",
      "Epoch 622/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.4721 - accuracy: 0.78\n",
      "32/32 [==============================] - 2s 79ms/step - loss: 0.4684 - accuracy: 0.7923 - val_loss: 0.3672 - val_accuracy: 0.8346\n",
      "Epoch 623/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.3453 - accuracy: 0.84\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3453 - accuracy: 0.8419 - val_loss: 0.5571 - val_accuracy: 0.7449\n",
      "Epoch 624/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.3924 - accuracy: 0.81\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.3924 - accuracy: 0.8194 - val_loss: 0.3575 - val_accuracy: 0.8245\n",
      "Epoch 625/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.3163 - accuracy: 0.84\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.3163 - accuracy: 0.8479 - val_loss: 0.3290 - val_accuracy: 0.8371\n",
      "Epoch 626/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.3277 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3277 - accuracy: 0.8532 - val_loss: 0.4740 - val_accuracy: 0.8232\n",
      "Epoch 627/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.4745 - accuracy: 0.79\n",
      "32/32 [==============================] - 3s 108ms/step - loss: 0.4745 - accuracy: 0.7932 - val_loss: 0.3860 - val_accuracy: 0.7854\n",
      "Epoch 628/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.3227 - accuracy: 0.85\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.3227 - accuracy: 0.8520 - val_loss: 0.3189 - val_accuracy: 0.8396\n",
      "Epoch 629/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.3113 - accuracy: 0.85\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.3118 - accuracy: 0.8504 - val_loss: 0.3126 - val_accuracy: 0.8649\n",
      "Epoch 630/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.3243 - accuracy: 0.86\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.3243 - accuracy: 0.8662 - val_loss: 0.3752 - val_accuracy: 0.8359\n",
      "Epoch 631/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.3293 - accuracy: 0.85\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3270 - accuracy: 0.8539 - val_loss: 0.3015 - val_accuracy: 0.8699\n",
      "Epoch 632/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.3358 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.3358 - accuracy: 0.8573 - val_loss: 0.3889 - val_accuracy: 0.8270\n",
      "Epoch 633/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2986 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2986 - accuracy: 0.8759 - val_loss: 0.2906 - val_accuracy: 0.8611\n",
      "Epoch 634/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.2760 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2760 - accuracy: 0.8797 - val_loss: 0.3163 - val_accuracy: 0.8712\n",
      "Epoch 635/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2770 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2770 - accuracy: 0.8845 - val_loss: 0.3209 - val_accuracy: 0.8649\n",
      "Epoch 636/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2850 - accuracy: 0.88\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.2850 - accuracy: 0.8879 - val_loss: 0.2627 - val_accuracy: 0.8927\n",
      "Epoch 637/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.3311 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 79ms/step - loss: 0.3311 - accuracy: 0.8709 - val_loss: 0.5885 - val_accuracy: 0.7753\n",
      "Epoch 638/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.3854 - accuracy: 0.84\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.3854 - accuracy: 0.8434 - val_loss: 0.3142 - val_accuracy: 0.8598\n",
      "Epoch 639/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.2753 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2753 - accuracy: 0.8832 - val_loss: 0.2635 - val_accuracy: 0.8851\n",
      "Epoch 640/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2458 - accuracy: 0.90\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2456 - accuracy: 0.9028 - val_loss: 0.2745 - val_accuracy: 0.8864\n",
      "Epoch 641/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.2533 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2523 - accuracy: 0.8999 - val_loss: 0.2629 - val_accuracy: 0.8851\n",
      "Epoch 642/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.2299 - accuracy: 0.90\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2295 - accuracy: 0.9018 - val_loss: 0.2186 - val_accuracy: 0.9078\n",
      "Epoch 643/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2106 - accuracy: 0.91\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2116 - accuracy: 0.9132 - val_loss: 0.2677 - val_accuracy: 0.8851\n",
      "Epoch 644/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2622 - accuracy: 0.89\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2622 - accuracy: 0.8936 - val_loss: 0.3022 - val_accuracy: 0.8548\n",
      "Epoch 645/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.4283 - accuracy: 0.83\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.4283 - accuracy: 0.8349 - val_loss: 0.4754 - val_accuracy: 0.8131\n",
      "Epoch 646/4000\n",
      "3/3 [==============================] - 0s 29ms/steploss: 0.4124 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 83ms/step - loss: 0.4115 - accuracy: 0.8261 - val_loss: 0.3151 - val_accuracy: 0.8523\n",
      "Epoch 647/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.3158 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.3158 - accuracy: 0.8633 - val_loss: 0.3413 - val_accuracy: 0.8422\n",
      "Epoch 648/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.3037 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3037 - accuracy: 0.8712 - val_loss: 0.2914 - val_accuracy: 0.8699\n",
      "Epoch 649/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.6059 - accuracy: 0.79\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.6059 - accuracy: 0.7929 - val_loss: 0.6107 - val_accuracy: 0.7677\n",
      "Epoch 650/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 1.6579 - accuracy: 0.53\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 1.6549 - accuracy: 0.5385 - val_loss: 1.1709 - val_accuracy: 0.6237\n",
      "Epoch 651/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.9111 - accuracy: 0.67\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.9111 - accuracy: 0.6749 - val_loss: 0.6680 - val_accuracy: 0.7109\n",
      "Epoch 652/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.6660 - accuracy: 0.71\n",
      "32/32 [==============================] - 3s 91ms/step - loss: 0.6652 - accuracy: 0.7162 - val_loss: 0.5557 - val_accuracy: 0.7475\n",
      "Epoch 653/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.5416 - accuracy: 0.78\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.5416 - accuracy: 0.7847 - val_loss: 0.4602 - val_accuracy: 0.8409\n",
      "Epoch 654/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.4785 - accuracy: 0.82\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.4800 - accuracy: 0.8220 - val_loss: 0.4838 - val_accuracy: 0.8106\n",
      "Epoch 655/4000\n",
      "3/3 [==============================] - 0s 28ms/steploss: 0.4232 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.4232 - accuracy: 0.8409 - val_loss: 0.4102 - val_accuracy: 0.8409\n",
      "Epoch 656/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3821 - accuracy: 0.85\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3821 - accuracy: 0.8567 - val_loss: 0.3996 - val_accuracy: 0.8548\n",
      "Epoch 657/4000\n",
      "3/3 [==============================] - 0s 30ms/steploss: 0.3663 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.3663 - accuracy: 0.8602 - val_loss: 0.3657 - val_accuracy: 0.8611\n",
      "Epoch 658/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.3613 - accuracy: 0.86\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3585 - accuracy: 0.8652 - val_loss: 0.3655 - val_accuracy: 0.8548\n",
      "Epoch 659/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.3766 - accuracy: 0.85\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3766 - accuracy: 0.8545 - val_loss: 0.3878 - val_accuracy: 0.8485\n",
      "Epoch 660/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.3651 - accuracy: 0.86\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.3633 - accuracy: 0.8643 - val_loss: 0.3549 - val_accuracy: 0.8624\n",
      "Epoch 661/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.3354 - accuracy: 0.86\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3367 - accuracy: 0.8693 - val_loss: 0.3539 - val_accuracy: 0.8523\n",
      "Epoch 662/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.3324 - accuracy: 0.86\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3359 - accuracy: 0.8687 - val_loss: 0.3492 - val_accuracy: 0.8535\n",
      "Epoch 663/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.3293 - accuracy: 0.86\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3293 - accuracy: 0.8693 - val_loss: 0.3422 - val_accuracy: 0.8611\n",
      "Epoch 664/4000\n",
      "3/3 [==============================] - 0s 19ms/steploss: 0.3198 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3198 - accuracy: 0.8709 - val_loss: 0.3236 - val_accuracy: 0.8674\n",
      "Epoch 665/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3081 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3081 - accuracy: 0.8747 - val_loss: 0.3995 - val_accuracy: 0.8472\n",
      "Epoch 666/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3219 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3225 - accuracy: 0.8703 - val_loss: 0.3230 - val_accuracy: 0.8687\n",
      "Epoch 667/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.3077 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3077 - accuracy: 0.8718 - val_loss: 0.3432 - val_accuracy: 0.8611\n",
      "Epoch 668/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3263 - accuracy: 0.87\n",
      "32/32 [==============================] - 3s 84ms/step - loss: 0.3257 - accuracy: 0.8699 - val_loss: 0.4401 - val_accuracy: 0.8384\n",
      "Epoch 669/4000\n",
      "3/3 [==============================] - 0s 27ms/steploss: 0.2982 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 91ms/step - loss: 0.2982 - accuracy: 0.8785 - val_loss: 0.3052 - val_accuracy: 0.8737\n",
      "Epoch 670/4000\n",
      "3/3 [==============================] - 0s 19ms/steploss: 0.3037 - accuracy: 0.87\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.3037 - accuracy: 0.8722 - val_loss: 0.3213 - val_accuracy: 0.8775\n",
      "Epoch 671/4000\n",
      "3/3 [==============================] - 0s 19ms/steploss: 0.3445 - accuracy: 0.86\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3445 - accuracy: 0.8621 - val_loss: 0.3293 - val_accuracy: 0.8598\n",
      "Epoch 672/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.2897 - accuracy: 0.87\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.2897 - accuracy: 0.8785 - val_loss: 0.2882 - val_accuracy: 0.8813\n",
      "Epoch 673/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.2972 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2976 - accuracy: 0.8763 - val_loss: 0.2939 - val_accuracy: 0.8687\n",
      "Epoch 674/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.3309 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3350 - accuracy: 0.8747 - val_loss: 0.3686 - val_accuracy: 0.8598\n",
      "Epoch 675/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.5283 - accuracy: 0.79\n",
      "32/32 [==============================] - 3s 82ms/step - loss: 0.5283 - accuracy: 0.7970 - val_loss: 0.3489 - val_accuracy: 0.8548\n",
      "Epoch 676/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.3417 - accuracy: 0.86\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.3417 - accuracy: 0.8621 - val_loss: 0.5667 - val_accuracy: 0.8056\n",
      "Epoch 677/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.3160 - accuracy: 0.87\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3162 - accuracy: 0.8769 - val_loss: 0.3117 - val_accuracy: 0.8699\n",
      "Epoch 678/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.3030 - accuracy: 0.88\n",
      "32/32 [==============================] - 3s 92ms/step - loss: 0.3030 - accuracy: 0.8832 - val_loss: 0.3545 - val_accuracy: 0.8422\n",
      "Epoch 679/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2901 - accuracy: 0.88\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.2901 - accuracy: 0.8848 - val_loss: 0.3023 - val_accuracy: 0.8914\n",
      "Epoch 680/4000\n",
      "3/3 [==============================] - 0s 28ms/steploss: 0.2964 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.2965 - accuracy: 0.8756 - val_loss: 0.2967 - val_accuracy: 0.8788\n",
      "Epoch 681/4000\n",
      "3/3 [==============================] - 0s 21ms/steploss: 0.2873 - accuracy: 0.88\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2873 - accuracy: 0.8854 - val_loss: 0.2728 - val_accuracy: 0.8838\n",
      "Epoch 682/4000\n",
      "3/3 [==============================] - 0s 22ms/steploss: 0.3246 - accuracy: 0.86\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.3246 - accuracy: 0.8681 - val_loss: 0.3189 - val_accuracy: 0.8699\n",
      "Epoch 683/4000\n",
      "3/3 [==============================] - 0s 25ms/steploss: 0.5998 - accuracy: 0.79\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.5991 - accuracy: 0.7961 - val_loss: 0.8372 - val_accuracy: 0.6932\n",
      "Epoch 684/4000\n",
      "3/3 [==============================] - 0s 23ms/steploss: 0.5131 - accuracy: 0.81\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.5131 - accuracy: 0.8153 - val_loss: 0.6046 - val_accuracy: 0.7677\n",
      "Epoch 685/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.5979 - accuracy: 0.\n",
      "32/32 [==============================] - 3s 91ms/step - loss: 0.5979 - accuracy: 0.7825 - val_loss: 0.6924 - val_accuracy: 0.7361\n",
      "Epoch 686/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.4880 - accuracy: 0.78\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.4880 - accuracy: 0.7895 - val_loss: 0.4722 - val_accuracy: 0.7841\n",
      "Epoch 687/4000\n",
      "3/3 [==============================] - 0s 26ms/steploss: 0.3701 - accuracy: 0.\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3723 - accuracy: 0.8403 - val_loss: 0.3498 - val_accuracy: 0.8535\n",
      "Epoch 688/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.3217 - accuracy: 0.86\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.3222 - accuracy: 0.8674 - val_loss: 0.3661 - val_accuracy: 0.8295\n",
      "Epoch 689/4000\n",
      "3/3 [==============================] - 0s 20ms/steploss: 0.3005 - accuracy: 0.87\n",
      "32/32 [==============================] - 3s 82ms/step - loss: 0.3005 - accuracy: 0.8718 - val_loss: 0.3216 - val_accuracy: 0.8611\n",
      "Epoch 690/4000\n",
      "3/3 [==============================] - 0s 24ms/steploss: 0.2917 - accuracy: 0.87\n",
      "Restoring model weights from the end of the best epoch: 190.\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2917 - accuracy: 0.8741 - val_loss: 0.3097 - val_accuracy: 0.8674\n",
      "Epoch 690: early stopping\n",
      "Accuracy: 22.47%\n"
     ]
    }
   ],
   "source": [
    "early_stop=tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=500, verbose=2, mode='auto', baseline=None, restore_best_weights=True)\n",
    "model.fit(X_train_Normalizado, y_train_Normalizado, epochs=4000, batch_size=100, callbacks=[tensorboard_callback,cm_callback,early_stop], validation_data=(X_val_def, y_val_def))\n",
    "# Final evaluation of the model \n",
    "scores = model.evaluate(X_test_def, y_test_def, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 21ms/step\n",
      "(89, 5)\n",
      "(89,)\n",
      "(89,)\n",
      "[0 1 0 2 2 2 2 4 0 0 4 0 0 0 4 0 0 0 2 2 0 1 2 0 1 2 0 0 4 2 0 0 2 2 4 0 0\n",
      " 2 4 0 0 4 0 2 0 0 0 0 3 0 0 0 0 2 0 0 0 0 0 0 0 4 0 2 1 0 0 4 0 4 2 2 0 0\n",
      " 4 2 2 0 0 0 2 0 0 0 2 4 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "#y_pred2=np.where(y_pred>0,1,0)\n",
    "#y_pred2=y_pred2[:,-1]\n",
    "y_test_def2=np.argmax(y_test_def,axis=1)\n",
    "#y_test_def2=np.where(y_test_def>0,1,0)\n",
    "print(y_pred.shape)\n",
    "print(y_pred2.shape)\n",
    "print(y_test_def2.shape)\n",
    "#print(y_test_def[25])\n",
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#docs_infra: no_execute\n",
    "classes = [0, 1, 2, 3, 4]\n",
    "#classes = [0, 1]\n",
    "cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A     0.2745    0.4828    0.3500        29\n",
      "          B+     0.0000    0.0000    0.0000         9\n",
      "           B     0.1905    0.2667    0.2222        15\n",
      "          B-     0.0000    0.0000    0.0000        10\n",
      "           C     0.1667    0.0769    0.1053        26\n",
      "\n",
      "    accuracy                         0.2247        89\n",
      "   macro avg     0.1263    0.1653    0.1355        89\n",
      "weighted avg     0.1702    0.2247    0.1822        89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['A', 'B+', 'B', 'B-','C']\n",
    "print(classification_report(y_test_def2, y_pred2, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('modelos/modelote1203_200')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('idea.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "model.save('modelos\\modelo_perfecto_{}_{}.h5'.format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#este modo de guardar no funciona en esta version de tensorflow\n",
    "#model.save('modelos\\modelo_perfecto_{}_{}'.format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 30ms/step\n",
      "[1 2 1 1 1 1 1 2 2 2 2 0 1 0 0 2 1 2 2 0 0 2]\n",
      "[0 2 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 2 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "n = len(y_pred2)\n",
    "reshaped = y_pred2[:n//4*4].reshape(-1, 4)\n",
    "mean_values = reshaped.mean(axis=1)\n",
    "\n",
    "mean_values = np.round(mean_values)\n",
    "mean_values = np.clip(mean_values, 0, 4)\n",
    "mean_values = mean_values.astype(int)\n",
    "print(mean_values)\n",
    "\n",
    "mode_values = stats.mode(reshaped, axis=1)[0]\n",
    "print(mode_values)\n",
    "\n",
    "# Convierte los arrays a DataFrames\n",
    "mean_df = pd.DataFrame(mean_values, columns=['mean'])\n",
    "mode_df = pd.DataFrame(mode_values, columns=['mode'])\n",
    "\n",
    "# Guarda los DataFrames en archivos Excel\n",
    "mean_df.to_excel(\"excels_borrar\\clasificacion_P1P2_mean_best7.xlsx\", index=False)\n",
    "mode_df.to_excel(\"excels_borrar\\clasificacion_P1_mode_best7.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 2 2 2 2 4 0 0 4 0 0 0 4 0 0 0 2 2 0 1 2 0 1 2 0 0 4 2 0 0 2 2 4 0 0\n",
      " 2 4 0 0 4 0 2 0 0 0 0 3 0 0 0 0 2 0 0 0 0 0 0 0 4 0 2 1 0 0 4 0 4 2 2 0 0\n",
      " 4 2 2 0 0 0 2 0 0 0 2 4 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 220, 8)\n",
      "(200, 5)\n",
      "(200, 5)\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "filename5 = \"COPIA_PANDAS\\lomosP1_20240430_clasificado_experto.hdf\"\n",
    "with pd.HDFStore(filename5,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e2  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e2 = pre_p_e2.loc[pre_p_e2['Pollo'] != 0]\n",
    "    pre_p_e2 =pre_p_e2.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_test2=np.zeros((pre_p_e2.shape[0],220,8))\n",
    "    y_test2=np.zeros((pre_p_e2.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e2.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if estado == 0 or estado== 1:\n",
    "           target = 1\n",
    "        else:\n",
    "           target = 0\n",
    "        target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_test2[x]=pepito[:,3:11]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_test2[x]=target\n",
    "        y_test2_to_categorical = to_categorical(y_test2)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_test2_filtrado = X_test2\n",
    "#y_train_filtrado = y_train\n",
    "y_test2_filtrado = y_test2_to_categorical\n",
    "\n",
    "print(X_test2_filtrado.shape)\n",
    "print(y_test2_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "# concatenamos train y test\n",
    "#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\n",
    "data_2d_test = X_test2_filtrado.reshape(-1, X_test2_filtrado.shape[-1])\n",
    "normalized_data_2d_test = scaler.transform(data_2d_test)\n",
    "\n",
    "\n",
    "X_test2_def=normalized_data_2d_test.reshape(X_test2_filtrado.shape) \n",
    "# la alternativa es normalizar con el total\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "\n",
    "y_test2_def=y_test2_filtrado # los valores ya estaban normalizados\n",
    "\n",
    "print(y_test2_def.shape)\n",
    "\n",
    "print(y_test2_filtrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 27ms/step\n",
      "200\n",
      "(50,)\n",
      "(50,)\n",
      "(89,)\n",
      "200\n",
      "(50,)\n",
      "(50,)\n",
      "[[4 0 4 2]\n",
      " [0 0 0 4]\n",
      " [0 4 0 0]\n",
      " [0 0 2 2]\n",
      " [4 0 0 0]\n",
      " [0 0 4 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 2]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 2 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [2 0 0 0]\n",
      " [0 1 2 0]\n",
      " [0 0 0 0]\n",
      " [2 2 2 2]\n",
      " [3 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 2 0]\n",
      " [2 0 0 0]\n",
      " [0 0 0 2]\n",
      " [0 0 0 0]\n",
      " [0 0 2 3]\n",
      " [0 2 0 0]\n",
      " [2 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [2 2 0 0]\n",
      " [3 2 0 4]\n",
      " [2 0 4 0]\n",
      " [0 0 4 0]\n",
      " [3 0 2 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 4 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 2 2]\n",
      " [0 0 1 0]\n",
      " [0 2 2 0]]\n",
      "[4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 2 3 4 0 0 0 4 0 0 3 4 2 4 0 2 0 0 3 2 4 0 4 0 4 1 0 4 4 0 3 0 0 4 2 2\n",
      " 3 0 0 4 0 2 0 0 4 4 0 0 2]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# # Crear un nuevo modelo con la misma arquitectura\n",
    "# best_val_model = create_model()  # Reemplaza esto con la función que usaste para crear el modelo original\n",
    "\n",
    "# # Cargar los mejores pesos\n",
    "# best_val_model.load_weights('best_weights.h5')\n",
    "\n",
    "y_pred = model.predict(X_test2_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "n = len(y_pred2)\n",
    "print(n)\n",
    "reshaped = y_pred2[:n//4*4].reshape(-1, 4)\n",
    "mean_values = reshaped.mean(axis=1)\n",
    "\n",
    "mean_values = np.round(mean_values)\n",
    "mean_values = np.clip(mean_values, 0, 4)\n",
    "mean_values = mean_values.astype(int)\n",
    "print(mean_values.shape)\n",
    "\n",
    "mode_values = stats.mode(reshaped, axis=1)[0]\n",
    "print(mode_values.shape)\n",
    "\n",
    "n = len(y_test2_def)\n",
    "y_test2_def2=np.argmax(y_test2_def,axis=1)\n",
    "print(y_test_def2.shape)\n",
    "print(n)\n",
    "reshaped2 = y_test2_def2[:n//4*4].reshape(-1, 4)\n",
    "target_mean_values = reshaped2.mean(axis=1)\n",
    "\n",
    "target_mean_values = np.round(target_mean_values)\n",
    "target_mean_values = np.clip(target_mean_values, 0, 4)\n",
    "target_mean_values = target_mean_values.astype(int)\n",
    "print(target_mean_values.shape)\n",
    "\n",
    "target_mode_values = stats.mode(reshaped2, axis=1)[0]\n",
    "print(target_mode_values.shape)\n",
    "print(reshaped)\n",
    "print(mode_values)\n",
    "print(target_mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#docs_infra: no_execute\n",
    "classes = [0, 1, 2, 3, 4]\n",
    "#classes = [0, 1]\n",
    "cm=confusion_matrix(target_mode_values, mode_values,labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91304348 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(cm.diagonal()/cm.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A     0.4375    0.9130    0.5915        23\n",
      "          B+     0.0000    0.0000    0.0000         1\n",
      "           B     0.0000    0.0000    0.0000         8\n",
      "          B-     0.0000    0.0000    0.0000         5\n",
      "           C     0.0000    0.0000    0.0000        13\n",
      "\n",
      "    accuracy                         0.4200        50\n",
      "   macro avg     0.0875    0.1826    0.1183        50\n",
      "weighted avg     0.2013    0.4200    0.2721        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "target_names= ['A', 'B+', 'B', 'B-','C']\n",
    "print(classification_report(target_mode_values, mode_values, target_names=target_names, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
