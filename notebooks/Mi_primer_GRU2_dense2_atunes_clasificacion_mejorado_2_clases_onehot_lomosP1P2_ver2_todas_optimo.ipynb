{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:\\nuevas_investigaciones_alimentos_2024\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,TimeDistributed,Flatten\n",
    "from tensorflow.keras.layers import LSTM,Bidirectional,GRU\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import datetime\n",
    "import io\n",
    "import itertools\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Obtener la ruta del directorio actual\n",
    "os.chdir('..')\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "# Construir la ruta relativa al directorio que quieres agregar\n",
    "relative_dir = os.path.join(current_dir, 'mis_pkgs/')\n",
    "\n",
    "# Agregar la ruta relativa al sys.path\n",
    "sys.path.insert(0, relative_dir)\n",
    "\n",
    "from MIOPATIA_db import DB_management as db \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_muestras=220\n",
    "numero_clases=2\n",
    "entrada=slice(3,11)\n",
    "numero_entradas = entrada.stop - entrada.start\n",
    "numero_epochs=400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a quedarme con los 50 atunes P1 para obtener conjunto de training y validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Add, Activation, Concatenate, Conv2D, Dropout \n",
    "from tensorflow.keras.layers import Flatten, Input, GlobalAveragePooling2D, MaxPooling2D\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "__version__ = '0.0.1'\n",
    "\n",
    "\n",
    "def SqueezeNet(input_shape, nb_classes, use_bypass=False, dropout_rate=None, compression=1.0):\n",
    "    \"\"\"\n",
    "    Creating a SqueezeNet of version 1.0\n",
    "    \n",
    "    Arguments:\n",
    "        input_shape  : shape of the input images e.g. (224,224,3)\n",
    "        nb_classes   : number of classes\n",
    "        use_bypass   : if true, bypass connections will be created at fire module 3, 5, 7, and 9 (default: False)\n",
    "        dropout_rate : defines the dropout rate that is accomplished after last fire module (default: None)\n",
    "        compression  : reduce the number of feature-maps (default: 1.0)\n",
    "        \n",
    "    Returns:\n",
    "        Model        : Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(int(96*compression), (7,7), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "    x = create_fire_module(x, int(16*compression), name='fire3', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool4')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(32*compression), name='fire5', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "    x = create_fire_module(x, int(48*compression), name='fire7', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool8')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(64*compression), name='fire9', use_bypass=use_bypass)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        \n",
    "    x = output(x, nb_classes)\n",
    "\n",
    "    return Model(inputs=input_img, outputs=x)\n",
    "\n",
    "\n",
    "def SqueezeNet_11(input_shape, nb_classes, dropout_rate=None, compression=1.0):\n",
    "    \"\"\"\n",
    "    Creating a SqueezeNet of version 1.1\n",
    "    \n",
    "    2.4x less computation over SqueezeNet 1.0 implemented above.\n",
    "    \n",
    "    Arguments:\n",
    "        input_shape  : shape of the input images e.g. (224,224,3)\n",
    "        nb_classes   : number of classes\n",
    "        dropout_rate : defines the dropout rate that is accomplished after last fire module (default: None)\n",
    "        compression  : reduce the number of feature-maps\n",
    "        \n",
    "    Returns:\n",
    "        Model        : Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(int(64*compression), (3,3), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "    x = create_fire_module(x, int(16*compression), name='fire3')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool3')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "    x = create_fire_module(x, int(32*compression), name='fire5')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool5')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "    x = create_fire_module(x, int(48*compression), name='fire7')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire9')\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # Creating last conv10\n",
    "    x = output(x, nb_classes)\n",
    "\n",
    "    return Model(inputs=input_img, outputs=x)\n",
    "\n",
    "\n",
    "def output(x, nb_classes):\n",
    "    x = Conv2D(nb_classes, (1,1), strides=(1,1), padding='valid', name='conv10')(x)\n",
    "    x = GlobalAveragePooling2D(name='avgpool10')(x)\n",
    "    x = Activation(\"softmax\", name='softmax')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_fire_module(x, nb_squeeze_filter, name, use_bypass=False):\n",
    "    \"\"\"\n",
    "    Creates a fire module\n",
    "    \n",
    "    Arguments:\n",
    "        x                 : input\n",
    "        nb_squeeze_filter : number of filters of squeeze. The filtersize of expand is 4 times of squeeze\n",
    "        use_bypass        : if True then a bypass will be added\n",
    "        name              : name of module e.g. fire123\n",
    "    \n",
    "    Returns:\n",
    "        x                 : returns a fire module\n",
    "    \"\"\"\n",
    "    \n",
    "    nb_expand_filter = 4 * nb_squeeze_filter\n",
    "    squeeze    = Conv2D(nb_squeeze_filter,(1,1), activation='relu', padding='same', name='%s_squeeze'%name)(x)\n",
    "    expand_1x1 = Conv2D(nb_expand_filter, (1,1), activation='relu', padding='same', name='%s_expand_1x1'%name)(squeeze)\n",
    "    expand_3x3 = Conv2D(nb_expand_filter, (3,3), activation='relu', padding='same', name='%s_expand_3x3'%name)(squeeze)\n",
    "    \n",
    "    axis = get_axis()\n",
    "    x_ret = Concatenate(axis=axis, name='%s_concatenate'%name)([expand_1x1, expand_3x3])\n",
    "    \n",
    "    if use_bypass:\n",
    "        x_ret = Add(name='%s_concatenate_bypass'%name)([x_ret, x])\n",
    "        \n",
    "    return x_ret\n",
    "\n",
    "\n",
    "def get_axis():\n",
    "    axis = -1 if K.image_data_format() == 'channels_last' else 1\n",
    "    return axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5280, 2)\n"
     ]
    }
   ],
   "source": [
    "filename = \"COPIA_PANDAS\\lomosP1P2_20240430_clasificado_experto_filtrado_automatico_trainval_ampliado_meditado.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    # p_e =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_train=np.zeros((pre_p_e1.shape[0],numero_muestras,numero_entradas))\n",
    "    y_train=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1:\n",
    "                target = 0\n",
    "            else:\n",
    "                target = 1\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_train[x]=pepito[:,entrada]\n",
    "        #X_train[x]=X_train[x].reshape(X_train[x].shape[0],-1)\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_train[x]=target\n",
    "        y_train_to_categorical = to_categorical(y_train)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_train_filtrado = X_train\n",
    "#y_train_filtrado = y_train\n",
    "y_train_filtrado = y_train_to_categorical\n",
    "\n",
    "# print(X_train_filtrado.shape)\n",
    "# print(y_train_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "scaler = StandardScaler()\n",
    "data_2d = X_train_filtrado.reshape(-1, X_train_filtrado.shape[-1])\n",
    "normalized_data_2d = scaler.fit_transform(data_2d)\n",
    "#para recurrentes\n",
    "X_train_Normalizado=normalized_data_2d.reshape(X_train_filtrado.shape) #para recurrentes\n",
    "#para densas\n",
    "#X_train_Normalizado=normalized_data_2d.reshape(X_train_filtrado.shape[0],-1)\n",
    "y_train_Normalizado=y_train_filtrado # los valores ya estaban normalizados\n",
    "print(y_train_Normalizado.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 220, 8)\n",
      "(43, 2)\n",
      "[[-0.35546171  1.34262018  2.06781266 ... -1.34262018 -0.35545069\n",
      "   0.38227165]\n",
      " [-0.35594834  1.35525272  1.93633445 ... -1.35525272 -0.35593735\n",
      "   0.38260625]\n",
      " [-0.35639266  1.36763591  1.81007274 ... -1.36763591 -0.3563817\n",
      "   0.38292124]\n",
      " ...\n",
      " [-0.3894466  -1.059254   -0.18508903 ...  1.059254   -0.38943909\n",
      "   0.38734405]\n",
      " [-0.3895557  -1.04533658 -0.18512607 ...  1.04533658 -0.38954817\n",
      "   0.38751309]\n",
      " [-0.38965607 -1.02821332 -0.18518923 ...  1.02821332 -0.38964853\n",
      "   0.38767187]]\n"
     ]
    }
   ],
   "source": [
    "filename = \"COPIA_PANDAS\\lomosP1P2_20240430_clasificado_experto_filtrado_automatico_test.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    pre_p_e1 =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_test=np.zeros((pre_p_e1.shape[0],numero_muestras,numero_entradas))\n",
    "    y_test=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1:\n",
    "                target = 0\n",
    "            else:\n",
    "                target = 1\n",
    "\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_test[x]=pepito[:,entrada]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_test[x]=target\n",
    "        y_test_to_categorical = to_categorical(y_test)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_test_filtrado = X_test\n",
    "#y_train_filtrado = y_train\n",
    "y_test_filtrado = y_test_to_categorical\n",
    "\n",
    "print(X_test_filtrado.shape)\n",
    "print(y_test_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "# concatenamos train y test\n",
    "#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\n",
    "data_2d_test = X_test_filtrado.reshape(-1, X_test_filtrado.shape[-1])\n",
    "normalized_data_2d_test = scaler.transform(data_2d_test)\n",
    "\n",
    "\n",
    "X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape[0],-1) \n",
    "# la alternativa es normalizar con el total\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "\n",
    "y_test_def=y_test_filtrado # los valores ya estaban normalizados\n",
    "print(X_test_def[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer los conjuntos de entrenamiento validacion y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide el dataset en entrenamiento y temporal (test+validación)\n",
    "# X_temp, X_test_def, y_temp, y_test_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.2, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Divide el dataset temporal en validación y test\n",
    "X_train_def, X_val_def, y_train_def, y_val_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.25, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Ahora, X_train, X_val y X_test contienen los datos de entrada para los conjuntos de entrenamiento, validación y prueba, respectivamente.\n",
    "# y_train, y_val y y_test contienen las clases correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3960, 220, 8)\n",
      "(1320, 220, 8)\n",
      "(43, 220, 8)\n",
      "(3960, 2)\n",
      "(1320, 2)\n",
      "(43, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_def.shape)\n",
    "print(X_val_def.shape)\n",
    "print(X_test_def.shape)\n",
    "print(y_train_def.shape)\n",
    "print(y_val_def.shape)\n",
    "print(y_test_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "\n",
    "#%tensorboard --logdir logs\n",
    "#log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"\n",
    "    Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\n",
    "    \"\"\"\n",
    "    \n",
    "    buf = io.BytesIO()\n",
    "    \n",
    "    # Use plt.savefig to save the plot to a PNG in memory.\n",
    "    plt.savefig(buf, format='png')\n",
    "    \n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    \n",
    "    # Use tf.image.decode_png to convert the PNG buffer\n",
    "    # to a TF image. Make sure you use 4 channels.\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    \n",
    "    # Use tf.expand_dims to add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "       class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    \n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    # Normalize the confusion matrix.\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    \n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    threshold = 0.5\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"red\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_aprendizaje=0.001\n",
    "dimension_LSTM=80\n",
    "dimension_dense1=50\n",
    "dimension_dense2=20\n",
    "algoritmo='rmsprop'\n",
    "supermax=8*4\n",
    "lossfunction='categorical_crossentropy'\n",
    "def create_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(GRU(dimension_LSTM, return_sequences=True, input_shape=(numero_muestras, numero_entradas)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(dimension_dense1, activation='tanh'))\n",
    "    model.add(Dense(dimension_dense2, activation='tanh'))\n",
    "    model.add(Dense(numero_clases, activation='softmax'))\n",
    "    model.compile(loss=lossfunction, optimizer=algoritmo, metrics=['accuracy'])\n",
    "    model.optimizer.lr=(factor_aprendizaje)\n",
    "    return model\n",
    "\n",
    "model=create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 220, 80)           21600     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 17600)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                880050    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                1020      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 902,712\n",
      "Trainable params: 902,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar una lista de los números en el rango del slice\n",
    "numbers = list(range(entrada.start, entrada.stop))\n",
    "\n",
    "# Convertir la lista a un string con los números separados por guiones\n",
    "slice_str = \"-\".join(map(str, numbers))\n",
    "slice_str=\"todas\"\n",
    "\n",
    "\n",
    "#experimento=\"idea\"\n",
    "experimento=\"LOMOS_P1P2_entradas_{}_GRU1_{}_dense1_{}_dense2_{}_clases_{}_loss_{}_lr_{}_algoritmo_{}\".format(slice_str,dimension_LSTM, dimension_dense1,dimension_dense2,numero_clases,lossfunction,factor_aprendizaje,algoritmo)\n",
    "logdir=\"./logs/defs/{}_{}\".format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if numero_clases==2:\n",
    "    class_names=['Buenos', 'Malos']\n",
    "else:\n",
    "    class_names=['A', 'B+', 'B', 'B-','C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    \n",
    "    # Use the model to predict the values from the test_images.\n",
    "    y_pred = model.predict(X_test_def)\n",
    "    #y_pred1=y_pred[:,-1]\n",
    "    y_pred2=y_pred.argmax(axis=1)\n",
    "    #y_pred2=np.where(y_pred>0,1,0)\n",
    "    #y_pred2=y_pred2[:,-1]\n",
    "    if numero_clases==2:\n",
    "        classes = [0, 1]    \n",
    "    else:\n",
    "\n",
    "        classes = [0, 1, 2, 3, 4] \n",
    "    #classes = [0, 1]\n",
    "    y_test_def2=np.argmax(y_test_def,axis=1)  \n",
    "    #y_test_def2=np.where(y_test_def>0,1,0)\n",
    "    cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    figura = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figura)\n",
    "    \n",
    "    # Log the confusion matrix as an image summary.\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5280, 2)\n",
      "(1320, 2)\n"
     ]
    }
   ],
   "source": [
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "print(y_train_Normalizado.shape)\n",
    "print(y_val_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un callback para guardar los mejores pesos\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('best_weights.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "40/40 [==============================] - 5s 38ms/step - loss: 0.7317 - accuracy: 0.6033 - val_loss: 0.6397 - val_accuracy: 0.6341\n",
      "Epoch 2/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.6297 - accuracy: 0.6311 - val_loss: 0.6138 - val_accuracy: 0.6311\n",
      "Epoch 3/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.6068 - accuracy: 0.6412 - val_loss: 0.5951 - val_accuracy: 0.6508\n",
      "Epoch 4/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.5816 - accuracy: 0.6735 - val_loss: 0.5791 - val_accuracy: 0.6644\n",
      "Epoch 5/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5466 - accuracy: 0.7061 - val_loss: 0.5585 - val_accuracy: 0.7008\n",
      "Epoch 6/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.5226 - accuracy: 0.7263 - val_loss: 0.5468 - val_accuracy: 0.6947\n",
      "Epoch 7/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5043 - accuracy: 0.7404 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 8/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.4622 - accuracy: 0.7775 - val_loss: 0.4493 - val_accuracy: 0.8053\n",
      "Epoch 9/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.4267 - accuracy: 0.7992 - val_loss: 0.4088 - val_accuracy: 0.8144\n",
      "Epoch 10/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.3774 - accuracy: 0.8321 - val_loss: 0.4456 - val_accuracy: 0.7856\n",
      "Epoch 11/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.3429 - accuracy: 0.8510 - val_loss: 0.3889 - val_accuracy: 0.8068\n",
      "Epoch 12/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.3055 - accuracy: 0.8795 - val_loss: 0.3917 - val_accuracy: 0.7924\n",
      "Epoch 13/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.3039 - accuracy: 0.8737 - val_loss: 0.2955 - val_accuracy: 0.8917\n",
      "Epoch 14/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.2927 - accuracy: 0.8841 - val_loss: 0.2813 - val_accuracy: 0.8992\n",
      "Epoch 15/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.2654 - accuracy: 0.8939 - val_loss: 0.3269 - val_accuracy: 0.8379\n",
      "Epoch 16/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.2310 - accuracy: 0.9083 - val_loss: 0.2977 - val_accuracy: 0.8689\n",
      "Epoch 17/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.2359 - accuracy: 0.9045 - val_loss: 0.2698 - val_accuracy: 0.8636\n",
      "Epoch 18/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.2360 - accuracy: 0.9025 - val_loss: 0.2033 - val_accuracy: 0.9061\n",
      "Epoch 19/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.2081 - accuracy: 0.9144 - val_loss: 0.1731 - val_accuracy: 0.9348\n",
      "Epoch 20/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.1654 - accuracy: 0.9384 - val_loss: 0.1851 - val_accuracy: 0.9144\n",
      "Epoch 21/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.1670 - accuracy: 0.9391 - val_loss: 0.1486 - val_accuracy: 0.9386\n",
      "Epoch 22/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.1568 - accuracy: 0.9409 - val_loss: 0.1307 - val_accuracy: 0.9530\n",
      "Epoch 23/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.1565 - accuracy: 0.9376 - val_loss: 0.2305 - val_accuracy: 0.9068\n",
      "Epoch 24/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.1411 - accuracy: 0.9533 - val_loss: 0.1836 - val_accuracy: 0.9159\n",
      "Epoch 25/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.1528 - accuracy: 0.9449 - val_loss: 0.1743 - val_accuracy: 0.9333\n",
      "Epoch 26/400\n",
      "40/40 [==============================] - 1s 33ms/step - loss: 0.1319 - accuracy: 0.9566 - val_loss: 0.1937 - val_accuracy: 0.9235\n",
      "Epoch 27/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.1194 - accuracy: 0.9616 - val_loss: 0.2062 - val_accuracy: 0.9167\n",
      "Epoch 28/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.1152 - accuracy: 0.9619 - val_loss: 0.0744 - val_accuracy: 0.9841\n",
      "Epoch 29/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.1248 - accuracy: 0.9548 - val_loss: 0.1026 - val_accuracy: 0.9598\n",
      "Epoch 30/400\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.0975 - accuracy: 0.9641 - val_loss: 0.1045 - val_accuracy: 0.9545\n",
      "Epoch 31/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.1069 - accuracy: 0.9596 - val_loss: 0.0865 - val_accuracy: 0.9689\n",
      "Epoch 32/400\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.0869 - accuracy: 0.9682 - val_loss: 0.0961 - val_accuracy: 0.9682\n",
      "Epoch 33/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.1175 - accuracy: 0.9556 - val_loss: 0.1240 - val_accuracy: 0.9424\n",
      "Epoch 34/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.1115 - accuracy: 0.9510 - val_loss: 0.0833 - val_accuracy: 0.9727\n",
      "Epoch 35/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.1023 - accuracy: 0.9563 - val_loss: 0.0706 - val_accuracy: 0.9705\n",
      "Epoch 36/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.1271 - accuracy: 0.9508 - val_loss: 0.1316 - val_accuracy: 0.9364\n",
      "Epoch 37/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0821 - accuracy: 0.9677 - val_loss: 0.0608 - val_accuracy: 0.9803\n",
      "Epoch 38/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.1002 - accuracy: 0.9606 - val_loss: 0.0621 - val_accuracy: 0.9667\n",
      "Epoch 39/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0931 - accuracy: 0.9614 - val_loss: 0.0771 - val_accuracy: 0.9606\n",
      "Epoch 40/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0843 - accuracy: 0.9631 - val_loss: 0.0710 - val_accuracy: 0.9697\n",
      "Epoch 41/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0858 - accuracy: 0.9649 - val_loss: 0.0708 - val_accuracy: 0.9720\n",
      "Epoch 42/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0790 - accuracy: 0.9669 - val_loss: 0.0952 - val_accuracy: 0.9591\n",
      "Epoch 43/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0901 - accuracy: 0.9677 - val_loss: 0.0836 - val_accuracy: 0.9614\n",
      "Epoch 44/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0950 - accuracy: 0.9657 - val_loss: 0.0764 - val_accuracy: 0.9689\n",
      "Epoch 45/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0911 - accuracy: 0.9616 - val_loss: 0.0739 - val_accuracy: 0.9780\n",
      "Epoch 46/400\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.0793 - accuracy: 0.9682 - val_loss: 0.1280 - val_accuracy: 0.9523\n",
      "Epoch 47/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.1045 - accuracy: 0.9598 - val_loss: 0.0630 - val_accuracy: 0.9788\n",
      "Epoch 48/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0652 - accuracy: 0.9730 - val_loss: 0.1182 - val_accuracy: 0.9644\n",
      "Epoch 49/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0799 - accuracy: 0.9705 - val_loss: 0.0761 - val_accuracy: 0.9682\n",
      "Epoch 50/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0997 - accuracy: 0.9606 - val_loss: 0.0572 - val_accuracy: 0.9811\n",
      "Epoch 51/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0671 - accuracy: 0.9750 - val_loss: 0.0603 - val_accuracy: 0.9795\n",
      "Epoch 52/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0702 - accuracy: 0.9727 - val_loss: 0.3334 - val_accuracy: 0.9083\n",
      "Epoch 53/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0689 - accuracy: 0.9720 - val_loss: 0.0566 - val_accuracy: 0.9803\n",
      "Epoch 54/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0837 - accuracy: 0.9725 - val_loss: 0.0571 - val_accuracy: 0.9795\n",
      "Epoch 55/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0502 - accuracy: 0.9821 - val_loss: 0.1260 - val_accuracy: 0.9568\n",
      "Epoch 56/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0682 - accuracy: 0.9793 - val_loss: 0.0496 - val_accuracy: 0.9902\n",
      "Epoch 57/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0631 - accuracy: 0.9818 - val_loss: 0.0660 - val_accuracy: 0.9848\n",
      "Epoch 58/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0742 - accuracy: 0.9765 - val_loss: 0.0391 - val_accuracy: 0.9894\n",
      "Epoch 59/400\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.0406 - accuracy: 0.9879 - val_loss: 0.0584 - val_accuracy: 0.9720\n",
      "Epoch 60/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0750 - accuracy: 0.9722 - val_loss: 0.0576 - val_accuracy: 0.9788\n",
      "Epoch 61/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0525 - accuracy: 0.9803 - val_loss: 0.0445 - val_accuracy: 0.9773\n",
      "Epoch 62/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0692 - accuracy: 0.9730 - val_loss: 0.0530 - val_accuracy: 0.9750\n",
      "Epoch 63/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0477 - accuracy: 0.9801 - val_loss: 0.0666 - val_accuracy: 0.9758\n",
      "Epoch 64/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0567 - accuracy: 0.9813 - val_loss: 0.0478 - val_accuracy: 0.9841\n",
      "Epoch 65/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0572 - accuracy: 0.9793 - val_loss: 0.0479 - val_accuracy: 0.9818\n",
      "Epoch 66/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0476 - accuracy: 0.9838 - val_loss: 0.1000 - val_accuracy: 0.9773\n",
      "Epoch 67/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0443 - accuracy: 0.9843 - val_loss: 0.0429 - val_accuracy: 0.9856\n",
      "Epoch 68/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0765 - accuracy: 0.9745 - val_loss: 0.0601 - val_accuracy: 0.9811\n",
      "Epoch 69/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0422 - accuracy: 0.9856 - val_loss: 0.0650 - val_accuracy: 0.9667\n",
      "Epoch 70/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0406 - accuracy: 0.9843 - val_loss: 0.0348 - val_accuracy: 0.9856\n",
      "Epoch 71/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0462 - accuracy: 0.9841 - val_loss: 0.0369 - val_accuracy: 0.9902\n",
      "Epoch 72/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0411 - accuracy: 0.9884 - val_loss: 0.0381 - val_accuracy: 0.9818\n",
      "Epoch 73/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0504 - accuracy: 0.9806 - val_loss: 0.0569 - val_accuracy: 0.9795\n",
      "Epoch 74/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0462 - accuracy: 0.9828 - val_loss: 0.0903 - val_accuracy: 0.9652\n",
      "Epoch 75/400\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.0423 - accuracy: 0.9876 - val_loss: 0.0325 - val_accuracy: 0.9848\n",
      "Epoch 76/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0376 - accuracy: 0.9899 - val_loss: 0.0395 - val_accuracy: 0.9886\n",
      "Epoch 77/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0767 - accuracy: 0.9798 - val_loss: 0.0427 - val_accuracy: 0.9856\n",
      "Epoch 78/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0324 - accuracy: 0.9866 - val_loss: 0.0369 - val_accuracy: 0.9848\n",
      "Epoch 79/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0290 - accuracy: 0.9874 - val_loss: 0.0376 - val_accuracy: 0.9818\n",
      "Epoch 80/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0510 - accuracy: 0.9808 - val_loss: 0.0355 - val_accuracy: 0.9902\n",
      "Epoch 81/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0492 - accuracy: 0.9864 - val_loss: 0.0438 - val_accuracy: 0.9871\n",
      "Epoch 82/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0264 - accuracy: 0.9937 - val_loss: 0.0328 - val_accuracy: 0.9902\n",
      "Epoch 83/400\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.0426 - accuracy: 0.9841 - val_loss: 0.0721 - val_accuracy: 0.9818\n",
      "Epoch 84/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0444 - accuracy: 0.9836 - val_loss: 0.0437 - val_accuracy: 0.9856\n",
      "Epoch 85/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0384 - accuracy: 0.9854 - val_loss: 0.0416 - val_accuracy: 0.9818\n",
      "Epoch 86/400\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.0433 - accuracy: 0.9836 - val_loss: 0.0609 - val_accuracy: 0.9765\n",
      "Epoch 87/400\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.0332 - accuracy: 0.9884 - val_loss: 0.0403 - val_accuracy: 0.9856\n",
      "Epoch 88/400\n",
      "40/40 [==============================] - 1s 31ms/step - loss: 0.0401 - accuracy: 0.9856 - val_loss: 0.0402 - val_accuracy: 0.9818\n",
      "Epoch 89/400\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.0451 - accuracy: 0.9843 - val_loss: 0.0735 - val_accuracy: 0.9712\n",
      "Epoch 90/400\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.0327 - accuracy: 0.9871 - val_loss: 0.0386 - val_accuracy: 0.9818\n",
      "Epoch 91/400\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.0433 - accuracy: 0.9841 - val_loss: 0.0417 - val_accuracy: 0.9864\n",
      "Epoch 92/400\n",
      "40/40 [==============================] - 1s 33ms/step - loss: 0.0282 - accuracy: 0.9876 - val_loss: 0.0371 - val_accuracy: 0.9811\n",
      "Epoch 93/400\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.0335 - accuracy: 0.9854 - val_loss: 0.0361 - val_accuracy: 0.9848\n",
      "Epoch 94/400\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.0515 - accuracy: 0.9801 - val_loss: 0.0466 - val_accuracy: 0.9811\n",
      "Epoch 95/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0373 - accuracy: 0.9864 - val_loss: 0.0452 - val_accuracy: 0.9864\n",
      "Epoch 96/400\n",
      "40/40 [==============================] - 1s 33ms/step - loss: 0.0397 - accuracy: 0.9859 - val_loss: 0.0443 - val_accuracy: 0.9848\n",
      "Epoch 97/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0302 - accuracy: 0.9884 - val_loss: 0.0598 - val_accuracy: 0.9818\n",
      "Epoch 98/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0883 - accuracy: 0.9715 - val_loss: 0.0660 - val_accuracy: 0.9697\n",
      "Epoch 99/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0595 - accuracy: 0.9750 - val_loss: 0.0494 - val_accuracy: 0.9735\n",
      "Epoch 100/400\n",
      "40/40 [==============================] - 1s 33ms/step - loss: 0.0541 - accuracy: 0.9755 - val_loss: 0.0537 - val_accuracy: 0.9780\n",
      "Epoch 101/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0717 - accuracy: 0.9705 - val_loss: 0.0355 - val_accuracy: 0.9856\n",
      "Epoch 102/400\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.0322 - accuracy: 0.9876 - val_loss: 0.0315 - val_accuracy: 0.9856\n",
      "Epoch 103/400\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.0288 - accuracy: 0.9874 - val_loss: 0.0553 - val_accuracy: 0.9856\n",
      "Epoch 104/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0358 - accuracy: 0.9886 - val_loss: 0.5065 - val_accuracy: 0.8818\n",
      "Epoch 105/400\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.0916 - accuracy: 0.9699 - val_loss: 0.0558 - val_accuracy: 0.9765\n",
      "Epoch 106/400\n",
      "40/40 [==============================] - 1s 30ms/step - loss: 0.0608 - accuracy: 0.9785 - val_loss: 0.0917 - val_accuracy: 0.9636\n",
      "Epoch 107/400\n",
      "40/40 [==============================] - 1s 31ms/step - loss: 0.0338 - accuracy: 0.9866 - val_loss: 0.0362 - val_accuracy: 0.9818\n",
      "Epoch 108/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0512 - accuracy: 0.9821 - val_loss: 0.0812 - val_accuracy: 0.9750\n",
      "Epoch 109/400\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.0411 - accuracy: 0.9856 - val_loss: 0.0484 - val_accuracy: 0.9818\n",
      "Epoch 110/400\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.0357 - accuracy: 0.9876 - val_loss: 0.0531 - val_accuracy: 0.9848\n",
      "Epoch 111/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0384 - accuracy: 0.9841 - val_loss: 0.0425 - val_accuracy: 0.9856\n",
      "Epoch 112/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0443 - accuracy: 0.9841 - val_loss: 0.0634 - val_accuracy: 0.9780\n",
      "Epoch 113/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0347 - accuracy: 0.9881 - val_loss: 0.0430 - val_accuracy: 0.9826\n",
      "Epoch 114/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0323 - accuracy: 0.9881 - val_loss: 0.0437 - val_accuracy: 0.9818\n",
      "Epoch 115/400\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.0528 - accuracy: 0.9811 - val_loss: 0.0420 - val_accuracy: 0.9864\n",
      "Epoch 116/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0321 - accuracy: 0.9869 - val_loss: 0.0412 - val_accuracy: 0.9826\n",
      "Epoch 117/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0308 - accuracy: 0.9859 - val_loss: 0.0418 - val_accuracy: 0.9864\n",
      "Epoch 118/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0393 - accuracy: 0.9836 - val_loss: 0.0423 - val_accuracy: 0.9848\n",
      "Epoch 119/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0498 - accuracy: 0.9831 - val_loss: 0.0319 - val_accuracy: 0.9818\n",
      "Epoch 120/400\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.0306 - accuracy: 0.9881 - val_loss: 0.0439 - val_accuracy: 0.9864\n",
      "Epoch 121/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0511 - accuracy: 0.9813 - val_loss: 0.0826 - val_accuracy: 0.9689\n",
      "Epoch 122/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0371 - accuracy: 0.9866 - val_loss: 0.0451 - val_accuracy: 0.9856\n",
      "Epoch 123/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0321 - accuracy: 0.9889 - val_loss: 0.0430 - val_accuracy: 0.9788\n",
      "Epoch 124/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0337 - accuracy: 0.9871 - val_loss: 0.0425 - val_accuracy: 0.9818\n",
      "Epoch 125/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0297 - accuracy: 0.9879 - val_loss: 0.0357 - val_accuracy: 0.9856\n",
      "Epoch 126/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0433 - accuracy: 0.9854 - val_loss: 0.0378 - val_accuracy: 0.9818\n",
      "Epoch 127/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0291 - accuracy: 0.9884 - val_loss: 0.0394 - val_accuracy: 0.9818\n",
      "Epoch 128/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0269 - accuracy: 0.9881 - val_loss: 0.0364 - val_accuracy: 0.9864\n",
      "Epoch 129/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0447 - accuracy: 0.9816 - val_loss: 0.0373 - val_accuracy: 0.9848\n",
      "Epoch 130/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0276 - accuracy: 0.9859 - val_loss: 0.0346 - val_accuracy: 0.9826\n",
      "Epoch 131/400\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.0302 - accuracy: 0.9874 - val_loss: 0.0377 - val_accuracy: 0.9902\n",
      "Epoch 132/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0338 - accuracy: 0.9884 - val_loss: 0.0549 - val_accuracy: 0.9811\n",
      "Epoch 133/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0376 - accuracy: 0.9881 - val_loss: 0.1120 - val_accuracy: 0.9629\n",
      "Epoch 134/400\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.0362 - accuracy: 0.9881 - val_loss: 0.0680 - val_accuracy: 0.9697\n",
      "Epoch 135/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0329 - accuracy: 0.9874 - val_loss: 0.0370 - val_accuracy: 0.9818\n",
      "Epoch 136/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0326 - accuracy: 0.9871 - val_loss: 0.0360 - val_accuracy: 0.9818\n",
      "Epoch 137/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0337 - accuracy: 0.9871 - val_loss: 0.0450 - val_accuracy: 0.9795\n",
      "Epoch 138/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0297 - accuracy: 0.9871 - val_loss: 0.0407 - val_accuracy: 0.9856\n",
      "Epoch 139/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0422 - accuracy: 0.9841 - val_loss: 0.0417 - val_accuracy: 0.9848\n",
      "Epoch 140/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0288 - accuracy: 0.9871 - val_loss: 0.0388 - val_accuracy: 0.9826\n",
      "Epoch 141/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0277 - accuracy: 0.9881 - val_loss: 0.0389 - val_accuracy: 0.9826\n",
      "Epoch 142/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0483 - accuracy: 0.9816 - val_loss: 0.0468 - val_accuracy: 0.9795\n",
      "Epoch 143/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0276 - accuracy: 0.9889 - val_loss: 0.0381 - val_accuracy: 0.9864\n",
      "Epoch 144/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0329 - accuracy: 0.9859 - val_loss: 0.0377 - val_accuracy: 0.9856\n",
      "Epoch 145/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0249 - accuracy: 0.9919 - val_loss: 0.0368 - val_accuracy: 0.9909\n",
      "Epoch 146/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0278 - accuracy: 0.9919 - val_loss: 0.0294 - val_accuracy: 0.9909\n",
      "Epoch 147/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0372 - accuracy: 0.9869 - val_loss: 0.0381 - val_accuracy: 0.9856\n",
      "Epoch 148/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0279 - accuracy: 0.9876 - val_loss: 0.0386 - val_accuracy: 0.9864\n",
      "Epoch 149/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0282 - accuracy: 0.9871 - val_loss: 0.0357 - val_accuracy: 0.9826\n",
      "Epoch 150/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0295 - accuracy: 0.9886 - val_loss: 0.0382 - val_accuracy: 0.9818\n",
      "Epoch 151/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0279 - accuracy: 0.9886 - val_loss: 0.0341 - val_accuracy: 0.9826\n",
      "Epoch 152/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0295 - accuracy: 0.9874 - val_loss: 0.0420 - val_accuracy: 0.9780\n",
      "Epoch 153/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0436 - accuracy: 0.9841 - val_loss: 0.0427 - val_accuracy: 0.9811\n",
      "Epoch 154/400\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.0274 - accuracy: 0.9879 - val_loss: 0.0373 - val_accuracy: 0.9856\n",
      "Epoch 155/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0276 - accuracy: 0.9871 - val_loss: 0.0365 - val_accuracy: 0.9856\n",
      "Epoch 156/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0286 - accuracy: 0.9876 - val_loss: 0.0367 - val_accuracy: 0.9856\n",
      "Epoch 157/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0333 - accuracy: 0.9874 - val_loss: 0.0400 - val_accuracy: 0.9856\n",
      "Epoch 158/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0274 - accuracy: 0.9886 - val_loss: 0.0349 - val_accuracy: 0.9826\n",
      "Epoch 159/400\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.0266 - accuracy: 0.9876 - val_loss: 0.0349 - val_accuracy: 0.9818\n",
      "Epoch 160/400\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.0397 - accuracy: 0.9856 - val_loss: 0.0334 - val_accuracy: 0.9909\n",
      "Epoch 161/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0257 - accuracy: 0.9929 - val_loss: 0.0321 - val_accuracy: 0.9909\n",
      "Epoch 162/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0286 - accuracy: 0.9912 - val_loss: 0.0639 - val_accuracy: 0.9856\n",
      "Epoch 163/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0341 - accuracy: 0.9927 - val_loss: 0.0513 - val_accuracy: 0.9826\n",
      "Epoch 164/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0311 - accuracy: 0.9912 - val_loss: 0.0512 - val_accuracy: 0.9856\n",
      "Epoch 165/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0278 - accuracy: 0.9937 - val_loss: 0.0366 - val_accuracy: 0.9902\n",
      "Epoch 166/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0313 - accuracy: 0.9886 - val_loss: 0.0425 - val_accuracy: 0.9886\n",
      "Epoch 167/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0246 - accuracy: 0.9942 - val_loss: 0.0404 - val_accuracy: 0.9856\n",
      "Epoch 168/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0503 - accuracy: 0.9879 - val_loss: 0.0390 - val_accuracy: 0.9902\n",
      "Epoch 169/400\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.0251 - accuracy: 0.9937 - val_loss: 0.0326 - val_accuracy: 0.9909\n",
      "Epoch 170/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0243 - accuracy: 0.9937 - val_loss: 0.0411 - val_accuracy: 0.9894\n",
      "Epoch 171/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0357 - accuracy: 0.9909 - val_loss: 0.0357 - val_accuracy: 0.9886\n",
      "Epoch 172/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0234 - accuracy: 0.9944 - val_loss: 0.0460 - val_accuracy: 0.9856\n",
      "Epoch 173/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0302 - accuracy: 0.9889 - val_loss: 0.0365 - val_accuracy: 0.9902\n",
      "Epoch 174/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0226 - accuracy: 0.9944 - val_loss: 0.0347 - val_accuracy: 0.9909\n",
      "Epoch 175/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0236 - accuracy: 0.9944 - val_loss: 0.0365 - val_accuracy: 0.9902\n",
      "Epoch 176/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0244 - accuracy: 0.9937 - val_loss: 0.0342 - val_accuracy: 0.9902\n",
      "Epoch 177/400\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.0221 - accuracy: 0.9944 - val_loss: 0.0322 - val_accuracy: 0.9909\n",
      "Epoch 178/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0283 - accuracy: 0.9927 - val_loss: 0.0317 - val_accuracy: 0.9909\n",
      "Epoch 179/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0221 - accuracy: 0.9944 - val_loss: 0.0336 - val_accuracy: 0.9909\n",
      "Epoch 180/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 0.0321 - val_accuracy: 0.9909\n",
      "Epoch 181/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0363 - accuracy: 0.9902 - val_loss: 0.0341 - val_accuracy: 0.9894\n",
      "Epoch 182/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0218 - accuracy: 0.9942 - val_loss: 0.0328 - val_accuracy: 0.9909\n",
      "Epoch 183/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0310 - accuracy: 0.9914 - val_loss: 0.0293 - val_accuracy: 0.9902\n",
      "Epoch 184/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 0.0273 - val_accuracy: 0.9902\n",
      "Epoch 185/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0243 - accuracy: 0.9929 - val_loss: 0.0345 - val_accuracy: 0.9902\n",
      "Epoch 186/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0264 - accuracy: 0.9927 - val_loss: 0.0359 - val_accuracy: 0.9902\n",
      "Epoch 187/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0230 - accuracy: 0.9942 - val_loss: 0.0313 - val_accuracy: 0.9902\n",
      "Epoch 188/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0235 - accuracy: 0.9932 - val_loss: 0.0318 - val_accuracy: 0.9902\n",
      "Epoch 189/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0252 - accuracy: 0.9934 - val_loss: 0.0329 - val_accuracy: 0.9909\n",
      "Epoch 190/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0215 - accuracy: 0.9947 - val_loss: 0.0319 - val_accuracy: 0.9909\n",
      "Epoch 191/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0253 - accuracy: 0.9929 - val_loss: 0.0300 - val_accuracy: 0.9909\n",
      "Epoch 192/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0208 - accuracy: 0.9947 - val_loss: 0.0317 - val_accuracy: 0.9909\n",
      "Epoch 193/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0230 - accuracy: 0.9934 - val_loss: 0.0324 - val_accuracy: 0.9909\n",
      "Epoch 194/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0264 - accuracy: 0.9939 - val_loss: 0.0369 - val_accuracy: 0.9909\n",
      "Epoch 195/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0230 - accuracy: 0.9947 - val_loss: 0.0375 - val_accuracy: 0.9909\n",
      "Epoch 196/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0578 - accuracy: 0.9881 - val_loss: 0.0417 - val_accuracy: 0.9909\n",
      "Epoch 197/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0246 - accuracy: 0.9947 - val_loss: 0.0363 - val_accuracy: 0.9902\n",
      "Epoch 198/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0275 - accuracy: 0.9927 - val_loss: 0.1554 - val_accuracy: 0.9629\n",
      "Epoch 199/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0356 - accuracy: 0.9909 - val_loss: 0.0321 - val_accuracy: 0.9902\n",
      "Epoch 200/400\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.0214 - accuracy: 0.9947 - val_loss: 0.0332 - val_accuracy: 0.9909\n",
      "Epoch 201/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0305 - accuracy: 0.9927 - val_loss: 0.0415 - val_accuracy: 0.9909\n",
      "Epoch 202/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0226 - accuracy: 0.9947 - val_loss: 0.0349 - val_accuracy: 0.9909\n",
      "Epoch 203/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0208 - accuracy: 0.9947 - val_loss: 0.0298 - val_accuracy: 0.9909\n",
      "Epoch 204/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0327 - accuracy: 0.9917 - val_loss: 0.0280 - val_accuracy: 0.9909\n",
      "Epoch 205/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.0263 - val_accuracy: 0.9909\n",
      "Epoch 206/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0193 - accuracy: 0.9947 - val_loss: 0.0317 - val_accuracy: 0.9902\n",
      "Epoch 207/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 0.0258 - val_accuracy: 0.9909\n",
      "Epoch 208/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 0.0276 - val_accuracy: 0.9902\n",
      "Epoch 209/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0214 - accuracy: 0.9937 - val_loss: 0.0306 - val_accuracy: 0.9909\n",
      "Epoch 210/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 0.0239 - val_accuracy: 0.9909\n",
      "Epoch 211/400\n",
      "40/40 [==============================] - 1s 30ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.0240 - val_accuracy: 0.9909\n",
      "Epoch 212/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0205 - accuracy: 0.9929 - val_loss: 0.0487 - val_accuracy: 0.9841\n",
      "Epoch 213/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0203 - accuracy: 0.9932 - val_loss: 0.0227 - val_accuracy: 0.9909\n",
      "Epoch 214/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.0353 - val_accuracy: 0.9894\n",
      "Epoch 215/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0249 - accuracy: 0.9917 - val_loss: 0.0290 - val_accuracy: 0.9894\n",
      "Epoch 216/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0198 - accuracy: 0.9942 - val_loss: 0.0322 - val_accuracy: 0.9902\n",
      "Epoch 217/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0306 - accuracy: 0.9929 - val_loss: 0.0692 - val_accuracy: 0.9833\n",
      "Epoch 218/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0360 - accuracy: 0.9899 - val_loss: 0.0298 - val_accuracy: 0.9909\n",
      "Epoch 219/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.0263 - val_accuracy: 0.9909\n",
      "Epoch 220/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0292 - accuracy: 0.9924 - val_loss: 0.0276 - val_accuracy: 0.9909\n",
      "Epoch 221/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.0266 - val_accuracy: 0.9909\n",
      "Epoch 222/400\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.0242 - accuracy: 0.9922 - val_loss: 0.0436 - val_accuracy: 0.9841\n",
      "Epoch 223/400\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.0272 - accuracy: 0.9927 - val_loss: 0.0248 - val_accuracy: 0.9909\n",
      "Epoch 224/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.0285 - val_accuracy: 0.9902\n",
      "Epoch 225/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0299 - accuracy: 0.9909 - val_loss: 0.0273 - val_accuracy: 0.9902\n",
      "Epoch 226/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.0250 - val_accuracy: 0.9909\n",
      "Epoch 227/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0193 - accuracy: 0.9929 - val_loss: 0.0251 - val_accuracy: 0.9909\n",
      "Epoch 228/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.0244 - val_accuracy: 0.9909\n",
      "Epoch 229/400\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.0213 - accuracy: 0.9937 - val_loss: 0.0333 - val_accuracy: 0.9886\n",
      "Epoch 230/400\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.0179 - accuracy: 0.9947 - val_loss: 0.0269 - val_accuracy: 0.9909\n",
      "Epoch 231/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0200 - accuracy: 0.9942 - val_loss: 0.0237 - val_accuracy: 0.9909\n",
      "Epoch 232/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.0236 - val_accuracy: 0.9909\n",
      "Epoch 233/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.0272 - val_accuracy: 0.9909\n",
      "Epoch 234/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0239 - accuracy: 0.9937 - val_loss: 0.0262 - val_accuracy: 0.9909\n",
      "Epoch 235/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.0237 - val_accuracy: 0.9909\n",
      "Epoch 236/400\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.0228 - val_accuracy: 0.9909\n",
      "Epoch 237/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0149 - accuracy: 0.9947 - val_loss: 0.0209 - val_accuracy: 0.9909\n",
      "Epoch 238/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.0198 - val_accuracy: 0.9909\n",
      "Epoch 239/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0142 - accuracy: 0.9947 - val_loss: 0.0203 - val_accuracy: 0.9909\n",
      "Epoch 240/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0189 - accuracy: 0.9932 - val_loss: 0.0195 - val_accuracy: 0.9909\n",
      "Epoch 241/400\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.0139 - accuracy: 0.9947 - val_loss: 0.0216 - val_accuracy: 0.9909\n",
      "Epoch 242/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.0323 - val_accuracy: 0.9909\n",
      "Epoch 243/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 0.0286 - val_accuracy: 0.9902\n",
      "Epoch 244/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.0254 - val_accuracy: 0.9909\n",
      "Epoch 245/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0262 - accuracy: 0.9927 - val_loss: 0.0265 - val_accuracy: 0.9909\n",
      "Epoch 246/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.0318 - val_accuracy: 0.9909\n",
      "Epoch 247/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0349 - val_accuracy: 0.9871\n",
      "Epoch 248/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0212 - accuracy: 0.9934 - val_loss: 0.0251 - val_accuracy: 0.9909\n",
      "Epoch 249/400\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.0244 - val_accuracy: 0.9909\n",
      "Epoch 250/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0281 - accuracy: 0.9912 - val_loss: 0.0277 - val_accuracy: 0.9909\n",
      "Epoch 251/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.0268 - val_accuracy: 0.9909\n",
      "Epoch 252/400\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.0255 - val_accuracy: 0.9909\n",
      "Epoch 253/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0210 - accuracy: 0.9939 - val_loss: 0.0244 - val_accuracy: 0.9902\n",
      "Epoch 254/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0222 - accuracy: 0.9932 - val_loss: 0.0237 - val_accuracy: 0.9909\n",
      "Epoch 255/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0179 - accuracy: 0.9947 - val_loss: 0.0270 - val_accuracy: 0.9909\n",
      "Epoch 256/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.0231 - val_accuracy: 0.9909\n",
      "Epoch 257/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0283 - accuracy: 0.9922 - val_loss: 0.0251 - val_accuracy: 0.9909\n",
      "Epoch 258/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0292 - val_accuracy: 0.9902\n",
      "Epoch 259/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0257 - val_accuracy: 0.9902\n",
      "Epoch 260/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0243 - val_accuracy: 0.9909\n",
      "Epoch 261/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.0236 - val_accuracy: 0.9909\n",
      "Epoch 262/400\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.0250 - val_accuracy: 0.9902\n",
      "Epoch 263/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0269 - accuracy: 0.9924 - val_loss: 0.0259 - val_accuracy: 0.9894\n",
      "Epoch 264/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0244 - val_accuracy: 0.9909\n",
      "Epoch 265/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.0231 - val_accuracy: 0.9909\n",
      "Epoch 266/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0248 - accuracy: 0.9937 - val_loss: 0.0252 - val_accuracy: 0.9902\n",
      "Epoch 267/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.0241 - val_accuracy: 0.9909\n",
      "Epoch 268/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.0237 - val_accuracy: 0.9909\n",
      "Epoch 269/400\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 0.0192 - val_accuracy: 0.9909\n",
      "Epoch 270/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.0278 - val_accuracy: 0.9902\n",
      "Epoch 271/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.0284 - val_accuracy: 0.9909\n",
      "Epoch 272/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.0234 - val_accuracy: 0.9909\n",
      "Epoch 273/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0556 - accuracy: 0.9899 - val_loss: 0.0387 - val_accuracy: 0.9902\n",
      "Epoch 274/400\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.0188 - accuracy: 0.9947 - val_loss: 0.0237 - val_accuracy: 0.9902\n",
      "Epoch 275/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0271 - val_accuracy: 0.9902\n",
      "Epoch 276/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0267 - val_accuracy: 0.9902\n",
      "Epoch 277/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.0260 - val_accuracy: 0.9909\n",
      "Epoch 278/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0306 - accuracy: 0.9922 - val_loss: 0.0471 - val_accuracy: 0.9848\n",
      "Epoch 279/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 0.0272 - val_accuracy: 0.9902\n",
      "Epoch 280/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 0.0314 - val_accuracy: 0.9902\n",
      "Epoch 281/400\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.0267 - accuracy: 0.9929 - val_loss: 0.0253 - val_accuracy: 0.9909\n",
      "Epoch 282/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 0.0267 - val_accuracy: 0.9909\n",
      "Epoch 283/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.0237 - val_accuracy: 0.9909\n",
      "Epoch 284/400\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.0274 - val_accuracy: 0.9909\n",
      "Epoch 285/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0474 - accuracy: 0.9879 - val_loss: 0.0259 - val_accuracy: 0.9902\n",
      "Epoch 286/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0194 - accuracy: 0.9934 - val_loss: 0.0298 - val_accuracy: 0.9886\n",
      "Epoch 287/400\n",
      "40/40 [==============================] - 1s 33ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.0255 - val_accuracy: 0.9902\n",
      "Epoch 288/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0222 - accuracy: 0.9929 - val_loss: 0.0257 - val_accuracy: 0.9902\n",
      "Epoch 289/400\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.0242 - val_accuracy: 0.9902\n",
      "Epoch 290/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.0333 - val_accuracy: 0.9894\n",
      "Epoch 291/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.0227 - val_accuracy: 0.9909\n",
      "Epoch 292/400\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.0235 - accuracy: 0.9929 - val_loss: 0.0266 - val_accuracy: 0.9902\n",
      "Epoch 293/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.0278 - val_accuracy: 0.9909\n",
      "Epoch 294/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.0228 - val_accuracy: 0.9909\n",
      "Epoch 295/400\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.0186 - accuracy: 0.9942 - val_loss: 0.0287 - val_accuracy: 0.9909\n",
      "Epoch 296/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.0233 - val_accuracy: 0.9909\n",
      "Epoch 297/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.0257 - val_accuracy: 0.9909\n",
      "Epoch 298/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0212 - accuracy: 0.9939 - val_loss: 0.0242 - val_accuracy: 0.9902\n",
      "Epoch 299/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.0219 - val_accuracy: 0.9909\n",
      "Epoch 300/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.0261 - val_accuracy: 0.9909\n",
      "Epoch 301/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0158 - accuracy: 0.9944 - val_loss: 0.0289 - val_accuracy: 0.9886\n",
      "Epoch 302/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.0241 - val_accuracy: 0.9909\n",
      "Epoch 303/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.0284 - val_accuracy: 0.9909\n",
      "Epoch 304/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.0271 - val_accuracy: 0.9909\n",
      "Epoch 305/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.0235 - val_accuracy: 0.9902\n",
      "Epoch 306/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0165 - accuracy: 0.9944 - val_loss: 0.0216 - val_accuracy: 0.9909\n",
      "Epoch 307/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0159 - accuracy: 0.9942 - val_loss: 0.0306 - val_accuracy: 0.9788\n",
      "Epoch 308/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0177 - accuracy: 0.9934 - val_loss: 0.0234 - val_accuracy: 0.9902\n",
      "Epoch 309/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0172 - accuracy: 0.9934 - val_loss: 0.0217 - val_accuracy: 0.9909\n",
      "Epoch 310/400\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 0.0430 - val_accuracy: 0.9894\n",
      "Epoch 311/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.0275 - val_accuracy: 0.9902\n",
      "Epoch 312/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.1605 - val_accuracy: 0.9614\n",
      "Epoch 313/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 0.0250 - val_accuracy: 0.9909\n",
      "Epoch 314/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.0231 - val_accuracy: 0.9909\n",
      "Epoch 315/400\n",
      "40/40 [==============================] - 1s 31ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.0247 - val_accuracy: 0.9909\n",
      "Epoch 316/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0269 - accuracy: 0.9919 - val_loss: 0.0214 - val_accuracy: 0.9909\n",
      "Epoch 317/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.0274 - val_accuracy: 0.9909\n",
      "Epoch 318/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0167 - accuracy: 0.9929 - val_loss: 0.0372 - val_accuracy: 0.9909\n",
      "Epoch 319/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0197 - accuracy: 0.9944 - val_loss: 0.0239 - val_accuracy: 0.9909\n",
      "Epoch 320/400\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.0238 - val_accuracy: 0.9909\n",
      "Epoch 321/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0188 - accuracy: 0.9934 - val_loss: 0.0244 - val_accuracy: 0.9909\n",
      "Epoch 322/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.0308 - val_accuracy: 0.9909\n",
      "Epoch 323/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.0256 - val_accuracy: 0.9909\n",
      "Epoch 324/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.0224 - val_accuracy: 0.9909\n",
      "Epoch 325/400\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.0135 - accuracy: 0.9947 - val_loss: 0.0201 - val_accuracy: 0.9909\n",
      "Epoch 326/400\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.0159 - accuracy: 0.9944 - val_loss: 0.0274 - val_accuracy: 0.9909\n",
      "Epoch 327/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.0206 - val_accuracy: 0.9909\n",
      "Epoch 328/400\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.0173 - accuracy: 0.9939 - val_loss: 0.0164 - val_accuracy: 0.9909\n",
      "Epoch 329/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0104 - accuracy: 0.9947 - val_loss: 0.0147 - val_accuracy: 0.9909\n",
      "Epoch 330/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0199 - accuracy: 0.9927 - val_loss: 0.0264 - val_accuracy: 0.9902\n",
      "Epoch 331/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.0270 - val_accuracy: 0.9902\n",
      "Epoch 332/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.0307 - val_accuracy: 0.9902\n",
      "Epoch 333/400\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.0238 - accuracy: 0.9932 - val_loss: 0.0243 - val_accuracy: 0.9909\n",
      "Epoch 334/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.0229 - val_accuracy: 0.9894\n",
      "Epoch 335/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.0188 - val_accuracy: 0.9902\n",
      "Epoch 336/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0132 - accuracy: 0.9939 - val_loss: 0.0274 - val_accuracy: 0.9902\n",
      "Epoch 337/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0230 - accuracy: 0.9909 - val_loss: 0.0255 - val_accuracy: 0.9894\n",
      "Epoch 338/400\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.0133 - accuracy: 0.9944 - val_loss: 0.0188 - val_accuracy: 0.9894\n",
      "Epoch 339/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0091 - accuracy: 0.9949 - val_loss: 0.0160 - val_accuracy: 0.9902\n",
      "Epoch 340/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0201 - accuracy: 0.9919 - val_loss: 0.0264 - val_accuracy: 0.9894\n",
      "Epoch 341/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0142 - accuracy: 0.9947 - val_loss: 0.0202 - val_accuracy: 0.9909\n",
      "Epoch 342/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0151 - accuracy: 0.9942 - val_loss: 0.0281 - val_accuracy: 0.9826\n",
      "Epoch 343/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0134 - accuracy: 0.9944 - val_loss: 0.0234 - val_accuracy: 0.9909\n",
      "Epoch 344/400\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.0148 - accuracy: 0.9939 - val_loss: 0.0228 - val_accuracy: 0.9909\n",
      "Epoch 345/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0251 - accuracy: 0.9917 - val_loss: 0.0215 - val_accuracy: 0.9909\n",
      "Epoch 346/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.0208 - val_accuracy: 0.9909\n",
      "Epoch 347/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0109 - accuracy: 0.9947 - val_loss: 0.0142 - val_accuracy: 0.9909\n",
      "Epoch 348/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0185 - accuracy: 0.9927 - val_loss: 0.0218 - val_accuracy: 0.9902\n",
      "Epoch 349/400\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.0099 - accuracy: 0.9942 - val_loss: 0.0176 - val_accuracy: 0.9902\n",
      "Epoch 350/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0092 - accuracy: 0.9942 - val_loss: 0.0158 - val_accuracy: 0.9902\n",
      "Epoch 351/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0195 - accuracy: 0.9922 - val_loss: 0.0148 - val_accuracy: 0.9909\n",
      "Epoch 352/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0113 - accuracy: 0.9929 - val_loss: 0.0203 - val_accuracy: 0.9909\n",
      "Epoch 353/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0151 - accuracy: 0.9947 - val_loss: 0.0200 - val_accuracy: 0.9909\n",
      "Epoch 354/400\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.0140 - accuracy: 0.9947 - val_loss: 0.0204 - val_accuracy: 0.9902\n",
      "Epoch 355/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0133 - accuracy: 0.9947 - val_loss: 0.0203 - val_accuracy: 0.9909\n",
      "Epoch 356/400\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 0.0233 - val_accuracy: 0.9909\n",
      "Epoch 357/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.0228 - val_accuracy: 0.9909\n",
      "Epoch 358/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 0.0200 - val_accuracy: 0.9909\n",
      "Epoch 359/400\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.0163 - accuracy: 0.9942 - val_loss: 0.0224 - val_accuracy: 0.9909\n",
      "Epoch 360/400\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.0284 - val_accuracy: 0.9909\n",
      "Epoch 361/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.0257 - val_accuracy: 0.9902\n",
      "Epoch 362/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.0289 - val_accuracy: 0.9909\n",
      "Epoch 363/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 0.0370 - val_accuracy: 0.9894\n",
      "Epoch 364/400\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 0.0313 - val_accuracy: 0.9909\n",
      "Epoch 365/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.0239 - val_accuracy: 0.9909\n",
      "Epoch 366/400\n",
      "40/40 [==============================] - 1s 30ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.0232 - val_accuracy: 0.9909\n",
      "Epoch 367/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0204 - accuracy: 0.9937 - val_loss: 0.0281 - val_accuracy: 0.9909\n",
      "Epoch 368/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.0262 - val_accuracy: 0.9909\n",
      "Epoch 369/400\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.0264 - val_accuracy: 0.9909\n",
      "Epoch 370/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.0230 - val_accuracy: 0.9909\n",
      "Epoch 371/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0226 - accuracy: 0.9934 - val_loss: 0.0285 - val_accuracy: 0.9902\n",
      "Epoch 372/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0269 - val_accuracy: 0.9909\n",
      "Epoch 373/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.0243 - val_accuracy: 0.9909\n",
      "Epoch 374/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.0228 - val_accuracy: 0.9909\n",
      "Epoch 375/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.0262 - val_accuracy: 0.9909\n",
      "Epoch 376/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.0293 - val_accuracy: 0.9909\n",
      "Epoch 377/400\n",
      "40/40 [==============================] - 1s 30ms/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.0267 - val_accuracy: 0.9909\n",
      "Epoch 378/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.0260 - val_accuracy: 0.9909\n",
      "Epoch 379/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.0248 - val_accuracy: 0.9909\n",
      "Epoch 380/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0259 - accuracy: 0.9917 - val_loss: 0.0257 - val_accuracy: 0.9909\n",
      "Epoch 381/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.0229 - val_accuracy: 0.9909\n",
      "Epoch 382/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.0253 - val_accuracy: 0.9909\n",
      "Epoch 383/400\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.0231 - val_accuracy: 0.9909\n",
      "Epoch 384/400\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0242 - val_accuracy: 0.9909\n",
      "Epoch 385/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.0279 - val_accuracy: 0.9909\n",
      "Epoch 386/400\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.0230 - val_accuracy: 0.9909\n",
      "Epoch 387/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.0252 - val_accuracy: 0.9909\n",
      "Epoch 388/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0310 - val_accuracy: 0.9909\n",
      "Epoch 389/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.0250 - val_accuracy: 0.9909\n",
      "Epoch 390/400\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.0245 - val_accuracy: 0.9909\n",
      "Epoch 391/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.0214 - val_accuracy: 0.9909\n",
      "Epoch 392/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0139 - accuracy: 0.9947 - val_loss: 0.0207 - val_accuracy: 0.9909\n",
      "Epoch 393/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0793 - accuracy: 0.9808 - val_loss: 0.0182 - val_accuracy: 0.9909\n",
      "Epoch 394/400\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.0237 - val_accuracy: 0.9902\n",
      "Epoch 395/400\n",
      "40/40 [==============================] - 1s 33ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.0246 - val_accuracy: 0.9894\n",
      "Epoch 396/400\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.0291 - accuracy: 0.9929 - val_loss: 0.0262 - val_accuracy: 0.9902\n",
      "Epoch 397/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.0233 - val_accuracy: 0.9909\n",
      "Epoch 398/400\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0280 - val_accuracy: 0.9909\n",
      "Epoch 399/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.0266 - val_accuracy: 0.9909\n",
      "Epoch 400/400\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 0.0233 - val_accuracy: 0.9909\n",
      "Accuracy: 46.51%\n"
     ]
    }
   ],
   "source": [
    "early_stop=tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1000, verbose=2, mode='auto', baseline=None, restore_best_weights=True)\n",
    "model.fit(X_train_def, y_train_def, epochs=numero_epochs, batch_size=100, callbacks=[tensorboard_callback,early_stop], validation_data=(X_val_def, y_val_def))\n",
    "# Final evaluation of the model \n",
    "scores = model.evaluate(X_test_def, y_test_def, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step\n",
      "(43, 2)\n",
      "(43,)\n",
      "(43,)\n",
      "[1 0 0 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "#y_pred2=np.where(y_pred>0,1,0)\n",
    "#y_pred2=y_pred2[:,-1]\n",
    "y_test_def2=np.argmax(y_test_def,axis=1)\n",
    "#y_test_def2=np.where(y_test_def>0,1,0)\n",
    "print(y_pred.shape)\n",
    "print(y_pred2.shape)\n",
    "print(y_test_def2.shape)\n",
    "#print(y_test_def[25])\n",
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#docs_infra: no_execute\n",
    "if numero_clases==2:\n",
    "    classes = [0, 1]\n",
    "else:   \n",
    "    classes = [0, 1, 2, 3, 4]\n",
    "#classes = [0, 1]\n",
    "cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Buenos     0.4615    0.5714    0.5106        21\n",
      "       Malos     0.4706    0.3636    0.4103        22\n",
      "\n",
      "    accuracy                         0.4651        43\n",
      "   macro avg     0.4661    0.4675    0.4604        43\n",
      "weighted avg     0.4662    0.4651    0.4593        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "if numero_clases==2:\n",
    "    target_names = ['Buenos', 'Malos']\n",
    "else:   \n",
    "    target_names = ['A', 'B+', 'B', 'B-','C']\n",
    "print(classification_report(y_test_def2, y_pred2, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('modelos/modelote1203_200')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('idea.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "model.save('modelos\\modelo_perfecto_{}_{}.h5'.format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "\n",
    "existing_file='RESULTADOS_EXCEL\\clasificacion_71_P1P2_def.xlsx'\n",
    "\n",
    "# Verifica si el archivo existe y si está vacío\n",
    "if not os.path.exists(existing_file) or os.path.getsize(existing_file) == 0:\n",
    "    df_inicial=pd.DataFrame(y_test_def2, columns=[\"target\"])\n",
    "    df_inicial.to_excel(existing_file, index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'RESULTADOS_EXCEL\\\\clasificacion_71_P1P2_def.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m df_combined\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mconcat([df_existing, df_new], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Guarda los DataFrames en archivos Excel\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mdf_combined\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexisting_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\pandas\\core\\generic.py:2345\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   2332\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2334\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2335\u001b[0m     df,\n\u001b[0;32m   2336\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2343\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2344\u001b[0m )\n\u001b[1;32m-> 2345\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2347\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2354\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\pandas\\io\\formats\\excel.py:946\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    942\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;66;03m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001b[39;00m\n\u001b[0;32m    945\u001b[0m     \u001b[38;5;66;03m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[abstract]\u001b[39;49;00m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    952\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:61\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[0;32m     59\u001b[0m engine_kwargs \u001b[38;5;241m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# ExcelWriter replaced \"a\" by \"r+\" to allow us to first read the excel file from\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# the file and later write to it\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode:  \u001b[38;5;66;03m# Load from existing workbook\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1263\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m   1260\u001b[0m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m   1261\u001b[0m )\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m date_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\pandas\\io\\common.py:872\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    873\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'RESULTADOS_EXCEL\\\\clasificacion_71_P1P2_def.xlsx'"
     ]
    }
   ],
   "source": [
    "# Convierte los arrays a DataFrames\n",
    "df_new = pd.DataFrame(y_pred2, columns=[experimento])\n",
    "# Read existing data\n",
    "df_existing = pd.read_excel(existing_file)\n",
    "# Append new data\n",
    "df_combined=pd.concat([df_existing, df_new], axis=1)\n",
    "\n",
    "# Guarda los DataFrames en archivos Excel\n",
    "df_combined.to_excel(existing_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#este modo de guardar no funciona en esta version de tensorflow\n",
    "#model.save('modelos\\modelo_perfecto_{}_{}'.format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "n = len(y_pred2)\n",
    "reshaped = y_pred2[:n//4*4].reshape(-1, 4)\n",
    "mean_values = reshaped.mean(axis=1)\n",
    "\n",
    "mean_values = np.round(mean_values)\n",
    "mean_values = np.clip(mean_values, 0, 4)\n",
    "mean_values = mean_values.astype(int)\n",
    "print(mean_values)\n",
    "\n",
    "mode_values = stats.mode(reshaped, axis=1)[0]\n",
    "print(mode_values)\n",
    "\n",
    "# Convierte los arrays a DataFrames\n",
    "mean_df = pd.DataFrame(mean_values, columns=['mean'])\n",
    "mode_df = pd.DataFrame(mode_values, columns=['mode'])\n",
    "\n",
    "# Guarda los DataFrames en archivos Excel\n",
    "mean_df.to_excel(\"excels_borrar\\clasificacion_P1P2_mean_best7.xlsx\", index=False)\n",
    "mode_df.to_excel(\"excels_borrar\\clasificacion_P1_mode_best7.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename5 = \"COPIA_PANDAS\\lomosP1_20240430_clasificado_experto.hdf\"\n",
    "with pd.HDFStore(filename5,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e2  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e2 = pre_p_e2.loc[pre_p_e2['Pollo'] != 0]\n",
    "    pre_p_e2 =pre_p_e2.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_test2=np.zeros((pre_p_e2.shape[0],220,8))\n",
    "    y_test2=np.zeros((pre_p_e2.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e2.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1:\n",
    "                target = 0 \n",
    "            else:\n",
    "                target = 1\n",
    "\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_test2[x]=pepito[:,3:4]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_test2[x]=target\n",
    "        y_test2_to_categorical = to_categorical(y_test2)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_test2_filtrado = X_test2\n",
    "#y_train_filtrado = y_train\n",
    "y_test2_filtrado = y_test2_to_categorical\n",
    "\n",
    "print(X_test2_filtrado.shape)\n",
    "print(y_test2_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "# concatenamos train y test\n",
    "#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\n",
    "data_2d_test = X_test2_filtrado.reshape(-1, X_test2_filtrado.shape[-1])\n",
    "normalized_data_2d_test = scaler.transform(data_2d_test)\n",
    "\n",
    "\n",
    "X_test2_def=normalized_data_2d_test.reshape(X_test2_filtrado.shape) \n",
    "# la alternativa es normalizar con el total\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "\n",
    "y_test2_def=y_test2_filtrado # los valores ya estaban normalizados\n",
    "\n",
    "print(y_test2_def.shape)\n",
    "\n",
    "print(y_test2_filtrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# # Crear un nuevo modelo con la misma arquitectura\n",
    "# best_val_model = create_model()  # Reemplaza esto con la función que usaste para crear el modelo original\n",
    "\n",
    "# # Cargar los mejores pesos\n",
    "# best_val_model.load_weights('best_weights.h5')\n",
    "\n",
    "y_pred = model.predict(X_test2_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "n = len(y_pred2)\n",
    "print(n)\n",
    "reshaped = y_pred2[:n//4*4].reshape(-1, 4)\n",
    "mean_values = reshaped.mean(axis=1)\n",
    "\n",
    "mean_values = np.round(mean_values)\n",
    "mean_values = np.clip(mean_values, 0, 4)\n",
    "mean_values = mean_values.astype(int)\n",
    "print(mean_values.shape)\n",
    "\n",
    "mode_values = stats.mode(reshaped, axis=1)[0]\n",
    "print(mode_values.shape)\n",
    "\n",
    "n = len(y_test2_def)\n",
    "y_test2_def2=np.argmax(y_test2_def,axis=1)\n",
    "print(y_test_def2.shape)\n",
    "print(n)\n",
    "reshaped2 = y_test2_def2[:n//4*4].reshape(-1, 4)\n",
    "target_mean_values = reshaped2.mean(axis=1)\n",
    "\n",
    "target_mean_values = np.round(target_mean_values)\n",
    "target_mean_values = np.clip(target_mean_values, 0, 4)\n",
    "target_mean_values = target_mean_values.astype(int)\n",
    "print(target_mean_values.shape)\n",
    "\n",
    "target_mode_values = stats.mode(reshaped2, axis=1)[0]\n",
    "print(target_mode_values.shape)\n",
    "print(reshaped)\n",
    "print(mode_values)\n",
    "print(target_mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs_infra: no_execute\n",
    "if numero_clases==2:\n",
    "    classes = [0, 1]    \n",
    "else:\n",
    "\n",
    "    classes = [0, 1, 2, 3, 4]\n",
    "#classes = [0, 1]\n",
    "cm=confusion_matrix(target_mode_values, mode_values,labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm.diagonal()/cm.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if numero_clases==2:\n",
    "    target_names= ['Buenos', 'Malos']\n",
    "else:\n",
    "    target_names= ['A', 'B+', 'B', 'B-','C']\n",
    "print(classification_report(target_mode_values, mode_values, target_names=target_names, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
