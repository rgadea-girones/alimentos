{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:\\nuevas_investigaciones_alimentos_2024\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM,Bidirectional,GRU\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import datetime\n",
    "import io\n",
    "import itertools\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Obtener la ruta del directorio actual\n",
    "os.chdir('..')\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "# Construir la ruta relativa al directorio que quieres agregar\n",
    "relative_dir = os.path.join(current_dir, 'mis_pkgs/')\n",
    "\n",
    "# Agregar la ruta relativa al sys.path\n",
    "sys.path.insert(0, relative_dir)\n",
    "\n",
    "from MIOPATIA_db import DB_management as db \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_muestras=401\n",
    "numero_clases=2\n",
    "entrada=slice(5,7)\n",
    "numero_entradas = entrada.stop - entrada.start\n",
    "numero_epochs=2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a quedarme con los 50 atunes P1 para obtener conjunto de training y validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Add, Activation, Concatenate, Conv2D, Dropout \n",
    "from tensorflow.keras.layers import Flatten, Input, GlobalAveragePooling2D, MaxPooling2D\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "__version__ = '0.0.1'\n",
    "\n",
    "\n",
    "def SqueezeNet(input_shape, nb_classes, use_bypass=False, dropout_rate=None, compression=1.0):\n",
    "    \"\"\"\n",
    "    Creating a SqueezeNet of version 1.0\n",
    "    \n",
    "    Arguments:\n",
    "        input_shape  : shape of the input images e.g. (224,224,3)\n",
    "        nb_classes   : number of classes\n",
    "        use_bypass   : if true, bypass connections will be created at fire module 3, 5, 7, and 9 (default: False)\n",
    "        dropout_rate : defines the dropout rate that is accomplished after last fire module (default: None)\n",
    "        compression  : reduce the number of feature-maps (default: 1.0)\n",
    "        \n",
    "    Returns:\n",
    "        Model        : Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(int(96*compression), (7,7), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "    x = create_fire_module(x, int(16*compression), name='fire3', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool4')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(32*compression), name='fire5', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "    x = create_fire_module(x, int(48*compression), name='fire7', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool8')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(64*compression), name='fire9', use_bypass=use_bypass)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        \n",
    "    x = output(x, nb_classes)\n",
    "\n",
    "    return Model(inputs=input_img, outputs=x)\n",
    "\n",
    "\n",
    "def SqueezeNet_11(input_shape, nb_classes, dropout_rate=None, compression=1.0):\n",
    "    \"\"\"\n",
    "    Creating a SqueezeNet of version 1.1\n",
    "    \n",
    "    2.4x less computation over SqueezeNet 1.0 implemented above.\n",
    "    \n",
    "    Arguments:\n",
    "        input_shape  : shape of the input images e.g. (224,224,3)\n",
    "        nb_classes   : number of classes\n",
    "        dropout_rate : defines the dropout rate that is accomplished after last fire module (default: None)\n",
    "        compression  : reduce the number of feature-maps\n",
    "        \n",
    "    Returns:\n",
    "        Model        : Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(int(64*compression), (3,3), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "    x = create_fire_module(x, int(16*compression), name='fire3')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool3')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "    x = create_fire_module(x, int(32*compression), name='fire5')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool5')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "    x = create_fire_module(x, int(48*compression), name='fire7')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire9')\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # Creating last conv10\n",
    "    x = output(x, nb_classes)\n",
    "\n",
    "    return Model(inputs=input_img, outputs=x)\n",
    "\n",
    "\n",
    "def output(x, nb_classes):\n",
    "    x = Conv2D(nb_classes, (1,1), strides=(1,1), padding='valid', name='conv10')(x)\n",
    "    x = GlobalAveragePooling2D(name='avgpool10')(x)\n",
    "    x = Activation(\"softmax\", name='softmax')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_fire_module(x, nb_squeeze_filter, name, use_bypass=False):\n",
    "    \"\"\"\n",
    "    Creates a fire module\n",
    "    \n",
    "    Arguments:\n",
    "        x                 : input\n",
    "        nb_squeeze_filter : number of filters of squeeze. The filtersize of expand is 4 times of squeeze\n",
    "        use_bypass        : if True then a bypass will be added\n",
    "        name              : name of module e.g. fire123\n",
    "    \n",
    "    Returns:\n",
    "        x                 : returns a fire module\n",
    "    \"\"\"\n",
    "    \n",
    "    nb_expand_filter = 4 * nb_squeeze_filter\n",
    "    squeeze    = Conv2D(nb_squeeze_filter,(1,1), activation='relu', padding='same', name='%s_squeeze'%name)(x)\n",
    "    expand_1x1 = Conv2D(nb_expand_filter, (1,1), activation='relu', padding='same', name='%s_expand_1x1'%name)(squeeze)\n",
    "    expand_3x3 = Conv2D(nb_expand_filter, (3,3), activation='relu', padding='same', name='%s_expand_3x3'%name)(squeeze)\n",
    "    \n",
    "    axis = get_axis()\n",
    "    x_ret = Concatenate(axis=axis, name='%s_concatenate'%name)([expand_1x1, expand_3x3])\n",
    "    \n",
    "    if use_bypass:\n",
    "        x_ret = Add(name='%s_concatenate_bypass'%name)([x_ret, x])\n",
    "        \n",
    "    return x_ret\n",
    "\n",
    "\n",
    "def get_axis():\n",
    "    axis = -1 if K.image_data_format() == 'channels_last' else 1\n",
    "    return axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1749, 2)\n"
     ]
    }
   ],
   "source": [
    "filename = \"COPIA_PANDAS\\hdf_lomosAgilent_trainval_filtrado_def_good_ampliado_the_best7.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    # p_e =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_train=np.zeros((pre_p_e1.shape[0],numero_muestras,numero_entradas))\n",
    "    y_train=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1:\n",
    "                target = 0\n",
    "            else:\n",
    "                target = 1\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_train[x]=pepito[:,entrada]\n",
    "        #X_train[x]=X_train[x].reshape(X_train[x].shape[0],-1)\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_train[x]=target\n",
    "        y_train_to_categorical = to_categorical(y_train)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_train_filtrado = X_train\n",
    "#y_train_filtrado = y_train\n",
    "y_train_filtrado = y_train_to_categorical\n",
    "\n",
    "# print(X_train_filtrado.shape)\n",
    "# print(y_train_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "scaler = StandardScaler()\n",
    "data_2d = X_train_filtrado.reshape(-1, X_train_filtrado.shape[-1])\n",
    "normalized_data_2d = scaler.fit_transform(data_2d)\n",
    "#para recurrentes\n",
    "#X_train_Normalizado=normalized_data_2d.reshape(X_train_filtrado.shape) #para recurrentes\n",
    "#para densas\n",
    "X_train_Normalizado=normalized_data_2d.reshape(X_train_filtrado.shape[0],-1)\n",
    "y_train_Normalizado=y_train_filtrado # los valores ya estaban normalizados\n",
    "print(y_train_Normalizado.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 401, 2)\n",
      "(39, 2)\n",
      "[ 1.03436926e+00  1.91861454e+00  9.94594036e-01  1.90546265e+00\n",
      "  9.58967366e-01  1.89065386e+00  9.16890050e-01  1.86993752e+00\n",
      "  8.67591138e-01  1.84633546e+00  8.59714270e-01  1.82604768e+00\n",
      "  7.83126951e-01  1.79991355e+00  7.70077225e-01  1.77280557e+00\n",
      "  7.35715548e-01  1.74676649e+00  7.07188378e-01  1.71712412e+00\n",
      "  6.81108018e-01  1.68366517e+00  6.50836269e-01  1.65132585e+00\n",
      "  6.01971434e-01  1.61786022e+00  5.87894473e-01  1.58249179e+00\n",
      "  5.73803434e-01  1.55245165e+00  5.59751672e-01  1.51821165e+00\n",
      "  5.29378673e-01  1.48538895e+00  5.08386650e-01  1.45463465e+00\n",
      "  4.86638083e-01  1.42417954e+00  4.58748903e-01  1.39270211e+00\n",
      "  4.35801673e-01  1.36148791e+00  4.11791956e-01  1.32948122e+00\n",
      "  3.95793590e-01  1.29727080e+00  3.78913027e-01  1.26388488e+00\n",
      "  3.60935475e-01  1.23279909e+00  3.41446934e-01  1.20332514e+00\n",
      "  3.23203450e-01  1.17212840e+00  3.07133320e-01  1.14177528e+00\n",
      "  2.90213163e-01  1.11122812e+00  2.72764107e-01  1.08004454e+00\n",
      "  2.56611197e-01  1.05005158e+00  2.40155273e-01  1.02123650e+00\n",
      "  2.25687642e-01  9.92377796e-01  2.11526169e-01  9.64353004e-01\n",
      "  1.96817962e-01  9.36477257e-01  1.82984296e-01  9.09283584e-01\n",
      "  1.69611409e-01  8.82831951e-01  1.59506101e-01  8.54397411e-01\n",
      "  1.49944376e-01  8.27849660e-01  1.37689798e-01  8.03092262e-01\n",
      "  1.29329132e-01  7.76607754e-01  1.17931542e-01  7.53892826e-01\n",
      "  1.07981365e-01  7.29861067e-01  9.77891640e-02  7.06835287e-01\n",
      "  8.85252959e-02  6.83964937e-01  7.90894422e-02  6.61283656e-01\n",
      "  7.11141058e-02  6.38952804e-01  6.29246182e-02  6.17465961e-01\n",
      "  5.17861578e-02  5.99191700e-01  4.31217059e-02  5.79745538e-01\n",
      "  3.51258899e-02  5.60168221e-01  2.69751259e-02  5.41480694e-01\n",
      "  1.94849035e-02  5.22514543e-01  1.26096500e-02  5.04229708e-01\n",
      "  5.05194663e-03  4.86011059e-01 -3.60886927e-04  4.66945752e-01\n",
      " -4.23307579e-03  4.47929066e-01 -1.14442196e-02  4.31452324e-01\n",
      " -1.57873012e-02  4.13777092e-01 -2.28229457e-02  4.00243841e-01\n",
      " -2.94059022e-02  3.85868299e-01 -3.53314018e-02  3.72060581e-01\n",
      " -4.02954196e-02  3.57709423e-01 -4.57291190e-02  3.44211653e-01\n",
      " -5.03649911e-02  3.30486705e-01 -5.56635324e-02  3.17218345e-01\n",
      " -6.00187930e-02  3.03468615e-01 -6.32062518e-02  2.90371484e-01\n",
      " -6.75236152e-02  2.78168075e-01 -7.08912037e-02  2.65059567e-01\n",
      " -7.42440602e-02  2.52807288e-01 -7.75614409e-02  2.40953089e-01\n",
      " -8.09369378e-02  2.28709612e-01 -8.26837331e-02  2.16395641e-01\n",
      " -8.61176628e-02  2.05502060e-01 -8.81228732e-02  1.94512641e-01\n",
      " -9.10485760e-02  1.83928617e-01 -9.39792687e-02  1.73752697e-01\n",
      " -9.60298076e-02  1.63234900e-01 -9.84360770e-02  1.53119176e-01\n",
      " -1.00093141e-01  1.43127102e-01 -1.02521057e-01  1.33678822e-01\n",
      " -1.05705917e-01  1.24468672e-01 -1.06758428e-01  1.15592096e-01\n",
      " -1.08551097e-01  1.06648924e-01 -1.10953977e-01  9.83474955e-02\n",
      " -1.12617714e-01  8.97696702e-02 -1.14369601e-01  8.14363260e-02\n",
      " -1.15862494e-01  7.36198248e-02 -1.17521815e-01  6.61980729e-02\n",
      " -1.19360019e-01  5.84954907e-02 -1.20376970e-01  5.13250310e-02\n",
      " -1.21892129e-01  4.39900647e-02 -1.23081337e-01  3.71732078e-02\n",
      " -1.24262904e-01  2.98488179e-02 -1.25372505e-01  2.33681056e-02\n",
      " -1.26817135e-01  1.67287669e-02 -1.27750563e-01  1.01161468e-02\n",
      " -1.28673206e-01  3.67799983e-03 -1.29487728e-01 -2.29576886e-03\n",
      " -1.30741021e-01 -8.13418787e-03 -1.31574857e-01 -1.39394594e-02\n",
      " -1.32504314e-01 -1.97893804e-02 -1.33625961e-01 -2.51951836e-02\n",
      " -1.34422424e-01 -3.03635454e-02 -1.35087105e-01 -3.56374722e-02\n",
      " -1.35886563e-01 -4.07567810e-02 -1.36717678e-01 -4.57644559e-02\n",
      " -1.37308225e-01 -5.05405540e-02 -1.38328037e-01 -5.52045764e-02\n",
      " -1.38898846e-01 -5.99268070e-02 -1.39686438e-01 -6.45565416e-02\n",
      " -1.40425745e-01 -6.87847917e-02 -1.41041301e-01 -7.28371716e-02\n",
      " -1.41626267e-01 -7.73710433e-02 -1.42160271e-01 -8.15380728e-02\n",
      " -1.42741707e-01 -8.52169389e-02 -1.43434624e-01 -8.88593766e-02\n",
      " -1.43862442e-01 -9.24144639e-02 -1.44401484e-01 -9.61758033e-02\n",
      " -1.44989274e-01 -9.98777185e-02 -1.45359026e-01 -1.03270453e-01\n",
      " -1.45866665e-01 -1.06743359e-01 -1.46251607e-01 -1.09990903e-01\n",
      " -1.46649391e-01 -1.13174118e-01 -1.47066873e-01 -1.16316557e-01\n",
      " -1.47518354e-01 -1.19449544e-01 -1.47753270e-01 -1.22589370e-01\n",
      " -1.48223320e-01 -1.25408621e-01 -1.48631529e-01 -1.28334950e-01\n",
      " -1.48847138e-01 -1.31202184e-01 -1.49165986e-01 -1.33812954e-01\n",
      " -1.49575829e-01 -1.36464472e-01 -1.49990458e-01 -1.38994253e-01\n",
      " -1.50231129e-01 -1.41422476e-01 -1.50424965e-01 -1.43942728e-01\n",
      " -1.50703845e-01 -1.46393144e-01 -1.50995455e-01 -1.48804940e-01\n",
      " -1.51213987e-01 -1.51083988e-01 -1.51489451e-01 -1.53237443e-01\n",
      " -1.51756404e-01 -1.55286986e-01 -1.52054709e-01 -1.57306805e-01\n",
      " -1.52351796e-01 -1.59260314e-01 -1.52597807e-01 -1.61203980e-01\n",
      " -1.52759635e-01 -1.63162949e-01 -1.52988072e-01 -1.64992280e-01\n",
      " -1.53180811e-01 -1.66785270e-01 -1.53393778e-01 -1.68574649e-01\n",
      " -1.53434567e-01 -1.70248327e-01 -1.53692055e-01 -1.71924513e-01\n",
      " -1.53871160e-01 -1.73630661e-01 -1.54055980e-01 -1.75201474e-01\n",
      " -1.54166823e-01 -1.76792231e-01 -1.54275938e-01 -1.78326392e-01\n",
      " -1.54482189e-01 -1.79748221e-01 -1.54658188e-01 -1.81202159e-01\n",
      " -1.54767027e-01 -1.82729984e-01 -1.54890453e-01 -1.84031478e-01\n",
      " -1.55130575e-01 -1.85295762e-01 -1.55174089e-01 -1.86585520e-01\n",
      " -1.55300063e-01 -1.87778934e-01 -1.55360210e-01 -1.89007635e-01\n",
      " -1.55565835e-01 -1.90207337e-01 -1.55659247e-01 -1.91366387e-01\n",
      " -1.55826772e-01 -1.92514107e-01 -1.55922343e-01 -1.93616965e-01\n",
      " -1.56007142e-01 -1.94691229e-01 -1.56093993e-01 -1.95708344e-01\n",
      " -1.56253002e-01 -1.96726257e-01 -1.56422810e-01 -1.97744482e-01\n",
      " -1.56450669e-01 -1.98693751e-01 -1.56583660e-01 -1.99608127e-01\n",
      " -1.56741540e-01 -2.00542027e-01 -1.56792047e-01 -2.01406329e-01\n",
      " -1.56859121e-01 -2.02241176e-01 -1.57001827e-01 -2.03074819e-01\n",
      " -1.57113219e-01 -2.03899082e-01 -1.57250969e-01 -2.04689438e-01\n",
      " -1.57321772e-01 -2.05454855e-01 -1.57444296e-01 -2.06217437e-01\n",
      " -1.57602056e-01 -2.06957948e-01 -1.57718967e-01 -2.07666543e-01\n",
      " -1.57892713e-01 -2.08354026e-01 -1.57991900e-01 -2.09027602e-01\n",
      " -1.58089011e-01 -2.09672255e-01 -1.58234243e-01 -2.10305232e-01\n",
      " -1.58382206e-01 -2.10937169e-01 -1.58529597e-01 -2.11534492e-01\n",
      " -1.58646026e-01 -2.12108389e-01 -1.58774319e-01 -2.12659636e-01\n",
      " -1.58927816e-01 -2.13209934e-01 -1.59083114e-01 -2.13737239e-01\n",
      " -1.59201203e-01 -2.14247081e-01 -1.59353255e-01 -2.14744647e-01\n",
      " -1.59507915e-01 -2.15228521e-01 -1.59679028e-01 -2.15693790e-01\n",
      " -1.59846398e-01 -2.16151317e-01 -1.60037485e-01 -2.16601653e-01\n",
      " -1.60222997e-01 -2.17040427e-01 -1.60426748e-01 -2.17466455e-01\n",
      " -1.60601464e-01 -2.17875037e-01 -1.60823559e-01 -2.18270392e-01\n",
      " -1.61007126e-01 -2.18652432e-01 -1.61262859e-01 -2.19046216e-01\n",
      " -1.61515186e-01 -2.19424780e-01 -1.61728561e-01 -2.19788440e-01\n",
      " -1.62007118e-01 -2.20155227e-01 -1.62267075e-01 -2.20509952e-01\n",
      " -1.62504973e-01 -2.20839576e-01 -1.62749616e-01 -2.21172742e-01\n",
      " -1.63036271e-01 -2.21497410e-01 -1.63328584e-01 -2.21818878e-01\n",
      " -1.63616919e-01 -2.22123976e-01 -1.63930359e-01 -2.22427273e-01\n",
      " -1.64252359e-01 -2.22728360e-01 -1.64535998e-01 -2.23009635e-01\n",
      " -1.64880363e-01 -2.23292236e-01 -1.65215872e-01 -2.23573006e-01\n",
      " -1.65540402e-01 -2.23836706e-01 -1.65889771e-01 -2.24098529e-01\n",
      " -1.66264252e-01 -2.24369133e-01 -1.66654545e-01 -2.24637799e-01\n",
      " -1.67026062e-01 -2.24899689e-01 -1.67431239e-01 -2.25153265e-01\n",
      " -1.67802384e-01 -2.25407759e-01 -1.68195927e-01 -2.25647546e-01\n",
      " -1.68589707e-01 -2.25880908e-01 -1.69002279e-01 -2.26122304e-01\n",
      " -1.69405293e-01 -2.26358305e-01 -1.69835077e-01 -2.26591098e-01\n",
      " -1.70260470e-01 -2.26819719e-01 -1.70687859e-01 -2.27052585e-01\n",
      " -1.71124006e-01 -2.27275001e-01 -1.71540869e-01 -2.27499736e-01\n",
      " -1.71965612e-01 -2.27717372e-01 -1.72413832e-01 -2.27936171e-01\n",
      " -1.72857664e-01 -2.28151358e-01 -1.73281515e-01 -2.28361488e-01\n",
      " -1.73722215e-01 -2.28573619e-01 -1.74145976e-01 -2.28776681e-01\n",
      " -1.74590553e-01 -2.28981785e-01 -1.75015585e-01 -2.29189254e-01\n",
      " -1.75477070e-01 -2.29403492e-01 -1.75925276e-01 -2.29617374e-01\n",
      " -1.76355949e-01 -2.29820993e-01 -1.76795437e-01 -2.30024228e-01\n",
      " -1.77235054e-01 -2.30226704e-01 -1.77635125e-01 -2.30421100e-01\n",
      " -1.78046332e-01 -2.30608984e-01 -1.78458191e-01 -2.30800493e-01\n",
      " -1.78887138e-01 -2.30996383e-01 -1.79244225e-01 -2.31180356e-01\n",
      " -1.79654677e-01 -2.31365457e-01 -1.80038160e-01 -2.31547737e-01\n",
      " -1.80398582e-01 -2.31725574e-01 -1.80778186e-01 -2.31904861e-01\n",
      " -1.81150517e-01 -2.32088317e-01 -1.81505670e-01 -2.32266078e-01\n",
      " -1.81856516e-01 -2.32445670e-01 -1.82209840e-01 -2.32625588e-01\n",
      " -1.82539447e-01 -2.32794259e-01 -1.82865757e-01 -2.32956381e-01\n",
      " -1.83180379e-01 -2.33121727e-01 -1.83498033e-01 -2.33288993e-01\n",
      " -1.83793884e-01 -2.33450980e-01 -1.84107104e-01 -2.33616557e-01\n",
      " -1.84382956e-01 -2.33776342e-01 -1.84687812e-01 -2.33934601e-01\n",
      " -1.84952266e-01 -2.34090079e-01 -1.85207380e-01 -2.34240956e-01\n",
      " -1.85461621e-01 -2.34388300e-01 -1.85713656e-01 -2.34537016e-01\n",
      " -1.85955428e-01 -2.34683356e-01 -1.86184132e-01 -2.34825558e-01\n",
      " -1.86401236e-01 -2.34966363e-01 -1.86619372e-01 -2.35103362e-01\n",
      " -1.86830310e-01 -2.35238597e-01 -1.87025235e-01 -2.35374109e-01\n",
      " -1.87226416e-01 -2.35504798e-01 -1.87415878e-01 -2.35635459e-01\n",
      " -1.87604587e-01 -2.35762628e-01 -1.87781333e-01 -2.35893639e-01\n",
      " -1.87952867e-01 -2.36020677e-01 -1.88117979e-01 -2.36145391e-01\n",
      " -1.88266069e-01 -2.36261949e-01 -1.88421137e-01 -2.36371048e-01\n",
      " -1.88562009e-01 -2.36484234e-01 -1.88688140e-01 -2.36594229e-01\n",
      " -1.88827120e-01 -2.36705030e-01 -1.88942500e-01 -2.36809505e-01\n",
      " -1.89060730e-01 -2.36914535e-01 -1.89174007e-01 -2.37012247e-01\n",
      " -1.89271909e-01 -2.37113533e-01 -1.89377804e-01 -2.37209973e-01\n",
      " -1.89477022e-01 -2.37304466e-01 -1.89560325e-01 -2.37396167e-01\n",
      " -1.89654295e-01 -2.37488433e-01 -1.89740396e-01 -2.37579094e-01\n",
      " -1.89822493e-01 -2.37668816e-01 -1.89901554e-01 -2.37756650e-01\n",
      " -1.89978609e-01 -2.37842007e-01 -1.90054675e-01 -2.37924660e-01\n",
      " -1.90121114e-01 -2.38005729e-01 -1.90181827e-01 -2.38083100e-01\n",
      " -1.90241347e-01 -2.38159581e-01 -1.90294212e-01 -2.38236437e-01\n",
      " -1.90345631e-01 -2.38307168e-01 -1.90390848e-01 -2.38377991e-01\n",
      " -1.90441002e-01 -2.38444937e-01 -1.90482446e-01 -2.38511151e-01\n",
      " -1.90523013e-01 -2.38578855e-01 -1.90566928e-01 -2.38643178e-01\n",
      " -1.90599210e-01 -2.38705455e-01 -1.90628374e-01 -2.38764978e-01\n",
      " -1.90668187e-01 -2.38825107e-01 -1.90696833e-01 -2.38881525e-01\n",
      " -1.90724722e-01 -2.38937186e-01 -1.90745622e-01 -2.38992421e-01\n",
      " -1.90788045e-01 -2.39045818e-01 -1.90807317e-01 -2.39098398e-01\n",
      " -1.90824509e-01 -2.39146464e-01 -1.90837003e-01 -2.39193678e-01\n",
      " -1.90859533e-01 -2.39242235e-01 -1.90879127e-01 -2.39287900e-01\n",
      " -1.90894803e-01 -2.39332195e-01 -1.90908697e-01 -2.39374892e-01\n",
      " -1.90921920e-01 -2.39416897e-01 -1.90933999e-01 -2.39459639e-01\n",
      " -1.90953281e-01 -2.39501412e-01 -1.90962891e-01 -2.39538777e-01\n",
      " -1.90970276e-01 -2.39575034e-01 -1.90979423e-01 -2.39612543e-01\n",
      " -1.90986655e-01 -2.39647276e-01 -1.90995018e-01 -2.39682078e-01\n",
      " -1.91004865e-01 -2.39715615e-01 -1.91009670e-01 -2.39747548e-01\n",
      " -1.91014436e-01 -2.39778022e-01 -1.91014888e-01 -2.39806819e-01\n",
      " -1.91022827e-01 -2.39835995e-01 -1.91024110e-01 -2.39864403e-01\n",
      " -1.91022398e-01 -2.39890452e-01 -1.91025472e-01 -2.39916878e-01\n",
      " -1.91029310e-01 -2.39942603e-01 -1.91028359e-01 -2.39966930e-01\n",
      " -1.91033631e-01 -2.39990986e-01 -1.91030070e-01 -2.40013664e-01\n",
      " -1.91032950e-01 -2.40036052e-01 -1.91033279e-01 -2.40058025e-01\n",
      " -1.91031776e-01 -2.40078535e-01 -1.91034176e-01 -2.40098775e-01\n",
      " -1.91034673e-01 -2.40119216e-01 -1.91030422e-01 -2.40137495e-01\n",
      " -1.91026267e-01 -2.40155171e-01 -1.91019340e-01 -2.40172001e-01\n",
      " -1.91012796e-01 -2.40187052e-01 -1.91004736e-01 -2.40201669e-01\n",
      " -1.91005261e-01 -2.40217422e-01 -1.91005952e-01 -2.40232953e-01\n",
      " -1.91003343e-01 -2.40248281e-01 -1.91001334e-01 -2.40263254e-01\n",
      " -1.90995476e-01 -2.40276494e-01 -1.90997862e-01 -2.40290514e-01\n",
      " -1.90992999e-01 -2.40303112e-01 -1.90988599e-01 -2.40315516e-01\n",
      " -1.90986514e-01 -2.40327803e-01 -1.90985497e-01 -2.40339909e-01\n",
      " -1.90980410e-01 -2.40351360e-01 -1.90978087e-01 -2.40362386e-01\n",
      " -1.90970558e-01 -2.40373611e-01 -1.90972662e-01 -2.40384395e-01\n",
      " -1.90969166e-01 -2.40393768e-01 -1.90963312e-01 -2.40403596e-01\n",
      " -1.90963173e-01 -2.40413540e-01 -1.90957350e-01 -2.40422460e-01\n",
      " -1.90950342e-01 -2.40430476e-01 -1.90944276e-01 -2.40438417e-01\n",
      " -1.90934287e-01 -2.40446829e-01 -1.90936269e-01 -2.40454844e-01\n",
      " -1.90943218e-01 -2.40464481e-01 -1.90930649e-01 -2.40471885e-01\n",
      " -1.90927347e-01 -2.40478752e-01 -1.90927678e-01 -2.40485782e-01\n",
      " -1.90914910e-01 -2.40492174e-01 -1.90914809e-01 -2.40498817e-01\n",
      " -1.90871265e-01 -2.40504784e-01 -1.90904194e-01 -2.40511223e-01\n",
      " -1.90906191e-01 -2.40519607e-01 -1.90893512e-01 -2.40522737e-01\n",
      " -1.90891452e-01 -2.40528796e-01 -1.90889149e-01 -2.40534965e-01\n",
      " -1.90883343e-01 -2.40540333e-01 -1.90876764e-01 -2.40544975e-01\n",
      " -1.90874961e-01 -2.40550542e-01 -1.90869462e-01 -2.40555250e-01\n",
      " -1.90861966e-01 -2.40559425e-01 -1.90860170e-01 -2.40564196e-01\n",
      " -1.90857031e-01 -2.40569047e-01 -1.90849359e-01 -2.40573250e-01\n",
      " -1.90843379e-01 -2.40577214e-01 -1.90837186e-01 -2.40581255e-01\n",
      " -1.90924105e-01 -2.40601543e-01]\n"
     ]
    }
   ],
   "source": [
    "filename = \"COPIA_PANDAS\\hdf_lomosAgilent_test_filtrado_def_good.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    pre_p_e1 =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_test=np.zeros((pre_p_e1.shape[0],numero_muestras,numero_entradas))\n",
    "    y_test=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1:\n",
    "                target = 0\n",
    "            else:\n",
    "                target = 1\n",
    "\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_test[x]=pepito[:,entrada]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_test[x]=target\n",
    "        y_test_to_categorical = to_categorical(y_test)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_test_filtrado = X_test\n",
    "#y_train_filtrado = y_train\n",
    "y_test_filtrado = y_test_to_categorical\n",
    "\n",
    "print(X_test_filtrado.shape)\n",
    "print(y_test_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "# concatenamos train y test\n",
    "#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\n",
    "data_2d_test = X_test_filtrado.reshape(-1, X_test_filtrado.shape[-1])\n",
    "normalized_data_2d_test = scaler.transform(data_2d_test)\n",
    "\n",
    "\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape[0],-1) \n",
    "# la alternativa es normalizar con el total\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "\n",
    "y_test_def=y_test_filtrado # los valores ya estaban normalizados\n",
    "print(X_test_def[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer los conjuntos de entrenamiento validacion y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide el dataset en entrenamiento y temporal (test+validación)\n",
    "# X_temp, X_test_def, y_temp, y_test_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.2, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Divide el dataset temporal en validación y test\n",
    "X_train_def, X_val_def, y_train_def, y_val_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.25, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Ahora, X_train, X_val y X_test contienen los datos de entrada para los conjuntos de entrenamiento, validación y prueba, respectivamente.\n",
    "# y_train, y_val y y_test contienen las clases correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1311, 802)\n",
      "(438, 802)\n",
      "(39, 802)\n",
      "(1311, 2)\n",
      "(438, 2)\n",
      "(39, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_def.shape)\n",
    "print(X_val_def.shape)\n",
    "print(X_test_def.shape)\n",
    "print(y_train_def.shape)\n",
    "print(y_val_def.shape)\n",
    "print(y_test_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "#%tensorboard --logdir logs\n",
    "#log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"\n",
    "    Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\n",
    "    \"\"\"\n",
    "    \n",
    "    buf = io.BytesIO()\n",
    "    \n",
    "    # Use plt.savefig to save the plot to a PNG in memory.\n",
    "    plt.savefig(buf, format='png')\n",
    "    \n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    \n",
    "    # Use tf.image.decode_png to convert the PNG buffer\n",
    "    # to a TF image. Make sure you use 4 channels.\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    \n",
    "    # Use tf.expand_dims to add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "       class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    \n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    # Normalize the confusion matrix.\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    \n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    threshold = 0.5\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"red\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_aprendizaje=0.001\n",
    "dimension_LSTM=50\n",
    "dimension_dense1=50\n",
    "dimension_dense2=20\n",
    "algoritmo='rmsprop'\n",
    "supermax=8*4\n",
    "lossfunction='categorical_crossentropy'\n",
    "def create_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    # model.add(Bidirectional(GRU(dimension_LSTM, return_sequences=True, recurrent_regularizer='L2'),input_shape=(401, 8)))\n",
    "    # # model.add(GRU(50, return_sequences=True))\n",
    "    # model.add(GRU(50, return_sequences=False))\n",
    "    model.add(Dense(dimension_dense1, activation='tanh', activity_regularizer='L2'))\n",
    "    model.add(Dense(dimension_dense2, activation='tanh'))\n",
    "    model.add(Dense(numero_clases, activation='softmax'))\n",
    "    model.compile(loss=lossfunction, optimizer=algoritmo, metrics=['accuracy'])\n",
    "    model.optimizer.lr=(factor_aprendizaje)\n",
    "    return model\n",
    "\n",
    "model=create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar una lista de los números en el rango del slice\n",
    "numbers = list(range(entrada.start, entrada.stop))\n",
    "\n",
    "# Convertir la lista a un string con los números separados por guiones\n",
    "slice_str = \"-\".join(map(str, numbers))\n",
    "\n",
    "\n",
    "experimento=\"LOMOS_Agilent_entradas_{}_dense1Rl2_{}_dense2_{}_clases_{}_loss_{}_lr_{}_algoritmo_{}\".format(slice_str,dimension_dense1,dimension_dense2,numero_clases,lossfunction,factor_aprendizaje,algoritmo)\n",
    "logdir=\"./logs/defs/{}_{}\".format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if numero_clases==2:\n",
    "    class_names=['Buenos', 'Malos']\n",
    "else:\n",
    "    class_names=['A', 'B+', 'B', 'B-','C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    \n",
    "    # Use the model to predict the values from the test_images.\n",
    "    y_pred = model.predict(X_test_def)\n",
    "    #y_pred1=y_pred[:,-1]\n",
    "    y_pred2=y_pred.argmax(axis=1)\n",
    "    #y_pred2=np.where(y_pred>0,1,0)\n",
    "    #y_pred2=y_pred2[:,-1]\n",
    "    if numero_clases==2:\n",
    "        classes = [0, 1]    \n",
    "    else:\n",
    "\n",
    "        classes = [0, 1, 2, 3, 4] \n",
    "    #classes = [0, 1]\n",
    "    y_test_def2=np.argmax(y_test_def,axis=1)  \n",
    "    #y_test_def2=np.where(y_test_def>0,1,0)\n",
    "    cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    figura = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figura)\n",
    "    \n",
    "    # Log the confusion matrix as an image summary.\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1749, 2)\n",
      "(438, 2)\n"
     ]
    }
   ],
   "source": [
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "print(y_train_Normalizado.shape)\n",
    "print(y_val_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un callback para guardar los mejores pesos\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('best_weights.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step loss: 0.8136 - accuracy: 0.55\n",
      "14/14 [==============================] - 3s 95ms/step - loss: 0.8121 - accuracy: 0.5584 - val_loss: 0.8810 - val_accuracy: 0.5091\n",
      "Epoch 2/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.7702 - accuracy: 0.56\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.7778 - accuracy: 0.5584 - val_loss: 0.7438 - val_accuracy: 0.6050\n",
      "Epoch 3/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.7273 - accuracy: 0.59\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.7263 - accuracy: 0.6003 - val_loss: 0.9089 - val_accuracy: 0.5160\n",
      "Epoch 4/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.7286 - accuracy: 0.60\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.7286 - accuracy: 0.6026 - val_loss: 0.9473 - val_accuracy: 0.4977\n",
      "Epoch 5/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.7239 - accuracy: 0.60\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.7239 - accuracy: 0.6003 - val_loss: 0.8815 - val_accuracy: 0.5571\n",
      "Epoch 6/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.7133 - accuracy: 0.59\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.7133 - accuracy: 0.5965 - val_loss: 1.0045 - val_accuracy: 0.4909\n",
      "Epoch 7/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7201 - accuracy: 0.59\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.7201 - accuracy: 0.5973 - val_loss: 0.7176 - val_accuracy: 0.6119\n",
      "Epoch 8/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6918 - accuracy: 0.62\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.6918 - accuracy: 0.6247 - val_loss: 0.7069 - val_accuracy: 0.6256\n",
      "Epoch 9/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7100 - accuracy: 0.60\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.7100 - accuracy: 0.6034 - val_loss: 0.7428 - val_accuracy: 0.5274\n",
      "Epoch 10/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6903 - accuracy: 0.59\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.6899 - accuracy: 0.5995 - val_loss: 0.7279 - val_accuracy: 0.5434\n",
      "Epoch 11/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6877 - accuracy: 0.61\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.6877 - accuracy: 0.6156 - val_loss: 0.9407 - val_accuracy: 0.5091\n",
      "Epoch 12/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7095 - accuracy: 0.62\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.7095 - accuracy: 0.6209 - val_loss: 0.6661 - val_accuracy: 0.6553\n",
      "Epoch 13/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6919 - accuracy: 0.61\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.6912 - accuracy: 0.6156 - val_loss: 0.6921 - val_accuracy: 0.5868\n",
      "Epoch 14/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6885 - accuracy: 0.61\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.6907 - accuracy: 0.6072 - val_loss: 0.7037 - val_accuracy: 0.6073\n",
      "Epoch 15/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6636 - accuracy: 0.63\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 0.6645 - accuracy: 0.6392 - val_loss: 0.6656 - val_accuracy: 0.6484\n",
      "Epoch 16/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.6653 - accuracy: 0.66\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.6655 - accuracy: 0.6453 - val_loss: 0.7433 - val_accuracy: 0.5982\n",
      "Epoch 17/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6853 - accuracy: 0.63\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.6698 - accuracy: 0.6362 - val_loss: 0.6675 - val_accuracy: 0.6667\n",
      "Epoch 18/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6183 - accuracy: 0.78\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6812 - accuracy: 0.6285 - val_loss: 0.6950 - val_accuracy: 0.6461\n",
      "Epoch 19/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6894 - accuracy: 0.68\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.6767 - accuracy: 0.6438 - val_loss: 0.8664 - val_accuracy: 0.5160\n",
      "Epoch 20/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.7407 - accuracy: 0.61\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.6558 - accuracy: 0.6522 - val_loss: 0.7720 - val_accuracy: 0.5228\n",
      "Epoch 21/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7457 - accuracy: 0.53\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.6829 - accuracy: 0.6285 - val_loss: 0.6990 - val_accuracy: 0.6073\n",
      "Epoch 22/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.7488 - accuracy: 0.59\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.6538 - accuracy: 0.6476 - val_loss: 0.7811 - val_accuracy: 0.5434\n",
      "Epoch 23/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7463 - accuracy: 0.59\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6635 - accuracy: 0.6499 - val_loss: 0.6674 - val_accuracy: 0.6484\n",
      "Epoch 24/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6491 - accuracy: 0.66\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.6492 - accuracy: 0.6598 - val_loss: 1.0216 - val_accuracy: 0.5023\n",
      "Epoch 25/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6721 - accuracy: 0.65\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6728 - accuracy: 0.6575 - val_loss: 0.7419 - val_accuracy: 0.6187\n",
      "Epoch 26/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6636 - accuracy: 0.64\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6636 - accuracy: 0.6445 - val_loss: 0.8956 - val_accuracy: 0.5091\n",
      "Epoch 27/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6451 - accuracy: 0.65\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.6463 - accuracy: 0.6514 - val_loss: 0.9087 - val_accuracy: 0.5023\n",
      "Epoch 28/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6697 - accuracy: 0.65\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6697 - accuracy: 0.6529 - val_loss: 0.6749 - val_accuracy: 0.6370\n",
      "Epoch 29/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6471 - accuracy: 0.64\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.6471 - accuracy: 0.6491 - val_loss: 0.7831 - val_accuracy: 0.5525\n",
      "Epoch 30/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6288 - accuracy: 0.66\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6316 - accuracy: 0.6644 - val_loss: 0.6871 - val_accuracy: 0.6301\n",
      "Epoch 31/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6543 - accuracy: 0.65\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.6540 - accuracy: 0.6537 - val_loss: 0.7475 - val_accuracy: 0.5594\n",
      "Epoch 32/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6440 - accuracy: 0.65\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.6397 - accuracy: 0.6537 - val_loss: 0.8359 - val_accuracy: 0.5365\n",
      "Epoch 33/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6602 - accuracy: 0.65\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6547 - accuracy: 0.6529 - val_loss: 0.7827 - val_accuracy: 0.6073\n",
      "Epoch 34/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6470 - accuracy: 0.64\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.6470 - accuracy: 0.6415 - val_loss: 0.6680 - val_accuracy: 0.6461\n",
      "Epoch 35/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6423 - accuracy: 0.64\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.6423 - accuracy: 0.6423 - val_loss: 0.6675 - val_accuracy: 0.6279\n",
      "Epoch 36/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6148 - accuracy: 0.66\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6148 - accuracy: 0.6636 - val_loss: 1.0457 - val_accuracy: 0.4977\n",
      "Epoch 37/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6509 - accuracy: 0.65\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6514 - accuracy: 0.6506 - val_loss: 0.7780 - val_accuracy: 0.5959\n",
      "Epoch 38/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6294 - accuracy: 0.67\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.6303 - accuracy: 0.6728 - val_loss: 0.6927 - val_accuracy: 0.6507\n",
      "Epoch 39/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.6344 - accuracy: 0.64\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.6341 - accuracy: 0.6453 - val_loss: 0.7934 - val_accuracy: 0.5297\n",
      "Epoch 40/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6673 - accuracy: 0.62\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.6560 - accuracy: 0.6316 - val_loss: 0.6994 - val_accuracy: 0.6142\n",
      "Epoch 41/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6236 - accuracy: 0.65\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6232 - accuracy: 0.6575 - val_loss: 0.5891 - val_accuracy: 0.6553\n",
      "Epoch 42/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6321 - accuracy: 0.67\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.6428 - accuracy: 0.6659 - val_loss: 0.6143 - val_accuracy: 0.6872\n",
      "Epoch 43/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6030 - accuracy: 0.68\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6030 - accuracy: 0.6796 - val_loss: 0.6623 - val_accuracy: 0.6210\n",
      "Epoch 44/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6257 - accuracy: 0.65\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6262 - accuracy: 0.6560 - val_loss: 0.7272 - val_accuracy: 0.6416\n",
      "Epoch 45/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6220 - accuracy: 0.68\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6217 - accuracy: 0.6804 - val_loss: 0.7718 - val_accuracy: 0.5479\n",
      "Epoch 46/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6167 - accuracy: 0.66\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6167 - accuracy: 0.6651 - val_loss: 0.6454 - val_accuracy: 0.6324\n",
      "Epoch 47/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6434 - accuracy: 0.64\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.6369 - accuracy: 0.6461 - val_loss: 0.6362 - val_accuracy: 0.6324\n",
      "Epoch 48/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6405 - accuracy: 0.66\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.6348 - accuracy: 0.6697 - val_loss: 0.8158 - val_accuracy: 0.6324\n",
      "Epoch 49/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6199 - accuracy: 0.66\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6198 - accuracy: 0.6621 - val_loss: 0.6558 - val_accuracy: 0.7146\n",
      "Epoch 50/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6085 - accuracy: 0.67\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6085 - accuracy: 0.6758 - val_loss: 0.8111 - val_accuracy: 0.5639\n",
      "Epoch 51/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6080 - accuracy: 0.66\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.6074 - accuracy: 0.6690 - val_loss: 0.7082 - val_accuracy: 0.6073\n",
      "Epoch 52/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6409 - accuracy: 0.66\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6404 - accuracy: 0.6613 - val_loss: 0.5879 - val_accuracy: 0.6461\n",
      "Epoch 53/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5888 - accuracy: 0.67\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.5901 - accuracy: 0.6773 - val_loss: 0.7015 - val_accuracy: 0.6324\n",
      "Epoch 54/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6134 - accuracy: 0.67\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6097 - accuracy: 0.6781 - val_loss: 0.8927 - val_accuracy: 0.5548\n",
      "Epoch 55/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6185 - accuracy: 0.68\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6172 - accuracy: 0.6857 - val_loss: 0.6621 - val_accuracy: 0.5753\n",
      "Epoch 56/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6083 - accuracy: 0.67\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.6132 - accuracy: 0.6697 - val_loss: 0.6708 - val_accuracy: 0.6621\n",
      "Epoch 57/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6160 - accuracy: 0.67\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6160 - accuracy: 0.6728 - val_loss: 0.6102 - val_accuracy: 0.7215\n",
      "Epoch 58/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5892 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5892 - accuracy: 0.6903 - val_loss: 0.6059 - val_accuracy: 0.6735\n",
      "Epoch 59/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6003 - accuracy: 0.67\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5996 - accuracy: 0.6796 - val_loss: 0.6492 - val_accuracy: 0.6461\n",
      "Epoch 60/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5867 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5873 - accuracy: 0.6918 - val_loss: 0.6818 - val_accuracy: 0.5502\n",
      "Epoch 61/2000\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.6354 - accuracy: 0.64\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6348 - accuracy: 0.6445 - val_loss: 0.5954 - val_accuracy: 0.6644\n",
      "Epoch 62/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.5865 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5862 - accuracy: 0.6957 - val_loss: 0.6240 - val_accuracy: 0.6712\n",
      "Epoch 63/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5919 - accuracy: 0.67\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.5919 - accuracy: 0.6796 - val_loss: 0.6233 - val_accuracy: 0.6553\n",
      "Epoch 64/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5909 - accuracy: 0.68\n",
      "14/14 [==============================] - 2s 168ms/step - loss: 0.5966 - accuracy: 0.6880 - val_loss: 0.6937 - val_accuracy: 0.6233\n",
      "Epoch 65/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5969 - accuracy: 0.68\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.5955 - accuracy: 0.6781 - val_loss: 0.8215 - val_accuracy: 0.5753\n",
      "Epoch 66/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6935 - accuracy: 0.64\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6132 - accuracy: 0.6705 - val_loss: 0.5719 - val_accuracy: 0.6644\n",
      "Epoch 67/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5904 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6055 - accuracy: 0.6895 - val_loss: 0.6476 - val_accuracy: 0.6233\n",
      "Epoch 68/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6397 - accuracy: 0.62\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5910 - accuracy: 0.6873 - val_loss: 0.5754 - val_accuracy: 0.6712\n",
      "Epoch 69/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5727 - accuracy: 0.66\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5852 - accuracy: 0.7048 - val_loss: 0.6337 - val_accuracy: 0.6005\n",
      "Epoch 70/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6291 - accuracy: 0.62\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6129 - accuracy: 0.6682 - val_loss: 0.5866 - val_accuracy: 0.6849\n",
      "Epoch 71/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5357 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.6116 - accuracy: 0.6911 - val_loss: 0.5871 - val_accuracy: 0.6621\n",
      "Epoch 72/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5194 - accuracy: 0.76\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5887 - accuracy: 0.6964 - val_loss: 0.7308 - val_accuracy: 0.6553\n",
      "Epoch 73/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6344 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5966 - accuracy: 0.6880 - val_loss: 0.5796 - val_accuracy: 0.6941\n",
      "Epoch 74/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5893 - accuracy: 0.68\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5814 - accuracy: 0.6911 - val_loss: 0.9806 - val_accuracy: 0.5434\n",
      "Epoch 75/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.8970 - accuracy: 0.59\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6013 - accuracy: 0.6873 - val_loss: 0.6843 - val_accuracy: 0.6164\n",
      "Epoch 76/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6384 - accuracy: 0.62\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.6009 - accuracy: 0.6728 - val_loss: 0.6842 - val_accuracy: 0.6872\n",
      "Epoch 77/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6058 - accuracy: 0.72\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5986 - accuracy: 0.6880 - val_loss: 0.7756 - val_accuracy: 0.5502\n",
      "Epoch 78/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5894 - accuracy: 0.68\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5894 - accuracy: 0.6819 - val_loss: 0.6934 - val_accuracy: 0.6735\n",
      "Epoch 79/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5817 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5817 - accuracy: 0.7002 - val_loss: 0.6166 - val_accuracy: 0.6256\n",
      "Epoch 80/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5460 - accuracy: 0.67\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5784 - accuracy: 0.6911 - val_loss: 0.6514 - val_accuracy: 0.6164\n",
      "Epoch 81/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6003 - accuracy: 0.68\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.6149 - accuracy: 0.6682 - val_loss: 0.5998 - val_accuracy: 0.7215\n",
      "Epoch 82/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5424 - accuracy: 0.77\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5838 - accuracy: 0.6796 - val_loss: 0.5670 - val_accuracy: 0.6438\n",
      "Epoch 83/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5051 - accuracy: 0.71\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5772 - accuracy: 0.6850 - val_loss: 0.6675 - val_accuracy: 0.6119\n",
      "Epoch 84/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.7097 - accuracy: 0.54\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.6109 - accuracy: 0.6682 - val_loss: 0.7719 - val_accuracy: 0.5639\n",
      "Epoch 85/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.7603 - accuracy: 0.53\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5890 - accuracy: 0.6751 - val_loss: 0.7893 - val_accuracy: 0.6073\n",
      "Epoch 86/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.8200 - accuracy: 0.58\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5902 - accuracy: 0.6812 - val_loss: 0.5810 - val_accuracy: 0.7215\n",
      "Epoch 87/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5856 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5960 - accuracy: 0.7094 - val_loss: 0.6305 - val_accuracy: 0.6644\n",
      "Epoch 88/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6500 - accuracy: 0.66\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5785 - accuracy: 0.6972 - val_loss: 0.5466 - val_accuracy: 0.6963\n",
      "Epoch 89/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4989 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.6076 - accuracy: 0.6705 - val_loss: 0.6536 - val_accuracy: 0.7260\n",
      "Epoch 90/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6953 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5961 - accuracy: 0.6934 - val_loss: 0.8110 - val_accuracy: 0.5616\n",
      "Epoch 91/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.8930 - accuracy: 0.49\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5859 - accuracy: 0.6895 - val_loss: 0.6062 - val_accuracy: 0.6849\n",
      "Epoch 92/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5911 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5911 - accuracy: 0.7071 - val_loss: 0.6413 - val_accuracy: 0.6233\n",
      "Epoch 93/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6053 - accuracy: 0.68\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.6053 - accuracy: 0.6888 - val_loss: 0.7704 - val_accuracy: 0.6027\n",
      "Epoch 94/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7777 - accuracy: 0.55\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5826 - accuracy: 0.6834 - val_loss: 0.5480 - val_accuracy: 0.6644\n",
      "Epoch 95/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5639 - accuracy: 0.65\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5853 - accuracy: 0.6987 - val_loss: 0.7891 - val_accuracy: 0.5502\n",
      "Epoch 96/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.7453 - accuracy: 0.62\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5852 - accuracy: 0.7025 - val_loss: 0.7399 - val_accuracy: 0.6712\n",
      "Epoch 97/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6399 - accuracy: 0.68\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.6132 - accuracy: 0.6918 - val_loss: 0.6610 - val_accuracy: 0.7055\n",
      "Epoch 98/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6838 - accuracy: 0.62\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.5718 - accuracy: 0.6972 - val_loss: 0.6719 - val_accuracy: 0.7032\n",
      "Epoch 99/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5795 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5795 - accuracy: 0.6941 - val_loss: 0.5968 - val_accuracy: 0.6438\n",
      "Epoch 100/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5838 - accuracy: 0.64\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5847 - accuracy: 0.6895 - val_loss: 0.8102 - val_accuracy: 0.5890\n",
      "Epoch 101/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.7680 - accuracy: 0.61\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.6057 - accuracy: 0.6789 - val_loss: 0.7285 - val_accuracy: 0.6621\n",
      "Epoch 102/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7275 - accuracy: 0.61\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5825 - accuracy: 0.6781 - val_loss: 0.7194 - val_accuracy: 0.6027\n",
      "Epoch 103/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7926 - accuracy: 0.56\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5848 - accuracy: 0.6895 - val_loss: 0.6634 - val_accuracy: 0.6484\n",
      "Epoch 104/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6329 - accuracy: 0.68\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5736 - accuracy: 0.7033 - val_loss: 0.5846 - val_accuracy: 0.7306\n",
      "Epoch 105/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5379 - accuracy: 0.76\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5775 - accuracy: 0.6827 - val_loss: 0.6522 - val_accuracy: 0.6872\n",
      "Epoch 106/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5725 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5725 - accuracy: 0.6987 - val_loss: 0.6664 - val_accuracy: 0.6598\n",
      "Epoch 107/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6499 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.6070 - accuracy: 0.6926 - val_loss: 0.6694 - val_accuracy: 0.6233\n",
      "Epoch 108/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6845 - accuracy: 0.58\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5745 - accuracy: 0.6850 - val_loss: 0.7679 - val_accuracy: 0.6005\n",
      "Epoch 109/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6639 - accuracy: 0.66\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5683 - accuracy: 0.6880 - val_loss: 0.6075 - val_accuracy: 0.7123\n",
      "Epoch 110/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5642 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5538 - accuracy: 0.7056 - val_loss: 0.9533 - val_accuracy: 0.5890\n",
      "Epoch 111/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 1.0184 - accuracy: 0.59\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.6024 - accuracy: 0.6804 - val_loss: 1.1928 - val_accuracy: 0.5205\n",
      "Epoch 112/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 1.1234 - accuracy: 0.54\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5972 - accuracy: 0.6949 - val_loss: 0.6280 - val_accuracy: 0.6461\n",
      "Epoch 113/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5425 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5642 - accuracy: 0.6895 - val_loss: 0.7430 - val_accuracy: 0.6598\n",
      "Epoch 114/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6369 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5879 - accuracy: 0.6819 - val_loss: 0.5546 - val_accuracy: 0.6575\n",
      "Epoch 115/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5562 - accuracy: 0.66\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5911 - accuracy: 0.6827 - val_loss: 0.5987 - val_accuracy: 0.6644\n",
      "Epoch 116/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5362 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5649 - accuracy: 0.6987 - val_loss: 0.5873 - val_accuracy: 0.6826\n",
      "Epoch 117/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6092 - accuracy: 0.64\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5742 - accuracy: 0.6941 - val_loss: 0.5701 - val_accuracy: 0.6918\n",
      "Epoch 118/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5543 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5795 - accuracy: 0.7063 - val_loss: 0.5994 - val_accuracy: 0.7260\n",
      "Epoch 119/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4694 - accuracy: 0.84\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5865 - accuracy: 0.6918 - val_loss: 0.6313 - val_accuracy: 0.7215\n",
      "Epoch 120/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5419 - accuracy: 0.77\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5721 - accuracy: 0.7040 - val_loss: 0.6119 - val_accuracy: 0.6484\n",
      "Epoch 121/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5505 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5826 - accuracy: 0.6934 - val_loss: 0.6659 - val_accuracy: 0.6119\n",
      "Epoch 122/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6494 - accuracy: 0.68\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5564 - accuracy: 0.6926 - val_loss: 0.5983 - val_accuracy: 0.7283\n",
      "Epoch 123/2000\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.5707 - accuracy: 0.77\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.5582 - accuracy: 0.7208 - val_loss: 0.6955 - val_accuracy: 0.6438\n",
      "Epoch 124/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5766 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5756 - accuracy: 0.6949 - val_loss: 0.5854 - val_accuracy: 0.7123\n",
      "Epoch 125/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5437 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5716 - accuracy: 0.6941 - val_loss: 0.6164 - val_accuracy: 0.7397\n",
      "Epoch 126/2000\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.5680 - accuracy: 0.70\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.5752 - accuracy: 0.7002 - val_loss: 0.5706 - val_accuracy: 0.6553\n",
      "Epoch 127/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5674 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5566 - accuracy: 0.7040 - val_loss: 0.8527 - val_accuracy: 0.5320\n",
      "Epoch 128/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.7853 - accuracy: 0.57\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5633 - accuracy: 0.7033 - val_loss: 0.6538 - val_accuracy: 0.6849\n",
      "Epoch 129/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6880 - accuracy: 0.66\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5836 - accuracy: 0.6850 - val_loss: 0.6121 - val_accuracy: 0.6598\n",
      "Epoch 130/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5265 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5773 - accuracy: 0.7025 - val_loss: 0.5593 - val_accuracy: 0.7009\n",
      "Epoch 131/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5902 - accuracy: 0.64\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5516 - accuracy: 0.7025 - val_loss: 0.8882 - val_accuracy: 0.6279\n",
      "Epoch 132/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 1.1861 - accuracy: 0.51\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.6095 - accuracy: 0.7002 - val_loss: 0.6093 - val_accuracy: 0.7283\n",
      "Epoch 133/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5514 - accuracy: 0.72\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5505 - accuracy: 0.7208 - val_loss: 0.9456 - val_accuracy: 0.5776\n",
      "Epoch 134/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 1.0164 - accuracy: 0.54\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5835 - accuracy: 0.6781 - val_loss: 0.5595 - val_accuracy: 0.6553\n",
      "Epoch 135/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5472 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5600 - accuracy: 0.7086 - val_loss: 0.5846 - val_accuracy: 0.7169\n",
      "Epoch 136/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5011 - accuracy: 0.75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5544 - accuracy: 0.7147 - val_loss: 0.9437 - val_accuracy: 0.5594\n",
      "Epoch 137/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.8818 - accuracy: 0.57\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.6020 - accuracy: 0.6857 - val_loss: 0.7440 - val_accuracy: 0.5936\n",
      "Epoch 138/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.8614 - accuracy: 0.55\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5663 - accuracy: 0.7048 - val_loss: 0.6972 - val_accuracy: 0.6849\n",
      "Epoch 139/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.7525 - accuracy: 0.67\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.5573 - accuracy: 0.7063 - val_loss: 0.7074 - val_accuracy: 0.6050\n",
      "Epoch 140/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7752 - accuracy: 0.55\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5767 - accuracy: 0.6812 - val_loss: 0.5768 - val_accuracy: 0.6644\n",
      "Epoch 141/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4978 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5634 - accuracy: 0.6903 - val_loss: 0.5949 - val_accuracy: 0.6758\n",
      "Epoch 142/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5738 - accuracy: 0.71\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5762 - accuracy: 0.7033 - val_loss: 0.5986 - val_accuracy: 0.7032\n",
      "Epoch 143/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5885 - accuracy: 0.71\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5643 - accuracy: 0.7040 - val_loss: 0.5746 - val_accuracy: 0.7123\n",
      "Epoch 144/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5226 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5533 - accuracy: 0.7018 - val_loss: 0.6255 - val_accuracy: 0.7055\n",
      "Epoch 145/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6585 - accuracy: 0.64\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5655 - accuracy: 0.7178 - val_loss: 0.6971 - val_accuracy: 0.6712\n",
      "Epoch 146/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5617 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5617 - accuracy: 0.7040 - val_loss: 0.6516 - val_accuracy: 0.6872\n",
      "Epoch 147/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5485 - accuracy: 0.71\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5552 - accuracy: 0.7079 - val_loss: 0.5670 - val_accuracy: 0.6872\n",
      "Epoch 148/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6057 - accuracy: 0.67\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5625 - accuracy: 0.7048 - val_loss: 0.5291 - val_accuracy: 0.6963\n",
      "Epoch 149/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5480 - accuracy: 0.70\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.5472 - accuracy: 0.7040 - val_loss: 0.9415 - val_accuracy: 0.5160\n",
      "Epoch 150/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.9266 - accuracy: 0.50\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5726 - accuracy: 0.7040 - val_loss: 0.5896 - val_accuracy: 0.6689\n",
      "Epoch 151/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5616 - accuracy: 0.71\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5578 - accuracy: 0.7002 - val_loss: 0.5641 - val_accuracy: 0.7329\n",
      "Epoch 152/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5583 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5615 - accuracy: 0.7117 - val_loss: 0.6409 - val_accuracy: 0.6575\n",
      "Epoch 153/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5556 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5556 - accuracy: 0.7079 - val_loss: 0.7242 - val_accuracy: 0.6347\n",
      "Epoch 154/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7592 - accuracy: 0.65\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5877 - accuracy: 0.7094 - val_loss: 0.5565 - val_accuracy: 0.7260\n",
      "Epoch 155/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5272 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5345 - accuracy: 0.7307 - val_loss: 0.5520 - val_accuracy: 0.7169\n",
      "Epoch 156/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5816 - accuracy: 0.69\n",
      "14/14 [==============================] - 1s 92ms/step - loss: 0.5702 - accuracy: 0.7048 - val_loss: 0.6068 - val_accuracy: 0.7100\n",
      "Epoch 157/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5317 - accuracy: 0.76\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5503 - accuracy: 0.7193 - val_loss: 0.6065 - val_accuracy: 0.7123\n",
      "Epoch 158/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5544 - accuracy: 0.69\n",
      "14/14 [==============================] - 1s 74ms/step - loss: 0.5544 - accuracy: 0.6979 - val_loss: 0.7373 - val_accuracy: 0.6347\n",
      "Epoch 159/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.5878 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5845 - accuracy: 0.7056 - val_loss: 0.5443 - val_accuracy: 0.7032\n",
      "Epoch 160/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.5931 - accuracy: 0.66\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5360 - accuracy: 0.7124 - val_loss: 0.7085 - val_accuracy: 0.6096\n",
      "Epoch 161/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7002 - accuracy: 0.67\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5670 - accuracy: 0.7124 - val_loss: 0.7138 - val_accuracy: 0.6210\n",
      "Epoch 162/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.7080 - accuracy: 0.63\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5624 - accuracy: 0.6918 - val_loss: 0.7530 - val_accuracy: 0.6963\n",
      "Epoch 163/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6902 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.5422 - accuracy: 0.7079 - val_loss: 0.6083 - val_accuracy: 0.6553\n",
      "Epoch 164/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5697 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5697 - accuracy: 0.6941 - val_loss: 0.5492 - val_accuracy: 0.7420\n",
      "Epoch 165/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6044 - accuracy: 0.67\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5463 - accuracy: 0.7086 - val_loss: 0.5382 - val_accuracy: 0.6941\n",
      "Epoch 166/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5540 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5546 - accuracy: 0.7018 - val_loss: 0.5933 - val_accuracy: 0.6918\n",
      "Epoch 167/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5038 - accuracy: 0.76\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.5497 - accuracy: 0.7170 - val_loss: 0.6964 - val_accuracy: 0.7192\n",
      "Epoch 168/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5895 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5793 - accuracy: 0.7002 - val_loss: 0.5651 - val_accuracy: 0.6918\n",
      "Epoch 169/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5179 - accuracy: 0.75\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.5528 - accuracy: 0.7071 - val_loss: 0.5463 - val_accuracy: 0.7283\n",
      "Epoch 170/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5644 - accuracy: 0.69\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.5644 - accuracy: 0.6911 - val_loss: 0.5979 - val_accuracy: 0.6781\n",
      "Epoch 171/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5397 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5397 - accuracy: 0.7040 - val_loss: 0.5637 - val_accuracy: 0.6804\n",
      "Epoch 172/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5831 - accuracy: 0.65\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5584 - accuracy: 0.6949 - val_loss: 0.5427 - val_accuracy: 0.7009\n",
      "Epoch 173/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5622 - accuracy: 0.67\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.5561 - accuracy: 0.7033 - val_loss: 0.5993 - val_accuracy: 0.6895\n",
      "Epoch 174/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5536 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5536 - accuracy: 0.7056 - val_loss: 0.6709 - val_accuracy: 0.6621\n",
      "Epoch 175/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5472 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.5530 - accuracy: 0.7223 - val_loss: 0.6573 - val_accuracy: 0.6393\n",
      "Epoch 176/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6436 - accuracy: 0.66\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5435 - accuracy: 0.7147 - val_loss: 0.5499 - val_accuracy: 0.7352\n",
      "Epoch 177/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5454 - accuracy: 0.72\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5454 - accuracy: 0.7208 - val_loss: 0.8121 - val_accuracy: 0.5913\n",
      "Epoch 178/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.8272 - accuracy: 0.56\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5509 - accuracy: 0.7002 - val_loss: 0.5923 - val_accuracy: 0.6758\n",
      "Epoch 179/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5592 - accuracy: 0.65\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5500 - accuracy: 0.7117 - val_loss: 0.6253 - val_accuracy: 0.6667\n",
      "Epoch 180/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5337 - accuracy: 0.76\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5294 - accuracy: 0.7300 - val_loss: 0.6733 - val_accuracy: 0.7260\n",
      "Epoch 181/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.7179 - accuracy: 0.72\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5592 - accuracy: 0.7178 - val_loss: 0.7308 - val_accuracy: 0.6073\n",
      "Epoch 182/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.7610 - accuracy: 0.62\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5727 - accuracy: 0.7002 - val_loss: 0.8421 - val_accuracy: 0.5731\n",
      "Epoch 183/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5757 - accuracy: 0.68\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5757 - accuracy: 0.6865 - val_loss: 0.6058 - val_accuracy: 0.6621\n",
      "Epoch 184/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6547 - accuracy: 0.64\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5483 - accuracy: 0.7140 - val_loss: 0.6846 - val_accuracy: 0.6986\n",
      "Epoch 185/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.6764 - accuracy: 0.71\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.5528 - accuracy: 0.7254 - val_loss: 0.5273 - val_accuracy: 0.7192\n",
      "Epoch 186/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4684 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5459 - accuracy: 0.7117 - val_loss: 0.5710 - val_accuracy: 0.7420\n",
      "Epoch 187/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5608 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5547 - accuracy: 0.7124 - val_loss: 0.6424 - val_accuracy: 0.6142\n",
      "Epoch 188/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6244 - accuracy: 0.63\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5499 - accuracy: 0.7094 - val_loss: 0.6385 - val_accuracy: 0.6621\n",
      "Epoch 189/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6384 - accuracy: 0.64\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.5448 - accuracy: 0.7063 - val_loss: 0.5693 - val_accuracy: 0.7146\n",
      "Epoch 190/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5609 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5380 - accuracy: 0.7338 - val_loss: 0.5885 - val_accuracy: 0.6963\n",
      "Epoch 191/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5173 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.5515 - accuracy: 0.7132 - val_loss: 0.6062 - val_accuracy: 0.7306\n",
      "Epoch 192/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6009 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5308 - accuracy: 0.7185 - val_loss: 0.5896 - val_accuracy: 0.7306\n",
      "Epoch 193/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5435 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5435 - accuracy: 0.7056 - val_loss: 0.5454 - val_accuracy: 0.6872\n",
      "Epoch 194/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5442 - accuracy: 0.68\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5500 - accuracy: 0.7033 - val_loss: 0.5307 - val_accuracy: 0.7123\n",
      "Epoch 195/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5211 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5237 - accuracy: 0.7277 - val_loss: 0.7532 - val_accuracy: 0.6370\n",
      "Epoch 196/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.7384 - accuracy: 0.63\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 0.5722 - accuracy: 0.6987 - val_loss: 0.5758 - val_accuracy: 0.6712\n",
      "Epoch 197/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5485 - accuracy: 0.72\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5485 - accuracy: 0.7223 - val_loss: 0.5901 - val_accuracy: 0.7146\n",
      "Epoch 198/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5475 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5475 - accuracy: 0.7071 - val_loss: 0.6348 - val_accuracy: 0.7078\n",
      "Epoch 199/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5561 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5505 - accuracy: 0.7147 - val_loss: 0.5468 - val_accuracy: 0.7146\n",
      "Epoch 200/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.5351 - accuracy: 0.71\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.5351 - accuracy: 0.7185 - val_loss: 0.6564 - val_accuracy: 0.6530\n",
      "Epoch 201/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5318 - accuracy: 0.72\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5315 - accuracy: 0.7285 - val_loss: 0.6156 - val_accuracy: 0.7352\n",
      "Epoch 202/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5468 - accuracy: 0.72\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5468 - accuracy: 0.7285 - val_loss: 0.5084 - val_accuracy: 0.7078\n",
      "Epoch 203/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5181 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5167 - accuracy: 0.7368 - val_loss: 0.5055 - val_accuracy: 0.7169\n",
      "Epoch 204/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5461 - accuracy: 0.72\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5461 - accuracy: 0.7201 - val_loss: 0.5725 - val_accuracy: 0.6963\n",
      "Epoch 205/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5837 - accuracy: 0.66\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5633 - accuracy: 0.7094 - val_loss: 0.5626 - val_accuracy: 0.6849\n",
      "Epoch 206/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.5458 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5137 - accuracy: 0.7178 - val_loss: 0.5762 - val_accuracy: 0.6758\n",
      "Epoch 207/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5137 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5268 - accuracy: 0.7323 - val_loss: 0.5405 - val_accuracy: 0.6781\n",
      "Epoch 208/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.4974 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5159 - accuracy: 0.7254 - val_loss: 0.5647 - val_accuracy: 0.7283\n",
      "Epoch 209/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5275 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 38ms/step - loss: 0.5317 - accuracy: 0.7414 - val_loss: 0.5545 - val_accuracy: 0.6895\n",
      "Epoch 210/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5301 - accuracy: 0.73\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.5394 - accuracy: 0.7307 - val_loss: 0.5682 - val_accuracy: 0.7123\n",
      "Epoch 211/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5274 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.5317 - accuracy: 0.7262 - val_loss: 0.5399 - val_accuracy: 0.6941\n",
      "Epoch 212/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.5273 - accuracy: 0.71\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.5279 - accuracy: 0.7109 - val_loss: 0.7486 - val_accuracy: 0.6347\n",
      "Epoch 213/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5264 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 0.5268 - accuracy: 0.7086 - val_loss: 0.7012 - val_accuracy: 0.6187\n",
      "Epoch 214/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5294 - accuracy: 0.72\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5294 - accuracy: 0.7254 - val_loss: 0.8199 - val_accuracy: 0.6553\n",
      "Epoch 215/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.8238 - accuracy: 0.66\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.5655 - accuracy: 0.7079 - val_loss: 0.6284 - val_accuracy: 0.7146\n",
      "Epoch 216/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5693 - accuracy: 0.71\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5332 - accuracy: 0.7079 - val_loss: 0.6397 - val_accuracy: 0.6872\n",
      "Epoch 217/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6448 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5660 - accuracy: 0.7094 - val_loss: 0.5155 - val_accuracy: 0.7192\n",
      "Epoch 218/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5139 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5139 - accuracy: 0.7300 - val_loss: 0.7015 - val_accuracy: 0.6872\n",
      "Epoch 219/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6882 - accuracy: 0.64\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5355 - accuracy: 0.7071 - val_loss: 0.5801 - val_accuracy: 0.6895\n",
      "Epoch 220/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6079 - accuracy: 0.67\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5177 - accuracy: 0.7170 - val_loss: 0.6209 - val_accuracy: 0.7123\n",
      "Epoch 221/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5191 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5191 - accuracy: 0.7338 - val_loss: 0.6261 - val_accuracy: 0.7055\n",
      "Epoch 222/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5163 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5165 - accuracy: 0.7368 - val_loss: 0.6395 - val_accuracy: 0.6758\n",
      "Epoch 223/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6127 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5213 - accuracy: 0.7452 - val_loss: 0.6458 - val_accuracy: 0.6895\n",
      "Epoch 224/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5560 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5405 - accuracy: 0.7162 - val_loss: 0.5628 - val_accuracy: 0.6963\n",
      "Epoch 225/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5177 - accuracy: 0.72\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5177 - accuracy: 0.7262 - val_loss: 0.7511 - val_accuracy: 0.6370\n",
      "Epoch 226/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5417 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5417 - accuracy: 0.7407 - val_loss: 0.5686 - val_accuracy: 0.7055\n",
      "Epoch 227/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5065 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5458 - accuracy: 0.7201 - val_loss: 0.7247 - val_accuracy: 0.6849\n",
      "Epoch 228/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.7690 - accuracy: 0.66\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5308 - accuracy: 0.7262 - val_loss: 0.5315 - val_accuracy: 0.7192\n",
      "Epoch 229/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5688 - accuracy: 0.63\n",
      "14/14 [==============================] - 0s 38ms/step - loss: 0.5047 - accuracy: 0.7307 - val_loss: 0.7034 - val_accuracy: 0.6712\n",
      "Epoch 230/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5290 - accuracy: 0.72\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5290 - accuracy: 0.7231 - val_loss: 0.6904 - val_accuracy: 0.6621\n",
      "Epoch 231/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5355 - accuracy: 0.72\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5355 - accuracy: 0.7208 - val_loss: 0.5942 - val_accuracy: 0.6826\n",
      "Epoch 232/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5061 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5051 - accuracy: 0.7323 - val_loss: 0.5895 - val_accuracy: 0.7237\n",
      "Epoch 233/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5865 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5122 - accuracy: 0.7315 - val_loss: 0.5593 - val_accuracy: 0.6804\n",
      "Epoch 234/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5164 - accuracy: 0.72\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5164 - accuracy: 0.7277 - val_loss: 0.5985 - val_accuracy: 0.6986\n",
      "Epoch 235/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5914 - accuracy: 0.71\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5382 - accuracy: 0.7079 - val_loss: 0.6632 - val_accuracy: 0.6963\n",
      "Epoch 236/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5248 - accuracy: 0.71\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5248 - accuracy: 0.7101 - val_loss: 0.6310 - val_accuracy: 0.6986\n",
      "Epoch 237/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5283 - accuracy: 0.75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4992 - accuracy: 0.7429 - val_loss: 0.7279 - val_accuracy: 0.6370\n",
      "Epoch 238/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7316 - accuracy: 0.58\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5515 - accuracy: 0.7117 - val_loss: 0.5149 - val_accuracy: 0.7237\n",
      "Epoch 239/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.5061 - accuracy: 0.75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4892 - accuracy: 0.7422 - val_loss: 0.6910 - val_accuracy: 0.6758\n",
      "Epoch 240/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6504 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5229 - accuracy: 0.7323 - val_loss: 0.7141 - val_accuracy: 0.6393\n",
      "Epoch 241/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7026 - accuracy: 0.65\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.5294 - accuracy: 0.7269 - val_loss: 0.5624 - val_accuracy: 0.7443\n",
      "Epoch 242/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5705 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5259 - accuracy: 0.7414 - val_loss: 0.6021 - val_accuracy: 0.6804\n",
      "Epoch 243/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5074 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 0.5060 - accuracy: 0.7475 - val_loss: 0.5853 - val_accuracy: 0.6872\n",
      "Epoch 244/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5218 - accuracy: 0.71\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.5216 - accuracy: 0.7193 - val_loss: 0.7984 - val_accuracy: 0.6416\n",
      "Epoch 245/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6795 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.5348 - accuracy: 0.7223 - val_loss: 0.6780 - val_accuracy: 0.6804\n",
      "Epoch 246/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6683 - accuracy: 0.67\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5114 - accuracy: 0.7170 - val_loss: 0.5821 - val_accuracy: 0.7557\n",
      "Epoch 247/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5349 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.5349 - accuracy: 0.7239 - val_loss: 0.5237 - val_accuracy: 0.7443\n",
      "Epoch 248/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4996 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5046 - accuracy: 0.7399 - val_loss: 0.5346 - val_accuracy: 0.6895\n",
      "Epoch 249/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5116 - accuracy: 0.71\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5049 - accuracy: 0.7376 - val_loss: 0.5587 - val_accuracy: 0.7443\n",
      "Epoch 250/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5174 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5172 - accuracy: 0.7407 - val_loss: 0.7210 - val_accuracy: 0.6438\n",
      "Epoch 251/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.7357 - accuracy: 0.64\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5118 - accuracy: 0.7307 - val_loss: 0.6520 - val_accuracy: 0.6484\n",
      "Epoch 252/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5204 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.5204 - accuracy: 0.7285 - val_loss: 0.5970 - val_accuracy: 0.7032\n",
      "Epoch 253/2000\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.4930 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4926 - accuracy: 0.7353 - val_loss: 0.5759 - val_accuracy: 0.6667\n",
      "Epoch 254/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6048 - accuracy: 0.72\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5083 - accuracy: 0.7414 - val_loss: 0.7054 - val_accuracy: 0.6941\n",
      "Epoch 255/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5292 - accuracy: 0.71\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5307 - accuracy: 0.7162 - val_loss: 0.6970 - val_accuracy: 0.6712\n",
      "Epoch 256/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.7681 - accuracy: 0.61\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5004 - accuracy: 0.7468 - val_loss: 0.7150 - val_accuracy: 0.6210\n",
      "Epoch 257/2000\n",
      "2/2 [==============================] - 0s 1ms/step loss: 0.6869 - accuracy: 0.62\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5048 - accuracy: 0.7460 - val_loss: 0.6565 - val_accuracy: 0.6644\n",
      "Epoch 258/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6013 - accuracy: 0.66\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4931 - accuracy: 0.7330 - val_loss: 0.5739 - val_accuracy: 0.7260\n",
      "Epoch 259/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5392 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5122 - accuracy: 0.7315 - val_loss: 0.7317 - val_accuracy: 0.6301\n",
      "Epoch 260/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5112 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5112 - accuracy: 0.7323 - val_loss: 0.6646 - val_accuracy: 0.6735\n",
      "Epoch 261/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5862 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5121 - accuracy: 0.7368 - val_loss: 0.6318 - val_accuracy: 0.7169\n",
      "Epoch 262/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6569 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5001 - accuracy: 0.7483 - val_loss: 0.6133 - val_accuracy: 0.7123\n",
      "Epoch 263/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5115 - accuracy: 0.72\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5124 - accuracy: 0.7254 - val_loss: 0.7656 - val_accuracy: 0.6324\n",
      "Epoch 264/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.7510 - accuracy: 0.61\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5093 - accuracy: 0.7208 - val_loss: 0.5370 - val_accuracy: 0.6735\n",
      "Epoch 265/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4295 - accuracy: 0.78\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4953 - accuracy: 0.7414 - val_loss: 0.5610 - val_accuracy: 0.7397\n",
      "Epoch 266/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4917 - accuracy: 0.73\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.4917 - accuracy: 0.7376 - val_loss: 0.8195 - val_accuracy: 0.6575\n",
      "Epoch 267/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5158 - accuracy: 0.72\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5158 - accuracy: 0.7223 - val_loss: 0.4994 - val_accuracy: 0.7466\n",
      "Epoch 268/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.4843 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4820 - accuracy: 0.7429 - val_loss: 1.0011 - val_accuracy: 0.5822\n",
      "Epoch 269/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5112 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5116 - accuracy: 0.7483 - val_loss: 0.6157 - val_accuracy: 0.6598\n",
      "Epoch 270/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5175 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.5079 - accuracy: 0.7323 - val_loss: 0.4987 - val_accuracy: 0.7580\n",
      "Epoch 271/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4803 - accuracy: 0.75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4829 - accuracy: 0.7574 - val_loss: 0.8013 - val_accuracy: 0.6187\n",
      "Epoch 272/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5004 - accuracy: 0.71\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4954 - accuracy: 0.7155 - val_loss: 0.6365 - val_accuracy: 0.6507\n",
      "Epoch 273/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4990 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4970 - accuracy: 0.7391 - val_loss: 0.5155 - val_accuracy: 0.7557\n",
      "Epoch 274/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5098 - accuracy: 0.75\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.5121 - accuracy: 0.7376 - val_loss: 0.5834 - val_accuracy: 0.7032\n",
      "Epoch 275/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4856 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4852 - accuracy: 0.7399 - val_loss: 0.6129 - val_accuracy: 0.6575\n",
      "Epoch 276/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5060 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.5061 - accuracy: 0.7330 - val_loss: 0.4996 - val_accuracy: 0.7260\n",
      "Epoch 277/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4925 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4798 - accuracy: 0.7521 - val_loss: 0.6690 - val_accuracy: 0.6735\n",
      "Epoch 278/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4960 - accuracy: 0.75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4951 - accuracy: 0.7513 - val_loss: 0.5847 - val_accuracy: 0.7329\n",
      "Epoch 279/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5294 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.5294 - accuracy: 0.7376 - val_loss: 0.4913 - val_accuracy: 0.7260\n",
      "Epoch 280/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4738 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4756 - accuracy: 0.7460 - val_loss: 0.5818 - val_accuracy: 0.7192\n",
      "Epoch 281/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4825 - accuracy: 0.76\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.4802 - accuracy: 0.7628 - val_loss: 0.5377 - val_accuracy: 0.6507\n",
      "Epoch 282/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4882 - accuracy: 0.75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4886 - accuracy: 0.7529 - val_loss: 0.6311 - val_accuracy: 0.7123\n",
      "Epoch 283/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4730 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4729 - accuracy: 0.7452 - val_loss: 0.6039 - val_accuracy: 0.7306\n",
      "Epoch 284/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4888 - accuracy: 0.76\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4930 - accuracy: 0.7567 - val_loss: 0.5254 - val_accuracy: 0.6941\n",
      "Epoch 285/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4816 - accuracy: 0.75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4847 - accuracy: 0.7551 - val_loss: 0.5263 - val_accuracy: 0.7192\n",
      "Epoch 286/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4744 - accuracy: 0.77\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4840 - accuracy: 0.7727 - val_loss: 0.6292 - val_accuracy: 0.6735\n",
      "Epoch 287/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6513 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5015 - accuracy: 0.7452 - val_loss: 0.6291 - val_accuracy: 0.6621\n",
      "Epoch 288/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6468 - accuracy: 0.65\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4942 - accuracy: 0.7368 - val_loss: 0.6461 - val_accuracy: 0.7009\n",
      "Epoch 289/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6178 - accuracy: 0.71\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4823 - accuracy: 0.7674 - val_loss: 0.5244 - val_accuracy: 0.7603\n",
      "Epoch 290/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5440 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4918 - accuracy: 0.7574 - val_loss: 0.5686 - val_accuracy: 0.7215\n",
      "Epoch 291/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4909 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4909 - accuracy: 0.7460 - val_loss: 0.6626 - val_accuracy: 0.7215\n",
      "Epoch 292/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6433 - accuracy: 0.78\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4826 - accuracy: 0.7666 - val_loss: 0.6260 - val_accuracy: 0.7100\n",
      "Epoch 293/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5231 - accuracy: 0.78\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4794 - accuracy: 0.7635 - val_loss: 0.5590 - val_accuracy: 0.6826\n",
      "Epoch 294/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4798 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4798 - accuracy: 0.7490 - val_loss: 0.5939 - val_accuracy: 0.7237\n",
      "Epoch 295/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.6071 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.4745 - accuracy: 0.7506 - val_loss: 0.7278 - val_accuracy: 0.6667\n",
      "Epoch 296/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7800 - accuracy: 0.63\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4936 - accuracy: 0.7559 - val_loss: 0.7370 - val_accuracy: 0.6461\n",
      "Epoch 297/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7131 - accuracy: 0.68\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4888 - accuracy: 0.7536 - val_loss: 0.5662 - val_accuracy: 0.7306\n",
      "Epoch 298/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5239 - accuracy: 0.75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4803 - accuracy: 0.7628 - val_loss: 0.5681 - val_accuracy: 0.6553\n",
      "Epoch 299/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5295 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4759 - accuracy: 0.7582 - val_loss: 0.6555 - val_accuracy: 0.7055\n",
      "Epoch 300/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.4847 - accuracy: 0.77\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4827 - accuracy: 0.7773 - val_loss: 0.5906 - val_accuracy: 0.7603\n",
      "Epoch 301/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5158 - accuracy: 0.84\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4783 - accuracy: 0.7651 - val_loss: 0.5463 - val_accuracy: 0.7374\n",
      "Epoch 302/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.5772 - accuracy: 0.69\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.4618 - accuracy: 0.7742 - val_loss: 0.6322 - val_accuracy: 0.7237\n",
      "Epoch 303/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4857 - accuracy: 0.76\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4897 - accuracy: 0.7613 - val_loss: 0.5434 - val_accuracy: 0.7557\n",
      "Epoch 304/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5766 - accuracy: 0.71\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4786 - accuracy: 0.7735 - val_loss: 0.6308 - val_accuracy: 0.7306\n",
      "Epoch 305/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7122 - accuracy: 0.68\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4849 - accuracy: 0.7689 - val_loss: 0.6270 - val_accuracy: 0.7146\n",
      "Epoch 306/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6715 - accuracy: 0.72\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4863 - accuracy: 0.7750 - val_loss: 0.5201 - val_accuracy: 0.7648\n",
      "Epoch 307/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5151 - accuracy: 0.78\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4810 - accuracy: 0.7597 - val_loss: 0.6760 - val_accuracy: 0.6872\n",
      "Epoch 308/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6107 - accuracy: 0.68\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4917 - accuracy: 0.7551 - val_loss: 0.6938 - val_accuracy: 0.6667\n",
      "Epoch 309/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5676 - accuracy: 0.75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4685 - accuracy: 0.7773 - val_loss: 0.6572 - val_accuracy: 0.6187\n",
      "Epoch 310/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4730 - accuracy: 0.76\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.4730 - accuracy: 0.7658 - val_loss: 0.4641 - val_accuracy: 0.7900\n",
      "Epoch 311/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4654 - accuracy: 0.78\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4738 - accuracy: 0.7750 - val_loss: 0.4960 - val_accuracy: 0.7283\n",
      "Epoch 312/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4511 - accuracy: 0.82\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4481 - accuracy: 0.7918 - val_loss: 0.7345 - val_accuracy: 0.6941\n",
      "Epoch 313/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5148 - accuracy: 0.76\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.5094 - accuracy: 0.7620 - val_loss: 0.7456 - val_accuracy: 0.6598\n",
      "Epoch 314/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5859 - accuracy: 0.75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4839 - accuracy: 0.7750 - val_loss: 0.5228 - val_accuracy: 0.6895\n",
      "Epoch 315/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4781 - accuracy: 0.77\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4809 - accuracy: 0.7674 - val_loss: 0.5013 - val_accuracy: 0.7374\n",
      "Epoch 316/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4538 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4646 - accuracy: 0.7757 - val_loss: 0.5109 - val_accuracy: 0.7100\n",
      "Epoch 317/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4684 - accuracy: 0.76\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4713 - accuracy: 0.7742 - val_loss: 0.5020 - val_accuracy: 0.7580\n",
      "Epoch 318/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4633 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4697 - accuracy: 0.7696 - val_loss: 0.7337 - val_accuracy: 0.6553\n",
      "Epoch 319/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.8493 - accuracy: 0.60\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5007 - accuracy: 0.7567 - val_loss: 0.5597 - val_accuracy: 0.7420\n",
      "Epoch 320/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5461 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4714 - accuracy: 0.7590 - val_loss: 0.5540 - val_accuracy: 0.7306\n",
      "Epoch 321/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6421 - accuracy: 0.59\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5090 - accuracy: 0.7559 - val_loss: 0.7292 - val_accuracy: 0.6826\n",
      "Epoch 322/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7507 - accuracy: 0.64\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4747 - accuracy: 0.7735 - val_loss: 0.5680 - val_accuracy: 0.6941\n",
      "Epoch 323/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5475 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4676 - accuracy: 0.7803 - val_loss: 0.5922 - val_accuracy: 0.7534\n",
      "Epoch 324/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4762 - accuracy: 0.78\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4756 - accuracy: 0.7864 - val_loss: 0.4988 - val_accuracy: 0.7100\n",
      "Epoch 325/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5473 - accuracy: 0.62\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4707 - accuracy: 0.7757 - val_loss: 0.4745 - val_accuracy: 0.7352\n",
      "Epoch 326/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4887 - accuracy: 0.75\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4887 - accuracy: 0.7551 - val_loss: 0.5385 - val_accuracy: 0.7466\n",
      "Epoch 327/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4486 - accuracy: 0.78\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4486 - accuracy: 0.7811 - val_loss: 0.4620 - val_accuracy: 0.7694\n",
      "Epoch 328/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4718 - accuracy: 0.77\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4718 - accuracy: 0.7712 - val_loss: 0.7975 - val_accuracy: 0.6507\n",
      "Epoch 329/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.8944 - accuracy: 0.61\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4842 - accuracy: 0.7521 - val_loss: 0.6255 - val_accuracy: 0.6963\n",
      "Epoch 330/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4751 - accuracy: 0.77\n",
      "14/14 [==============================] - 1s 64ms/step - loss: 0.4751 - accuracy: 0.7735 - val_loss: 0.5162 - val_accuracy: 0.7511\n",
      "Epoch 331/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.5001 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4511 - accuracy: 0.7796 - val_loss: 0.5232 - val_accuracy: 0.7534\n",
      "Epoch 332/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4541 - accuracy: 0.78\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4541 - accuracy: 0.7826 - val_loss: 0.5585 - val_accuracy: 0.6895\n",
      "Epoch 333/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6032 - accuracy: 0.65\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4598 - accuracy: 0.7689 - val_loss: 0.5682 - val_accuracy: 0.7374\n",
      "Epoch 334/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.6259 - accuracy: 0.68\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4764 - accuracy: 0.7719 - val_loss: 0.4713 - val_accuracy: 0.7854\n",
      "Epoch 335/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5014 - accuracy: 0.75\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.4456 - accuracy: 0.7979 - val_loss: 0.5362 - val_accuracy: 0.7671\n",
      "Epoch 336/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4679 - accuracy: 0.78\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.4687 - accuracy: 0.7826 - val_loss: 0.5532 - val_accuracy: 0.7489\n",
      "Epoch 337/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4633 - accuracy: 0.77\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.4619 - accuracy: 0.7742 - val_loss: 0.7989 - val_accuracy: 0.6484\n",
      "Epoch 338/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4811 - accuracy: 0.77\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4811 - accuracy: 0.7712 - val_loss: 0.6314 - val_accuracy: 0.7123\n",
      "Epoch 339/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4863 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4561 - accuracy: 0.7879 - val_loss: 0.4987 - val_accuracy: 0.7877\n",
      "Epoch 340/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4591 - accuracy: 0.84\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4678 - accuracy: 0.7757 - val_loss: 0.4907 - val_accuracy: 0.8037\n",
      "Epoch 341/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5008 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4357 - accuracy: 0.8055 - val_loss: 0.8360 - val_accuracy: 0.6073\n",
      "Epoch 342/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4711 - accuracy: 0.78\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4711 - accuracy: 0.7803 - val_loss: 0.5901 - val_accuracy: 0.7374\n",
      "Epoch 343/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4746 - accuracy: 0.78\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4746 - accuracy: 0.7811 - val_loss: 0.4652 - val_accuracy: 0.7329\n",
      "Epoch 344/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4854 - accuracy: 0.72\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4668 - accuracy: 0.7803 - val_loss: 0.7251 - val_accuracy: 0.6689\n",
      "Epoch 345/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5485 - accuracy: 0.77\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4473 - accuracy: 0.7963 - val_loss: 0.6236 - val_accuracy: 0.7100\n",
      "Epoch 346/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.5200 - accuracy: 0.76\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4657 - accuracy: 0.7712 - val_loss: 0.4651 - val_accuracy: 0.7580\n",
      "Epoch 347/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4040 - accuracy: 0.81\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4450 - accuracy: 0.7872 - val_loss: 0.4766 - val_accuracy: 0.7397\n",
      "Epoch 348/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4734 - accuracy: 0.78\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4734 - accuracy: 0.7879 - val_loss: 0.5669 - val_accuracy: 0.6941\n",
      "Epoch 349/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4455 - accuracy: 0.79\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.4434 - accuracy: 0.7994 - val_loss: 0.6746 - val_accuracy: 0.7100\n",
      "Epoch 350/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4870 - accuracy: 0.78\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4863 - accuracy: 0.7841 - val_loss: 0.4813 - val_accuracy: 0.8059\n",
      "Epoch 351/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4556 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4556 - accuracy: 0.7994 - val_loss: 0.5941 - val_accuracy: 0.7192\n",
      "Epoch 352/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7159 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4709 - accuracy: 0.7780 - val_loss: 0.4791 - val_accuracy: 0.7215\n",
      "Epoch 353/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4500 - accuracy: 0.76\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4370 - accuracy: 0.8085 - val_loss: 0.5443 - val_accuracy: 0.7215\n",
      "Epoch 354/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5055 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4770 - accuracy: 0.7696 - val_loss: 0.5230 - val_accuracy: 0.7534\n",
      "Epoch 355/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4905 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4242 - accuracy: 0.8024 - val_loss: 0.5592 - val_accuracy: 0.7648\n",
      "Epoch 356/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5501 - accuracy: 0.75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4788 - accuracy: 0.7818 - val_loss: 0.5812 - val_accuracy: 0.7443\n",
      "Epoch 357/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6156 - accuracy: 0.72\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4396 - accuracy: 0.8078 - val_loss: 0.4518 - val_accuracy: 0.7740\n",
      "Epoch 358/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4274 - accuracy: 0.78\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4446 - accuracy: 0.7948 - val_loss: 0.4719 - val_accuracy: 0.7489\n",
      "Epoch 359/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3900 - accuracy: 0.84\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4536 - accuracy: 0.7994 - val_loss: 0.4907 - val_accuracy: 0.8059\n",
      "Epoch 360/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4276 - accuracy: 0.84\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4652 - accuracy: 0.8024 - val_loss: 0.5304 - val_accuracy: 0.7922\n",
      "Epoch 361/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5360 - accuracy: 0.77\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4395 - accuracy: 0.8108 - val_loss: 0.5137 - val_accuracy: 0.7146\n",
      "Epoch 362/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4728 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4322 - accuracy: 0.8040 - val_loss: 0.6138 - val_accuracy: 0.6918\n",
      "Epoch 363/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4549 - accuracy: 0.80\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.4636 - accuracy: 0.7925 - val_loss: 0.5892 - val_accuracy: 0.6644\n",
      "Epoch 364/2000\n",
      "2/2 [==============================] - 0s 1ms/step loss: 0.4159 - accuracy: 0.82\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4146 - accuracy: 0.8223 - val_loss: 0.6089 - val_accuracy: 0.7443\n",
      "Epoch 365/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4525 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4525 - accuracy: 0.7963 - val_loss: 0.8173 - val_accuracy: 0.6301\n",
      "Epoch 366/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7292 - accuracy: 0.66\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4637 - accuracy: 0.8070 - val_loss: 0.5960 - val_accuracy: 0.7466\n",
      "Epoch 367/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5773 - accuracy: 0.78\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4449 - accuracy: 0.7887 - val_loss: 0.5248 - val_accuracy: 0.7626\n",
      "Epoch 368/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4362 - accuracy: 0.81\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4362 - accuracy: 0.8101 - val_loss: 0.6197 - val_accuracy: 0.7420\n",
      "Epoch 369/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4572 - accuracy: 0.80\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4501 - accuracy: 0.8101 - val_loss: 0.5079 - val_accuracy: 0.7352\n",
      "Epoch 370/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4147 - accuracy: 0.81\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4147 - accuracy: 0.8146 - val_loss: 0.7808 - val_accuracy: 0.6233\n",
      "Epoch 371/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.4870 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4870 - accuracy: 0.7925 - val_loss: 0.5514 - val_accuracy: 0.7055\n",
      "Epoch 372/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5690 - accuracy: 0.68\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4435 - accuracy: 0.8024 - val_loss: 0.5415 - val_accuracy: 0.7192\n",
      "Epoch 373/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4288 - accuracy: 0.81\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4288 - accuracy: 0.8108 - val_loss: 0.5609 - val_accuracy: 0.7557\n",
      "Epoch 374/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4462 - accuracy: 0.80\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.4436 - accuracy: 0.7994 - val_loss: 0.5692 - val_accuracy: 0.7922\n",
      "Epoch 375/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5470 - accuracy: 0.83\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4560 - accuracy: 0.8108 - val_loss: 0.6095 - val_accuracy: 0.7237\n",
      "Epoch 376/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4661 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4610 - accuracy: 0.7994 - val_loss: 0.6428 - val_accuracy: 0.7648\n",
      "Epoch 377/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4539 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4532 - accuracy: 0.7963 - val_loss: 0.6745 - val_accuracy: 0.6461\n",
      "Epoch 378/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4434 - accuracy: 0.81\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4434 - accuracy: 0.8116 - val_loss: 0.5164 - val_accuracy: 0.7169\n",
      "Epoch 379/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.4483 - accuracy: 0.80\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.4483 - accuracy: 0.8040 - val_loss: 0.6043 - val_accuracy: 0.7511\n",
      "Epoch 380/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4614 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4614 - accuracy: 0.7902 - val_loss: 0.5716 - val_accuracy: 0.7397\n",
      "Epoch 381/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5529 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4382 - accuracy: 0.8116 - val_loss: 0.5148 - val_accuracy: 0.8128\n",
      "Epoch 382/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5049 - accuracy: 0.81\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4480 - accuracy: 0.7956 - val_loss: 0.6664 - val_accuracy: 0.7100\n",
      "Epoch 383/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6803 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4560 - accuracy: 0.8009 - val_loss: 0.5684 - val_accuracy: 0.7237\n",
      "Epoch 384/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4639 - accuracy: 0.80\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4238 - accuracy: 0.8169 - val_loss: 0.4510 - val_accuracy: 0.8288\n",
      "Epoch 385/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.3965 - accuracy: 0.85\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4291 - accuracy: 0.8024 - val_loss: 0.6087 - val_accuracy: 0.6963\n",
      "Epoch 386/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4256 - accuracy: 0.82\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.4256 - accuracy: 0.8230 - val_loss: 0.4470 - val_accuracy: 0.8699\n",
      "Epoch 387/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3760 - accuracy: 0.89\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4291 - accuracy: 0.8078 - val_loss: 0.5349 - val_accuracy: 0.7671\n",
      "Epoch 388/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5085 - accuracy: 0.81\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4458 - accuracy: 0.7925 - val_loss: 0.4952 - val_accuracy: 0.8196\n",
      "Epoch 389/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4542 - accuracy: 0.81\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.4528 - accuracy: 0.8185 - val_loss: 0.4910 - val_accuracy: 0.7283\n",
      "Epoch 390/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4144 - accuracy: 0.82\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4250 - accuracy: 0.8246 - val_loss: 0.6228 - val_accuracy: 0.7443\n",
      "Epoch 391/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5564 - accuracy: 0.76\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4395 - accuracy: 0.8017 - val_loss: 0.5839 - val_accuracy: 0.7831\n",
      "Epoch 392/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4441 - accuracy: 0.81\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.4441 - accuracy: 0.8162 - val_loss: 0.6995 - val_accuracy: 0.7215\n",
      "Epoch 393/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4615 - accuracy: 0.81\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.4606 - accuracy: 0.8131 - val_loss: 0.5669 - val_accuracy: 0.7534\n",
      "Epoch 394/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5112 - accuracy: 0.77\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4155 - accuracy: 0.8330 - val_loss: 0.5485 - val_accuracy: 0.7648\n",
      "Epoch 395/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5742 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4413 - accuracy: 0.8032 - val_loss: 0.5207 - val_accuracy: 0.7694\n",
      "Epoch 396/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5108 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4238 - accuracy: 0.8368 - val_loss: 0.5236 - val_accuracy: 0.7991\n",
      "Epoch 397/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4315 - accuracy: 0.81\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.4315 - accuracy: 0.8116 - val_loss: 0.5914 - val_accuracy: 0.6621\n",
      "Epoch 398/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4356 - accuracy: 0.81\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4344 - accuracy: 0.8185 - val_loss: 0.4633 - val_accuracy: 0.7648\n",
      "Epoch 399/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4431 - accuracy: 0.81\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 0.4588 - accuracy: 0.7963 - val_loss: 0.5658 - val_accuracy: 0.7169\n",
      "Epoch 400/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.4339 - accuracy: 0.80\n",
      "14/14 [==============================] - 0s 38ms/step - loss: 0.4295 - accuracy: 0.8116 - val_loss: 0.6374 - val_accuracy: 0.7397\n",
      "Epoch 401/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4333 - accuracy: 0.82\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.4328 - accuracy: 0.8238 - val_loss: 0.4700 - val_accuracy: 0.7922\n",
      "Epoch 402/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4313 - accuracy: 0.80\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4293 - accuracy: 0.8093 - val_loss: 0.5018 - val_accuracy: 0.6758\n",
      "Epoch 403/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4530 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 0.4554 - accuracy: 0.7895 - val_loss: 0.6665 - val_accuracy: 0.6986\n",
      "Epoch 404/2000\n",
      "2/2 [==============================] - 0s 1ms/step loss: 0.4776 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 0.4678 - accuracy: 0.7948 - val_loss: 0.5064 - val_accuracy: 0.7626\n",
      "Epoch 405/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5077 - accuracy: 0.78\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4140 - accuracy: 0.8230 - val_loss: 0.6365 - val_accuracy: 0.7283\n",
      "Epoch 406/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4669 - accuracy: 0.80\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4602 - accuracy: 0.8085 - val_loss: 0.7215 - val_accuracy: 0.7055\n",
      "Epoch 407/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6524 - accuracy: 0.71\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4488 - accuracy: 0.8131 - val_loss: 0.5816 - val_accuracy: 0.7146\n",
      "Epoch 408/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4075 - accuracy: 0.84\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.4070 - accuracy: 0.8421 - val_loss: 0.4642 - val_accuracy: 0.7808\n",
      "Epoch 409/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4157 - accuracy: 0.81\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.4136 - accuracy: 0.8192 - val_loss: 0.5326 - val_accuracy: 0.7260\n",
      "Epoch 410/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5414 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4488 - accuracy: 0.8093 - val_loss: 0.4302 - val_accuracy: 0.8174\n",
      "Epoch 411/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3065 - accuracy: 0.90\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4189 - accuracy: 0.8276 - val_loss: 0.5745 - val_accuracy: 0.7123\n",
      "Epoch 412/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5014 - accuracy: 0.76\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4412 - accuracy: 0.8116 - val_loss: 0.4882 - val_accuracy: 0.7900\n",
      "Epoch 413/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5360 - accuracy: 0.78\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4362 - accuracy: 0.8215 - val_loss: 0.4459 - val_accuracy: 0.8219\n",
      "Epoch 414/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4165 - accuracy: 0.82\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 0.4165 - accuracy: 0.8200 - val_loss: 0.5678 - val_accuracy: 0.6963\n",
      "Epoch 415/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5926 - accuracy: 0.62\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4265 - accuracy: 0.8223 - val_loss: 0.5287 - val_accuracy: 0.7443\n",
      "Epoch 416/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5105 - accuracy: 0.76\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4122 - accuracy: 0.8352 - val_loss: 0.6140 - val_accuracy: 0.6438\n",
      "Epoch 417/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4342 - accuracy: 0.80\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4346 - accuracy: 0.8063 - val_loss: 0.4815 - val_accuracy: 0.7831\n",
      "Epoch 418/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5115 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4110 - accuracy: 0.8452 - val_loss: 0.6773 - val_accuracy: 0.6849\n",
      "Epoch 419/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6630 - accuracy: 0.67\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4241 - accuracy: 0.8185 - val_loss: 0.4765 - val_accuracy: 0.7717\n",
      "Epoch 420/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4920 - accuracy: 0.75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4103 - accuracy: 0.8223 - val_loss: 0.4903 - val_accuracy: 0.7991\n",
      "Epoch 421/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4276 - accuracy: 0.86\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4269 - accuracy: 0.8238 - val_loss: 0.5132 - val_accuracy: 0.7466\n",
      "Epoch 422/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4139 - accuracy: 0.83\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4111 - accuracy: 0.8352 - val_loss: 0.6629 - val_accuracy: 0.7055\n",
      "Epoch 423/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6318 - accuracy: 0.75\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.4197 - accuracy: 0.8452 - val_loss: 0.7747 - val_accuracy: 0.6963\n",
      "Epoch 424/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.8394 - accuracy: 0.63\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.4326 - accuracy: 0.8268 - val_loss: 0.4549 - val_accuracy: 0.8539\n",
      "Epoch 425/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4163 - accuracy: 0.88\n",
      "14/14 [==============================] - 1s 71ms/step - loss: 0.4098 - accuracy: 0.8436 - val_loss: 0.4967 - val_accuracy: 0.7900\n",
      "Epoch 426/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5740 - accuracy: 0.78\n",
      "14/14 [==============================] - 1s 63ms/step - loss: 0.4223 - accuracy: 0.8230 - val_loss: 0.4175 - val_accuracy: 0.8174\n",
      "Epoch 427/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4141 - accuracy: 0.84\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4141 - accuracy: 0.8444 - val_loss: 0.5799 - val_accuracy: 0.7420\n",
      "Epoch 428/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5481 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4258 - accuracy: 0.8085 - val_loss: 0.4745 - val_accuracy: 0.7511\n",
      "Epoch 429/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4849 - accuracy: 0.75\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4159 - accuracy: 0.8307 - val_loss: 0.5318 - val_accuracy: 0.7283\n",
      "Epoch 430/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4416 - accuracy: 0.80\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4061 - accuracy: 0.8436 - val_loss: 0.5836 - val_accuracy: 0.7877\n",
      "Epoch 431/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7183 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4094 - accuracy: 0.8474 - val_loss: 0.5794 - val_accuracy: 0.7626\n",
      "Epoch 432/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4966 - accuracy: 0.80\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4020 - accuracy: 0.8383 - val_loss: 0.4231 - val_accuracy: 0.8242\n",
      "Epoch 433/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3828 - accuracy: 0.84\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.3965 - accuracy: 0.8360 - val_loss: 0.6304 - val_accuracy: 0.7466\n",
      "Epoch 434/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6530 - accuracy: 0.71\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4168 - accuracy: 0.8497 - val_loss: 0.6804 - val_accuracy: 0.6963\n",
      "Epoch 435/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5118 - accuracy: 0.76\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4399 - accuracy: 0.8215 - val_loss: 0.4068 - val_accuracy: 0.8356\n",
      "Epoch 436/2000\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.3553 - accuracy: 0.86\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3954 - accuracy: 0.8490 - val_loss: 0.9629 - val_accuracy: 0.6849\n",
      "Epoch 437/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.4387 - accuracy: 0.82\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 0.4387 - accuracy: 0.8284 - val_loss: 0.3980 - val_accuracy: 0.8676\n",
      "Epoch 438/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3994 - accuracy: 0.84\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3994 - accuracy: 0.8467 - val_loss: 0.4526 - val_accuracy: 0.7648\n",
      "Epoch 439/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.3856 - accuracy: 0.82\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4087 - accuracy: 0.8314 - val_loss: 0.6622 - val_accuracy: 0.7237\n",
      "Epoch 440/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4100 - accuracy: 0.83\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.4127 - accuracy: 0.8314 - val_loss: 0.5718 - val_accuracy: 0.7329\n",
      "Epoch 441/2000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.4252 - accuracy: 0.83\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4252 - accuracy: 0.8307 - val_loss: 0.5703 - val_accuracy: 0.8037\n",
      "Epoch 442/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5097 - accuracy: 0.82\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3911 - accuracy: 0.8467 - val_loss: 0.4614 - val_accuracy: 0.8014\n",
      "Epoch 443/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4270 - accuracy: 0.84\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3962 - accuracy: 0.8436 - val_loss: 0.4821 - val_accuracy: 0.7900\n",
      "Epoch 444/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4212 - accuracy: 0.84\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4037 - accuracy: 0.8535 - val_loss: 0.5374 - val_accuracy: 0.7717\n",
      "Epoch 445/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4708 - accuracy: 0.83\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.3821 - accuracy: 0.8596 - val_loss: 0.5022 - val_accuracy: 0.7306\n",
      "Epoch 446/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5430 - accuracy: 0.68\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4338 - accuracy: 0.8330 - val_loss: 0.6016 - val_accuracy: 0.6895\n",
      "Epoch 447/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5170 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4005 - accuracy: 0.8452 - val_loss: 0.7136 - val_accuracy: 0.6872\n",
      "Epoch 448/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7944 - accuracy: 0.67\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4254 - accuracy: 0.8352 - val_loss: 0.5406 - val_accuracy: 0.7854\n",
      "Epoch 449/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4651 - accuracy: 0.80\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4057 - accuracy: 0.8375 - val_loss: 0.5470 - val_accuracy: 0.7808\n",
      "Epoch 450/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5930 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4262 - accuracy: 0.8299 - val_loss: 0.3828 - val_accuracy: 0.8653\n",
      "Epoch 451/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3798 - accuracy: 0.86\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3798 - accuracy: 0.8635 - val_loss: 0.4557 - val_accuracy: 0.7945\n",
      "Epoch 452/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4799 - accuracy: 0.76\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4061 - accuracy: 0.8337 - val_loss: 0.6322 - val_accuracy: 0.6963\n",
      "Epoch 453/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6525 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4160 - accuracy: 0.8612 - val_loss: 0.5344 - val_accuracy: 0.7283\n",
      "Epoch 454/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5264 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3969 - accuracy: 0.8474 - val_loss: 0.6572 - val_accuracy: 0.7443\n",
      "Epoch 455/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6510 - accuracy: 0.80\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4051 - accuracy: 0.8452 - val_loss: 0.4142 - val_accuracy: 0.8242\n",
      "Epoch 456/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4055 - accuracy: 0.81\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3886 - accuracy: 0.8551 - val_loss: 0.5064 - val_accuracy: 0.7763\n",
      "Epoch 457/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3884 - accuracy: 0.86\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3872 - accuracy: 0.8513 - val_loss: 0.5486 - val_accuracy: 0.7763\n",
      "Epoch 458/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5174 - accuracy: 0.79\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3911 - accuracy: 0.8558 - val_loss: 0.5721 - val_accuracy: 0.7968\n",
      "Epoch 459/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5510 - accuracy: 0.80\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4210 - accuracy: 0.8543 - val_loss: 0.5023 - val_accuracy: 0.7603\n",
      "Epoch 460/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.2980 - accuracy: 0.90\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3859 - accuracy: 0.8589 - val_loss: 0.6354 - val_accuracy: 0.7078\n",
      "Epoch 461/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5039 - accuracy: 0.78\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3989 - accuracy: 0.8436 - val_loss: 0.5409 - val_accuracy: 0.7694\n",
      "Epoch 462/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3958 - accuracy: 0.84\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3953 - accuracy: 0.8444 - val_loss: 0.5121 - val_accuracy: 0.7511\n",
      "Epoch 463/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4520 - accuracy: 0.78\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4075 - accuracy: 0.8352 - val_loss: 0.5488 - val_accuracy: 0.7420\n",
      "Epoch 464/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3991 - accuracy: 0.85\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4005 - accuracy: 0.8574 - val_loss: 0.4517 - val_accuracy: 0.7991\n",
      "Epoch 465/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3686 - accuracy: 0.85\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3706 - accuracy: 0.8490 - val_loss: 0.4866 - val_accuracy: 0.7808\n",
      "Epoch 466/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5649 - accuracy: 0.78\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3975 - accuracy: 0.8734 - val_loss: 0.4002 - val_accuracy: 0.8037\n",
      "Epoch 467/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3239 - accuracy: 0.88\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3728 - accuracy: 0.8619 - val_loss: 0.6336 - val_accuracy: 0.7420\n",
      "Epoch 468/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4935 - accuracy: 0.82\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4105 - accuracy: 0.8635 - val_loss: 0.5264 - val_accuracy: 0.7397\n",
      "Epoch 469/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4382 - accuracy: 0.81\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3716 - accuracy: 0.8505 - val_loss: 0.4927 - val_accuracy: 0.7945\n",
      "Epoch 470/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4379 - accuracy: 0.80\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3811 - accuracy: 0.8551 - val_loss: 0.6290 - val_accuracy: 0.7466\n",
      "Epoch 471/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4324 - accuracy: 0.85\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.4107 - accuracy: 0.8703 - val_loss: 0.6766 - val_accuracy: 0.7534\n",
      "Epoch 472/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.8724 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4023 - accuracy: 0.8604 - val_loss: 0.4230 - val_accuracy: 0.8242\n",
      "Epoch 473/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3674 - accuracy: 0.86\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3674 - accuracy: 0.8680 - val_loss: 0.7502 - val_accuracy: 0.6941\n",
      "Epoch 474/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.8093 - accuracy: 0.64\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4358 - accuracy: 0.8330 - val_loss: 0.7481 - val_accuracy: 0.6895\n",
      "Epoch 475/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.7067 - accuracy: 0.71\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3894 - accuracy: 0.8528 - val_loss: 0.5325 - val_accuracy: 0.7557\n",
      "Epoch 476/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4843 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3549 - accuracy: 0.8810 - val_loss: 0.5718 - val_accuracy: 0.7534\n",
      "Epoch 477/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5338 - accuracy: 0.78\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4021 - accuracy: 0.8474 - val_loss: 0.4686 - val_accuracy: 0.7922\n",
      "Epoch 478/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3780 - accuracy: 0.85\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3780 - accuracy: 0.8581 - val_loss: 0.6183 - val_accuracy: 0.7352\n",
      "Epoch 479/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4015 - accuracy: 0.85\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3919 - accuracy: 0.8535 - val_loss: 0.4444 - val_accuracy: 0.8151\n",
      "Epoch 480/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4786 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3505 - accuracy: 0.8749 - val_loss: 0.6418 - val_accuracy: 0.7397\n",
      "Epoch 481/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6448 - accuracy: 0.76\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4065 - accuracy: 0.8581 - val_loss: 0.6479 - val_accuracy: 0.7443\n",
      "Epoch 482/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6724 - accuracy: 0.72\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.4014 - accuracy: 0.8490 - val_loss: 0.4759 - val_accuracy: 0.8744\n",
      "Epoch 483/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3936 - accuracy: 0.89\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3705 - accuracy: 0.8604 - val_loss: 0.6623 - val_accuracy: 0.7511\n",
      "Epoch 484/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.8271 - accuracy: 0.69\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3873 - accuracy: 0.8741 - val_loss: 0.6064 - val_accuracy: 0.7671\n",
      "Epoch 485/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3772 - accuracy: 0.87\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 0.3648 - accuracy: 0.8802 - val_loss: 0.5970 - val_accuracy: 0.7717\n",
      "Epoch 486/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5192 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3787 - accuracy: 0.8474 - val_loss: 0.6690 - val_accuracy: 0.6575\n",
      "Epoch 487/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5809 - accuracy: 0.71\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3909 - accuracy: 0.8612 - val_loss: 0.5503 - val_accuracy: 0.7740\n",
      "Epoch 488/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5317 - accuracy: 0.80\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3716 - accuracy: 0.8604 - val_loss: 0.5684 - val_accuracy: 0.7603\n",
      "Epoch 489/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4613 - accuracy: 0.83\n",
      "14/14 [==============================] - 0s 38ms/step - loss: 0.3770 - accuracy: 0.8696 - val_loss: 0.6930 - val_accuracy: 0.6735\n",
      "Epoch 490/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6249 - accuracy: 0.71\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3937 - accuracy: 0.8604 - val_loss: 0.3912 - val_accuracy: 0.8333\n",
      "Epoch 491/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3776 - accuracy: 0.85\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3768 - accuracy: 0.8535 - val_loss: 0.5515 - val_accuracy: 0.7603\n",
      "Epoch 492/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3668 - accuracy: 0.87\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3668 - accuracy: 0.8726 - val_loss: 0.5373 - val_accuracy: 0.7808\n",
      "Epoch 493/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3805 - accuracy: 0.87\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.3983 - accuracy: 0.8467 - val_loss: 0.3416 - val_accuracy: 0.8790\n",
      "Epoch 494/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3402 - accuracy: 0.88\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3542 - accuracy: 0.8833 - val_loss: 0.5878 - val_accuracy: 0.7443\n",
      "Epoch 495/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5971 - accuracy: 0.76\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3802 - accuracy: 0.8658 - val_loss: 0.4702 - val_accuracy: 0.7854\n",
      "Epoch 496/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4332 - accuracy: 0.85\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3525 - accuracy: 0.8726 - val_loss: 0.4244 - val_accuracy: 0.8242\n",
      "Epoch 497/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3355 - accuracy: 0.88\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 0.3481 - accuracy: 0.8833 - val_loss: 0.5495 - val_accuracy: 0.8174\n",
      "Epoch 498/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5124 - accuracy: 0.82\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3942 - accuracy: 0.8825 - val_loss: 0.5485 - val_accuracy: 0.7603\n",
      "Epoch 499/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3674 - accuracy: 0.88\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.3689 - accuracy: 0.8780 - val_loss: 0.5059 - val_accuracy: 0.7945\n",
      "Epoch 500/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3677 - accuracy: 0.87\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3677 - accuracy: 0.8734 - val_loss: 0.4657 - val_accuracy: 0.7740\n",
      "Epoch 501/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3812 - accuracy: 0.86\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3812 - accuracy: 0.8635 - val_loss: 0.4411 - val_accuracy: 0.8288\n",
      "Epoch 502/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4236 - accuracy: 0.88\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3622 - accuracy: 0.8658 - val_loss: 0.4418 - val_accuracy: 0.7991\n",
      "Epoch 503/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3825 - accuracy: 0.86\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.3804 - accuracy: 0.8642 - val_loss: 0.4650 - val_accuracy: 0.8196\n",
      "Epoch 504/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3466 - accuracy: 0.89\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 0.3444 - accuracy: 0.8894 - val_loss: 0.3281 - val_accuracy: 0.8973\n",
      "Epoch 505/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3098 - accuracy: 0.89\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3530 - accuracy: 0.8848 - val_loss: 0.4412 - val_accuracy: 0.8105\n",
      "Epoch 506/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3413 - accuracy: 0.91\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3731 - accuracy: 0.8650 - val_loss: 0.4134 - val_accuracy: 0.8356\n",
      "Epoch 507/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3770 - accuracy: 0.87\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3449 - accuracy: 0.8764 - val_loss: 0.4636 - val_accuracy: 0.7991\n",
      "Epoch 508/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4402 - accuracy: 0.83\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3554 - accuracy: 0.8810 - val_loss: 0.4212 - val_accuracy: 0.7991\n",
      "Epoch 509/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4556 - accuracy: 0.75\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3424 - accuracy: 0.8787 - val_loss: 0.4150 - val_accuracy: 0.8151\n",
      "Epoch 510/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3741 - accuracy: 0.86\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3741 - accuracy: 0.8665 - val_loss: 0.6488 - val_accuracy: 0.7078\n",
      "Epoch 511/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6677 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3628 - accuracy: 0.8711 - val_loss: 0.6600 - val_accuracy: 0.7100\n",
      "Epoch 512/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6364 - accuracy: 0.74\n",
      "14/14 [==============================] - 0s 38ms/step - loss: 0.3603 - accuracy: 0.8924 - val_loss: 0.4671 - val_accuracy: 0.8128\n",
      "Epoch 513/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3611 - accuracy: 0.87\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.3603 - accuracy: 0.8734 - val_loss: 0.4346 - val_accuracy: 0.8059\n",
      "Epoch 514/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3380 - accuracy: 0.88\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3385 - accuracy: 0.8825 - val_loss: 0.6945 - val_accuracy: 0.7123\n",
      "Epoch 515/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3919 - accuracy: 0.87\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.3842 - accuracy: 0.8741 - val_loss: 0.4929 - val_accuracy: 0.8059\n",
      "Epoch 516/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3601 - accuracy: 0.88\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3599 - accuracy: 0.8871 - val_loss: 0.3951 - val_accuracy: 0.8447\n",
      "Epoch 517/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3406 - accuracy: 0.89\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3422 - accuracy: 0.8940 - val_loss: 0.5207 - val_accuracy: 0.7968\n",
      "Epoch 518/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3617 - accuracy: 0.88\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3624 - accuracy: 0.8818 - val_loss: 0.4280 - val_accuracy: 0.8265\n",
      "Epoch 519/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3551 - accuracy: 0.87\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3550 - accuracy: 0.8795 - val_loss: 0.4351 - val_accuracy: 0.8356\n",
      "Epoch 520/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3563 - accuracy: 0.87\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3561 - accuracy: 0.8780 - val_loss: 0.4498 - val_accuracy: 0.8265\n",
      "Epoch 521/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3578 - accuracy: 0.88\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3568 - accuracy: 0.8871 - val_loss: 0.3883 - val_accuracy: 0.8607\n",
      "Epoch 522/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3816 - accuracy: 0.88\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3808 - accuracy: 0.8818 - val_loss: 0.4506 - val_accuracy: 0.7900\n",
      "Epoch 523/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3418 - accuracy: 0.88\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3408 - accuracy: 0.8879 - val_loss: 0.4239 - val_accuracy: 0.8493\n",
      "Epoch 524/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3789 - accuracy: 0.88\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3784 - accuracy: 0.8848 - val_loss: 0.3689 - val_accuracy: 0.8881\n",
      "Epoch 525/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3317 - accuracy: 0.90\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3292 - accuracy: 0.9016 - val_loss: 0.4210 - val_accuracy: 0.7945\n",
      "Epoch 526/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3526 - accuracy: 0.87\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3522 - accuracy: 0.8802 - val_loss: 0.4256 - val_accuracy: 0.7968\n",
      "Epoch 527/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3328 - accuracy: 0.89\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 0.3359 - accuracy: 0.8932 - val_loss: 0.6081 - val_accuracy: 0.7763\n",
      "Epoch 528/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3604 - accuracy: 0.89\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3597 - accuracy: 0.8955 - val_loss: 0.6113 - val_accuracy: 0.7922\n",
      "Epoch 529/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3787 - accuracy: 0.87\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.3800 - accuracy: 0.8787 - val_loss: 0.6067 - val_accuracy: 0.7648\n",
      "Epoch 530/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3476 - accuracy: 0.89\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3481 - accuracy: 0.8947 - val_loss: 0.5049 - val_accuracy: 0.8059\n",
      "Epoch 531/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3520 - accuracy: 0.87\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3505 - accuracy: 0.8795 - val_loss: 0.3957 - val_accuracy: 0.8402\n",
      "Epoch 532/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3210 - accuracy: 0.88\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3195 - accuracy: 0.8894 - val_loss: 0.3049 - val_accuracy: 0.9384\n",
      "Epoch 533/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3411 - accuracy: 0.89\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.3353 - accuracy: 0.8963 - val_loss: 0.4713 - val_accuracy: 0.8653\n",
      "Epoch 534/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3661 - accuracy: 0.87\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.3661 - accuracy: 0.8757 - val_loss: 0.6288 - val_accuracy: 0.7671\n",
      "Epoch 535/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3544 - accuracy: 0.90\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3544 - accuracy: 0.8986 - val_loss: 0.5345 - val_accuracy: 0.8174\n",
      "Epoch 536/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4523 - accuracy: 0.86\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3145 - accuracy: 0.9024 - val_loss: 0.4454 - val_accuracy: 0.7831\n",
      "Epoch 537/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3465 - accuracy: 0.88\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.3469 - accuracy: 0.8833 - val_loss: 0.5457 - val_accuracy: 0.7374\n",
      "Epoch 538/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5128 - accuracy: 0.75\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3477 - accuracy: 0.8886 - val_loss: 0.3637 - val_accuracy: 0.8470\n",
      "Epoch 539/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3320 - accuracy: 0.84\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3234 - accuracy: 0.8947 - val_loss: 0.4725 - val_accuracy: 0.7534\n",
      "Epoch 540/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5207 - accuracy: 0.72\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3471 - accuracy: 0.8749 - val_loss: 0.3264 - val_accuracy: 0.9018\n",
      "Epoch 541/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.2577 - accuracy: 0.98\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3115 - accuracy: 0.9016 - val_loss: 0.5589 - val_accuracy: 0.8128\n",
      "Epoch 542/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6243 - accuracy: 0.73\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3518 - accuracy: 0.8940 - val_loss: 0.5160 - val_accuracy: 0.8311\n",
      "Epoch 543/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5480 - accuracy: 0.81\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3476 - accuracy: 0.8886 - val_loss: 0.2926 - val_accuracy: 0.9201\n",
      "Epoch 544/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.2907 - accuracy: 0.90\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.3294 - accuracy: 0.9039 - val_loss: 0.4777 - val_accuracy: 0.7717\n",
      "Epoch 545/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4494 - accuracy: 0.81\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3531 - accuracy: 0.8871 - val_loss: 0.4211 - val_accuracy: 0.8037\n",
      "Epoch 546/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3068 - accuracy: 0.91\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3298 - accuracy: 0.8986 - val_loss: 0.3065 - val_accuracy: 0.9178\n",
      "Epoch 547/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.2992 - accuracy: 0.89\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2947 - accuracy: 0.9123 - val_loss: 0.7113 - val_accuracy: 0.7306\n",
      "Epoch 548/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3733 - accuracy: 0.87\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 0.3727 - accuracy: 0.8795 - val_loss: 0.5652 - val_accuracy: 0.8311\n",
      "Epoch 549/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3412 - accuracy: 0.90\n",
      "14/14 [==============================] - 0s 37ms/step - loss: 0.3410 - accuracy: 0.9062 - val_loss: 0.4758 - val_accuracy: 0.8082\n",
      "Epoch 550/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3569 - accuracy: 0.87\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3557 - accuracy: 0.8726 - val_loss: 0.4257 - val_accuracy: 0.8516\n",
      "Epoch 551/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3116 - accuracy: 0.89\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3116 - accuracy: 0.8978 - val_loss: 0.4779 - val_accuracy: 0.8219\n",
      "Epoch 552/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3003 - accuracy: 0.91\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.2997 - accuracy: 0.9169 - val_loss: 0.5226 - val_accuracy: 0.7968\n",
      "Epoch 553/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3297 - accuracy: 0.89\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3297 - accuracy: 0.8963 - val_loss: 0.3833 - val_accuracy: 0.8995\n",
      "Epoch 554/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3139 - accuracy: 0.90\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3139 - accuracy: 0.9069 - val_loss: 0.5937 - val_accuracy: 0.8014\n",
      "Epoch 555/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3397 - accuracy: 0.91\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3397 - accuracy: 0.9115 - val_loss: 0.7176 - val_accuracy: 0.7100\n",
      "Epoch 556/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3505 - accuracy: 0.90\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3505 - accuracy: 0.9001 - val_loss: 0.4754 - val_accuracy: 0.7991\n",
      "Epoch 557/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3619 - accuracy: 0.86\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3034 - accuracy: 0.9130 - val_loss: 0.3151 - val_accuracy: 0.9589\n",
      "Epoch 558/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.2060 - accuracy: 0.99\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3181 - accuracy: 0.9069 - val_loss: 0.5714 - val_accuracy: 0.7580\n",
      "Epoch 559/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4214 - accuracy: 0.82\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3270 - accuracy: 0.9016 - val_loss: 0.2844 - val_accuracy: 0.9338\n",
      "Epoch 560/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3149 - accuracy: 0.91\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3410 - accuracy: 0.9008 - val_loss: 0.4256 - val_accuracy: 0.8311\n",
      "Epoch 561/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4978 - accuracy: 0.82\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3117 - accuracy: 0.9024 - val_loss: 0.3402 - val_accuracy: 0.8470\n",
      "Epoch 562/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3098 - accuracy: 0.89\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.3098 - accuracy: 0.8909 - val_loss: 0.6703 - val_accuracy: 0.7397\n",
      "Epoch 563/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3394 - accuracy: 0.89\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3394 - accuracy: 0.8993 - val_loss: 0.3487 - val_accuracy: 0.9201\n",
      "Epoch 564/2000\n",
      "2/2 [==============================] - 0s 1ms/step loss: 0.2739 - accuracy: 0.94\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2909 - accuracy: 0.9184 - val_loss: 0.5398 - val_accuracy: 0.8105\n",
      "Epoch 565/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4930 - accuracy: 0.80\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3128 - accuracy: 0.9062 - val_loss: 0.3570 - val_accuracy: 0.8562\n",
      "Epoch 566/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3210 - accuracy: 0.85\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3603 - accuracy: 0.8940 - val_loss: 0.3239 - val_accuracy: 0.9087\n",
      "Epoch 567/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3072 - accuracy: 0.91\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2749 - accuracy: 0.9199 - val_loss: 0.5723 - val_accuracy: 0.7808\n",
      "Epoch 568/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5766 - accuracy: 0.76\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3180 - accuracy: 0.8932 - val_loss: 0.2820 - val_accuracy: 0.9087\n",
      "Epoch 569/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3402 - accuracy: 0.84\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3053 - accuracy: 0.9016 - val_loss: 0.2809 - val_accuracy: 0.9064\n",
      "Epoch 570/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3317 - accuracy: 0.91\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3317 - accuracy: 0.9108 - val_loss: 0.3479 - val_accuracy: 0.8653\n",
      "Epoch 571/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3424 - accuracy: 0.90\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.3430 - accuracy: 0.9001 - val_loss: 0.3823 - val_accuracy: 0.8744\n",
      "Epoch 572/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3770 - accuracy: 0.87\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3035 - accuracy: 0.9230 - val_loss: 0.4270 - val_accuracy: 0.8311\n",
      "Epoch 573/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3203 - accuracy: 0.89\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3203 - accuracy: 0.8932 - val_loss: 0.3970 - val_accuracy: 0.8995\n",
      "Epoch 574/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3066 - accuracy: 0.92\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.3066 - accuracy: 0.9207 - val_loss: 0.5107 - val_accuracy: 0.8014\n",
      "Epoch 575/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4139 - accuracy: 0.82\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3029 - accuracy: 0.9123 - val_loss: 0.2612 - val_accuracy: 0.9429\n",
      "Epoch 576/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3049 - accuracy: 0.91\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.3054 - accuracy: 0.9138 - val_loss: 0.5216 - val_accuracy: 0.7740\n",
      "Epoch 577/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6545 - accuracy: 0.70\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3387 - accuracy: 0.8932 - val_loss: 0.3210 - val_accuracy: 0.8973\n",
      "Epoch 578/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3053 - accuracy: 0.90\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3244 - accuracy: 0.9016 - val_loss: 0.3921 - val_accuracy: 0.8653\n",
      "Epoch 579/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3454 - accuracy: 0.90\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2980 - accuracy: 0.9123 - val_loss: 0.2847 - val_accuracy: 0.9338\n",
      "Epoch 580/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.2292 - accuracy: 0.94\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2970 - accuracy: 0.9069 - val_loss: 0.4312 - val_accuracy: 0.8037\n",
      "Epoch 581/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4438 - accuracy: 0.82\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2981 - accuracy: 0.9199 - val_loss: 0.2965 - val_accuracy: 0.9132\n",
      "Epoch 582/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.2933 - accuracy: 0.91\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2922 - accuracy: 0.9077 - val_loss: 0.3157 - val_accuracy: 0.8927\n",
      "Epoch 583/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.2909 - accuracy: 0.91\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2996 - accuracy: 0.9153 - val_loss: 0.4705 - val_accuracy: 0.8470\n",
      "Epoch 584/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.2897 - accuracy: 0.94\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3239 - accuracy: 0.9191 - val_loss: 0.3279 - val_accuracy: 0.8927\n",
      "Epoch 585/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.2884 - accuracy: 0.90\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2946 - accuracy: 0.9016 - val_loss: 0.5227 - val_accuracy: 0.7785\n",
      "Epoch 586/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4332 - accuracy: 0.85\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3162 - accuracy: 0.9207 - val_loss: 0.4353 - val_accuracy: 0.8653\n",
      "Epoch 587/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.2886 - accuracy: 0.91\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.2886 - accuracy: 0.9100 - val_loss: 0.4129 - val_accuracy: 0.8470\n",
      "Epoch 588/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.2850 - accuracy: 0.91\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2923 - accuracy: 0.9176 - val_loss: 0.3120 - val_accuracy: 0.8995\n",
      "Epoch 589/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.2694 - accuracy: 0.91\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2689 - accuracy: 0.9146 - val_loss: 0.5024 - val_accuracy: 0.8539\n",
      "Epoch 590/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5632 - accuracy: 0.86\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3109 - accuracy: 0.9214 - val_loss: 0.3567 - val_accuracy: 0.8744\n",
      "Epoch 591/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4431 - accuracy: 0.78\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3252 - accuracy: 0.8932 - val_loss: 0.2856 - val_accuracy: 0.9132\n",
      "Epoch 592/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3327 - accuracy: 0.86\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2864 - accuracy: 0.9169 - val_loss: 0.3053 - val_accuracy: 0.9155\n",
      "Epoch 593/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3381 - accuracy: 0.89\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2779 - accuracy: 0.9199 - val_loss: 0.4000 - val_accuracy: 0.8447\n",
      "Epoch 594/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4283 - accuracy: 0.87\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3222 - accuracy: 0.9008 - val_loss: 0.3672 - val_accuracy: 0.8516\n",
      "Epoch 595/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3776 - accuracy: 0.84\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2966 - accuracy: 0.9222 - val_loss: 0.3295 - val_accuracy: 0.8904\n",
      "Epoch 596/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.2760 - accuracy: 0.91\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2735 - accuracy: 0.9153 - val_loss: 0.2559 - val_accuracy: 0.9269\n",
      "Epoch 597/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.2906 - accuracy: 0.93\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2774 - accuracy: 0.9344 - val_loss: 0.3039 - val_accuracy: 0.9064\n",
      "Epoch 598/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.2999 - accuracy: 0.90\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2926 - accuracy: 0.9161 - val_loss: 0.4210 - val_accuracy: 0.8904\n",
      "Epoch 599/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3738 - accuracy: 0.91\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2759 - accuracy: 0.9306 - val_loss: 0.3057 - val_accuracy: 0.8904\n",
      "Epoch 600/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3036 - accuracy: 0.89\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.3046 - accuracy: 0.9077 - val_loss: 0.3804 - val_accuracy: 0.8288\n",
      "Epoch 601/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.2673 - accuracy: 0.92\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2673 - accuracy: 0.9283 - val_loss: 0.6636 - val_accuracy: 0.7443\n",
      "Epoch 602/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3271 - accuracy: 0.91\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3271 - accuracy: 0.9184 - val_loss: 0.4086 - val_accuracy: 0.8493\n",
      "Epoch 603/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.2561 - accuracy: 0.93\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.2496 - accuracy: 0.9352 - val_loss: 0.3483 - val_accuracy: 0.8927\n",
      "Epoch 604/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.2882 - accuracy: 0.92\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2882 - accuracy: 0.9214 - val_loss: 0.3458 - val_accuracy: 0.8470\n",
      "Epoch 605/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3004 - accuracy: 0.90\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2892 - accuracy: 0.9169 - val_loss: 0.4777 - val_accuracy: 0.8516\n",
      "Epoch 606/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5075 - accuracy: 0.79\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2921 - accuracy: 0.9153 - val_loss: 0.2965 - val_accuracy: 0.9018\n",
      "Epoch 607/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3024 - accuracy: 0.89\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3088 - accuracy: 0.9016 - val_loss: 0.4771 - val_accuracy: 0.8447\n",
      "Epoch 608/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.2724 - accuracy: 0.94\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2724 - accuracy: 0.9405 - val_loss: 0.4068 - val_accuracy: 0.8790\n",
      "Epoch 609/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3600 - accuracy: 0.85\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2841 - accuracy: 0.9153 - val_loss: 0.7148 - val_accuracy: 0.7420\n",
      "Epoch 610/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3403 - accuracy: 0.90\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3209 - accuracy: 0.9138 - val_loss: 0.4259 - val_accuracy: 0.8607\n",
      "Epoch 611/2000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3300 - accuracy: 0.90\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2604 - accuracy: 0.9291 - val_loss: 0.4646 - val_accuracy: 0.8196\n",
      "Epoch 612/2000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5554 - accuracy: 0.77\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2893 - accuracy: 0.9146 - val_loss: 0.4259 - val_accuracy: 0.8425\n",
      "Epoch 613/2000\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.3047 - accuracy: 0.9142"
     ]
    }
   ],
   "source": [
    "early_stop=tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=200, verbose=2, mode='auto', baseline=None, restore_best_weights=True)\n",
    "model.fit(X_train_def, y_train_def, epochs=numero_epochs, batch_size=100, callbacks=[tensorboard_callback,cm_callback,early_stop], validation_data=(X_val_def, y_val_def))\n",
    "# Final evaluation of the model \n",
    "scores = model.evaluate(X_test_def, y_test_def, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "(39, 2)\n",
      "(39,)\n",
      "(39,)\n",
      "[0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 0 0 1 1\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "#y_pred2=np.where(y_pred>0,1,0)\n",
    "#y_pred2=y_pred2[:,-1]\n",
    "y_test_def2=np.argmax(y_test_def,axis=1)\n",
    "#y_test_def2=np.where(y_test_def>0,1,0)\n",
    "print(y_pred.shape)\n",
    "print(y_pred2.shape)\n",
    "print(y_test_def2.shape)\n",
    "#print(y_test_def[25])\n",
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#docs_infra: no_execute\n",
    "if numero_clases==2:\n",
    "    classes = [0, 1]\n",
    "else:   \n",
    "    classes = [0, 1, 2, 3, 4]\n",
    "#classes = [0, 1]\n",
    "cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Buenos     0.7143    0.5172    0.6000        29\n",
      "       Malos     0.2222    0.4000    0.2857        10\n",
      "\n",
      "    accuracy                         0.4872        39\n",
      "   macro avg     0.4683    0.4586    0.4429        39\n",
      "weighted avg     0.5881    0.4872    0.5194        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "if numero_clases==2:\n",
    "    target_names = ['Buenos', 'Malos']\n",
    "else:   \n",
    "    target_names = ['A', 'B+', 'B', 'B-','C']\n",
    "print(classification_report(y_test_def2, y_pred2, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('modelos/modelote1203_200')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('idea.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "model.save('modelos\\modelo_perfecto_{}_{}.h5'.format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "\n",
    "existing_file='RESULTADOS_EXCEL\\clasificacion_39_AGILENT_def.xlsx'\n",
    "\n",
    "# Verifica si el archivo existe y si está vacío\n",
    "if not os.path.exists(existing_file) or os.path.getsize(existing_file) == 0:\n",
    "    df_inicial=pd.DataFrame(y_test_def2, columns=[\"target\"])\n",
    "    df_inicial.to_excel(existing_file, index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte los arrays a DataFrames\n",
    "df_new = pd.DataFrame(y_pred2, columns=[experimento])\n",
    "# Read existing data\n",
    "df_existing = pd.read_excel(existing_file)\n",
    "# Append new data\n",
    "df_combined=pd.concat([df_existing, df_new], axis=1)\n",
    "\n",
    "# Guarda los DataFrames en archivos Excel\n",
    "df_combined.to_excel(existing_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#este modo de guardar no funciona en esta version de tensorflow\n",
    "#model.save('modelos\\modelo_perfecto_{}_{}'.format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n",
      "[0 0 0 0 1 1 0 1 0]\n",
      "[0 0 0 0 1 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "n = len(y_pred2)\n",
    "reshaped = y_pred2[:n//4*4].reshape(-1, 4)\n",
    "mean_values = reshaped.mean(axis=1)\n",
    "\n",
    "mean_values = np.round(mean_values)\n",
    "mean_values = np.clip(mean_values, 0, 4)\n",
    "mean_values = mean_values.astype(int)\n",
    "print(mean_values)\n",
    "\n",
    "mode_values = stats.mode(reshaped, axis=1)[0]\n",
    "print(mode_values)\n",
    "\n",
    "# Convierte los arrays a DataFrames\n",
    "mean_df = pd.DataFrame(mean_values, columns=['mean'])\n",
    "mode_df = pd.DataFrame(mode_values, columns=['mode'])\n",
    "\n",
    "# Guarda los DataFrames en archivos Excel\n",
    "mean_df.to_excel(\"excels_borrar\\clasificacion_P1P2_mean_best7.xlsx\", index=False)\n",
    "mode_df.to_excel(\"excels_borrar\\clasificacion_P1_mode_best7.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 0 0 1 1\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 220, 8)\n",
      "(200, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 8 features, but StandardScaler is expecting 2 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 57\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# print(X_train_filtrado[0][:,:])\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# # # Vamos a normalizar o escalar los datos\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# concatenamos train y test\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m#scaler = MinMaxScaler(feature_range=(0, 1))\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\u001b[39;00m\n\u001b[0;32m     56\u001b[0m data_2d_test \u001b[38;5;241m=\u001b[39m X_test2_filtrado\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, X_test2_filtrado\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 57\u001b[0m normalized_data_2d_test \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_2d_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m X_test2_def\u001b[38;5;241m=\u001b[39mnormalized_data_2d_test\u001b[38;5;241m.\u001b[39mreshape(X_test2_filtrado\u001b[38;5;241m.\u001b[39mshape) \n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# la alternativa es normalizar con el total\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1004\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1001\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1003\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1004\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\sklearn\\base.py:625\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 625\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\sklearn\\base.py:414\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 8 features, but StandardScaler is expecting 2 features as input."
     ]
    }
   ],
   "source": [
    "filename5 = \"COPIA_PANDAS\\lomosP1_20240430_clasificado_experto.hdf\"\n",
    "with pd.HDFStore(filename5,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e2  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e2 = pre_p_e2.loc[pre_p_e2['Pollo'] != 0]\n",
    "    pre_p_e2 =pre_p_e2.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_test2=np.zeros((pre_p_e2.shape[0],220,8))\n",
    "    y_test2=np.zeros((pre_p_e2.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e2.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1:\n",
    "                target = 0 \n",
    "            else:\n",
    "                target = 1\n",
    "\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_test2[x]=pepito[:,3:4]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_test2[x]=target\n",
    "        y_test2_to_categorical = to_categorical(y_test2)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_test2_filtrado = X_test2\n",
    "#y_train_filtrado = y_train\n",
    "y_test2_filtrado = y_test2_to_categorical\n",
    "\n",
    "print(X_test2_filtrado.shape)\n",
    "print(y_test2_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "# concatenamos train y test\n",
    "#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\n",
    "data_2d_test = X_test2_filtrado.reshape(-1, X_test2_filtrado.shape[-1])\n",
    "normalized_data_2d_test = scaler.transform(data_2d_test)\n",
    "\n",
    "\n",
    "X_test2_def=normalized_data_2d_test.reshape(X_test2_filtrado.shape) \n",
    "# la alternativa es normalizar con el total\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "\n",
    "y_test2_def=y_test2_filtrado # los valores ya estaban normalizados\n",
    "\n",
    "print(y_test2_def.shape)\n",
    "\n",
    "print(y_test2_filtrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# # Crear un nuevo modelo con la misma arquitectura\n",
    "# best_val_model = create_model()  # Reemplaza esto con la función que usaste para crear el modelo original\n",
    "\n",
    "# # Cargar los mejores pesos\n",
    "# best_val_model.load_weights('best_weights.h5')\n",
    "\n",
    "y_pred = model.predict(X_test2_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "n = len(y_pred2)\n",
    "print(n)\n",
    "reshaped = y_pred2[:n//4*4].reshape(-1, 4)\n",
    "mean_values = reshaped.mean(axis=1)\n",
    "\n",
    "mean_values = np.round(mean_values)\n",
    "mean_values = np.clip(mean_values, 0, 4)\n",
    "mean_values = mean_values.astype(int)\n",
    "print(mean_values.shape)\n",
    "\n",
    "mode_values = stats.mode(reshaped, axis=1)[0]\n",
    "print(mode_values.shape)\n",
    "\n",
    "n = len(y_test2_def)\n",
    "y_test2_def2=np.argmax(y_test2_def,axis=1)\n",
    "print(y_test_def2.shape)\n",
    "print(n)\n",
    "reshaped2 = y_test2_def2[:n//4*4].reshape(-1, 4)\n",
    "target_mean_values = reshaped2.mean(axis=1)\n",
    "\n",
    "target_mean_values = np.round(target_mean_values)\n",
    "target_mean_values = np.clip(target_mean_values, 0, 4)\n",
    "target_mean_values = target_mean_values.astype(int)\n",
    "print(target_mean_values.shape)\n",
    "\n",
    "target_mode_values = stats.mode(reshaped2, axis=1)[0]\n",
    "print(target_mode_values.shape)\n",
    "print(reshaped)\n",
    "print(mode_values)\n",
    "print(target_mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs_infra: no_execute\n",
    "if numero_clases==2:\n",
    "    classes = [0, 1]    \n",
    "else:\n",
    "\n",
    "    classes = [0, 1, 2, 3, 4]\n",
    "#classes = [0, 1]\n",
    "cm=confusion_matrix(target_mode_values, mode_values,labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm.diagonal()/cm.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if numero_clases==2:\n",
    "    target_names= ['Buenos', 'Malos']\n",
    "else:\n",
    "    target_names= ['A', 'B+', 'B', 'B-','C']\n",
    "print(classification_report(target_mode_values, mode_values, target_names=target_names, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
