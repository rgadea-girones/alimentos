{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:\\nuevas_investigaciones_alimentos_2024\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM,Bidirectional,GRU\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import datetime\n",
    "import io\n",
    "import itertools\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Obtener la ruta del directorio actual\n",
    "os.chdir('..')\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "# Construir la ruta relativa al directorio que quieres agregar\n",
    "relative_dir = os.path.join(current_dir, 'mis_pkgs/')\n",
    "\n",
    "# Agregar la ruta relativa al sys.path\n",
    "sys.path.insert(0, relative_dir)\n",
    "\n",
    "from MIOPATIA_db import DB_management as db \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_muestras=220\n",
    "numero_clases=2\n",
    "entrada=slice(7 ,9)\n",
    "numero_entradas = entrada.stop - entrada.start\n",
    "numero_epochs=200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a quedarme con los 50 atunes P1 para obtener conjunto de training y validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Add, Activation, Concatenate, Conv2D, Dropout \n",
    "from tensorflow.keras.layers import Flatten, Input, GlobalAveragePooling2D, MaxPooling2D\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "__version__ = '0.0.1'\n",
    "\n",
    "\n",
    "def SqueezeNet(input_shape, nb_classes, use_bypass=False, dropout_rate=None, compression=1.0):\n",
    "    \"\"\"\n",
    "    Creating a SqueezeNet of version 1.0\n",
    "    \n",
    "    Arguments:\n",
    "        input_shape  : shape of the input images e.g. (224,224,3)\n",
    "        nb_classes   : number of classes\n",
    "        use_bypass   : if true, bypass connections will be created at fire module 3, 5, 7, and 9 (default: False)\n",
    "        dropout_rate : defines the dropout rate that is accomplished after last fire module (default: None)\n",
    "        compression  : reduce the number of feature-maps (default: 1.0)\n",
    "        \n",
    "    Returns:\n",
    "        Model        : Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(int(96*compression), (7,7), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "    x = create_fire_module(x, int(16*compression), name='fire3', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool4')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(32*compression), name='fire5', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "    x = create_fire_module(x, int(48*compression), name='fire7', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool8')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(64*compression), name='fire9', use_bypass=use_bypass)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        \n",
    "    x = output(x, nb_classes)\n",
    "\n",
    "    return Model(inputs=input_img, outputs=x)\n",
    "\n",
    "\n",
    "def SqueezeNet_11(input_shape, nb_classes, dropout_rate=None, compression=1.0):\n",
    "    \"\"\"\n",
    "    Creating a SqueezeNet of version 1.1\n",
    "    \n",
    "    2.4x less computation over SqueezeNet 1.0 implemented above.\n",
    "    \n",
    "    Arguments:\n",
    "        input_shape  : shape of the input images e.g. (224,224,3)\n",
    "        nb_classes   : number of classes\n",
    "        dropout_rate : defines the dropout rate that is accomplished after last fire module (default: None)\n",
    "        compression  : reduce the number of feature-maps\n",
    "        \n",
    "    Returns:\n",
    "        Model        : Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(int(64*compression), (3,3), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "    x = create_fire_module(x, int(16*compression), name='fire3')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool3')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "    x = create_fire_module(x, int(32*compression), name='fire5')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool5')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "    x = create_fire_module(x, int(48*compression), name='fire7')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire9')\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # Creating last conv10\n",
    "    x = output(x, nb_classes)\n",
    "\n",
    "    return Model(inputs=input_img, outputs=x)\n",
    "\n",
    "\n",
    "def output(x, nb_classes):\n",
    "    x = Conv2D(nb_classes, (1,1), strides=(1,1), padding='valid', name='conv10')(x)\n",
    "    x = GlobalAveragePooling2D(name='avgpool10')(x)\n",
    "    x = Activation(\"softmax\", name='softmax')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_fire_module(x, nb_squeeze_filter, name, use_bypass=False):\n",
    "    \"\"\"\n",
    "    Creates a fire module\n",
    "    \n",
    "    Arguments:\n",
    "        x                 : input\n",
    "        nb_squeeze_filter : number of filters of squeeze. The filtersize of expand is 4 times of squeeze\n",
    "        use_bypass        : if True then a bypass will be added\n",
    "        name              : name of module e.g. fire123\n",
    "    \n",
    "    Returns:\n",
    "        x                 : returns a fire module\n",
    "    \"\"\"\n",
    "    \n",
    "    nb_expand_filter = 4 * nb_squeeze_filter\n",
    "    squeeze    = Conv2D(nb_squeeze_filter,(1,1), activation='relu', padding='same', name='%s_squeeze'%name)(x)\n",
    "    expand_1x1 = Conv2D(nb_expand_filter, (1,1), activation='relu', padding='same', name='%s_expand_1x1'%name)(squeeze)\n",
    "    expand_3x3 = Conv2D(nb_expand_filter, (3,3), activation='relu', padding='same', name='%s_expand_3x3'%name)(squeeze)\n",
    "    \n",
    "    axis = get_axis()\n",
    "    x_ret = Concatenate(axis=axis, name='%s_concatenate'%name)([expand_1x1, expand_3x3])\n",
    "    \n",
    "    if use_bypass:\n",
    "        x_ret = Add(name='%s_concatenate_bypass'%name)([x_ret, x])\n",
    "        \n",
    "    return x_ret\n",
    "\n",
    "\n",
    "def get_axis():\n",
    "    axis = -1 if K.image_data_format() == 'channels_last' else 1\n",
    "    return axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6336, 2)\n"
     ]
    }
   ],
   "source": [
    "filename = \"COPIA_PANDAS\\lomosP1P2_20240430_clasificado_experto_filtrado_total_trainval_ampliado_meditado.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    # p_e =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_train=np.zeros((pre_p_e1.shape[0],numero_muestras,numero_entradas))\n",
    "    y_train=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1 or estado== 2:\n",
    "                target = 0\n",
    "            else:\n",
    "                target = 1\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_train[x]=pepito[:,entrada]\n",
    "        #X_train[x]=X_train[x].reshape(X_train[x].shape[0],-1)\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_train[x]=target\n",
    "        y_train_to_categorical = to_categorical(y_train)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_train_filtrado = X_train\n",
    "#y_train_filtrado = y_train\n",
    "y_train_filtrado = y_train_to_categorical\n",
    "\n",
    "# print(X_train_filtrado.shape)\n",
    "# print(y_train_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "scaler = StandardScaler()\n",
    "data_2d = X_train_filtrado.reshape(-1, X_train_filtrado.shape[-1])\n",
    "normalized_data_2d = scaler.fit_transform(data_2d)\n",
    "#para recurrentes\n",
    "#X_train_Normalizado=normalized_data_2d.reshape(X_train_filtrado.shape) #para recurrentes\n",
    "#para densas\n",
    "X_train_Normalizado=normalized_data_2d.reshape(X_train_filtrado.shape[0],-1)\n",
    "y_train_Normalizado=y_train_filtrado # los valores ya estaban normalizados\n",
    "print(y_train_Normalizado.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71, 220, 2)\n",
      "(71, 2)\n",
      "[ 2.89885164e+00 -1.31244727e+00  2.79779759e+00 -1.32487254e+00\n",
      "  2.69703354e+00 -1.33705255e+00  2.59472548e+00 -1.34214028e+00\n",
      "  2.48079991e+00 -1.35868228e+00  2.41257120e+00 -1.38753693e+00\n",
      "  2.31436900e+00 -1.36262883e+00  2.23165916e+00 -1.37822236e+00\n",
      "  2.13296372e+00 -1.39006703e+00  2.04768086e+00 -1.39535246e+00\n",
      "  1.97291500e+00 -1.40532271e+00  1.88807398e+00 -1.41478994e+00\n",
      "  1.80020156e+00 -1.42173457e+00  1.72349870e+00 -1.42979535e+00\n",
      "  1.64591108e+00 -1.43665240e+00  1.58192027e+00 -1.44733338e+00\n",
      "  1.50901012e+00 -1.45611740e+00  1.44194216e+00 -1.46230626e+00\n",
      "  1.37688338e+00 -1.47266691e+00  1.31392872e+00 -1.47892584e+00\n",
      "  1.25170124e+00 -1.48596307e+00  1.19133679e+00 -1.49158885e+00\n",
      "  1.13335338e+00 -1.49613352e+00  1.07693604e+00 -1.50148903e+00\n",
      "  1.02595611e+00 -1.50990518e+00  9.76874053e-01 -1.51947751e+00\n",
      "  9.25665642e-01 -1.52493562e+00  8.78202995e-01 -1.53143730e+00\n",
      "  8.34140830e-01 -1.53892500e+00  7.88894896e-01 -1.54306350e+00\n",
      "  7.47901979e-01 -1.55061226e+00  7.05976125e-01 -1.55453454e+00\n",
      "  6.65653658e-01 -1.55726184e+00  6.28502408e-01 -1.56328753e+00\n",
      "  5.93175600e-01 -1.56955898e+00  5.56570442e-01 -1.57013832e+00\n",
      "  5.26151186e-01 -1.58149925e+00  4.91329926e-01 -1.58040963e+00\n",
      "  4.59401655e-01 -1.58407690e+00  4.32592077e-01 -1.59448935e+00\n",
      "  4.04781528e-01 -1.59562501e+00  3.78148360e-01 -1.60145801e+00\n",
      "  3.52636248e-01 -1.60527618e+00  3.27900489e-01 -1.60883008e+00\n",
      "  3.04371464e-01 -1.61121954e+00  2.81349316e-01 -1.61432398e+00\n",
      "  2.59672142e-01 -1.61634205e+00  2.38740417e-01 -1.61902756e+00\n",
      "  2.18167188e-01 -1.62071279e+00  1.98966331e-01 -1.62229967e+00\n",
      "  1.80714036e-01 -1.62374266e+00  1.62934998e-01 -1.62523019e+00\n",
      "  1.45860419e-01 -1.62632231e+00  1.29578493e-01 -1.62714691e+00\n",
      "  1.14079586e-01 -1.62747499e+00  9.90972831e-02 -1.62807486e+00\n",
      "  8.49028746e-02 -1.62823577e+00  7.11793132e-02 -1.62841446e+00\n",
      "  5.78370774e-02 -1.62872277e+00  4.54016720e-02 -1.62860390e+00\n",
      "  3.34365782e-02 -1.62811490e+00  2.19968361e-02 -1.62748225e+00\n",
      "  1.10243733e-02 -1.62659809e+00  3.81220015e-04 -1.62562859e+00\n",
      " -9.77084701e-03 -1.62431650e+00 -1.97259713e-02 -1.62049657e+00\n",
      " -2.90812919e-02 -1.62137447e+00 -3.81108216e-02 -1.61990571e+00\n",
      " -4.66941049e-02 -1.61784259e+00 -5.50118598e-02 -1.61491258e+00\n",
      " -6.28547379e-02 -1.61286298e+00 -7.04841476e-02 -1.60957510e+00\n",
      " -7.79012753e-02 -1.60507047e+00 -8.49262010e-02 -1.60164945e+00\n",
      " -9.16162141e-02 -1.59809380e+00 -9.79846111e-02 -1.59369453e+00\n",
      " -1.04140018e-01 -1.58882027e+00 -1.10075918e-01 -1.58378585e+00\n",
      " -1.15642566e-01 -1.57874967e+00 -1.21045958e-01 -1.57240315e+00\n",
      " -1.26151680e-01 -1.56757469e+00 -1.30946323e-01 -1.56305780e+00\n",
      " -1.35458065e-01 -1.55839425e+00 -1.39753721e-01 -1.55336133e+00\n",
      " -1.43809532e-01 -1.54779987e+00 -1.47635791e-01 -1.54137451e+00\n",
      " -1.51376490e-01 -1.53416160e+00 -1.54988354e-01 -1.52657981e+00\n",
      " -1.58416121e-01 -1.51859911e+00 -1.61692768e-01 -1.51025804e+00\n",
      " -1.64856239e-01 -1.50166671e+00 -1.67926737e-01 -1.49272252e+00\n",
      " -1.70882333e-01 -1.48316770e+00 -1.73674014e-01 -1.47359036e+00\n",
      " -1.76311602e-01 -1.46336235e+00 -1.78845556e-01 -1.45253122e+00\n",
      " -1.81288764e-01 -1.44128466e+00 -1.83624138e-01 -1.42945751e+00\n",
      " -1.85898401e-01 -1.41646165e+00 -1.88049275e-01 -1.40390375e+00\n",
      " -1.90087903e-01 -1.39074022e+00 -1.92091632e-01 -1.37608016e+00\n",
      " -1.94007649e-01 -1.36198818e+00 -1.95843163e-01 -1.34720048e+00\n",
      " -1.97549788e-01 -1.33271810e+00 -1.99136802e-01 -1.31770517e+00\n",
      " -2.00663855e-01 -1.30161864e+00 -2.02136893e-01 -1.28496653e+00\n",
      " -2.03547064e-01 -1.26753612e+00 -2.04952042e-01 -1.24906213e+00\n",
      " -2.06240513e-01 -1.23129888e+00 -2.07446573e-01 -1.21222177e+00\n",
      " -2.08610538e-01 -1.19218869e+00 -2.09698200e-01 -1.17160504e+00\n",
      " -2.10737341e-01 -1.15087874e+00 -2.11748009e-01 -1.12914390e+00\n",
      " -2.12696277e-01 -1.10770938e+00 -2.13591950e-01 -1.08602459e+00\n",
      " -2.14449838e-01 -1.06416213e+00 -2.15250744e-01 -1.04114347e+00\n",
      " -2.16031553e-01 -1.01752670e+00 -2.16819475e-01 -9.93492006e-01\n",
      " -2.17586101e-01 -9.68924260e-01 -2.18295639e-01 -9.43668307e-01\n",
      " -2.18974687e-01 -9.17571489e-01 -2.19626390e-01 -8.90726403e-01\n",
      " -2.20252353e-01 -8.63140556e-01 -2.20834438e-01 -8.35452103e-01\n",
      " -2.21391700e-01 -8.06567421e-01 -2.21908458e-01 -7.77329876e-01\n",
      " -2.22396313e-01 -7.47041251e-01 -2.22861202e-01 -7.16254614e-01\n",
      " -2.23304348e-01 -6.85215218e-01 -2.23716255e-01 -6.53217337e-01\n",
      " -2.24108798e-01 -6.20914142e-01 -2.24503889e-01 -5.88288115e-01\n",
      " -2.24887868e-01 -5.56643096e-01 -2.25249726e-01 -5.24092147e-01\n",
      " -2.25607407e-01 -4.91616274e-01 -2.25947987e-01 -4.58987745e-01\n",
      " -2.26335283e-01 -4.25613449e-01 -2.26692683e-01 -3.93422870e-01\n",
      " -2.26996491e-01 -3.60934484e-01 -2.27270468e-01 -3.28270919e-01\n",
      " -2.27486167e-01 -2.95772523e-01 -2.27741363e-01 -2.61367168e-01\n",
      " -2.27998421e-01 -2.28000380e-01 -2.28240304e-01 -1.95201676e-01\n",
      " -2.28466324e-01 -1.62933517e-01 -2.28661613e-01 -1.31516232e-01\n",
      " -2.28858381e-01 -9.88801950e-02 -2.29066882e-01 -7.02582829e-02\n",
      " -2.29243193e-01 -3.86357874e-02 -2.29415266e-01 -6.91819409e-03\n",
      " -2.29585074e-01  2.44965880e-02 -2.29747254e-01  5.45825046e-02\n",
      " -2.29897508e-01  8.41053425e-02 -2.30060830e-01  1.14509086e-01\n",
      " -2.30231076e-01  1.43206075e-01 -2.30390247e-01  1.71299944e-01\n",
      " -2.30547453e-01  1.99691620e-01 -2.30735973e-01  2.25763412e-01\n",
      " -2.30889244e-01  2.52293174e-01 -2.31026291e-01  2.78184780e-01\n",
      " -2.31150425e-01  3.04599424e-01 -2.31283311e-01  3.29967993e-01\n",
      " -2.31409348e-01  3.54705914e-01 -2.31526194e-01  3.79291178e-01\n",
      " -2.31639112e-01  4.04181756e-01 -2.31748413e-01  4.28661912e-01\n",
      " -2.31872402e-01  4.52418825e-01 -2.32004908e-01  4.73372857e-01\n",
      " -2.32132697e-01  4.95140225e-01 -2.32256036e-01  5.16216884e-01\n",
      " -2.32368473e-01  5.37551307e-01 -2.32473681e-01  5.58480314e-01\n",
      " -2.32576078e-01  5.79306716e-01 -2.32672154e-01  5.99817793e-01\n",
      " -2.32771461e-01  6.19480499e-01 -2.32855175e-01  6.41891028e-01\n",
      " -2.32933297e-01  6.61118286e-01 -2.33021273e-01  6.82655418e-01\n",
      " -2.33076019e-01  7.06512433e-01 -2.33072967e-01  7.34468661e-01\n",
      " -2.33126446e-01  7.58493349e-01 -2.33146370e-01  7.82818346e-01\n",
      " -2.33166371e-01  8.05541697e-01 -2.33195413e-01  8.28640433e-01\n",
      " -2.33232135e-01  8.51188604e-01 -2.33277608e-01  8.71959949e-01\n",
      " -2.33322746e-01  8.91980522e-01 -2.33362123e-01  9.13652793e-01\n",
      " -2.33405238e-01  9.25264725e-01 -2.33435074e-01  9.41731647e-01\n",
      " -2.33470196e-01  9.57272617e-01 -2.33509027e-01  9.73364152e-01\n",
      " -2.33539178e-01  9.86827988e-01 -2.33564462e-01  9.99040538e-01\n",
      " -2.33605118e-01  1.01538233e+00 -2.33647670e-01  1.02739467e+00\n",
      " -2.33692248e-01  1.04426201e+00 -2.33732124e-01  1.05782595e+00\n",
      " -2.33767863e-01  1.07274127e+00 -2.33799432e-01  1.09303713e+00\n",
      " -2.33814370e-01  1.11798777e+00 -2.33817380e-01  1.09498914e+00\n",
      " -2.33839491e-01  1.09966894e+00 -2.33902918e-01  1.07882252e+00\n",
      " -2.33945181e-01  1.09391303e+00 -2.33966481e-01  1.08412797e+00\n",
      " -2.33993702e-01  1.08993394e+00 -2.34015700e-01  1.09984412e+00\n",
      " -2.34015080e-01  1.07461820e+00 -2.34018213e-01  1.07864734e+00\n",
      " -2.34042402e-01  1.07068916e+00 -2.34041190e-01  1.06846188e+00\n",
      " -2.34040534e-01  1.06122944e+00 -2.34049379e-01  1.05001792e+00\n",
      " -2.34047597e-01  1.03632886e+00 -2.34049431e-01  1.01948655e+00]\n"
     ]
    }
   ],
   "source": [
    "filename = \"COPIA_PANDAS\\lomosP1P2_20240430_clasificado_experto_filtrado_total_test.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    pre_p_e1 =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_test=np.zeros((pre_p_e1.shape[0],numero_muestras,numero_entradas))\n",
    "    y_test=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1 or estado== 2 :\n",
    "                target = 0\n",
    "            else:\n",
    "                target = 1\n",
    "\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_test[x]=pepito[:,entrada]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_test[x]=target\n",
    "        y_test_to_categorical = to_categorical(y_test)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_test_filtrado = X_test\n",
    "#y_train_filtrado = y_train\n",
    "y_test_filtrado = y_test_to_categorical\n",
    "\n",
    "print(X_test_filtrado.shape)\n",
    "print(y_test_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "# concatenamos train y test\n",
    "#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\n",
    "data_2d_test = X_test_filtrado.reshape(-1, X_test_filtrado.shape[-1])\n",
    "normalized_data_2d_test = scaler.transform(data_2d_test)\n",
    "\n",
    "\n",
    "#X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape[0],-1) \n",
    "# la alternativa es normalizar con el total\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "\n",
    "y_test_def=y_test_filtrado # los valores ya estaban normalizados\n",
    "print(X_test_def[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer los conjuntos de entrenamiento validacion y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide el dataset en entrenamiento y temporal (test+validación)\n",
    "# X_temp, X_test_def, y_temp, y_test_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.2, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Divide el dataset temporal en validación y test\n",
    "X_train_def, X_val_def, y_train_def, y_val_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.25, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Ahora, X_train, X_val y X_test contienen los datos de entrada para los conjuntos de entrenamiento, validación y prueba, respectivamente.\n",
    "# y_train, y_val y y_test contienen las clases correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4752, 440)\n",
      "(1584, 440)\n",
      "(71, 440)\n",
      "(4752, 2)\n",
      "(1584, 2)\n",
      "(71, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_def.shape)\n",
    "print(X_val_def.shape)\n",
    "print(X_test_def.shape)\n",
    "print(y_train_def.shape)\n",
    "print(y_val_def.shape)\n",
    "print(y_test_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "#%tensorboard --logdir logs\n",
    "#log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"\n",
    "    Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\n",
    "    \"\"\"\n",
    "    \n",
    "    buf = io.BytesIO()\n",
    "    \n",
    "    # Use plt.savefig to save the plot to a PNG in memory.\n",
    "    plt.savefig(buf, format='png')\n",
    "    \n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    \n",
    "    # Use tf.image.decode_png to convert the PNG buffer\n",
    "    # to a TF image. Make sure you use 4 channels.\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    \n",
    "    # Use tf.expand_dims to add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "       class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    \n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    # Normalize the confusion matrix.\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    \n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    threshold = 0.5\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"red\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_aprendizaje=0.001\n",
    "dimension_LSTM=50\n",
    "dimension_dense1=50\n",
    "dimension_dense2=20\n",
    "algoritmo='rmsprop'\n",
    "supermax=8*4\n",
    "lossfunction='categorical_crossentropy'\n",
    "def create_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    # model.add(GRU(dimension_LSTM, return_sequences=False,input_shape=(numero_muestras, numero_entradas)))\n",
    "    # # model.add(GRU(50, return_sequences=True))\n",
    "    # model.add(GRU(50, return_sequences=False))\n",
    "    model.add(Dense(dimension_dense1, activation='tanh'))\n",
    "    model.add(Dense(dimension_dense2, activation='tanh'))\n",
    "    model.add(Dense(numero_clases, activation='softmax'))\n",
    "    model.compile(loss=lossfunction, optimizer=algoritmo, metrics=['accuracy'])\n",
    "    model.optimizer.lr=(factor_aprendizaje)\n",
    "    return model\n",
    "\n",
    "model=create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar una lista de los números en el rango del slice\n",
    "numbers = list(range(entrada.start, entrada.stop))\n",
    "\n",
    "# Convertir la lista a un string con los números separados por guiones\n",
    "slice_str = \"-\".join(map(str, numbers))\n",
    "#slice_str=\"todas\"\n",
    "\n",
    "\n",
    "#experimento=\"idea\"\n",
    "experimento=\"LOMOS_P1P2_entradas_{}_dense1_{}_dense2_{}_clases_{}_loss_{}_lr_{}_algoritmo_{}\".format(slice_str, dimension_dense1,dimension_dense2,numero_clases,lossfunction,factor_aprendizaje,algoritmo)\n",
    "logdir=\"./logs/defs/{}_{}\".format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if numero_clases==2:\n",
    "    class_names=['Buenos', 'Malos']\n",
    "else:\n",
    "    class_names=['A', 'B+', 'B', 'B-','C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    \n",
    "    # Use the model to predict the values from the test_images.\n",
    "    y_pred = model.predict(X_test_def)\n",
    "    #y_pred1=y_pred[:,-1]\n",
    "    y_pred2=y_pred.argmax(axis=1)\n",
    "    #y_pred2=np.where(y_pred>0,1,0)\n",
    "    #y_pred2=y_pred2[:,-1]\n",
    "    if numero_clases==2:\n",
    "        classes = [0, 1]    \n",
    "    else:\n",
    "\n",
    "        classes = [0, 1, 2, 3, 4] \n",
    "    #classes = [0, 1]\n",
    "    y_test_def2=np.argmax(y_test_def,axis=1)  \n",
    "    #y_test_def2=np.where(y_test_def>0,1,0)\n",
    "    cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    figura = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figura)\n",
    "    \n",
    "    # Log the confusion matrix as an image summary.\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6336, 2)\n",
      "(1584, 2)\n"
     ]
    }
   ],
   "source": [
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "print(y_train_Normalizado.shape)\n",
    "print(y_val_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un callback para guardar los mejores pesos\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('best_weights.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.5057 - accuracy: 0.75\n",
      "48/48 [==============================] - 2s 20ms/step - loss: 0.5057 - accuracy: 0.7557 - val_loss: 0.4996 - val_accuracy: 0.7734\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.4464 - accuracy: 0.78\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4464 - accuracy: 0.7885 - val_loss: 0.4477 - val_accuracy: 0.7803\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.4231 - accuracy: 0.79\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4178 - accuracy: 0.8045 - val_loss: 0.4157 - val_accuracy: 0.8352\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3991 - accuracy: 0.81\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3943 - accuracy: 0.8157 - val_loss: 0.4255 - val_accuracy: 0.8264\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3739 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.3749 - accuracy: 0.8335 - val_loss: 0.3838 - val_accuracy: 0.8472\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3566 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3551 - accuracy: 0.8510 - val_loss: 0.3569 - val_accuracy: 0.8668\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.3316 - accuracy: 0.86\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3316 - accuracy: 0.8651 - val_loss: 0.3620 - val_accuracy: 0.8763\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.3291 - accuracy: 0.86\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3185 - accuracy: 0.8651 - val_loss: 0.3121 - val_accuracy: 0.8611\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2970 - accuracy: 0.87\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2947 - accuracy: 0.8794 - val_loss: 0.3012 - val_accuracy: 0.8946\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2809 - accuracy: 0.88\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2812 - accuracy: 0.8880 - val_loss: 0.2706 - val_accuracy: 0.9066\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2645 - accuracy: 0.89\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2641 - accuracy: 0.8937 - val_loss: 0.2818 - val_accuracy: 0.9104\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.2474 - accuracy: 0.90\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2472 - accuracy: 0.9057 - val_loss: 0.2433 - val_accuracy: 0.8933\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2335 - accuracy: 0.90\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2334 - accuracy: 0.9097 - val_loss: 0.2881 - val_accuracy: 0.8725\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2155 - accuracy: 0.92\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2155 - accuracy: 0.9234 - val_loss: 0.2098 - val_accuracy: 0.9533\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2020 - accuracy: 0.93\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.2020 - accuracy: 0.9312 - val_loss: 0.2029 - val_accuracy: 0.9148\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.1885 - accuracy: 0.93\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.1869 - accuracy: 0.9392 - val_loss: 0.1857 - val_accuracy: 0.9306\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.1773 - accuracy: 0.94\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.1769 - accuracy: 0.9411 - val_loss: 0.1892 - val_accuracy: 0.9394\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.1610 - accuracy: 0.94\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.1610 - accuracy: 0.9468 - val_loss: 0.1725 - val_accuracy: 0.9293\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.1568 - accuracy: 0.94\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.1544 - accuracy: 0.9432 - val_loss: 0.1474 - val_accuracy: 0.9482\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.1375 - accuracy: 0.95\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.1355 - accuracy: 0.9590 - val_loss: 0.1765 - val_accuracy: 0.9249\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.1319 - accuracy: 0.95\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.1338 - accuracy: 0.9520 - val_loss: 0.1235 - val_accuracy: 0.9571\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.1236 - accuracy: 0.95\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.1235 - accuracy: 0.9564 - val_loss: 0.1265 - val_accuracy: 0.9501\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.1166 - accuracy: 0.95\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.1137 - accuracy: 0.9600 - val_loss: 0.1390 - val_accuracy: 0.9583\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.1047 - accuracy: 0.96\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.1047 - accuracy: 0.9646 - val_loss: 0.1028 - val_accuracy: 0.9501\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0965 - accuracy: 0.96\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0973 - accuracy: 0.9678 - val_loss: 0.1029 - val_accuracy: 0.9621\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.0905 - accuracy: 0.96\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0880 - accuracy: 0.9701 - val_loss: 0.0823 - val_accuracy: 0.9609\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0891 - accuracy: 0.96\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0866 - accuracy: 0.9695 - val_loss: 0.0712 - val_accuracy: 0.9684\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0726 - accuracy: 0.98\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 0.0767 - accuracy: 0.9769 - val_loss: 0.0920 - val_accuracy: 0.9672\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0717 - accuracy: 0.97\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0695 - accuracy: 0.9804 - val_loss: 0.0549 - val_accuracy: 0.9931\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0662 - accuracy: 0.98\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0674 - accuracy: 0.9800 - val_loss: 0.0625 - val_accuracy: 0.9785\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0615 - accuracy: 0.98\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.0635 - accuracy: 0.9809 - val_loss: 0.1061 - val_accuracy: 0.9665\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0586 - accuracy: 0.98\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0554 - accuracy: 0.9846 - val_loss: 0.0669 - val_accuracy: 0.9817\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0587 - accuracy: 0.98\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0555 - accuracy: 0.9838 - val_loss: 0.0844 - val_accuracy: 0.9640\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0504 - accuracy: 0.98\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0496 - accuracy: 0.9840 - val_loss: 0.0409 - val_accuracy: 0.9912\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0469 - accuracy: 0.98\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0476 - accuracy: 0.9870 - val_loss: 0.0845 - val_accuracy: 0.9583\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0468 - accuracy: 0.98\n",
      "48/48 [==============================] - 1s 19ms/step - loss: 0.0453 - accuracy: 0.9859 - val_loss: 0.0939 - val_accuracy: 0.9583\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0424 - accuracy: 0.98\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.0410 - accuracy: 0.9888 - val_loss: 0.0475 - val_accuracy: 0.9836\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0427 - accuracy: 0.98\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0432 - accuracy: 0.9853 - val_loss: 0.0335 - val_accuracy: 0.9962\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0378 - accuracy: 0.98\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 0.0377 - accuracy: 0.9897 - val_loss: 0.0454 - val_accuracy: 0.9842\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.0386 - accuracy: 0.98\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0383 - accuracy: 0.9870 - val_loss: 0.0277 - val_accuracy: 0.9931\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0348 - accuracy: 0.98\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.0356 - accuracy: 0.9888 - val_loss: 0.0270 - val_accuracy: 0.9931\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.0318 - accuracy: 0.98\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0321 - accuracy: 0.9888 - val_loss: 0.0252 - val_accuracy: 0.9975\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0317 - accuracy: 0.98\n",
      "48/48 [==============================] - 1s 16ms/step - loss: 0.0317 - accuracy: 0.9899 - val_loss: 0.0238 - val_accuracy: 0.9981\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.0305 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0328 - accuracy: 0.9907 - val_loss: 0.0216 - val_accuracy: 0.9937\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.0298 - accuracy: 0.98\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0285 - accuracy: 0.9899 - val_loss: 0.0240 - val_accuracy: 0.9962\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0264 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0318 - accuracy: 0.9891 - val_loss: 0.0283 - val_accuracy: 0.9924\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0243 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.1053 - val_accuracy: 0.9634\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0298 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0342 - accuracy: 0.9886 - val_loss: 0.0242 - val_accuracy: 0.9943\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0220 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.0220 - accuracy: 0.9935 - val_loss: 0.0243 - val_accuracy: 0.9931\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.0223 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 17ms/step - loss: 0.0280 - accuracy: 0.9918 - val_loss: 0.0185 - val_accuracy: 0.9937\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0174 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0220 - accuracy: 0.9937 - val_loss: 0.0187 - val_accuracy: 0.9975\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0255 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 19ms/step - loss: 0.0265 - accuracy: 0.9943 - val_loss: 0.0371 - val_accuracy: 0.9924\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0182 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.0278 - val_accuracy: 0.9912\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0202 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0189 - accuracy: 0.9947 - val_loss: 0.1165 - val_accuracy: 0.9609\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.0221 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0223 - accuracy: 0.9931 - val_loss: 0.0202 - val_accuracy: 0.9968\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0191 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.0253 - val_accuracy: 0.9874\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0173 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.0182 - val_accuracy: 0.9949\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0192 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0180 - accuracy: 0.9954 - val_loss: 0.0815 - val_accuracy: 0.9773\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0186 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.0119 - val_accuracy: 0.9981\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0155 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 0.0826 - val_accuracy: 0.9722\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.0187 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0179 - accuracy: 0.9937 - val_loss: 0.0135 - val_accuracy: 0.9981\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0172 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0198 - accuracy: 0.9922 - val_loss: 0.0147 - val_accuracy: 0.9981\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0203 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.0121 - val_accuracy: 0.9981\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0133 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0149 - accuracy: 0.9964 - val_loss: 0.0793 - val_accuracy: 0.9621\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0136 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.0117 - val_accuracy: 0.9975\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.0145 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 17ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 0.0169 - val_accuracy: 0.9962\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0112 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 0.0241 - val_accuracy: 0.9943\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.0098 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.0166 - val_accuracy: 0.9975\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0101 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.0139 - val_accuracy: 0.9975\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0063 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0135 - accuracy: 0.9962 - val_loss: 0.0128 - val_accuracy: 0.9975\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0087 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.0298 - val_accuracy: 0.9893\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0092 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.0154 - val_accuracy: 0.9968\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0142 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 0.0165 - val_accuracy: 0.9962\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0088 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.0231 - val_accuracy: 0.9924\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.0082 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.0160 - val_accuracy: 0.9949\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0141 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0135 - accuracy: 0.9966 - val_loss: 0.0318 - val_accuracy: 0.9842\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.0127 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 0.0088 - val_accuracy: 0.9987\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0102 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.0109 - val_accuracy: 0.9975\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0112 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0101 - accuracy: 0.9973 - val_loss: 0.0101 - val_accuracy: 0.9981\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0073 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.0103 - val_accuracy: 0.9981\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0105 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.0136 - val_accuracy: 0.9975\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0072 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.0124 - val_accuracy: 0.9975\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0078 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.0105 - val_accuracy: 0.9981\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0057 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.0129 - val_accuracy: 0.9975\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0051 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.1199 - val_accuracy: 0.9602\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0055 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0119 - val_accuracy: 0.9981\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.0072 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.0594 - val_accuracy: 0.9754\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0049 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 0.0094 - val_accuracy: 0.9975\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0028 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.0091 - val_accuracy: 0.9975\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0050 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0710 - val_accuracy: 0.9735\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0091 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0105 - accuracy: 0.9958 - val_loss: 0.0087 - val_accuracy: 0.9987\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0040 - accuracy: 0.9991\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0114 - val_accuracy: 0.9968\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0080 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.0119 - val_accuracy: 0.9981\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0093 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.0079 - val_accuracy: 0.9987\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0088 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0076 - accuracy: 0.9971 - val_loss: 0.0088 - val_accuracy: 0.9987\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0072 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.0453 - val_accuracy: 0.9842\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0025 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.1080 - val_accuracy: 0.9716\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.0041 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0059 - val_accuracy: 0.9987\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0049 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 16ms/step - loss: 0.0049 - accuracy: 0.9981 - val_loss: 0.0070 - val_accuracy: 0.9987\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0068 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0144 - val_accuracy: 0.9962\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0029 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.0066 - val_accuracy: 0.9994\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0063 - accuracy: 0.99\n",
      "48/48 [==============================] - 2s 35ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.0096 - val_accuracy: 0.9987\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.0053 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.0072 - val_accuracy: 0.9987\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0062 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.0078 - val_accuracy: 0.9987\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.0041 - accuracy: 0.9989\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0055 - val_accuracy: 0.9994\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0058 - accuracy: 0.9986\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0083 - val_accuracy: 0.9987\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0029 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.0253 - val_accuracy: 0.9899\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0024 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0087 - val_accuracy: 0.9987\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0044 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 0.0084 - val_accuracy: 0.9987\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 9.5808e-04 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.0928 - val_accuracy: 0.9792\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0042 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.0069 - val_accuracy: 0.9987\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0051 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0074 - val_accuracy: 0.9994\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0040 - accuracy: 0.9990\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0066 - val_accuracy: 0.9987\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0053 - accuracy: 0.9975\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0049 - accuracy: 0.9977 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 8.5019e-04 - accuracy: 1.00\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0060 - val_accuracy: 0.9981\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0041 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.0071 - val_accuracy: 0.9987\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0022 - accuracy: 0.9998  \n",
      "48/48 [==============================] - 1s 16ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0067 - val_accuracy: 0.9987\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0020 - accuracy: 0.9995  \n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0136 - val_accuracy: 0.9918\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0037 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0100 - val_accuracy: 0.9987\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0026 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0075 - val_accuracy: 0.9987\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.0019 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0078 - val_accuracy: 0.9981\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0055 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0062 - val_accuracy: 0.9987\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0031 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.0049 - val_accuracy: 0.9994\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0064 - accuracy: 0.9990\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 3.0183e-04 - accuracy: 1.00\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0102 - val_accuracy: 0.9987\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 4.2339e-04 - accuracy: 1.00\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 6.8961e-04 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9931\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0037 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.0138 - val_accuracy: 0.9949\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.0049 - accuracy: 0.9991\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.0044 - val_accuracy: 0.9994\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0032 - accuracy: 0.9988  \n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 2.6515e-04 - accuracy: 1.00\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.0086 - val_accuracy: 0.9981\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 9.0951e-04 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 8.1787e-04 - accuracy: 0.9996 - val_loss: 0.0071 - val_accuracy: 0.9987\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0045 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0076 - val_accuracy: 0.9987\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 2.3679e-04 - accuracy: 1.00\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.2680e-04 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 0.9886\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.0068 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0082 - val_accuracy: 0.9987\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0034 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0037 - accuracy: 0.9985 - val_loss: 0.0119 - val_accuracy: 0.9981\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 6.1599e-04 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.0068 - val_accuracy: 0.9987\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 3.0280e-04 - accuracy: 1.00\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.9915e-04 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 0.9823\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0035 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 0.0122 - val_accuracy: 0.9968\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0041 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0070 - val_accuracy: 0.9987\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.0017 - accuracy: 0.9996  \n",
      "48/48 [==============================] - 1s 19ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0087 - val_accuracy: 0.9994\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.0022 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0071 - val_accuracy: 0.9987\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0043 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 3ms/step loss: 3.5264e-04 - accuracy: 1.00\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 3.5020e-04 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9766\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0035 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.0066 - val_accuracy: 0.9994\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0065 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.0044 - val_accuracy: 0.9994\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 3.4679e-04 - accuracy: 1.00\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 3.1192e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9994\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0051 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.0418 - val_accuracy: 0.9912\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0034 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 0.0066 - val_accuracy: 0.9987\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0032 - accuracy: 0.9990  \n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0071 - val_accuracy: 0.9987\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0014 - accuracy: 0.9998\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0058 - val_accuracy: 0.9994\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.0051 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0088 - val_accuracy: 0.9994\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 1.8600e-04 - accuracy: 1.00\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.6907e-04 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9987\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0019 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0074 - val_accuracy: 0.9987\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.0038 - accuracy: 0.9983  \n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0033 - accuracy: 0.9985 - val_loss: 0.0068 - val_accuracy: 0.9987\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0012 - accuracy: 0.9995\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.0086 - val_accuracy: 0.9994\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.0017 - accuracy: 0.9995\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0084 - val_accuracy: 0.9994\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0028 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 0.0075 - val_accuracy: 0.9994\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0016 - accuracy: 0.9995  \n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0085 - val_accuracy: 0.9994\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 9.7907e-04 - accuracy: 1.00\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0691 - val_accuracy: 0.9842\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0056 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0049 - accuracy: 0.9981 - val_loss: 0.0067 - val_accuracy: 0.9994\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 9.3171e-05 - accuracy: 1.00\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 8.9360e-05 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9987\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0053 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0047 - accuracy: 0.9981 - val_loss: 0.0043 - val_accuracy: 0.9994\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 1.6165e-04 - accuracy: 1.00\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.7414e-04 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9981\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.0011 - accuracy: 0.9998  \n",
      "48/48 [==============================] - 1s 13ms/step - loss: 9.9293e-04 - accuracy: 0.9998 - val_loss: 0.0081 - val_accuracy: 0.9987\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.0015 - accuracy: 0.9995\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0087 - val_accuracy: 0.9987\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.0027 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0090 - val_accuracy: 0.9987\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.0040 - accuracy: 0.9987\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0091 - val_accuracy: 0.9987\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 8.0380e-05 - accuracy: 1.00\n",
      "48/48 [==============================] - 1s 18ms/step - loss: 8.0380e-05 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9994\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.0020 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 17ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0078 - val_accuracy: 0.9987\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0015 - accuracy: 0.9997\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0103 - val_accuracy: 0.9987\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 1.2565e-04 - accuracy: 1.00\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 3.4612e-04 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9987\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0027 - accuracy: 0.9992\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0095 - val_accuracy: 0.9987\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.0040 - accuracy: 0.9989  \n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0086 - val_accuracy: 0.9994\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 5.9574e-04 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 5.6695e-04 - accuracy: 0.9998 - val_loss: 0.0072 - val_accuracy: 0.9987\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 4.8156e-04 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 7.3905e-04 - accuracy: 0.9996 - val_loss: 0.0099 - val_accuracy: 0.9987\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0015 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0099 - val_accuracy: 0.9994\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0032 - accuracy: 0.9989\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0087 - val_accuracy: 0.9987\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0013 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 18ms/step - loss: 0.0013 - accuracy: 0.9992 - val_loss: 0.0093 - val_accuracy: 0.9987\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.0056 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.0088 - val_accuracy: 0.9994\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 3ms/step loss: 6.8131e-05 - accuracy: 1.00\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 7.2389e-05 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9880\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0023 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0072 - val_accuracy: 0.9994\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0034 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0032 - accuracy: 0.9983 - val_loss: 0.0092 - val_accuracy: 0.9981\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 8.9788e-05 - accuracy: 1.00\n",
      "48/48 [==============================] - 1s 16ms/step - loss: 8.9275e-05 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 0.9987\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0057 - accuracy: 0.9987\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0090 - val_accuracy: 0.9987\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 4.5473e-05 - accuracy: 1.00\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 3.1020e-04 - accuracy: 0.9998 - val_loss: 0.0173 - val_accuracy: 0.9949\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0034 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 0.0232 - val_accuracy: 0.9893\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0044 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0037 - accuracy: 0.9985 - val_loss: 0.0092 - val_accuracy: 0.9987\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 5.8113e-04 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 5.8207e-04 - accuracy: 0.9998 - val_loss: 0.0067 - val_accuracy: 0.9987\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 3.1037e-04 - accuracy: 1.00\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.5983e-04 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9987\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0035 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0083 - val_accuracy: 0.9987\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 7.9159e-05 - accuracy: 1.00\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 7.1243e-05 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9994\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0049 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.0146 - val_accuracy: 0.9962\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0023 - accuracy: 0.9992  \n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0111 - val_accuracy: 0.9987\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0021 - accuracy: 0.9995\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0090 - val_accuracy: 0.9987\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 8.2334e-04 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 7.0014e-04 - accuracy: 0.9998 - val_loss: 0.0088 - val_accuracy: 0.9994\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0021 - accuracy: 0.9991\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0067 - val_accuracy: 0.9994\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 3.5234e-05 - accuracy: 1.00\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 5.1820e-05 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 0.9987\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0040 - accuracy: 0.9978\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0032 - accuracy: 0.9983 - val_loss: 0.0129 - val_accuracy: 0.9962\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 1.7604e-04 - accuracy: 1.00\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.5523e-04 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 0.9987\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.0045 - accuracy: 0.99\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0097 - val_accuracy: 0.9987\n",
      "Accuracy: 61.97%\n"
     ]
    }
   ],
   "source": [
    "early_stop=tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1000, verbose=2, mode='auto', baseline=None, restore_best_weights=True)\n",
    "model.fit(X_train_def, y_train_def, epochs=numero_epochs, batch_size=100, callbacks=[tensorboard_callback,cm_callback,early_stop], validation_data=(X_val_def, y_val_def))\n",
    "# Final evaluation of the model \n",
    "scores = model.evaluate(X_test_def, y_test_def, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n",
      "(71, 2)\n",
      "(71,)\n",
      "(71,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "#y_pred2=np.where(y_pred>0,1,0)\n",
    "#y_pred2=y_pred2[:,-1]\n",
    "y_test_def2=np.argmax(y_test_def,axis=1)\n",
    "#y_test_def2=np.where(y_test_def>0,1,0)\n",
    "print(y_pred.shape)\n",
    "print(y_pred2.shape)\n",
    "print(y_test_def2.shape)\n",
    "#print(y_test_def[25])\n",
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#docs_infra: no_execute\n",
    "if numero_clases==2:\n",
    "    classes = [0, 1]\n",
    "else:   \n",
    "    classes = [0, 1, 2, 3, 4]\n",
    "#classes = [0, 1]\n",
    "cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Buenos     0.7241    0.7925    0.7568        53\n",
      "       Malos     0.1538    0.1111    0.1290        18\n",
      "\n",
      "    accuracy                         0.6197        71\n",
      "   macro avg     0.4390    0.4518    0.4429        71\n",
      "weighted avg     0.5796    0.6197    0.5976        71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "if numero_clases==2:\n",
    "    target_names = ['Buenos', 'Malos']\n",
    "else:   \n",
    "    target_names = ['A', 'B+', 'B', 'B-','C']\n",
    "print(classification_report(y_test_def2, y_pred2, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('modelos/modelote1203_200')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('idea.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "model.save('modelos\\modelo_perfecto_{}_{}.h5'.format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "\n",
    "existing_file='RESULTADOS_EXCEL\\clasificacion_71_P1P2_def.xlsx'\n",
    "\n",
    "# Verifica si el archivo existe y si está vacío\n",
    "if not os.path.exists(existing_file) or os.path.getsize(existing_file) == 0:\n",
    "    df_inicial=pd.DataFrame(y_test_def2, columns=[\"target\"])\n",
    "    df_inicial.to_excel(existing_file, index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'RESULTADOS_EXCEL\\\\clasificacion_71_P1P2_def.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m df_combined\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mconcat([df_existing, df_new], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Guarda los DataFrames en archivos Excel\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mdf_combined\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexisting_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\pandas\\core\\generic.py:2345\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   2332\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2334\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2335\u001b[0m     df,\n\u001b[0;32m   2336\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2343\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2344\u001b[0m )\n\u001b[1;32m-> 2345\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2347\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2354\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\pandas\\io\\formats\\excel.py:946\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    942\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;66;03m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001b[39;00m\n\u001b[0;32m    945\u001b[0m     \u001b[38;5;66;03m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[abstract]\u001b[39;49;00m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    952\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:61\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[0;32m     59\u001b[0m engine_kwargs \u001b[38;5;241m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# ExcelWriter replaced \"a\" by \"r+\" to allow us to first read the excel file from\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# the file and later write to it\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode:  \u001b[38;5;66;03m# Load from existing workbook\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1263\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m   1260\u001b[0m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m   1261\u001b[0m )\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m date_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\pandas\\io\\common.py:872\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    873\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'RESULTADOS_EXCEL\\\\clasificacion_71_P1P2_def.xlsx'"
     ]
    }
   ],
   "source": [
    "# Convierte los arrays a DataFrames\n",
    "df_new = pd.DataFrame(y_pred2, columns=[experimento])\n",
    "# Read existing data\n",
    "df_existing = pd.read_excel(existing_file)\n",
    "# Append new data\n",
    "df_combined=pd.concat([df_existing, df_new], axis=1)\n",
    "\n",
    "# Guarda los DataFrames en archivos Excel\n",
    "df_combined.to_excel(existing_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#este modo de guardar no funciona en esta version de tensorflow\n",
    "#model.save('modelos\\modelo_perfecto_{}_{}'.format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "n = len(y_pred2)\n",
    "reshaped = y_pred2[:n//4*4].reshape(-1, 4)\n",
    "mean_values = reshaped.mean(axis=1)\n",
    "\n",
    "mean_values = np.round(mean_values)\n",
    "mean_values = np.clip(mean_values, 0, 4)\n",
    "mean_values = mean_values.astype(int)\n",
    "print(mean_values)\n",
    "\n",
    "mode_values = stats.mode(reshaped, axis=1)[0]\n",
    "print(mode_values)\n",
    "\n",
    "# Convierte los arrays a DataFrames\n",
    "mean_df = pd.DataFrame(mean_values, columns=['mean'])\n",
    "mode_df = pd.DataFrame(mode_values, columns=['mode'])\n",
    "\n",
    "# Guarda los DataFrames en archivos Excel\n",
    "mean_df.to_excel(\"excels_borrar\\clasificacion_P1P2_mean_best7.xlsx\", index=False)\n",
    "mode_df.to_excel(\"excels_borrar\\clasificacion_P1_mode_best7.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename5 = \"COPIA_PANDAS\\hdf_28_06_atunes_agilent_clasificados_220_puntos.hdf\"\n",
    "with pd.HDFStore(filename5,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e2  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e2 = pre_p_e2.loc[pre_p_e2['Pollo'] != 0]\n",
    "    pre_p_e2 =pre_p_e2.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_test2=np.zeros((pre_p_e2.shape[0],220,8))\n",
    "    y_test2=np.zeros((pre_p_e2.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e2.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1:\n",
    "                target = 0 \n",
    "            else:\n",
    "                target = 1\n",
    "\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_test2[x]=pepito[:,3:4]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_test2[x]=target\n",
    "        y_test2_to_categorical = to_categorical(y_test2)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_test2_filtrado = X_test2\n",
    "#y_train_filtrado = y_train\n",
    "y_test2_filtrado = y_test2_to_categorical\n",
    "\n",
    "print(X_test2_filtrado.shape)\n",
    "print(y_test2_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "# concatenamos train y test\n",
    "#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\n",
    "data_2d_test = X_test2_filtrado.reshape(-1, X_test2_filtrado.shape[-1])\n",
    "normalized_data_2d_test = scaler.transform(data_2d_test)\n",
    "\n",
    "\n",
    "X_test2_def=normalized_data_2d_test.reshape(X_test2_filtrado.shape) \n",
    "# la alternativa es normalizar con el total\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "\n",
    "y_test2_def=y_test2_filtrado # los valores ya estaban normalizados\n",
    "\n",
    "print(y_test2_def.shape)\n",
    "\n",
    "print(y_test2_filtrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# # Crear un nuevo modelo con la misma arquitectura\n",
    "# best_val_model = create_model()  # Reemplaza esto con la función que usaste para crear el modelo original\n",
    "\n",
    "# # Cargar los mejores pesos\n",
    "# best_val_model.load_weights('best_weights.h5')\n",
    "\n",
    "y_pred = model.predict(X_test2_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "n = len(y_pred2)\n",
    "print(n)\n",
    "reshaped = y_pred2[:n//4*4].reshape(-1, 4)\n",
    "mean_values = reshaped.mean(axis=1)\n",
    "\n",
    "mean_values = np.round(mean_values)\n",
    "mean_values = np.clip(mean_values, 0, 4)\n",
    "mean_values = mean_values.astype(int)\n",
    "print(mean_values.shape)\n",
    "\n",
    "mode_values = stats.mode(reshaped, axis=1)[0]\n",
    "print(mode_values.shape)\n",
    "\n",
    "n = len(y_test2_def)\n",
    "y_test2_def2=np.argmax(y_test2_def,axis=1)\n",
    "print(y_test_def2.shape)\n",
    "print(n)\n",
    "reshaped2 = y_test2_def2[:n//4*4].reshape(-1, 4)\n",
    "target_mean_values = reshaped2.mean(axis=1)\n",
    "\n",
    "target_mean_values = np.round(target_mean_values)\n",
    "target_mean_values = np.clip(target_mean_values, 0, 4)\n",
    "target_mean_values = target_mean_values.astype(int)\n",
    "print(target_mean_values.shape)\n",
    "\n",
    "target_mode_values = stats.mode(reshaped2, axis=1)[0]\n",
    "print(target_mode_values.shape)\n",
    "print(reshaped)\n",
    "print(mode_values)\n",
    "print(target_mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs_infra: no_execute\n",
    "if numero_clases==2:\n",
    "    classes = [0, 1]    \n",
    "else:\n",
    "\n",
    "    classes = [0, 1, 2, 3, 4]\n",
    "#classes = [0, 1]\n",
    "cm=confusion_matrix(y_test2_def2, y_pred2,labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm.diagonal()/cm.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if numero_clases==2:\n",
    "    target_names= ['Buenos', 'Malos']\n",
    "else:\n",
    "    target_names= ['A', 'B+', 'B', 'B-','C']\n",
    "print(classification_report(target_mode_values, mode_values, target_names=target_names, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
