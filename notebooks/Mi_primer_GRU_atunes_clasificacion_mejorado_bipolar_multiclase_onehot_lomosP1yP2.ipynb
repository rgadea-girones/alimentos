{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rgadea/experimentos_software_2024\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM,Bidirectional,GRU\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import datetime\n",
    "import io\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Obtener la ruta del directorio actual\n",
    "os.chdir('/home/rgadea/experimentos_software_2024')\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "# Construir la ruta relativa al directorio que quieres agregar\n",
    "relative_dir = os.path.join(current_dir, 'mis_pkgs/')\n",
    "\n",
    "# Agregar la ruta relativa al sys.path\n",
    "sys.path.insert(0, relative_dir)\n",
    "\n",
    "from MIOPATIA_db import DB_management as db \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a quedarme con los 50 atunes P1 para obtener conjunto de training y validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rgadea/experimentos_software_2024\n"
     ]
    }
   ],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.59059849e-04 6.02334232e-01 2.09243895e-01 ... 3.97666103e-01\n",
      "  5.59148408e-04 8.98444367e-01]\n",
      " [5.32692283e-04 6.01851048e-01 2.10280898e-01 ... 3.98149286e-01\n",
      "  5.32776684e-04 8.98444937e-01]\n",
      " [5.23422176e-04 6.02312810e-01 2.08059305e-01 ... 3.97687525e-01\n",
      "  5.23505162e-04 8.98445730e-01]\n",
      " ...\n",
      " [6.90117158e-07 4.10655386e-01 1.65373568e-01 ... 5.89344843e-01\n",
      "  6.90201187e-07 8.98463166e-01]\n",
      " [3.49024769e-07 4.14711733e-01 1.65342858e-01 ... 5.85288497e-01\n",
      "  3.49145000e-07 8.98463350e-01]\n",
      " [0.00000000e+00 4.19288217e-01 1.65312668e-01 ... 5.80712016e-01\n",
      "  1.56981087e-10 8.98463540e-01]]\n"
     ]
    }
   ],
   "source": [
    "filename = \"lomosP1_20240430_clasificado_experto_ampliado_the_best7.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    # p_e =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_train=np.zeros((pre_p_e1.shape[0],220,8))\n",
    "    y_train=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        #if estado == 0 or estado== 1:\n",
    "        #    target = 1\n",
    "        #else:\n",
    "        #    target = 0\n",
    "        target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_train[x]=pepito[:,3:11]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_train[x]=target\n",
    "        y_train_to_categorical = to_categorical(y_train)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_train_filtrado = X_train\n",
    "#y_train_filtrado = y_train\n",
    "y_train_filtrado = y_train_to_categorical\n",
    "\n",
    "# print(X_train_filtrado.shape)\n",
    "# print(y_train_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_2d = X_train_filtrado.reshape(-1, X_train_filtrado.shape[-1])\n",
    "normalized_data_2d = scaler.fit_transform(data_2d)\n",
    "X_train_Normalizado=normalized_data_2d.reshape(X_train_filtrado.shape)\n",
    "y_train_Normalizado=y_train_filtrado # los valores ya estaban normalizados\n",
    "print(X_train_Normalizado[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 220, 8)\n",
      "(200, 5)\n",
      "[[8.61839703e-05 5.64525281e-01 6.27511981e-01 ... 4.35475066e-01\n",
      "  8.61956522e-05 9.54751150e-01]\n",
      " [7.95233660e-05 5.52105715e-01 6.83226649e-01 ... 4.47894637e-01\n",
      "  7.95339149e-05 9.54747869e-01]\n",
      " [7.82429225e-05 5.53651114e-01 6.70817401e-01 ... 4.46349237e-01\n",
      "  7.82533416e-05 9.54748691e-01]\n",
      " ...\n",
      " [1.07084974e-05 3.79849460e-01 4.74229191e-01 ... 6.20150968e-01\n",
      "  1.07084572e-05 9.54753309e-01]\n",
      " [1.02172207e-05 3.77571475e-01 4.74229705e-01 ... 6.22428954e-01\n",
      "  1.02171460e-05 9.54753658e-01]\n",
      " [9.71743706e-06 3.75437107e-01 4.74230608e-01 ... 6.24563323e-01\n",
      "  9.71733246e-06 9.54754033e-01]]\n"
     ]
    }
   ],
   "source": [
    "filename = \"lomosP2_20240430_clasificado_experto.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    pre_p_e1 =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_test=np.zeros((pre_p_e1.shape[0],220,8))\n",
    "    y_test=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        #if estado == 0 or estado== 1:\n",
    "        #    target = 1\n",
    "        #else:\n",
    "        #    target = 0\n",
    "        target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_test[x]=pepito[:,3:11]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_test[x]=target\n",
    "        y_test_to_categorical = to_categorical(y_test)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_test_filtrado = X_test\n",
    "#y_train_filtrado = y_train\n",
    "y_test_filtrado = y_test_to_categorical\n",
    "\n",
    "print(X_test_filtrado.shape)\n",
    "print(y_test_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "# concatenamos train y test\n",
    "#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\n",
    "data_2d_test = X_test_filtrado.reshape(-1, X_test_filtrado.shape[-1])\n",
    "normalized_data_2d_test = scaler.transform(data_2d_test)\n",
    "\n",
    "\n",
    "X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "# la alternativa es normalizar con el total\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "\n",
    "y_test_def=y_test_filtrado # los valores ya estaban normalizados\n",
    "print(X_test_def[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer los conjuntos de entrenamiento validacion y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide el dataset en entrenamiento y temporal (test+validaci√≥n)\n",
    "# X_temp, X_test_def, y_temp, y_test_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.2, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Divide el dataset temporal en validaci√≥n y test\n",
    "X_train_def, X_val_def, y_train_def, y_val_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.25, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Ahora, X_train, X_val y X_test contienen los datos de entrada para los conjuntos de entrenamiento, validaci√≥n y prueba, respectivamente.\n",
    "# y_train, y_val y y_test contienen las clases correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4950, 220, 8)\n",
      "(1650, 220, 8)\n",
      "(200, 220, 8)\n",
      "(4950, 5)\n",
      "(1650, 5)\n",
      "(200, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_def.shape)\n",
    "print(X_val_def.shape)\n",
    "print(X_test_def.shape)\n",
    "print(y_train_def.shape)\n",
    "print(y_val_def.shape)\n",
    "print(y_test_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "#%tensorboard --logdir logs\n",
    "#log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"\n",
    "    Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\n",
    "    \"\"\"\n",
    "    \n",
    "    buf = io.BytesIO()\n",
    "    \n",
    "    # Use plt.savefig to save the plot to a PNG in memory.\n",
    "    plt.savefig(buf, format='png')\n",
    "    \n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    \n",
    "    # Use tf.image.decode_png to convert the PNG buffer\n",
    "    # to a TF image. Make sure you use 4 channels.\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    \n",
    "    # Use tf.expand_dims to add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "       class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    \n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    # Normalize the confusion matrix.\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    \n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    threshold = 0.5\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"red\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_1 (GRU)                 (None, 50)                9000      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 255       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11805 (46.11 KB)\n",
      "Trainable params: 11805 (46.11 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "algoritmo='RMSprop'\n",
    "supermax=8*4\n",
    "lossfunction='categorical_crossentropy'\n",
    "factor_aprendizaje=0.001\n",
    "dimension_LSTM=50\n",
    "dimension_dense=50\n",
    "model = Sequential()\n",
    "model.add(GRU(dimension_LSTM, return_sequences=False,input_shape=(220, 8)))\n",
    "#model.add(Bidirectional(LSTM(50, return_sequences=True)))\n",
    "#model.add(Bidirectional(LSTM(50, return_sequences=True)))\n",
    "#model.add(Bidirectional(LSTM(50, return_sequences=False)))\n",
    "model.add(Dense(dimension_dense, activation='tanh'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss=lossfunction, optimizer=algoritmo, metrics=['accuracy'])\n",
    "model.optimizer.lr=(factor_aprendizaje)\n",
    "print(model.summary())\n",
    "\n",
    "experimento=\"LOMOS_P1 yP2_GRU2_best7_{}_dense_onehot_{}_loss_{}_lr_{}_algoritmo_{}\".format(dimension_LSTM,dimension_dense,lossfunction,factor_aprendizaje,algoritmo)\n",
    "logdir=\"./logs/defs/{}_{}\".format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=[\"A\",\"B-\",\"B\",\"B+\", \"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    \n",
    "    # Use the model to predict the values from the test_images.\n",
    "    y_pred = model.predict(X_test_def)\n",
    "    #y_pred1=y_pred[:,-1]\n",
    "    y_pred2=y_pred.argmax(axis=1)\n",
    "    #y_pred2=np.where(y_pred>0,1,0)\n",
    "    #y_pred2=y_pred2[:,-1]\n",
    "    classes = [0, 1, 2, 3, 4]\n",
    "    y_test_def2=np.argmax(y_test_def,axis=1)  \n",
    "    #y_test_def2=np.where(y_test_def>0,1,0)\n",
    "    cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    figura = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figura)\n",
    "    \n",
    "    # Log the confusion matrix as an image summary.\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6600, 5)\n",
      "(1650, 5)\n"
     ]
    }
   ],
   "source": [
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "print(y_train_Normalizado.shape)\n",
    "print(y_val_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "7/7 [==============================] - 1s 20ms/step- loss: 1.3139 - accuracy: \n",
      "330/330 [==============================] - 24s 68ms/step - loss: 1.3139 - accuracy: 0.4583 - val_loss: 1.2956 - val_accuracy: 0.4600\n",
      "Epoch 2/400\n",
      "140/330 [===========>..................] - ETA: 11s - loss: 1.2941 - accuracy: 0.4514"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m early_stop\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, baseline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_Normalizado\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_Normalizado\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcm_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_def\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Final evaluation of the model \u001b[39;00m\n\u001b[1;32m      4\u001b[0m scores \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test_def, y_test_def, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/experimentos_software_2024/envs/tensorflow_2024/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/experimentos_software_2024/envs/tensorflow_2024/lib/python3.11/site-packages/keras/src/engine/training.py:1798\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1796\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[1;32m   1797\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m-> 1798\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1799\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1800\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1801\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepoch_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_r\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1805\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1806\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/experimentos_software_2024/envs/tensorflow_2024/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1411\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[1;32m   1410\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1411\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m   1412\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1413\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1414\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1415\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[1;32m   1416\u001b[0m )\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[0;32m~/experimentos_software_2024/envs/tensorflow_2024/lib/python3.11/site-packages/tensorflow/python/ops/resource_variable_ops.py:689\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    688\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    690\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    691\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/experimentos_software_2024/envs/tensorflow_2024/lib/python3.11/site-packages/tensorflow/python/ops/resource_variable_ops.py:839\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \n\u001b[1;32m    832\u001b[0m \u001b[38;5;124;03mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;124;03m  The value of the variable.\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 839\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;66;03m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(value)\n",
      "File \u001b[0;32m~/experimentos_software_2024/envs/tensorflow_2024/lib/python3.11/site-packages/tensorflow/python/ops/resource_variable_ops.py:818\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[0;34m(self, no_copy)\u001b[0m\n\u001b[1;32m    816\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 818\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mread_and_set_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mno_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    821\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[1;32m    822\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[1;32m    823\u001b[0m   record\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[1;32m    824\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[1;32m    825\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[1;32m    826\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[0;32m~/experimentos_software_2024/envs/tensorflow_2024/lib/python3.11/site-packages/tensorflow/python/ops/resource_variable_ops.py:808\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[0;34m(no_copy)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_copy \u001b[38;5;129;01mand\u001b[39;00m forward_compat\u001b[38;5;241m.\u001b[39mforward_compatible(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m    807\u001b[0m   gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mdisable_copy_on_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m--> 808\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/experimentos_software_2024/envs/tensorflow_2024/lib/python3.11/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:534\u001b[0m, in \u001b[0;36mread_variable_op\u001b[0;34m(resource, dtype, name)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    533\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadVariableOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    537\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early_stop=tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=500, verbose=2, mode='auto', baseline=None, restore_best_weights=True)\n",
    "model.fit(X_train_Normalizado, y_train_Normalizado, epochs=400, batch_size=20, callbacks=[tensorboard_callback,cm_callback, early_stop], validation_data=(X_val_def, y_val_def))\n",
    "# Final evaluation of the model \n",
    "scores = model.evaluate(X_test_def, y_test_def, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 18ms/step\n",
      "(200, 5)\n",
      "(200,)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "#y_pred2=np.where(y_pred>0,1,0)\n",
    "#y_pred2=y_pred2[:,-1]\n",
    "y_test_def2=np.argmax(y_test_def,axis=1)\n",
    "#y_test_def2=np.where(y_test_def>0,1,0)\n",
    "print(y_pred.shape)\n",
    "print(y_pred2.shape)\n",
    "print(y_test_def2.shape)\n",
    "#print(y_test_def[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#docs_infra: no_execute\n",
    "classes = [0, 1, 2, 3, 4]\n",
    "cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('modelos/modelote1203_200')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modelos/modelo_perfecto_LOMOS_P1 yP2_GRU2_best7_50_dense_onehot_50_loss_categorical_crossentropy_lr_0.001_algoritmo_RMSprop_20240509-193133/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modelos/modelo_perfecto_LOMOS_P1 yP2_GRU2_best7_50_dense_onehot_50_loss_categorical_crossentropy_lr_0.001_algoritmo_RMSprop_20240509-193133/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('modelos/modelo_perfecto_{}_{}'.format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 18ms/step\n",
      "[2 1 2 2 2 1 2 2 2 2 2 2 1 1 1 2 1 1 1 2 2 1 1 1 2 2 1 2 2 2 2 1 1 2 1 2 2\n",
      " 2 1 1 2 2 2 2 2 2 1 1 1 3]\n",
      "[2 2 2 0 2 0 2 2 2 2 2 2 2 0 0 0 0 1 0 2 2 1 0 0 2 2 0 2 2 1 1 1 1 2 0 3 2\n",
      " 1 2 0 2 1 0 1 2 0 0 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "n = len(y_pred2)\n",
    "reshaped = y_pred2[:n//4*4].reshape(-1, 4)\n",
    "mean_values = reshaped.mean(axis=1)\n",
    "\n",
    "mean_values = np.round(mean_values)\n",
    "mean_values = np.clip(mean_values, 0, 4)\n",
    "mean_values = mean_values.astype(int)\n",
    "print(mean_values)\n",
    "\n",
    "mode_values = stats.mode(reshaped, axis=1)[0]\n",
    "print(mode_values)\n",
    "\n",
    "# Convierte los arrays a DataFrames\n",
    "mean_df = pd.DataFrame(mean_values, columns=['mean'])\n",
    "mode_df = pd.DataFrame(mode_values, columns=['mode'])\n",
    "\n",
    "# Guarda los DataFrames en archivos Excel\n",
    "mean_df.to_excel(\"clasificacion_P2_mean_best7.xlsx\", index=False)\n",
    "mode_df.to_excel(\"clasificacion_P2_mode_best7.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 1 2 2 0 1 2 2 3 0 2 0 4 0 2 0 2 3 0 0 2 2 2 0 2 2 2 1 2 2 2 2 2 2 2\n",
      " 1 2 2 2 2 2 2 2 2 2 2 2 1 2 0 0 0 2 3 0 0 3 0 3 4 1 0 2 0 0 1 1 2 1 0 2 0\n",
      " 3 0 4 2 0 2 2 2 3 0 1 0 2 1 1 2 0 0 2 0 2 0 2 2 1 2 2 1 2 2 2 0 0 2 1 2 2\n",
      " 2 2 1 2 2 1 2 3 1 1 1 2 2 2 0 1 1 0 2 1 1 2 4 0 2 0 0 1 3 3 0 1 3 2 4 2 2\n",
      " 3 2 1 1 0 2 2 1 0 4 0 0 0 4 2 2 3 3 1 1 2 0 3 1 1 4 1 4 3 2 2 3 0 2 4 0 2\n",
      " 0 0 2 1 1 1 2 0 3 2 0 1 2 4 4]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow_2024_GPU)",
   "language": "python",
   "name": "tensorflow_2024"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
