{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rgadea/experimentos_software_2024\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM,Bidirectional,GRU\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import datetime\n",
    "import io\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Obtener la ruta del directorio actual\n",
    "os.chdir('/home/rgadea/experimentos_software_2024')\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "# Construir la ruta relativa al directorio que quieres agregar\n",
    "relative_dir = os.path.join(current_dir, 'mis_pkgs/')\n",
    "\n",
    "# Agregar la ruta relativa al sys.path\n",
    "sys.path.insert(0, relative_dir)\n",
    "\n",
    "from MIOPATIA_db import DB_management as db \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a quedarme con los 50 atunes P1 para obtener conjunto de training y validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rgadea/experimentos_software_2024\n"
     ]
    }
   ],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3168, 2)\n"
     ]
    }
   ],
   "source": [
    "filename = \"hdf_lomosP2_trainval_filtrado_def_good_ampliado_the_best7.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    # p_e =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_train=np.zeros((pre_p_e1.shape[0],220,8))\n",
    "    y_train=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if estado == 0 or estado== 1:\n",
    "            target = 1\n",
    "        else:\n",
    "            target = 0\n",
    "        #target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_train[x]=pepito[:,3:11]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_train[x]=target\n",
    "        y_train_to_categorical = to_categorical(y_train)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_train_filtrado = X_train\n",
    "#y_train_filtrado = y_train\n",
    "y_train_filtrado = y_train_to_categorical\n",
    "\n",
    "# print(X_train_filtrado.shape)\n",
    "# print(y_train_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_2d = X_train_filtrado.reshape(-1, X_train_filtrado.shape[-1])\n",
    "normalized_data_2d = scaler.fit_transform(data_2d)\n",
    "X_train_Normalizado=normalized_data_2d.reshape(X_train_filtrado.shape)\n",
    "y_train_Normalizado=y_train_filtrado # los valores ya estaban normalizados\n",
    "print(y_train_Normalizado.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89, 220, 8)\n",
      "(89, 2)\n",
      "[[1.45375657e-01 4.74795267e-01 2.80281244e-02 ... 5.25204733e-01\n",
      "  1.45375842e-01 6.87729402e-01]\n",
      " [1.04024516e-01 4.57433188e-01 2.91808316e-02 ... 5.42566812e-01\n",
      "  1.04024006e-01 6.97578524e-01]\n",
      " [8.71835342e-02 4.33210717e-01 3.04208802e-02 ... 5.66789283e-01\n",
      "  8.71821912e-02 6.95625305e-01]\n",
      " ...\n",
      " [2.02802467e-04 3.24435285e-01 2.62623498e-02 ... 6.75564715e-01\n",
      "  2.02784951e-04 7.57016975e-01]\n",
      " [1.94554576e-04 3.21521964e-01 2.62630472e-02 ... 6.78478036e-01\n",
      "  1.94537255e-04 7.57024384e-01]\n",
      " [1.86099353e-04 3.17958187e-01 2.62645389e-02 ... 6.82041813e-01\n",
      "  1.86082165e-04 7.57031614e-01]]\n"
     ]
    }
   ],
   "source": [
    "filename = \"hdf_lomosP2_test_filtrado_def_good.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    pre_p_e1 =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_test=np.zeros((pre_p_e1.shape[0],220,8))\n",
    "    y_test=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if estado == 0 or estado== 1:\n",
    "           target = 1\n",
    "        else:\n",
    "           target = 0\n",
    "        #target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_test[x]=pepito[:,3:11]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_test[x]=target\n",
    "        y_test_to_categorical = to_categorical(y_test)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_test_filtrado = X_test\n",
    "#y_train_filtrado = y_train\n",
    "y_test_filtrado = y_test_to_categorical\n",
    "\n",
    "print(X_test_filtrado.shape)\n",
    "print(y_test_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "# concatenamos train y test\n",
    "#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\n",
    "data_2d_test = X_test_filtrado.reshape(-1, X_test_filtrado.shape[-1])\n",
    "normalized_data_2d_test = scaler.transform(data_2d_test)\n",
    "\n",
    "\n",
    "X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "# la alternativa es normalizar con el total\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "\n",
    "y_test_def=y_test_filtrado # los valores ya estaban normalizados\n",
    "print(X_test_def[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer los conjuntos de entrenamiento validacion y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide el dataset en entrenamiento y temporal (test+validación)\n",
    "# X_temp, X_test_def, y_temp, y_test_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.2, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Divide el dataset temporal en validación y test\n",
    "X_train_def, X_val_def, y_train_def, y_val_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.25, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Ahora, X_train, X_val y X_test contienen los datos de entrada para los conjuntos de entrenamiento, validación y prueba, respectivamente.\n",
    "# y_train, y_val y y_test contienen las clases correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2376, 220, 8)\n",
      "(792, 220, 8)\n",
      "(89, 220, 8)\n",
      "(2376, 2)\n",
      "(792, 2)\n",
      "(89, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_def.shape)\n",
    "print(X_val_def.shape)\n",
    "print(X_test_def.shape)\n",
    "print(y_train_def.shape)\n",
    "print(y_val_def.shape)\n",
    "print(y_test_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "#%tensorboard --logdir logs\n",
    "#log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"\n",
    "    Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\n",
    "    \"\"\"\n",
    "    \n",
    "    buf = io.BytesIO()\n",
    "    \n",
    "    # Use plt.savefig to save the plot to a PNG in memory.\n",
    "    plt.savefig(buf, format='png')\n",
    "    \n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    \n",
    "    # Use tf.image.decode_png to convert the PNG buffer\n",
    "    # to a TF image. Make sure you use 4 channels.\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    \n",
    "    # Use tf.expand_dims to add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "       class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    \n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    # Normalize the confusion matrix.\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    \n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    threshold = 0.5\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"red\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_aprendizaje=0.001\n",
    "dimension_LSTM=50\n",
    "dimension_dense=50\n",
    "algoritmo='RMSprop'\n",
    "supermax=8*4\n",
    "lossfunction='categorical_crossentropy'\n",
    "def create_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(GRU(dimension_LSTM, return_sequences=True,input_shape=(220, 8)))\n",
    "    #model.add(Bidirectional(LSTM(50, return_sequences=True)))\n",
    "    #model.add(Bidirectional(LSTM(50, return_sequences=True)))\n",
    "    model.add(GRU(dimension_LSTM, return_sequences=False))\n",
    "    model.add(Dense(dimension_dense, activation='tanh'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss=lossfunction, optimizer=algoritmo, metrics=['accuracy'])\n",
    "    model.optimizer.lr=(factor_aprendizaje)\n",
    "    return model\n",
    "\n",
    "model=create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "experimento=\"LOMOS_P2_GRU2_2_clasesfiltrado_{}_dense_onehot_{}_loss_{}_lr_{}_algoritmo_{}\".format(dimension_LSTM,dimension_dense,lossfunction,factor_aprendizaje,algoritmo)\n",
    "logdir=\"./logs/defs/{}_{}\".format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=[\"Buenos\",\"Malos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    \n",
    "    # Use the model to predict the values from the test_images.\n",
    "    y_pred = model.predict(X_test_def)\n",
    "    #y_pred1=y_pred[:,-1]\n",
    "    y_pred2=y_pred.argmax(axis=1)\n",
    "    #y_pred2=np.where(y_pred>0,1,0)\n",
    "    #y_pred2=y_pred2[:,-1]\n",
    "    #classes = [0, 1, 2, 3, 4] \n",
    "    classes = [0, 1]\n",
    "    y_test_def2=np.argmax(y_test_def,axis=1)  \n",
    "    #y_test_def2=np.where(y_test_def>0,1,0)\n",
    "    cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    figura = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figura)\n",
    "    \n",
    "    # Log the confusion matrix as an image summary.\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3168, 2)\n",
      "(792, 2)\n"
     ]
    }
   ],
   "source": [
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "print(y_train_Normalizado.shape)\n",
    "print(y_val_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un callback para guardar los mejores pesos\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('best_weights.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.6842 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 164ms/step - loss: 0.6842 - accuracy: 0.5650 - val_loss: 0.6808 - val_accuracy: 0.6187\n",
      "Epoch 2/400\n",
      "3/3 [==============================] - 0s 44ms/step- loss: 0.6851 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 160ms/step - loss: 0.6851 - accuracy: 0.5660 - val_loss: 0.6778 - val_accuracy: 0.5821\n",
      "Epoch 3/400\n",
      "3/3 [==============================] - 0s 37ms/step- loss: 0.6850 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 165ms/step - loss: 0.6850 - accuracy: 0.5723 - val_loss: 0.6775 - val_accuracy: 0.5783\n",
      "Epoch 4/400\n",
      "3/3 [==============================] - 0s 52ms/step- loss: 0.6820 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 166ms/step - loss: 0.6820 - accuracy: 0.5764 - val_loss: 0.7064 - val_accuracy: 0.5631\n",
      "Epoch 5/400\n",
      "3/3 [==============================] - 0s 47ms/step- loss: 0.6834 - accuracy: 0.\n",
      "159/159 [==============================] - 27s 169ms/step - loss: 0.6834 - accuracy: 0.5707 - val_loss: 0.6778 - val_accuracy: 0.5758\n",
      "Epoch 6/400\n",
      "3/3 [==============================] - 0s 42ms/step- loss: 0.6824 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 165ms/step - loss: 0.6824 - accuracy: 0.5685 - val_loss: 0.6796 - val_accuracy: 0.5694\n",
      "Epoch 7/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.6827 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 166ms/step - loss: 0.6827 - accuracy: 0.5745 - val_loss: 0.6836 - val_accuracy: 0.5492\n",
      "Epoch 8/400\n",
      "3/3 [==============================] - 0s 45ms/step- loss: 0.6835 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 161ms/step - loss: 0.6835 - accuracy: 0.5729 - val_loss: 0.6766 - val_accuracy: 0.6048\n",
      "Epoch 9/400\n",
      "3/3 [==============================] - 0s 42ms/step- loss: 0.6827 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 158ms/step - loss: 0.6827 - accuracy: 0.5792 - val_loss: 0.6748 - val_accuracy: 0.5947\n",
      "Epoch 10/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.6833 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 162ms/step - loss: 0.6833 - accuracy: 0.5805 - val_loss: 0.6778 - val_accuracy: 0.5581\n",
      "Epoch 11/400\n",
      "3/3 [==============================] - 0s 42ms/step- loss: 0.6828 - accuracy: 0.\n",
      "159/159 [==============================] - 27s 168ms/step - loss: 0.6828 - accuracy: 0.5745 - val_loss: 0.6752 - val_accuracy: 0.5846\n",
      "Epoch 12/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.6806 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 161ms/step - loss: 0.6806 - accuracy: 0.5748 - val_loss: 0.6974 - val_accuracy: 0.5631\n",
      "Epoch 13/400\n",
      "3/3 [==============================] - 0s 59ms/step- loss: 0.6830 - accuracy: \n",
      "159/159 [==============================] - 25s 160ms/step - loss: 0.6830 - accuracy: 0.5688 - val_loss: 0.6768 - val_accuracy: 0.6111\n",
      "Epoch 14/400\n",
      "3/3 [==============================] - 0s 46ms/step- loss: 0.6818 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 162ms/step - loss: 0.6818 - accuracy: 0.5713 - val_loss: 0.6775 - val_accuracy: 0.5783\n",
      "Epoch 15/400\n",
      "3/3 [==============================] - 0s 39ms/step- loss: 0.6819 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 162ms/step - loss: 0.6819 - accuracy: 0.5707 - val_loss: 0.6763 - val_accuracy: 0.5808\n",
      "Epoch 16/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.6811 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 164ms/step - loss: 0.6811 - accuracy: 0.5754 - val_loss: 0.6816 - val_accuracy: 0.5795\n",
      "Epoch 17/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.6820 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 159ms/step - loss: 0.6820 - accuracy: 0.5754 - val_loss: 0.6767 - val_accuracy: 0.6111\n",
      "Epoch 18/400\n",
      "3/3 [==============================] - 0s 40ms/step- loss: 0.6820 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 159ms/step - loss: 0.6820 - accuracy: 0.5685 - val_loss: 0.6741 - val_accuracy: 0.5947\n",
      "Epoch 19/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.6813 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 164ms/step - loss: 0.6813 - accuracy: 0.5764 - val_loss: 0.6819 - val_accuracy: 0.5556\n",
      "Epoch 20/400\n",
      "3/3 [==============================] - 0s 33ms/step- loss: 0.6820 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 160ms/step - loss: 0.6820 - accuracy: 0.5792 - val_loss: 0.6714 - val_accuracy: 0.5884\n",
      "Epoch 21/400\n",
      "3/3 [==============================] - 0s 46ms/step- loss: 0.6822 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 159ms/step - loss: 0.6822 - accuracy: 0.5739 - val_loss: 0.6725 - val_accuracy: 0.6225\n",
      "Epoch 22/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.6809 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 165ms/step - loss: 0.6809 - accuracy: 0.5836 - val_loss: 0.6757 - val_accuracy: 0.5859\n",
      "Epoch 23/400\n",
      "3/3 [==============================] - 0s 44ms/step- loss: 0.6814 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 160ms/step - loss: 0.6814 - accuracy: 0.5811 - val_loss: 0.6719 - val_accuracy: 0.5947\n",
      "Epoch 24/400\n",
      "3/3 [==============================] - 0s 42ms/step- loss: 0.6808 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 164ms/step - loss: 0.6808 - accuracy: 0.5780 - val_loss: 0.6699 - val_accuracy: 0.5947\n",
      "Epoch 25/400\n",
      "3/3 [==============================] - 0s 47ms/step- loss: 0.6903 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 166ms/step - loss: 0.6903 - accuracy: 0.5726 - val_loss: 0.6744 - val_accuracy: 0.5795\n",
      "Epoch 26/400\n",
      "3/3 [==============================] - 0s 47ms/step- loss: 0.6800 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 164ms/step - loss: 0.6800 - accuracy: 0.5789 - val_loss: 0.6816 - val_accuracy: 0.5694\n",
      "Epoch 27/400\n",
      "3/3 [==============================] - 0s 44ms/step- loss: 0.6797 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 157ms/step - loss: 0.6797 - accuracy: 0.5761 - val_loss: 0.6709 - val_accuracy: 0.5808\n",
      "Epoch 28/400\n",
      "3/3 [==============================] - 0s 38ms/step- loss: 0.6800 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 165ms/step - loss: 0.6800 - accuracy: 0.5751 - val_loss: 0.6723 - val_accuracy: 0.5694\n",
      "Epoch 29/400\n",
      "3/3 [==============================] - 0s 44ms/step- loss: 0.6807 - accuracy: 0.\n",
      "159/159 [==============================] - 24s 152ms/step - loss: 0.6807 - accuracy: 0.5713 - val_loss: 0.6703 - val_accuracy: 0.5947\n",
      "Epoch 30/400\n",
      "3/3 [==============================] - 0s 38ms/step- loss: 0.6809 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 163ms/step - loss: 0.6809 - accuracy: 0.5694 - val_loss: 0.6702 - val_accuracy: 0.5821\n",
      "Epoch 31/400\n",
      "3/3 [==============================] - 0s 37ms/step- loss: 0.6803 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 163ms/step - loss: 0.6803 - accuracy: 0.5799 - val_loss: 0.6708 - val_accuracy: 0.5694\n",
      "Epoch 32/400\n",
      "3/3 [==============================] - 0s 45ms/step- loss: 0.6781 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 163ms/step - loss: 0.6781 - accuracy: 0.5735 - val_loss: 0.6706 - val_accuracy: 0.5922\n",
      "Epoch 33/400\n",
      "3/3 [==============================] - 0s 45ms/step- loss: 0.6830 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 162ms/step - loss: 0.6830 - accuracy: 0.5773 - val_loss: 0.6714 - val_accuracy: 0.5783\n",
      "Epoch 34/400\n",
      "3/3 [==============================] - 0s 42ms/step- loss: 0.6836 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 160ms/step - loss: 0.6836 - accuracy: 0.5701 - val_loss: 0.6702 - val_accuracy: 0.5821\n",
      "Epoch 35/400\n",
      "3/3 [==============================] - 0s 45ms/step- loss: 0.6772 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 162ms/step - loss: 0.6772 - accuracy: 0.5758 - val_loss: 0.6796 - val_accuracy: 0.5644\n",
      "Epoch 36/400\n",
      "3/3 [==============================] - 0s 45ms/step- loss: 0.6804 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 159ms/step - loss: 0.6804 - accuracy: 0.5846 - val_loss: 0.6726 - val_accuracy: 0.5783\n",
      "Epoch 37/400\n",
      "3/3 [==============================] - 0s 45ms/step- loss: 0.6794 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 160ms/step - loss: 0.6794 - accuracy: 0.5726 - val_loss: 0.6699 - val_accuracy: 0.5821\n",
      "Epoch 38/400\n",
      "3/3 [==============================] - 0s 56ms/step- loss: 0.6795 - accuracy: \n",
      "159/159 [==============================] - 26s 160ms/step - loss: 0.6795 - accuracy: 0.5739 - val_loss: 0.6693 - val_accuracy: 0.5821\n",
      "Epoch 39/400\n",
      "3/3 [==============================] - 0s 45ms/step- loss: 0.6771 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 158ms/step - loss: 0.6771 - accuracy: 0.5780 - val_loss: 0.6793 - val_accuracy: 0.5783\n",
      "Epoch 40/400\n",
      "3/3 [==============================] - 0s 46ms/step- loss: 0.6896 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 166ms/step - loss: 0.6896 - accuracy: 0.5720 - val_loss: 0.6705 - val_accuracy: 0.5821\n",
      "Epoch 41/400\n",
      "3/3 [==============================] - 0s 44ms/step- loss: 0.7011 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 163ms/step - loss: 0.7011 - accuracy: 0.5571 - val_loss: 0.7196 - val_accuracy: 0.5631\n",
      "Epoch 42/400\n",
      "3/3 [==============================] - 0s 51ms/step- loss: 0.6917 - accuracy: 0.\n",
      "159/159 [==============================] - 27s 169ms/step - loss: 0.6917 - accuracy: 0.5404 - val_loss: 0.6836 - val_accuracy: 0.5631\n",
      "Epoch 43/400\n",
      "3/3 [==============================] - 0s 45ms/step- loss: 0.6873 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 160ms/step - loss: 0.6873 - accuracy: 0.5508 - val_loss: 0.6826 - val_accuracy: 0.5631\n",
      "Epoch 44/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.6851 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 160ms/step - loss: 0.6851 - accuracy: 0.5606 - val_loss: 0.6800 - val_accuracy: 0.5631\n",
      "Epoch 45/400\n",
      "3/3 [==============================] - 0s 42ms/step- loss: 0.6827 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 161ms/step - loss: 0.6827 - accuracy: 0.5625 - val_loss: 0.6857 - val_accuracy: 0.5631\n",
      "Epoch 46/400\n",
      "3/3 [==============================] - 0s 42ms/step- loss: 0.6830 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 160ms/step - loss: 0.6830 - accuracy: 0.5600 - val_loss: 0.6943 - val_accuracy: 0.4482\n",
      "Epoch 47/400\n",
      "3/3 [==============================] - 0s 47ms/step- loss: 0.6823 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 161ms/step - loss: 0.6823 - accuracy: 0.5660 - val_loss: 0.6753 - val_accuracy: 0.5947\n",
      "Epoch 48/400\n",
      "3/3 [==============================] - 0s 55ms/step- loss: 0.6799 - accuracy: \n",
      "159/159 [==============================] - 26s 161ms/step - loss: 0.6799 - accuracy: 0.5669 - val_loss: 0.6757 - val_accuracy: 0.5758\n",
      "Epoch 49/400\n",
      "3/3 [==============================] - 0s 42ms/step- loss: 0.6793 - accuracy: 0.\n",
      "159/159 [==============================] - 27s 170ms/step - loss: 0.6793 - accuracy: 0.5717 - val_loss: 0.7703 - val_accuracy: 0.4482\n",
      "Epoch 50/400\n",
      "3/3 [==============================] - 0s 44ms/step- loss: 0.6777 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 166ms/step - loss: 0.6777 - accuracy: 0.5754 - val_loss: 0.6894 - val_accuracy: 0.5758\n",
      "Epoch 51/400\n",
      "3/3 [==============================] - 0s 46ms/step- loss: 0.6827 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 160ms/step - loss: 0.6827 - accuracy: 0.5764 - val_loss: 0.6835 - val_accuracy: 0.5631\n",
      "Epoch 52/400\n",
      "3/3 [==============================] - 0s 44ms/step- loss: 0.6896 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 165ms/step - loss: 0.6896 - accuracy: 0.5464 - val_loss: 0.6842 - val_accuracy: 0.5631\n",
      "Epoch 53/400\n",
      "3/3 [==============================] - 0s 40ms/step- loss: 0.6848 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 160ms/step - loss: 0.6848 - accuracy: 0.5647 - val_loss: 0.6761 - val_accuracy: 0.5833\n",
      "Epoch 54/400\n",
      "3/3 [==============================] - 0s 44ms/step- loss: 0.6758 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 164ms/step - loss: 0.6758 - accuracy: 0.5871 - val_loss: 0.6677 - val_accuracy: 0.5758\n",
      "Epoch 55/400\n",
      "3/3 [==============================] - 0s 44ms/step- loss: 0.6849 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 161ms/step - loss: 0.6849 - accuracy: 0.5650 - val_loss: 0.6683 - val_accuracy: 0.5909\n",
      "Epoch 56/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.6879 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 163ms/step - loss: 0.6879 - accuracy: 0.5584 - val_loss: 0.7033 - val_accuracy: 0.5227\n",
      "Epoch 57/400\n",
      "3/3 [==============================] - 0s 54ms/step- loss: 0.6820 - accuracy: \n",
      "159/159 [==============================] - 26s 163ms/step - loss: 0.6820 - accuracy: 0.5767 - val_loss: 0.6724 - val_accuracy: 0.6187\n",
      "Epoch 58/400\n",
      "3/3 [==============================] - 0s 49ms/step- loss: 0.6781 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 166ms/step - loss: 0.6781 - accuracy: 0.5855 - val_loss: 0.6639 - val_accuracy: 0.6225\n",
      "Epoch 59/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.6889 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 162ms/step - loss: 0.6889 - accuracy: 0.5559 - val_loss: 0.6852 - val_accuracy: 0.5631\n",
      "Epoch 60/400\n",
      "3/3 [==============================] - 0s 41ms/step- loss: 0.6860 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 165ms/step - loss: 0.6860 - accuracy: 0.5556 - val_loss: 0.6899 - val_accuracy: 0.5745\n",
      "Epoch 61/400\n",
      "3/3 [==============================] - 0s 44ms/step- loss: 0.6876 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 162ms/step - loss: 0.6876 - accuracy: 0.5612 - val_loss: 0.6702 - val_accuracy: 0.5732\n",
      "Epoch 62/400\n",
      "3/3 [==============================] - 0s 39ms/step- loss: 0.6790 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 166ms/step - loss: 0.6790 - accuracy: 0.5701 - val_loss: 0.6862 - val_accuracy: 0.5631\n",
      "Epoch 63/400\n",
      "3/3 [==============================] - 0s 45ms/step- loss: 0.6774 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 157ms/step - loss: 0.6774 - accuracy: 0.5739 - val_loss: 0.6801 - val_accuracy: 0.5859\n",
      "Epoch 64/400\n",
      "3/3 [==============================] - 0s 37ms/step- loss: 0.6775 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 163ms/step - loss: 0.6775 - accuracy: 0.5830 - val_loss: 0.6707 - val_accuracy: 0.5947\n",
      "Epoch 65/400\n",
      "3/3 [==============================] - 0s 41ms/step- loss: 0.6755 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 161ms/step - loss: 0.6755 - accuracy: 0.5739 - val_loss: 0.6725 - val_accuracy: 0.5947\n",
      "Epoch 66/400\n",
      "3/3 [==============================] - 0s 40ms/step- loss: 0.6774 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 162ms/step - loss: 0.6774 - accuracy: 0.5723 - val_loss: 0.6606 - val_accuracy: 0.6162\n",
      "Epoch 67/400\n",
      "3/3 [==============================] - 0s 41ms/step- loss: 0.6755 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 160ms/step - loss: 0.6755 - accuracy: 0.5814 - val_loss: 0.6703 - val_accuracy: 0.5821\n",
      "Epoch 68/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.6758 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 166ms/step - loss: 0.6758 - accuracy: 0.5780 - val_loss: 0.6656 - val_accuracy: 0.6149\n",
      "Epoch 69/400\n",
      "3/3 [==============================] - 0s 39ms/step- loss: 0.6734 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 162ms/step - loss: 0.6734 - accuracy: 0.5795 - val_loss: 0.6685 - val_accuracy: 0.5669\n",
      "Epoch 70/400\n",
      "3/3 [==============================] - 0s 40ms/step- loss: 0.6742 - accuracy: 0.\n",
      "159/159 [==============================] - 27s 168ms/step - loss: 0.6742 - accuracy: 0.5792 - val_loss: 0.6646 - val_accuracy: 0.6111\n",
      "Epoch 71/400\n",
      "3/3 [==============================] - 0s 41ms/step- loss: 0.6722 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 165ms/step - loss: 0.6722 - accuracy: 0.5881 - val_loss: 0.6642 - val_accuracy: 0.5694\n",
      "Epoch 72/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.6718 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 161ms/step - loss: 0.6718 - accuracy: 0.5878 - val_loss: 0.6758 - val_accuracy: 0.5821\n",
      "Epoch 73/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.6713 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 161ms/step - loss: 0.6713 - accuracy: 0.5855 - val_loss: 0.6644 - val_accuracy: 0.5821\n",
      "Epoch 74/400\n",
      "3/3 [==============================] - 0s 42ms/step- loss: 0.6673 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 161ms/step - loss: 0.6673 - accuracy: 0.5922 - val_loss: 0.6620 - val_accuracy: 0.6010\n",
      "Epoch 75/400\n",
      "3/3 [==============================] - 0s 44ms/step- loss: 0.6615 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 165ms/step - loss: 0.6615 - accuracy: 0.6020 - val_loss: 0.7091 - val_accuracy: 0.5795\n",
      "Epoch 76/400\n",
      "3/3 [==============================] - 0s 42ms/step- loss: 0.6614 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 162ms/step - loss: 0.6614 - accuracy: 0.6057 - val_loss: 0.6414 - val_accuracy: 0.6237\n",
      "Epoch 77/400\n",
      "3/3 [==============================] - 0s 48ms/step- loss: 0.6574 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 162ms/step - loss: 0.6574 - accuracy: 0.6108 - val_loss: 0.6463 - val_accuracy: 0.6174\n",
      "Epoch 78/400\n",
      "3/3 [==============================] - 0s 46ms/step- loss: 0.6540 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 161ms/step - loss: 0.6540 - accuracy: 0.6130 - val_loss: 0.6536 - val_accuracy: 0.6237\n",
      "Epoch 79/400\n",
      "3/3 [==============================] - 0s 40ms/step- loss: 0.6502 - accuracy: 0.\n",
      "159/159 [==============================] - 27s 167ms/step - loss: 0.6502 - accuracy: 0.6171 - val_loss: 0.6232 - val_accuracy: 0.6477\n",
      "Epoch 80/400\n",
      "3/3 [==============================] - 0s 42ms/step- loss: 0.6557 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 161ms/step - loss: 0.6557 - accuracy: 0.6051 - val_loss: 0.6764 - val_accuracy: 0.5189\n",
      "Epoch 81/400\n",
      "3/3 [==============================] - 0s 34ms/step- loss: 0.6550 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 166ms/step - loss: 0.6550 - accuracy: 0.6064 - val_loss: 0.6251 - val_accuracy: 0.6465\n",
      "Epoch 82/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.6593 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 156ms/step - loss: 0.6593 - accuracy: 0.6111 - val_loss: 0.6681 - val_accuracy: 0.6174\n",
      "Epoch 83/400\n",
      "3/3 [==============================] - 0s 44ms/step- loss: 0.6818 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 163ms/step - loss: 0.6818 - accuracy: 0.5660 - val_loss: 0.6823 - val_accuracy: 0.4621\n",
      "Epoch 84/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.6794 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 159ms/step - loss: 0.6794 - accuracy: 0.5584 - val_loss: 0.6768 - val_accuracy: 0.5745\n",
      "Epoch 85/400\n",
      "3/3 [==============================] - 0s 39ms/step- loss: 0.6769 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 157ms/step - loss: 0.6769 - accuracy: 0.5625 - val_loss: 0.6663 - val_accuracy: 0.5808\n",
      "Epoch 86/400\n",
      "3/3 [==============================] - 0s 44ms/step- loss: 0.6772 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 159ms/step - loss: 0.6772 - accuracy: 0.5619 - val_loss: 0.6592 - val_accuracy: 0.5997\n",
      "Epoch 87/400\n",
      "3/3 [==============================] - 0s 44ms/step- loss: 0.6680 - accuracy: 0.\n",
      "159/159 [==============================] - 24s 154ms/step - loss: 0.6680 - accuracy: 0.5764 - val_loss: 0.6481 - val_accuracy: 0.5972\n",
      "Epoch 88/400\n",
      "3/3 [==============================] - 0s 45ms/step- loss: 0.6580 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 163ms/step - loss: 0.6580 - accuracy: 0.5922 - val_loss: 0.6443 - val_accuracy: 0.6149\n",
      "Epoch 89/400\n",
      "3/3 [==============================] - 0s 48ms/step- loss: 0.6409 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 164ms/step - loss: 0.6409 - accuracy: 0.5953 - val_loss: 0.6471 - val_accuracy: 0.5821\n",
      "Epoch 90/400\n",
      "3/3 [==============================] - 0s 38ms/step- loss: 0.6424 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 166ms/step - loss: 0.6424 - accuracy: 0.5900 - val_loss: 0.6203 - val_accuracy: 0.5896\n",
      "Epoch 91/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.6399 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 166ms/step - loss: 0.6399 - accuracy: 0.5931 - val_loss: 0.6816 - val_accuracy: 0.5391\n",
      "Epoch 92/400\n",
      "3/3 [==============================] - 0s 39ms/step- loss: 0.6308 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 155ms/step - loss: 0.6308 - accuracy: 0.6080 - val_loss: 0.6204 - val_accuracy: 0.6098\n",
      "Epoch 93/400\n",
      "3/3 [==============================] - 0s 49ms/step- loss: 0.6207 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 162ms/step - loss: 0.6207 - accuracy: 0.6155 - val_loss: 0.6064 - val_accuracy: 0.5909\n",
      "Epoch 94/400\n",
      "3/3 [==============================] - 0s 41ms/step- loss: 0.6126 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 162ms/step - loss: 0.6126 - accuracy: 0.6149 - val_loss: 0.6071 - val_accuracy: 0.5884\n",
      "Epoch 95/400\n",
      "3/3 [==============================] - 0s 41ms/step- loss: 0.6048 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 160ms/step - loss: 0.6048 - accuracy: 0.6351 - val_loss: 0.5933 - val_accuracy: 0.6692\n",
      "Epoch 96/400\n",
      "3/3 [==============================] - 0s 44ms/step- loss: 0.5997 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 158ms/step - loss: 0.5997 - accuracy: 0.6373 - val_loss: 0.5839 - val_accuracy: 0.6907\n",
      "Epoch 97/400\n",
      "3/3 [==============================] - 0s 41ms/step- loss: 0.5948 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 164ms/step - loss: 0.5948 - accuracy: 0.6408 - val_loss: 0.5972 - val_accuracy: 0.6124\n",
      "Epoch 98/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.5956 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 159ms/step - loss: 0.5956 - accuracy: 0.6360 - val_loss: 0.5923 - val_accuracy: 0.6477\n",
      "Epoch 99/400\n",
      "3/3 [==============================] - 0s 39ms/step- loss: 0.6117 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 162ms/step - loss: 0.6117 - accuracy: 0.6484 - val_loss: 0.6985 - val_accuracy: 0.6414\n",
      "Epoch 100/400\n",
      "3/3 [==============================] - 0s 47ms/step- loss: 0.6212 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 165ms/step - loss: 0.6212 - accuracy: 0.6439 - val_loss: 0.6110 - val_accuracy: 0.6212\n",
      "Epoch 101/400\n",
      "3/3 [==============================] - 0s 45ms/step- loss: 0.6070 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 161ms/step - loss: 0.6070 - accuracy: 0.6619 - val_loss: 0.6683 - val_accuracy: 0.5972\n",
      "Epoch 102/400\n",
      "3/3 [==============================] - 0s 41ms/step- loss: 0.6077 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 156ms/step - loss: 0.6077 - accuracy: 0.6190 - val_loss: 0.5819 - val_accuracy: 0.6503\n",
      "Epoch 103/400\n",
      "3/3 [==============================] - 0s 42ms/step- loss: 0.5807 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 165ms/step - loss: 0.5807 - accuracy: 0.6591 - val_loss: 0.5728 - val_accuracy: 0.6919\n",
      "Epoch 104/400\n",
      "3/3 [==============================] - 0s 40ms/step- loss: 0.5649 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 167ms/step - loss: 0.5649 - accuracy: 0.6711 - val_loss: 0.5415 - val_accuracy: 0.6856\n",
      "Epoch 105/400\n",
      "3/3 [==============================] - 0s 54ms/step- loss: 0.5561 - accuracy: \n",
      "159/159 [==============================] - 26s 164ms/step - loss: 0.5561 - accuracy: 0.6783 - val_loss: 0.5483 - val_accuracy: 0.6439\n",
      "Epoch 106/400\n",
      "3/3 [==============================] - 0s 36ms/step- loss: 0.5484 - accuracy: 0.\n",
      "159/159 [==============================] - 27s 167ms/step - loss: 0.5484 - accuracy: 0.6796 - val_loss: 0.5379 - val_accuracy: 0.7096\n",
      "Epoch 107/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.5608 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 160ms/step - loss: 0.5608 - accuracy: 0.6689 - val_loss: 0.5605 - val_accuracy: 0.6742\n",
      "Epoch 108/400\n",
      "3/3 [==============================] - 0s 42ms/step- loss: 0.5761 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 165ms/step - loss: 0.5761 - accuracy: 0.6676 - val_loss: 0.5973 - val_accuracy: 0.6389\n",
      "Epoch 109/400\n",
      "3/3 [==============================] - 0s 53ms/step- loss: 0.5388 - accuracy: 0.\n",
      "159/159 [==============================] - 27s 170ms/step - loss: 0.5388 - accuracy: 0.6989 - val_loss: 0.5265 - val_accuracy: 0.6944\n",
      "Epoch 110/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.5323 - accuracy: 0.\n",
      "159/159 [==============================] - 27s 171ms/step - loss: 0.5323 - accuracy: 0.6976 - val_loss: 0.5387 - val_accuracy: 0.6667\n",
      "Epoch 111/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.5176 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 161ms/step - loss: 0.5176 - accuracy: 0.6992 - val_loss: 0.5127 - val_accuracy: 0.6679\n",
      "Epoch 112/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.5073 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 161ms/step - loss: 0.5073 - accuracy: 0.7131 - val_loss: 0.4844 - val_accuracy: 0.7412\n",
      "Epoch 113/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.4971 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 156ms/step - loss: 0.4971 - accuracy: 0.7181 - val_loss: 0.4819 - val_accuracy: 0.7172\n",
      "Epoch 114/400\n",
      "3/3 [==============================] - 0s 49ms/step- loss: 0.4911 - accuracy: 0.\n",
      "159/159 [==============================] - 27s 167ms/step - loss: 0.4911 - accuracy: 0.7333 - val_loss: 0.4479 - val_accuracy: 0.8106\n",
      "Epoch 115/400\n",
      "3/3 [==============================] - 0s 37ms/step- loss: 0.4759 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 165ms/step - loss: 0.4759 - accuracy: 0.7408 - val_loss: 0.4343 - val_accuracy: 0.7790\n",
      "Epoch 116/400\n",
      "3/3 [==============================] - 0s 46ms/step- loss: 0.4722 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 162ms/step - loss: 0.4722 - accuracy: 0.7377 - val_loss: 0.4397 - val_accuracy: 0.7866\n",
      "Epoch 117/400\n",
      "3/3 [==============================] - 0s 49ms/step- loss: 0.4578 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 161ms/step - loss: 0.4578 - accuracy: 0.7402 - val_loss: 0.4474 - val_accuracy: 0.7462\n",
      "Epoch 118/400\n",
      "3/3 [==============================] - 0s 50ms/step- loss: 0.4456 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 159ms/step - loss: 0.4456 - accuracy: 0.7563 - val_loss: 0.4534 - val_accuracy: 0.7399\n",
      "Epoch 119/400\n",
      "3/3 [==============================] - 0s 48ms/step- loss: 0.4406 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 162ms/step - loss: 0.4406 - accuracy: 0.7674 - val_loss: 0.4354 - val_accuracy: 0.7765\n",
      "Epoch 120/400\n",
      "3/3 [==============================] - 0s 41ms/step- loss: 0.4333 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 164ms/step - loss: 0.4333 - accuracy: 0.7648 - val_loss: 0.4150 - val_accuracy: 0.8157\n",
      "Epoch 121/400\n",
      "3/3 [==============================] - 0s 39ms/step- loss: 0.4231 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 164ms/step - loss: 0.4231 - accuracy: 0.7740 - val_loss: 0.6442 - val_accuracy: 0.6667\n",
      "Epoch 122/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.4238 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 157ms/step - loss: 0.4238 - accuracy: 0.7781 - val_loss: 0.6104 - val_accuracy: 0.6111\n",
      "Epoch 123/400\n",
      "3/3 [==============================] - 0s 42ms/step- loss: 0.4136 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 162ms/step - loss: 0.4136 - accuracy: 0.7847 - val_loss: 0.5004 - val_accuracy: 0.6717\n",
      "Epoch 124/400\n",
      "3/3 [==============================] - 0s 35ms/step- loss: 0.4022 - accuracy: 0.\n",
      "159/159 [==============================] - 27s 168ms/step - loss: 0.4022 - accuracy: 0.7929 - val_loss: 0.4075 - val_accuracy: 0.7967\n",
      "Epoch 125/400\n",
      "3/3 [==============================] - 0s 42ms/step- loss: 0.3920 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 162ms/step - loss: 0.3920 - accuracy: 0.7980 - val_loss: 0.4187 - val_accuracy: 0.7045\n",
      "Epoch 126/400\n",
      "3/3 [==============================] - 0s 45ms/step- loss: 0.3825 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 162ms/step - loss: 0.3825 - accuracy: 0.8046 - val_loss: 1.6728 - val_accuracy: 0.6616\n",
      "Epoch 127/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.4116 - accuracy: 0.\n",
      "159/159 [==============================] - 27s 169ms/step - loss: 0.4116 - accuracy: 0.8068 - val_loss: 0.4765 - val_accuracy: 0.7424\n",
      "Epoch 128/400\n",
      "3/3 [==============================] - 0s 43ms/step- loss: 0.3798 - accuracy: 0.\n",
      "159/159 [==============================] - 25s 160ms/step - loss: 0.3798 - accuracy: 0.8134 - val_loss: 0.3493 - val_accuracy: 0.8523\n",
      "Epoch 129/400\n",
      "3/3 [==============================] - 0s 45ms/step- loss: 0.3620 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 164ms/step - loss: 0.3620 - accuracy: 0.8220 - val_loss: 0.3335 - val_accuracy: 0.8561\n",
      "Epoch 130/400\n",
      "3/3 [==============================] - 0s 38ms/step- loss: 0.3540 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 163ms/step - loss: 0.3540 - accuracy: 0.8239 - val_loss: 0.2938 - val_accuracy: 0.8510\n",
      "Epoch 131/400\n",
      "3/3 [==============================] - 0s 42ms/step- loss: 0.3417 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 165ms/step - loss: 0.3417 - accuracy: 0.8321 - val_loss: 0.5848 - val_accuracy: 0.6818\n",
      "Epoch 132/400\n",
      "3/3 [==============================] - 0s 44ms/step- loss: 0.3527 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 161ms/step - loss: 0.3527 - accuracy: 0.8267 - val_loss: 0.3942 - val_accuracy: 0.8005\n",
      "Epoch 133/400\n",
      "3/3 [==============================] - 0s 40ms/step- loss: 0.3321 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 162ms/step - loss: 0.3321 - accuracy: 0.8368 - val_loss: 0.2822 - val_accuracy: 0.8750\n",
      "Epoch 134/400\n",
      "3/3 [==============================] - 0s 44ms/step- loss: 0.3456 - accuracy: 0.\n",
      "159/159 [==============================] - 26s 163ms/step - loss: 0.3456 - accuracy: 0.8371 - val_loss: 0.4472 - val_accuracy: 0.8043\n",
      "Epoch 135/400\n",
      " 19/159 [==>...........................] - ETA: 20s - loss: 0.2861 - accuracy: 0.8816"
     ]
    }
   ],
   "source": [
    "early_stop=tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=500, verbose=2, mode='auto', baseline=None, restore_best_weights=True)\n",
    "model.fit(X_train_Normalizado, y_train_Normalizado, epochs=400, batch_size=20, callbacks=[tensorboard_callback,cm_callback,early_stop], validation_data=(X_val_def, y_val_def))\n",
    "# Final evaluation of the model \n",
    "scores = model.evaluate(X_test_def, y_test_def, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "#y_pred2=np.where(y_pred>0,1,0)\n",
    "#y_pred2=y_pred2[:,-1]\n",
    "y_test_def2=np.argmax(y_test_def,axis=1)\n",
    "#y_test_def2=np.where(y_test_def>0,1,0)\n",
    "print(y_pred.shape)\n",
    "print(y_pred2.shape)\n",
    "print(y_test_def2.shape)\n",
    "#print(y_test_def[25])\n",
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs_infra: no_execute\n",
    "classes = [0, 1, 2, 3, 4]\n",
    "classes = [0, 1]\n",
    "cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test_def2, y_pred2, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('modelos/modelote1203_200')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('modelos/modelo_perfecto_{}_{}'.format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "n = len(y_pred2)\n",
    "reshaped = y_pred2[:n//4*4].reshape(-1, 4)\n",
    "mean_values = reshaped.mean(axis=1)\n",
    "\n",
    "mean_values = np.round(mean_values)\n",
    "mean_values = np.clip(mean_values, 0, 4)\n",
    "mean_values = mean_values.astype(int)\n",
    "print(mean_values)\n",
    "\n",
    "mode_values = stats.mode(reshaped, axis=1)[0]\n",
    "print(mode_values)\n",
    "\n",
    "# Convierte los arrays a DataFrames\n",
    "mean_df = pd.DataFrame(mean_values, columns=['mean'])\n",
    "mode_df = pd.DataFrame(mode_values, columns=['mode'])\n",
    "\n",
    "# Guarda los DataFrames en archivos Excel\n",
    "mean_df.to_excel(\"clasificacion_P1P2_mean_best7.xlsx\", index=False)\n",
    "mode_df.to_excel(\"clasificacion_P1_mode_best7.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename5 = \"lomosP1_20240430_clasificado_experto.hdf\"\n",
    "with pd.HDFStore(filename5,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e2  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e2 = pre_p_e2.loc[pre_p_e2['Pollo'] != 0]\n",
    "    pre_p_e2 =pre_p_e2.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_test2=np.zeros((pre_p_e2.shape[0],220,8))\n",
    "    y_test2=np.zeros((pre_p_e2.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e2.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if estado == 0 or estado== 1:\n",
    "           target = 1\n",
    "        else:\n",
    "           target = 0\n",
    "        #target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_test2[x]=pepito[:,3:11]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_test2[x]=target\n",
    "        y_test2_to_categorical = to_categorical(y_test2)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_test2_filtrado = X_test2\n",
    "#y_train_filtrado = y_train\n",
    "y_test2_filtrado = y_test2_to_categorical\n",
    "\n",
    "print(X_test2_filtrado.shape)\n",
    "print(y_test2_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "# concatenamos train y test\n",
    "#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\n",
    "data_2d_test = X_test2_filtrado.reshape(-1, X_test2_filtrado.shape[-1])\n",
    "normalized_data_2d_test = scaler.transform(data_2d_test)\n",
    "\n",
    "\n",
    "X_test2_def=normalized_data_2d_test.reshape(X_test2_filtrado.shape) \n",
    "# la alternativa es normalizar con el total\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "\n",
    "y_test2_def=y_test2_filtrado # los valores ya estaban normalizados\n",
    "\n",
    "print(y_test2_def.shape)\n",
    "\n",
    "print(y_test2_filtrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Crear un nuevo modelo con la misma arquitectura\n",
    "best_val_model = create_model()  # Reemplaza esto con la función que usaste para crear el modelo original\n",
    "\n",
    "# Cargar los mejores pesos\n",
    "best_val_model.load_weights('best_weights.h5')\n",
    "\n",
    "y_pred = best_val_model.predict(X_test2_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "n = len(y_pred2)\n",
    "print(n)\n",
    "reshaped = y_pred2[:n//4*4].reshape(-1, 4)\n",
    "mean_values = reshaped.mean(axis=1)\n",
    "\n",
    "mean_values = np.round(mean_values)\n",
    "mean_values = np.clip(mean_values, 0, 4)\n",
    "mean_values = mean_values.astype(int)\n",
    "print(mean_values.shape)\n",
    "\n",
    "mode_values = stats.mode(reshaped, axis=1)[0]\n",
    "print(mode_values.shape)\n",
    "\n",
    "n = len(y_test2_def)\n",
    "y_test2_def2=np.argmax(y_test2_def,axis=1)\n",
    "print(y_test_def2.shape)\n",
    "print(n)\n",
    "reshaped2 = y_test2_def2[:n//4*4].reshape(-1, 4)\n",
    "target_mean_values = reshaped2.mean(axis=1)\n",
    "\n",
    "target_mean_values = np.round(target_mean_values)\n",
    "target_mean_values = np.clip(target_mean_values, 0, 4)\n",
    "target_mean_values = target_mean_values.astype(int)\n",
    "print(target_mean_values.shape)\n",
    "\n",
    "target_mode_values = stats.mode(reshaped2, axis=1)[0]\n",
    "print(target_mode_values.shape)\n",
    "print(reshaped)\n",
    "print(mode_values)\n",
    "print(target_mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs_infra: no_execute\n",
    "classes = [0, 1, 2, 3, 4]\n",
    "classes = [0, 1]\n",
    "cm=confusion_matrix(y_test2_def2, y_pred2,labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm.diagonal()/cm.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(target_mean_values, mean_values, target_names=target_names, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow_2024_GPU)",
   "language": "python",
   "name": "tensorflow_2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
