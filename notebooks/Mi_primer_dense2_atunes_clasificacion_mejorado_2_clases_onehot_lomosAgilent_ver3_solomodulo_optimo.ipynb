{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:\\nuevas_investigaciones_alimentos_2024\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM,Bidirectional,GRU\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import datetime\n",
    "import io\n",
    "import itertools\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Obtener la ruta del directorio actual\n",
    "os.chdir('..')\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "# Construir la ruta relativa al directorio que quieres agregar\n",
    "relative_dir = os.path.join(current_dir, 'mis_pkgs/')\n",
    "\n",
    "# Agregar la ruta relativa al sys.path\n",
    "sys.path.insert(0, relative_dir)\n",
    "\n",
    "from MIOPATIA_db import DB_management as db \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_muestras=401\n",
    "numero_clases=2\n",
    "entrada=slice(3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a quedarme con los 50 atunes P1 para obtener conjunto de training y validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Add, Activation, Concatenate, Conv2D, Dropout \n",
    "from tensorflow.keras.layers import Flatten, Input, GlobalAveragePooling2D, MaxPooling2D\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "__version__ = '0.0.1'\n",
    "\n",
    "\n",
    "def SqueezeNet(input_shape, nb_classes, use_bypass=False, dropout_rate=None, compression=1.0):\n",
    "    \"\"\"\n",
    "    Creating a SqueezeNet of version 1.0\n",
    "    \n",
    "    Arguments:\n",
    "        input_shape  : shape of the input images e.g. (224,224,3)\n",
    "        nb_classes   : number of classes\n",
    "        use_bypass   : if true, bypass connections will be created at fire module 3, 5, 7, and 9 (default: False)\n",
    "        dropout_rate : defines the dropout rate that is accomplished after last fire module (default: None)\n",
    "        compression  : reduce the number of feature-maps (default: 1.0)\n",
    "        \n",
    "    Returns:\n",
    "        Model        : Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(int(96*compression), (7,7), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "    x = create_fire_module(x, int(16*compression), name='fire3', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool4')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(32*compression), name='fire5', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "    x = create_fire_module(x, int(48*compression), name='fire7', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool8')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(64*compression), name='fire9', use_bypass=use_bypass)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        \n",
    "    x = output(x, nb_classes)\n",
    "\n",
    "    return Model(inputs=input_img, outputs=x)\n",
    "\n",
    "\n",
    "def SqueezeNet_11(input_shape, nb_classes, dropout_rate=None, compression=1.0):\n",
    "    \"\"\"\n",
    "    Creating a SqueezeNet of version 1.1\n",
    "    \n",
    "    2.4x less computation over SqueezeNet 1.0 implemented above.\n",
    "    \n",
    "    Arguments:\n",
    "        input_shape  : shape of the input images e.g. (224,224,3)\n",
    "        nb_classes   : number of classes\n",
    "        dropout_rate : defines the dropout rate that is accomplished after last fire module (default: None)\n",
    "        compression  : reduce the number of feature-maps\n",
    "        \n",
    "    Returns:\n",
    "        Model        : Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(int(64*compression), (3,3), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "    x = create_fire_module(x, int(16*compression), name='fire3')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool3')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "    x = create_fire_module(x, int(32*compression), name='fire5')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool5')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "    x = create_fire_module(x, int(48*compression), name='fire7')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire9')\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # Creating last conv10\n",
    "    x = output(x, nb_classes)\n",
    "\n",
    "    return Model(inputs=input_img, outputs=x)\n",
    "\n",
    "\n",
    "def output(x, nb_classes):\n",
    "    x = Conv2D(nb_classes, (1,1), strides=(1,1), padding='valid', name='conv10')(x)\n",
    "    x = GlobalAveragePooling2D(name='avgpool10')(x)\n",
    "    x = Activation(\"softmax\", name='softmax')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_fire_module(x, nb_squeeze_filter, name, use_bypass=False):\n",
    "    \"\"\"\n",
    "    Creates a fire module\n",
    "    \n",
    "    Arguments:\n",
    "        x                 : input\n",
    "        nb_squeeze_filter : number of filters of squeeze. The filtersize of expand is 4 times of squeeze\n",
    "        use_bypass        : if True then a bypass will be added\n",
    "        name              : name of module e.g. fire123\n",
    "    \n",
    "    Returns:\n",
    "        x                 : returns a fire module\n",
    "    \"\"\"\n",
    "    \n",
    "    nb_expand_filter = 4 * nb_squeeze_filter\n",
    "    squeeze    = Conv2D(nb_squeeze_filter,(1,1), activation='relu', padding='same', name='%s_squeeze'%name)(x)\n",
    "    expand_1x1 = Conv2D(nb_expand_filter, (1,1), activation='relu', padding='same', name='%s_expand_1x1'%name)(squeeze)\n",
    "    expand_3x3 = Conv2D(nb_expand_filter, (3,3), activation='relu', padding='same', name='%s_expand_3x3'%name)(squeeze)\n",
    "    \n",
    "    axis = get_axis()\n",
    "    x_ret = Concatenate(axis=axis, name='%s_concatenate'%name)([expand_1x1, expand_3x3])\n",
    "    \n",
    "    if use_bypass:\n",
    "        x_ret = Add(name='%s_concatenate_bypass'%name)([x_ret, x])\n",
    "        \n",
    "    return x_ret\n",
    "\n",
    "\n",
    "def get_axis():\n",
    "    axis = -1 if K.image_data_format() == 'channels_last' else 1\n",
    "    return axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1749, 2)\n"
     ]
    }
   ],
   "source": [
    "filename = \"COPIA_PANDAS\\hdf_lomosAgilent_trainval_filtrado_def_good_ampliado_the_best7.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    # p_e =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_train=np.zeros((pre_p_e1.shape[0],numero_muestras,1))\n",
    "    y_train=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1:\n",
    "                target = 0\n",
    "            else:\n",
    "                target = 1\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_train[x]=pepito[:,entrada]\n",
    "        #X_train[x]=X_train[x].reshape(X_train[x].shape[0],-1)\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_train[x]=target\n",
    "        y_train_to_categorical = to_categorical(y_train)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_train_filtrado = X_train\n",
    "#y_train_filtrado = y_train\n",
    "y_train_filtrado = y_train_to_categorical\n",
    "\n",
    "# print(X_train_filtrado.shape)\n",
    "# print(y_train_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "scaler = StandardScaler()\n",
    "data_2d = X_train_filtrado.reshape(-1, X_train_filtrado.shape[-1])\n",
    "normalized_data_2d = scaler.fit_transform(data_2d)\n",
    "#para recurrentes\n",
    "#X_train_Normalizado=normalized_data_2d.reshape(X_train_filtrado.shape) #para recurrentes\n",
    "#para densas\n",
    "X_train_Normalizado=normalized_data_2d.reshape(X_train_filtrado.shape[0],-1)\n",
    "y_train_Normalizado=y_train_filtrado # los valores ya estaban normalizados\n",
    "print(y_train_Normalizado.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 401, 1)\n",
      "(39, 2)\n",
      "[-0.27723021 -0.28713828 -0.29644955 -0.30418939 -0.3110908  -0.31860429\n",
      " -0.32460417 -0.33022638 -0.33594659 -0.34067864 -0.34436083 -0.34814366\n",
      " -0.35149426 -0.35421378 -0.35806156 -0.36071227 -0.36353922 -0.36671855\n",
      " -0.3698107  -0.37247238 -0.37503001 -0.37720052 -0.37913055 -0.38054311\n",
      " -0.38239564 -0.38451774 -0.38595603 -0.38743977 -0.3886623  -0.38947622\n",
      " -0.39043743 -0.39155647 -0.39244684 -0.39339374 -0.39417131 -0.39496054\n",
      " -0.39578907 -0.39566669 -0.39598378 -0.39674184 -0.39659332 -0.39769482\n",
      " -0.39804358 -0.39857145 -0.39893024 -0.39912852 -0.39923359 -0.39947396\n",
      " -0.40098808 -0.40174455 -0.4022128  -0.40289413 -0.40320536 -0.4036337\n",
      " -0.40386031 -0.40336821 -0.40261684 -0.40305904 -0.4025417  -0.40429375\n",
      " -0.40533684 -0.40653404 -0.40717541 -0.40816068 -0.40878208 -0.40949632\n",
      " -0.40964735 -0.41002768 -0.41083956 -0.41074534 -0.41106303 -0.41146191\n",
      " -0.41130685 -0.41082938 -0.41130383 -0.41146295 -0.41174475 -0.41216682\n",
      " -0.41203064 -0.41202709 -0.41189368 -0.41205962 -0.41223171 -0.41251972\n",
      " -0.41249524 -0.41294486 -0.41284269 -0.41277371 -0.41308046 -0.41364393\n",
      " -0.41362304 -0.41404774 -0.41402017 -0.41445357 -0.41393905 -0.41436994\n",
      " -0.41433463 -0.41408585 -0.41384473 -0.41408522 -0.41430855 -0.41434704\n",
      " -0.4140578  -0.41429042 -0.41471472 -0.41471182 -0.41475238 -0.41476194\n",
      " -0.41498552 -0.4151995  -0.41504992 -0.41484098 -0.41526159 -0.41585131\n",
      " -0.41509748 -0.41493018 -0.4157015  -0.41635034 -0.41700406 -0.41689858\n",
      " -0.41669703 -0.41708904 -0.41702357 -0.41735855 -0.41765146 -0.41783339\n",
      " -0.41780425 -0.41750152 -0.41798622 -0.41788537 -0.41773331 -0.41823144\n",
      " -0.41835734 -0.41869215 -0.41918038 -0.41908611 -0.41901667 -0.41885262\n",
      " -0.41898897 -0.41942406 -0.42008951 -0.42067294 -0.42134212 -0.42184289\n",
      " -0.42204783 -0.42265517 -0.4232288  -0.42360319 -0.42436016 -0.42489488\n",
      " -0.42504588 -0.42572364 -0.42607496 -0.42653395 -0.42744968 -0.4279679\n",
      " -0.42780207 -0.42884928 -0.42994792 -0.43068496 -0.43187713 -0.43263715\n",
      " -0.43340111 -0.43425907 -0.43500352 -0.43588684 -0.43679629 -0.43796389\n",
      " -0.43894233 -0.43972843 -0.4408964  -0.44218177 -0.4431216  -0.44449106\n",
      " -0.44595552 -0.44726445 -0.44848972 -0.44986418 -0.45131288 -0.45262571\n",
      " -0.45399207 -0.45551895 -0.45710616 -0.45868436 -0.46041709 -0.46212779\n",
      " -0.46370159 -0.46551103 -0.46744295 -0.4694966  -0.47142727 -0.47349292\n",
      " -0.47563566 -0.47779846 -0.4800021  -0.4823113  -0.48459661 -0.48685283\n",
      " -0.48913729 -0.49146862 -0.49391182 -0.49641704 -0.49898935 -0.50129837\n",
      " -0.50370227 -0.50620163 -0.50855392 -0.51096746 -0.51362759 -0.51614003\n",
      " -0.51867355 -0.52115518 -0.52377448 -0.52632595 -0.52881601 -0.53150238\n",
      " -0.53407982 -0.53659478 -0.53927418 -0.54189549 -0.54429951 -0.54664579\n",
      " -0.54900849 -0.55141308 -0.55371985 -0.55617061 -0.55864034 -0.56090462\n",
      " -0.56317283 -0.56541188 -0.56763815 -0.56971781 -0.57188697 -0.57394118\n",
      " -0.57603391 -0.57803115 -0.58001173 -0.582001   -0.58388161 -0.58584071\n",
      " -0.58769136 -0.58942694 -0.59096906 -0.59243905 -0.59401286 -0.59551744\n",
      " -0.59695907 -0.59847204 -0.60003102 -0.60144871 -0.60270764 -0.60411725\n",
      " -0.60543068 -0.60672392 -0.60803013 -0.60923262 -0.61027349 -0.61135219\n",
      " -0.61231376 -0.61318684 -0.61422032 -0.61531962 -0.61627135 -0.6171001\n",
      " -0.61796756 -0.61866978 -0.61942377 -0.62013065 -0.62082088 -0.6215412\n",
      " -0.62226783 -0.62287548 -0.62345881 -0.624066   -0.62462506 -0.62520276\n",
      " -0.62574384 -0.62618874 -0.62668531 -0.62709345 -0.62751702 -0.62772711\n",
      " -0.62796468 -0.62817941 -0.62856977 -0.6291252  -0.62945134 -0.62979754\n",
      " -0.63002037 -0.6303821  -0.63062982 -0.63106739 -0.63127273 -0.63157771\n",
      " -0.63186994 -0.63218706 -0.6323859  -0.63255789 -0.63267296 -0.6327741\n",
      " -0.63289132 -0.63303945 -0.63316675 -0.63338359 -0.63355014 -0.63359671\n",
      " -0.63387779 -0.63405965 -0.6343679  -0.63462713 -0.63470135 -0.63488236\n",
      " -0.63509554 -0.63539136 -0.63555454 -0.63587168 -0.63615035 -0.63636659\n",
      " -0.636621   -0.63684264 -0.63731205 -0.63776368 -0.63802526 -0.63842795\n",
      " -0.63885771 -0.6393372  -0.63979393 -0.64010383 -0.64041146 -0.64103164\n",
      " -0.64167878 -0.64213411 -0.64277459 -0.64333472 -0.64394417 -0.64464151\n",
      " -0.64541804 -0.64630128 -0.64708097 -0.64787646 -0.64886251 -0.64974757\n",
      " -0.65064913 -0.65164741 -0.65261887 -0.65369144 -0.65474302 -0.65578875\n",
      " -0.65695393 -0.65810031 -0.65917153 -0.66045435 -0.66176371 -0.66313064\n",
      " -0.66467216 -0.66622424 -0.66759291 -0.66894594 -0.67028179 -0.67161977\n",
      " -0.67313468 -0.67451088 -0.67602696 -0.67752829 -0.67900588 -0.68046806\n",
      " -0.68197572 -0.68349973 -0.684962   -0.68644352 -0.68806709 -0.68959741\n",
      " -0.69107826 -0.69265224 -0.69430363 -0.69592894 -0.69746204 -0.69900983\n",
      " -0.70032777 -0.70188471 -0.70347281 -0.70500838 -0.70658693 -0.70810307\n",
      " -0.7096662  -0.71114211 -0.71236561 -0.71415626 -0.71558296 -0.71696781\n",
      " -0.71841132 -0.71990342 -0.72126559 -0.72269037 -0.72414104 -0.72549989\n",
      " -0.7268224  -0.72818261 -0.72953794 -0.73085726 -0.73054362]\n"
     ]
    }
   ],
   "source": [
    "filename = \"COPIA_PANDAS\\hdf_lomosAgilent_test_filtrado_def_good.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    pre_p_e1 =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_test=np.zeros((pre_p_e1.shape[0],numero_muestras,1))\n",
    "    y_test=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1:\n",
    "                target = 0\n",
    "            else:\n",
    "                target = 1\n",
    "\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_test[x]=pepito[:,entrada]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_test[x]=target\n",
    "        y_test_to_categorical = to_categorical(y_test)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_test_filtrado = X_test\n",
    "#y_train_filtrado = y_train\n",
    "y_test_filtrado = y_test_to_categorical\n",
    "\n",
    "print(X_test_filtrado.shape)\n",
    "print(y_test_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "# concatenamos train y test\n",
    "#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\n",
    "data_2d_test = X_test_filtrado.reshape(-1, X_test_filtrado.shape[-1])\n",
    "normalized_data_2d_test = scaler.transform(data_2d_test)\n",
    "\n",
    "\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape[0],-1) \n",
    "# la alternativa es normalizar con el total\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "\n",
    "y_test_def=y_test_filtrado # los valores ya estaban normalizados\n",
    "print(X_test_def[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer los conjuntos de entrenamiento validacion y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide el dataset en entrenamiento y temporal (test+validación)\n",
    "# X_temp, X_test_def, y_temp, y_test_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.2, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Divide el dataset temporal en validación y test\n",
    "X_train_def, X_val_def, y_train_def, y_val_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.25, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Ahora, X_train, X_val y X_test contienen los datos de entrada para los conjuntos de entrenamiento, validación y prueba, respectivamente.\n",
    "# y_train, y_val y y_test contienen las clases correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1311, 401)\n",
      "(438, 401)\n",
      "(39, 401)\n",
      "(1311, 2)\n",
      "(438, 2)\n",
      "(39, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_def.shape)\n",
    "print(X_val_def.shape)\n",
    "print(X_test_def.shape)\n",
    "print(y_train_def.shape)\n",
    "print(y_val_def.shape)\n",
    "print(y_test_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "#%tensorboard --logdir logs\n",
    "#log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"\n",
    "    Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\n",
    "    \"\"\"\n",
    "    \n",
    "    buf = io.BytesIO()\n",
    "    \n",
    "    # Use plt.savefig to save the plot to a PNG in memory.\n",
    "    plt.savefig(buf, format='png')\n",
    "    \n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    \n",
    "    # Use tf.image.decode_png to convert the PNG buffer\n",
    "    # to a TF image. Make sure you use 4 channels.\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    \n",
    "    # Use tf.expand_dims to add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "       class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    \n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    # Normalize the confusion matrix.\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    \n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    threshold = 0.5\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"red\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_aprendizaje=0.001\n",
    "dimension_LSTM=50\n",
    "dimension_dense1=50\n",
    "dimension_dense2=20\n",
    "algoritmo='rmsprop'\n",
    "supermax=8*4\n",
    "lossfunction='categorical_crossentropy'\n",
    "def create_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    # model.add(Bidirectional(GRU(dimension_LSTM, return_sequences=True, recurrent_regularizer='L2'),input_shape=(401, 8)))\n",
    "    # # model.add(GRU(50, return_sequences=True))\n",
    "    # model.add(GRU(50, return_sequences=False))\n",
    "    model.add(Dense(dimension_dense1, activation='tanh', activity_regularizer='L2'))\n",
    "    model.add(Dense(dimension_dense2, activation='tanh'))\n",
    "    model.add(Dense(numero_clases, activation='softmax'))\n",
    "    model.compile(loss=lossfunction, optimizer=algoritmo, metrics=['accuracy'])\n",
    "    model.optimizer.lr=(factor_aprendizaje)\n",
    "    return model\n",
    "\n",
    "model=create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar una lista de los números en el rango del slice\n",
    "numbers = list(range(entrada.start, entrada.stop))\n",
    "\n",
    "# Convertir la lista a un string con los números separados por guiones\n",
    "slice_str = \"-\".join(map(str, numbers))\n",
    "\n",
    "\n",
    "experimento=\"LOMOS_Agilent_entradas_{}_dense1Rl2_{}_dense2_{}_clases_{}_loss_{}_lr_{}_algoritmo_{}\".format(slice_str,dimension_dense1,dimension_dense2,numero_clases,lossfunction,factor_aprendizaje,algoritmo)\n",
    "logdir=\"./logs/defs/{}_{}\".format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if numero_clases==2:\n",
    "    class_names=['Buenos', 'Malos']\n",
    "else:\n",
    "    class_names=['A', 'B+', 'B', 'B-','C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    \n",
    "    # Use the model to predict the values from the test_images.\n",
    "    y_pred = model.predict(X_test_def)\n",
    "    #y_pred1=y_pred[:,-1]\n",
    "    y_pred2=y_pred.argmax(axis=1)\n",
    "    #y_pred2=np.where(y_pred>0,1,0)\n",
    "    #y_pred2=y_pred2[:,-1]\n",
    "    if numero_clases==2:\n",
    "        classes = [0, 1]    \n",
    "    else:\n",
    "\n",
    "        classes = [0, 1, 2, 3, 4] \n",
    "    #classes = [0, 1]\n",
    "    y_test_def2=np.argmax(y_test_def,axis=1)  \n",
    "    #y_test_def2=np.where(y_test_def>0,1,0)\n",
    "    cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    figura = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figura)\n",
    "    \n",
    "    # Log the confusion matrix as an image summary.\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1749, 2)\n",
      "(438, 2)\n"
     ]
    }
   ],
   "source": [
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "print(y_train_Normalizado.shape)\n",
    "print(y_val_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un callback para guardar los mejores pesos\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('best_weights.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step loss: 0.9028 - accuracy: 0.578\n",
      "14/14 [==============================] - 2s 75ms/step - loss: 0.8910 - accuracy: 0.5843 - val_loss: 1.0445 - val_accuracy: 0.6027\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.8106 - accuracy: 0.61\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.8053 - accuracy: 0.6034 - val_loss: 1.0195 - val_accuracy: 0.4909\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7530 - accuracy: 0.60\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.7487 - accuracy: 0.6064 - val_loss: 0.9692 - val_accuracy: 0.4749\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 1.0621 - accuracy: 0.47\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.7410 - accuracy: 0.6171 - val_loss: 0.7592 - val_accuracy: 0.5936\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6892 - accuracy: 0.63\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.6892 - accuracy: 0.6377 - val_loss: 0.7449 - val_accuracy: 0.5662\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7056 - accuracy: 0.63\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.6993 - accuracy: 0.6468 - val_loss: 0.7174 - val_accuracy: 0.6027\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6637 - accuracy: 0.65\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.6637 - accuracy: 0.6598 - val_loss: 0.8154 - val_accuracy: 0.5890\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7176 - accuracy: 0.64\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7165 - accuracy: 0.6423 - val_loss: 0.7426 - val_accuracy: 0.5662\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6770 - accuracy: 0.63\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.6768 - accuracy: 0.6400 - val_loss: 0.6740 - val_accuracy: 0.6073\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.6544 - accuracy: 0.68\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.6551 - accuracy: 0.6865 - val_loss: 0.7172 - val_accuracy: 0.6416\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6772 - accuracy: 0.66\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.6765 - accuracy: 0.6674 - val_loss: 0.9983 - val_accuracy: 0.5320\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6818 - accuracy: 0.68\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m early_stop\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, baseline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcm_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_def\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Final evaluation of the model \u001b[39;00m\n\u001b[0;32m      4\u001b[0m scores \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test_def, y_test_def, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\keras\\engine\\training.py:1624\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1619\u001b[0m     val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1620\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1621\u001b[0m     }\n\u001b[0;32m   1622\u001b[0m     epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n\u001b[1;32m-> 1624\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_logs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1625\u001b[0m training_logs \u001b[38;5;241m=\u001b[39m epoch_logs\n\u001b[0;32m   1626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\keras\\callbacks.py:448\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    446\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_logs(logs)\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m--> 448\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 20\u001b[0m, in \u001b[0;36mlog_confusion_matrix\u001b[1;34m(epoch, logs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# disp = ConfusionMatrixDisplay(confusion_matrix=cm)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m figura \u001b[38;5;241m=\u001b[39m plot_confusion_matrix(cm, class_names\u001b[38;5;241m=\u001b[39mclass_names)\n\u001b[1;32m---> 20\u001b[0m cm_image \u001b[38;5;241m=\u001b[39m \u001b[43mplot_to_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigura\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Log the confusion matrix as an image summary.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_writer_cm\u001b[38;5;241m.\u001b[39mas_default():\n",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m, in \u001b[0;36mplot_to_image\u001b[1;34m(figure)\u001b[0m\n\u001b[0;32m      7\u001b[0m buf \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Use plt.savefig to save the plot to a PNG in memory.\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Closing the figure prevents it from being displayed directly inside\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# the notebook.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mclose(figure)\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\matplotlib\\pyplot.py:1134\u001b[0m, in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1131\u001b[0m fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;66;03m# savefig default implementation has no return, so mypy is unhappy\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;66;03m# presumably this is here because subclasses can return?\u001b[39;00m\n\u001b[1;32m-> 1134\u001b[0m res \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[func-returns-value]\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\matplotlib\\figure.py:3390\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[1;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[0;32m   3388\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[0;32m   3389\u001b[0m         _recursively_make_axes_transparent(stack, ax)\n\u001b[1;32m-> 3390\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mprint_figure(fname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\matplotlib\\backend_bases.py:2193\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2190\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[0;32m   2191\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[0;32m   2192\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[1;32m-> 2193\u001b[0m         result \u001b[38;5;241m=\u001b[39m print_method(\n\u001b[0;32m   2194\u001b[0m             filename,\n\u001b[0;32m   2195\u001b[0m             facecolor\u001b[38;5;241m=\u001b[39mfacecolor,\n\u001b[0;32m   2196\u001b[0m             edgecolor\u001b[38;5;241m=\u001b[39medgecolor,\n\u001b[0;32m   2197\u001b[0m             orientation\u001b[38;5;241m=\u001b[39morientation,\n\u001b[0;32m   2198\u001b[0m             bbox_inches_restore\u001b[38;5;241m=\u001b[39m_bbox_inches_restore,\n\u001b[0;32m   2199\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2200\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2201\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\matplotlib\\backend_bases.py:2043\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2039\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[0;32m   2040\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2041\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m   2042\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[1;32m-> 2043\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: meth(\n\u001b[0;32m   2044\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m skip}))\n\u001b[0;32m   2045\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[0;32m   2046\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:497\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    451\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:445\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[1;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_print_pil\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, fmt, pil_kwargs, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    441\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;124;03m    Draw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;124;03m    *pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 445\u001b[0m     \u001b[43mFigureCanvasAgg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    446\u001b[0m     mpl\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave(\n\u001b[0;32m    447\u001b[0m         filename_or_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_rgba(), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mfmt, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    448\u001b[0m         dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi, metadata\u001b[38;5;241m=\u001b[39mmetadata, pil_kwargs\u001b[38;5;241m=\u001b[39mpil_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:388\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\u001b[38;5;241m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\n\u001b[0;32m    387\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[1;32m--> 388\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdraw()\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\matplotlib\\artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m draw(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[0;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\matplotlib\\figure.py:3154\u001b[0m, in \u001b[0;36mFigure.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3151\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m   3153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m-> 3154\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sfig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubfigs:\n\u001b[0;32m   3158\u001b[0m     sfig\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\matplotlib\\axes\\_base.py:3070\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[0;32m   3068\u001b[0m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, artists_rasterized, renderer)\n\u001b[1;32m-> 3070\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3073\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\matplotlib\\image.py:649\u001b[0m, in \u001b[0;36m_ImageBase.draw\u001b[1;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    647\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mdraw_image(gc, l, b, im, trans)\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 649\u001b[0m     im, l, b, trans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image_magnification\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m im \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    652\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mdraw_image(gc, l, b, im)\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\matplotlib\\image.py:939\u001b[0m, in \u001b[0;36mAxesImage.make_image\u001b[1;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[0;32m    936\u001b[0m transformed_bbox \u001b[38;5;241m=\u001b[39m TransformedBbox(bbox, trans)\n\u001b[0;32m    937\u001b[0m clip \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_clip_box() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mbbox) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_clip_on()\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mbbox)\n\u001b[1;32m--> 939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed_bbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmagnification\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munsampled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munsampled\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\matplotlib\\image.py:504\u001b[0m, in \u001b[0;36m_ImageBase._make_image\u001b[1;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[0;32m    502\u001b[0m vrange \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m offset\n\u001b[0;32m    503\u001b[0m \u001b[38;5;66;03m# resample the input data to the correct resolution and shape\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m A_resampled \u001b[38;5;241m=\u001b[39m \u001b[43m_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m A_scaled  \u001b[38;5;66;03m# Make sure we don't use A_scaled anymore!\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Un-scale the resampled data to approximately the original\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# range. Things that interpolated to outside the original range\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# will still be outside, but possibly clipped in the case of\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;66;03m# higher order interpolation + drastically changing data.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\matplotlib\\image.py:205\u001b[0m, in \u001b[0;36m_resample\u001b[1;34m(image_obj, data, out_shape, transform, resample, alpha)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    204\u001b[0m         interpolation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhanning\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 205\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 2D->2D, 3D->3D.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     resample \u001b[38;5;241m=\u001b[39m image_obj\u001b[38;5;241m.\u001b[39mget_resample()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwAAAAMWCAYAAABGDuEIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABbi0lEQVR4nO3deZyN9fvH8fd9xiyWmbHOgrHvS/Y9IUvWXyKSNntl+0pJEqYFUSEppEJFtFhbRDK0DCGyJKksIya7McPMmJnz+2PM6ZxQZ5iZc8+5X8/zuB8P516vMx7GfZ3r+nxuw2632wUAAADAEmyeDgAAAABAziEBAAAAACyEBAAAAACwEBIAAAAAwEJIAAAAAAALIQEAAAAALIQEAAAAALAQEgAAAADAQkgAAAAAAAshAQAAAAAshAQAAAAAMIHJkyerQYMGCgwMVEhIiLp27ar9+/e77NOnTx8ZhuGyNG7cOFPXIQEAAAAATGDjxo0aMmSINm/erHXr1iklJUXt2rVTQkKCy37t27fX8ePHHcvnn3+eqevkycqgAQAAANyYNWvWuLyfP3++QkJCtH37dt12222O9f7+/goLC7vh61ABAAAAAEzo/PnzkqTChQu7rI+KilJISIgqVaqkgQMH6sSJE5k6r2G32+1ZFiUAAADgAYmJiUpOTvZ0GFex2+0yDMNlnb+/v/z9/f/zuDvvvFNnz57VN99841i/dOlSFShQQKVLl9bBgwc1btw4paSkaPv27f95zgwkAAAAAMjVEhMTlTewiJRy0dOhXKVAgQKKj493WTdhwgRFRkb+63FDhgzRZ599pm+//VYlS5a87n7Hjx9X6dKltWTJEnXr1s2tmBgDAAAAgFwtOTlZSrko/2oPST5+ng7nb6nJiv95oWJiYhQUFORY/V/f1A8bNkyrVq3Spk2b/vXmX5LCw8NVunRpHThwwO2wSAAAAADgHfIEyDBRAmA30ofbBgUFuSQA193fbtewYcO0fPlyRUVFqWzZsv95zOnTpxUTE6Pw8HC342IQMAAAAGACQ4YM0fvvv6/FixcrMDBQsbGxio2N1aVLlyRJ8fHxeuKJJxQdHa1Dhw4pKipKXbp0UdGiRXXXXXe5fR0qAAAAAIAJzJ49W5LUsmVLl/Xz589Xnz595OPjo927d+vdd9/VuXPnFB4erlatWmnp0qUKDAx0+zokAAAAAPAOhqR/zLjjUZkM5b/m5smbN6++/PLLmwgoHS1AAAAAgIWQAAAAAAAWQgsQAAAAvINhS1/MwkyxODFnVAAAAACyBQkAAAAAYCG0AAEAAMA7GIbJZgEyUSxOqAAAAAAAFkICAAAAAFgILUAAAADwDswC5BZzRgUAAAAgW5AAAAAAABZCCxAAAAC8A7MAuYUKAAAAAGAhJAAAAACAhdACBAAAAC9hslmATPpduzmjAgAAAJAtSAAAAAAAC6EFCAAAAN6BWYDcQgUAAAAAsBASAAAAAMBCaAECAACAdzBMNguQmWJxYs6oAAAAAGQLEgAAAADAQmgBAgAAgHdgFiC3UAEAAAAALIQEAAAAALAQWoAAAADgHZgFyC3mjAoAAABAtiABAAAAACyEFiAAAAB4B2YBcgsVAAAAAMBCSAAAAAAAC6EFCAAAAN6BWYDcYs6oAAAAAGQLEgAAAADAQmgBAgAAgHcwDHO13TALEAAAAABPIwEAAAAALIQWIAAAAHgHm5G+mIWZYnFCBQAAAACwEBIAAAAAwEJoAQIAAIB34EFgbjFnVAAAAACyBQkAAAAAYCG0AAEAAMA7GIa5Hr5lplicUAEAAAAALIQEAAAAALAQWoAAAADgHZgFyC3mjAoAAABAtiABAAAAACyEFiAAAAB4B2YBcgsVAAAAAMBCSAAAAAAAC6EFCAAAAN6BWYDcYs6oAAAAAGQLEgAAAADAQmgBAgAAgHdgFiC3UAEAAAAALIQEAAAAALAQWoAAAADgHZgFyC3mjAoAAABAtiABAAAAACyEFiAAAAB4B2YBcgsVAAAAAMBCSAAAAAAAC6EFCAAAAF7CZLMAmfS7dnNGBQAAACBbkAAAAAAAFkILEAAAALwDswC5hQoAAAAAYCEkAAAAAICF0AIEAAAA72AY5poFiBYgAMgeu3btUt++fVW2bFkFBASoQIECqlu3rqZOnaozZ85k67V37NihFi1aKDg4WIZhaMaMGVl+DcMwFBkZmeXnNZNJkyZpxYoVmTpmwYIFMgxDhw4dypaYAMBbUQEAkKvNmzdPgwcPVuXKlTVq1ChVq1ZNly9f1rZt2zRnzhxFR0dr+fLl2Xb9fv36KSEhQUuWLFGhQoVUpkyZLL9GdHS0SpYsmeXnNZNJkybp7rvvVteuXd0+plOnToqOjlZ4eHj2BQYAXogEAECuFR0drUcffVRt27bVihUr5O/v79jWtm1bPf7441qzZk22xrBnzx4NHDhQHTp0yLZrNG7cONvOnRtdunRJAQEBKlasmIoVK+bpcACYiWGyB4GZKRYn5owKANwwadIkGYahN9980+XmP4Ofn5/+7//+z/E+LS1NU6dOVZUqVeTv76+QkBA9+OCDOnr0qMtxLVu2VI0aNbR161Y1b95c+fLlU7ly5fTiiy8qLS1N0t/tJykpKZo9e7YMw5BxpdczMjLS8Wdn12pZ+frrr9WyZUsVKVJEefPmValSpdS9e3ddvHjRsc+1WoD27NmjO++8U4UKFVJAQIBq166thQsXuuwTFRUlwzD0wQcfaOzYsSpevLiCgoLUpk0b7d+//z9/vhmfY9euXerRo4eCg4NVuHBhjRw5UikpKdq/f7/at2+vwMBAlSlTRlOnTnU5PjExUY8//rhq167tOLZJkyZauXKly36GYSghIUELFy50/Bxbtmzp8jNbu3at+vXrp2LFiilfvnxKSkq66ud54MABBQUFqUePHi7n//rrr+Xj46Nx48b952cGACsgAQCQK6Wmpurrr79WvXr1FBER4dYxjz76qEaPHq22bdtq1apVev7557VmzRo1bdpUp06dctk3NjZW9913n+6//36tWrVKHTp00JgxY/T+++9L+rv9RJLuvvtuRUdHO96769ChQ+rUqZP8/Pz0zjvvaM2aNXrxxReVP39+JScnX/e4/fv3q2nTptq7d69mzpypZcuWqVq1aurTp89VN+GS9PTTT+vw4cN666239Oabb+rAgQPq0qWLUlNT3YqzZ8+eqlWrlj755BMNHDhQ06dP12OPPaauXbuqU6dOWr58uW6//XaNHj1ay5YtcxyXlJSkM2fO6IknntCKFSv0wQcf6NZbb1W3bt307rvvOvaLjo5W3rx51bFjR8fP8Y033nCJoV+/fvL19dV7772njz/+WL6+vlfFWbFiRc2bN08ff/yxZs6cKSn977F3795q3ry514+jAAB30QIEIFc6deqULl68qLJly7q1/y+//KI333xTgwcP1muvveZYX6dOHTVq1EjTp0/XxIkTHetPnz6tzz//XA0bNpQktWnTRlFRUVq8eLEefPBBl/aT0NDQG2rT2b59uxITE/XSSy+pVq1ajvW9e/f+1+MiIyOVnJysDRs2OJKfjh076ty5c3r22Wf18MMPKzg42LF/tWrVHImLJPn4+Khnz57aunWrW3EPGjRII0eOlJT+c1i7dq1mzZqlZcuW6a677pKUXjX59NNPtWjRInXr1k2SFBwcrPnz5zvOk5qaqtatW+vs2bOaMWOGHnzwQUnpLU42m03FihW7bjytW7fW3Llz/zPWe+65Rxs3btSoUaPUsGFDjR07Vna7XR988IF8fHz+83gAuRwPAnMLFQAAlrBhwwZJUp8+fVzWN2zYUFWrVtX69etd1oeFhTlu/jPccsstOnz4cJbFVLt2bfn5+WnQoEFauHCh/vjjD7eO+/rrr9W6deurKh99+vTRxYsXr6pEOLdBSemfQ5Lbn6Vz584u76tWrSrDMFzGPeTJk0cVKlS46pwfffSRmjVrpgIFCihPnjzy9fXV22+/rX379rl17Qzdu3d3e9/p06erevXqatWqlaKiovT+++8zUBgAnJAAAMiVihYtqnz58ungwYNu7X/69GlJuuaNYPHixR3bMxQpUuSq/fz9/XXp0qUbiPbaypcvr6+++kohISEaMmSIypcvr/Lly+vVV1/91+NOnz593c+Rsd3ZPz9LxngJdz9L4cKFXd77+fkpX758CggIuGp9YmKi4/2yZcvUs2dPlShRQu+//76io6O1detW9evXz2U/d2TmBt7f31+9e/dWYmKiateurbZt22bqWgDg7UgAAORKPj4+at26tbZv337VIN5rybgJPn78+FXbjh07pqJFi2ZZbBk3xklJSS7r/znOQJKaN2+u1atX6/z589q8ebOaNGmiESNGaMmSJdc9f5EiRa77OSRl6We5Ge+//77Kli2rpUuXqmvXrmrcuLHq169/1c/FHdcaVH09e/bs0fjx49WgQQP9+OOPmjZtWqavByCXypgFyEyLCZkzKgBww5gxY2S32zVw4MBrDpq9fPmyVq9eLUm6/fbbJcmlF16Stm7dqn379ql169ZZFlfGswB27drlsj4jlmvx8fFRo0aN9Prrr0uSfvzxx+vu27p1a3399deOG/4M7777rvLly2eaaUMNw5Cfn5/LzXtsbOxVswBJWVddSUhIUI8ePVSmTBlt2LBBQ4cO1VNPPaUtW7bc9LkBwFswCBhArtWkSRPNnj1bgwcPVr169fToo4+qevXqunz5snbs2KE333xTNWrUUJcuXVS5cmUNGjRIr732mmw2mzp06KBDhw5p3LhxioiI0GOPPZZlcXXs2FGFCxdW//799dxzzylPnjxasGCBYmJiXPabM2eOvv76a3Xq1EmlSpVSYmKi3nnnHUnpg22vZ8KECfr000/VqlUrjR8/XoULF9aiRYv02WefaerUqS4DgD2pc+fOWrZsmQYPHqy7775bMTExev755xUeHq4DBw647FuzZk1FRUVp9erVCg8PV2BgoCpXrpzpaz7yyCM6cuSIfvjhB+XPn1+vvPKKoqOj1atXL+3YsUMFCxbMok8HALkXCQCAXG3gwIFq2LChpk+frilTpig2Nla+vr6qVKmSevfuraFDhzr2nT17tsqXL6+3335br7/+uoKDg9W+fXtNnjz5mj3/NyooKEhr1qzRiBEjdP/996tgwYIaMGCAOnTooAEDBjj2q127ttauXasJEyYoNjZWBQoUUI0aNbRq1Sq1a9fuuuevXLmyvv/+ez399NMaMmSILl26pKpVq2r+/PlXDXL2pL59++rEiROaM2eO3nnnHZUrV05PPfWUjh49qmeffdZl31dffVVDhgxRr169dPHiRbVo0UJRUVGZut5bb72l999/X/Pnz1f16tUlpY9LWLp0qerWrau+fftm61OhAZgAswC5xbDb7XZPBwEAAADcqLi4OAUHB8u/4wwZvnk9HY6D/fIlJX0+QufPn1dQUJCnw3FgDAAAAABgIbQAAQAAwDuYbeYdM8XixJxRAQAAAMgWJAAAAACAhdACBAAAAO/ALEBuoQIAAAAAWAgVgBySlpamY8eOKTAwMFOPtAcAADAju92uCxcuqHjx4rLZ+E45NyEByCHHjh1TRESEp8MAAADIUjExMSpZsqSnw5AkGYZhri9azRSLExKAHBIYGChJ8qv2kAwfPw9HA8Db/fTpJE+HAMDLxV+4oPo1yjnucZB7kADkkIxs1PDxIwEAkO0CTfTESQDezVTfuMMtJAAAAADwCrQAuYcRGwAAAICFkAAAAAAAFkILEAAAALyDcWUxCzPF4oQKAAAAAGAhJAAAAACAhdACBAAAAK/ALEDuoQIAAAAAWAgJAAAAAGAhtAABAADAK9AC5B4qAAAAAICFkAAAAAAAFkILEAAAALwCLUDuoQIAAAAAWAgJAAAAAGAhtAABAADAK9AC5B4qAAAAAICFkAAAAAAAFkILEAAAALyDcWUxCzPF4oQKAAAAAGAhJAAAAACAhdACBAAAAK/ALEDuoQIAAAAAWAgJAAAAAGAhtAABAADAKxiGTNYC5OkAro0KAAAAAGAhJAAAAACAhdACBAAAAK9gyGSzAJm0B4gKAAAAAGAhJAAAAACAhdACBAAAAK/Ag8DcQwUAAAAAsBASAAAAAMBCaAECAACAdzBkrol3zBSLEyoAAAAAgIWQAAAAAAAWQgsQAAAAvIPJZgGymygWZ1QAAAAAAAshAQAAAAAshBYgAAAAeAWzPQjMTLE4owIAAAAAWAgJAAAAAGAhtAABAADAK9AC5B4qAAAAAICFkAAAAAAAFkILEAAAALyDcWUxCzPF4oQKAAAAAGAhJAAAAACAhdACBAAAAK/ALEDuoQIAAAAAWAgJAAAAAGAhtAABAADAK9AC5B4qAAAAAICFkAAAAAAAFkILEAAAALwCLUDuoQIAAAAAWAgJAAAAAGAhtAABAADAK9AC5B4qAAAAAICFkAAAAAAAFkICAAAAAO9gmHDJhMmTJ6tBgwYKDAxUSEiIunbtqv3797vsY7fbFRkZqeLFiytv3rxq2bKl9u7dm6nrkAAAAAAAJrBx40YNGTJEmzdv1rp165SSkqJ27dopISHBsc/UqVM1bdo0zZo1S1u3blVYWJjatm2rCxcuuH0dBgEDAAAAJrBmzRqX9/Pnz1dISIi2b9+u2267TXa7XTNmzNDYsWPVrVs3SdLChQsVGhqqxYsX6+GHH3brOlQAAAAA4BUyZgEy03Izzp8/L0kqXLiwJOngwYOKjY1Vu3btHPv4+/urRYsW+v77790+LxUAAAAAIBvFxcW5vPf395e/v/+/HmO32zVy5EjdeuutqlGjhiQpNjZWkhQaGuqyb2hoqA4fPux2PFQAAAAAgGwUERGh4OBgxzJ58uT/PGbo0KHatWuXPvjgg6u2/bOyYLfbM1VtoAIAAAAAr2DWB4HFxMQoKCjIsf6/vv0fNmyYVq1apU2bNqlkyZKO9WFhYZLSKwHh4eGO9SdOnLiqKvBvqAAAAAAA2SgoKMhluV4CYLfbNXToUC1btkxff/21ypYt67K9bNmyCgsL07p16xzrkpOTtXHjRjVt2tTteKgAAAAAACYwZMgQLV68WCtXrlRgYKCj5z84OFh58+aVYRgaMWKEJk2apIoVK6pixYqaNGmS8uXLp969e7t9HRIAAAAAeAWztgC5a/bs2ZKkli1buqyfP3+++vTpI0l68skndenSJQ0ePFhnz55Vo0aNtHbtWgUGBrp9HRIAAAAAwATsdvt/7mMYhiIjIxUZGXnD12EMAAAAAGAhVAAAAADgHYwri1mYKRYnVAAAAAAACyEBAAAAACyEFiAAAAB4hdw+C1BOoQIAAAAAWAgJAAAAAGAhtAABAADAK9AC5B4qAAAAAICFkAAAAAAAFkILEAAAALyCIZO1AJn0SWBUAAAAAAALIQEAAAAALIQWIAAAAHgFZgFyDxUAAAAAwEJIAAAAAAALoQUIAAAA3sG4spiFmWJxQgUAAAAAsBASAAAAAMBCaAECAACAV2AWIPdQAQAAAAAshAQAAAAAsBBagAAAAOAVaAFyDxUAAAAAwEJIAAAAAAALoQUIAAAAXsEw0hezMFMszqgAAAAAABZCAgAAAABYCC1AAAAA8ArpLUDm6bsxUSguqAAAAAAAFkICAAAAAFgILUAAAADwDiabBUhmisUJFQAAAADAQkgAAAAAAAuhBQgAAABewTAMk80CZJ5YnFEBAAAAACyEBAAAAACwEFqAAAAA4BUMk80CZKZYnFEBAAAAACyEBAAAAACwEFqAAAAA4BVsNkM2m3n6buwmisUZFQAAAADAQkgAAAAAAAuhBQgAAABegVmA3EMFAAAAALAQEgAAAADAQmgBAgAAgFcwDEOGifpuzBSLMyoAAAAAgIVQAQAAAIBXYBCwe6gAAAAAABZCAgAAAABYCC1AAAAA8AoMAnYPFQAAAADAQkgAAAAAAAuhBQgAAABegRYg91ABAAAAACyEBAAAAACwEFqAAAAA4BV4EJh7qAAAOWjQqd3a9/O7OvvTHH23/0M1iz/2r/v3OrNfW35ZotM/zdUfe+Zr7pH1KpyS6LJPcEqSph/dqD/2zNfZn+Zox77FuiPuUDZ+CgBmt+CtOWpcq5LKhQWpfcvG2vL9t9fd96/Y4xoy4EE1b1BDJQsHaPyYx//13Cs/+VAlCvmr3313Z3XYAHIICQCQQ+4+e0Av/fmtpoTWV+PKPfV9/nCt+GO1IpIvXHP/pvHH9NaR9VpYpKrqVrlX95e5Q/UuntDsmK8d+/impeqz31epdPIF3VemvWpV7a0hES11zLdATn0sACazctlHinz6CQ1//Cl9uXGLGjZppvt7/p/+jDlyzf2Tk5NUpGhRDX/8KVWrccu/nvvokcN6bvxTatTk1uwIHUAOIQEAcsjwkzu1oHBVLShSTfsDCmtUyeY66huogaf2XHP/hhf/0mG/QL1RrJYO+wfp+wLF9XaR6qp78aRjn4fO7FOh1ET1LNtB0QXCdcQvfb/deYvm1McCYDLz3nhVve7vo94P9lPFylX13ORXVLxESb37zpvX3D+iVBk99+I09eh1v4KCgq973tTUVA0d1EdPPDVOpcqUza7wgZtiyHDMBGSKRebsASIBAHKAb1qq6lw8qfWBpVzWrw+MUOOE2Gseszl/mEpcjk9v57HbFXL5ou4697u+CCrt2KfT+YPakj9MM45u0qE972jbLx9o1F/bZLOnZefHAWBSycnJ2rXzR7W4va3L+hat2mjbD5tv6tzTp05UkaJFde8DfW/qPAA8j0HAQA4ompqoPLLrhG9el/V/+eZV6IWL1zxmc/5w9S3dVu8dWquAtFT5Kk2rg8poZMnmjn3KJsepZfyfWlKoku4q11kVks5r+tGNymO3a3JYg2z9TADM58zpU0pNTVXRYiEu64sWC9WJE9f+ssEdWzd/rw/eX6B1m3642RABmIBHKwB9+vRxKZMUKVJE7du3165duzwZFpBt7P8oBRp2yX6dfaskntErR7/R5LD6alq5h7qU66IyyRf0WsxGxz422XUyT14NiWipHflC9FGhipoaWv+6bUUArOGfDx+y2+03/ECi+AsXNOzhPnppxhsqXIT2QphbxixAZlrMyOMVgPbt22v+/PmSpNjYWD3zzDPq3Lmzjhy59mAlIDc65ROgFBkKvez6bX9IyiWdyJPvmseM+mu7ovOHa3pIXUnSnrzSRVserf9tuZ4Nb6RY3/yKzZNflw2b0oy/c/lfAgopPOWifNNSddnmk30fCoDpFC5SVD4+Pjp54i+X9adPnVCxYqE3dM5Dh/5QzJHD6nNvN8e6tLT0NsNSRfNp09bdKlO2/I0HDSDHeXwMgL+/v8LCwhQWFqbatWtr9OjRiomJ0cmTJxUVFSXDMHTu3DnH/jt37pRhGDp06JBj3ffff6/bbrtNefPmVUREhIYPH66EhATH9jJlymjSpEnq16+fAgMDVapUKb35putgqN27d+v2229X3rx5VaRIEQ0aNEjx8fGO7VFRUWrYsKHy58+vggULqlmzZjp8+HC2/VzgXS7bfLQjXzHdfiHGZf3tF2K0OX/YNY/Jl5aitH98dZB65UY/Y210/jCVTzovw/53HaFi0jkdz5OPm3/Agvz8/HRL7bratOErl/WbotarfsPGN3TOChUra/13P2rtpq2OpV2HzmravIXWbtqq4iUisiJ0ADnI4wmAs/j4eC1atEgVKlRQkSJF3Dpm9+7duuOOO9StWzft2rVLS5cu1bfffquhQ4e67PfKK6+ofv362rFjhwYPHqxHH31Uv/zyiyTp4sWLat++vQoVKqStW7fqo48+0ldffeU4R0pKirp27aoWLVpo165dio6O1qBBg264nAprmlmstvqe+VkPnv5ZlRPPaOqf3yri8gW9VbS6JOm5Y9F66/Df/2l/FlRGd577QwNP7VGZpPNqEn9crxz9Rlvzhei4b35J0ryiNVQ4NVGv/PmNKiSeU/vzhzTqr+2aU7SmRz4jAM8bOPh/+uC9+Vry/gId2L9PE55+Qn8ejdEDfQdKkiY/+4yGP9LP5Zg9u3/Snt0/KSEhXmdOndKe3T/p11/2SZICAgJUpVp1lyUouKAKFAhUlWrV5efnl+OfEbgej8/6c43FjDzeAvTpp5+qQIH0OcsTEhIUHh6uTz/9VDabe7nJSy+9pN69e2vEiBGSpIoVK2rmzJlq0aKFZs+erYCAAElSx44dNXjwYEnS6NGjNX36dEVFRalKlSpatGiRLl26pHfffVf586ffWM2aNUtdunTRlClT5Ovrq/Pnz6tz584qXz69zFm1atV/jSspKUlJSUmO93Fxce7/UOCVPi5UUYVTE/V07DaFpSRob0ARdS3XRUf8giRJYZcvujwT4P0iVRWYdlmPnNqlF//8Tud9/BQVWFLPhDdx7HPUL1Bdyv+fpv75rbbuX6Jjvvn1erFb9MqVtiEA1nNntx46e+a0pk+dpBN/HVflqtX13tKVKlkqfQaxv/6K1bGjrtXIO25r6Pjzrp0/avnHS1QyorS27Po1R2MHkDM8ngC0atVKs2fPliSdOXNGb7zxhjp06KAffnBvpoHt27frt99+06JFixzr7Ha70tLSdPDgQceN+i23/P1wE8MwFBYWphMnTkiS9u3bp1q1ajlu/iWpWbNmSktL0/79+3XbbbepT58+uuOOO9S2bVu1adNGPXv2VHh4+HXjmjx5sp599ln3fxCwhDeL1tSb1/l2flDp1letm13sFs0u9u8P5tmSP0wtKvFETgB/6zPgEfUZ8Mg1t814462r1v15Nukae17ftc4BIPfweAtQ/vz5VaFCBVWoUEENGzbU22+/rYSEBM2bN89RBbA79TdfvnzZ5fi0tDQ9/PDD2rlzp2P56aefdODAAce39ZLk6+vrcpxhGI5BTP82O0LG+vnz5ys6OlpNmzbV0qVLValSJW3efP05lceMGaPz5887lpiYmOvuCwAAgJvn6Rl/mAXoBhmGIZvNpkuXLqlYsWKSpOPHj6tQoUKS0gcBO6tbt6727t2rChUq3PA1q1WrpoULFyohIcFRBfjuu+9ks9lUqVIlx3516tRRnTp1NGbMGDVp0kSLFy9W48bXHlTl7+8vf3//G44JAAAAyA4erwAkJSUpNjZWsbGx2rdvn4YNG6b4+Hh16dJFFSpUUEREhCIjI/Xrr7/qs88+0yuvvOJy/OjRoxUdHa0hQ4Zo586dOnDggFatWqVhw4a5HcN9992ngIAAPfTQQ9qzZ482bNigYcOG6YEHHlBoaKgOHjyoMWPGKDo6WocPH9batWv166+//uc4AAAAAMBsPF4BWLNmjaOXPjAwUFWqVNFHH32kli1bSpI++OADPfroo6pVq5YaNGigF154QT169HAcf8stt2jjxo0aO3asmjdvLrvdrvLly+uee+5xO4Z8+fLpyy+/1P/+9z81aNBA+fLlU/fu3TVt2jTH9l9++UULFy7U6dOnFR4erqFDh+rhhx/Ouh8EAAAAborZZt4xUyzODLtzgz2yTVxcnIKDg+Vfc6AMH6ZMA5C9ft8wzdMhAPByF+LiVKV0MZ0/f15BQUEejSXjPqvOM5/KJyD/fx+QQ1ITE7Tjhc6m+Bk583gLEAAAAICc4/EWIAAAACArmG3mHTPF4owKAAAAAGAhJAAAAACAhdACBAAAAK/ALEDuoQIAAAAAWAgJAAAAAGAhtAABAADAO5hsFiCZKRYnVAAAAAAACyEBAAAAACyEFiAAAAB4BWYBcg8VAAAAAMBCSAAAAAAAC6EFCAAAAF7BMNksQGaKxRkVAAAAAMBCSAAAAAAAC6EFCAAAAF6BWYDcQwUAAAAAsBASAAAAAMBCaAECAACAV2AWIPdQAQAAAAAshAQAAAAAsBBagAAAAOAVmAXIPVQAAAAAAAshAQAAAAAshBYgAAAAeAVagNxDBQAAAACwEBIAAAAAwEJoAQIAAIBX4EFg7qECAAAAAFgICQAAAABgIbQAAQAAwCswC5B7qAAAAAAAFkICAAAAAFgILUAAAADwCswC5B4qAAAAAICFkAAAAAAAFkILEAAAALwCswC5hwoAAAAAYCEkAAAAAICF0AIEAAAAr2DIXDPvmCgUF1QAAAAAAAshAQAAAAAshBYgAAAAeAWbYchmoh4gM8XijAoAAAAAYCEkAAAAAICF0AIEAAAAr2AYJpsFyESxOKMCAAAAAFgICQAAAABgIbQAAQAAwCsYhiHDRH03ZorFGRUAAAAAwEJIAAAAAAALoQUIAAAAXsFmpC9mYaZYnFEBAAAAACyEBAAAAACwEFqAAAAA4B0Mk828Y6JQnFEBAAAAACyEBAAAAACwEFqAAAAA4BUMI30xCzPF4owKAAAAAGAhJAAAAACAhdACBAAAAK9gXHmZhZlicUYFAAAAALAQEgAAAADAQmgBAgAAgFewGemLWZgpFmdUAAAAAAALIQEAAAAALIQWIAAAAHgFwzBkmOjpW2aKxRkVAAAAAMBCSAAAAAAAC6EFCAAAAF7BMNIXszBTLM6oAAAAAAAWQgIAAAAAWAgtQAAAAPAKNsOQzUR9N2aKxRkVAAAAAMBCSAAAAAAAC6EFCAAAAF6BWYDcQwUAAAAAsBASAAAAAMBCaAECAACAVzAMQ4aJ+m7MFIszKgAAAACAhZAAAAAAACaxadMmdenSRcWLF5dhGFqxYoXL9j59+jgqHRlL48aNM3UNEgAAAAB4hYxZgMy0ZFZCQoJq1aqlWbNmXXef9u3b6/jx447l888/z9Q1GAMAAAAAmESHDh3UoUOHf93H399fYWFhN3wNKgAAAABALhIVFaWQkBBVqlRJAwcO1IkTJzJ1PBUAAAAAeAWbYchmopl3MmKJi4tzWe/v7y9/f/8bOmeHDh3Uo0cPlS5dWgcPHtS4ceN0++23a/v27W6fkwQAAAAAyEYREREu7ydMmKDIyMgbOtc999zj+HONGjVUv359lS5dWp999pm6devm1jlIAAAAAIBsFBMTo6CgIMf7G/32/1rCw8NVunRpHThwwO1jSAAAAADgFYwri1lkxBIUFOSSAGSl06dPKyYmRuHh4W4fQwIAAAAAmER8fLx+++03x/uDBw9q586dKly4sAoXLqzIyEh1795d4eHhOnTokJ5++mkVLVpUd911l9vXIAEAAAAATGLbtm1q1aqV4/3IkSMlSQ899JBmz56t3bt3691339W5c+cUHh6uVq1aaenSpQoMDHT7GiQAAAAA8AoZT8Y1ixuJpWXLlrLb7dfd/uWXX95MSJJ4DgAAAABgKSQAAAAAgIXQAgQAAACvYDPSF7MwUyzOqAAAAAAAFkICAAAAAFgILUAAAADwCt4wC1BOoAIAAAAAWAgJAAAAAGAhtAABAADAa5i068ZUqAAAAAAAFkICAAAAAFgILUAAAADwCswC5B63EoCZM2e6fcLhw4ffcDAAAAAAspdbCcD06dPdOplhGCQAAAAAgIm5lQAcPHgwu+MAAAAAborNSF/MwkyxOLvhQcDJycnav3+/UlJSsjIeAAAAANko0wnAxYsX1b9/f+XLl0/Vq1fXkSNHJKX3/r/44otZHiAAAACArJPpBGDMmDH66aefFBUVpYCAAMf6Nm3aaOnSpVkaHAAAAOCujFmAzLSYUaanAV2xYoWWLl2qxo0bu3yoatWq6ffff8/S4AAAAABkrUxXAE6ePKmQkJCr1ickJJg2ywEAAACQLtMJQIMGDfTZZ5853mfc9M+bN09NmjTJusgAAACATDBMuJhRpluAJk+erPbt2+vnn39WSkqKXn31Ve3du1fR0dHauHFjdsQIAAAAIItkugLQtGlTfffdd7p48aLKly+vtWvXKjQ0VNHR0apXr152xAgAAAAgi2S6AiBJNWvW1MKFC7M6FgAAAOCG2QxDNhONSTVTLM5uKAFITU3V8uXLtW/fPhmGoapVq+rOO+9Unjw3dDoAAAAAOSTTd+x79uzRnXfeqdjYWFWuXFmS9Ouvv6pYsWJatWqVatasmeVBAgAAAMgamR4DMGDAAFWvXl1Hjx7Vjz/+qB9//FExMTG65ZZbNGjQoOyIEQAAAPhPhmG+xYwyXQH46aeftG3bNhUqVMixrlChQpo4caIaNGiQpcEBAAAAyFqZrgBUrlxZf/3111XrT5w4oQoVKmRJUAAAAACyh1sVgLi4OMefJ02apOHDhysyMlKNGzeWJG3evFnPPfecpkyZkj1RAgAAAP/BMAzHQ2rNwEyxOHMrAShYsKDLB7Db7erZs6djnd1ulyR16dJFqamp2RAmAAAAgKzgVgKwYcOG7I4DAAAAQA5wKwFo0aJFdscBAAAA3BSzzbxjplic3fCTuy5evKgjR44oOTnZZf0tt9xy00EBAAAAyB6ZTgBOnjypvn376osvvrjmdsYAAAAAAOaV6WlAR4wYobNnz2rz5s3Kmzev1qxZo4ULF6pixYpatWpVdsQIAAAA/CebYZhuMaNMVwC+/vprrVy5Ug0aNJDNZlPp0qXVtm1bBQUFafLkyerUqVN2xAkAAAAgC2S6ApCQkKCQkBBJUuHChXXy5ElJUs2aNfXjjz9mbXQAAAAAstQNPQl4//79kqTatWtr7ty5+vPPPzVnzhyFh4dneYAAAACAOzJmATLTYkaZbgEaMWKEjh8/LkmaMGGC7rjjDi1atEh+fn5asGBBVscHAAAAIAtlOgG47777HH+uU6eODh06pF9++UWlSpVS0aJFszQ4AAAAAFnrhp8DkCFfvnyqW7duVsQCAAAA3DDDMGSYqO/GTLE4cysBGDlypNsnnDZt2g0HYwUrF4xV/gJBng4DgJcrXMDP0yEA8HJ50vg9k1u5lQDs2LHDrZOZNcsBAAAAkM6tBGDDhg3ZHQcAAABwU2y6gSkus5GZYnFm1rgAAAAAZAMSAAAAAMBCbnoWIAAAAMAMmAXIPVQAAAAAAAshAQAAAAAs5IYSgPfee0/NmjVT8eLFdfjwYUnSjBkztHLlyiwNDgAAAHCXYUg2Ey0m7QDKfAIwe/ZsjRw5Uh07dtS5c+eUmpoqSSpYsKBmzJiR1fEBAAAAyEKZTgBee+01zZs3T2PHjpWPj49jff369bV79+4sDQ4AAABA1sr0LEAHDx5UnTp1rlrv7++vhISELAkKAAAAyKyM1huzMFMszjJdAShbtqx27tx51fovvvhC1apVy4qYAAAAAGSTTFcARo0apSFDhigxMVF2u10//PCDPvjgA02ePFlvvfVWdsQIAAAAIItkOgHo27evUlJS9OSTT+rixYvq3bu3SpQooVdffVW9evXKjhgBAACA/8SDwNxzQ08CHjhwoAYOHKhTp04pLS1NISEhWR0XAAAAgGxwQwlAhqJFi2ZVHAAAAAByQKYTgLJly/5rOeOPP/64qYAAAACAG8EsQO7JdAIwYsQIl/eXL1/Wjh07tGbNGo0aNSqr4gIAAACQDTKdAPzvf/+75vrXX39d27Ztu+mAAAAAAGSfTD8H4Ho6dOigTz75JKtOBwAAAGSKYZhvMaMsSwA+/vhjFS5cOKtOBwAAACAbZLoFqE6dOi6DgO12u2JjY3Xy5Em98cYbWRocAAAAgKyV6QSga9euLu9tNpuKFSumli1bqkqVKlkVFwAAAJApNsOQzUR9N2aKxVmmEoCUlBSVKVNGd9xxh8LCwrIrJgAAAADZJFNjAPLkyaNHH31USUlJ2RUPAAAAgGyU6UHAjRo10o4dO7IjFgAAAOCG2Uy4mFGmxwAMHjxYjz/+uI4ePap69eopf/78LttvueWWLAsOAAAAQNZyOwHo16+fZsyYoXvuuUeSNHz4cMc2wzBkt9tlGIZSU1OzPkoAAAAAWcLtBGDhwoV68cUXdfDgweyMBwAAALghZnv4lpliceZ2AmC32yVJpUuXzrZgAAAAAGSvTI1NMMyaxgAAAABwS6YGAVeqVOk/k4AzZ87cVEAAAADAjbDJZA8Ck3licZapBODZZ59VcHBwdsUCAAAAIJtlKgHo1auXQkJCsisWAAAAANnM7QSA/n8AAACYGbMAucftQcAZswABAAAAyL3crgCkpaVlZxwAAAAAckCmxgAAAAAAZmUz0hezMFMszjL1HAAAAAAAuRsJAAAAAGAhtAABAADAKxiGTPUgMBOF4oIKAAAAAGAhJAAAAACAhdACBAAAAK/Ag8DcQwUAAAAAsBASAAAAAMBCaAECAACAV+BBYO6hAgAAAABYCAkAAAAAYCG0AAEAAMArGFdeZmGmWJxRAQAAAAAshAQAAAAAsBBagAAAAOAVmAXIPVQAAAAAAAshAQAAAAAshBYgAAAAeAVagNxDBQAAAACwECoAAAAA8AqGYcgwzPO1u5licUYFAAAAALAQEgAAAADAQmgBAgAAgFdgELB7qAAAAAAAFkICAAAAAFgILUAAAADwCoaRvpiFmWJxRgUAAAAAsBASAAAAAMBCaAECAACAV7AZhmwm6rsxUyzOqAAAAAAAFkICAAAAAFgILUAAAADwCjwIzD1UAAAAAAALIQEAAAAALIQWIAAAAHgHkz0ITGaKxQkVAAAAAMBCSAAAAAAAC6EFCAAAAF7BJkM2E/XdmCkWZ1QAAAAAAAshAQAAAAAshBYgAAAAeAXDZLMAmSkWZ1QAAAAAAAshAQAAAAAshBYgAAAAeAWbkb6YhZlicUYFAAAAALAQEgAAAADAQmgBAgAAgFewGYZsJpp6x0yxOKMCAAAAAFgICQAAAABgIbQAAQAAwCvwIDD3UAEAAAAALIQEAAAAALAQWoAAAADgFWwy2SxAMk8szqgAAAAAABZCAgAAAABYCC1AAAAA8ArMAuQeKgAAAACAhZAAAAAAABZCCxAAAAC8gk3m+nbbTLE4M2tcAAAAALIBCQAAAABgIbQAAQAAwCsYhiHDRFPvmCkWZ1QAAAAAAAshAQAAAAAshBYgAAAAeAXjymIWZorFGRUAAAAAwEJIAAAAAAALoQUIAAAAXsFmGLKZaOYdM8XijAoAAAAAYCEkAAAAAICF0AIEAAAAr2HOphtzoQIAAAAAWAgJAAAAAGAhtAABAADAKxhG+mIWZorFGRUAAAAAwEJIAAAAAACT2LRpk7p06aLixYvLMAytWLHCZbvdbldkZKSKFy+uvHnzqmXLltq7d2+mrkECAAAAAK9gGIbplsxKSEhQrVq1NGvWrGtunzp1qqZNm6ZZs2Zp69atCgsLU9u2bXXhwgW3r8EYAAAAAMAkOnTooA4dOlxzm91u14wZMzR27Fh169ZNkrRw4UKFhoZq8eLFevjhh926BhUAAAAAIBvFxcW5LElJSTd0noMHDyo2Nlbt2rVzrPP391eLFi30/fffu30eEgAAAAB4BZsJF0mKiIhQcHCwY5k8efINfb7Y2FhJUmhoqMv60NBQxzZ30AIEAAAAZKOYmBgFBQU53vv7+9/U+f45tsBut2dqvAEJAAAAAJCNgoKCXBKAGxUWFiYpvRIQHh7uWH/ixImrqgL/hhYgAAAAeAVPz/iTFbMA/ZuyZcsqLCxM69atc6xLTk7Wxo0b1bRpU7fPQwUAAAAAMIn4+Hj99ttvjvcHDx7Uzp07VbhwYZUqVUojRozQpEmTVLFiRVWsWFGTJk1Svnz51Lt3b7evQQIAAAAAmMS2bdvUqlUrx/uRI0dKkh566CEtWLBATz75pC5duqTBgwfr7NmzatSokdauXavAwEC3r0ECAAAAAK9gXFnM4kZiadmypex2+/XPaRiKjIxUZGTkDcfFGAAAAADAQkgAAAAAAAuhBQgAAABeITtm3rkZZorFGRUAAAAAwEJIAAAAAAALoQUIAAAAXsEmc327baZYnJk1LgAAAADZgAQAAAAAsBBagAAAAOAVmAXIPVQAAA8KW/S26t9eW01rhqt2t1YK2hb9r/sXW/WR6vxfczWpVUINb62qimOGKM/ZMzkULYDcbO7sN1SlYlkVLBCgpg3r6dtvv7nuviuWL1On9m0VEV5MIYWD1OLWJlq39sscjBZAdiIBADyk6OfLVG7y04p5dKR2rIjS+XqNVX1gT/kfO3rN/YO2bVal0Y8q9u779eOn3+uXGfNVYPcOVXzmfzkcOYDc5qMPl2rU4yM0+qmx2rx1h5re2lxdO3fQkSNHrrn/t99s0u1t2mr5qs/1/ZbtatGylbp37aKdO3bkcOQAsgMJAOAhJea/ob+636+/ejyoS+Ur6+DYyUoKK66wD9655v6BP21VYolSOv7gw0qKKK24+o0Ve08fFdjDf8gA/t3MGdPUp29/9e0/QFWqVtXL02aoZESE5s2dfc39X542Q48/8aTqN2igChUr6rkXJqlCxYr6/LPVORw5kDmGCRczIgEAPMBITlaBvT/p3K2tXNafa9ZKQTt+uOYxcXUayj/2mAptXCfZ7fI9dUJFv1ylMy3a5UTIAHKp5ORk7fhxu1q3df1d0bpNO22O/t6tc6SlpenChQsqVKhwdoQIIIdZMgE4dOiQDMPQzp07PR0KLMr37GkZqalKLlLMZX1y0RD5njxxzWMu1G2k/S/PVeUR/dW0RqgaNauilMBg/TFuSk6EDCCXOnXqlFJTUxUSEuqyPjQ0VH/9FevWOWZMf0UXExLUvUfP7AgRQA7LNQlAnz59ZBiGHnnkkau2DR48WIZhqE+fPjkfGHAz/jk7gN1+9bor8v72i8q9MEYxQ57Qzk82aM9bHyng6GGVnzAyBwIFkNv9czYSu93u1gwlS5d8oInPReq9xUsVEhKSTdEBWcMwzLeYUa5JACQpIiJCS5Ys0aVLlxzrEhMT9cEHH6hUqVIejAzInMuFisju4yO/U67f9vudPqnLRYtd85iIuTN0oW5D/TlguC5Wqa5zzVvr9wkvK+yTRfI94d63eACsp2jRovLx8bnq2/4TJ05cVRX4p48+XKpHB/XX+x98qNtbt8nOMAHkoFyVANStW1elSpXSsmXLHOuWLVumiIgI1alTx7FuzZo1uvXWW1WwYEEVKVJEnTt31u+///6v5964caMaNmwof39/hYeH66mnnlJKSopj+8cff6yaNWsqb968KlKkiNq0aaOEhISs/5CwBLufn+Kr11LB76Jc1hf8PkpxdRpe8xhb4kXZba7/ZO0+6e8Nuz1b4gSQ+/n5+alO3Xr6+qt1Luu/Xr9OjZs0ve5xS5d8oEH9+2jBe4vVoWOn7A4TQA7KVQmAJPXt21fz5893vH/nnXfUr18/l30SEhI0cuRIbd26VevXr5fNZtNdd92ltLS0a57zzz//VMeOHdWgQQP99NNPmj17tt5++2298MILkqTjx4/r3nvvVb9+/bRv3z5FRUWpW7dusnPThZvwZ9/BCv34PYV+/L7y/r5fZSc9Lf/jfyq2V19JUulXnlOlJx917H+mVXsVWfepwha/I/+YQwrcvlnlXhijC7fUVXJouKc+BoBcYPiIkZr/zltaOP8d/bJvn0Y9/phijhzRgEHpbbXjxo5R/z4POvZfuuQDDej7oF6c+ooaNmqs2NhYxcbG6vz58576CIBbbDJMt5hRrnsS8AMPPKAxY8Y4BvJ+9913WrJkiaKiohz7dO/e3eWYt99+WyEhIfr5559Vo0aNq875xhtvKCIiQrNmzZJhGKpSpYqOHTum0aNHa/z48Tp+/LhSUlLUrVs3lS5dWpJUs2bNf40zKSlJSUlJjvdxcXE38anhjU517KY8Z88q4o2X5HfiL12sVFV731yqpBIRkiS/k3/J//jfzwQ40a23fBLiFb5onspOGaeUwGCdb9xch0ZN8NRHAJBL9Oh5j86cPq1JE59T7PHjql69hlas/tzxf1rs8eOKifn7mQBvz5urlJQUjRg+RCOGD3Gsv/+BhzTvnQU5HT6ALJbrEoCiRYuqU6dOWrhwoex2uzp16qSiRYu67PP7779r3Lhx2rx5s06dOuX45v/IkSPXTAD27dunJk2auAyGatasmeLj43X06FHVqlVLrVu3Vs2aNXXHHXeoXbt2uvvuu1WoUKHrxjl58mQ9++yzWfSp4a1i7+uv2Pv6X3PbgRdfv2rd8QcG6fgDg7I7LABe6OFHB+vhRwdfc9s/b+rXro/K/oAAeEyuawGSpH79+mnBggVauHDhVe0/ktSlSxedPn1a8+bN05YtW7RlyxZJ6XMhX8u1ZkLIaO8xDEM+Pj5at26dvvjiC1WrVk2vvfaaKleurIMHD143xjFjxuj8+fOOJSYm5kY/LgAAANzg6Rl/mAUoG7Vv317JyclKTk7WHXfc4bLt9OnT2rdvn5555hm1bt1aVatW1dmzZ//1fNWqVdP333/v0tP//fffKzAwUCVKlJCUngg0a9ZMzz77rHbs2CE/Pz8tX778uuf09/dXUFCQywIAAAB4Wq5rAZIkHx8f7du3z/FnZ4UKFVKRIkX05ptvKjw8XEeOHNFTTz31r+cbPHiwZsyYoWHDhmno0KHav3+/JkyYoJEjR8pms2nLli1av3692rVrp5CQEG3ZskUnT55U1apVs+0zAgAAANkhVyYAkq77jbrNZtOSJUs0fPhw1ahRQ5UrV9bMmTPVsmXL656rRIkS+vzzzzVq1CjVqlVLhQsXVv/+/fXMM884rrVp0ybNmDFDcXFxKl26tF555RV16NAhOz4aAAAAboBx5WUWZorFmWFnLsscERcXp+DgYK3Zfkj5C9AOBCB71S93/UkKACArxMXFKbRIsM6fP+/xVueM+6wPo39TvgKBHo3F2cX4C+rZpIIpfkbOcuUYAAAAAAA3Jte2AAEAAADOzDbzjplicUYFAAAAALAQEgAAAADAQmgBAgAAgFcwZMhmopl3zDoLEBUAAAAAwEJIAAAAAAALoQUIAAAAXoFZgNxDBQAAAACwEBIAAAAAwEJoAQIAAIBXoAXIPVQAAAAAAAshAQAAAAAshBYgAAAAeAXjyssszBSLMyoAAAAAgIWQAAAAAAAWQgsQAAAAvILNSF/MwkyxOKMCAAAAAFgICQAAAABgIbQAAQAAwCswC5B7qAAAAAAAFkICAAAAAFgILUAAAADwCoaRvpiFmWJxRgUAAAAAsBASAAAAAMBCaAECAACAVzBkrpl3zBOJKyoAAAAAgIWQAAAAAAAWQgsQAAAAvILNSF/MwkyxOKMCAAAAAFgICQAAAABgIbQAAQAAwCsYV15mYaZYnFEBAAAAACyEBAAAAACwEFqAAAAA4BUMI30xCzPF4owKAAAAAGAhJAAAAACAhdACBAAAAK9gXFnMwkyxOKMCAAAAAFgICQAAAABgIbQAAQAAwCvYZMhmoql3bCZtAqICAAAAAFgICQAAAABgIbQAAQAAwCswC5B7qAAAAAAAFkICAAAAAFgILUAAAADwDvQAuYUKAAAAAGAhJAAAAACAhdACBAAAAK9gXHmZhZlicUYFAAAAALAQEgAAAADAQmgBAgAAgHcwJMNMXTdmisUJFQAAAADAQkgAAAAAAAuhBQgAAABegeeAuYcKAAAAAGAhJAAAAACAhdACBAAAAO9AD5BbqAAAAAAAFkICAAAAAFgILUAAAADwCsaVl1mYKRZnVAAAAAAACyEBAAAAACyEFiAAAAB4BcNIX8zCTLE4owIAAAAAWAgJAAAAAGAhtAABAADAK/AcMPdQAQAAAAAshAQAAAAAsBBagAAAAOAd6AFyCxUAAAAAwEJIAAAAAAALoQUIAAAAXsG48jILM8XijAoAAAAAYCEkAAAAAICF0AIEAAAAr2AY6YtZmCkWZ1QAAAAAAAshAQAAAAAshBYgAAAAeAWeA+YeKgAAAACAhZAAAAAAABZCCxAAAAC8Az1AbqECAAAAAFgICQAAAABgIbQAAQAAwCsYV15mYaZYnFEBAAAAACyEBAAAAACwEFqAAAAA4BUMI30xCzPF4owKAAAAAGAhJAAAAACAhdACBAAAAK/Ac8DcQwUAAAAAsBASAAAAAMBCaAECAACAd6AHyC1UAAAAAAALIQEAAAAALIQWIAAAAHgF48rLLMwUizMqAAAAAICFkAAAAAAAFkILEAAAALyCYaQvZmGmWJxRAQAAAAAshAQAAAAAsBBagAAAAOAVeA6Ye6gAAAAAABZCAgAAAABYCC1AAAAA8A70ALmFCgAAAABgISQAAAAAgIXQAgQAAACvYFx5mYWZYnFGBQAAAACwEBIAAAAAwEJoAQIAAIBXMIz0xSzMFIszKgAAAACAhZAAAAAAABZCCxAAAAC8As8Bcw8VAAAAAMBCSAAAAAAAC6EFCAAAAN6BHiC3UAEAAAAALIQEAAAAALAQWoAAAADgFYwrL7MwUyzOqAAAAAAAFkICAAAAAFgILUAAAADwDoZkmKnrxkyxOKECAAAAAFgIFQAAAAB4BR4D4B4qAAAAAICFkAAAAAAAFkILEAAAALwDPUBuoQIAAAAAmEBkZKQMw3BZwsLCsvw6VAAAAAAAk6hevbq++uorx3sfH58svwYJAAAAALyCceVlFjcSS548ebLlW39ntAABAAAA2SguLs5lSUpKuu6+Bw4cUPHixVW2bFn16tVLf/zxR5bHQwUgh9jtdklSQvwFD0cCwAri4rK+ZAwAzi7ExUn6+x4H1xcREeHyfsKECYqMjLxqv0aNGundd99VpUqV9Ndff+mFF15Q06ZNtXfvXhUpUiTL4jHs/K3liKNHj171lw8AAJDbxcTEqGTJkh6NIS4uTsHBwfrpj78UGBjk0VicXbgQp1rlQhUTE6OgoL/j8vf3l7+//38en5CQoPLly+vJJ5/UyJEjsywuKgA5pHjx4oqJiVFgYKAMwzy9aTCvuLg4RUREXPVLAwCyGr9vcCPsdrsuXLig4sWLezoU0wsKCrqhf1v58+dXzZo1deDAgSyNhwQgh9hsNo9nx8idbvSXBgBkFr9vkFnBwcGeDsGrJSUlad++fWrevHmWnpdBwAAAAPAKhgmXzHjiiSe0ceNGHTx4UFu2bNHdd9+tuLg4PfTQQ5n+WfwbKgAAAACACRw9elT33nuvTp06pWLFiqlx48bavHmzSpcunaXXIQEATMrf318TJkxwa5AQANwMft8A5rBkyZIcuQ6zAAEAACBXy5gFaNdB880CdEvZUJ0/f95U42sYAwAAAABYCAkAAAAAYCGMAQAAAIBXMK68zMJMsTijAgAAAABYCAkAAAAAYCG0AAEAAMArGJIME3XdmCgUF1QAAABApjCDOJC7kQAAXiLjP+Q///xTycnJHo4GgDfJ+P2yb98+xcfHyzDTV6wAMo0EAPACdrtdhmFo1apV6tChgz799FMlJiZ6OiwAXiDj98vKlSvVvn17vfHGG0pKSvJ0WMA1GSZczIgEAPACGf859+7dWw888IBq1KihgIAAl30o2QO4EYZhaPXq1br33ns1ZswY9ejRQ/7+/p4OC8BNMOzcFQC53smTJ9WuXTv17t1bo0aNUkpKii5fvqyoqCiVKVNGVatW9XSIAHKp+Ph43X333WrWrJnGjRunxMREnTt3TsuXL1etWrVUqVIlFS1a1NNhwuLi4uIUHBysvQdPKDAoyNPhOFyIi1P1siE6f/68gkwUFxUAwAskJibq0qVLatCggf766y9NnjxZHTp00P/93/9pwIAB+uSTTzwdIoBcKiUlRYcPH1ZQUJDi4uI0fvx49ezZU08//bR69uypFStWSKLKCHMwDPMtZkQCAHiBiIgIBQUFqW/fvqpZs6Z27Nihu+66S7///rvOnz+vHTt2eDpEALlUwYIF1b17dz355JMqU6aMDhw4oAceeEBnz55Vw4YN9cUXX0gSA4OBXITnAAC5TMaAvCNHjig1NVUJCQmqUaOGNm/erFmzZilfvnzq0aOH8ufPrzx58qh69ery8fFxORYAriXjd8T+/fsVGxsrX19f1alTRy+88IJatmypCxcuqHPnzrLZ0r8/LFasmHx9fZWSkqI8ebilAHIL/rUCuUjGf87Lli3T2LFjlZCQoNTUVLVp00avvvqqhg8f7tg3Pj5ekydP1ldffaXnn39eEt/QAbi+jN8vn3zyiR577DFJ6b8zfH19tWzZMrVp08ax75EjRzRv3jwtXbpU3333HTf/MBGzzb1jplj+xr9YIBcxDENRUVG6//77NWPGDJUrV04XL17UgAEDdOzYMS1ZskRFihTR6tWrNWfOHP3888/66quvVKlSJU+HDsDkDMPQli1b1KdPH02fPl0tW7bU2bNn9fzzz6t169b65ptvVKVKFX3zzTd69dVXtWvXLkVFRal69eqeDh1AJjELEJDLREZGavv27Vq9erVj3ZEjR1S3bl3dfffdmjNnjo4fP66PPvpIHTt2VIUKFTwYLQCz2rJlixo1auSy7u2339aiRYu0du1ax7f6CQkJ6tmzpw4fPqwff/xRcXFx2rx5s2rUqKEyZcp4IHLgahmzAP186KTpZgGqVqYYswABuDkHDx5UXFyc431SUpJKlSqlmTNnat26dTpy5IjCw8M1bNgwbv4BXNP27dvVpEkTTZ061WX9yZMntWvXLsfNf0pKivLnz6/HH39c8fHxOnDggIoWLarOnTtz8w9T8vSMP8wCBCBbdO/eXXv37tWyZcskyfFAnoCAAPn4+DgeAEa/P4DrqVevnmbMmKFx48bp5ZdfVlpamiSpc+fOCg0N1aRJk5SUlORIBDLm+ecJwIB3YAwAYFIZA/J+++03xcbGqmrVqipcuLAaNWqkjh07aubMmZKkbt26KSUlRdu2bVPBggXl6+vr4cgB5AbDhw+Xj4+Phg0bJrvdrlGjRqlcuXJq06aNvvzyS6WmpmrMmDG6ePGiPvzwQwUEBKhEiRKeDhtAFmAMAGBin3zyiQYPHiwfHx/ZbDaNGzdODz30kA4cOKCXXnpJq1evVtmyZVWgQAHt2bNH69evV506dTwdNoBc5PXXX9ewYcM0adIkPfXUUzp37pwiIyO1bt06HT58WDVq1NAff/yhNWvWqG7dup4OF7imjDEAvxw23xiAKqXNNwaABAAwGedv/nv16qU+ffrojjvu0LRp07RhwwY99NBDGjFihJKSkrRt2zZ9/vnnKl26tDp27KiKFSt6OnwAudCsWbM0fPhwRxKQmJio2NhYffnllwoJCVGdOnXo+YepkQBkDgkAYEI//PCDoqKi9Pvvv+v111939OGOHj1aq1at0oMPPqgBAwaoWLFiPNwLgFsyflfs2bNHJ06cUFxcnLp27erY/s8kAMhNSAAyhzEAgAlNmzZNH374oWrVqqWLFy86fmlMmTJFkrRkyRIlJCRoxIgRjsF5AHA9GTf/y5cv1/Dhw1WoUCHFxMRo9uzZevnll1W9enUNHTpUkvTEE08oKSlJ48eP58sF5Dpmm3nHTLE4YxYgwISWLFmiRx55RMeOHdOiRYt04cIFx7YpU6aoefPmWr9+Pf85A7imjFl9MhiGoa+++kr9+/dXZGSkdu3apfXr12vdunUaMWKEdu7cKbvdrqFDh+r555/XzJkzdfbsWQ9FDyC70QIEeFjGN3N//vmnJOncuXOOJ2s+8MAD2rp1q0aPHq2ePXsqf/78juNOnDihkJAQj8QMwLzS0tJks9l06NAh7dq1S//3f/+n5ORkjR49WsHBwYqMjNTBgwfVpk0b3Xbbbdq0aZNCQkI0a9Ys1alTRzabTWfPnlWhQoU8/VEAt2W0AO0/Yr4WoMqlaAEC4CTj5n/lypV64YUXFB8fr9TUVLVv314zZ87Ue++9pwceeEBTp06VzWZT9+7dVaBAAUni5h/ANdlsNh07dkwNGjRQsWLFFB8fr969e6tjx44qUaKEzp07p3vuuUe333675s2bpw0bNqh169Z6+OGH9fbbb6tWrVrc/CPXMq68zMJMsTijBQjwIMMwtHbtWt17773q37+/Pv30Uz3xxBOaNWuWVq5cKUl677331KBBAz355JNauXKlKNoB+C/79+/X6dOnVaBAAS1dulRLlixR27ZtVa1aNW3cuFFS+qQCkpSYmKguXbooLS1NgYGBngwbQA4hAQA87Msvv9T//vc/PfLII8qTJ4+mTJmihx9+WHfeeafjZv/dd99V165d1bhxY/r+AfynVq1aqW/fvkpOTpavr6/efPNNvffee5LS2wePHTumvHnzSpK+/fZb1a5dW1u3blW5cuU8GTaAHEICAHhQSkqKoqOjFRISori4ODVr1kxt2rTRG2+8IUl68803tWrVKknS3LlzVb58eU+GC8CE/jngNykpSZLUvXt31alTR4MGDVKhQoX01ltvacWKFerRo4ckqUWLFrr11lv1+uuv66677pKPj0+Oxw5kOcOEiwmRAAA5KOMb/cuXL0uS8uTJow4dOig6OlpVqlRR586dNWfOHBmGoaSkJG3dulXbt29XcnIyrT8ArpIx4DcmJkYrVqyQJPn7+0uSGjRooM2bN+vAgQOaM2eOihYtqpdfflnffvutfvzxR91111267bbbFB0drdq1a3vuQwDIcSQAQA4yDEPfffedGjVqpBMnTkiSatasqW+//VZhYWF67LHHHDf/zz33nNauXasHHnhAfn5+tP4AuErGzX+dOnXUrVs3derUSR9++KF+/fVXFStWTFOnTtXSpUslSS+88IJCQ0P1yiuvaNOmTXrppZc0adIkVa1a1cOfAkBOIwEAclhoaKjOnDmjLl266PTp0+ratavGjx+vuLg49evXT126dFHPnj315ptvauXKlapQoYKnQwZgYmlpaSpbtqwaN26sv/76S+vWrVO7du00d+5cXbp0ScHBwdq2bZuqVq2q559/Xnny5NHChQsVFxfn6dCBLOfpbp9c0gHEcwCAnJQx7efvv/+url27Kk+ePFq/fr0KFy6sL774Qrt379b27dtVv3593XnnnapUqZKnQwaQCxw4cEBPPfWU0tLS9OCDD8pms2nGjBkqWLCgVq5cqQYNGuibb76Rn5+f9u/fr/z586tkyZKeDhvIMhnPATgQc8p0zwGoGFHUdM8BIAEAcsD27dtVr149SX8nAb/99pvuuusu+fr6at26dSpSpIiHowSQm+3fv1+PPfaYUlNT9dprr6lEiRLavXu3Jk6cqJ49e+qBBx5w/P4BvA0JQOaQAADZIOOflWEYOnfunCpVqqRq1aopKirKsd0wDO3Zs0dt2rRRnTp1tGDBAoWGhnowagC53YEDBzR06FBJ0vjx49WsWTMPRwTkjIwE4Lej5ksAKpQ0XwLAGAAgi/36668aPny4unfvrldeeUUFCxbURx99pD/++EMdO3aUJMc3cBUqVNAtt9yiL7/8Ur169bpqOj8AyIyKFStq1qxZstlsev755/Xtt996OiQAJkQCAGShn376SbfeequOHj0qf39/PfXUU5o+fbpatGihxYsXa+fOnerQoYNj/4CAAFWrVk3r1q3T/PnzZbPxTxLAzalYsaJmzpwpX19fjRo1Sps3b/Z0SABMhrsNIIvs2rVLTZo00cCBA7V8+XK9//77euSRR3T48GElJyfr1ltv1dKlS/Xbb7+padOmmjNnjoYMGaJPPvlEVatWVZkyZTz9EQB4iYoVK+qll15SyZIlVbx4cU+HA+QYw4QvM2IMAJAFYmJiVLduXbVq1UoffvihY32vXr30yy+/KDExURUqVFCPHj3UuHFjPfzwwzp79qxsNpvmz5/PQ3gAZIvk5GT5+fl5Ogwg22WMAfj96GnTjQEoX7IIYwAAb5SamqqyZcsqKSlJ3333nSTpxRdf1OrVq9W9e3c98cQT+v333zVx4kT5+PgoKipK69ev16ZNm7j5B5BtuPkHcC15PB0A4A3KlCmjRYsWafjw4Zo6dapCQkK0atUqLV++XO3atZMktWvXTmXKlNHatWtVoUIFFS1a1MNRAwDgZcz29C0zxeKECgCQRSpWrKhXX31Vly5d0qJFi/Tkk0+qXbt2stvtunz5snx8fHTLLbcoJCTE06ECAAALIwEAslClSpU0e/ZsNW/eXOvXr9c333wjwzDk6+uruXPnKi4uTo0aNfJ0mAAAwMJIAIAsVr58ec2aNUt2u10TJ07Ujh07NHXqVL300kv65JNPFBER4ekQAQDwSoYJFzNiDACQDTLm4R45cqTat2+vs2fPKjo6WnXq1PF0aAAAwOKoAADZpGLFinr55ZfVuHFj7dixQ/Xq1fN0SAAAAFQAgOxUuXJlffzxx/L19fV0KAAAeD3DSF/MwkyxOKMCAGQzbv4BAICZkAAAAAAAFkILEAAAALyEIcNUc++YKZa/UQEAAAAALIQEAAAAALAQWoAAAADgFZgFyD1UAAAAAAALIQEAgBwWGRmp2rVrO9736dNHXbt2zfE4Dh06JMMwtHPnzuvuU6ZMGc2YMcPtcy5YsEAFCxa86dgMw9CKFStu+jwAgKuRAACA0m/CDcOQYRjy9fVVuXLl9MQTTyghISHbr/3qq69qwYIFbu3rzk07AAD/hjEAAHBF+/btNX/+fF2+fFnffPONBgwYoISEBM2ePfuqfS9fvpxlD3kLDg7OkvMAAOAOKgAAcIW/v7/CwsIUERGh3r1767777nO0oWS07bzzzjsqV66c/P39Zbfbdf78eQ0aNEghISEKCgrS7bffrp9++snlvC+++KJCQ0MVGBio/v37KzEx0WX7P1uA0tLSNGXKFFWoUEH+/v4qVaqUJk6cKEkqW7asJKlOnToyDEMtW7Z0HDd//nxVrVpVAQEBqlKlit544w2X6/zwww+qU6eOAgICVL9+fe3YsSPTP6Np06apZs2ayp8/vyIiIjR48GDFx8dftd+KFStUqVIlBQQEqG3btoqJiXHZvnr1atWrV08BAQEqV66cnn32WaWkpGQ6HgBA5pEAAMB15M2bV5cvX3a8/+233/Thhx/qk08+cbTgdOrUSbGxsfr888+1fft21a1bV61bt9aZM2ckSR9++KEmTJigiRMnatu2bQoPD7/qxvyfxowZoylTpmjcuHH6+eeftXjxYoWGhkpKv4mXpK+++krHjx/XsmXLJEnz5s3T2LFjNXHiRO3bt0+TJk3SuHHjtHDhQklSQkKCOnfurMqVK2v79u2KjIzUE088kemfic1m08yZM7Vnzx4tXLhQX3/9tZ588kmXfS5evKiJEydq4cKF+u677xQXF6devXo5tn/55Ze6//77NXz4cP3888+aO3euFixY4EhyAOBGZcwCZKbFlOwAAPtDDz1kv/POOx3vt2zZYi9SpIi9Z8+edrvdbp8wYYLd19fXfuLECcc+69evtwcFBdkTExNdzlW+fHn73Llz7Xa73d6kSRP7I4884rK9UaNG9lq1al3z2nFxcXZ/f3/7vHnzrhnnwYMH7ZLsO3bscFkfERFhX7x4scu6559/3t6kSRO73W63z5071164cGF7QkKCY/vs2bOveS5npUuXtk+fPv262z/88EN7kSJFHO/nz59vl2TfvHmzY92+ffvskuxbtmyx2+12e/Pmze2TJk1yOc97771nDw8Pd7yXZF++fPl1rwsAzs6fP2+XZD8ce8Z+9mKKaZbDsWfskuznz5/39I/IBWMAAOCKTz/9VAUKFFBKSoouX76sO++8U6+99ppje+nSpVWsWDHH++3btys+Pl5FihRxOc+lS5f0+++/S5L27dunRx55xGV7kyZNtGHDhmvGsG/fPiUlJal169Zux33y5EnFxMSof//+GjhwoGN9SkqKY3zBvn37VKtWLeXLl88ljszasGGDJk2apJ9//llxcXFKSUlRYmKiEhISlD9/fklSnjx5VL9+fccxVapUUcGCBbVv3z41bNhQ27dv19atW12+8U9NTVViYqIuXrzoEiMAIOuRAADAFa1atdLs2bPl6+ur4sWLXzXIN+MGN0NaWprCw8MVFRV11bludCrMvHnzZvqYtLQ0SeltQI0aNXLZ5uPjI0my2+03FI+zw4cPq2PHjnrkkUf0/PPPq3Dhwvr222/Vv39/l1YpKX0az3/KWJeWlqZnn31W3bp1u2qfgICAm44TgHUZV15mYaZYnJEAAMAV+fPnV4UKFdzev27duoqNjVWePHlUpkyZa+5TtWpVbd68WQ8++KBj3ebNm697zooVKypv3rxav369BgwYcNV2Pz8/SenfmGcIDQ1ViRIl9Mcff+i+++675nmrVaum9957T5cuXXIkGf8Wx7Vs27ZNKSkpeuWVV2SzpQ8h+/DDD6/aLyUlRdu2bVPDhg0lSfv379e5c+dUpUoVSek/t/3792fqZw0AyDokAABwg9q0aaMmTZqoa9eumjJliipXrqxjx47p888/V9euXVW/fn3973//00MPPaT69evr1ltv1aJFi7R3716VK1fumucMCAjQ6NGj9eSTT8rPz0/NmjXTyZMntXfvXvXv318hISHKmzev1qxZo5IlSyogIEDBwcGKjIzU8OHDFRQUpA4dOigpKUnbtm3T2bNnNXLkSPXu3Vtjx45V//799cwzz+jQoUN6+eWXM/V5y5cvr5SUFL322mvq0qWLvvvuO82ZM+eq/Xx9fTVs2DDNnDlTvr6+Gjp0qBo3buxICMaPH6/OnTsrIiJCPXr0kM1m065du7R792698MILmf+LAABkCrMAAcANMgxDn3/+uW677Tb169dPlSpVUq9evXTo0CHHrD333HOPxo8fr9GjR6tevXo6fPiwHn300X8977hx4/T4449r/Pjxqlq1qu655x6dOHFCUnp//cyZMzV37lwVL15cd955pyRpwIABeuutt7RgwQLVrFlTLVq00IIFCxzThhYoUECrV6/Wzz//rDp16mjs2LGaMmVKpj5v7dq1NW3aNE2ZMkU1atTQokWLNHny5Kv2y5cvn0aPHq3evXurSZMmyps3r5YsWeLYfscdd+jTTz/VunXr1KBBAzVu3FjTpk1T6dKlMxUPAPyTp2f8yS2zABn2rGgMBQAAADwkLi5OwcHBivnrrIKCgjwdjkNcXJwiQgvp/PnzpoqLCgAAAABgIYwBAAAAgFcwrixmYaZYnFEBAAAAACyEBAAAAACwEFqAAAAA4B3oAXILFQAAAADAQkgAAAAAAAuhBQgAAABewbjyMgszxeKMCgAAAABgISQAAAAAgIXQAgQAAACvYBjpi1mYKRZnVAAAAAAACyEBAAAAACyEFiAAAAB4BZ4D5h4qAAAAAICFkAAAAAAAFkILEAAAALwDPUBuoQIAAAAAWAgJAAAAAGAhtAABAADAKxhXXmZhplicUQEAAAAALIQEAAAAALAQWoAAAADgFQwjfTELM8XijAoAAAAAYCFUAAAAAOAV4uLiPB2CC7PFk4EEAAAAALman5+fwsLCVLFshKdDuUpYWJj8/Pw8HYYLw2632z0dBAAAAHAzEhMTlZyc7OkwruLn56eAgABPh+GCBAAAAACwEAYBAwAAABZCAgAAAABYCAkAAAAAYCEkAAAAAICFkAAAAAAAFkICAAAAAFgICQAAAABgIf8PrTLS458ONj4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "early_stop=tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=200, verbose=2, mode='auto', baseline=None, restore_best_weights=True)\n",
    "model.fit(X_train_def, y_train_def, epochs=1000, batch_size=100, callbacks=[tensorboard_callback,cm_callback,early_stop], validation_data=(X_val_def, y_val_def))\n",
    "# Final evaluation of the model \n",
    "scores = model.evaluate(X_test_def, y_test_def, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n",
      "(39, 2)\n",
      "(39,)\n",
      "(39,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "#y_pred2=np.where(y_pred>0,1,0)\n",
    "#y_pred2=y_pred2[:,-1]\n",
    "y_test_def2=np.argmax(y_test_def,axis=1)\n",
    "#y_test_def2=np.where(y_test_def>0,1,0)\n",
    "print(y_pred.shape)\n",
    "print(y_pred2.shape)\n",
    "print(y_test_def2.shape)\n",
    "#print(y_test_def[25])\n",
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#docs_infra: no_execute\n",
    "if numero_clases==2:\n",
    "    classes = [0, 1]\n",
    "else:   \n",
    "    classes = [0, 1, 2, 3, 4]\n",
    "#classes = [0, 1]\n",
    "cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Buenos     0.7576    0.8621    0.8065        29\n",
      "       Malos     0.3333    0.2000    0.2500        10\n",
      "\n",
      "    accuracy                         0.6923        39\n",
      "   macro avg     0.5455    0.5310    0.5282        39\n",
      "weighted avg     0.6488    0.6923    0.6638        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "if numero_clases==2:\n",
    "    target_names = ['Buenos', 'Malos']\n",
    "else:   \n",
    "    target_names = ['A', 'B+', 'B', 'B-','C']\n",
    "print(classification_report(y_test_def2, y_pred2, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('modelos/modelote1203_200')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('idea.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "model.save('modelos\\modelo_perfecto_{}_{}.h5'.format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_34824\\1048258104.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_def\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rgadea\\AppData\\Local\\miniconda3\\envs\\tensorflow_gpu_2024\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6200\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6201\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6202\u001b[0m         ):\n\u001b[0;32m   6203\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6204\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "\n",
    "existing_file='RESULTADOS_EXCEL\\clasificacion_39_AGILENT.xlsx'\n",
    "\n",
    "# Convierte los arrays a DataFrames\n",
    "df_new = pd.DataFrame(y_pred2, columns=[experimento])\n",
    "\n",
    "# Read existing data\n",
    "df_existing = pd.read_excel(existing_file)\n",
    "\n",
    "# Verifica que df_existing es un DataFrame\n",
    "if isinstance(df_existing, pd.DataFrame):\n",
    "    # Agrega los nuevos datos\n",
    "    df_combined = df_existing.append(df_new, ignore_index=True)\n",
    "else:\n",
    "    print(\"df_existing no es un DataFrame\")\n",
    " \n",
    "# Append new data\n",
    "df_combined = df_existing.append(df_new, ignore_index=True)\n",
    "\n",
    "# Guarda los DataFrames en archivos Excel\n",
    "df_combined.to_excel(existing_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#este modo de guardar no funciona en esta version de tensorflow\n",
    "#model.save('modelos\\modelo_perfecto_{}_{}'.format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "n = len(y_pred2)\n",
    "reshaped = y_pred2[:n//4*4].reshape(-1, 4)\n",
    "mean_values = reshaped.mean(axis=1)\n",
    "\n",
    "mean_values = np.round(mean_values)\n",
    "mean_values = np.clip(mean_values, 0, 4)\n",
    "mean_values = mean_values.astype(int)\n",
    "print(mean_values)\n",
    "\n",
    "mode_values = stats.mode(reshaped, axis=1)[0]\n",
    "print(mode_values)\n",
    "\n",
    "# Convierte los arrays a DataFrames\n",
    "mean_df = pd.DataFrame(mean_values, columns=['mean'])\n",
    "mode_df = pd.DataFrame(mode_values, columns=['mode'])\n",
    "\n",
    "# Guarda los DataFrames en archivos Excel\n",
    "mean_df.to_excel(\"excels_borrar\\clasificacion_P1P2_mean_best7.xlsx\", index=False)\n",
    "mode_df.to_excel(\"excels_borrar\\clasificacion_P1_mode_best7.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename5 = \"COPIA_PANDAS\\lomosP1_20240430_clasificado_experto.hdf\"\n",
    "with pd.HDFStore(filename5,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e2  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e2 = pre_p_e2.loc[pre_p_e2['Pollo'] != 0]\n",
    "    pre_p_e2 =pre_p_e2.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_test2=np.zeros((pre_p_e2.shape[0],220,8))\n",
    "    y_test2=np.zeros((pre_p_e2.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e2.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1:\n",
    "                target = 0 \n",
    "            else:\n",
    "                target = 1\n",
    "\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_test2[x]=pepito[:,3:4]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_test2[x]=target\n",
    "        y_test2_to_categorical = to_categorical(y_test2)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_test2_filtrado = X_test2\n",
    "#y_train_filtrado = y_train\n",
    "y_test2_filtrado = y_test2_to_categorical\n",
    "\n",
    "print(X_test2_filtrado.shape)\n",
    "print(y_test2_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "# concatenamos train y test\n",
    "#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\n",
    "data_2d_test = X_test2_filtrado.reshape(-1, X_test2_filtrado.shape[-1])\n",
    "normalized_data_2d_test = scaler.transform(data_2d_test)\n",
    "\n",
    "\n",
    "X_test2_def=normalized_data_2d_test.reshape(X_test2_filtrado.shape) \n",
    "# la alternativa es normalizar con el total\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "\n",
    "y_test2_def=y_test2_filtrado # los valores ya estaban normalizados\n",
    "\n",
    "print(y_test2_def.shape)\n",
    "\n",
    "print(y_test2_filtrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# # Crear un nuevo modelo con la misma arquitectura\n",
    "# best_val_model = create_model()  # Reemplaza esto con la función que usaste para crear el modelo original\n",
    "\n",
    "# # Cargar los mejores pesos\n",
    "# best_val_model.load_weights('best_weights.h5')\n",
    "\n",
    "y_pred = model.predict(X_test2_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "n = len(y_pred2)\n",
    "print(n)\n",
    "reshaped = y_pred2[:n//4*4].reshape(-1, 4)\n",
    "mean_values = reshaped.mean(axis=1)\n",
    "\n",
    "mean_values = np.round(mean_values)\n",
    "mean_values = np.clip(mean_values, 0, 4)\n",
    "mean_values = mean_values.astype(int)\n",
    "print(mean_values.shape)\n",
    "\n",
    "mode_values = stats.mode(reshaped, axis=1)[0]\n",
    "print(mode_values.shape)\n",
    "\n",
    "n = len(y_test2_def)\n",
    "y_test2_def2=np.argmax(y_test2_def,axis=1)\n",
    "print(y_test_def2.shape)\n",
    "print(n)\n",
    "reshaped2 = y_test2_def2[:n//4*4].reshape(-1, 4)\n",
    "target_mean_values = reshaped2.mean(axis=1)\n",
    "\n",
    "target_mean_values = np.round(target_mean_values)\n",
    "target_mean_values = np.clip(target_mean_values, 0, 4)\n",
    "target_mean_values = target_mean_values.astype(int)\n",
    "print(target_mean_values.shape)\n",
    "\n",
    "target_mode_values = stats.mode(reshaped2, axis=1)[0]\n",
    "print(target_mode_values.shape)\n",
    "print(reshaped)\n",
    "print(mode_values)\n",
    "print(target_mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs_infra: no_execute\n",
    "if numero_clases==2:\n",
    "    classes = [0, 1]    \n",
    "else:\n",
    "\n",
    "    classes = [0, 1, 2, 3, 4]\n",
    "#classes = [0, 1]\n",
    "cm=confusion_matrix(target_mode_values, mode_values,labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm.diagonal()/cm.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if numero_clases==2:\n",
    "    target_names= ['Buenos', 'Malos']\n",
    "else:\n",
    "    target_names= ['A', 'B+', 'B', 'B-','C']\n",
    "print(classification_report(target_mode_values, mode_values, target_names=target_names, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
