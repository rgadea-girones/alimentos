{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:\\nuevas_investigaciones_alimentos_2024\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM,Bidirectional,GRU\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import datetime\n",
    "import io\n",
    "import itertools\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Obtener la ruta del directorio actual\n",
    "os.chdir('..')\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "# Construir la ruta relativa al directorio que quieres agregar\n",
    "relative_dir = os.path.join(current_dir, 'mis_pkgs/')\n",
    "\n",
    "# Agregar la ruta relativa al sys.path\n",
    "sys.path.insert(0, relative_dir)\n",
    "\n",
    "from MIOPATIA_db import DB_management as db \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_muestras=220\n",
    "numero_clases=2\n",
    "entrada=slice(3,4)\n",
    "numero_entradas = entrada.stop - entrada.start\n",
    "numero_epochs=800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a quedarme con los 50 atunes P1 para obtener conjunto de training y validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Add, Activation, Concatenate, Conv2D, Dropout \n",
    "from tensorflow.keras.layers import Flatten, Input, GlobalAveragePooling2D, MaxPooling2D\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "__version__ = '0.0.1'\n",
    "\n",
    "\n",
    "def SqueezeNet(input_shape, nb_classes, use_bypass=False, dropout_rate=None, compression=1.0):\n",
    "    \"\"\"\n",
    "    Creating a SqueezeNet of version 1.0\n",
    "    \n",
    "    Arguments:\n",
    "        input_shape  : shape of the input images e.g. (224,224,3)\n",
    "        nb_classes   : number of classes\n",
    "        use_bypass   : if true, bypass connections will be created at fire module 3, 5, 7, and 9 (default: False)\n",
    "        dropout_rate : defines the dropout rate that is accomplished after last fire module (default: None)\n",
    "        compression  : reduce the number of feature-maps (default: 1.0)\n",
    "        \n",
    "    Returns:\n",
    "        Model        : Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(int(96*compression), (7,7), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "    x = create_fire_module(x, int(16*compression), name='fire3', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool4')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(32*compression), name='fire5', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "    x = create_fire_module(x, int(48*compression), name='fire7', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool8')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(64*compression), name='fire9', use_bypass=use_bypass)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        \n",
    "    x = output(x, nb_classes)\n",
    "\n",
    "    return Model(inputs=input_img, outputs=x)\n",
    "\n",
    "\n",
    "def SqueezeNet_11(input_shape, nb_classes, dropout_rate=None, compression=1.0):\n",
    "    \"\"\"\n",
    "    Creating a SqueezeNet of version 1.1\n",
    "    \n",
    "    2.4x less computation over SqueezeNet 1.0 implemented above.\n",
    "    \n",
    "    Arguments:\n",
    "        input_shape  : shape of the input images e.g. (224,224,3)\n",
    "        nb_classes   : number of classes\n",
    "        dropout_rate : defines the dropout rate that is accomplished after last fire module (default: None)\n",
    "        compression  : reduce the number of feature-maps\n",
    "        \n",
    "    Returns:\n",
    "        Model        : Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(int(64*compression), (3,3), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "    x = create_fire_module(x, int(16*compression), name='fire3')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool3')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "    x = create_fire_module(x, int(32*compression), name='fire5')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool5')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "    x = create_fire_module(x, int(48*compression), name='fire7')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire9')\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # Creating last conv10\n",
    "    x = output(x, nb_classes)\n",
    "\n",
    "    return Model(inputs=input_img, outputs=x)\n",
    "\n",
    "\n",
    "def output(x, nb_classes):\n",
    "    x = Conv2D(nb_classes, (1,1), strides=(1,1), padding='valid', name='conv10')(x)\n",
    "    x = GlobalAveragePooling2D(name='avgpool10')(x)\n",
    "    x = Activation(\"softmax\", name='softmax')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_fire_module(x, nb_squeeze_filter, name, use_bypass=False):\n",
    "    \"\"\"\n",
    "    Creates a fire module\n",
    "    \n",
    "    Arguments:\n",
    "        x                 : input\n",
    "        nb_squeeze_filter : number of filters of squeeze. The filtersize of expand is 4 times of squeeze\n",
    "        use_bypass        : if True then a bypass will be added\n",
    "        name              : name of module e.g. fire123\n",
    "    \n",
    "    Returns:\n",
    "        x                 : returns a fire module\n",
    "    \"\"\"\n",
    "    \n",
    "    nb_expand_filter = 4 * nb_squeeze_filter\n",
    "    squeeze    = Conv2D(nb_squeeze_filter,(1,1), activation='relu', padding='same', name='%s_squeeze'%name)(x)\n",
    "    expand_1x1 = Conv2D(nb_expand_filter, (1,1), activation='relu', padding='same', name='%s_expand_1x1'%name)(squeeze)\n",
    "    expand_3x3 = Conv2D(nb_expand_filter, (3,3), activation='relu', padding='same', name='%s_expand_3x3'%name)(squeeze)\n",
    "    \n",
    "    axis = get_axis()\n",
    "    x_ret = Concatenate(axis=axis, name='%s_concatenate'%name)([expand_1x1, expand_3x3])\n",
    "    \n",
    "    if use_bypass:\n",
    "        x_ret = Add(name='%s_concatenate_bypass'%name)([x_ret, x])\n",
    "        \n",
    "    return x_ret\n",
    "\n",
    "\n",
    "def get_axis():\n",
    "    axis = -1 if K.image_data_format() == 'channels_last' else 1\n",
    "    return axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6336, 2)\n"
     ]
    }
   ],
   "source": [
    "filename = \"COPIA_PANDAS\\lomosP1P2_20240430_clasificado_experto_filtrado_total_trainval_ampliado_meditado.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    # p_e =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_train=np.zeros((pre_p_e1.shape[0],numero_muestras,numero_entradas))\n",
    "    y_train=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1:\n",
    "                target = 0\n",
    "            else:\n",
    "                target = 1\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_train[x]=pepito[:,entrada]\n",
    "        #X_train[x]=X_train[x].reshape(X_train[x].shape[0],-1)\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_train[x]=target\n",
    "        y_train_to_categorical = to_categorical(y_train)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_train_filtrado = X_train\n",
    "#y_train_filtrado = y_train\n",
    "y_train_filtrado = y_train_to_categorical\n",
    "\n",
    "# print(X_train_filtrado.shape)\n",
    "# print(y_train_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "scaler = StandardScaler()\n",
    "data_2d = X_train_filtrado.reshape(-1, X_train_filtrado.shape[-1])\n",
    "normalized_data_2d = scaler.fit_transform(data_2d)\n",
    "#para recurrentes\n",
    "#X_train_Normalizado=normalized_data_2d.reshape(X_train_filtrado.shape) #para recurrentes\n",
    "#para densas\n",
    "X_train_Normalizado=normalized_data_2d.reshape(X_train_filtrado.shape[0],-1)\n",
    "y_train_Normalizado=y_train_filtrado # los valores ya estaban normalizados\n",
    "print(y_train_Normalizado.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71, 220, 1)\n",
      "(71, 2)\n",
      "[-0.29305509 -0.29343913 -0.29378977 -0.29408836 -0.29423083 -0.29479745\n",
      " -0.29502449 -0.29537686 -0.29551954 -0.29576957 -0.29610394 -0.29628479\n",
      " -0.29638628 -0.29658447 -0.29673106 -0.29702077 -0.29715174 -0.29732457\n",
      " -0.29748764 -0.29764311 -0.29776975 -0.29788511 -0.29799874 -0.29809762\n",
      " -0.29825418 -0.29840815 -0.29848057 -0.29858574 -0.29872192 -0.29879196\n",
      " -0.29891621 -0.2989778  -0.29903461 -0.29912916 -0.29923129 -0.29925601\n",
      " -0.29941539 -0.2994039  -0.29943426 -0.29958844 -0.29967171 -0.29975541\n",
      " -0.29983933 -0.29991197 -0.29999112 -0.3000501  -0.30012483 -0.30019192\n",
      " -0.30023396 -0.30029967 -0.3003722  -0.30042889 -0.30048243 -0.30053943\n",
      " -0.30060167 -0.30065491 -0.30071764 -0.30077131 -0.30081023 -0.3008734\n",
      " -0.30093208 -0.30099195 -0.30105013 -0.30109619 -0.30114513 -0.30117128\n",
      " -0.30121348 -0.30124746 -0.30128705 -0.30131457 -0.30135497 -0.3013798\n",
      " -0.30138871 -0.30140571 -0.30142594 -0.30144993 -0.3014635  -0.30146827\n",
      " -0.30149026 -0.30149772 -0.30151537 -0.30154926 -0.3015979  -0.30165114\n",
      " -0.30171652 -0.30179497 -0.30185601 -0.30190973 -0.30197098 -0.30203374\n",
      " -0.30208943 -0.30213306 -0.30217139 -0.30222088 -0.30228153 -0.30233938\n",
      " -0.30239123 -0.30244429 -0.30248255 -0.30253069 -0.30258711 -0.30262104\n",
      " -0.30265518 -0.30268792 -0.30274473 -0.30282562 -0.30290336 -0.30297583\n",
      " -0.30304901 -0.30309013 -0.30316598 -0.30326035 -0.30334988 -0.30345913\n",
      " -0.30357172 -0.30367448 -0.30379368 -0.30392455 -0.30405739 -0.3042097\n",
      " -0.30435254 -0.30446185 -0.30456164 -0.30468639 -0.30481357 -0.30494136\n",
      " -0.30506925 -0.30521797 -0.30536926 -0.30554222 -0.30572595 -0.30591506\n",
      " -0.30610929 -0.30632158 -0.30653877 -0.3067337  -0.3069237  -0.307124\n",
      " -0.30731142 -0.30750393 -0.30761131 -0.30774042 -0.30792984 -0.30814749\n",
      " -0.30843901 -0.30865508 -0.30885284 -0.30905937 -0.30927669 -0.30952999\n",
      " -0.30976758 -0.30997257 -0.31021795 -0.31045798 -0.31068961 -0.31092216\n",
      " -0.31116323 -0.31137077 -0.31155504 -0.31174702 -0.31193134 -0.312049\n",
      " -0.31221783 -0.31240543 -0.31260642 -0.31278152 -0.31295942 -0.31314483\n",
      " -0.31332828 -0.31350943 -0.31365409 -0.31377322 -0.31389182 -0.31400967\n",
      " -0.31414008 -0.31427639 -0.31441003 -0.31454847 -0.31467218 -0.31482063\n",
      " -0.31497338 -0.31509804 -0.3152857  -0.31558375 -0.31575842 -0.31599119\n",
      " -0.31621452 -0.31641271 -0.31658981 -0.31674509 -0.31689506 -0.31704905\n",
      " -0.31719106 -0.31734925 -0.31749308 -0.31762575 -0.31776665 -0.31790945\n",
      " -0.31802448 -0.31813243 -0.31823335 -0.31833696 -0.31844234 -0.31854942\n",
      " -0.31867443 -0.31880949 -0.31891546 -0.31896735 -0.31904225 -0.31913935\n",
      " -0.31922585 -0.31931504 -0.31942559 -0.31952722 -0.31960328 -0.3197013\n",
      " -0.31979433 -0.31987473 -0.31996082 -0.32004003]\n"
     ]
    }
   ],
   "source": [
    "filename = \"COPIA_PANDAS\\lomosP1P2_20240430_clasificado_experto_filtrado_total_test.hdf\"\n",
    "with pd.HDFStore(filename,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e1  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e1 = pre_p_e1.loc[pre_p_e1['Pollo'] != 0]\n",
    "    pre_p_e1 =pre_p_e1.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_test=np.zeros((pre_p_e1.shape[0],numero_muestras,numero_entradas))\n",
    "    y_test=np.zeros((pre_p_e1.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e1.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1:\n",
    "                target = 0\n",
    "            else:\n",
    "                target = 1\n",
    "\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_test[x]=pepito[:,entrada]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_test[x]=target\n",
    "        y_test_to_categorical = to_categorical(y_test)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_test_filtrado = X_test\n",
    "#y_train_filtrado = y_train\n",
    "y_test_filtrado = y_test_to_categorical\n",
    "\n",
    "print(X_test_filtrado.shape)\n",
    "print(y_test_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "# concatenamos train y test\n",
    "#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\n",
    "data_2d_test = X_test_filtrado.reshape(-1, X_test_filtrado.shape[-1])\n",
    "normalized_data_2d_test = scaler.transform(data_2d_test)\n",
    "\n",
    "\n",
    "#X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape[0],-1) \n",
    "# la alternativa es normalizar con el total\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "\n",
    "y_test_def=y_test_filtrado # los valores ya estaban normalizados\n",
    "print(X_test_def[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer los conjuntos de entrenamiento validacion y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide el dataset en entrenamiento y temporal (test+validación)\n",
    "# X_temp, X_test_def, y_temp, y_test_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.2, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Divide el dataset temporal en validación y test\n",
    "X_train_def, X_val_def, y_train_def, y_val_def = train_test_split(X_train_Normalizado, y_train_Normalizado, test_size=0.25, stratify=y_train_Normalizado, random_state=42)\n",
    "\n",
    "# Ahora, X_train, X_val y X_test contienen los datos de entrada para los conjuntos de entrenamiento, validación y prueba, respectivamente.\n",
    "# y_train, y_val y y_test contienen las clases correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4752, 220)\n",
      "(1584, 220)\n",
      "(71, 220)\n",
      "(4752, 2)\n",
      "(1584, 2)\n",
      "(71, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_def.shape)\n",
    "print(X_val_def.shape)\n",
    "print(X_test_def.shape)\n",
    "print(y_train_def.shape)\n",
    "print(y_val_def.shape)\n",
    "print(y_test_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "#%tensorboard --logdir logs\n",
    "#log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"\n",
    "    Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\n",
    "    \"\"\"\n",
    "    \n",
    "    buf = io.BytesIO()\n",
    "    \n",
    "    # Use plt.savefig to save the plot to a PNG in memory.\n",
    "    plt.savefig(buf, format='png')\n",
    "    \n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    \n",
    "    # Use tf.image.decode_png to convert the PNG buffer\n",
    "    # to a TF image. Make sure you use 4 channels.\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    \n",
    "    # Use tf.expand_dims to add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "       class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    \n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    # Normalize the confusion matrix.\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    \n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    threshold = 0.5\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"red\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_aprendizaje=0.001\n",
    "dimension_LSTM=50\n",
    "dimension_dense1=50\n",
    "dimension_dense2=20\n",
    "algoritmo='rmsprop'\n",
    "supermax=8*4\n",
    "lossfunction='categorical_crossentropy'\n",
    "def create_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    # model.add(GRU(dimension_LSTM, return_sequences=False,input_shape=(numero_muestras, numero_entradas)))\n",
    "    # # model.add(GRU(50, return_sequences=True))\n",
    "    # model.add(GRU(50, return_sequences=False))\n",
    "    model.add(Dense(dimension_dense1, activation='tanh'))\n",
    "    model.add(Dense(dimension_dense2, activation='tanh'))\n",
    "    model.add(Dense(numero_clases, activation='softmax'))\n",
    "    model.compile(loss=lossfunction, optimizer=algoritmo, metrics=['accuracy'])\n",
    "    model.optimizer.lr=(factor_aprendizaje)\n",
    "    return model\n",
    "\n",
    "model=create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar una lista de los números en el rango del slice\n",
    "numbers = list(range(entrada.start, entrada.stop))\n",
    "\n",
    "# Convertir la lista a un string con los números separados por guiones\n",
    "slice_str = \"-\".join(map(str, numbers))\n",
    "#slice_str=\"todas\"\n",
    "\n",
    "\n",
    "#experimento=\"idea\"\n",
    "experimento=\"LOMOS_P1P2_entradas_{}_dense1_{}_dense2_{}_clases_{}_loss_{}_lr_{}_algoritmo_{}\".format(slice_str, dimension_dense1,dimension_dense2,numero_clases,lossfunction,factor_aprendizaje,algoritmo)\n",
    "logdir=\"./logs/defs/{}_{}\".format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if numero_clases==2:\n",
    "    class_names=['Buenos', 'Malos']\n",
    "else:\n",
    "    class_names=['A', 'B+', 'B', 'B-','C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    \n",
    "    # Use the model to predict the values from the test_images.\n",
    "    y_pred = model.predict(X_test_def)\n",
    "    #y_pred1=y_pred[:,-1]\n",
    "    y_pred2=y_pred.argmax(axis=1)\n",
    "    #y_pred2=np.where(y_pred>0,1,0)\n",
    "    #y_pred2=y_pred2[:,-1]\n",
    "    if numero_clases==2:\n",
    "        classes = [0, 1]    \n",
    "    else:\n",
    "\n",
    "        classes = [0, 1, 2, 3, 4] \n",
    "    #classes = [0, 1]\n",
    "    y_test_def2=np.argmax(y_test_def,axis=1)  \n",
    "    #y_test_def2=np.where(y_test_def>0,1,0)\n",
    "    cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    figura = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figura)\n",
    "    \n",
    "    # Log the confusion matrix as an image summary.\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6336, 2)\n",
      "(1584, 2)\n"
     ]
    }
   ],
   "source": [
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "print(y_train_Normalizado.shape)\n",
    "print(y_val_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un callback para guardar los mejores pesos\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('best_weights.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.6711 - accuracy: 0.62\n",
      "48/48 [==============================] - 2s 24ms/step - loss: 0.6701 - accuracy: 0.6204 - val_loss: 0.6504 - val_accuracy: 0.6383\n",
      "Epoch 2/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.6460 - accuracy: 0.63\n",
      "48/48 [==============================] - 1s 16ms/step - loss: 0.6452 - accuracy: 0.6416 - val_loss: 0.6355 - val_accuracy: 0.6408\n",
      "Epoch 3/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.6395 - accuracy: 0.63\n",
      "48/48 [==============================] - 1s 10ms/step - loss: 0.6378 - accuracy: 0.6418 - val_loss: 0.6361 - val_accuracy: 0.6521\n",
      "Epoch 4/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.6313 - accuracy: 0.65\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6283 - accuracy: 0.6576 - val_loss: 0.6174 - val_accuracy: 0.6799\n",
      "Epoch 5/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.6211 - accuracy: 0.66\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6195 - accuracy: 0.6644 - val_loss: 0.6298 - val_accuracy: 0.6496\n",
      "Epoch 6/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.6114 - accuracy: 0.68\n",
      "48/48 [==============================] - 0s 11ms/step - loss: 0.6112 - accuracy: 0.6797 - val_loss: 0.6068 - val_accuracy: 0.6698\n",
      "Epoch 7/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.6049 - accuracy: 0.67\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6019 - accuracy: 0.6780 - val_loss: 0.5884 - val_accuracy: 0.6919\n",
      "Epoch 8/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.5959 - accuracy: 0.68\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5920 - accuracy: 0.6923 - val_loss: 0.6046 - val_accuracy: 0.6736\n",
      "Epoch 9/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.5874 - accuracy: 0.70\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5862 - accuracy: 0.7016 - val_loss: 0.5727 - val_accuracy: 0.7197\n",
      "Epoch 10/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.5784 - accuracy: 0.71\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5788 - accuracy: 0.7125 - val_loss: 0.6031 - val_accuracy: 0.6553\n",
      "Epoch 11/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.5747 - accuracy: 0.70\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5720 - accuracy: 0.7096 - val_loss: 0.5634 - val_accuracy: 0.7336\n",
      "Epoch 12/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.5669 - accuracy: 0.71\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5661 - accuracy: 0.7193 - val_loss: 0.5573 - val_accuracy: 0.7109\n",
      "Epoch 13/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.5612 - accuracy: 0.72\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5606 - accuracy: 0.7210 - val_loss: 0.5503 - val_accuracy: 0.7330\n",
      "Epoch 14/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.5542 - accuracy: 0.72\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5526 - accuracy: 0.7233 - val_loss: 0.5425 - val_accuracy: 0.7298\n",
      "Epoch 15/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.5520 - accuracy: 0.72\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5468 - accuracy: 0.7283 - val_loss: 0.5398 - val_accuracy: 0.7424\n",
      "Epoch 16/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.5386 - accuracy: 0.73\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5384 - accuracy: 0.7346 - val_loss: 0.5631 - val_accuracy: 0.6976\n",
      "Epoch 17/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.5369 - accuracy: 0.73\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.5360 - accuracy: 0.7319 - val_loss: 0.5272 - val_accuracy: 0.7393\n",
      "Epoch 18/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.5276 - accuracy: 0.74\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5274 - accuracy: 0.7422 - val_loss: 0.5212 - val_accuracy: 0.7525\n",
      "Epoch 19/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.5232 - accuracy: 0.74\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.5232 - accuracy: 0.7412 - val_loss: 0.5330 - val_accuracy: 0.7140\n",
      "Epoch 20/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.5170 - accuracy: 0.73\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5172 - accuracy: 0.7395 - val_loss: 0.5087 - val_accuracy: 0.7367\n",
      "Epoch 21/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.5141 - accuracy: 0.74\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5145 - accuracy: 0.7466 - val_loss: 0.5100 - val_accuracy: 0.7412\n",
      "Epoch 22/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.5036 - accuracy: 0.75\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5112 - accuracy: 0.7464 - val_loss: 0.5096 - val_accuracy: 0.7393\n",
      "Epoch 23/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.5073 - accuracy: 0.74\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5043 - accuracy: 0.7454 - val_loss: 0.5137 - val_accuracy: 0.7386\n",
      "Epoch 24/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.5070 - accuracy: 0.73\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5019 - accuracy: 0.7454 - val_loss: 0.5012 - val_accuracy: 0.7614\n",
      "Epoch 25/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.4922 - accuracy: 0.75\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4951 - accuracy: 0.7506 - val_loss: 0.5631 - val_accuracy: 0.7064\n",
      "Epoch 26/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4961 - accuracy: 0.74\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4964 - accuracy: 0.7475 - val_loss: 0.4777 - val_accuracy: 0.7582\n",
      "Epoch 27/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4901 - accuracy: 0.74\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4869 - accuracy: 0.7527 - val_loss: 0.4833 - val_accuracy: 0.7652\n",
      "Epoch 28/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4889 - accuracy: 0.75\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.4893 - accuracy: 0.7532 - val_loss: 0.4713 - val_accuracy: 0.7462\n",
      "Epoch 29/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4824 - accuracy: 0.76\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4806 - accuracy: 0.7595 - val_loss: 0.4813 - val_accuracy: 0.7437\n",
      "Epoch 30/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4811 - accuracy: 0.75\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4799 - accuracy: 0.7580 - val_loss: 0.4888 - val_accuracy: 0.7481\n",
      "Epoch 31/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4698 - accuracy: 0.76\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4749 - accuracy: 0.7609 - val_loss: 0.5358 - val_accuracy: 0.7027\n",
      "Epoch 32/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4739 - accuracy: 0.76\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4744 - accuracy: 0.7605 - val_loss: 0.4541 - val_accuracy: 0.7607\n",
      "Epoch 33/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4699 - accuracy: 0.76\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4685 - accuracy: 0.7660 - val_loss: 0.4770 - val_accuracy: 0.7279\n",
      "Epoch 34/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4718 - accuracy: 0.75\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4653 - accuracy: 0.7616 - val_loss: 0.4706 - val_accuracy: 0.7525\n",
      "Epoch 35/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4643 - accuracy: 0.76\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4643 - accuracy: 0.7675 - val_loss: 0.4642 - val_accuracy: 0.7588\n",
      "Epoch 36/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4634 - accuracy: 0.76\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4642 - accuracy: 0.7677 - val_loss: 0.4489 - val_accuracy: 0.7746\n",
      "Epoch 37/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.4565 - accuracy: 0.77\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4603 - accuracy: 0.7689 - val_loss: 0.4558 - val_accuracy: 0.7626\n",
      "Epoch 38/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4620 - accuracy: 0.76\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4560 - accuracy: 0.7691 - val_loss: 0.4747 - val_accuracy: 0.7715\n",
      "Epoch 39/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4572 - accuracy: 0.76\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.4570 - accuracy: 0.7683 - val_loss: 0.4974 - val_accuracy: 0.7551\n",
      "Epoch 40/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4551 - accuracy: 0.76\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4525 - accuracy: 0.7725 - val_loss: 0.4377 - val_accuracy: 0.7544\n",
      "Epoch 41/800\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.4548 - accuracy: 0.77\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4531 - accuracy: 0.7731 - val_loss: 0.4514 - val_accuracy: 0.7519\n",
      "Epoch 42/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4466 - accuracy: 0.77\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4494 - accuracy: 0.7736 - val_loss: 0.4565 - val_accuracy: 0.7727\n",
      "Epoch 43/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4473 - accuracy: 0.77\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4474 - accuracy: 0.7790 - val_loss: 0.4520 - val_accuracy: 0.7715\n",
      "Epoch 44/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4462 - accuracy: 0.77\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4461 - accuracy: 0.7765 - val_loss: 0.4268 - val_accuracy: 0.7904\n",
      "Epoch 45/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4443 - accuracy: 0.77\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4443 - accuracy: 0.7755 - val_loss: 0.4628 - val_accuracy: 0.7468\n",
      "Epoch 46/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4417 - accuracy: 0.78\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.4418 - accuracy: 0.7841 - val_loss: 0.4785 - val_accuracy: 0.7292\n",
      "Epoch 47/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4339 - accuracy: 0.79\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4398 - accuracy: 0.7845 - val_loss: 0.4734 - val_accuracy: 0.7645\n",
      "Epoch 48/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4373 - accuracy: 0.78\n",
      "48/48 [==============================] - 0s 11ms/step - loss: 0.4389 - accuracy: 0.7849 - val_loss: 0.4322 - val_accuracy: 0.7513\n",
      "Epoch 49/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4362 - accuracy: 0.78\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4372 - accuracy: 0.7822 - val_loss: 0.4307 - val_accuracy: 0.7910\n",
      "Epoch 50/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4343 - accuracy: 0.78\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4341 - accuracy: 0.7841 - val_loss: 0.4472 - val_accuracy: 0.7702\n",
      "Epoch 51/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4357 - accuracy: 0.78\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4324 - accuracy: 0.7856 - val_loss: 0.4209 - val_accuracy: 0.7923\n",
      "Epoch 52/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4308 - accuracy: 0.78\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4313 - accuracy: 0.7828 - val_loss: 0.4205 - val_accuracy: 0.7753\n",
      "Epoch 53/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4285 - accuracy: 0.78\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4285 - accuracy: 0.7864 - val_loss: 0.4411 - val_accuracy: 0.7860\n",
      "Epoch 54/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4269 - accuracy: 0.78\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4261 - accuracy: 0.7881 - val_loss: 0.4122 - val_accuracy: 0.7923\n",
      "Epoch 55/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4240 - accuracy: 0.78\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4256 - accuracy: 0.7877 - val_loss: 0.4162 - val_accuracy: 0.7891\n",
      "Epoch 56/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4237 - accuracy: 0.78\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4234 - accuracy: 0.7851 - val_loss: 0.4231 - val_accuracy: 0.7967\n",
      "Epoch 57/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4222 - accuracy: 0.78\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4221 - accuracy: 0.7900 - val_loss: 0.4021 - val_accuracy: 0.8011\n",
      "Epoch 58/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4203 - accuracy: 0.78\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4243 - accuracy: 0.7881 - val_loss: 0.4019 - val_accuracy: 0.8024\n",
      "Epoch 59/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4169 - accuracy: 0.79\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4179 - accuracy: 0.7936 - val_loss: 0.4228 - val_accuracy: 0.7828\n",
      "Epoch 60/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4206 - accuracy: 0.79\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4186 - accuracy: 0.7934 - val_loss: 0.4269 - val_accuracy: 0.7917\n",
      "Epoch 61/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4190 - accuracy: 0.79\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4200 - accuracy: 0.7931 - val_loss: 0.4191 - val_accuracy: 0.7765\n",
      "Epoch 62/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4166 - accuracy: 0.79\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4156 - accuracy: 0.7915 - val_loss: 0.4014 - val_accuracy: 0.8037\n",
      "Epoch 63/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4180 - accuracy: 0.78\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4158 - accuracy: 0.7894 - val_loss: 0.4107 - val_accuracy: 0.7885\n",
      "Epoch 64/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4106 - accuracy: 0.79\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4097 - accuracy: 0.7965 - val_loss: 0.4516 - val_accuracy: 0.7500\n",
      "Epoch 65/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4152 - accuracy: 0.78\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.4097 - accuracy: 0.7931 - val_loss: 0.4081 - val_accuracy: 0.7980\n",
      "Epoch 66/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4022 - accuracy: 0.80\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4116 - accuracy: 0.7948 - val_loss: 0.3966 - val_accuracy: 0.8011\n",
      "Epoch 67/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4042 - accuracy: 0.80\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4053 - accuracy: 0.7988 - val_loss: 0.3926 - val_accuracy: 0.8081\n",
      "Epoch 68/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4066 - accuracy: 0.79\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4037 - accuracy: 0.7997 - val_loss: 0.3808 - val_accuracy: 0.8049\n",
      "Epoch 69/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.4012 - accuracy: 0.80\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4011 - accuracy: 0.8022 - val_loss: 0.3975 - val_accuracy: 0.8081\n",
      "Epoch 70/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.4041 - accuracy: 0.79\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.4006 - accuracy: 0.7999 - val_loss: 0.3923 - val_accuracy: 0.7999\n",
      "Epoch 71/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.3978 - accuracy: 0.80\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4001 - accuracy: 0.7999 - val_loss: 0.3885 - val_accuracy: 0.8112\n",
      "Epoch 72/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3990 - accuracy: 0.80\n",
      "48/48 [==============================] - 1s 27ms/step - loss: 0.3984 - accuracy: 0.8037 - val_loss: 0.4008 - val_accuracy: 0.8037\n",
      "Epoch 73/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3918 - accuracy: 0.80\n",
      "48/48 [==============================] - 1s 17ms/step - loss: 0.3972 - accuracy: 0.8032 - val_loss: 0.4181 - val_accuracy: 0.7816\n",
      "Epoch 74/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3983 - accuracy: 0.79\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.3977 - accuracy: 0.8003 - val_loss: 0.3739 - val_accuracy: 0.8093\n",
      "Epoch 75/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3981 - accuracy: 0.80\n",
      "48/48 [==============================] - 0s 11ms/step - loss: 0.3948 - accuracy: 0.8047 - val_loss: 0.3992 - val_accuracy: 0.8005\n",
      "Epoch 76/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3923 - accuracy: 0.80\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3940 - accuracy: 0.8026 - val_loss: 0.3962 - val_accuracy: 0.8056\n",
      "Epoch 77/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3862 - accuracy: 0.80\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3874 - accuracy: 0.8066 - val_loss: 0.4293 - val_accuracy: 0.7721\n",
      "Epoch 78/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3911 - accuracy: 0.80\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3908 - accuracy: 0.8053 - val_loss: 0.3952 - val_accuracy: 0.7753\n",
      "Epoch 79/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3876 - accuracy: 0.80\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.3886 - accuracy: 0.8077 - val_loss: 0.3833 - val_accuracy: 0.8011\n",
      "Epoch 80/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3861 - accuracy: 0.80\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.3860 - accuracy: 0.8091 - val_loss: 0.3867 - val_accuracy: 0.8131\n",
      "Epoch 81/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3900 - accuracy: 0.80\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.3862 - accuracy: 0.8077 - val_loss: 0.3654 - val_accuracy: 0.8093\n",
      "Epoch 82/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3850 - accuracy: 0.80\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.3843 - accuracy: 0.8064 - val_loss: 0.3739 - val_accuracy: 0.8119\n",
      "Epoch 83/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3829 - accuracy: 0.81\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3836 - accuracy: 0.8114 - val_loss: 0.3666 - val_accuracy: 0.8220\n",
      "Epoch 84/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3787 - accuracy: 0.81\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3788 - accuracy: 0.8148 - val_loss: 0.4409 - val_accuracy: 0.7677\n",
      "Epoch 85/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3776 - accuracy: 0.81\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3804 - accuracy: 0.8127 - val_loss: 0.3976 - val_accuracy: 0.7948\n",
      "Epoch 86/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.3787 - accuracy: 0.81\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3765 - accuracy: 0.8144 - val_loss: 0.4215 - val_accuracy: 0.7822\n",
      "Epoch 87/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3749 - accuracy: 0.81\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3752 - accuracy: 0.8129 - val_loss: 0.4558 - val_accuracy: 0.7727\n",
      "Epoch 88/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3767 - accuracy: 0.81\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3752 - accuracy: 0.8150 - val_loss: 0.3736 - val_accuracy: 0.8106\n",
      "Epoch 89/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3742 - accuracy: 0.81\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.3740 - accuracy: 0.8169 - val_loss: 0.3466 - val_accuracy: 0.8327\n",
      "Epoch 90/800\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.3705 - accuracy: 0.81\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 0.3714 - accuracy: 0.8171 - val_loss: 0.3519 - val_accuracy: 0.8213\n",
      "Epoch 91/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3710 - accuracy: 0.82\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.3715 - accuracy: 0.8171 - val_loss: 0.3524 - val_accuracy: 0.8138\n",
      "Epoch 92/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3655 - accuracy: 0.82\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3673 - accuracy: 0.8192 - val_loss: 0.3649 - val_accuracy: 0.8163\n",
      "Epoch 93/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3669 - accuracy: 0.82\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3669 - accuracy: 0.8203 - val_loss: 0.3986 - val_accuracy: 0.7847\n",
      "Epoch 94/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3671 - accuracy: 0.81\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.3674 - accuracy: 0.8201 - val_loss: 0.3801 - val_accuracy: 0.8081\n",
      "Epoch 95/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.3633 - accuracy: 0.81\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.3637 - accuracy: 0.8180 - val_loss: 0.3389 - val_accuracy: 0.8314\n",
      "Epoch 96/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3628 - accuracy: 0.82\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3635 - accuracy: 0.8218 - val_loss: 0.3496 - val_accuracy: 0.8359\n",
      "Epoch 97/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3606 - accuracy: 0.82\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3609 - accuracy: 0.8224 - val_loss: 0.3393 - val_accuracy: 0.8207\n",
      "Epoch 98/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.3561 - accuracy: 0.82\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 0.3587 - accuracy: 0.8251 - val_loss: 0.3438 - val_accuracy: 0.8314\n",
      "Epoch 99/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3593 - accuracy: 0.82\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.3598 - accuracy: 0.8211 - val_loss: 0.3391 - val_accuracy: 0.8302\n",
      "Epoch 100/800\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.3559 - accuracy: 0.82\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3559 - accuracy: 0.8270 - val_loss: 0.3952 - val_accuracy: 0.7904\n",
      "Epoch 101/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3588 - accuracy: 0.82\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.3558 - accuracy: 0.8258 - val_loss: 0.3905 - val_accuracy: 0.7973\n",
      "Epoch 102/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.3516 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3551 - accuracy: 0.8291 - val_loss: 0.3393 - val_accuracy: 0.8302\n",
      "Epoch 103/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3562 - accuracy: 0.82\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3516 - accuracy: 0.8287 - val_loss: 0.3324 - val_accuracy: 0.8327\n",
      "Epoch 104/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3564 - accuracy: 0.82\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3518 - accuracy: 0.8277 - val_loss: 0.3368 - val_accuracy: 0.8245\n",
      "Epoch 105/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3468 - accuracy: 0.82\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3490 - accuracy: 0.8264 - val_loss: 0.4908 - val_accuracy: 0.7551\n",
      "Epoch 106/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3570 - accuracy: 0.82\n",
      "48/48 [==============================] - 0s 11ms/step - loss: 0.3508 - accuracy: 0.8289 - val_loss: 0.3303 - val_accuracy: 0.8378\n",
      "Epoch 107/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3395 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3459 - accuracy: 0.8327 - val_loss: 0.3352 - val_accuracy: 0.8314\n",
      "Epoch 108/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.3498 - accuracy: 0.82\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.3481 - accuracy: 0.8289 - val_loss: 0.3520 - val_accuracy: 0.8295\n",
      "Epoch 109/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3515 - accuracy: 0.82\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.3469 - accuracy: 0.8279 - val_loss: 0.3949 - val_accuracy: 0.7866\n",
      "Epoch 110/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3453 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.3465 - accuracy: 0.8285 - val_loss: 0.3472 - val_accuracy: 0.8005\n",
      "Epoch 111/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.3411 - accuracy: 0.82\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3411 - accuracy: 0.8289 - val_loss: 0.3322 - val_accuracy: 0.8295\n",
      "Epoch 112/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3397 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3417 - accuracy: 0.8316 - val_loss: 0.3213 - val_accuracy: 0.8384\n",
      "Epoch 113/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3435 - accuracy: 0.82\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.3429 - accuracy: 0.8300 - val_loss: 0.3260 - val_accuracy: 0.8302\n",
      "Epoch 114/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3364 - accuracy: 0.83\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.3416 - accuracy: 0.8308 - val_loss: 0.3221 - val_accuracy: 0.8396\n",
      "Epoch 115/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3432 - accuracy: 0.82\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3378 - accuracy: 0.8338 - val_loss: 0.3125 - val_accuracy: 0.8378\n",
      "Epoch 116/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3354 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3365 - accuracy: 0.8312 - val_loss: 0.3795 - val_accuracy: 0.8062\n",
      "Epoch 117/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3429 - accuracy: 0.82\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3385 - accuracy: 0.8310 - val_loss: 0.3511 - val_accuracy: 0.8074\n",
      "Epoch 118/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3356 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.3363 - accuracy: 0.8308 - val_loss: 0.3300 - val_accuracy: 0.8270\n",
      "Epoch 119/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3342 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.3339 - accuracy: 0.8308 - val_loss: 0.3136 - val_accuracy: 0.8396\n",
      "Epoch 120/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3325 - accuracy: 0.82\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.3327 - accuracy: 0.8302 - val_loss: 0.3461 - val_accuracy: 0.8087\n",
      "Epoch 121/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3336 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3320 - accuracy: 0.8361 - val_loss: 0.3153 - val_accuracy: 0.8371\n",
      "Epoch 122/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3303 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.3320 - accuracy: 0.8363 - val_loss: 0.3288 - val_accuracy: 0.8352\n",
      "Epoch 123/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.3328 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3327 - accuracy: 0.8338 - val_loss: 0.3092 - val_accuracy: 0.8365\n",
      "Epoch 124/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.3318 - accuracy: 0.82\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3296 - accuracy: 0.8308 - val_loss: 0.3708 - val_accuracy: 0.8081\n",
      "Epoch 125/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3256 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3256 - accuracy: 0.8356 - val_loss: 0.3186 - val_accuracy: 0.8346\n",
      "Epoch 126/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3287 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3279 - accuracy: 0.8338 - val_loss: 0.3672 - val_accuracy: 0.8112\n",
      "Epoch 127/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3277 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3260 - accuracy: 0.8356 - val_loss: 0.3357 - val_accuracy: 0.8258\n",
      "Epoch 128/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3285 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.3253 - accuracy: 0.8356 - val_loss: 0.3798 - val_accuracy: 0.7992\n",
      "Epoch 129/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3278 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3269 - accuracy: 0.8346 - val_loss: 0.2996 - val_accuracy: 0.8365\n",
      "Epoch 130/800\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.3215 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3227 - accuracy: 0.8356 - val_loss: 0.3022 - val_accuracy: 0.8333\n",
      "Epoch 131/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3226 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3214 - accuracy: 0.8331 - val_loss: 0.3119 - val_accuracy: 0.8365\n",
      "Epoch 132/800\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.3163 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.3182 - accuracy: 0.8361 - val_loss: 0.3389 - val_accuracy: 0.8201\n",
      "Epoch 133/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3208 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.3204 - accuracy: 0.8373 - val_loss: 0.3045 - val_accuracy: 0.8428\n",
      "Epoch 134/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3211 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.3216 - accuracy: 0.8335 - val_loss: 0.3003 - val_accuracy: 0.8384\n",
      "Epoch 135/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.3207 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3195 - accuracy: 0.8371 - val_loss: 0.3008 - val_accuracy: 0.8314\n",
      "Epoch 136/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3174 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3186 - accuracy: 0.8363 - val_loss: 0.3198 - val_accuracy: 0.8277\n",
      "Epoch 137/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3198 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.3180 - accuracy: 0.8390 - val_loss: 0.2941 - val_accuracy: 0.8365\n",
      "Epoch 138/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3179 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3161 - accuracy: 0.8361 - val_loss: 0.2983 - val_accuracy: 0.8302\n",
      "Epoch 139/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.3156 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 16ms/step - loss: 0.3146 - accuracy: 0.8388 - val_loss: 0.3513 - val_accuracy: 0.8119\n",
      "Epoch 140/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3226 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3161 - accuracy: 0.8378 - val_loss: 0.3084 - val_accuracy: 0.8359\n",
      "Epoch 141/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3138 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.3150 - accuracy: 0.8373 - val_loss: 0.2991 - val_accuracy: 0.8441\n",
      "Epoch 142/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3138 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 17ms/step - loss: 0.3151 - accuracy: 0.8394 - val_loss: 0.3346 - val_accuracy: 0.8258\n",
      "Epoch 143/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3099 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.3130 - accuracy: 0.8386 - val_loss: 0.2859 - val_accuracy: 0.8548\n",
      "Epoch 144/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.3108 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.3118 - accuracy: 0.8396 - val_loss: 0.2910 - val_accuracy: 0.8460\n",
      "Epoch 145/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3140 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.3148 - accuracy: 0.8352 - val_loss: 0.2972 - val_accuracy: 0.8390\n",
      "Epoch 146/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3145 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3098 - accuracy: 0.8418 - val_loss: 0.3202 - val_accuracy: 0.8504\n",
      "Epoch 147/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3116 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.3111 - accuracy: 0.8455 - val_loss: 0.2977 - val_accuracy: 0.8434\n",
      "Epoch 148/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3168 - accuracy: 0.83\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.3120 - accuracy: 0.8378 - val_loss: 0.3081 - val_accuracy: 0.8460\n",
      "Epoch 149/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3107 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3107 - accuracy: 0.8382 - val_loss: 0.2895 - val_accuracy: 0.8447\n",
      "Epoch 150/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3075 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3065 - accuracy: 0.8453 - val_loss: 0.2954 - val_accuracy: 0.8491\n",
      "Epoch 151/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3060 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3080 - accuracy: 0.8392 - val_loss: 0.3016 - val_accuracy: 0.8409\n",
      "Epoch 152/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.3070 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.3064 - accuracy: 0.8491 - val_loss: 0.3296 - val_accuracy: 0.8251\n",
      "Epoch 153/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.3137 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.3097 - accuracy: 0.8375 - val_loss: 0.3034 - val_accuracy: 0.8415\n",
      "Epoch 154/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.3004 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.3046 - accuracy: 0.8428 - val_loss: 0.3054 - val_accuracy: 0.8396\n",
      "Epoch 155/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3017 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3036 - accuracy: 0.8468 - val_loss: 0.2984 - val_accuracy: 0.8441\n",
      "Epoch 156/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2952 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3037 - accuracy: 0.8487 - val_loss: 0.3316 - val_accuracy: 0.8220\n",
      "Epoch 157/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3115 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3064 - accuracy: 0.8426 - val_loss: 0.3178 - val_accuracy: 0.8371\n",
      "Epoch 158/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.3018 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.3040 - accuracy: 0.8445 - val_loss: 0.2846 - val_accuracy: 0.8447\n",
      "Epoch 159/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.3082 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.3059 - accuracy: 0.8447 - val_loss: 0.2929 - val_accuracy: 0.8441\n",
      "Epoch 160/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3004 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.3010 - accuracy: 0.8457 - val_loss: 0.2927 - val_accuracy: 0.8434\n",
      "Epoch 161/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3113 - accuracy: 0.83\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3045 - accuracy: 0.8447 - val_loss: 0.2988 - val_accuracy: 0.8453\n",
      "Epoch 162/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.3033 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.3033 - accuracy: 0.8447 - val_loss: 0.2832 - val_accuracy: 0.8453\n",
      "Epoch 163/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3017 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.3004 - accuracy: 0.8493 - val_loss: 0.2899 - val_accuracy: 0.8447\n",
      "Epoch 164/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3014 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3013 - accuracy: 0.8466 - val_loss: 0.2779 - val_accuracy: 0.8485\n",
      "Epoch 165/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2960 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.2979 - accuracy: 0.8426 - val_loss: 0.3138 - val_accuracy: 0.7917\n",
      "Epoch 166/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2987 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.2999 - accuracy: 0.8479 - val_loss: 0.3566 - val_accuracy: 0.8302\n",
      "Epoch 167/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2985 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3011 - accuracy: 0.8510 - val_loss: 0.3011 - val_accuracy: 0.8466\n",
      "Epoch 168/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3021 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.3023 - accuracy: 0.8449 - val_loss: 0.3002 - val_accuracy: 0.8415\n",
      "Epoch 169/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2991 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2995 - accuracy: 0.8481 - val_loss: 0.2831 - val_accuracy: 0.8523\n",
      "Epoch 170/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2968 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.2983 - accuracy: 0.8479 - val_loss: 0.2841 - val_accuracy: 0.8409\n",
      "Epoch 171/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3003 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.3003 - accuracy: 0.8455 - val_loss: 0.2780 - val_accuracy: 0.8479\n",
      "Epoch 172/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2941 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.2946 - accuracy: 0.8506 - val_loss: 0.3177 - val_accuracy: 0.7513\n",
      "Epoch 173/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2963 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.2983 - accuracy: 0.8466 - val_loss: 0.2850 - val_accuracy: 0.8561\n",
      "Epoch 174/800\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.2950 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.2963 - accuracy: 0.8521 - val_loss: 0.2756 - val_accuracy: 0.8497\n",
      "Epoch 175/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2981 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.2981 - accuracy: 0.8495 - val_loss: 0.3105 - val_accuracy: 0.8447\n",
      "Epoch 176/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2958 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2954 - accuracy: 0.8523 - val_loss: 0.2883 - val_accuracy: 0.8674\n",
      "Epoch 177/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3009 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.2998 - accuracy: 0.8434 - val_loss: 0.2770 - val_accuracy: 0.8409\n",
      "Epoch 178/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2982 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.2977 - accuracy: 0.8491 - val_loss: 0.2933 - val_accuracy: 0.8434\n",
      "Epoch 179/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2949 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.2929 - accuracy: 0.8506 - val_loss: 0.3113 - val_accuracy: 0.8378\n",
      "Epoch 180/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.2959 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2964 - accuracy: 0.8504 - val_loss: 0.2871 - val_accuracy: 0.8624\n",
      "Epoch 181/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2951 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 0.2954 - accuracy: 0.8468 - val_loss: 0.2759 - val_accuracy: 0.8491\n",
      "Epoch 182/800\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.2956 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.2937 - accuracy: 0.8537 - val_loss: 0.2760 - val_accuracy: 0.8472\n",
      "Epoch 183/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.2941 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.2929 - accuracy: 0.8481 - val_loss: 0.2838 - val_accuracy: 0.8403\n",
      "Epoch 184/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2980 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2952 - accuracy: 0.8489 - val_loss: 0.2869 - val_accuracy: 0.8434\n",
      "Epoch 185/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2935 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2956 - accuracy: 0.8554 - val_loss: 0.2988 - val_accuracy: 0.8491\n",
      "Epoch 186/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.2887 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2903 - accuracy: 0.8489 - val_loss: 0.2900 - val_accuracy: 0.8453\n",
      "Epoch 187/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.2932 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2961 - accuracy: 0.8508 - val_loss: 0.2857 - val_accuracy: 0.8497\n",
      "Epoch 188/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2940 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2925 - accuracy: 0.8516 - val_loss: 0.2816 - val_accuracy: 0.8434\n",
      "Epoch 189/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.2931 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2926 - accuracy: 0.8497 - val_loss: 0.2716 - val_accuracy: 0.8485\n",
      "Epoch 190/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2883 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 18ms/step - loss: 0.2889 - accuracy: 0.8500 - val_loss: 0.3453 - val_accuracy: 0.8245\n",
      "Epoch 191/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2935 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2925 - accuracy: 0.8512 - val_loss: 0.2893 - val_accuracy: 0.8573\n",
      "Epoch 192/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.2946 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2890 - accuracy: 0.8504 - val_loss: 0.2863 - val_accuracy: 0.8485\n",
      "Epoch 193/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2930 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2930 - accuracy: 0.8497 - val_loss: 0.2769 - val_accuracy: 0.8441\n",
      "Epoch 194/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.2908 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2916 - accuracy: 0.8552 - val_loss: 0.2722 - val_accuracy: 0.8662\n",
      "Epoch 195/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.2873 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2874 - accuracy: 0.8544 - val_loss: 0.2931 - val_accuracy: 0.8567\n",
      "Epoch 196/800\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.2884 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2876 - accuracy: 0.8556 - val_loss: 0.3821 - val_accuracy: 0.8106\n",
      "Epoch 197/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2885 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2885 - accuracy: 0.8548 - val_loss: 0.2817 - val_accuracy: 0.8491\n",
      "Epoch 198/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.3008 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2907 - accuracy: 0.8523 - val_loss: 0.2676 - val_accuracy: 0.8561\n",
      "Epoch 199/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2879 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.2874 - accuracy: 0.8575 - val_loss: 0.2738 - val_accuracy: 0.8422\n",
      "Epoch 200/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.2868 - accuracy: 0.84\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.2881 - accuracy: 0.8476 - val_loss: 0.2863 - val_accuracy: 0.8384\n",
      "Epoch 201/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.2894 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2875 - accuracy: 0.8523 - val_loss: 0.2838 - val_accuracy: 0.8466\n",
      "Epoch 202/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2873 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2873 - accuracy: 0.8531 - val_loss: 0.2791 - val_accuracy: 0.8655\n",
      "Epoch 203/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2890 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2890 - accuracy: 0.8569 - val_loss: 0.2900 - val_accuracy: 0.8491\n",
      "Epoch 204/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2796 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2846 - accuracy: 0.8527 - val_loss: 0.2696 - val_accuracy: 0.8504\n",
      "Epoch 205/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2861 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2858 - accuracy: 0.8521 - val_loss: 0.2825 - val_accuracy: 0.8447\n",
      "Epoch 206/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2886 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2853 - accuracy: 0.8519 - val_loss: 0.2671 - val_accuracy: 0.8516\n",
      "Epoch 207/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2864 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2859 - accuracy: 0.8561 - val_loss: 0.2731 - val_accuracy: 0.8460\n",
      "Epoch 208/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2818 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2844 - accuracy: 0.8556 - val_loss: 0.3591 - val_accuracy: 0.8453\n",
      "Epoch 209/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2781 - accuracy: 0.86\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.2819 - accuracy: 0.8563 - val_loss: 0.2623 - val_accuracy: 0.8655\n",
      "Epoch 210/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2836 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2834 - accuracy: 0.8544 - val_loss: 0.2759 - val_accuracy: 0.8510\n",
      "Epoch 211/800\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.2878 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.2855 - accuracy: 0.8540 - val_loss: 0.3091 - val_accuracy: 0.8422\n",
      "Epoch 212/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2828 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2826 - accuracy: 0.8544 - val_loss: 0.3162 - val_accuracy: 0.8371\n",
      "Epoch 213/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2823 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.2825 - accuracy: 0.8559 - val_loss: 0.2776 - val_accuracy: 0.8567\n",
      "Epoch 214/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2896 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2827 - accuracy: 0.8569 - val_loss: 0.2799 - val_accuracy: 0.8674\n",
      "Epoch 215/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.2760 - accuracy: 0.86\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 0.2830 - accuracy: 0.8573 - val_loss: 0.2757 - val_accuracy: 0.8586\n",
      "Epoch 216/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2880 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 19ms/step - loss: 0.2844 - accuracy: 0.8584 - val_loss: 0.2699 - val_accuracy: 0.8605\n",
      "Epoch 217/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2768 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.2785 - accuracy: 0.8529 - val_loss: 0.2689 - val_accuracy: 0.8510\n",
      "Epoch 218/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2828 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.2851 - accuracy: 0.8550 - val_loss: 0.2846 - val_accuracy: 0.8378\n",
      "Epoch 219/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2787 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2793 - accuracy: 0.8567 - val_loss: 0.2847 - val_accuracy: 0.8428\n",
      "Epoch 220/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2820 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.2834 - accuracy: 0.8500 - val_loss: 0.2851 - val_accuracy: 0.8611\n",
      "Epoch 221/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.2819 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.2806 - accuracy: 0.8575 - val_loss: 0.2657 - val_accuracy: 0.8516\n",
      "Epoch 222/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2775 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2775 - accuracy: 0.8588 - val_loss: 0.2892 - val_accuracy: 0.8428\n",
      "Epoch 223/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.2809 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2809 - accuracy: 0.8571 - val_loss: 0.2839 - val_accuracy: 0.8466\n",
      "Epoch 224/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2853 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 0.2832 - accuracy: 0.8563 - val_loss: 0.2875 - val_accuracy: 0.8485\n",
      "Epoch 225/800\n",
      "3/3 [==============================] - 0s 3ms/step loss: 0.2848 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.2818 - accuracy: 0.8521 - val_loss: 0.2743 - val_accuracy: 0.8611\n",
      "Epoch 226/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2794 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.2816 - accuracy: 0.8563 - val_loss: 0.2702 - val_accuracy: 0.8428\n",
      "Epoch 227/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2769 - accuracy: 0.86\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2778 - accuracy: 0.8647 - val_loss: 0.2716 - val_accuracy: 0.8567\n",
      "Epoch 228/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2784 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2771 - accuracy: 0.8592 - val_loss: 0.2661 - val_accuracy: 0.8542\n",
      "Epoch 229/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2787 - accuracy: 0.85\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.2772 - accuracy: 0.8598 - val_loss: 0.2571 - val_accuracy: 0.8712\n",
      "Epoch 230/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2786 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.2786 - accuracy: 0.8594 - val_loss: 0.2708 - val_accuracy: 0.8441\n",
      "Epoch 231/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2814 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2798 - accuracy: 0.8588 - val_loss: 0.2942 - val_accuracy: 0.8466\n",
      "Epoch 232/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2734 - accuracy: 0.86\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2771 - accuracy: 0.8582 - val_loss: 0.2573 - val_accuracy: 0.8662\n",
      "Epoch 233/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2716 - accuracy: 0.86\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.2786 - accuracy: 0.8590 - val_loss: 0.2716 - val_accuracy: 0.8674\n",
      "Epoch 234/800\n",
      "3/3 [==============================] - 0s 2ms/step loss: 0.2763 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2777 - accuracy: 0.8573 - val_loss: 0.2645 - val_accuracy: 0.8548\n",
      "Epoch 235/800\n",
      "3/3 [==============================] - 0s 1ms/step loss: 0.2789 - accuracy: 0.85\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.2760 - accuracy: 0.8607 - val_loss: 0.2836 - val_accuracy: 0.8491\n",
      "Epoch 236/800\n",
      " 1/48 [..............................] - ETA: 0s - loss: 0.3337 - accuracy: 0.8100"
     ]
    }
   ],
   "source": [
    "early_stop=tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1000, verbose=2, mode='auto', baseline=None, restore_best_weights=True)\n",
    "model.fit(X_train_def, y_train_def, epochs=numero_epochs, batch_size=100, callbacks=[tensorboard_callback,cm_callback,early_stop], validation_data=(X_val_def, y_val_def))\n",
    "# Final evaluation of the model \n",
    "scores = model.evaluate(X_test_def, y_test_def, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "#y_pred2=np.where(y_pred>0,1,0)\n",
    "#y_pred2=y_pred2[:,-1]\n",
    "y_test_def2=np.argmax(y_test_def,axis=1)\n",
    "#y_test_def2=np.where(y_test_def>0,1,0)\n",
    "print(y_pred.shape)\n",
    "print(y_pred2.shape)\n",
    "print(y_test_def2.shape)\n",
    "#print(y_test_def[25])\n",
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs_infra: no_execute\n",
    "if numero_clases==2:\n",
    "    classes = [0, 1]\n",
    "else:   \n",
    "    classes = [0, 1, 2, 3, 4]\n",
    "#classes = [0, 1]\n",
    "cm=confusion_matrix(y_test_def2, y_pred2,labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "if numero_clases==2:\n",
    "    target_names = ['Buenos', 'Malos']\n",
    "else:   \n",
    "    target_names = ['A', 'B+', 'B', 'B-','C']\n",
    "print(classification_report(y_test_def2, y_pred2, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('modelos/modelote1203_200')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('idea.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "model.save('modelos\\modelo_perfecto_{}_{}.h5'.format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "\n",
    "existing_file='RESULTADOS_EXCEL\\clasificacion_71_P1P2_def.xlsx'\n",
    "\n",
    "# Verifica si el archivo existe y si está vacío\n",
    "if not os.path.exists(existing_file) or os.path.getsize(existing_file) == 0:\n",
    "    df_inicial=pd.DataFrame(y_test_def2, columns=[\"target\"])\n",
    "    df_inicial.to_excel(existing_file, index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte los arrays a DataFrames\n",
    "df_new = pd.DataFrame(y_pred2, columns=[experimento])\n",
    "# Read existing data\n",
    "df_existing = pd.read_excel(existing_file)\n",
    "# Append new data\n",
    "df_combined=pd.concat([df_existing, df_new], axis=1)\n",
    "\n",
    "# Guarda los DataFrames en archivos Excel\n",
    "df_combined.to_excel(existing_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#este modo de guardar no funciona en esta version de tensorflow\n",
    "#model.save('modelos\\modelo_perfecto_{}_{}'.format(experimento,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "n = len(y_pred2)\n",
    "reshaped = y_pred2[:n//4*4].reshape(-1, 4)\n",
    "mean_values = reshaped.mean(axis=1)\n",
    "\n",
    "mean_values = np.round(mean_values)\n",
    "mean_values = np.clip(mean_values, 0, 4)\n",
    "mean_values = mean_values.astype(int)\n",
    "print(mean_values)\n",
    "\n",
    "mode_values = stats.mode(reshaped, axis=1)[0]\n",
    "print(mode_values)\n",
    "\n",
    "# Convierte los arrays a DataFrames\n",
    "mean_df = pd.DataFrame(mean_values, columns=['mean'])\n",
    "mode_df = pd.DataFrame(mode_values, columns=['mode'])\n",
    "\n",
    "# Guarda los DataFrames en archivos Excel\n",
    "mean_df.to_excel(\"excels_borrar\\clasificacion_P1P2_mean_best7.xlsx\", index=False)\n",
    "mode_df.to_excel(\"excels_borrar\\clasificacion_P1_mode_best7.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename5 = \"COPIA_PANDAS\\hdf_28_06_atunes_agilent_clasificados_220_puntos.hdf\"\n",
    "with pd.HDFStore(filename5,complib=\"zlib\",complevel=4) as hdf_db:\n",
    "    pre_p_e2  = hdf_db.get('data/pollos_estado')\n",
    "    pre_p_e2 = pre_p_e2.loc[pre_p_e2['Pollo'] != 0]\n",
    "    pre_p_e2 =pre_p_e2.drop_duplicates(subset = ['Pollo', 'Medida'],  keep = 'last').reset_index(drop = True)\n",
    "    t    = hdf_db.get('data/tabla')\n",
    "    X_test2=np.zeros((pre_p_e2.shape[0],220,8))\n",
    "    y_test2=np.zeros((pre_p_e2.shape[0],1))\n",
    "    x=0\n",
    "    for index, row in pre_p_e2.iterrows():   # El primer registro no se toma en cuenta porque es basura\n",
    "        Primero = int(row['Primero'])\n",
    "        Ultimo  = int(row['Ultimo'])\n",
    "        estado  = int(row['Estado'])\n",
    "        #print(Primero)\n",
    "        #print(Ultimo)\n",
    "        #print(estado)\n",
    "        if numero_clases==2:\n",
    "            if estado == 0 or estado== 1:\n",
    "                target = 0 \n",
    "            else:\n",
    "                target = 1\n",
    "\n",
    "        else:\n",
    "            target=estado\n",
    "        pepito=np.array(t.iloc[Primero:Ultimo+1])\n",
    "        # #print(pepito.shape)\n",
    "        X_test2[x]=pepito[:,3:4]\n",
    "        #print(X_train[x][0:4,:])       \n",
    "        y_test2[x]=target\n",
    "        y_test2_to_categorical = to_categorical(y_test2)\n",
    "        x=x+1\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train_to_categorical.shape)\n",
    "# #print(X_train[0:4,:,:])\n",
    "# #print(X_train[1][0:4][:])\n",
    "# print(y_train[1:20])\n",
    "# print(y_train_to_categorical[1:20])\n",
    "# # #Aqui filtrariamos si hay filas que no nos interesan. En este caso dejo pasar todos los casos\n",
    "# print(p_e)\n",
    "# # X_train_filtrado = X_train[2:][:,:]\n",
    "# # y_train_filtrado = y_train[2:]\n",
    "X_test2_filtrado = X_test2\n",
    "#y_train_filtrado = y_train\n",
    "y_test2_filtrado = y_test2_to_categorical\n",
    "\n",
    "print(X_test2_filtrado.shape)\n",
    "print(y_test2_filtrado.shape)\n",
    "# print(X_train_filtrado[0][:,:])\n",
    "# # # Vamos a normalizar o escalar los datos\n",
    "# concatenamos train y test\n",
    "#X_total=np.concatenate((X_train_filtrado,X_test_filtrado),axis=0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#data_2d_test = X_total.reshape(-1, X_total.shape[-1])\n",
    "data_2d_test = X_test2_filtrado.reshape(-1, X_test2_filtrado.shape[-1])\n",
    "normalized_data_2d_test = scaler.transform(data_2d_test)\n",
    "\n",
    "\n",
    "X_test2_def=normalized_data_2d_test.reshape(X_test2_filtrado.shape) \n",
    "# la alternativa es normalizar con el total\n",
    "# X_test_def=normalized_data_2d_test.reshape(X_test_filtrado.shape) \n",
    "\n",
    "y_test2_def=y_test2_filtrado # los valores ya estaban normalizados\n",
    "\n",
    "print(y_test2_def.shape)\n",
    "\n",
    "print(y_test2_filtrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# # Crear un nuevo modelo con la misma arquitectura\n",
    "# best_val_model = create_model()  # Reemplaza esto con la función que usaste para crear el modelo original\n",
    "\n",
    "# # Cargar los mejores pesos\n",
    "# best_val_model.load_weights('best_weights.h5')\n",
    "\n",
    "y_pred = model.predict(X_test2_def)\n",
    "#y_pred2 = scaler_out.inverse_transform(y_pred) #valor denormalizado\n",
    "\n",
    "#y_pred1=y_pred[:,-1]\n",
    "y_pred2=np.argmax(y_pred,axis=1)\n",
    "n = len(y_pred2)\n",
    "print(n)\n",
    "reshaped = y_pred2[:n//4*4].reshape(-1, 4)\n",
    "mean_values = reshaped.mean(axis=1)\n",
    "\n",
    "mean_values = np.round(mean_values)\n",
    "mean_values = np.clip(mean_values, 0, 4)\n",
    "mean_values = mean_values.astype(int)\n",
    "print(mean_values.shape)\n",
    "\n",
    "mode_values = stats.mode(reshaped, axis=1)[0]\n",
    "print(mode_values.shape)\n",
    "\n",
    "n = len(y_test2_def)\n",
    "y_test2_def2=np.argmax(y_test2_def,axis=1)\n",
    "print(y_test_def2.shape)\n",
    "print(n)\n",
    "reshaped2 = y_test2_def2[:n//4*4].reshape(-1, 4)\n",
    "target_mean_values = reshaped2.mean(axis=1)\n",
    "\n",
    "target_mean_values = np.round(target_mean_values)\n",
    "target_mean_values = np.clip(target_mean_values, 0, 4)\n",
    "target_mean_values = target_mean_values.astype(int)\n",
    "print(target_mean_values.shape)\n",
    "\n",
    "target_mode_values = stats.mode(reshaped2, axis=1)[0]\n",
    "print(target_mode_values.shape)\n",
    "print(reshaped)\n",
    "print(mode_values)\n",
    "print(target_mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs_infra: no_execute\n",
    "if numero_clases==2:\n",
    "    classes = [0, 1]    \n",
    "else:\n",
    "\n",
    "    classes = [0, 1, 2, 3, 4]\n",
    "#classes = [0, 1]\n",
    "cm=confusion_matrix(y_test2_def2, y_pred2,labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm.diagonal()/cm.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if numero_clases==2:\n",
    "    target_names= ['Buenos', 'Malos']\n",
    "else:\n",
    "    target_names= ['A', 'B+', 'B', 'B-','C']\n",
    "print(classification_report(target_mode_values, mode_values, target_names=target_names, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
