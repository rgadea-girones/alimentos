{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple CNN for PETALO\n",
    "\n",
    "Esta red la vamos a utilizar para obtener el radio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/rgadea/anaconda3/envs/tensorflow3/lib/python36.zip', '/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6', '/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/lib-dynload', '', '/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages', '/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/IPython/extensions', '/volumedisk0/home/rgadea/.ipython', '/home/rgadea/lmfit-py/', '/home/rgadea/experimentos/viherbos/']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#np.random.seed(1337)  # for reproducibility\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/rgadea/lmfit-py/\")\n",
    "sys.path.append(\"/home/rgadea/experimentos/viherbos/\")\n",
    "\n",
    "print(sys.path)\n",
    "import json \n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# import seaborn as sns\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D,Conv3D, MaxPooling3D, MaxPooling2D,BatchNormalization\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam, Nadam, RMSprop, SGD\n",
    "from math import floor\n",
    "from lmfit.models import  GaussianModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos introducir los datos de petalo preprocesados en pyhton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conjunto_datos_entradas A shape: (29714, 20, 175)\n",
      "conjunto_datos_entradas B shape: (29714, 20, 175)\n",
      "conjunto_datos_salidas shape: (29714, 3)\n"
     ]
    }
   ],
   "source": [
    "filtro=2\n",
    "if filtro==1:\n",
    "    npzfile = np.load('../conjuntos_datos_nuevos_2020/20_12_2019_comptom_filt.npz')\n",
    "    npzfile.files\n",
    "    conjunto_datos_entradasA=npzfile['arr_0']\n",
    "    conjunto_datos_entradasB=npzfile['arr_1']\n",
    "    conjunto_datos_salidas=npzfile['arr_2']\n",
    "else:\n",
    "    if filtro==2:\n",
    "        npzfile = np.load('../conjuntos_datos_nuevos_2020/26_12_2019_filt4.npz')\n",
    "        npzfile.files\n",
    "        conjunto_datos_entradasA=npzfile['arr_0']\n",
    "        conjunto_datos_entradasB=npzfile['arr_1']\n",
    "        conjunto_datos_salidas=npzfile['arr_2']\n",
    "    else:\n",
    "        npzfile = np.load('../conjuntos_datos_nuevos_2020/11_12_2019.npz')\n",
    "        npzfile.files\n",
    "        entradas_sensorsA1=npzfile['arr_0']\n",
    "        entradas_sensorsB1=npzfile['arr_1']\n",
    "        coordenadas1=npzfile['arr_2']\n",
    "        entradas_sensorsA2=npzfile['arr_3']\n",
    "        entradas_sensorsB2=npzfile['arr_4']\n",
    "        coordenadas2=npzfile['arr_5']\n",
    "        conjunto_datos_entradasA=np.concatenate((entradas_sensorsA1,entradas_sensorsA2),axis=0)\n",
    "        conjunto_datos_entradasB=np.concatenate((entradas_sensorsB1,entradas_sensorsB2),axis=0)\n",
    "        conjunto_datos_salidas=np.concatenate((coordenadas1,coordenadas2),axis=0)\n",
    "\n",
    "\n",
    "print('conjunto_datos_entradas A shape:', conjunto_datos_entradasA.shape)\n",
    "print('conjunto_datos_entradas B shape:', conjunto_datos_entradasB.shape)\n",
    "print('conjunto_datos_salidas shape:', conjunto_datos_salidas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[181.4969897  196.28245542 -35.24111557]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[166.77087194 146.1265914   45.79463196]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[167.5466638  205.84701211  35.1293335 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[165.79331126  62.32125662  10.07481575]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[171.33327257 222.8657208   41.08970642]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[181.72599788 303.94898093 -38.49809265]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[179.40194102 210.62954804 -47.31930542]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[170.1713784  304.84804678  29.31446838]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[165.33451793 342.15883302  55.36669922]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[194.16873989 281.16108326 -64.51516724]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "    idea=np.random.randint(1,conjunto_datos_entradasB.shape[0])\n",
    "    plt.imshow(conjunto_datos_entradasB[idea], cmap='viridis')\n",
    "    plt.show()\n",
    "    print(conjunto_datos_salidas[idea,0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 250\n",
    "nb_classes = 10\n",
    "nb_epoch = 1000\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 20, 43\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (1,2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (2, 4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "muestras=conjunto_datos_entradasA.shape[0]\n",
    "# veamos=idea.reshape(idea.shape[0],175, 20)\n",
    "\n",
    "\n",
    "veamos2A=np.zeros([muestras,20,175])\n",
    "veamos2_3A=np.zeros([muestras,20,525])\n",
    "veamos2B=np.zeros([muestras,20,175])\n",
    "veamos2_3B=np.zeros([muestras,20,525])\n",
    "sector2A=np.zeros([muestras,20,img_cols])\n",
    "sector2B=np.zeros([muestras,20,img_cols])\n",
    "veamos3=np.zeros([muestras,175])\n",
    "# for i in range(idea.shape[0]):\n",
    "for i in range(muestras):\n",
    "    veamos2A[i]=conjunto_datos_entradasA[i]\n",
    "    veamos2B[i]=conjunto_datos_entradasB[i]\n",
    "    veamos3[i]=np.sum(veamos2A[i], axis=0)\n",
    "    indice=np.argmax(veamos3[i], axis=0)\n",
    "    indice_inferior=int(indice-((img_cols-1)/2)+175)\n",
    "    indice_superior=int(indice+((img_cols+1)/2)+175)\n",
    "    veamos2_3A[i]=np.concatenate((veamos2A[i],veamos2A[i],veamos2A[i]),axis=1) \n",
    "    veamos2_3B[i]=np.concatenate((veamos2B[i],veamos2B[i],veamos2B[i]),axis=1) \n",
    "    sector2A[i]=veamos2_3A[i,:,indice_inferior:indice_superior]\n",
    "    sector2B[i]=veamos2_3B[i,:,indice_inferior:indice_superior]      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data augmentation mediante flip horizontal y vertical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atencion: la z es copiada pero en realidad es incorrecta. Podemos asegurar que el radio y phi si que son las mismas; pero la z claramente al hacer un flip vertical no puede ser la misma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "veamosA=np.zeros([4*muestras,20,img_cols])\n",
    "veamosB=np.zeros([4*muestras,20,img_cols])\n",
    "conjunto_datos_salidas_nuevo=np.zeros([4*muestras,3])\n",
    "for i in range(muestras):\n",
    "    veamosA[i*4]=sector2A[i]  \n",
    "    caramba=np.flipud(sector2A[i]) \n",
    "    veamosA[i*4+1]=caramba  \n",
    "    veamosA[i*4+2]=np.fliplr(caramba)     \n",
    "    veamosA[i*4+3]=np.fliplr(sector2A[i])     \n",
    "    veamosB[i*4]=sector2B[i]   \n",
    "    caramba=np.flipud(sector2B[i]) \n",
    "    veamosB[i*4+1]=caramba   \n",
    "    veamosB[i*4+2]=np.fliplr(caramba)  \n",
    "    veamosB[i*4+3]=np.fliplr(sector2B[i])\n",
    "    conjunto_datos_salidas_nuevo[i*4]=conjunto_datos_salidas[i]\n",
    "    conjunto_datos_salidas_nuevo[i*4+1]=conjunto_datos_salidas[i]    \n",
    "    conjunto_datos_salidas_nuevo[i*4+2]=conjunto_datos_salidas[i]  \n",
    "    conjunto_datos_salidas_nuevo[i*4+3]=conjunto_datos_salidas[i]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sector A shape: (118856, 20, 43)\n",
      "conjunto_datos_nuevo A: (118856, 860)\n",
      "sector B shape: (118856, 20, 43)\n",
      "conjunto_datos_nuevo B: (118856, 860)\n",
      "conjunto_datos_salidas_nuevo: (118856, 3)\n"
     ]
    }
   ],
   "source": [
    "print('sector A shape:', veamosA.shape)\n",
    "conjunto_datos_nuevoA=veamosA.reshape(veamosA.shape[0], img_rows*img_cols)\n",
    "print('conjunto_datos_nuevo A:', conjunto_datos_nuevoA.shape)\n",
    "\n",
    "print('sector B shape:', veamosB.shape)\n",
    "conjunto_datos_nuevoB=veamosB.reshape(veamosB.shape[0], img_rows*img_cols)\n",
    "print('conjunto_datos_nuevo B:', conjunto_datos_nuevoB.shape)\n",
    "print('conjunto_datos_salidas_nuevo:', conjunto_datos_salidas_nuevo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 5  # how many digits we will display\n",
    "\n",
    "fig = plt.figure(figsize=(8,20))\n",
    "\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ideas=np.random.randint(1,muestras)\n",
    "    ax = fig.add_subplot(n, 2, (i)*2+1)\n",
    "    plt.imshow(sector2A[ideas], cmap='viridis')\n",
    "    plt.viridis()\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = fig.add_subplot(n, 2, (i)*2+2)\n",
    "    plt.imshow(sector2B[ideas], cmap='viridis')\n",
    "    plt.viridis()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# print(x_test[idea])\n",
    "# print(decoded_imgs[idea])\n",
    "# print(decoded_imgs_scaled[idea])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "#Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "#Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "for i in range(1,5):\n",
    "    idea=np.random.randint(1,sector2B.shape[0])\n",
    "    plt.imshow(sector2B[idea], cmap='viridis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71313\n",
      "23771\n",
      "23772\n",
      "(10668, 1720)\n",
      "(5748, 1720)\n",
      "(4372, 1720)\n",
      "(2048, 1720)\n",
      "(936, 1720)\n"
     ]
    }
   ],
   "source": [
    "numero_muestras=4*muestras\n",
    "tr_size=60\n",
    "val_size=20\n",
    "test_size=100-val_size-tr_size\n",
    "conjunto_datos_nuevo2=np.concatenate((conjunto_datos_salidas_nuevo,conjunto_datos_nuevoB, conjunto_datos_nuevoA), axis=1)\n",
    "\n",
    "tamanyo_tr=floor(tr_size*numero_muestras/100)\n",
    "tamanyo_val=floor(val_size*numero_muestras/100)\n",
    "tamanyo_test=numero_muestras-tamanyo_tr-tamanyo_val\n",
    "print(tamanyo_tr)\n",
    "print(tamanyo_val)\n",
    "print(tamanyo_test)\n",
    "\n",
    "\n",
    "XY_test=conjunto_datos_nuevo2[tamanyo_tr+tamanyo_val:numero_muestras,:]\n",
    "\n",
    "\n",
    "XY_test_bin0=XY_test[np.where((XY_test[:,0]>=164.9999) * (XY_test[:,0]<171.000))]\n",
    "XY_test_bin1=XY_test[np.where((XY_test[:,0]>=171.000) * (XY_test[:,0]<177.000))]\n",
    "XY_test_bin2=XY_test[np.where((XY_test[:,0]>=177.000) * (XY_test[:,0]<183.0000))]\n",
    "XY_test_bin3=XY_test[np.where((XY_test[:,0]>=183.000) * (XY_test[:,0]<189.0000))]\n",
    "XY_test_bin4=XY_test[np.where((XY_test[:,0]>=189.0000))]\n",
    "\n",
    "X_train=conjunto_datos_nuevo2[:tamanyo_tr,3:]\n",
    "X_val=conjunto_datos_nuevo2[tamanyo_tr:tamanyo_tr+tamanyo_val,3:]\n",
    "X_test=conjunto_datos_nuevo2[tamanyo_tr+tamanyo_val:numero_muestras,3:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_test_bin0=XY_test_bin0[:,3:]\n",
    "Y_test_bin0=XY_test_bin0[:,0]\n",
    "print(X_test_bin0.shape)\n",
    "X_test_bin1=XY_test_bin1[:,3:]\n",
    "Y_test_bin1=XY_test_bin1[:,0]\n",
    "print(X_test_bin1.shape)\n",
    "X_test_bin2=XY_test_bin2[:,3:]\n",
    "Y_test_bin2=XY_test_bin2[:,0]\n",
    "print(X_test_bin2.shape)\n",
    "X_test_bin3=XY_test_bin3[:,3:]\n",
    "Y_test_bin3=XY_test_bin3[:,0]\n",
    "print(X_test_bin3.shape)\n",
    "X_test_bin4=XY_test_bin4[:,3:]\n",
    "Y_test_bin4=XY_test_bin4[:,0]\n",
    "print(X_test_bin4.shape)\n",
    "\n",
    "Y_train=conjunto_datos_nuevo2[:tamanyo_tr,0] #elijo la coordenada radius\n",
    "Y_val=conjunto_datos_nuevo2[tamanyo_tr:tamanyo_tr+tamanyo_val,0] #elijo la corrdenada radius\n",
    "Y_test=conjunto_datos_nuevo2[tamanyo_tr+tamanyo_val:numero_muestras,0] #elijo la corrdenada radius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a normalizar las salidas por si luego nos interea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_total=conjunto_datos_nuevo2[:numero_muestras,0]\n",
    "min_max_scaler = preprocessing.MinMaxScaler().fit(Y_total.reshape(-1, 1))\n",
    "\n",
    "Y_train_scaled = min_max_scaler.transform(Y_train.reshape(-1, 1))\n",
    "Y_val_scaled = min_max_scaler.transform(Y_val.reshape(-1, 1))\n",
    "Y_test_scaled = min_max_scaler.transform(Y_test.reshape(-1, 1))\n",
    "\n",
    "Y_test_bin4_scaled=min_max_scaler.transform(Y_test_bin4.reshape(-1, 1))\n",
    "Y_test_bin3_scaled=min_max_scaler.transform(Y_test_bin3.reshape(-1, 1))\n",
    "Y_test_bin2_scaled=min_max_scaler.transform(Y_test_bin2.reshape(-1, 1))\n",
    "Y_test_bin1_scaled=min_max_scaler.transform(Y_test_bin1.reshape(-1, 1))\n",
    "Y_test_bin0_scaled=min_max_scaler.transform(Y_test_bin0.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],2, img_rows, img_cols,1)\n",
    "X_val = X_val.reshape(X_val.shape[0], 2, img_rows, img_cols,1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 2,img_rows, img_cols,1)\n",
    "\n",
    "X_test_bin0 = X_test_bin0.reshape(X_test_bin0.shape[0], 2, img_rows, img_cols,1)\n",
    "X_test_bin1 = X_test_bin1.reshape(X_test_bin1.shape[0], 2, img_rows, img_cols,1)\n",
    "X_test_bin2 = X_test_bin2.reshape(X_test_bin2.shape[0], 2, img_rows, img_cols,1)\n",
    "X_test_bin3 = X_test_bin3.reshape(X_test_bin3.shape[0], 2, img_rows, img_cols,1)\n",
    "X_test_bin4 = X_test_bin4.reshape(X_test_bin4.shape[0], 2, img_rows, img_cols,1)\n",
    "\n",
    "input_shape = (2, img_rows, img_cols,1)\n",
    "#input_shape=input_shape.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (71313, 2, 20, 43, 1)\n",
      "71313 train samples\n",
      "23771 validation samples\n",
      "23772 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_val= X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_val.shape[0], 'validation samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                            vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_regularizer = False\n",
    "my_regularizer = None\n",
    "# my_epochs = 50\n",
    "# hidden_size=320\n",
    "features_path = 'simple_autoe_features.pickle'\n",
    "labels_path = 'simple_autoe_labels.pickle'\n",
    "\n",
    "if use_regularizer:\n",
    "    # add a sparsity constraint on the encoded representations\n",
    "    # note use of 10e-5 leads to blurred results\n",
    "    my_regularizer = regularizers.l1(0.00001)\n",
    "    # and a larger number of epochs as the added regularization the model\n",
    "    # is less likely to overfit and can be trained longer\n",
    "    my_epochs = 100\n",
    "    features_path = 'sparse_autoe_features.pickle'\n",
    "    labels_path = 'sparse_autoe_labels.pickle'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the CNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(16, kernel_size=kernel_size,\n",
    "                        padding='same',\n",
    "                        kernel_regularizer=my_regularizer,\n",
    "                        data_format='channels_last',\n",
    "                        input_shape=(2,img_rows,img_cols,1)))\n",
    "model.add(BatchNormalization(momentum=0.6))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=pool_size))\n",
    "\n",
    "model.add(Conv3D(16, kernel_size,  kernel_regularizer=my_regularizer, padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.6))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=pool_size))\n",
    "\n",
    "model.add(Conv3D(32, kernel_size,  kernel_regularizer=my_regularizer, padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.6))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=pool_size))\n",
    "\n",
    "model.add(Conv3D(32, kernel_size,  kernel_regularizer=my_regularizer, padding='same'))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization(momentum=0.6))\n",
    "\n",
    "model.add(Conv3D(64, kernel_size, kernel_regularizer=my_regularizer, padding='same'))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization(momentum=0.6))\n",
    "\n",
    "model.add(Conv3D(64, kernel_size, kernel_regularizer=my_regularizer, padding='same'))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization(momentum=0.6))\n",
    "\n",
    "model.add(Conv3D(128, kernel_size,kernel_regularizer=my_regularizer, padding='same'))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization(momentum=0.6))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(10))\n",
    "# model.add(Activation('tanh'))\n",
    "model.add(Dense(1,use_bias=True, \n",
    "                kernel_regularizer=my_regularizer             \n",
    "               ))\n",
    "\n",
    "\n",
    "dt = datetime.now().replace(second=0, microsecond=0)\n",
    "experimento=\"CNN_kernel_{}x{}x{}_con_batchnormalization_sector_{}x{}x{}_elu\".format(kernel_size[0],kernel_size[1],kernel_size[2],img_rows,img_cols,1)\n",
    "algoritmo='Nadam'\n",
    "optimizador=Nadam(beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "tensorboard=TensorBoard(log_dir=\"../logs/defs/{}{}{}\".format(experimento,algoritmo,dt))\n",
    "best_model_name='../redes_CNN_R/models_best/CNN_regression_R_{}_{}_{}_{}_{}.h5'.format(nb_epoch,batch_size,experimento,algoritmo,dt)\n",
    "model_check=ModelCheckpoint(best_model_name, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='min', period=1)\n",
    "early_stop=EarlyStopping(monitor='val_loss', min_delta=0, patience=600, verbose=1, mode='auto', baseline=None)\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=optimizador)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a summary of the model parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 2, 20, 43, 16)     528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2, 20, 43, 16)     64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2, 20, 43, 16)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 2, 10, 21, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 2, 10, 21, 16)     8208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 2, 10, 21, 16)     64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2, 10, 21, 16)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 2, 5, 10, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 2, 5, 10, 32)      16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2, 5, 10, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2, 5, 10, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 2, 2, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 2, 2, 5, 32)       32800     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2, 2, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 2, 2, 5, 32)       128       \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 2, 2, 5, 64)       65600     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2, 2, 5, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 2, 2, 5, 64)       256       \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 2, 2, 5, 64)       131136    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 2, 2, 5, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 2, 2, 5, 64)       256       \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 2, 2, 5, 128)      262272    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 2, 2, 5, 128)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 2, 2, 5, 128)      512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 2, 5, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2561      \n",
      "=================================================================\n",
      "Total params: 520,929\n",
      "Trainable params: 520,225\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now train the model and evaluate on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 71313 samples, validate on 23771 samples\n",
      "Epoch 1/1000\n",
      "71313/71313 [==============================] - 17s 231us/step - loss: 779.4843 - val_loss: 11.3538\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 11.35380, saving model to ../redes_CNN_R/models_best/CNN_regression_R_1000_250_CNN_kernel_2x4x4_con_batchnormalization_sector_20x43x1_elu_Nadam_2019-12-31 11:57:00.h5\n",
      "Epoch 2/1000\n",
      "71313/71313 [==============================] - 10s 143us/step - loss: 11.0026 - val_loss: 8.3209\n",
      "\n",
      "Epoch 00002: val_loss improved from 11.35380 to 8.32090, saving model to ../redes_CNN_R/models_best/CNN_regression_R_1000_250_CNN_kernel_2x4x4_con_batchnormalization_sector_20x43x1_elu_Nadam_2019-12-31 11:57:00.h5\n",
      "Epoch 3/1000\n",
      "71313/71313 [==============================] - 10s 146us/step - loss: 10.3868 - val_loss: 6.8416\n",
      "\n",
      "Epoch 00003: val_loss improved from 8.32090 to 6.84158, saving model to ../redes_CNN_R/models_best/CNN_regression_R_1000_250_CNN_kernel_2x4x4_con_batchnormalization_sector_20x43x1_elu_Nadam_2019-12-31 11:57:00.h5\n",
      "Epoch 4/1000\n",
      "71313/71313 [==============================] - 10s 147us/step - loss: 9.9362 - val_loss: 8.9167\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 6.84158\n",
      "Epoch 5/1000\n",
      "71313/71313 [==============================] - 10s 144us/step - loss: 9.7825 - val_loss: 8.8171\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 6.84158\n",
      "Epoch 6/1000\n",
      "71313/71313 [==============================] - 10s 145us/step - loss: 9.5257 - val_loss: 6.4873\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.84158 to 6.48729, saving model to ../redes_CNN_R/models_best/CNN_regression_R_1000_250_CNN_kernel_2x4x4_con_batchnormalization_sector_20x43x1_elu_Nadam_2019-12-31 11:57:00.h5\n",
      "Epoch 7/1000\n",
      "71313/71313 [==============================] - 10s 143us/step - loss: 9.3647 - val_loss: 9.3577\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 6.48729\n",
      "Epoch 8/1000\n",
      "71313/71313 [==============================] - 10s 142us/step - loss: 9.3035 - val_loss: 9.4951\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 6.48729\n",
      "Epoch 9/1000\n",
      "71313/71313 [==============================] - 10s 143us/step - loss: 9.1083 - val_loss: 10.5939\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 6.48729\n",
      "Epoch 10/1000\n",
      "71313/71313 [==============================] - 10s 142us/step - loss: 9.0346 - val_loss: 6.8423\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.48729\n",
      "Epoch 11/1000\n",
      "71313/71313 [==============================] - 10s 143us/step - loss: 8.9806 - val_loss: 5.4316\n",
      "\n",
      "Epoch 00011: val_loss improved from 6.48729 to 5.43157, saving model to ../redes_CNN_R/models_best/CNN_regression_R_1000_250_CNN_kernel_2x4x4_con_batchnormalization_sector_20x43x1_elu_Nadam_2019-12-31 11:57:00.h5\n",
      "Epoch 12/1000\n",
      "71313/71313 [==============================] - 10s 141us/step - loss: 8.7963 - val_loss: 12.2358\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 5.43157\n",
      "Epoch 13/1000\n",
      "71313/71313 [==============================] - 10s 140us/step - loss: 8.8417 - val_loss: 6.2948\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 5.43157\n",
      "Epoch 14/1000\n",
      "71313/71313 [==============================] - 10s 140us/step - loss: 8.9630 - val_loss: 5.8819\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 5.43157\n",
      "Epoch 15/1000\n",
      "71313/71313 [==============================] - 10s 138us/step - loss: 8.8111 - val_loss: 7.4775\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 5.43157\n",
      "Epoch 16/1000\n",
      "71313/71313 [==============================] - 10s 139us/step - loss: 8.8968 - val_loss: 20.3904\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 5.43157\n",
      "Epoch 17/1000\n",
      "71313/71313 [==============================] - 10s 142us/step - loss: 8.8018 - val_loss: 5.8269\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 5.43157\n",
      "Epoch 18/1000\n",
      "71313/71313 [==============================] - 10s 141us/step - loss: 8.7607 - val_loss: 5.3785\n",
      "\n",
      "Epoch 00018: val_loss improved from 5.43157 to 5.37851, saving model to ../redes_CNN_R/models_best/CNN_regression_R_1000_250_CNN_kernel_2x4x4_con_batchnormalization_sector_20x43x1_elu_Nadam_2019-12-31 11:57:00.h5\n",
      "Epoch 19/1000\n",
      "71313/71313 [==============================] - 10s 142us/step - loss: 8.8083 - val_loss: 11.3232\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 5.37851\n",
      "Epoch 20/1000\n",
      "71313/71313 [==============================] - 10s 139us/step - loss: 8.5365 - val_loss: 13.0939\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 5.37851\n",
      "Epoch 21/1000\n",
      "71313/71313 [==============================] - 10s 147us/step - loss: 8.8041 - val_loss: 5.6688\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 5.37851\n",
      "Epoch 22/1000\n",
      "71313/71313 [==============================] - 10s 136us/step - loss: 8.5384 - val_loss: 11.8570\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 5.37851\n",
      "Epoch 23/1000\n",
      "71313/71313 [==============================] - 10s 142us/step - loss: 8.5222 - val_loss: 12.3156\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 5.37851\n",
      "Epoch 24/1000\n",
      "71313/71313 [==============================] - 10s 134us/step - loss: 8.3387 - val_loss: 9.5125\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 5.37851\n",
      "Epoch 25/1000\n",
      "71313/71313 [==============================] - 10s 135us/step - loss: 8.3242 - val_loss: 6.5579\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 5.37851\n",
      "Epoch 26/1000\n",
      "71313/71313 [==============================] - 9s 132us/step - loss: 8.2466 - val_loss: 6.1711\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 5.37851\n",
      "Epoch 27/1000\n",
      "71313/71313 [==============================] - 9s 133us/step - loss: 8.1543 - val_loss: 7.4394\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 5.37851\n",
      "Epoch 28/1000\n",
      "71313/71313 [==============================] - 10s 136us/step - loss: 8.2644 - val_loss: 6.5421\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 5.37851\n",
      "Epoch 29/1000\n",
      "71313/71313 [==============================] - 10s 134us/step - loss: 8.0029 - val_loss: 20.5412\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 5.37851\n",
      "Epoch 30/1000\n",
      "71313/71313 [==============================] - 9s 132us/step - loss: 7.8017 - val_loss: 7.1698\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 5.37851\n",
      "Epoch 31/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 7.8544 - val_loss: 5.2215\n",
      "\n",
      "Epoch 00031: val_loss improved from 5.37851 to 5.22153, saving model to ../redes_CNN_R/models_best/CNN_regression_R_1000_250_CNN_kernel_2x4x4_con_batchnormalization_sector_20x43x1_elu_Nadam_2019-12-31 11:57:00.h5\n",
      "Epoch 32/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 7.6073 - val_loss: 8.3675\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 5.22153\n",
      "Epoch 33/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 7.7042 - val_loss: 16.5674\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 5.22153\n",
      "Epoch 34/1000\n",
      "71313/71313 [==============================] - 10s 135us/step - loss: 7.6259 - val_loss: 5.8141\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 5.22153\n",
      "Epoch 35/1000\n",
      "71313/71313 [==============================] - 10s 138us/step - loss: 7.5848 - val_loss: 17.0021\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 5.22153\n",
      "Epoch 36/1000\n",
      "71313/71313 [==============================] - 9s 133us/step - loss: 7.3454 - val_loss: 5.3342\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 5.22153\n",
      "Epoch 37/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 7.3624 - val_loss: 5.3565\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 5.22153\n",
      "Epoch 38/1000\n",
      "71313/71313 [==============================] - 9s 133us/step - loss: 7.3461 - val_loss: 20.4584\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 5.22153\n",
      "Epoch 39/1000\n",
      "71313/71313 [==============================] - 9s 132us/step - loss: 7.2026 - val_loss: 5.8844\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 5.22153\n",
      "Epoch 40/1000\n",
      "71313/71313 [==============================] - 10s 139us/step - loss: 7.1294 - val_loss: 5.8578\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 5.22153\n",
      "Epoch 41/1000\n",
      "71313/71313 [==============================] - 10s 136us/step - loss: 7.0273 - val_loss: 5.5432\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 5.22153\n",
      "Epoch 42/1000\n",
      "71313/71313 [==============================] - 10s 134us/step - loss: 6.9166 - val_loss: 5.1592\n",
      "\n",
      "Epoch 00042: val_loss improved from 5.22153 to 5.15921, saving model to ../redes_CNN_R/models_best/CNN_regression_R_1000_250_CNN_kernel_2x4x4_con_batchnormalization_sector_20x43x1_elu_Nadam_2019-12-31 11:57:00.h5\n",
      "Epoch 43/1000\n",
      "71313/71313 [==============================] - 10s 135us/step - loss: 6.8505 - val_loss: 5.8620\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 5.15921\n",
      "Epoch 44/1000\n",
      "71313/71313 [==============================] - 10s 135us/step - loss: 6.6833 - val_loss: 6.1672\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 5.15921\n",
      "Epoch 45/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 6.9050 - val_loss: 5.5553\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 5.15921\n",
      "Epoch 46/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 6.6179 - val_loss: 9.1180\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 5.15921\n",
      "Epoch 47/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 6.6092 - val_loss: 6.3244\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 5.15921\n",
      "Epoch 48/1000\n",
      "71313/71313 [==============================] - 9s 132us/step - loss: 6.5326 - val_loss: 5.5041\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 5.15921\n",
      "Epoch 49/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 6.5124 - val_loss: 5.4801\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 5.15921\n",
      "Epoch 50/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 6.4532 - val_loss: 7.2614\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 5.15921\n",
      "Epoch 51/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 6.3503 - val_loss: 5.2351\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 5.15921\n",
      "Epoch 52/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 6.2898 - val_loss: 5.6371\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 5.15921\n",
      "Epoch 53/1000\n",
      "71313/71313 [==============================] - 9s 133us/step - loss: 6.2811 - val_loss: 5.4712\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 5.15921\n",
      "Epoch 54/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 6.1830 - val_loss: 8.0907\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 5.15921\n",
      "Epoch 55/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 6.0940 - val_loss: 4.9276\n",
      "\n",
      "Epoch 00055: val_loss improved from 5.15921 to 4.92756, saving model to ../redes_CNN_R/models_best/CNN_regression_R_1000_250_CNN_kernel_2x4x4_con_batchnormalization_sector_20x43x1_elu_Nadam_2019-12-31 11:57:00.h5\n",
      "Epoch 56/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 6.0718 - val_loss: 5.2475\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 4.92756\n",
      "Epoch 57/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 6.0890 - val_loss: 8.0068\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 4.92756\n",
      "Epoch 58/1000\n",
      "71313/71313 [==============================] - 10s 133us/step - loss: 5.9594 - val_loss: 5.7183\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 4.92756\n",
      "Epoch 59/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 6.0198 - val_loss: 5.3041\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 4.92756\n",
      "Epoch 60/1000\n",
      "71313/71313 [==============================] - 9s 133us/step - loss: 6.0052 - val_loss: 6.2999\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 4.92756\n",
      "Epoch 61/1000\n",
      "71313/71313 [==============================] - 10s 137us/step - loss: 5.9095 - val_loss: 5.1258\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 4.92756\n",
      "Epoch 62/1000\n",
      "71313/71313 [==============================] - 10s 134us/step - loss: 5.8225 - val_loss: 6.3386\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 4.92756\n",
      "Epoch 63/1000\n",
      "71313/71313 [==============================] - 10s 134us/step - loss: 5.7490 - val_loss: 12.3287\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 4.92756\n",
      "Epoch 64/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 5.7931 - val_loss: 7.4185\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 4.92756\n",
      "Epoch 65/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 5.7989 - val_loss: 5.2442\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 4.92756\n",
      "Epoch 66/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 5.7094 - val_loss: 6.2011\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 4.92756\n",
      "Epoch 67/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 5.6739 - val_loss: 5.4561\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 4.92756\n",
      "Epoch 68/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 5.6579 - val_loss: 5.7844\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 4.92756\n",
      "Epoch 69/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 5.6241 - val_loss: 5.8130\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 4.92756\n",
      "Epoch 70/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 5.5429 - val_loss: 5.4618\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 4.92756\n",
      "Epoch 71/1000\n",
      "71313/71313 [==============================] - 10s 136us/step - loss: 5.5341 - val_loss: 5.5756\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 4.92756\n",
      "Epoch 72/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 5.6445 - val_loss: 6.8452\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 4.92756\n",
      "Epoch 73/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 5.4144 - val_loss: 5.6155\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 4.92756\n",
      "Epoch 74/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 5.4131 - val_loss: 6.3564\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 4.92756\n",
      "Epoch 75/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 5.5737 - val_loss: 6.2829\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 4.92756\n",
      "Epoch 76/1000\n",
      "71313/71313 [==============================] - 9s 132us/step - loss: 5.3678 - val_loss: 6.3494\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 4.92756\n",
      "Epoch 77/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 5.5009 - val_loss: 5.5192\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 4.92756\n",
      "Epoch 78/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 5.3739 - val_loss: 5.3652\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 4.92756\n",
      "Epoch 79/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 5.3659 - val_loss: 5.9041\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 4.92756\n",
      "Epoch 80/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 5.3558 - val_loss: 5.6140\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 4.92756\n",
      "Epoch 81/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 5.3424 - val_loss: 5.6551\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 4.92756\n",
      "Epoch 82/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 5.2928 - val_loss: 5.9046\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 4.92756\n",
      "Epoch 83/1000\n",
      "71313/71313 [==============================] - 10s 134us/step - loss: 5.2222 - val_loss: 5.7960\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 4.92756\n",
      "Epoch 84/1000\n",
      "71313/71313 [==============================] - 9s 132us/step - loss: 5.2239 - val_loss: 5.7523\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 4.92756\n",
      "Epoch 85/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 5.2600 - val_loss: 6.2020\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 4.92756\n",
      "Epoch 86/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 5.2017 - val_loss: 5.9669\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 4.92756\n",
      "Epoch 87/1000\n",
      "71313/71313 [==============================] - 10s 135us/step - loss: 5.1174 - val_loss: 5.5343\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 4.92756\n",
      "Epoch 88/1000\n",
      "71313/71313 [==============================] - 9s 133us/step - loss: 5.2387 - val_loss: 9.5719\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 4.92756\n",
      "Epoch 89/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 5.2114 - val_loss: 5.7354\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 4.92756\n",
      "Epoch 90/1000\n",
      "71313/71313 [==============================] - 9s 132us/step - loss: 5.1528 - val_loss: 8.7767\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 4.92756\n",
      "Epoch 91/1000\n",
      "71313/71313 [==============================] - 9s 132us/step - loss: 5.0542 - val_loss: 5.2126\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 4.92756\n",
      "Epoch 92/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 5.0401 - val_loss: 6.1876\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 4.92756\n",
      "Epoch 93/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 5.1540 - val_loss: 5.4003\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 4.92756\n",
      "Epoch 94/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 5.1299 - val_loss: 6.2098\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 4.92756\n",
      "Epoch 95/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 5.0498 - val_loss: 5.1821\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 4.92756\n",
      "Epoch 96/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 4.9305 - val_loss: 6.7621\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 4.92756\n",
      "Epoch 97/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 5.2036 - val_loss: 5.6664\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 4.92756\n",
      "Epoch 98/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 4.9877 - val_loss: 6.1561\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 4.92756\n",
      "Epoch 99/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 4.9790 - val_loss: 5.4072\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 4.92756\n",
      "Epoch 100/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 4.9746 - val_loss: 5.6044\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 4.92756\n",
      "Epoch 101/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 4.8573 - val_loss: 6.5473\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 4.92756\n",
      "Epoch 102/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 4.9886 - val_loss: 5.8955\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 4.92756\n",
      "Epoch 103/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 4.9626 - val_loss: 5.9807\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 4.92756\n",
      "Epoch 104/1000\n",
      "71313/71313 [==============================] - 9s 133us/step - loss: 5.0039 - val_loss: 5.8493\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 4.92756\n",
      "Epoch 105/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 4.7785 - val_loss: 6.6884\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 4.92756\n",
      "Epoch 106/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 4.9265 - val_loss: 6.0541\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 4.92756\n",
      "Epoch 107/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 4.9252 - val_loss: 10.2215\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 4.92756\n",
      "Epoch 108/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.8797 - val_loss: 8.6644\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 4.92756\n",
      "Epoch 109/1000\n",
      "71313/71313 [==============================] - 10s 135us/step - loss: 4.8187 - val_loss: 5.5199\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 4.92756\n",
      "Epoch 110/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 4.7924 - val_loss: 8.3100\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 4.92756\n",
      "Epoch 111/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 4.8285 - val_loss: 7.1669\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 4.92756\n",
      "Epoch 112/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 4.7060 - val_loss: 5.5250\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 4.92756\n",
      "Epoch 113/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.8255 - val_loss: 6.2865\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 4.92756\n",
      "Epoch 114/1000\n",
      "71313/71313 [==============================] - 10s 134us/step - loss: 4.7665 - val_loss: 5.8313\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 4.92756\n",
      "Epoch 115/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 4.7775 - val_loss: 8.7020\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 4.92756\n",
      "Epoch 116/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 4.7554 - val_loss: 5.8428\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 4.92756\n",
      "Epoch 117/1000\n",
      "71313/71313 [==============================] - 10s 136us/step - loss: 4.7470 - val_loss: 6.0105\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 4.92756\n",
      "Epoch 118/1000\n",
      "71313/71313 [==============================] - 9s 132us/step - loss: 4.6361 - val_loss: 5.8626\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 4.92756\n",
      "Epoch 119/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 4.6451 - val_loss: 5.9089\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 4.92756\n",
      "Epoch 120/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 4.7379 - val_loss: 5.8231\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 4.92756\n",
      "Epoch 121/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.6523 - val_loss: 6.0286\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 4.92756\n",
      "Epoch 122/1000\n",
      "71313/71313 [==============================] - 9s 133us/step - loss: 4.6423 - val_loss: 7.4565\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 4.92756\n",
      "Epoch 123/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 4.6175 - val_loss: 5.6989\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 4.92756\n",
      "Epoch 124/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 4.6626 - val_loss: 5.8005\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 4.92756\n",
      "Epoch 125/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.5523 - val_loss: 6.2281\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 4.92756\n",
      "Epoch 126/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 4.6012 - val_loss: 5.7113\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 4.92756\n",
      "Epoch 127/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 4.5549 - val_loss: 5.6100\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 4.92756\n",
      "Epoch 128/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 4.5116 - val_loss: 5.6454\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 4.92756\n",
      "Epoch 129/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 4.6565 - val_loss: 6.1481\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 4.92756\n",
      "Epoch 130/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 4.5852 - val_loss: 5.6024\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 4.92756\n",
      "Epoch 131/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 4.5769 - val_loss: 5.9661\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 4.92756\n",
      "Epoch 132/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 4.5231 - val_loss: 6.9224\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 4.92756\n",
      "Epoch 133/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 4.5562 - val_loss: 5.5212\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 4.92756\n",
      "Epoch 134/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 4.4666 - val_loss: 8.0559\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 4.92756\n",
      "Epoch 135/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.5260 - val_loss: 6.4608\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 4.92756\n",
      "Epoch 136/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.4804 - val_loss: 5.7403\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 4.92756\n",
      "Epoch 137/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 4.4448 - val_loss: 5.9770\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 4.92756\n",
      "Epoch 138/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.3993 - val_loss: 5.7019\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 4.92756\n",
      "Epoch 139/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.4659 - val_loss: 6.7396\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 4.92756\n",
      "Epoch 140/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 4.4422 - val_loss: 5.7982\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 4.92756\n",
      "Epoch 141/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.3769 - val_loss: 6.4471\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 4.92756\n",
      "Epoch 142/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 4.4388 - val_loss: 6.5291\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 4.92756\n",
      "Epoch 143/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 4.4391 - val_loss: 5.7347\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 4.92756\n",
      "Epoch 144/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 4.3667 - val_loss: 6.6812\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 4.92756\n",
      "Epoch 145/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 4.3162 - val_loss: 5.7874\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 4.92756\n",
      "Epoch 146/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.3575 - val_loss: 5.6366\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 4.92756\n",
      "Epoch 147/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 4.3332 - val_loss: 6.0858\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 4.92756\n",
      "Epoch 148/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 4.3425 - val_loss: 5.7478\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 4.92756\n",
      "Epoch 149/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.4404 - val_loss: 9.2152\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 4.92756\n",
      "Epoch 150/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 4.3336 - val_loss: 6.4618\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 4.92756\n",
      "Epoch 151/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.2709 - val_loss: 5.9592\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 4.92756\n",
      "Epoch 152/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.3089 - val_loss: 6.2949\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 4.92756\n",
      "Epoch 153/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 4.2931 - val_loss: 6.1210\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 4.92756\n",
      "Epoch 154/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 4.3097 - val_loss: 5.9715\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 4.92756\n",
      "Epoch 155/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.2177 - val_loss: 6.1541\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 4.92756\n",
      "Epoch 156/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 4.2280 - val_loss: 6.6560\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 4.92756\n",
      "Epoch 157/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 4.2454 - val_loss: 6.7343\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 4.92756\n",
      "Epoch 158/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 4.2122 - val_loss: 5.5283\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 4.92756\n",
      "Epoch 159/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 4.2411 - val_loss: 5.9919\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 4.92756\n",
      "Epoch 160/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.2859 - val_loss: 6.2340\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 4.92756\n",
      "Epoch 161/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 4.2546 - val_loss: 6.1350\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 4.92756\n",
      "Epoch 162/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.2510 - val_loss: 7.4918\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 4.92756\n",
      "Epoch 163/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.2049 - val_loss: 5.8357\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 4.92756\n",
      "Epoch 164/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.1583 - val_loss: 8.2149\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 4.92756\n",
      "Epoch 165/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 4.2588 - val_loss: 6.8367\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 4.92756\n",
      "Epoch 166/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 4.1781 - val_loss: 6.4522\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 4.92756\n",
      "Epoch 167/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 4.2114 - val_loss: 6.3961\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 4.92756\n",
      "Epoch 168/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 4.1184 - val_loss: 5.9233\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 4.92756\n",
      "Epoch 169/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 4.1916 - val_loss: 5.5340\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 4.92756\n",
      "Epoch 170/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 4.1300 - val_loss: 7.6451\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 4.92756\n",
      "Epoch 171/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.1612 - val_loss: 5.8415\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 4.92756\n",
      "Epoch 172/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 4.1344 - val_loss: 8.4525\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 4.92756\n",
      "Epoch 173/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.2239 - val_loss: 5.8429\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 4.92756\n",
      "Epoch 174/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.1486 - val_loss: 6.0552\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 4.92756\n",
      "Epoch 175/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 4.1239 - val_loss: 6.0405\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 4.92756\n",
      "Epoch 176/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 4.1227 - val_loss: 6.0001\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 4.92756\n",
      "Epoch 177/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 4.0488 - val_loss: 6.5223\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 4.92756\n",
      "Epoch 178/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 4.1417 - val_loss: 7.9352\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 4.92756\n",
      "Epoch 179/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 4.0649 - val_loss: 6.5386\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 4.92756\n",
      "Epoch 180/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 4.1144 - val_loss: 6.5610\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 4.92756\n",
      "Epoch 181/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.0818 - val_loss: 7.1217\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 4.92756\n",
      "Epoch 182/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.0820 - val_loss: 6.0324\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 4.92756\n",
      "Epoch 183/1000\n",
      "71313/71313 [==============================] - 9s 120us/step - loss: 4.0335 - val_loss: 8.8258\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 4.92756\n",
      "Epoch 184/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 4.0397 - val_loss: 6.5875\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 4.92756\n",
      "Epoch 185/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 4.0558 - val_loss: 5.9736\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 4.92756\n",
      "Epoch 186/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.0747 - val_loss: 7.5653\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 4.92756\n",
      "Epoch 187/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.0194 - val_loss: 6.3795\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 4.92756\n",
      "Epoch 188/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 4.0529 - val_loss: 5.6937\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 4.92756\n",
      "Epoch 189/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 4.0040 - val_loss: 5.9520\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 4.92756\n",
      "Epoch 190/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 4.0752 - val_loss: 5.8537\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 4.92756\n",
      "Epoch 191/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 4.0079 - val_loss: 6.0448\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 4.92756\n",
      "Epoch 192/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 4.0439 - val_loss: 5.7250\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 4.92756\n",
      "Epoch 193/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.9689 - val_loss: 6.2023\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 4.92756\n",
      "Epoch 194/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.0150 - val_loss: 8.1244\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 4.92756\n",
      "Epoch 195/1000\n",
      "71313/71313 [==============================] - 9s 132us/step - loss: 4.0120 - val_loss: 6.5110\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 4.92756\n",
      "Epoch 196/1000\n",
      "71313/71313 [==============================] - 9s 132us/step - loss: 4.0649 - val_loss: 5.9833\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 4.92756\n",
      "Epoch 197/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.9559 - val_loss: 6.0062\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 4.92756\n",
      "Epoch 198/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.9104 - val_loss: 6.0407\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 4.92756\n",
      "Epoch 199/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.9426 - val_loss: 7.5813\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 4.92756\n",
      "Epoch 200/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.9843 - val_loss: 5.7975\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 4.92756\n",
      "Epoch 201/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.9857 - val_loss: 6.0710\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 4.92756\n",
      "Epoch 202/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.9294 - val_loss: 6.3884\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 4.92756\n",
      "Epoch 203/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.9333 - val_loss: 5.8746\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 4.92756\n",
      "Epoch 204/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.9376 - val_loss: 6.1988\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 4.92756\n",
      "Epoch 205/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.9458 - val_loss: 5.7230\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 4.92756\n",
      "Epoch 206/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.9644 - val_loss: 6.2351\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 4.92756\n",
      "Epoch 207/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.9004 - val_loss: 7.1566\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 4.92756\n",
      "Epoch 208/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.8796 - val_loss: 5.9557\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 4.92756\n",
      "Epoch 209/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.9507 - val_loss: 5.7133\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 4.92756\n",
      "Epoch 210/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.9061 - val_loss: 5.9784\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 4.92756\n",
      "Epoch 211/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.9230 - val_loss: 5.8600\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 4.92756\n",
      "Epoch 212/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.9429 - val_loss: 5.8557\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 4.92756\n",
      "Epoch 213/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.9156 - val_loss: 6.5276\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 4.92756\n",
      "Epoch 214/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.8676 - val_loss: 5.9027\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 4.92756\n",
      "Epoch 215/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.9072 - val_loss: 5.7399\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 4.92756\n",
      "Epoch 216/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.8819 - val_loss: 5.8708\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 4.92756\n",
      "Epoch 217/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.8633 - val_loss: 6.1579\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 4.92756\n",
      "Epoch 218/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.8557 - val_loss: 5.8397\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 4.92756\n",
      "Epoch 219/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.8119 - val_loss: 6.1033\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 4.92756\n",
      "Epoch 220/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.8849 - val_loss: 6.5388\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 4.92756\n",
      "Epoch 221/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.8526 - val_loss: 5.5773\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 4.92756\n",
      "Epoch 222/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.8556 - val_loss: 7.0726\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 4.92756\n",
      "Epoch 223/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.8582 - val_loss: 6.2641\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 4.92756\n",
      "Epoch 224/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.8284 - val_loss: 5.6504\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 4.92756\n",
      "Epoch 225/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.8198 - val_loss: 5.7038\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 4.92756\n",
      "Epoch 226/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.8645 - val_loss: 5.9844\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 4.92756\n",
      "Epoch 227/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.8745 - val_loss: 5.7649\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 4.92756\n",
      "Epoch 228/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.7924 - val_loss: 7.4363\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 4.92756\n",
      "Epoch 229/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.8616 - val_loss: 5.9809\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 4.92756\n",
      "Epoch 230/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.8445 - val_loss: 6.1317\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 4.92756\n",
      "Epoch 231/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.8405 - val_loss: 8.0605\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 4.92756\n",
      "Epoch 232/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.7904 - val_loss: 5.7812\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 4.92756\n",
      "Epoch 233/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.7947 - val_loss: 8.2422\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 4.92756\n",
      "Epoch 234/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.7818 - val_loss: 5.7536\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 4.92756\n",
      "Epoch 235/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.8545 - val_loss: 5.6325\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 4.92756\n",
      "Epoch 236/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.7687 - val_loss: 6.5163\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 4.92756\n",
      "Epoch 237/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.8225 - val_loss: 5.6172\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 4.92756\n",
      "Epoch 238/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.7803 - val_loss: 7.6092\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 4.92756\n",
      "Epoch 239/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.8153 - val_loss: 6.6942\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 4.92756\n",
      "Epoch 240/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.8057 - val_loss: 6.0688\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 4.92756\n",
      "Epoch 241/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.7812 - val_loss: 6.2092\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 4.92756\n",
      "Epoch 242/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 3.7351 - val_loss: 5.9080\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 4.92756\n",
      "Epoch 243/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.7920 - val_loss: 5.6638\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 4.92756\n",
      "Epoch 244/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.7849 - val_loss: 6.6153\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 4.92756\n",
      "Epoch 245/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.7459 - val_loss: 6.0759\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 4.92756\n",
      "Epoch 246/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.7877 - val_loss: 5.8143\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 4.92756\n",
      "Epoch 247/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.7603 - val_loss: 5.7988\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 4.92756\n",
      "Epoch 248/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.7567 - val_loss: 6.6292\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 4.92756\n",
      "Epoch 249/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.7274 - val_loss: 6.9891\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 4.92756\n",
      "Epoch 250/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.7527 - val_loss: 7.2732\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 4.92756\n",
      "Epoch 251/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.7567 - val_loss: 5.8758\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 4.92756\n",
      "Epoch 252/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.7653 - val_loss: 5.8473\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 4.92756\n",
      "Epoch 253/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.7323 - val_loss: 6.0794\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 4.92756\n",
      "Epoch 254/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.7769 - val_loss: 5.9562\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 4.92756\n",
      "Epoch 255/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.7525 - val_loss: 5.9018\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 4.92756\n",
      "Epoch 256/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.6881 - val_loss: 5.7633\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 4.92756\n",
      "Epoch 257/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.7213 - val_loss: 7.2703\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 4.92756\n",
      "Epoch 258/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.7307 - val_loss: 6.0768\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 4.92756\n",
      "Epoch 259/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.7570 - val_loss: 6.0701\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 4.92756\n",
      "Epoch 260/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.7164 - val_loss: 6.0394\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 4.92756\n",
      "Epoch 261/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.7278 - val_loss: 5.9540\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 4.92756\n",
      "Epoch 262/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.7084 - val_loss: 6.4655\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 4.92756\n",
      "Epoch 263/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.6974 - val_loss: 5.7296\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 4.92756\n",
      "Epoch 264/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.7114 - val_loss: 7.6350\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 4.92756\n",
      "Epoch 265/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.6773 - val_loss: 5.9160\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 4.92756\n",
      "Epoch 266/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.6806 - val_loss: 5.6544\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 4.92756\n",
      "Epoch 267/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.7111 - val_loss: 9.1000\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 4.92756\n",
      "Epoch 268/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.6904 - val_loss: 6.3713\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 4.92756\n",
      "Epoch 269/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.7383 - val_loss: 5.9761\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 4.92756\n",
      "Epoch 270/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.6815 - val_loss: 6.3643\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 4.92756\n",
      "Epoch 271/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.6659 - val_loss: 6.6175\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 4.92756\n",
      "Epoch 272/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.6597 - val_loss: 5.8006\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 4.92756\n",
      "Epoch 273/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.7036 - val_loss: 6.7094\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 4.92756\n",
      "Epoch 274/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.6534 - val_loss: 5.6075\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 4.92756\n",
      "Epoch 275/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.6260 - val_loss: 5.9797\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 4.92756\n",
      "Epoch 276/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.6672 - val_loss: 6.5852\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 4.92756\n",
      "Epoch 277/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.6366 - val_loss: 6.3084\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 4.92756\n",
      "Epoch 278/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.6444 - val_loss: 6.0626\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 4.92756\n",
      "Epoch 279/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.6702 - val_loss: 6.4668\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 4.92756\n",
      "Epoch 280/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.6425 - val_loss: 7.1602\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 4.92756\n",
      "Epoch 281/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.6486 - val_loss: 6.0498\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 4.92756\n",
      "Epoch 282/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.6442 - val_loss: 5.6449\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 4.92756\n",
      "Epoch 283/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.6576 - val_loss: 5.9355\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 4.92756\n",
      "Epoch 284/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.6514 - val_loss: 6.0035\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 4.92756\n",
      "Epoch 285/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 3.6748 - val_loss: 6.3158\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 4.92756\n",
      "Epoch 286/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.6348 - val_loss: 7.0870\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 4.92756\n",
      "Epoch 287/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.6515 - val_loss: 8.4132\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 4.92756\n",
      "Epoch 288/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.6527 - val_loss: 5.7763\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 4.92756\n",
      "Epoch 289/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.6565 - val_loss: 5.8055\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 4.92756\n",
      "Epoch 290/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.5786 - val_loss: 5.8827\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 4.92756\n",
      "Epoch 291/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.6082 - val_loss: 6.1688\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 4.92756\n",
      "Epoch 292/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.6509 - val_loss: 5.9103\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 4.92756\n",
      "Epoch 293/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.6525 - val_loss: 5.9411\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 4.92756\n",
      "Epoch 294/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.5996 - val_loss: 5.7369\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 4.92756\n",
      "Epoch 295/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.6341 - val_loss: 5.7894\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 4.92756\n",
      "Epoch 296/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.5997 - val_loss: 5.8479\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 4.92756\n",
      "Epoch 297/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.5728 - val_loss: 5.7279\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 4.92756\n",
      "Epoch 298/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.6378 - val_loss: 6.4060\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 4.92756\n",
      "Epoch 299/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.5961 - val_loss: 5.8057\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 4.92756\n",
      "Epoch 300/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.6019 - val_loss: 5.9939\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 4.92756\n",
      "Epoch 301/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.5968 - val_loss: 6.0953\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 4.92756\n",
      "Epoch 302/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.5715 - val_loss: 5.9657\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 4.92756\n",
      "Epoch 303/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.5962 - val_loss: 5.7882\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 4.92756\n",
      "Epoch 304/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.5935 - val_loss: 5.7087\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 4.92756\n",
      "Epoch 305/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.5852 - val_loss: 5.8320\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 4.92756\n",
      "Epoch 306/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.5527 - val_loss: 6.1173\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 4.92756\n",
      "Epoch 307/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.5623 - val_loss: 5.7304\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 4.92756\n",
      "Epoch 308/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.5422 - val_loss: 6.7590\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 4.92756\n",
      "Epoch 309/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.5906 - val_loss: 5.9299\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 4.92756\n",
      "Epoch 310/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.5963 - val_loss: 5.9057\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 4.92756\n",
      "Epoch 311/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.5153 - val_loss: 7.9530\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 4.92756\n",
      "Epoch 312/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.6078 - val_loss: 6.1802\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 4.92756\n",
      "Epoch 313/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.6175 - val_loss: 6.2065\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 4.92756\n",
      "Epoch 314/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.5995 - val_loss: 6.0312\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 4.92756\n",
      "Epoch 315/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.5755 - val_loss: 6.6458\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 4.92756\n",
      "Epoch 316/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.5752 - val_loss: 5.9154\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 4.92756\n",
      "Epoch 317/1000\n",
      "71313/71313 [==============================] - 9s 120us/step - loss: 3.5376 - val_loss: 6.4974\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 4.92756\n",
      "Epoch 318/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.5343 - val_loss: 5.6959\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 4.92756\n",
      "Epoch 319/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.5940 - val_loss: 6.2910\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 4.92756\n",
      "Epoch 320/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.5851 - val_loss: 6.1204\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 4.92756\n",
      "Epoch 321/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.5518 - val_loss: 5.9718\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 4.92756\n",
      "Epoch 322/1000\n",
      "71313/71313 [==============================] - 9s 132us/step - loss: 3.5847 - val_loss: 5.8532\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 4.92756\n",
      "Epoch 323/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.5431 - val_loss: 6.8532\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 4.92756\n",
      "Epoch 324/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.5155 - val_loss: 5.8904\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 4.92756\n",
      "Epoch 325/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.5284 - val_loss: 5.8570\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 4.92756\n",
      "Epoch 326/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.5165 - val_loss: 5.8649\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 4.92756\n",
      "Epoch 327/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 3.5381 - val_loss: 5.7494\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 4.92756\n",
      "Epoch 328/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.5335 - val_loss: 6.0473\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 4.92756\n",
      "Epoch 329/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.4936 - val_loss: 6.4456\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 4.92756\n",
      "Epoch 330/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.5136 - val_loss: 5.9652\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 4.92756\n",
      "Epoch 331/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.5318 - val_loss: 5.7306\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 4.92756\n",
      "Epoch 332/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.5073 - val_loss: 6.1106\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 4.92756\n",
      "Epoch 333/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.4783 - val_loss: 6.0109\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 4.92756\n",
      "Epoch 334/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.4953 - val_loss: 5.9123\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 4.92756\n",
      "Epoch 335/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.5498 - val_loss: 5.9839\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 4.92756\n",
      "Epoch 336/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.4881 - val_loss: 6.5793\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 4.92756\n",
      "Epoch 337/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.4732 - val_loss: 6.4884\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 4.92756\n",
      "Epoch 338/1000\n",
      "71313/71313 [==============================] - 9s 120us/step - loss: 3.5138 - val_loss: 6.0373\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 4.92756\n",
      "Epoch 339/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.4720 - val_loss: 6.3302\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 4.92756\n",
      "Epoch 340/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.4554 - val_loss: 6.6148\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 4.92756\n",
      "Epoch 341/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.4820 - val_loss: 6.1784\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 4.92756\n",
      "Epoch 342/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.4183 - val_loss: 6.6596\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 4.92756\n",
      "Epoch 343/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.4943 - val_loss: 6.6194\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 4.92756\n",
      "Epoch 344/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.4506 - val_loss: 5.9495\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 4.92756\n",
      "Epoch 345/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.4721 - val_loss: 6.6166\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 4.92756\n",
      "Epoch 346/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.5191 - val_loss: 8.3130\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 4.92756\n",
      "Epoch 347/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.4640 - val_loss: 6.4825\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 4.92756\n",
      "Epoch 348/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.4288 - val_loss: 6.3780\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 4.92756\n",
      "Epoch 349/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.4285 - val_loss: 6.0143\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 4.92756\n",
      "Epoch 350/1000\n",
      "71313/71313 [==============================] - 10s 134us/step - loss: 3.4680 - val_loss: 6.3694\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 4.92756\n",
      "Epoch 351/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.4678 - val_loss: 6.9490\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 4.92756\n",
      "Epoch 352/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.4279 - val_loss: 6.1199\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 4.92756\n",
      "Epoch 353/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.4465 - val_loss: 6.1818\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 4.92756\n",
      "Epoch 354/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.4719 - val_loss: 5.8265\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 4.92756\n",
      "Epoch 355/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.4245 - val_loss: 5.8614\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 4.92756\n",
      "Epoch 356/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.4369 - val_loss: 5.9308\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 4.92756\n",
      "Epoch 357/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.4068 - val_loss: 5.9869\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 4.92756\n",
      "Epoch 358/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.4482 - val_loss: 5.8141\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 4.92756\n",
      "Epoch 359/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.4390 - val_loss: 5.7917\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 4.92756\n",
      "Epoch 360/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.4304 - val_loss: 6.0393\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 4.92756\n",
      "Epoch 361/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.4111 - val_loss: 6.7645\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 4.92756\n",
      "Epoch 362/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.4458 - val_loss: 6.1013\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 4.92756\n",
      "Epoch 363/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.4672 - val_loss: 6.2106\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 4.92756\n",
      "Epoch 364/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.4191 - val_loss: 5.7450\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 4.92756\n",
      "Epoch 365/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.4776 - val_loss: 6.0393\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 4.92756\n",
      "Epoch 366/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.4159 - val_loss: 6.3620\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 4.92756\n",
      "Epoch 367/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.4393 - val_loss: 5.8354\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 4.92756\n",
      "Epoch 368/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.4278 - val_loss: 5.6955\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 4.92756\n",
      "Epoch 369/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.4476 - val_loss: 6.4515\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 4.92756\n",
      "Epoch 370/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.4403 - val_loss: 5.9069\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 4.92756\n",
      "Epoch 371/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.4060 - val_loss: 5.8179\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 4.92756\n",
      "Epoch 372/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.4524 - val_loss: 6.4312\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 4.92756\n",
      "Epoch 373/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.4173 - val_loss: 6.2114\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 4.92756\n",
      "Epoch 374/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.4229 - val_loss: 6.1219\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 4.92756\n",
      "Epoch 375/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.4130 - val_loss: 6.3180\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 4.92756\n",
      "Epoch 376/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.3637 - val_loss: 5.7397\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 4.92756\n",
      "Epoch 377/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.3488 - val_loss: 6.0865\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 4.92756\n",
      "Epoch 378/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.4481 - val_loss: 6.1151\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 4.92756\n",
      "Epoch 379/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.4150 - val_loss: 6.0618\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 4.92756\n",
      "Epoch 380/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.4041 - val_loss: 5.9271\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 4.92756\n",
      "Epoch 381/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.4173 - val_loss: 6.1300\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 4.92756\n",
      "Epoch 382/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.3825 - val_loss: 5.8300\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 4.92756\n",
      "Epoch 383/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.3852 - val_loss: 7.5334\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 4.92756\n",
      "Epoch 384/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.4049 - val_loss: 5.8529\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 4.92756\n",
      "Epoch 385/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.3813 - val_loss: 5.7571\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 4.92756\n",
      "Epoch 386/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.3816 - val_loss: 5.8777\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 4.92756\n",
      "Epoch 387/1000\n",
      "71313/71313 [==============================] - 8s 119us/step - loss: 3.3727 - val_loss: 5.8461\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 4.92756\n",
      "Epoch 388/1000\n",
      "71313/71313 [==============================] - 9s 132us/step - loss: 3.4147 - val_loss: 6.0585\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 4.92756\n",
      "Epoch 389/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 3.4137 - val_loss: 6.1594\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 4.92756\n",
      "Epoch 390/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.4303 - val_loss: 6.1264\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 4.92756\n",
      "Epoch 391/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 3.3584 - val_loss: 7.7193\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 4.92756\n",
      "Epoch 392/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.3687 - val_loss: 5.8103\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 4.92756\n",
      "Epoch 393/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.4013 - val_loss: 6.4276\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 4.92756\n",
      "Epoch 394/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.3338 - val_loss: 6.1862\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 4.92756\n",
      "Epoch 395/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.3887 - val_loss: 5.7486\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 4.92756\n",
      "Epoch 396/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 3.3713 - val_loss: 5.7759\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 4.92756\n",
      "Epoch 397/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.3780 - val_loss: 5.6806\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 4.92756\n",
      "Epoch 398/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.3353 - val_loss: 6.2541\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 4.92756\n",
      "Epoch 399/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.3569 - val_loss: 5.9361\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 4.92756\n",
      "Epoch 400/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.3796 - val_loss: 5.8756\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 4.92756\n",
      "Epoch 401/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.3735 - val_loss: 5.8056\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 4.92756\n",
      "Epoch 402/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.3771 - val_loss: 5.7247\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 4.92756\n",
      "Epoch 403/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.3311 - val_loss: 5.8609\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 4.92756\n",
      "Epoch 404/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.3348 - val_loss: 6.0501\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 4.92756\n",
      "Epoch 405/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.3717 - val_loss: 5.8358\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 4.92756\n",
      "Epoch 406/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.3486 - val_loss: 6.0661\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 4.92756\n",
      "Epoch 407/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.3352 - val_loss: 5.9981\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 4.92756\n",
      "Epoch 408/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.3110 - val_loss: 5.9749\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 4.92756\n",
      "Epoch 409/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 3.3801 - val_loss: 6.3411\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 4.92756\n",
      "Epoch 410/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 3.3562 - val_loss: 5.8267\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 4.92756\n",
      "Epoch 411/1000\n",
      "71313/71313 [==============================] - 9s 132us/step - loss: 3.3184 - val_loss: 6.1090\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 4.92756\n",
      "Epoch 412/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.3463 - val_loss: 6.1403\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 4.92756\n",
      "Epoch 413/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.3416 - val_loss: 6.2633\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 4.92756\n",
      "Epoch 414/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.3520 - val_loss: 5.9039\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 4.92756\n",
      "Epoch 415/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.3356 - val_loss: 5.8155\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 4.92756\n",
      "Epoch 416/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.3157 - val_loss: 6.1755\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 4.92756\n",
      "Epoch 417/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.3519 - val_loss: 5.8825\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 4.92756\n",
      "Epoch 418/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 3.3355 - val_loss: 6.3154\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 4.92756\n",
      "Epoch 419/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.3244 - val_loss: 6.4843\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 4.92756\n",
      "Epoch 420/1000\n",
      "71313/71313 [==============================] - 10s 134us/step - loss: 3.3331 - val_loss: 5.9498\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 4.92756\n",
      "Epoch 421/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 3.2924 - val_loss: 6.1336\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 4.92756\n",
      "Epoch 422/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.3508 - val_loss: 5.6452\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 4.92756\n",
      "Epoch 423/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 3.3309 - val_loss: 5.8097\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 4.92756\n",
      "Epoch 424/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.2959 - val_loss: 6.3326\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 4.92756\n",
      "Epoch 425/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.2942 - val_loss: 6.0354\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 4.92756\n",
      "Epoch 426/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.2921 - val_loss: 6.2694\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 4.92756\n",
      "Epoch 427/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.2891 - val_loss: 6.0185\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 4.92756\n",
      "Epoch 428/1000\n",
      "71313/71313 [==============================] - 9s 120us/step - loss: 3.2991 - val_loss: 6.3419\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 4.92756\n",
      "Epoch 429/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.2984 - val_loss: 5.7785\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 4.92756\n",
      "Epoch 430/1000\n",
      "71313/71313 [==============================] - 10s 137us/step - loss: 3.3203 - val_loss: 6.2444\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 4.92756\n",
      "Epoch 431/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.2780 - val_loss: 6.1981\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 4.92756\n",
      "Epoch 432/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.2980 - val_loss: 5.8602\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 4.92756\n",
      "Epoch 433/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.3050 - val_loss: 5.7187\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 4.92756\n",
      "Epoch 434/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.2572 - val_loss: 7.4369\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 4.92756\n",
      "Epoch 435/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.2852 - val_loss: 6.2158\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 4.92756\n",
      "Epoch 436/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.2994 - val_loss: 5.6600\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 4.92756\n",
      "Epoch 437/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.2524 - val_loss: 5.8768\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 4.92756\n",
      "Epoch 438/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.3072 - val_loss: 5.7145\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 4.92756\n",
      "Epoch 439/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 3.2564 - val_loss: 7.3536\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 4.92756\n",
      "Epoch 440/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.2907 - val_loss: 5.7934\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 4.92756\n",
      "Epoch 441/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.2637 - val_loss: 5.8421\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 4.92756\n",
      "Epoch 442/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.2563 - val_loss: 6.6961\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 4.92756\n",
      "Epoch 443/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.2740 - val_loss: 7.5787\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 4.92756\n",
      "Epoch 444/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.2522 - val_loss: 5.9409\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 4.92756\n",
      "Epoch 445/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.2754 - val_loss: 6.4229\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 4.92756\n",
      "Epoch 446/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.2612 - val_loss: 5.9799\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 4.92756\n",
      "Epoch 447/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.3132 - val_loss: 5.8047\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 4.92756\n",
      "Epoch 448/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.2813 - val_loss: 5.8134\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 4.92756\n",
      "Epoch 449/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.2265 - val_loss: 6.4523\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 4.92756\n",
      "Epoch 450/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.3009 - val_loss: 5.8367\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 4.92756\n",
      "Epoch 451/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.2107 - val_loss: 6.2715\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 4.92756\n",
      "Epoch 452/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.2754 - val_loss: 6.1739\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 4.92756\n",
      "Epoch 453/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.2304 - val_loss: 5.8133\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 4.92756\n",
      "Epoch 454/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.2464 - val_loss: 6.0081\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 4.92756\n",
      "Epoch 455/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.2287 - val_loss: 6.2080\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 4.92756\n",
      "Epoch 456/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.2700 - val_loss: 5.9112\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 4.92756\n",
      "Epoch 457/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.2503 - val_loss: 6.2376\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 4.92756\n",
      "Epoch 458/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 3.2739 - val_loss: 6.8549\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 4.92756\n",
      "Epoch 459/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.2359 - val_loss: 5.8329\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 4.92756\n",
      "Epoch 460/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.3053 - val_loss: 6.0012\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 4.92756\n",
      "Epoch 461/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.2444 - val_loss: 6.2974\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 4.92756\n",
      "Epoch 462/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 3.2439 - val_loss: 5.9094\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 4.92756\n",
      "Epoch 463/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 3.2199 - val_loss: 5.8260\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 4.92756\n",
      "Epoch 464/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.2475 - val_loss: 5.9046\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 4.92756\n",
      "Epoch 465/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.2417 - val_loss: 6.0543\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 4.92756\n",
      "Epoch 466/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.2517 - val_loss: 6.0738\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 4.92756\n",
      "Epoch 467/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.2308 - val_loss: 7.3982\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 4.92756\n",
      "Epoch 468/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.2276 - val_loss: 6.2884\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 4.92756\n",
      "Epoch 469/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.2341 - val_loss: 7.9678\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 4.92756\n",
      "Epoch 470/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.2234 - val_loss: 5.7601\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 4.92756\n",
      "Epoch 471/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.2209 - val_loss: 6.1116\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 4.92756\n",
      "Epoch 472/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.2740 - val_loss: 6.5407\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 4.92756\n",
      "Epoch 473/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.2431 - val_loss: 5.6044\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 4.92756\n",
      "Epoch 474/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.2268 - val_loss: 6.1170\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 4.92756\n",
      "Epoch 475/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.2212 - val_loss: 6.0248\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 4.92756\n",
      "Epoch 476/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.2059 - val_loss: 5.8819\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 4.92756\n",
      "Epoch 477/1000\n",
      "71313/71313 [==============================] - 9s 120us/step - loss: 3.2189 - val_loss: 5.8034\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 4.92756\n",
      "Epoch 478/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.2329 - val_loss: 6.9349\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 4.92756\n",
      "Epoch 479/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.2359 - val_loss: 6.8173\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 4.92756\n",
      "Epoch 480/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.2243 - val_loss: 6.1647\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 4.92756\n",
      "Epoch 481/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.1933 - val_loss: 7.8018\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 4.92756\n",
      "Epoch 482/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.1975 - val_loss: 5.9412\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 4.92756\n",
      "Epoch 483/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.2028 - val_loss: 5.9320\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 4.92756\n",
      "Epoch 484/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.2183 - val_loss: 5.9403\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 4.92756\n",
      "Epoch 485/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.2465 - val_loss: 5.8393\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 4.92756\n",
      "Epoch 486/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.1936 - val_loss: 7.0968\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 4.92756\n",
      "Epoch 487/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 3.1794 - val_loss: 5.9174\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 4.92756\n",
      "Epoch 488/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.2487 - val_loss: 6.0554\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 4.92756\n",
      "Epoch 489/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.1711 - val_loss: 6.2452\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 4.92756\n",
      "Epoch 490/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.2534 - val_loss: 6.2020\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 4.92756\n",
      "Epoch 491/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.1741 - val_loss: 6.0156\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 4.92756\n",
      "Epoch 492/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.1979 - val_loss: 6.2403\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 4.92756\n",
      "Epoch 493/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.1973 - val_loss: 5.8343\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 4.92756\n",
      "Epoch 494/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.1988 - val_loss: 7.8645\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 4.92756\n",
      "Epoch 495/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.2122 - val_loss: 5.7804\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 4.92756\n",
      "Epoch 496/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.1795 - val_loss: 5.8541\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 4.92756\n",
      "Epoch 497/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.1756 - val_loss: 5.7883\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 4.92756\n",
      "Epoch 498/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.1490 - val_loss: 5.8398\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 4.92756\n",
      "Epoch 499/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.1771 - val_loss: 5.7474\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 4.92756\n",
      "Epoch 500/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.1599 - val_loss: 5.7442\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 4.92756\n",
      "Epoch 501/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.1662 - val_loss: 7.2763\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 4.92756\n",
      "Epoch 502/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.1723 - val_loss: 6.0166\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 4.92756\n",
      "Epoch 503/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.1856 - val_loss: 5.8657\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 4.92756\n",
      "Epoch 504/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.1391 - val_loss: 6.8824\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 4.92756\n",
      "Epoch 505/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.1739 - val_loss: 5.9724\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 4.92756\n",
      "Epoch 506/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.1963 - val_loss: 6.3582\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 4.92756\n",
      "Epoch 507/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.1545 - val_loss: 6.7556\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 4.92756\n",
      "Epoch 508/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.1627 - val_loss: 6.2790\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 4.92756\n",
      "Epoch 509/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.1572 - val_loss: 5.8756\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 4.92756\n",
      "Epoch 510/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.1647 - val_loss: 5.8061\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 4.92756\n",
      "Epoch 511/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.1796 - val_loss: 5.8023\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 4.92756\n",
      "Epoch 512/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.1391 - val_loss: 5.9657\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 4.92756\n",
      "Epoch 513/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 3.1833 - val_loss: 5.8480\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 4.92756\n",
      "Epoch 514/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.1598 - val_loss: 6.0976\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 4.92756\n",
      "Epoch 515/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.1455 - val_loss: 6.1978\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 4.92756\n",
      "Epoch 516/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.1564 - val_loss: 6.2659\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 4.92756\n",
      "Epoch 517/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.1757 - val_loss: 5.6899\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 4.92756\n",
      "Epoch 518/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.1784 - val_loss: 5.9114\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 4.92756\n",
      "Epoch 519/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.1793 - val_loss: 5.5635\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 4.92756\n",
      "Epoch 520/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.1528 - val_loss: 5.8473\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 4.92756\n",
      "Epoch 521/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.1976 - val_loss: 5.6740\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 4.92756\n",
      "Epoch 522/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.1326 - val_loss: 6.2991\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 4.92756\n",
      "Epoch 523/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.1669 - val_loss: 6.5118\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 4.92756\n",
      "Epoch 524/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.1384 - val_loss: 6.9063\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 4.92756\n",
      "Epoch 525/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.1438 - val_loss: 6.6553\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 4.92756\n",
      "Epoch 526/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.1546 - val_loss: 6.5540\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 4.92756\n",
      "Epoch 527/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.1150 - val_loss: 5.9558\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 4.92756\n",
      "Epoch 528/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.1029 - val_loss: 5.7066\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 4.92756\n",
      "Epoch 529/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.1572 - val_loss: 6.2246\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 4.92756\n",
      "Epoch 530/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.1370 - val_loss: 6.3057\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 4.92756\n",
      "Epoch 531/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.1214 - val_loss: 6.4046\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 4.92756\n",
      "Epoch 532/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.1381 - val_loss: 6.1834\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 4.92756\n",
      "Epoch 533/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.1035 - val_loss: 5.8721\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 4.92756\n",
      "Epoch 534/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.1383 - val_loss: 6.7762\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 4.92756\n",
      "Epoch 535/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.1455 - val_loss: 6.5692\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 4.92756\n",
      "Epoch 536/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.1333 - val_loss: 6.1599\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 4.92756\n",
      "Epoch 537/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.1311 - val_loss: 6.0855\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 4.92756\n",
      "Epoch 538/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.1042 - val_loss: 5.6658\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 4.92756\n",
      "Epoch 539/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 3.1420 - val_loss: 6.4489\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 4.92756\n",
      "Epoch 540/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.1232 - val_loss: 6.7682\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 4.92756\n",
      "Epoch 541/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.1365 - val_loss: 5.8872\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 4.92756\n",
      "Epoch 542/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 3.1346 - val_loss: 6.8791\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 4.92756\n",
      "Epoch 543/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.0786 - val_loss: 5.9341\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 4.92756\n",
      "Epoch 544/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.0882 - val_loss: 5.9627\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 4.92756\n",
      "Epoch 545/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.1234 - val_loss: 5.8420\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 4.92756\n",
      "Epoch 546/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.1275 - val_loss: 6.1915\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 4.92756\n",
      "Epoch 547/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.1008 - val_loss: 5.7493\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 4.92756\n",
      "Epoch 548/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.1474 - val_loss: 6.0107\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 4.92756\n",
      "Epoch 549/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.0678 - val_loss: 5.7763\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 4.92756\n",
      "Epoch 550/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.1036 - val_loss: 6.2790\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 4.92756\n",
      "Epoch 551/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.1194 - val_loss: 6.4438\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 4.92756\n",
      "Epoch 552/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.0914 - val_loss: 5.8923\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 4.92756\n",
      "Epoch 553/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.0989 - val_loss: 6.9481\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 4.92756\n",
      "Epoch 554/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 3.0948 - val_loss: 5.8660\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 4.92756\n",
      "Epoch 555/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.0681 - val_loss: 6.1913\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 4.92756\n",
      "Epoch 556/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.1248 - val_loss: 6.0217\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 4.92756\n",
      "Epoch 557/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.0855 - val_loss: 6.5937\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 4.92756\n",
      "Epoch 558/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.0719 - val_loss: 5.7437\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 4.92756\n",
      "Epoch 559/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.1136 - val_loss: 5.9054\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 4.92756\n",
      "Epoch 560/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.0725 - val_loss: 5.8423\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 4.92756\n",
      "Epoch 561/1000\n",
      "71313/71313 [==============================] - 9s 120us/step - loss: 3.0809 - val_loss: 5.7741\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 4.92756\n",
      "Epoch 562/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.0811 - val_loss: 6.3771\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 4.92756\n",
      "Epoch 563/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.1242 - val_loss: 6.4997\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 4.92756\n",
      "Epoch 564/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.0460 - val_loss: 6.0069\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 4.92756\n",
      "Epoch 565/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.0979 - val_loss: 5.8061\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 4.92756\n",
      "Epoch 566/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.0969 - val_loss: 5.7595\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 4.92756\n",
      "Epoch 567/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.0834 - val_loss: 6.2958\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 4.92756\n",
      "Epoch 568/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.0802 - val_loss: 5.9568\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 4.92756\n",
      "Epoch 569/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.0631 - val_loss: 5.9392\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 4.92756\n",
      "Epoch 570/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.0509 - val_loss: 7.2194\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 4.92756\n",
      "Epoch 571/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.0649 - val_loss: 6.1263\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 4.92756\n",
      "Epoch 572/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.1184 - val_loss: 5.7854\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 4.92756\n",
      "Epoch 573/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.0554 - val_loss: 5.8908\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 4.92756\n",
      "Epoch 574/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.1130 - val_loss: 7.9259\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 4.92756\n",
      "Epoch 575/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.0183 - val_loss: 5.9241\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 4.92756\n",
      "Epoch 576/1000\n",
      "71313/71313 [==============================] - 9s 120us/step - loss: 3.1094 - val_loss: 6.0211\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 4.92756\n",
      "Epoch 577/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.0621 - val_loss: 6.2812\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 4.92756\n",
      "Epoch 578/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.0297 - val_loss: 6.1250\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 4.92756\n",
      "Epoch 579/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.0769 - val_loss: 10.4052\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 4.92756\n",
      "Epoch 580/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.0573 - val_loss: 5.9547\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 4.92756\n",
      "Epoch 581/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.0763 - val_loss: 5.9574\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 4.92756\n",
      "Epoch 582/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.0465 - val_loss: 5.9407\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 4.92756\n",
      "Epoch 583/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.0366 - val_loss: 6.0442\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 4.92756\n",
      "Epoch 584/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.0751 - val_loss: 5.8108\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 4.92756\n",
      "Epoch 585/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.0340 - val_loss: 6.2922\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 4.92756\n",
      "Epoch 586/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.0391 - val_loss: 5.9208\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 4.92756\n",
      "Epoch 587/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.0319 - val_loss: 5.9471\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 4.92756\n",
      "Epoch 588/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.0466 - val_loss: 5.8209\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 4.92756\n",
      "Epoch 589/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.0578 - val_loss: 5.8228\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 4.92756\n",
      "Epoch 590/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.0726 - val_loss: 6.0566\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 4.92756\n",
      "Epoch 591/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.0340 - val_loss: 5.9441\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 4.92756\n",
      "Epoch 592/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.0170 - val_loss: 6.7543\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 4.92756\n",
      "Epoch 593/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.0592 - val_loss: 5.7282\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 4.92756\n",
      "Epoch 594/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.0499 - val_loss: 5.9488\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 4.92756\n",
      "Epoch 595/1000\n",
      "71313/71313 [==============================] - 9s 132us/step - loss: 3.0492 - val_loss: 6.0548\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 4.92756\n",
      "Epoch 596/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.0179 - val_loss: 5.9238\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 4.92756\n",
      "Epoch 597/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.0487 - val_loss: 6.3403\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 4.92756\n",
      "Epoch 598/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.0526 - val_loss: 5.8771\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 4.92756\n",
      "Epoch 599/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.0137 - val_loss: 6.5484\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 4.92756\n",
      "Epoch 600/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 3.0296 - val_loss: 8.0486\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 4.92756\n",
      "Epoch 601/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.0512 - val_loss: 6.0676\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 4.92756\n",
      "Epoch 602/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 2.9944 - val_loss: 5.8228\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 4.92756\n",
      "Epoch 603/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 2.9984 - val_loss: 6.3788\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 4.92756\n",
      "Epoch 604/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.0538 - val_loss: 5.9651\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 4.92756\n",
      "Epoch 605/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 3.0333 - val_loss: 5.8520\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 4.92756\n",
      "Epoch 606/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 3.0202 - val_loss: 7.0084\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 4.92756\n",
      "Epoch 607/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.0254 - val_loss: 5.9350\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 4.92756\n",
      "Epoch 608/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.0111 - val_loss: 5.8211\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 4.92756\n",
      "Epoch 609/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.0096 - val_loss: 6.6057\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 4.92756\n",
      "Epoch 610/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 2.9891 - val_loss: 6.2708\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 4.92756\n",
      "Epoch 611/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.0361 - val_loss: 5.9101\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 4.92756\n",
      "Epoch 612/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.0318 - val_loss: 6.2795\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 4.92756\n",
      "Epoch 613/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.0461 - val_loss: 6.0456\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 4.92756\n",
      "Epoch 614/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.0458 - val_loss: 5.9990\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 4.92756\n",
      "Epoch 615/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 2.9858 - val_loss: 6.6385\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 4.92756\n",
      "Epoch 616/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.0331 - val_loss: 5.7993\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 4.92756\n",
      "Epoch 617/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.0032 - val_loss: 7.0329\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 4.92756\n",
      "Epoch 618/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 2.9915 - val_loss: 5.8074\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 4.92756\n",
      "Epoch 619/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 2.9657 - val_loss: 6.0831\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 4.92756\n",
      "Epoch 620/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.0224 - val_loss: 6.1771\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 4.92756\n",
      "Epoch 621/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.0178 - val_loss: 8.3474\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 4.92756\n",
      "Epoch 622/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.0265 - val_loss: 6.1594\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 4.92756\n",
      "Epoch 623/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 2.9796 - val_loss: 7.1085\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 4.92756\n",
      "Epoch 624/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.0171 - val_loss: 5.8697\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 4.92756\n",
      "Epoch 625/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.0032 - val_loss: 5.9331\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 4.92756\n",
      "Epoch 626/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 2.9985 - val_loss: 6.8411\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 4.92756\n",
      "Epoch 627/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 2.9730 - val_loss: 6.0685\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 4.92756\n",
      "Epoch 628/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 2.9799 - val_loss: 6.3398\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 4.92756\n",
      "Epoch 629/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.0085 - val_loss: 5.8449\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 4.92756\n",
      "Epoch 630/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 2.9750 - val_loss: 5.9107\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 4.92756\n",
      "Epoch 631/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 2.9536 - val_loss: 6.2692\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 4.92756\n",
      "Epoch 632/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.0029 - val_loss: 6.0862\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 4.92756\n",
      "Epoch 633/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.0050 - val_loss: 5.9416\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 4.92756\n",
      "Epoch 634/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 2.9519 - val_loss: 5.8591\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 4.92756\n",
      "Epoch 635/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 2.9876 - val_loss: 6.1360\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 4.92756\n",
      "Epoch 636/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 2.9520 - val_loss: 6.5160\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 4.92756\n",
      "Epoch 637/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 2.9576 - val_loss: 5.7392\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 4.92756\n",
      "Epoch 638/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 2.9922 - val_loss: 7.4550\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 4.92756\n",
      "Epoch 639/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 2.9861 - val_loss: 5.8670\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 4.92756\n",
      "Epoch 640/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 2.9669 - val_loss: 5.9156\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 4.92756\n",
      "Epoch 641/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 2.9604 - val_loss: 6.3940\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 4.92756\n",
      "Epoch 642/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 2.9737 - val_loss: 5.9349\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 4.92756\n",
      "Epoch 643/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 2.9498 - val_loss: 5.8585\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 4.92756\n",
      "Epoch 644/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 2.9687 - val_loss: 5.8612\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 4.92756\n",
      "Epoch 645/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 2.9527 - val_loss: 5.8532\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 4.92756\n",
      "Epoch 646/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 2.9779 - val_loss: 5.8920\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 4.92756\n",
      "Epoch 647/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 2.9509 - val_loss: 6.0473\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 4.92756\n",
      "Epoch 648/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 2.9557 - val_loss: 5.8496\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 4.92756\n",
      "Epoch 649/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 2.9330 - val_loss: 5.9104\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 4.92756\n",
      "Epoch 650/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 2.9376 - val_loss: 5.8575\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 4.92756\n",
      "Epoch 651/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 2.9704 - val_loss: 6.2949\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 4.92756\n",
      "Epoch 652/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 2.9489 - val_loss: 6.1208\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 4.92756\n",
      "Epoch 653/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 2.9975 - val_loss: 5.7482\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 4.92756\n",
      "Epoch 654/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 2.9559 - val_loss: 7.1725\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 4.92756\n",
      "Epoch 655/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 2.9400 - val_loss: 5.8553\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 4.92756\n",
      "Epoch 00655: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch,\n",
    "          verbose=1, validation_data=(X_val, Y_val),\n",
    "                     callbacks=[tensorboard,model_check,early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.now().replace(second=0, microsecond=0)\n",
    "model.save_weights('../redes_CNN_R/defs/CNN_regression_R_{}_{}_{}_{}_{}'.format(nb_epoch,batch_size,experimento,algoritmo,dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test mse: 4.83352470859301\n",
      "[172.38214 172.10904 172.1719  172.04648 172.06471 171.63306 171.57935\n",
      " 171.39624 169.91165 167.29652]\n",
      "[173.03363647 173.03363647 173.03363647 173.03363647 172.59163044\n",
      " 172.59163044 172.59163044 172.59163044 168.20943551 168.20943551]\n",
      "[ 0.65149536  0.92459717  0.86173095  0.9871582   0.52691792  0.9585738\n",
      "  1.01228474  1.19539021 -1.7022161   0.91291147]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 2, 20, 43, 16)     528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2, 20, 43, 16)     64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2, 20, 43, 16)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 2, 10, 21, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 2, 10, 21, 16)     8208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 2, 10, 21, 16)     64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2, 10, 21, 16)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 2, 5, 10, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 2, 5, 10, 32)      16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2, 5, 10, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2, 5, 10, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 2, 2, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 2, 2, 5, 32)       32800     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2, 2, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 2, 2, 5, 32)       128       \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 2, 2, 5, 64)       65600     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2, 2, 5, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 2, 2, 5, 64)       256       \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 2, 2, 5, 64)       131136    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 2, 2, 5, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 2, 2, 5, 64)       256       \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 2, 2, 5, 128)      262272    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 2, 2, 5, 128)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 2, 2, 5, 128)      512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 2, 5, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2561      \n",
      "=================================================================\n",
      "Total params: 520,929\n",
      "Trainable params: 520,225\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# best_model_name='../redes_CNN_R/models_best/CNN_regression_R_1000_250_CNN_kernel_2x4x4_con_batchnormalization_sector_20x41x1_elu_Nadam_2019-12-29 10:55:00.h5'\n",
    "best_model = load_model(best_model_name)\n",
    "\n",
    "# best_model = model\n",
    "score = best_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test mse:', score)\n",
    "# print('Test mae:', score[1])\n",
    "Y_test_predicted=best_model.predict(X_test)\n",
    "print(Y_test_predicted[:10].flatten())\n",
    "print(Y_test[:10])\n",
    "\n",
    "error_prediction=Y_test-Y_test_predicted.flatten()\n",
    "\n",
    "print(error_prediction[:10])\n",
    "\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model error')\n",
    "plt.ylabel('error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(error_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel_launcher.py:1: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,)\n",
      "(401,)\n",
      "[[Model]]\n",
      "    Model(gaussian)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 25\n",
      "    # data points      = 400\n",
      "    # variables        = 3\n",
      "    chi-square         = 262307.836\n",
      "    reduced chi-square = 660.725028\n",
      "    Akaike info crit   = 2600.32380\n",
      "    Bayesian info crit = 2612.29819\n",
      "[[Variables]]\n",
      "    amp:  1231.65011 +/- 9.16049361 (0.74%) (init = 1000)\n",
      "    cen:  0.21490340 +/- 0.00719568 (3.35%) (init = 0)\n",
      "    wid:  1.18484051 +/- 0.01017623 (0.86%) (init = 1)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(amp, wid) = -0.577\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "n, bins, patches = plt.hist(error_prediction, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "plt.title(\"Histogram with 400 bins\")\n",
    "plt.show()\n",
    "x=bins[:400]\n",
    "y=n\n",
    "print(n.shape)\n",
    "print(bins.shape)\n",
    "from numpy import exp, loadtxt, pi, sqrt, log\n",
    "\n",
    "from lmfit import Model\n",
    "def gaussian(x, amp, cen, wid):\n",
    "    \"\"\"1-d gaussian: gaussian(x, amp, cen, wid)\"\"\"\n",
    "    return amp * exp(-((x-cen)/wid)**2 )\n",
    "\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "\n",
    "print(result.fit_report())\n",
    "\n",
    "plt.plot(x, y, 'bo')\n",
    "plt.plot(x, result.init_fit, 'k--')\n",
    "plt.plot(x, result.best_fit, 'r-')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWHM=result.params['wid'].value*2*sqrt(log(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9728888617431213\n"
     ]
    }
   ],
   "source": [
    "print(FWHM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[169.91165]\n",
      " [167.29652]\n",
      " [167.00626]\n",
      " ...\n",
      " [168.45403]\n",
      " [167.553  ]\n",
      " [167.54549]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel_launcher.py:4: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6683277112472095\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_bin0_predicted=best_model.predict(X_test_bin0)\n",
    "print(Y_test_bin0_predicted)\n",
    "error_prediction_bin0=Y_test_bin0-Y_test_bin0_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin0, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin0=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel_launcher.py:4: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1505854193435963\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_bin1_predicted=best_model.predict(X_test_bin1)\n",
    "#print(Y_test_bin1_predicted)\n",
    "error_prediction_bin1=Y_test_bin1-Y_test_bin1_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin1, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin1=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel_launcher.py:4: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9973032021861623\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_bin2_predicted=best_model.predict(X_test_bin2)\n",
    "#print(Y_test_bin2_predicted)\n",
    "error_prediction_bin2=Y_test_bin2-Y_test_bin2_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin2, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin2=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel_launcher.py:4: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6917428599753717\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_bin3_predicted=best_model.predict(X_test_bin3)\n",
    "#print(Y_test_bin3_predicted)\n",
    "error_prediction_bin3=Y_test_bin3-Y_test_bin3_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin3, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin3=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel_launcher.py:4: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "Y_test_bin4_predicted=best_model.predict(X_test_bin4)\n",
    "#print(Y_test_bin4_predicted)\n",
    "error_prediction_bin4=Y_test_bin4-Y_test_bin4_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin4, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin4=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin4)\n",
    "print(FWHM_bin3)\n",
    "print(FWHM_bin2)\n",
    "print(FWHM_bin1)\n",
    "print(FWHM_bin0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos ahora los histogramnas 2d que nos interesan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow3] *",
   "language": "python",
   "name": "conda-env-tensorflow3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "495px",
    "left": "909px",
    "right": "57px",
    "top": "246px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
