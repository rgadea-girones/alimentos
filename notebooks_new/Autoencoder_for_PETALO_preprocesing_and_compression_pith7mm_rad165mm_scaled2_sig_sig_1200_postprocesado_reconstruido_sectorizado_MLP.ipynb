{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple AUTOENCODER for PETALO\n",
    "\n",
    "Esta red la vamos a utilizar para obtener el radio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python36.zip', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/lib-dynload', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/extensions', '/home/rgadea3/.ipython']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#np.random.seed(1337)  # for reproducibility\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append(\"/home/rgadea/lmfit-py/\")\n",
    "import seaborn as sns\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from math import floor\n",
    "from lmfit.models import  GaussianModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos introducir los datos de petalo preprocesados en pyhton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22703, 3518)\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.59627137e-02\n",
      "  0.00000000e+00 3.93321030e-02 2.38600597e-02 1.10366344e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.36198878e-01 0.00000000e+00 2.38486826e-02 0.00000000e+00]\n",
      " [3.78941670e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 7.63966143e-02 2.33010277e-02\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.08729953e-02 1.83366984e-03 3.30588967e-03 6.81750476e-04\n",
      "  2.23696232e-04 3.82469594e-03 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 3.77336234e-01 1.43314585e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.92163807e-01\n",
      "  1.44141331e-01 6.95920408e-01 2.27891177e-01 0.00000000e+00\n",
      "  5.68094969e-01 9.33814764e-01 7.97464848e-01 0.00000000e+00\n",
      "  1.65551257e+00 3.11552691e+00 5.25702763e+00 4.69963837e+00]\n",
      " [3.56102377e-01 4.67843004e-02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 7.36187994e-02 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.41529605e-01 7.15653002e-02 0.00000000e+00]\n",
      " [1.12811126e-01 7.03886926e-01 1.31580794e+00 1.82600713e+00\n",
      "  1.62912667e+00 2.48161149e+00 3.54922920e-01 2.33536935e+00\n",
      "  3.91879416e+00 4.20606518e+00 4.47974920e+00 5.67776442e+00\n",
      "  5.89013052e+00 3.65220499e+00 1.42161191e+00 9.03163493e-01\n",
      "  1.85920215e+00 1.78852463e+00 9.38477039e-01 5.29134154e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.75582379e-01 4.65490967e-01 1.70304567e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.22029868e-02 1.03982471e-01 1.64179653e-02 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.49540648e-02\n",
      "  0.00000000e+00 1.62639134e-02 6.50969371e-02 2.43408233e-02\n",
      "  0.00000000e+00 5.36811277e-02 4.46215644e-02 0.00000000e+00\n",
      "  5.59123755e-02 0.00000000e+00 3.50227952e-03 0.00000000e+00]\n",
      " [2.20938474e-01 1.21085785e-01 3.75263155e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 9.27604735e-02 5.87190613e-02\n",
      "  0.00000000e+00 1.13891080e-01 1.63555443e+00 4.05669355e+00\n",
      "  3.82942724e+00 4.38016891e+00 6.07482290e+00 8.17432880e+00\n",
      "  9.18060017e+00 9.88374233e+00 4.30719805e+00 5.81379533e-01]\n",
      " [8.68651047e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.27615444e-02 2.60892734e-02 1.99821740e-02\n",
      "  0.00000000e+00 0.00000000e+00 3.70956436e-02 1.23187825e-02\n",
      "  0.00000000e+00 6.47932142e-02 1.24582350e-02 0.00000000e+00]\n",
      " [6.67236224e-02 3.23053170e-03 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25096813e-02 2.43978798e-02 1.87236890e-02\n",
      "  0.00000000e+00 0.00000000e+00 2.93837413e-02 3.11511308e-02\n",
      "  5.67313284e-02 3.46782133e-02 2.16378346e-02 3.28162834e-02\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import hdf5storage\n",
    "# datos_matlab = hdf5storage.loadmat('../datos_junio_2019/conjunto_entrenamiento_junio_2019_pitch7mm_rad165mm_29_total.mat')\n",
    "npzfile = np.load('../conjuntos_datos_reconstruidos/fil1_pith7mm_rad165mm_scaled2_sig_sig_1200.npz')\n",
    "npzfile.files\n",
    "\n",
    "conjunto_datos1= npzfile['arr_1']\n",
    "npzfile = np.load('../conjuntos_datos_reconstruidos/fil2_pith7mm_rad165mm_scaled2_sig_sig_1200.npz')\n",
    "npzfile.files\n",
    "\n",
    "conjunto_datos2= npzfile['arr_1']\n",
    "\n",
    "conjunto_datos=np.concatenate((conjunto_datos1,conjunto_datos2), axis=0)\n",
    "print(conjunto_datos.shape)\n",
    "print(conjunto_datos[:10,6:26])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "# aqui no aplicable porque es una regresion\n",
    "# nb_classes = 10 \n",
    "\n",
    "nb_epoch = 2000\n",
    "\n",
    "n_hidden1=50\n",
    "n_hidden2=20\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 20, 31\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22703\n",
      "conjunto_datos shape: (22703, 3518)\n",
      "194.99941139023045\n",
      "sector shape: (22703, 20, 31)\n",
      "conjunto_datos_nuevo: (22703, 620)\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.59627137e-02\n",
      "  0.00000000e+00 3.93321030e-02]\n",
      " [3.78941670e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 7.63966143e-02 2.33010277e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 3.77336234e-01 1.43314585e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.92163807e-01\n",
      "  1.44141331e-01 6.95920408e-01]\n",
      " [3.56102377e-01 4.67843004e-02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 7.36187994e-02 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.12811126e-01 7.03886926e-01 1.31580794e+00 1.82600713e+00\n",
      "  1.62912667e+00 2.48161149e+00 3.54922920e-01 2.33536935e+00\n",
      "  3.91879416e+00 4.20606518e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.75582379e-01 4.65490967e-01 1.70304567e-01\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.22029868e-02 1.03982471e-01 1.64179653e-02 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.49540648e-02\n",
      "  0.00000000e+00 1.62639134e-02]\n",
      " [2.20938474e-01 1.21085785e-01 3.75263155e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 9.27604735e-02 5.87190613e-02\n",
      "  0.00000000e+00 1.13891080e-01]\n",
      " [8.68651047e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.27615444e-02]\n",
      " [6.67236224e-02 3.23053170e-03 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25096813e-02 2.43978798e-02 1.87236890e-02\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "# (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# conjunto_datos=photodefbox2_todo_e\n",
    "numero_muestras=conjunto_datos.shape[0]\n",
    "print(numero_muestras)\n",
    "print('conjunto_datos shape:', conjunto_datos.shape)\n",
    "maxInColumns = np.amax(conjunto_datos, axis=0)\n",
    "print (maxInColumns[1])\n",
    "# n, bins, patches = plt.hist(conjunto_datos[:,1], 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "\n",
    "idea=conjunto_datos[:,6:3506]\n",
    "veamos=idea.reshape(idea.shape[0],175, 20)\n",
    "veamos2=np.zeros([idea.shape[0],20,175])\n",
    "veamos2_3=np.zeros([idea.shape[0],20,525])\n",
    "sector2=np.zeros([idea.shape[0],20,31])\n",
    "veamos3=np.zeros([idea.shape[0],175])\n",
    "# for i in range(idea.shape[0]):\n",
    "for i in range(idea.shape[0]):\n",
    "    veamos2[i]=np.reshape(veamos[i].transpose(), [20,175])\n",
    "    veamos3[i]=np.sum(veamos2[i], axis=0)\n",
    "    indice=np.argmax(veamos3[i], axis=0)\n",
    "    veamos2_3[i]=np.concatenate((veamos2[i],veamos2[i],veamos2[i]),axis=1)   \n",
    "    sector2[i]=veamos2_3[i,:,indice-15+175:indice+16+175]\n",
    "    \n",
    "\n",
    "print('sector shape:', sector2.shape)\n",
    "conjunto_datos_nuevo=sector2.reshape(sector2.shape[0], img_rows*img_cols)\n",
    "print('conjunto_datos_nuevo:', conjunto_datos_nuevo.shape)\n",
    "\n",
    "print(idea[:10,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD6CAYAAACmjCyGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAF2hJREFUeJzt3X2MXNV5x/Hvb9a7Nn6Lbd4xBJIUoSIanMgyiWgrCIECQiGpSGorbUlLZRIFKVGbKjSVQpqqUvqSpGpIIU6wIFUCpCEklmIRrJQKkMKLcQ2YAMGhTlnWsQEbv4DttT1P/9hrabPM2ufMzGV2fH4fydqZO8+ee+7euc9c37nPOYoIzMysHI1ed8DMzN5cTvxmZoVx4jczK4wTv5lZYZz4zcwK48RvZlYYJ34zs8I48ZuZFcaJ38ysMNN63YFWhjQ9ZjCr193oLWXEJhZfq5H+OR/NZvr6ld7ZmHNMcuzBobR2B3ftT25z34LB5Nhzjn8pOXZ7cyA5dvi1+WmBo+l/16Hd6RX4jX0Hk2M5cCA9NmMUgGgmxnpkAZR4fO2J1xiNvUnBUzLxz2AW5zXenxbc6zdGRtLLanYgPZFE4sHZOGZmcpvN119PjtX06cmxo+/9neTYnaenJekT7vt1cpv/+9GTk2Mfufbfk2Pv2j03OfavH7oqKW5gc/rf9ZQH0pP5rF9uT45l6yvpsfvTPySae/YmxcX+0fT1H6UaM2YkxT20d3V6m+12BkDSpZKelbRR0vUtXp8u6c7q9YclndHJ+szMrHNtJ35JA8DXgcuAs4Flks6eEHYNsD0ifgv4KvCP7a7PzMy6o5Mz/iXAxoh4PiJGgTuAKyfEXAncVj3+PnCRUi9YmZlZLTpJ/AuBF8Y9H66WtYyJiAPADuDYVo1JWi5praS1+9nXQbfMzOxwOkn8rc7cJ37TmhIztjBiRUQsjojFg6R/qWVmZnk6SfzDwGnjnp8KjEwWI2ka8BZgWwfrNDOzDnWS+B8FzpT0NklDwFJg1YSYVcDV1eOrgP8KT/llZtZTbd/HHxEHJF0H/AQYAFZGxFOSvgisjYhVwC3Af0jayNiZ/tJudNrMzNrXUQFXRKwGVk9Y9vlxj/cCH+5kHWZm1l1TsnIXqKcit5FYDdvMKGmv6cpVY86c5NjUKtvm3nrulhqYPy85duilPcmxcxPL+rcvOTG5zeZQ+v76yra3J8eePePF5Nh3LEwbCmLjvpOS29w3L73Se2ZGVbiOW5Aeuzu92ruR2IeD21252xxNG5Ik5yq6B2kzMyuME7+ZWWGc+M3MCuPEb2ZWGCd+M7PCOPGbmRXGid/MrDBO/GZmhXHiNzMrjBO/mVlhpu6QDYlyJvqO0cTy79ShHYCBubOTY5U4aTKkT6AOEPt6O3HNgV9vSY4dONhMjh1qnJAUt/fYtEnZAaZvS58A7muPXpgcmzOv3En3pPV3wdz0RmcPp78HdDB9SJL9J6UPHTJtXfr7oLl7d1pgxrGYNdRKP6lhu3zGb2ZWGCd+M7PCOPGbmRXGid/MrDBO/GZmhXHiNzMrTNuJX9Jpku6T9LSkpyR9qkXMBZJ2SFpf/ft8q7bMzOzN08l9/AeAv4qIdZLmAI9JWhMRP58Q90BEXNHBeszMrIvaPuOPiM0Rsa56vAt4GljYrY6ZmVk9ulK5K+kM4F3Awy1efq+kx4ER4DMR8dQkbSwHlgPMYGbyupOrcQGU+DkX6dWlJE4IDhD70yZNBmju2Jnehzomka/JwZfSJhoHGDh+flLcrBf3Jrc5fUdOle9QcmwzvVnmPJ9WtTpvd0Y17rYdybExf25y7OATm5JjD+7alRybSkPpKSrSD6+sY0HTMvqQUXHfSx0nfkmzgbuAT0fExGy1Djg9InZLuhz4IXBmq3YiYgWwAmCuFqRnUzMzy9LRXT2SBhlL+t+JiB9MfD0idkbE7urxamBQ0nGdrNPMzDrTyV09Am4Bno6Ir0wSc1IVh6Ql1fpeaXedZmbWuU4u9ZwP/AnwpKT11bLPAW8FiIibgauAT0g6AOwBlkaEL+OYmfVQ24k/Ih4EDjtubETcCNzY7jrMzKz7XLlrZlYYJ34zs8I48ZuZFcaJ38ysME78ZmaF6fvJ1rMklmkPzE0vaW9mTHSujOEl+qX0u1ab04Z3GIz0msDBZ19Njp05c0ZybMxOH2ZEr6T1oXnSscltsi9j6JKt/VNKkzUkS013imcdizrsjY7jGu3tXe0+4zczK4wTv5lZYZz4zcwK48RvZlYYJ34zs8I48ZuZFcaJ38ysME78ZmaFceI3MyuME7+ZWWH6f8iGjNLnxsy0svqcYRgiJzY5EjQtfdccrcM7NHftSorTnj3JbTbmvSW9AwfShvgA4IXNyaHNxP0VL6cPrZDaJuQNSdLz91bO0AapwyXktpsjtd0e99Vn/GZmhek48UvaJOlJSeslrW3xuiT9m6SNkp6Q9O5O12lmZu3r1qWeCyPi5Uleuww4s/p3HnBT9dPMzHrgzbjUcyXw7RjzEDBP0slvwnrNzKyFbiT+AO6V9Jik5S1eXwi8MO75cLXsN0haLmmtpLX7Sf/C1MzM8nTjUs/5ETEi6QRgjaRnIuL+ca+3+vr6DV9TR8QKYAXAXC3o7SwFZmZHsY7P+CNipPq5FbgbWDIhZBg4bdzzU4GRTtdrZmbt6SjxS5olac6hx8AlwIYJYauAP63u7nkPsCMi0m96NjOzrur0Us+JwN0aK0aYBnw3Iu6R9HGAiLgZWA1cDmwEXgf+rMN1mplZBzpK/BHxPHBui+U3j3scwCc7WY+ZmXVP/w/ZkKG5N/FuoWjW25GULuSUyieWfzdmz05uMnW4hDql/g1y/lbad0xybM7foOdDG2Q4uHNnr7tQD+Vcuc44xrPaTW0yfciGOt5bHrLBzKwwTvxmZoVx4jczK4wTv5lZYZz4zcwK48RvZlYYJ34zs8I48ZuZFcaJ38ysME78ZmaFKWrIBpoHe92DZJqWvmuimTZ9QYyOttud7mkMpMfWsL8Obt/e9TZtatBA+ntLg9OTY+s4brKObw/ZYGZmnXLiNzMrjBO/mVlhnPjNzArjxG9mVhgnfjOzwrSd+CWdJWn9uH87JX16QswFknaMi/l85102M7NOtH0ff0Q8CywCkDQAvAjc3SL0gYi4ot31mJlZd3XrUs9FwC8j4lddas/MzGrSrcrdpcDtk7z2XkmPAyPAZyLiqVZBkpYDywFmMDN5AvEcjelp1XrNvXu7vm7Iq9ZrzJyZHJs6eXbsy6iEzfn7Z0xG3RgaTI5t7u2fSuta9LjKud/Egf3psQfr+XulTqKuWenHN/v2pcWlFfADXTjjlzQEfAD4zxYvrwNOj4hzga8BP5ysnYhYERGLI2LxIOnl1GZmlqcbl3ouA9ZFxJaJL0TEzojYXT1eDQxKOq4L6zQzszZ1I/EvY5LLPJJOksauGUhaUq3vlS6s08zM2tTRNX5JM4GLgWvHLfs4QETcDFwFfELSAWAPsDQiMq5EmZlZt3WU+CPideDYCctuHvf4RuDGTtZhZmbd5cpdM7PCOPGbmRXGid/MrDBO/GZmhXHiNzMrzNSdbD3xrk8NDiU32RxNK+lW4tAOAJFaTk36pOgAzT3pw0akDgWRVaaecddtY3ZG+XkdpfI1DO8BZP0NatFnwzD0egLxrP0VGX/bnKEzEjV3v5YeXMP70Gf8ZmaFceI3MyuME7+ZWWGc+M3MCuPEb2ZWGCd+M7PCOPGbmRXGid/MrDBO/GZmhXHiNzMrzJQcskEDDQZmz00Lzhheobl9e1JcjI4mt1lHOfdYJ5rpoanl7zlDG+RsVzOjr/t7XKqftb/StyurD4n7oXHMMclNNvemDx1S11AQWcMwpO6HnL7mvL9z9ldGHyIS+1DH0CUZfMZvZlaYpMQvaaWkrZI2jFu2QNIaSc9VP+dP8rtXVzHPSbq6Wx03M7P2pJ7x3wpcOmHZ9cBPI+JM4KfV898gaQFwA3AesAS4YbIPCDMze3MkJf6IuB/YNmHxlcBt1ePbgA+2+NU/ANZExLaI2A6s4Y0fIGZm9ibq5MvdEyNiM0BEbJZ0QouYhcAL454PV8veQNJyYDnADM3qoFtmZnY4dX+52+or7pZfp0fEiohYHBGLhxozau6WmVm5Okn8WySdDFD93NoiZhg4bdzzU4GRDtZpZmYd6iTxrwIO3aVzNfCjFjE/AS6RNL/6UveSapmZmfVI6u2ctwM/A86SNCzpGuBLwMWSngMurp4jabGkbwFExDbg74FHq39frJaZmVmPJH25GxHLJnnpohaxa4G/GPd8JbCyrd6ZmVnXTckhGwiIxJLmSByGASCaiWXaSr8CpkZ6mXhOSXtQw1AQOWXqGcMVNF97Lb3Zuoa4SKTBjLd8TWX1qe+D1GNgLDhjeImaaHCo621GzpANWe/vDHUNBdFDHrLBzKwwTvxmZoVx4jczK4wTv5lZYZz4zcwK48RvZlYYJ34zs8I48ZuZFcaJ38ysME78ZmaFmZJDNkSzSfP11xODM0qkU0uvM9qsq1K+cUz6nATNPXsTA6dA+XtOHxI1Zs5MX33q+ypTLcMV7NvX9TaB2oYgiP2j3e9DTl8zaCB96JCsoTNqyDHJw5xkdNNn/GZmhXHiNzMrjBO/mVlhnPjNzArjxG9mVhgnfjOzwhwx8UtaKWmrpA3jlv2zpGckPSHpbknzJvndTZKelLRe0tpudtzMzNqTcsZ/K3DphGVrgHMi4p3AL4C/OczvXxgRiyJicXtdNDOzbjpi4o+I+4FtE5bdGxGHJg59CDi1hr6ZmVkNulG5++fAnZO8FsC9kgL4RkSsmKwRScuB5QAzmJlcWZczgXmyjGrBnApADaVXd+a025gxPSkuq2o1Z1L0Gqpxc9RVjZsjq2o1kaalH55Zx8HROil5xns26++Vs11K/No0q8nE4IxRBDpK/JL+FjgAfGeSkPMjYkTSCcAaSc9U/4N4g+pDYQXA3MaC/piq3sysD7V9V4+kq4ErgI9GtP74joiR6udW4G5gSbvrMzOz7mgr8Uu6FPgs8IGIaPn/bEmzJM059Bi4BNjQKtbMzN48Kbdz3g78DDhL0rCka4AbgTmMXb5ZL+nmKvYUSaurXz0ReFDS48AjwI8j4p5atsLMzJId8Rp/RCxrsfiWSWJHgMurx88D53bUOzMz6zpX7pqZFcaJ38ysME78ZmaFceI3MyuME7+ZWWGm5GTrRMYExzWUU2swo1R+NL1UP/bsSY5NLv2GeoZM6PEwDEA9E1dnaMxIn/A+DqbXy6cO71DLcCR1qmsoiOT1Z4xZkNVuznYl9iFnEvvUzcqZvz091MzMjgZO/GZmhXHiNzMrjBO/mVlhnPjNzArjxG9mVhgnfjOzwjjxm5kVxonfzKwwTvxmZoWZmkM2QHJJs6ZlDK+QWgLfHEhus7Yy9ZgCQyb0WuqwFRl/q5xhGJqj+5NjaxniopHxPsxZf84wJzl6PmRDj9c/VfqQwGf8ZmaFSZlzd6WkrZI2jFv2BUkvVvPtrpd0+SS/e6mkZyVtlHR9NztuZmbtSTnjvxW4tMXyr0bEourf6okvShoAvg5cBpwNLJN0diedNTOzzh0x8UfE/cC2NtpeAmyMiOcjYhS4A7iyjXbMzKyLOrnGf52kJ6pLQfNbvL4QeGHc8+FqWUuSlktaK2ntfvZ10C0zMzucdhP/TcA7gEXAZuDLLWJa3Tow6VfeEbEiIhZHxOJBprfZLTMzO5K2En9EbImIgxHRBL7J2GWdiYaB08Y9PxUYaWd9ZmbWPW0lfkknj3v6IWBDi7BHgTMlvU3SELAUWNXO+szMrHuOWP0k6XbgAuA4ScPADcAFkhYxdulmE3BtFXsK8K2IuDwiDki6DvgJMACsjIinatkKMzNLppiClWZztSDO00VJsXVU7mpwKL3NxImzrQ2plasZVauu3OXordwt3MPxU3bGtqSdO3WHbEiUPAwDJB9IcSDjgLc8OUmnhmTa3Lu3623WJmP7axm6pE51fPjkfPDU9aHaJzxkg5lZYZz4zcwK48RvZlYYJ34zs8I48ZuZFcaJ38ysME78ZmaFceI3MyuME7+ZWWGc+M3MCtP3QzZkSS29ziknzyj9bgwNJsfmlNVPiRL8VB7PJVnWuEL9NBRFjrreL0fhMAw5fMZvZlYYJ34zs8I48ZuZFcaJ38ysME78ZmaFceI3MytMypy7K4ErgK0RcU617E7grCpkHvBqRCxq8bubgF3AQeBARCzuUr/NzKxNKffx3wrcCHz70IKI+KNDjyV9GdhxmN+/MCJebreDZmbWXUdM/BFxv6QzWr0mScBHgPd1t1tmZlaXTit3fw/YEhHPTfJ6APdKCuAbEbFisoYkLQeWA8xgZnoPciZNjmZanDK++sioAGyOpjdbS2VhRkVyY/r05Nijtmo0Q2Nm+ns29idWWg+mV3rTb/sg9RiLjOMgJxfk6HWVb+pxm1Hk3GniXwbcfpjXz4+IEUknAGskPRMR97cKrD4UVgDM1QLX9ZuZ1aTtu3okTQP+ELhzspiIGKl+bgXuBpa0uz4zM+uOTm7nfD/wTEQMt3pR0ixJcw49Bi4BNnSwPjMz64IjJn5JtwM/A86SNCzpmuqlpUy4zCPpFEmrq6cnAg9Kehx4BPhxRNzTva6bmVk7Uu7qWTbJ8o+1WDYCXF49fh44t8P+mZlZl7ly18ysME78ZmaFceI3MyuME7+ZWWGc+M3MCtP/k63XUU6dUyaeI6evOeXnqe1mTFwdBxOHtzAgYxgGgEZaCX5z1642e9NFGcN8ZE2MXsdxm9Nmznb1Wg0TzvuM38ysME78ZmaFceI3MyuME7+ZWWGc+M3MCuPEb2ZWGCd+M7PCOPGbmRXGid/MrDBO/GZmhVHUUA7cKUkvAb+asPg44OUedKdu3q7+4u3qLyVt1+kRcXzKL0/JxN+KpLURsbjX/eg2b1d/8Xb1F29Xa77UY2ZWGCd+M7PC9FPiX9HrDtTE29VfvF39xdvVQt9c4zczs+7opzN+MzPrAid+M7PCTPnEL+lSSc9K2ijp+l73p5skbZL0pKT1ktb2uj/tkrRS0lZJG8YtWyBpjaTnqp/ze9nHdkyyXV+Q9GK1z9ZLuryXfcwl6TRJ90l6WtJTkj5VLe/r/XWY7er3/TVD0iOSHq+26++q5W+T9HC1v+6UNJTV7lS+xi9pAPgFcDEwDDwKLIuIn/e0Y10iaROwOCL6usBE0u8Du4FvR8Q51bJ/ArZFxJeqD+z5EfHZXvYz1yTb9QVgd0T8Sy/71i5JJwMnR8Q6SXOAx4APAh+jj/fXYbbrI/T3/hIwKyJ2SxoEHgQ+Bfwl8IOIuEPSzcDjEXFTartT/Yx/CbAxIp6PiFHgDuDKHvfJJoiI+4FtExZfCdxWPb6NsYOwr0yyXX0tIjZHxLrq8S7gaWAhfb6/DrNdfS3G7K6eDlb/Angf8P1qefb+muqJfyHwwrjnwxwFO3OcAO6V9Jik5b3uTJedGBGbYeygBE7ocX+66TpJT1SXgvrqksh4ks4A3gU8zFG0vyZsF/T5/pI0IGk9sBVYA/wSeDUiDlQh2Xlxqid+tVg2da9N5Ts/It4NXAZ8srq0YFPbTcA7gEXAZuDLve1OeyTNBu4CPh0RO3vdn25psV19v78i4mBELAJOZewqyG+3Cstpc6on/mHgtHHPTwVGetSXrouIkernVuBuxnbq0WJLdd310PXXrT3uT1dExJbqQGwC36QP91l1rfgu4DsR8YNqcd/vr1bbdTTsr0Mi4lXgv4H3APMkTateys6LUz3xPwqcWX2DPQQsBVb1uE9dIWlW9SUUkmYBlwAbDv9bfWUVcHX1+GrgRz3sS9ccSo6VD9Fn+6z6svAW4OmI+Mq4l/p6f022XUfB/jpe0rzq8THA+xn7/uI+4KoqLHt/Tem7egCq26/+FRgAVkbEP/S4S10h6e2MneUDTAO+26/bJul24ALGhordAtwA/BD4HvBW4P+AD0dEX31ROsl2XcDYZYMANgHXHro23g8k/S7wAPAk0KwWf46x6+F9u78Os13L6O/99U7GvrwdYOxE/XsR8cUqf9wBLAD+B/jjiNiX3O5UT/xmZtZdU/1Sj5mZdZkTv5lZYZz4zcwK48RvZlYYJ34zs8I48ZuZFcaJ38ysMP8PtwdXPGlGTwsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "#Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "#Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "for i in range(1,5):\n",
    "    idea=np.random.randint(1,sector2.shape[0])\n",
    "    plt.imshow(sector2[idea], cmap='viridis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13621\n",
      "4540\n",
      "4542\n",
      "(1896, 620)\n",
      "(851, 620)\n",
      "(586, 620)\n",
      "(585, 620)\n",
      "(624, 620)\n"
     ]
    }
   ],
   "source": [
    "tr_size=60\n",
    "val_size=20\n",
    "test_size=100-val_size-tr_size\n",
    "conjunto_datos_nuevo2=np.concatenate((conjunto_datos[:,0:3],conjunto_datos_nuevo), axis=1)\n",
    "tamanyo_tr=floor(tr_size*numero_muestras/100)\n",
    "tamanyo_val=floor(val_size*numero_muestras/100)\n",
    "tamanyo_test=numero_muestras-tamanyo_tr-tamanyo_val\n",
    "print(tamanyo_tr)\n",
    "print(tamanyo_val)\n",
    "print(tamanyo_test)\n",
    "\n",
    "\n",
    "XY_test=conjunto_datos_nuevo2[tamanyo_tr+tamanyo_val:numero_muestras,:]\n",
    "\n",
    "\n",
    "XY_test_bin0=XY_test[np.where((XY_test[:,1]>=164.9999) * (XY_test[:,1]<171.000))]\n",
    "XY_test_bin1=XY_test[np.where((XY_test[:,1]>=171.000) * (XY_test[:,1]<177.000))]\n",
    "XY_test_bin2=XY_test[np.where((XY_test[:,1]>=177.000) * (XY_test[:,1]<183.0000))]\n",
    "XY_test_bin3=XY_test[np.where((XY_test[:,1]>=183.000) * (XY_test[:,1]<189.0000))]\n",
    "XY_test_bin4=XY_test[np.where((XY_test[:,1]>=189.0000))]\n",
    "\n",
    "x_train=conjunto_datos_nuevo2[:tamanyo_tr,3:]\n",
    "x_val=conjunto_datos_nuevo2[tamanyo_tr:tamanyo_tr+tamanyo_val,3:]\n",
    "x_test=conjunto_datos_nuevo2[tamanyo_tr+tamanyo_val:numero_muestras,3:]\n",
    "\n",
    "x_test_bin0=XY_test_bin0[:,3:]\n",
    "Y_test_bin0=XY_test_bin0[:,1]\n",
    "print(x_test_bin0.shape)\n",
    "x_test_bin1=XY_test_bin1[:,3:]\n",
    "Y_test_bin1=XY_test_bin1[:,1]\n",
    "print(x_test_bin1.shape)\n",
    "x_test_bin2=XY_test_bin2[:,3:]\n",
    "Y_test_bin2=XY_test_bin2[:,1]\n",
    "print(x_test_bin2.shape)\n",
    "x_test_bin3=XY_test_bin3[:,3:]\n",
    "Y_test_bin3=XY_test_bin3[:,1]\n",
    "print(x_test_bin3.shape)\n",
    "x_test_bin4=XY_test_bin4[:,3:]\n",
    "Y_test_bin4=XY_test_bin4[:,1]\n",
    "print(x_test_bin4.shape)\n",
    "\n",
    "\n",
    "\n",
    "Y_train=conjunto_datos_nuevo2[:tamanyo_tr,1] #elijo la coordenada radius\n",
    "Y_val=conjunto_datos_nuevo2[tamanyo_tr:tamanyo_tr+tamanyo_val,1] #elijo la corrdenada radius\n",
    "Y_test=conjunto_datos_nuevo2[tamanyo_tr+tamanyo_val:numero_muestras,1] #elijo la corrdenada radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cols=31\n",
    "img_rows=20\n",
    "\n",
    "X_train = x_train.reshape(x_train.shape[0], img_rows, img_cols,1)\n",
    "X_val = x_val.reshape(x_val.shape[0], img_rows, img_cols,1)\n",
    "X_test = x_test.reshape(x_test.shape[0], img_rows, img_cols,1)\n",
    "\n",
    "X_test_bin0 = x_test_bin0.reshape(x_test_bin0.shape[0], img_rows, img_cols,1)\n",
    "X_test_bin1 = x_test_bin1.reshape(x_test_bin1.shape[0], img_rows, img_cols,1)\n",
    "X_test_bin2 = x_test_bin2.reshape(x_test_bin2.shape[0], img_rows, img_cols,1)\n",
    "X_test_bin3 = x_test_bin3.reshape(x_test_bin3.shape[0], img_rows, img_cols,1)\n",
    "X_test_bin4 = x_test_bin4.reshape(x_test_bin4.shape[0], img_rows, img_cols,1)\n",
    "\n",
    "input_shape = (img_rows, img_cols,1)\n",
    "#input_shape=input_shape.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (13621, 20, 31, 1)\n",
      "13621 train samples\n",
      "4540 validation samples\n",
      "4542 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_val= X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_val.shape[0], 'validation samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display 20 random training images using image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD6CAYAAACmjCyGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGp9JREFUeJzt3XuMpfV93/H355yZ2ZmdnVl2geW6NrZDSYkT43RFgmgrHMcUkBXi1klZ9UJaV+tEsWSriRQ3lWzXVaX04qRKiUw2YWVcOUAaGxspK5tV6goj2Zg1WQwYMBiBGWa9C+x19jKXc779Y56VJsOZ3e/vnDPMDM/nJa3mnOd85/f8nsv5zrPPOb/vTxGBmZnVR2OlO2BmZm8uJ34zs5px4jczqxknfjOzmnHiNzOrGSd+M7OaceI3M6sZJ34zs5px4jczq5mBle5AJ0ON4RhpjKVio9Va5t6cg5QPLWi2aDz1coy+LtiuIivd17fqSPVlO7nWkJqfB6c5wUxMp3bCqkz8I40xrtv4oVRs68iRfMPLcLC1bl0+tuDELCmlEdPT6disku0qsSx9HRzKr39uNt/wSieHRjMdqkbBuVVysVSyDwr6SzvZh5J9MJhPZ8txHi6b5D54pPVgvslu+wIg6SZJz0p6XtInO7y+TtJ91euPSLqil/WZmVnvuk78kprAnwA3A1cD2yVdvSjsI8DhiPgp4I+A/9rt+szMrD96ueK/Fng+Il6IiBngXuDWRTG3AndXj/8KeL9K7neYmVnf9ZL4LwNeXvB8olrWMSYi5oCjwPmdGpO0Q9JeSXtn4nQP3TIzs7PpJfF3unJf/ElQJmZ+YcTOiNgWEduGNNxDt8zM7Gx6SfwTwNYFzy8HJpeKkTQAbAQO9bBOMzPrUS+J/1HgSknvkDQE3AY8sCjmAeD26vGHgf8bnvLLzGxFdf09/oiYk/Qx4BtAE9gVEU9J+iywNyIeAO4C/rek55m/0r+tH502M7Pu9TSAKyJ2A7sXLfvUgsengV/rZR1mZtZfq3LkbrRbtI8fTwav7J2johGAA/nd3bzsknTs3EsvnzuoVLtg5PDsTP/XX2BNjcYt0BgaTMdGq51vd6RgpPPsXEFs/jxQwXshqzFS8KWQ9evToTGX3wfpvLXCXKTNzKxmnPjNzGrGid/MrGac+M3MasaJ38ysZpz4zcxqxonfzKxmnPjNzGrGid/MrGac+M3MamZVlmwQSg/pbhQMvW6fyk3wslwlCIqGfr/6ejo2OzH6cg2/X2kaKCltUDLReL4MQlEpiOQkdBoby6/+yNF8bMl5ULC/Sia9b4xvSLaZP7bZ/QoUHa+S9216cvjsZPOlsUm+4jczqxknfjOzmnHiNzOrGSd+M7OaceI3M6sZJ34zs5rpOvFL2irpm5KelvSUpI93iLlB0lFJ+6p/n+rUlpmZvXl6+R7/HPA7EfGYpDHge5L2RMQPFsV9KyI+2MN6zMysj7q+4o+I/RHxWPX4OPA0cFm/OmZmZsujLyN3JV0BvBd4pMPL10l6HJgEfjcinlqijR3ADoBhjUIzNwJOmzam+9lcP5KKi5On0m3GTH6Ea/t0buQwQPvkyXRsdsRi0SjnEyfy618mAxdflAxcpgHoJaN8C/oQR4/l4grOl8Zo7twGaBWM8i2ZFF3N/HVkdkRuzM7m2yw5v18/lI4tGem8HKNsl0PP7xhJG4AvA5+IiMVn9GPA2yNiStItwFeBKzu1ExE7gZ0AG5sXFIx/NzOzEj19q0fSIPNJ/0sR8ZXFr0fEsYiYqh7vBgYlXdDLOs3MrDe9fKtHwF3A0xHxh0vEXFzFIenaan356mNmZtZ3vdzquR74V8ATkvZVy34feBtARNwJfBj4LUlzwCngtoiSMoZmZtZvXSf+iHgYOOunihFxB3BHt+swM7P+88hdM7OaceI3M6sZJ34zs5px4jczqxknfjOzmlmVk61Hu50uGaCR4XS76Ymbk5OXz7dZsAtn8sPPS4Z+NzbkJq6mXTB5eIHsZO8AzYu3pGMjW4agYEh96/zkvgLUyn/zuD2Qv4ZqbkxONH56Ot0mBedho6BdDeUnUKfgvZgucVFQsiGmlqfMSEk5jPapXPmUmC44tsvAV/xmZjXjxG9mVjNO/GZmNePEb2ZWM078ZmY148RvZlYzTvxmZjXjxG9mVjNO/GZmNePEb2ZWM6uyZEOJmJ7Jx548lYprnzyZbrMxNpaObf7UFenY9gsvpWM1nBwq38gNJwdoFpQASK8faF0wno5tr8v1YWZjvqxAo6AMw6nz8/ugOZtvd+BErr8jk/nj1TieO7cBdGF+2usoeC9QUIagnXwvVjO3ppRM7qdLL8rHzhWUT2k2U3Etl2wwM7M3U8+JX9KLkp6QtE/S3g6vS9IfS3pe0vcl/Xyv6zQzs+7161bP+yLitSVeuxm4svr3C8Dnq59mZrYC3oxbPbcCX4x53wHOk3TJm7BeMzProB+JP4AHJX1P0o4Or18GvLzg+US17O+QtEPSXkl7Z1nZDz7MzN7K+nGr5/qImJS0Bdgj6ZmIeGjB650+ln/Dx+8RsRPYCTCuzfmP583MrEjPV/wRMVn9PAjcD1y7KGQC2Lrg+eXAZK/rNTOz7vSU+CWNSho78xi4EXhyUdgDwL+uvt3zi8DRiNjfy3rNzKx7vd7quQi4vxpkMQD8RUR8XdJvAkTEncBu4BbgeeAk8G96XKeZmfWgp8QfES8A7+mw/M4FjwP47V7WY2Zm/bMqSzZoYIDm5gtzsaMj6XZj6kQqruT+V2PDaD745Ol8u+vXp2Nbr76aihu44m3pNhlel49NDlMHaA/lT7nZscFUXEkZhvZAQRmEuYIyDCfb6djZDbkzbLhgX7XH8u+DxpGpdKxGCt5fBeVTmM2VgtDYhnSTGsmXDqGVP17MzuX7kCxfonX591e2bIVOF5zb6UgzM3tLcOI3M6sZJ34zs5px4jczqxknfjOzmnHiNzOrGSd+M7OaceI3M6sZJ34zs5px4jczq5lVWbIBCa0bSoXGqXwZhPaRo932aGnJfgLQKPg7e/nF+WZfSA6Vn2ul24yxfMmI9mh++Png/sPp2LmxLbm4kfx+nR3Nx06P54fAT2/Mtzt8OFcuoD2Yb3PwJ8fTsTNX5MqhAAweOJaOZX2+ZEJjIFfmI8YLSjbMzKZj4+SpfOzR/D5oJ/vQKCmJkpUs7QC+4jczqx0nfjOzmnHiNzOrGSd+M7OaceI3M6sZJ34zs5rpOvFLukrSvgX/jkn6xKKYGyQdXRDzqd67bGZmvej6e/wR8SxwDYCkJvAKcH+H0G9FxAe7XY+ZmfVXv271vB/4UUS81Kf2zMxsmfRr5O5twD1LvHadpMeBSeB3I+KpTkGSdgA7AIY1Svu11/vUtQXrSE5w3D6Rm5QdoP2Tg+nY1j/46XRsc99z6djGpvNSce3NY+k2p7fkJ5EfPJafZPvEz1yUjo3kSMTDfy9/Gsd1+dHbJw7m98G6g/kJ56OZu94aOJ0fFd6Y3ZSOVTs/ifzsJePp2MHJgpHxQ4O5uCP5UbOtQ0fSsTGbP2cbo/nzgHa+kkC+zeTE8JE/rj1f8UsaAn4F+D8dXn4MeHtEvAf4X8BXl2onInZGxLaI2DbEMgxnNjMzoD+3em4GHouIA4tfiIhjETFVPd4NDEq6oA/rNDOzLvUj8W9nids8ki6W5v+/Lunaan39v4djZmZpPd3jl7Qe+ADw0QXLfhMgIu4EPgz8lqQ54BRwW0TBjSgzM+u7nhJ/RJwEzl+07M4Fj+8A7uhlHWZm1l8euWtmVjNO/GZmNePEb2ZWM078ZmY148RvZlYzq3Ky9YigfTo39Lkxli9DkB36rIGC3VIwgfrAD19Jx2YnbQZob8kN15++MD+B+vGt+XIBpy/Ij7QeOpr/Nu/p83MlG6bfnZ84++NXPZyOHfzpuXTs7ld/Nh07cXRjKm763nwZhvbgSDq2xMBUKx07NJePZTpXMiGOT6WbbIzm90HraMH7q6CEC41c6Q4VlYFI7tfZfC7yFb+ZWc048ZuZ1YwTv5lZzTjxm5nVjBO/mVnNOPGbmdWME7+ZWc048ZuZ1YwTv5lZzTjxm5nVzKos2aBmg+aG8VxwIzesH4Bm7u9c+1SuXASAkmUggKK+ajB/aFqjufIKreHccHKAmfF8X09eUrAPCq41BpMj5cc2HU+3ecuGp9Kx7xrckI49r3kyHfu3429PxX35vdfl1/9s/tiO/zhfrkAF8+W1N+bLEDROT+fixgtKshTIrh9Il48BIHLvhfaRo+km07mgnT9YvuI3M6uZVOKXtEvSQUlPLli2WdIeSc9VPztWlJJ0exXznKTb+9VxMzPrTvaK/wvATYuWfRL4m4i4Evib6vnfIWkz8GngF4BrgU8v9QfCzMzeHKnEHxEPAYcWLb4VuLt6fDfwqx1+9Z8AeyLiUEQcBvbwxj8gZmb2Jurlw92LImI/QETsl7SlQ8xlwMsLnk9Uy95A0g5gB8CwCmpVm5lZkeX+cLfTV0M6fvQcETsjYltEbBtqDC9zt8zM6quXxH9A0iUA1c+DHWImgK0Lnl8OTPawTjMz61Evif8B4My3dG4HvtYh5hvAjZI2VR/q3lgtMzOzFZL9Ouc9wLeBqyRNSPoI8AfAByQ9B3ygeo6kbZL+HCAiDgH/GXi0+vfZapmZma2Q1Ie7EbF9iZfe3yF2L/DvFjzfBezqqndmZtZ3q7JkA0NDxDsvT4XGYH6oevP13ND+geH8h8tRMJy7vbXTF586a7yUH34dyVIUIz/JlxVozI2kY8d/nL9jeHzruWPOOHrNTCruitF8yYbfefGfpWM3DOaH9V+9YX869mvP/Wxu/S/ny2aMTeTLMAy9fiod216XTxHtofx7UTO5Y6uR/HlY8l6kme8rKii1MpQrnxLT+XMrZnP7KpLlIsAlG8zMaseJ38ysZpz4zcxqxonfzKxmnPjNzGrGid/MrGac+M3MasaJ38ysZpz4zcxqxonfzKxmVmfJhrkWjdeSs9AXDKeO4dxwajaOpdvUQH4XNn70Sjq2ZEj34DMTqbj2sWPpNtdfenE6NoYG07Fqb07HErnj9YMD70w32ZgpGH6fr5rBd658Rzq2dTS3vzYfyA/BX//0T9KxcTJf2mDuZ/I1NoaO5EtBaDC3D9qHj6TbpNVKh7YL3l/N887Lt3s8Xz4kqzGWy0eayl/H+4rfzKxmnPjNzGrGid/MrGac+M3MasaJ38ysZpz4zcxq5pyJX9IuSQclPblg2X+X9Iyk70u6X1LH7ztJelHSE5L2Sdrbz46bmVl3Mlf8XwBuWrRsD/DuiPg54IfAfzjL778vIq6JiG3dddHMzPrpnIk/Ih4CDi1a9mBEzFVPvwPkJsg1M7MV14+Ru/8WuG+J1wJ4UFIAfxoRO5dqRNIOYAfAcGMDcSI5MXjByFlFbihmzOYnro6x0XQs2ZHDQONUwWTMyUmmmxecn26Tdn7UqE7kR2wOTuVHV46/nItb/2r+o6qZ/KBsouATsONDw+nY0Vdzo4c3/PhEus2YyseWvGcGThS8FxoFOyw5Ol5zc+cOOqOVP2eZKdiu5MTwAJHsb8mI//bUVG7dBe/ZnhK/pP8IzAFfWiLk+oiYlLQF2CPpmep/EG9Q/VHYCbBx4MKCwfJmZlai62/1SLod+CDwLyI6X0pHxGT18yBwP3Btt+szM7P+6CrxS7oJ+D3gVyKi4z0ZSaOSxs48Bm4EnuwUa2Zmb57M1znvAb4NXCVpQtJHgDuAMeZv3+yTdGcVe6mk3dWvXgQ8LOlx4LvAX0fE15dlK8zMLO2c9/gjYnuHxXctETsJ3FI9fgF4T0+9MzOzvvPIXTOzmnHiNzOrGSd+M7OaceI3M6sZJ34zs5pZlZOtR6tF62hyYvAoKC0wkJvgOQombR4oGKYemzemY5nND1VvHc5NTD9w6Uh+/dMFw9Q3jadjh15LluIAQutTcc1T+XNg6Gh+svXjb8u/PTY+lw5l+Eju/FJBCYK4/KJ0rE7my4FoOl/agIH8e0HZUhAb8iVRYl2+JEqz4D1eojmeey+0T+UnvCcKylYk+YrfzKxmnPjNzGrGid/MrGac+M3MasaJ38ysZpz4zcxqxonfzKxmnPjNzGrGid/MrGac+M3MamZVlmwAoJ0cUt1o5tts5IbrK/LD+mM2P6Q9XpxIx7bnCoZpJ/dV+9DhdJNat65g/R2nXO5obnw4H7shd2zXvZYvL1Fi8w/6P1QeoHkqd840ThSUVjh2Ih3bPpIr8QGgS7akYykomcBM8n1T0mZBGQaN5sqBAMSJfJmRdJvLVDIiy1f8ZmY1k5lzd5ekg5KeXLDsM5Jeqebb3SfpliV+9yZJz0p6XtIn+9lxMzPrTuaK/wvATR2W/1FEXFP92734RUlN4E+Am4Grge2Sru6ls2Zm1rtzJv6IeAg41EXb1wLPR8QLETED3Avc2kU7ZmbWR73c4/+YpO9Xt4I2dXj9MuDlBc8nqmUdSdohaa+kvbPkP9QyM7My3Sb+zwPvAq4B9gOf6xDT6asxS379IyJ2RsS2iNg2SME3SszMrEhXiT8iDkREKyLawJ8xf1tnsQlg64LnlwOT3azPzMz6p6vEL+mSBU8/BDzZIexR4EpJ75A0BNwGPNDN+szMrH/OOYBL0j3ADcAFkiaATwM3SLqG+Vs3LwIfrWIvBf48Im6JiDlJHwO+ATSBXRHx1LJshZmZpZ0z8UfE9g6L71oidhK4ZcHz3cAbvuppZmYrZ/WWbEhSM1+yoZEsQxAzBSUAskPPgSiI1WD+0GQLJrRP5oeeN9rtdKyOHEvHDp08nY4dfD03rD4a+TuWKjgGqKB0x8T+fLPZY1tQNqN98lQ6tug8LDi2GhxMx7anciUmVHAMSvYXG/IlGxT5kiTpchjZkjTLxCUbzMxqxonfzKxmnPjNzGrGid/MrGac+M3MasaJ38ysZpz4zcxqxonfzKxmnPjNzGrGid/MrGZWb8mGRq4UQ8wVDMFnOBWlkZF0i63Dh9OxGsjvbg3lh7+TrMSgkiHtBcPvIzn8HiDIxzbm5lJxGs5vV0zly1aQXP98w/lh/a3ksP7mpk7zG3XWPn48HVtyHpZsV5zKl41In9/t/PqZzk/g1D6RPw9LSp1ocCgXV3AMouQ8TPIVv5lZzTjxm5nVjBO/mVnNOPGbmdWME7+ZWc048ZuZ1Uxmzt1dwAeBgxHx7mrZfcBVVch5wJGIuKbD774IHAdawFxEbOtTv83MrEuZL5N+AbgD+OKZBRHxz888lvQ54GxfTH5fRLzWbQfNzKy/MpOtPyTpik6vaX5CzF8Hfqm/3TIzs+XS68jdfwQciIjnlng9gAclBfCnEbFzqYYk7QB2AAyzflkmI25lR5gu00TIRSPwCkbZZkcBRsHIRg3lRiAC0Mrvr3ZBH7LtlvRV6/OjstsnCvpaMDl9Yzg3grxkVHiJovOwYLJzJbcLIKZnUnElo2ZLzu/lkq4kUDAiejn0mvi3A/ec5fXrI2JS0hZgj6RnIuKhToHVH4WdAOPavLJ7xczsLazrb/VIGgD+KXDfUjERMVn9PAjcD1zb7frMzKw/evk65y8Dz0TERKcXJY1KGjvzGLgReLKH9ZmZWR+cM/FLugf4NnCVpAlJH6leuo1Ft3kkXSppd/X0IuBhSY8D3wX+OiK+3r+um5lZNzLf6tm+xPLf6LBsErilevwC8J4e+2dmZn3mkbtmZjXjxG9mVjNO/GZmNePEb2ZWM078ZmY1s3onW18Oy1SKIas5Pp4PLphkOkompM62ebqgvEPBZOdq5UsbtGeSw99Pn063ybFj+dhGMx+anTycfNmKZZuQu6AMQ0lpgfbxqb63W1Q6pOQ9M5srGQFlx0HJUivtUwXn7DLkLV/xm5nVjBO/mVnNOPGbmdWME7+ZWc048ZuZ1YwTv5lZzTjxm5nVjBO/mVnNOPGbmdWME7+ZWc0oVni2904kvQq8tGjxBcBrK9Cd5ebtWlu8XWtLnbbr7RFxYeaXV2Xi70TS3ojYttL96Ddv19ri7VpbvF2d+VaPmVnNOPGbmdXMWkr8O1e6A8vE27W2eLvWFm9XB2vmHr+ZmfXHWrriNzOzPnDiNzOrmVWf+CXdJOlZSc9L+uRK96efJL0o6QlJ+yTtXen+dEvSLkkHJT25YNlmSXskPVf93LSSfezGEtv1GUmvVMdsn6RbVrKPpSRtlfRNSU9LekrSx6vla/p4nWW71vrxGpb0XUmPV9v1n6rl75D0SHW87pNUMEflKr/HL6kJ/BD4ADABPApsj4gfrGjH+kTSi8C2iFjTA0wk/WNgCvhiRLy7WvbfgEMR8QfVH+xNEfF7K9nPUkts12eAqYj4HyvZt25JugS4JCIekzQGfA/4VeA3WMPH6yzb9eus7eMlYDQipiQNAg8DHwf+PfCViLhX0p3A4xHx+Wy7q/2K/1rg+Yh4ISJmgHuBW1e4T7ZIRDwEHFq0+Fbg7urx3cy/CdeUJbZrTYuI/RHxWPX4OPA0cBlr/HidZbvWtJh3Zhb7wepfAL8E/FW1vPh4rfbEfxnw8oLnE7wFDuYCATwo6XuSdqx0Z/rsoojYD/NvSmDLCvennz4m6fvVraA1dUtkIUlXAO8FHuEtdLwWbRes8eMlqSlpH3AQ2AP8CDgSEXNVSHFeXO2JXx2Wrd57U+Wuj4ifB24Gfru6tWCr2+eBdwHXAPuBz61sd7ojaQPwZeATEXFspfvTLx22a80fr4hoRcQ1wOXM3wX5+53CStpc7Yl/Ati64PnlwOQK9aXvImKy+nkQuJ/5g/pWcaC673rm/uvBFe5PX0TEgeqN2Ab+jDV4zKp7xV8GvhQRX6kWr/nj1Wm73grH64yIOAL8P+AXgfMkDVQvFefF1Z74HwWurD7BHgJuAx5Y4T71haTR6kMoJI0CNwJPnv231pQHgNurx7cDX1vBvvTNmeRY+RBr7JhVHxbeBTwdEX+44KU1fbyW2q63wPG6UNJ51eMR4JeZ//zim8CHq7Di47Wqv9UDUH396n8CTWBXRPyXFe5SX0h6J/NX+QADwF+s1W2TdA9wA/OlYg8Anwa+Cvwl8Dbgx8CvRcSa+qB0ie26gfnbBgG8CHz0zL3xtUDSPwS+BTwBtKvFv8/8/fA1e7zOsl3bWdvH6+eY//C2yfyF+l9GxGer/HEvsBn4W+BfRsR0ut3VnvjNzKy/VvutHjMz6zMnfjOzmnHiNzOrGSd+M7OaceI3M6sZJ34zs5px4jczq5n/D5RpFd8D4Hj7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "#Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "#Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "for i in range(1,5):\n",
    "    idea=np.random.randint(1,X_train.shape[0])\n",
    "    plt.imshow(np.reshape(X_train[idea], [img_rows, img_cols]), cmap='viridis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the MLP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.47331315e-02 4.56523418e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 4.87628043e-01 5.72744429e-01 6.97216809e-01\n",
      "  7.29516327e-01 0.00000000e+00]\n",
      " [3.28089595e-01 0.00000000e+00 1.41425803e-02 3.79959419e-02\n",
      "  0.00000000e+00 1.41854212e-03 0.00000000e+00 0.00000000e+00\n",
      "  3.31108570e-02 2.42296115e-01]\n",
      " [6.14077806e-01 1.84137449e-02 0.00000000e+00 3.33131105e-02\n",
      "  2.35167295e-01 0.00000000e+00 1.02590032e-01 1.88835871e+00\n",
      "  9.82893586e-01 3.52151006e-01]\n",
      " [8.24568212e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  4.63586479e-01 4.35350090e-01 5.08791029e-01 7.51515329e-01\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.07754159e-01 1.99557796e-01 3.10198516e-02 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.43471509e-02 2.72802487e-02]\n",
      " [8.36109817e-02 1.31435409e-01 1.08125158e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.24881156e-01 0.00000000e+00\n",
      "  3.69951725e-02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.42821208e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 6.13516569e-02 0.00000000e+00\n",
      "  0.00000000e+00 3.22991163e-02]\n",
      " [2.64251590e-01 4.02289182e-01 4.39817309e-01 4.77583408e-02\n",
      "  9.18491840e-01 0.00000000e+00 4.85246599e-01 2.58924991e-01\n",
      "  4.52790022e-01 0.00000000e+00]\n",
      " [4.09002513e-01 3.84392172e-01 1.18253537e-01 2.06629634e-02\n",
      "  3.82232070e-02 1.49453610e-01 7.38620535e-02 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.53269821e-01 0.00000000e+00 1.51913905e+00 2.64269382e-01\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "X_train shape: (13621, 20, 31, 1)\n",
      "13621 train samples\n",
      "4540 validation samples\n",
      "4542 test samples\n",
      "[[3.47331315e-02 4.56523418e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 4.87628043e-01 5.72744429e-01 6.97216809e-01\n",
      "  7.29516327e-01 0.00000000e+00]\n",
      " [3.28089595e-01 0.00000000e+00 1.41425803e-02 3.79959419e-02\n",
      "  0.00000000e+00 1.41854212e-03 0.00000000e+00 0.00000000e+00\n",
      "  3.31108570e-02 2.42296115e-01]\n",
      " [6.14077806e-01 1.84137449e-02 0.00000000e+00 3.33131105e-02\n",
      "  2.35167295e-01 0.00000000e+00 1.02590032e-01 1.88835871e+00\n",
      "  9.82893586e-01 3.52151006e-01]\n",
      " [8.24568212e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  4.63586479e-01 4.35350090e-01 5.08791029e-01 7.51515329e-01\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.07754159e-01 1.99557796e-01 3.10198516e-02 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.43471509e-02 2.72802487e-02]\n",
      " [8.36109817e-02 1.31435409e-01 1.08125158e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.24881156e-01 0.00000000e+00\n",
      "  3.69951725e-02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.42821208e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 6.13516569e-02 0.00000000e+00\n",
      "  0.00000000e+00 3.22991163e-02]\n",
      " [2.64251590e-01 4.02289182e-01 4.39817309e-01 4.77583408e-02\n",
      "  9.18491840e-01 0.00000000e+00 4.85246599e-01 2.58924991e-01\n",
      "  4.52790022e-01 0.00000000e+00]\n",
      " [4.09002513e-01 3.84392172e-01 1.18253537e-01 2.06629634e-02\n",
      "  3.82232070e-02 1.49453610e-01 7.38620535e-02 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.53269821e-01 0.00000000e+00 1.51913905e+00 2.64269382e-01\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(x_val[:10,:10])\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler().fit(x_train)\n",
    "#min_max_scaler = preprocessing.RobustScaler().fit(x_train)\n",
    "# supermax=1\n",
    "# factor_aprendizaje=0.0001\n",
    "print(min_max_scaler)\n",
    "# comentar las siguientes lineas si no queremos normalizar\n",
    "# x_train = min_max_scaler.transform(x_train)\n",
    "# x_val = min_max_scaler.transform(x_val)\n",
    "# x_test = min_max_scaler.transform(x_test)\n",
    "# x_test_bin0 = min_max_scaler.transform(x_test_bin0)\n",
    "# x_test_bin1 = min_max_scaler.transform(x_test_bin1)\n",
    "# x_test_bin2 = min_max_scaler.transform(x_test_bin2)\n",
    "# x_test_bin3 = min_max_scaler.transform(x_test_bin3)\n",
    "# x_test_bin4 = min_max_scaler.transform(x_test_bin4)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_val.shape[0], 'validation samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "model=Sequential()\n",
    "# add input layer\n",
    "model.add(Dense(\n",
    "    units=n_hidden1,\n",
    "    input_dim=x_train.shape[1],\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    activation='tanh') \n",
    ")\n",
    "# add hidden layer\n",
    "model.add(\n",
    "    Dense(\n",
    "        units=n_hidden1,\n",
    "        input_dim=n_hidden2,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh')\n",
    "    )\n",
    "# add output layer\n",
    "model.add(\n",
    "    Dense(\n",
    "        units=1,\n",
    "        input_dim=n_hidden2,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='linear')\n",
    "    )\n",
    "\n",
    "# define SGD optimizer\n",
    "sgd_optimizer = SGD(\n",
    "    lr=0.001, decay=1e-7, momentum=0.9\n",
    ")\n",
    "# compile model\n",
    "experimento=\"{}_{}_tanh_tanh_linear_sin_normalizar_reconstruido\".format(n_hidden1,n_hidden2)\n",
    "algoritmo='adam'\n",
    "tensorboard=TensorBoard(log_dir=\"/home/rgadea3/EXPERIMENTOS/nuevas_investigaciones_2018/experimentos/logs/defs/{}{}{}\".format(experimento,algoritmo,datetime.now()))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=algoritmo\n",
    "\n",
    "             )\n",
    "print(x_val[:10,:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a summary of the model parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                31050     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 33,651\n",
      "Trainable params: 33,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now train the model and evaluate on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13621 samples, validate on 4540 samples\n",
      "Epoch 1/2000\n",
      "13621/13621 [==============================] - 1s 41us/step - loss: 30057.9229 - val_loss: 29136.3461\n",
      "Epoch 2/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 28701.6701 - val_loss: 28233.9131\n",
      "Epoch 3/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 28021.0006 - val_loss: 27747.7448\n",
      "Epoch 4/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 27610.2929 - val_loss: 27401.6949\n",
      "Epoch 5/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 27289.7007 - val_loss: 27103.2749\n",
      "Epoch 6/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 27001.3686 - val_loss: 26824.9325\n",
      "Epoch 7/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 26728.6211 - val_loss: 26558.2406\n",
      "Epoch 8/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 26465.6573 - val_loss: 26299.6037\n",
      "Epoch 9/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 26209.8434 - val_loss: 26047.1616\n",
      "Epoch 10/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 25959.7237 - val_loss: 25799.6695\n",
      "Epoch 11/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 25714.0922 - val_loss: 25556.4156\n",
      "Epoch 12/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 25472.4570 - val_loss: 25316.7935\n",
      "Epoch 13/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 25234.2498 - val_loss: 25080.4774\n",
      "Epoch 14/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 24999.2549 - val_loss: 24847.0477\n",
      "Epoch 15/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 24767.0176 - val_loss: 24616.4275\n",
      "Epoch 16/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 24537.4543 - val_loss: 24388.3425\n",
      "Epoch 17/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 24310.3889 - val_loss: 24162.5742\n",
      "Epoch 18/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 24085.5993 - val_loss: 23939.0841\n",
      "Epoch 19/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 23863.0195 - val_loss: 23717.8267\n",
      "Epoch 20/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 23642.6364 - val_loss: 23498.5446\n",
      "Epoch 21/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 23424.1954 - val_loss: 23281.2586\n",
      "Epoch 22/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 23207.6705 - val_loss: 23065.9490\n",
      "Epoch 23/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 22993.1574 - val_loss: 22852.3857\n",
      "Epoch 24/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 22780.3457 - val_loss: 22640.7113\n",
      "Epoch 25/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 22569.3667 - val_loss: 22430.8234\n",
      "Epoch 26/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 22360.1458 - val_loss: 22222.6287\n",
      "Epoch 27/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 22152.6892 - val_loss: 22016.0835\n",
      "Epoch 28/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 21946.8132 - val_loss: 21811.2656\n",
      "Epoch 29/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 21742.6327 - val_loss: 21608.0574\n",
      "Epoch 30/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 21540.0638 - val_loss: 21406.4472\n",
      "Epoch 31/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 21339.0495 - val_loss: 21206.4440\n",
      "Epoch 32/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 21139.6548 - val_loss: 21007.9117\n",
      "Epoch 33/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 20941.7374 - val_loss: 20810.9439\n",
      "Epoch 34/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 20745.3561 - val_loss: 20615.4839\n",
      "Epoch 35/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 20550.4963 - val_loss: 20421.4714\n",
      "Epoch 36/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 20357.0625 - val_loss: 20228.9776\n",
      "Epoch 37/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 20165.1268 - val_loss: 20037.9154\n",
      "Epoch 38/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 19974.5865 - val_loss: 19848.3259\n",
      "Epoch 39/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 19785.5314 - val_loss: 19660.0975\n",
      "Epoch 40/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 19597.8695 - val_loss: 19473.2819\n",
      "Epoch 41/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 19411.5678 - val_loss: 19287.9042\n",
      "Epoch 42/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 19226.7371 - val_loss: 19103.8182\n",
      "Epoch 43/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 19043.1611 - val_loss: 18921.2127\n",
      "Epoch 44/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 18861.0459 - val_loss: 18739.9034\n",
      "Epoch 45/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 18680.2772 - val_loss: 18559.9064\n",
      "Epoch 46/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 18500.8092 - val_loss: 18381.2690\n",
      "Epoch 47/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 18322.6500 - val_loss: 18204.0019\n",
      "Epoch 48/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 18145.8583 - val_loss: 18027.9863\n",
      "Epoch 49/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 17970.3094 - val_loss: 17853.2899\n",
      "Epoch 50/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 17796.1015 - val_loss: 17679.8426\n",
      "Epoch 51/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 17623.1749 - val_loss: 17507.6493\n",
      "Epoch 52/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 17451.4328 - val_loss: 17336.8383\n",
      "Epoch 53/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 17281.0911 - val_loss: 17167.2132\n",
      "Epoch 54/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 17111.9308 - val_loss: 16998.8584\n",
      "Epoch 55/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 16944.0361 - val_loss: 16831.7499\n",
      "Epoch 56/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 16777.3659 - val_loss: 16665.8854\n",
      "Epoch 57/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 16611.9732 - val_loss: 16501.2049\n",
      "Epoch 58/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 16447.7325 - val_loss: 16337.7795\n",
      "Epoch 59/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 16284.7525 - val_loss: 16175.5404\n",
      "Epoch 60/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 16122.9388 - val_loss: 16014.5441\n",
      "Epoch 61/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 15962.3764 - val_loss: 15854.7006\n",
      "Epoch 62/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 15802.9491 - val_loss: 15696.0616\n",
      "Epoch 63/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 15644.7235 - val_loss: 15538.5713\n",
      "Epoch 64/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 15487.6761 - val_loss: 15382.2591\n",
      "Epoch 65/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 15331.7736 - val_loss: 15227.1293\n",
      "Epoch 66/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 15177.0767 - val_loss: 15073.1027\n",
      "Epoch 67/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 15023.4677 - val_loss: 14920.3092\n",
      "Epoch 68/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 14871.0547 - val_loss: 14768.6242\n",
      "Epoch 69/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 14719.8009 - val_loss: 14618.0256\n",
      "Epoch 70/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 14569.6147 - val_loss: 14468.5953\n",
      "Epoch 71/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13621/13621 [==============================] - 0s 14us/step - loss: 14420.5745 - val_loss: 14320.2899\n",
      "Epoch 72/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 14272.6757 - val_loss: 14173.0686\n",
      "Epoch 73/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 14125.8789 - val_loss: 14026.9724\n",
      "Epoch 74/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 13980.1911 - val_loss: 13881.9881\n",
      "Epoch 75/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 13835.5804 - val_loss: 13738.1610\n",
      "Epoch 76/2000\n",
      "13621/13621 [==============================] - ETA: 0s - loss: 13700.169 - 0s 15us/step - loss: 13692.1266 - val_loss: 13595.3466\n",
      "Epoch 77/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 13549.7233 - val_loss: 13453.6214\n",
      "Epoch 78/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 13408.3767 - val_loss: 13313.0055\n",
      "Epoch 79/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 13268.1274 - val_loss: 13173.4821\n",
      "Epoch 80/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 13128.9995 - val_loss: 13034.9589\n",
      "Epoch 81/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 12990.8727 - val_loss: 12897.5359\n",
      "Epoch 82/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 12853.8150 - val_loss: 12761.1798\n",
      "Epoch 83/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 12717.8444 - val_loss: 12625.8373\n",
      "Epoch 84/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 12582.8582 - val_loss: 12491.5944\n",
      "Epoch 85/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 12448.9729 - val_loss: 12358.3387\n",
      "Epoch 86/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 12316.0836 - val_loss: 12226.1478\n",
      "Epoch 87/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 12184.2570 - val_loss: 12094.9492\n",
      "Epoch 88/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 12053.4252 - val_loss: 11964.7789\n",
      "Epoch 89/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 11923.6156 - val_loss: 11835.6401\n",
      "Epoch 90/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 11794.8116 - val_loss: 11707.5256\n",
      "Epoch 91/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 11667.0311 - val_loss: 11580.3829\n",
      "Epoch 92/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 11540.2434 - val_loss: 11454.2070\n",
      "Epoch 93/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 11414.4328 - val_loss: 11329.0554\n",
      "Epoch 94/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 11289.6303 - val_loss: 11204.8775\n",
      "Epoch 95/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 11165.8258 - val_loss: 11081.6673\n",
      "Epoch 96/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 11042.9359 - val_loss: 10959.4974\n",
      "Epoch 97/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 10921.1001 - val_loss: 10838.2711\n",
      "Epoch 98/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 10800.2298 - val_loss: 10718.0030\n",
      "Epoch 99/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 10680.2810 - val_loss: 10598.7194\n",
      "Epoch 100/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 10561.3155 - val_loss: 10480.4088\n",
      "Epoch 101/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 10443.3518 - val_loss: 10362.9712\n",
      "Epoch 102/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 10326.2509 - val_loss: 10246.5393\n",
      "Epoch 103/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 10210.1320 - val_loss: 10131.0383\n",
      "Epoch 104/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 10094.9820 - val_loss: 10016.4456\n",
      "Epoch 105/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 9980.7177 - val_loss: 9902.8373\n",
      "Epoch 106/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 9867.4133 - val_loss: 9790.1494\n",
      "Epoch 107/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 9755.0215 - val_loss: 9678.3890\n",
      "Epoch 108/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 9643.5856 - val_loss: 9567.5018\n",
      "Epoch 109/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 9533.0233 - val_loss: 9457.5427\n",
      "Epoch 110/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 9423.3464 - val_loss: 9348.5295\n",
      "Epoch 111/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 9314.6212 - val_loss: 9240.3826\n",
      "Epoch 112/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 9206.8027 - val_loss: 9133.0984\n",
      "Epoch 113/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 9099.8493 - val_loss: 9026.7451\n",
      "Epoch 114/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 8993.7872 - val_loss: 8921.2690\n",
      "Epoch 115/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 8888.6352 - val_loss: 8816.6640\n",
      "Epoch 116/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 8784.3578 - val_loss: 8712.9469\n",
      "Epoch 117/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 8680.9241 - val_loss: 8610.1521\n",
      "Epoch 118/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 8578.4188 - val_loss: 8508.2050\n",
      "Epoch 119/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 8476.7431 - val_loss: 8407.1497\n",
      "Epoch 120/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 8375.9957 - val_loss: 8306.9183\n",
      "Epoch 121/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 8276.0764 - val_loss: 8207.5352\n",
      "Epoch 122/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 8176.9951 - val_loss: 8108.9990\n",
      "Epoch 123/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 8078.7534 - val_loss: 8011.3447\n",
      "Epoch 124/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 7981.3626 - val_loss: 7914.5353\n",
      "Epoch 125/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 7884.8235 - val_loss: 7818.5648\n",
      "Epoch 126/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 7789.1315 - val_loss: 7723.4048\n",
      "Epoch 127/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 7694.2724 - val_loss: 7629.0811\n",
      "Epoch 128/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 7600.2118 - val_loss: 7535.6116\n",
      "Epoch 129/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 7507.0058 - val_loss: 7442.9401\n",
      "Epoch 130/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 7414.6198 - val_loss: 7351.0654\n",
      "Epoch 131/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 7323.0148 - val_loss: 7260.0267\n",
      "Epoch 132/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 7232.2626 - val_loss: 7169.7477\n",
      "Epoch 133/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 7142.2599 - val_loss: 7080.3287\n",
      "Epoch 134/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 7053.1129 - val_loss: 6991.6840\n",
      "Epoch 135/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 6964.7547 - val_loss: 6903.8185\n",
      "Epoch 136/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 6877.1269 - val_loss: 6816.8283\n",
      "Epoch 137/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 6790.4023 - val_loss: 6730.5427\n",
      "Epoch 138/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 6704.3729 - val_loss: 6645.0698\n",
      "Epoch 139/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 6619.1410 - val_loss: 6560.4030\n",
      "Epoch 140/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 6534.7648 - val_loss: 6476.4237\n",
      "Epoch 141/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 6451.0573 - val_loss: 6393.2812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 6368.1757 - val_loss: 6310.8897\n",
      "Epoch 143/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 6286.0394 - val_loss: 6229.2686\n",
      "Epoch 144/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 6204.6459 - val_loss: 6148.4174\n",
      "Epoch 145/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 6124.0430 - val_loss: 6068.2804\n",
      "Epoch 146/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 6044.1506 - val_loss: 5988.9239\n",
      "Epoch 147/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 5965.0275 - val_loss: 5910.2845\n",
      "Epoch 148/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 5886.6505 - val_loss: 5832.3863\n",
      "Epoch 149/2000\n",
      "13621/13621 [==============================] - ETA: 0s - loss: 5808.48 - 0s 16us/step - loss: 5808.9777 - val_loss: 5755.2588\n",
      "Epoch 150/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 5732.1023 - val_loss: 5678.8281\n",
      "Epoch 151/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 5655.9309 - val_loss: 5603.1357\n",
      "Epoch 152/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 5580.4852 - val_loss: 5528.1999\n",
      "Epoch 153/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 5505.7864 - val_loss: 5453.9812\n",
      "Epoch 154/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 5431.8105 - val_loss: 5380.4907\n",
      "Epoch 155/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 5358.5498 - val_loss: 5307.6985\n",
      "Epoch 156/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 5285.9931 - val_loss: 5235.6325\n",
      "Epoch 157/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 5214.1451 - val_loss: 5164.2726\n",
      "Epoch 158/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 5143.0014 - val_loss: 5093.5772\n",
      "Epoch 159/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 5072.5419 - val_loss: 5023.5959\n",
      "Epoch 160/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 5002.8147 - val_loss: 4954.2806\n",
      "Epoch 161/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 4933.7283 - val_loss: 4885.7152\n",
      "Epoch 162/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 4865.3569 - val_loss: 4817.8393\n",
      "Epoch 163/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 4797.6871 - val_loss: 4750.6120\n",
      "Epoch 164/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 4730.6994 - val_loss: 4684.0279\n",
      "Epoch 165/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 4664.3330 - val_loss: 4618.1616\n",
      "Epoch 166/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 4598.6894 - val_loss: 4552.9469\n",
      "Epoch 167/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 4533.7038 - val_loss: 4488.4116\n",
      "Epoch 168/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 4469.3942 - val_loss: 4424.5575\n",
      "Epoch 169/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 4405.7364 - val_loss: 4361.3557\n",
      "Epoch 170/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 4342.7548 - val_loss: 4298.8000\n",
      "Epoch 171/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 4280.3917 - val_loss: 4236.9211\n",
      "Epoch 172/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 4218.7268 - val_loss: 4175.6352\n",
      "Epoch 173/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 4157.6834 - val_loss: 4114.9944\n",
      "Epoch 174/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 4097.2313 - val_loss: 4055.0547\n",
      "Epoch 175/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 4037.4959 - val_loss: 3995.7272\n",
      "Epoch 176/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 3978.3721 - val_loss: 3937.0028\n",
      "Epoch 177/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 3919.8576 - val_loss: 3878.9193\n",
      "Epoch 178/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 3861.9688 - val_loss: 3821.4794\n",
      "Epoch 179/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 3804.7329 - val_loss: 3764.6467\n",
      "Epoch 180/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 3748.0734 - val_loss: 3708.4879\n",
      "Epoch 181/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 3692.0956 - val_loss: 3652.8720\n",
      "Epoch 182/2000\n",
      "13621/13621 [==============================] - 0s 11us/step - loss: 3636.6880 - val_loss: 3597.8602\n",
      "Epoch 183/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 3581.8942 - val_loss: 3543.4622\n",
      "Epoch 184/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 3527.6781 - val_loss: 3489.6929\n",
      "Epoch 185/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 3474.0862 - val_loss: 3436.5256\n",
      "Epoch 186/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 3421.1199 - val_loss: 3383.8883\n",
      "Epoch 187/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 3368.6894 - val_loss: 3331.8931\n",
      "Epoch 188/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 3316.8574 - val_loss: 3280.5089\n",
      "Epoch 189/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 3265.6508 - val_loss: 3229.6564\n",
      "Epoch 190/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 3214.9972 - val_loss: 3179.3918\n",
      "Epoch 191/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 3164.9215 - val_loss: 3129.7232\n",
      "Epoch 192/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 3115.4284 - val_loss: 3080.6254\n",
      "Epoch 193/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 3066.5137 - val_loss: 3032.0955\n",
      "Epoch 194/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 3018.1429 - val_loss: 2984.1461\n",
      "Epoch 195/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2970.3773 - val_loss: 2936.7106\n",
      "Epoch 196/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2923.1067 - val_loss: 2889.8814\n",
      "Epoch 197/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2876.4454 - val_loss: 2843.5786\n",
      "Epoch 198/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2830.3327 - val_loss: 2797.8245\n",
      "Epoch 199/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2784.7468 - val_loss: 2752.6212\n",
      "Epoch 200/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2739.7001 - val_loss: 2707.9746\n",
      "Epoch 201/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2695.2319 - val_loss: 2663.8419\n",
      "Epoch 202/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2651.2530 - val_loss: 2620.2742\n",
      "Epoch 203/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2607.8573 - val_loss: 2577.2021\n",
      "Epoch 204/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2564.9553 - val_loss: 2534.6788\n",
      "Epoch 205/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2522.5911 - val_loss: 2492.6845\n",
      "Epoch 206/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2480.7581 - val_loss: 2451.1973\n",
      "Epoch 207/2000\n",
      "13621/13621 [==============================] - 0s 17us/step - loss: 2439.4382 - val_loss: 2410.2276\n",
      "Epoch 208/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 2398.6078 - val_loss: 2369.7907\n",
      "Epoch 209/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2358.3388 - val_loss: 2329.8503\n",
      "Epoch 210/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2318.5457 - val_loss: 2290.4328\n",
      "Epoch 211/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2279.2712 - val_loss: 2251.5065\n",
      "Epoch 212/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2240.5197 - val_loss: 2213.0295\n",
      "Epoch 213/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13621/13621 [==============================] - 0s 15us/step - loss: 2202.1963 - val_loss: 2175.1137\n",
      "Epoch 214/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2164.4226 - val_loss: 2137.6645\n",
      "Epoch 215/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2127.1338 - val_loss: 2100.7046\n",
      "Epoch 216/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 2090.3119 - val_loss: 2064.2545\n",
      "Epoch 217/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2054.0030 - val_loss: 2028.2608\n",
      "Epoch 218/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2018.1716 - val_loss: 1992.7306\n",
      "Epoch 219/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1982.7800 - val_loss: 1957.7094\n",
      "Epoch 220/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1947.8958 - val_loss: 1923.1446\n",
      "Epoch 221/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1913.4730 - val_loss: 1889.0342\n",
      "Epoch 222/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 1879.5137 - val_loss: 1855.3831\n",
      "Epoch 223/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1845.9891 - val_loss: 1822.2183\n",
      "Epoch 224/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 1812.9676 - val_loss: 1789.4829\n",
      "Epoch 225/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1780.3587 - val_loss: 1757.2139\n",
      "Epoch 226/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1748.2143 - val_loss: 1725.3965\n",
      "Epoch 227/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1716.5437 - val_loss: 1693.9939\n",
      "Epoch 228/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 1685.2812 - val_loss: 1663.0439\n",
      "Epoch 229/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1654.4427 - val_loss: 1632.5613\n",
      "Epoch 230/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 1624.0900 - val_loss: 1602.4761\n",
      "Epoch 231/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1594.1304 - val_loss: 1572.8381\n",
      "Epoch 232/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 1564.6182 - val_loss: 1543.6231\n",
      "Epoch 233/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1535.5515 - val_loss: 1514.8120\n",
      "Epoch 234/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 1506.8636 - val_loss: 1486.4494\n",
      "Epoch 235/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 1478.6066 - val_loss: 1458.5236\n",
      "Epoch 236/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1450.8078 - val_loss: 1430.9608\n",
      "Epoch 237/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 1423.3614 - val_loss: 1403.8372\n",
      "Epoch 238/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1396.3437 - val_loss: 1377.1145\n",
      "Epoch 239/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1369.7448 - val_loss: 1350.7795\n",
      "Epoch 240/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 1343.5500 - val_loss: 1324.8201\n",
      "Epoch 241/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1317.7011 - val_loss: 1299.3115\n",
      "Epoch 242/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1292.2964 - val_loss: 1274.1533\n",
      "Epoch 243/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1267.2478 - val_loss: 1249.3971\n",
      "Epoch 244/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1242.5978 - val_loss: 1225.0147\n",
      "Epoch 245/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1218.3213 - val_loss: 1201.0239\n",
      "Epoch 246/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1194.4227 - val_loss: 1177.4004\n",
      "Epoch 247/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 1170.9106 - val_loss: 1154.1504\n",
      "Epoch 248/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 1147.7680 - val_loss: 1131.2700\n",
      "Epoch 249/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1124.9918 - val_loss: 1108.7532\n",
      "Epoch 250/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1102.5787 - val_loss: 1086.6130\n",
      "Epoch 251/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1080.5325 - val_loss: 1064.8037\n",
      "Epoch 252/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1058.8398 - val_loss: 1043.3536\n",
      "Epoch 253/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1037.4671 - val_loss: 1022.2923\n",
      "Epoch 254/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 1016.4984 - val_loss: 1001.5419\n",
      "Epoch 255/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 995.8708 - val_loss: 981.1124\n",
      "Epoch 256/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 975.5302 - val_loss: 961.0812\n",
      "Epoch 257/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 955.5885 - val_loss: 941.3659\n",
      "Epoch 258/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 935.9674 - val_loss: 921.9864\n",
      "Epoch 259/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 916.6814 - val_loss: 902.9386\n",
      "Epoch 260/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 897.7312 - val_loss: 884.2085\n",
      "Epoch 261/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 879.1020 - val_loss: 865.8165\n",
      "Epoch 262/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 860.7904 - val_loss: 847.7627\n",
      "Epoch 263/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 842.8225 - val_loss: 829.9968\n",
      "Epoch 264/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 825.1528 - val_loss: 812.5490\n",
      "Epoch 265/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 807.7695 - val_loss: 795.4374\n",
      "Epoch 266/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 790.7412 - val_loss: 778.5947\n",
      "Epoch 267/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 774.0049 - val_loss: 762.0531\n",
      "Epoch 268/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 757.5346 - val_loss: 745.8535\n",
      "Epoch 269/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 741.4064 - val_loss: 729.9231\n",
      "Epoch 270/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 725.5526 - val_loss: 714.2971\n",
      "Epoch 271/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 709.9893 - val_loss: 698.9607\n",
      "Epoch 272/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 694.7364 - val_loss: 683.8903\n",
      "Epoch 273/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 679.7565 - val_loss: 669.0945\n",
      "Epoch 274/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 665.0259 - val_loss: 654.6206\n",
      "Epoch 275/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 650.6114 - val_loss: 640.4163\n",
      "Epoch 276/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 636.4790 - val_loss: 626.4455\n",
      "Epoch 277/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 622.5876 - val_loss: 612.7675\n",
      "Epoch 278/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 608.9764 - val_loss: 599.3514\n",
      "Epoch 279/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 595.6209 - val_loss: 586.2077\n",
      "Epoch 280/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 582.5409 - val_loss: 573.3213\n",
      "Epoch 281/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 569.7104 - val_loss: 560.6947\n",
      "Epoch 282/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 557.1483 - val_loss: 548.3026\n",
      "Epoch 283/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 544.8209 - val_loss: 536.1636\n",
      "Epoch 284/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 532.7506 - val_loss: 524.2544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 520.9022 - val_loss: 512.6130\n",
      "Epoch 286/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 509.3240 - val_loss: 501.2030\n",
      "Epoch 287/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 497.9781 - val_loss: 490.0411\n",
      "Epoch 288/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 486.8691 - val_loss: 479.1070\n",
      "Epoch 289/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 475.9798 - val_loss: 468.4039\n",
      "Epoch 290/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 465.3559 - val_loss: 457.8895\n",
      "Epoch 291/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 454.8941 - val_loss: 447.6579\n",
      "Epoch 292/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 444.7046 - val_loss: 437.6302\n",
      "Epoch 293/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 434.7437 - val_loss: 427.8014\n",
      "Epoch 294/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 424.9740 - val_loss: 418.1963\n",
      "Epoch 295/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 415.4042 - val_loss: 408.8322\n",
      "Epoch 296/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 406.0771 - val_loss: 399.6532\n",
      "Epoch 297/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 396.9399 - val_loss: 390.6740\n",
      "Epoch 298/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 388.0098 - val_loss: 381.8969\n",
      "Epoch 299/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 379.2857 - val_loss: 373.3102\n",
      "Epoch 300/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 370.7520 - val_loss: 364.9190\n",
      "Epoch 301/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 362.3902 - val_loss: 356.7499\n",
      "Epoch 302/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 354.2609 - val_loss: 348.7372\n",
      "Epoch 303/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 346.2922 - val_loss: 340.9154\n",
      "Epoch 304/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 338.5274 - val_loss: 333.2637\n",
      "Epoch 305/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 330.9237 - val_loss: 325.8246\n",
      "Epoch 306/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 323.5235 - val_loss: 318.5548\n",
      "Epoch 307/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 316.2735 - val_loss: 311.4814\n",
      "Epoch 308/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 309.2443 - val_loss: 304.5343\n",
      "Epoch 309/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 302.3413 - val_loss: 297.7796\n",
      "Epoch 310/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 295.6238 - val_loss: 291.1916\n",
      "Epoch 311/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 289.0639 - val_loss: 284.7729\n",
      "Epoch 312/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 282.6758 - val_loss: 278.5038\n",
      "Epoch 313/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 276.4355 - val_loss: 272.3963\n",
      "Epoch 314/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 270.3641 - val_loss: 266.4379\n",
      "Epoch 315/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 264.4276 - val_loss: 260.6551\n",
      "Epoch 316/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 258.6822 - val_loss: 254.9909\n",
      "Epoch 317/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 253.0442 - val_loss: 249.4984\n",
      "Epoch 318/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 247.5833 - val_loss: 244.1225\n",
      "Epoch 319/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 242.2396 - val_loss: 238.9071\n",
      "Epoch 320/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 237.0479 - val_loss: 233.8218\n",
      "Epoch 321/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 231.9927 - val_loss: 228.8817\n",
      "Epoch 322/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 227.0711 - val_loss: 224.0813\n",
      "Epoch 323/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 222.2898 - val_loss: 219.3980\n",
      "Epoch 324/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 217.6239 - val_loss: 214.8576\n",
      "Epoch 325/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 213.0994 - val_loss: 210.4345\n",
      "Epoch 326/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 208.7035 - val_loss: 206.1194\n",
      "Epoch 327/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 204.4178 - val_loss: 201.9286\n",
      "Epoch 328/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 200.2454 - val_loss: 197.8634\n",
      "Epoch 329/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 196.1968 - val_loss: 193.9101\n",
      "Epoch 330/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 192.2723 - val_loss: 190.0700\n",
      "Epoch 331/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 188.4465 - val_loss: 186.3559\n",
      "Epoch 332/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 184.7463 - val_loss: 182.7364\n",
      "Epoch 333/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 181.1428 - val_loss: 179.2242\n",
      "Epoch 334/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 177.6491 - val_loss: 175.8131\n",
      "Epoch 335/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 174.2512 - val_loss: 172.5121\n",
      "Epoch 336/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 170.9575 - val_loss: 169.3116\n",
      "Epoch 337/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 167.7683 - val_loss: 166.1983\n",
      "Epoch 338/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 164.6662 - val_loss: 163.1831\n",
      "Epoch 339/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 161.6763 - val_loss: 160.2450\n",
      "Epoch 340/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 158.7503 - val_loss: 157.4258\n",
      "Epoch 341/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 155.9341 - val_loss: 154.6903\n",
      "Epoch 342/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 153.2095 - val_loss: 152.0247\n",
      "Epoch 343/2000\n",
      "13621/13621 [==============================] - ETA: 0s - loss: 150.306 - 0s 16us/step - loss: 150.5572 - val_loss: 149.4447\n",
      "Epoch 344/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 147.9840 - val_loss: 146.9568\n",
      "Epoch 345/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 145.5124 - val_loss: 144.5308\n",
      "Epoch 346/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 143.0977 - val_loss: 142.2047\n",
      "Epoch 347/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 140.7778 - val_loss: 139.9574\n",
      "Epoch 348/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 138.5321 - val_loss: 137.7810\n",
      "Epoch 349/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 136.3620 - val_loss: 135.6790\n",
      "Epoch 350/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 134.2604 - val_loss: 133.6472\n",
      "Epoch 351/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 132.2401 - val_loss: 131.6686\n",
      "Epoch 352/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 130.2671 - val_loss: 129.7744\n",
      "Epoch 353/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 128.3755 - val_loss: 127.9358\n",
      "Epoch 354/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 126.5414 - val_loss: 126.1639\n",
      "Epoch 355/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 124.7766 - val_loss: 124.4503\n",
      "Epoch 356/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 123.0703 - val_loss: 122.8010\n",
      "Epoch 357/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13621/13621 [==============================] - 0s 15us/step - loss: 121.4240 - val_loss: 121.2125\n",
      "Epoch 358/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 119.8328 - val_loss: 119.6841\n",
      "Epoch 359/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 118.3129 - val_loss: 118.1966\n",
      "Epoch 360/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 116.8310 - val_loss: 116.7729\n",
      "Epoch 361/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 115.4120 - val_loss: 115.4044\n",
      "Epoch 362/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 114.0410 - val_loss: 114.0849\n",
      "Epoch 363/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 112.7160 - val_loss: 112.8216\n",
      "Epoch 364/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 111.4499 - val_loss: 111.5966\n",
      "Epoch 365/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 110.2278 - val_loss: 110.4170\n",
      "Epoch 366/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 109.0511 - val_loss: 109.2793\n",
      "Epoch 367/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 107.9101 - val_loss: 108.1941\n",
      "Epoch 368/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 106.8255 - val_loss: 107.1408\n",
      "Epoch 369/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 105.7770 - val_loss: 106.1314\n",
      "Epoch 370/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 104.7653 - val_loss: 105.1691\n",
      "Epoch 371/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 103.7977 - val_loss: 104.2457\n",
      "Epoch 372/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 102.8742 - val_loss: 103.3524\n",
      "Epoch 373/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 101.9832 - val_loss: 102.4981\n",
      "Epoch 374/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 101.1265 - val_loss: 101.6789\n",
      "Epoch 375/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 100.3027 - val_loss: 100.8959\n",
      "Epoch 376/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 99.5173 - val_loss: 100.1425\n",
      "Epoch 377/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 98.7657 - val_loss: 99.4188\n",
      "Epoch 378/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 98.0345 - val_loss: 98.7353\n",
      "Epoch 379/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 97.3473 - val_loss: 98.0696\n",
      "Epoch 380/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 96.6802 - val_loss: 97.4361\n",
      "Epoch 381/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 96.0442 - val_loss: 96.8303\n",
      "Epoch 382/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 95.4319 - val_loss: 96.2513\n",
      "Epoch 383/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 94.8528 - val_loss: 95.6931\n",
      "Epoch 384/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 94.2899 - val_loss: 95.1664\n",
      "Epoch 385/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 93.7596 - val_loss: 94.6612\n",
      "Epoch 386/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 93.2459 - val_loss: 94.1837\n",
      "Epoch 387/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 92.7682 - val_loss: 93.7146\n",
      "Epoch 388/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 92.2959 - val_loss: 93.2768\n",
      "Epoch 389/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 91.8550 - val_loss: 92.8581\n",
      "Epoch 390/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 91.4283 - val_loss: 92.4619\n",
      "Epoch 391/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 91.0313 - val_loss: 92.0753\n",
      "Epoch 392/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 90.6409 - val_loss: 91.7167\n",
      "Epoch 393/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 90.2767 - val_loss: 91.3728\n",
      "Epoch 394/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 89.9245 - val_loss: 91.0474\n",
      "Epoch 395/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 89.5945 - val_loss: 90.7336\n",
      "Epoch 396/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 89.2778 - val_loss: 90.4354\n",
      "Epoch 397/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 88.9746 - val_loss: 90.1530\n",
      "Epoch 398/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 88.6871 - val_loss: 89.8848\n",
      "Epoch 399/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 88.4130 - val_loss: 89.6292\n",
      "Epoch 400/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 88.1549 - val_loss: 89.3842\n",
      "Epoch 401/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 87.9065 - val_loss: 89.1543\n",
      "Epoch 402/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 87.6732 - val_loss: 88.9360\n",
      "Epoch 403/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 87.4494 - val_loss: 88.7333\n",
      "Epoch 404/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 87.2375 - val_loss: 88.5412\n",
      "Epoch 405/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 87.0390 - val_loss: 88.3555\n",
      "Epoch 406/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 86.8488 - val_loss: 88.1797\n",
      "Epoch 407/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 86.6681 - val_loss: 88.0159\n",
      "Epoch 408/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 86.4987 - val_loss: 87.8578\n",
      "Epoch 409/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 86.3360 - val_loss: 87.7079\n",
      "Epoch 410/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 86.1807 - val_loss: 87.5669\n",
      "Epoch 411/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 86.0366 - val_loss: 87.4311\n",
      "Epoch 412/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 85.8972 - val_loss: 87.3056\n",
      "Epoch 413/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 85.7677 - val_loss: 87.1879\n",
      "Epoch 414/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 85.6447 - val_loss: 87.0769\n",
      "Epoch 415/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 85.5283 - val_loss: 86.9722\n",
      "Epoch 416/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 85.4198 - val_loss: 86.8733\n",
      "Epoch 417/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 85.3153 - val_loss: 86.7823\n",
      "Epoch 418/2000\n",
      "13621/13621 [==============================] - ETA: 0s - loss: 84.92 - 0s 15us/step - loss: 85.2192 - val_loss: 86.6960\n",
      "Epoch 419/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 85.1294 - val_loss: 86.6134\n",
      "Epoch 420/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 85.0439 - val_loss: 86.5339\n",
      "Epoch 421/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 84.9609 - val_loss: 86.4616\n",
      "Epoch 422/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 84.8819 - val_loss: 86.3973\n",
      "Epoch 423/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 84.8141 - val_loss: 86.3311\n",
      "Epoch 424/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 84.7433 - val_loss: 86.2726\n",
      "Epoch 425/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 84.6808 - val_loss: 86.2170\n",
      "Epoch 426/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 84.6219 - val_loss: 86.1632\n",
      "Epoch 427/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 84.5650 - val_loss: 86.1134\n",
      "Epoch 428/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 84.5099 - val_loss: 86.0705\n",
      "Epoch 429/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 84.4631 - val_loss: 86.0267\n",
      "Epoch 430/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13621/13621 [==============================] - 0s 15us/step - loss: 84.4155 - val_loss: 85.9869\n",
      "Epoch 431/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 84.3719 - val_loss: 85.9500\n",
      "Epoch 432/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 84.3313 - val_loss: 85.9151\n",
      "Epoch 433/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 84.2946 - val_loss: 85.8808\n",
      "Epoch 434/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 84.2562 - val_loss: 85.8517\n",
      "Epoch 435/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 84.2230 - val_loss: 85.8245\n",
      "Epoch 436/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 84.1923 - val_loss: 85.7989\n",
      "Epoch 437/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 84.1632 - val_loss: 85.7746\n",
      "Epoch 438/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 84.1353 - val_loss: 85.7533\n",
      "Epoch 439/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 84.1112 - val_loss: 85.7321\n",
      "Epoch 440/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 84.0868 - val_loss: 85.7131\n",
      "Epoch 441/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 84.0640 - val_loss: 85.6958\n",
      "Epoch 442/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 84.0441 - val_loss: 85.6787\n",
      "Epoch 443/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 84.0251 - val_loss: 85.6630\n",
      "Epoch 444/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 84.0061 - val_loss: 85.6494\n",
      "Epoch 445/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.9905 - val_loss: 85.6357\n",
      "Epoch 446/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.9738 - val_loss: 85.6247\n",
      "Epoch 447/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.9606 - val_loss: 85.6138\n",
      "Epoch 448/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.9470 - val_loss: 85.6042\n",
      "Epoch 449/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.9350 - val_loss: 85.5948\n",
      "Epoch 450/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.9234 - val_loss: 85.5865\n",
      "Epoch 451/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.9124 - val_loss: 85.5794\n",
      "Epoch 452/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.9037 - val_loss: 85.5718\n",
      "Epoch 453/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8941 - val_loss: 85.5659\n",
      "Epoch 454/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8859 - val_loss: 85.5606\n",
      "Epoch 455/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8786 - val_loss: 85.5552\n",
      "Epoch 456/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8713 - val_loss: 85.5507\n",
      "Epoch 457/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8652 - val_loss: 85.5464\n",
      "Epoch 458/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8590 - val_loss: 85.5424\n",
      "Epoch 459/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8525 - val_loss: 85.5390\n",
      "Epoch 460/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8479 - val_loss: 85.5356\n",
      "Epoch 461/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8425 - val_loss: 85.5334\n",
      "Epoch 462/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8386 - val_loss: 85.5308\n",
      "Epoch 463/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.8346 - val_loss: 85.5285\n",
      "Epoch 464/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8312 - val_loss: 85.5263\n",
      "Epoch 465/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8273 - val_loss: 85.5249\n",
      "Epoch 466/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8243 - val_loss: 85.5236\n",
      "Epoch 467/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8217 - val_loss: 85.5221\n",
      "Epoch 468/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.8188 - val_loss: 85.5209\n",
      "Epoch 469/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.8163 - val_loss: 85.5199\n",
      "Epoch 470/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 83.8142 - val_loss: 85.5190\n",
      "Epoch 471/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 83.8125 - val_loss: 85.5181\n",
      "Epoch 472/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 83.8103 - val_loss: 85.5175\n",
      "Epoch 473/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.8086 - val_loss: 85.5170\n",
      "Epoch 474/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8069 - val_loss: 85.5167\n",
      "Epoch 475/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.8057 - val_loss: 85.5163\n",
      "Epoch 476/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8045 - val_loss: 85.5160\n",
      "Epoch 477/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8032 - val_loss: 85.5159\n",
      "Epoch 478/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8022 - val_loss: 85.5157\n",
      "Epoch 479/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8013 - val_loss: 85.5157\n",
      "Epoch 480/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8004 - val_loss: 85.5157\n",
      "Epoch 481/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7995 - val_loss: 85.5157\n",
      "Epoch 482/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7987 - val_loss: 85.5157\n",
      "Epoch 483/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7980 - val_loss: 85.5158\n",
      "Epoch 484/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7975 - val_loss: 85.5160\n",
      "Epoch 485/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7968 - val_loss: 85.5161\n",
      "Epoch 486/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7966 - val_loss: 85.5163\n",
      "Epoch 487/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7960 - val_loss: 85.5163\n",
      "Epoch 488/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7957 - val_loss: 85.5165\n",
      "Epoch 489/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7955 - val_loss: 85.5167\n",
      "Epoch 490/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7951 - val_loss: 85.5170\n",
      "Epoch 491/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7946 - val_loss: 85.5172\n",
      "Epoch 492/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7946 - val_loss: 85.5172\n",
      "Epoch 493/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7944 - val_loss: 85.5177\n",
      "Epoch 494/2000\n",
      "13621/13621 [==============================] - 0s 17us/step - loss: 83.7939 - val_loss: 85.5179\n",
      "Epoch 495/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7940 - val_loss: 85.5183\n",
      "Epoch 496/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7935 - val_loss: 85.5184\n",
      "Epoch 497/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7934 - val_loss: 85.5185\n",
      "Epoch 498/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7933 - val_loss: 85.5187\n",
      "Epoch 499/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7933 - val_loss: 85.5190\n",
      "Epoch 500/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7931 - val_loss: 85.5192\n",
      "Epoch 501/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7930 - val_loss: 85.5192\n",
      "Epoch 502/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7928 - val_loss: 85.5195\n",
      "Epoch 503/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7928 - val_loss: 85.5198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7926 - val_loss: 85.5200\n",
      "Epoch 505/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7926 - val_loss: 85.5201\n",
      "Epoch 506/2000\n",
      "13621/13621 [==============================] - ETA: 0s - loss: 83.50 - 0s 16us/step - loss: 83.7927 - val_loss: 85.5203\n",
      "Epoch 507/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7926 - val_loss: 85.5207\n",
      "Epoch 508/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7925 - val_loss: 85.5206\n",
      "Epoch 509/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5207\n",
      "Epoch 510/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7925 - val_loss: 85.5209\n",
      "Epoch 511/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5210\n",
      "Epoch 512/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5210\n",
      "Epoch 513/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5213\n",
      "Epoch 514/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5214\n",
      "Epoch 515/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7929 - val_loss: 85.5211\n",
      "Epoch 516/2000\n",
      "13621/13621 [==============================] - 0s 17us/step - loss: 83.7923 - val_loss: 85.5214\n",
      "Epoch 517/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 83.7922 - val_loss: 85.5216\n",
      "Epoch 518/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7925 - val_loss: 85.5214\n",
      "Epoch 519/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5221\n",
      "Epoch 520/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7924 - val_loss: 85.5219\n",
      "Epoch 521/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5225\n",
      "Epoch 522/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 83.7923 - val_loss: 85.5225\n",
      "Epoch 523/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 83.7922 - val_loss: 85.5226\n",
      "Epoch 524/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 83.7921 - val_loss: 85.5227\n",
      "Epoch 525/2000\n",
      "13621/13621 [==============================] - 0s 10us/step - loss: 83.7922 - val_loss: 85.5231\n",
      "Epoch 526/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 83.7922 - val_loss: 85.5230\n",
      "Epoch 527/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5228\n",
      "Epoch 528/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5227\n",
      "Epoch 529/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7922 - val_loss: 85.5229\n",
      "Epoch 530/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7922 - val_loss: 85.5227\n",
      "Epoch 531/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5229\n",
      "Epoch 532/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7925 - val_loss: 85.5225\n",
      "Epoch 533/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5226\n",
      "Epoch 534/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5226\n",
      "Epoch 535/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7921 - val_loss: 85.5227\n",
      "Epoch 536/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5229\n",
      "Epoch 537/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5228\n",
      "Epoch 538/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5232\n",
      "Epoch 539/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5237\n",
      "Epoch 540/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5238\n",
      "Epoch 541/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5235\n",
      "Epoch 542/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5231\n",
      "Epoch 543/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5235\n",
      "Epoch 544/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7921 - val_loss: 85.5231\n",
      "Epoch 545/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5235\n",
      "Epoch 546/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7922 - val_loss: 85.5231\n",
      "Epoch 547/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5231\n",
      "Epoch 548/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5230\n",
      "Epoch 549/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5229\n",
      "Epoch 550/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5235\n",
      "Epoch 551/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5236\n",
      "Epoch 552/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5231\n",
      "Epoch 553/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5235\n",
      "Epoch 554/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7921 - val_loss: 85.5236\n",
      "Epoch 555/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5234\n",
      "Epoch 556/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5231\n",
      "Epoch 557/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5231\n",
      "Epoch 558/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5232\n",
      "Epoch 559/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5228\n",
      "Epoch 560/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7922 - val_loss: 85.5232\n",
      "Epoch 561/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5228\n",
      "Epoch 562/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5226\n",
      "Epoch 563/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5227\n",
      "Epoch 564/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5226\n",
      "Epoch 565/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5234\n",
      "Epoch 566/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5235\n",
      "Epoch 567/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5236\n",
      "Epoch 568/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5235\n",
      "Epoch 569/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5232\n",
      "Epoch 570/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5235\n",
      "Epoch 571/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5234\n",
      "Epoch 572/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5238\n",
      "Epoch 573/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7928 - val_loss: 85.5226\n",
      "Epoch 574/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7925 - val_loss: 85.5233\n",
      "Epoch 575/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5229\n",
      "Epoch 576/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5227\n",
      "Epoch 577/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5227\n",
      "Epoch 578/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7925 - val_loss: 85.5232\n",
      "Epoch 579/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5225\n",
      "Epoch 580/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5229\n",
      "Epoch 581/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5227\n",
      "Epoch 582/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7922 - val_loss: 85.5230\n",
      "Epoch 583/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5234\n",
      "Epoch 584/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5232\n",
      "Epoch 585/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7920 - val_loss: 85.5235\n",
      "Epoch 586/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7926 - val_loss: 85.5233\n",
      "Epoch 587/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7920 - val_loss: 85.5236\n",
      "Epoch 588/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5237\n",
      "Epoch 589/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5234\n",
      "Epoch 590/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5237\n",
      "Epoch 591/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5243\n",
      "Epoch 592/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5237\n",
      "Epoch 593/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5237\n",
      "Epoch 594/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7925 - val_loss: 85.5234\n",
      "Epoch 595/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5234\n",
      "Epoch 596/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5229\n",
      "Epoch 597/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7925 - val_loss: 85.5224\n",
      "Epoch 598/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5225\n",
      "Epoch 599/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5235\n",
      "Epoch 600/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5230\n",
      "Epoch 601/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5230\n",
      "Epoch 602/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7927 - val_loss: 85.5220\n",
      "Epoch 603/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7926 - val_loss: 85.5232\n",
      "Epoch 604/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5228\n",
      "Epoch 605/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7922 - val_loss: 85.5225\n",
      "Epoch 606/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7921 - val_loss: 85.5224\n",
      "Epoch 607/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7929 - val_loss: 85.5233\n",
      "Epoch 608/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7923 - val_loss: 85.5233\n",
      "Epoch 609/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7921 - val_loss: 85.5225\n",
      "Epoch 610/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5221\n",
      "Epoch 611/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5229\n",
      "Epoch 612/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5230\n",
      "Epoch 613/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5222\n",
      "Epoch 614/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7923 - val_loss: 85.5226\n",
      "Epoch 615/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 83.7923 - val_loss: 85.5221\n",
      "Epoch 616/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 83.7924 - val_loss: 85.5227\n",
      "Epoch 617/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7921 - val_loss: 85.5223\n",
      "Epoch 618/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7925 - val_loss: 85.5224\n",
      "Epoch 619/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7925 - val_loss: 85.5218\n",
      "Epoch 620/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7925 - val_loss: 85.5231\n",
      "Epoch 621/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5225\n",
      "Epoch 622/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5234\n",
      "Epoch 623/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7921 - val_loss: 85.5233\n",
      "Epoch 624/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7920 - val_loss: 85.5230\n",
      "Epoch 625/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5226\n",
      "Epoch 626/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5230\n",
      "Epoch 627/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5222\n",
      "Epoch 628/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5229\n",
      "Epoch 629/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5230\n",
      "Epoch 630/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5226\n",
      "Epoch 631/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5226\n",
      "Epoch 632/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7921 - val_loss: 85.5227\n",
      "Epoch 633/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5227\n",
      "Epoch 634/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7920 - val_loss: 85.5223\n",
      "Epoch 635/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5223\n",
      "Epoch 636/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5226\n",
      "Epoch 637/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7927 - val_loss: 85.5218\n",
      "Epoch 638/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5229\n",
      "Epoch 639/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7920 - val_loss: 85.5231\n",
      "Epoch 640/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7920 - val_loss: 85.5229\n",
      "Epoch 641/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7933 - val_loss: 85.5216\n",
      "Epoch 642/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7927 - val_loss: 85.5218\n",
      "Epoch 643/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7922 - val_loss: 85.5220\n",
      "Epoch 644/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5231\n",
      "Epoch 645/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7927 - val_loss: 85.5223\n",
      "Epoch 646/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7926 - val_loss: 85.5235\n",
      "Epoch 647/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7920 - val_loss: 85.5232\n",
      "Epoch 648/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5228\n",
      "Epoch 649/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5236\n",
      "Epoch 650/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 651/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5236\n",
      "Epoch 652/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7928 - val_loss: 85.5224\n",
      "Epoch 653/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7927 - val_loss: 85.5236\n",
      "Epoch 654/2000\n",
      "13621/13621 [==============================] - ETA: 0s - loss: 83.76 - 0s 15us/step - loss: 83.7921 - val_loss: 85.5234\n",
      "Epoch 655/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5236\n",
      "Epoch 656/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7920 - val_loss: 85.5232\n",
      "Epoch 657/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5231\n",
      "Epoch 658/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7924 - val_loss: 85.5222\n",
      "Epoch 659/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5226\n",
      "Epoch 660/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5219\n",
      "Epoch 661/2000\n",
      "13621/13621 [==============================] - 0s 18us/step - loss: 83.7926 - val_loss: 85.5213\n",
      "Epoch 662/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 83.7922 - val_loss: 85.5224\n",
      "Epoch 663/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7920 - val_loss: 85.5229\n",
      "Epoch 664/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5233\n",
      "Epoch 665/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7920 - val_loss: 85.5228\n",
      "Epoch 666/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7925 - val_loss: 85.5238\n",
      "Epoch 667/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7923 - val_loss: 85.5224\n",
      "Epoch 668/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7922 - val_loss: 85.5225\n",
      "Epoch 669/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7921 - val_loss: 85.5233\n",
      "Epoch 670/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7925 - val_loss: 85.5238\n",
      "Epoch 671/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5234\n",
      "Epoch 672/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5234\n",
      "Epoch 673/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5230\n",
      "Epoch 674/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7928 - val_loss: 85.5218\n",
      "Epoch 675/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7931 - val_loss: 85.5234\n",
      "Epoch 676/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5220\n",
      "Epoch 677/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7929 - val_loss: 85.5232\n",
      "Epoch 678/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7920 - val_loss: 85.5226\n",
      "Epoch 679/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7923 - val_loss: 85.5214\n",
      "Epoch 680/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7920 - val_loss: 85.5214\n",
      "Epoch 681/2000\n",
      "13621/13621 [==============================] - ETA: 0s - loss: 83.85 - 0s 15us/step - loss: 83.7921 - val_loss: 85.5215\n",
      "Epoch 682/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5215\n",
      "Epoch 683/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5218\n",
      "Epoch 684/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7940 - val_loss: 85.5236\n",
      "Epoch 685/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7946 - val_loss: 85.5208\n",
      "Epoch 686/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7925 - val_loss: 85.5213\n",
      "Epoch 687/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5225\n",
      "Epoch 688/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5226\n",
      "Epoch 689/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5233\n",
      "Epoch 690/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5231\n",
      "Epoch 691/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5230\n",
      "Epoch 692/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7925 - val_loss: 85.5215\n",
      "Epoch 693/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7931 - val_loss: 85.5206\n",
      "Epoch 694/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7918 - val_loss: 85.5218\n",
      "Epoch 695/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5223\n",
      "Epoch 696/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5217\n",
      "Epoch 697/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7933 - val_loss: 85.5244\n",
      "Epoch 698/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7920 - val_loss: 85.5236\n",
      "Epoch 699/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7919 - val_loss: 85.5225\n",
      "Epoch 700/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5230\n",
      "Epoch 701/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5215\n",
      "Epoch 702/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7926 - val_loss: 85.5209\n",
      "Epoch 703/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7920 - val_loss: 85.5218\n",
      "Epoch 704/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5219\n",
      "Epoch 705/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5235\n",
      "Epoch 706/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7922 - val_loss: 85.5235\n",
      "Epoch 707/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5235\n",
      "Epoch 708/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7927 - val_loss: 85.5221\n",
      "Epoch 709/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5227\n",
      "Epoch 710/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7936 - val_loss: 85.5211\n",
      "Epoch 711/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7922 - val_loss: 85.5223\n",
      "Epoch 712/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7921 - val_loss: 85.5229\n",
      "Epoch 713/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7919 - val_loss: 85.5223\n",
      "Epoch 714/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5215\n",
      "Epoch 715/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7925 - val_loss: 85.5218\n",
      "Epoch 716/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7925 - val_loss: 85.5222\n",
      "Epoch 717/2000\n",
      "13621/13621 [==============================] - 0s 11us/step - loss: 83.7927 - val_loss: 85.5213\n",
      "Epoch 718/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 83.7921 - val_loss: 85.5213\n",
      "Epoch 719/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 83.7934 - val_loss: 85.5231\n",
      "Epoch 720/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 83.7920 - val_loss: 85.5227\n",
      "Epoch 721/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7923 - val_loss: 85.5228\n",
      "Epoch 722/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5232\n",
      "Epoch 723/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5224\n",
      "Epoch 724/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7920 - val_loss: 85.5219\n",
      "Epoch 725/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7938 - val_loss: 85.5194\n",
      "Epoch 726/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7920 - val_loss: 85.5208\n",
      "Epoch 727/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5222\n",
      "Epoch 728/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5229\n",
      "Epoch 729/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7924 - val_loss: 85.5239\n",
      "Epoch 730/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7930 - val_loss: 85.5219\n",
      "Epoch 731/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7927 - val_loss: 85.5218\n",
      "Epoch 732/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7925 - val_loss: 85.5232\n",
      "Epoch 733/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7932 - val_loss: 85.5240\n",
      "Epoch 734/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7933 - val_loss: 85.5219\n",
      "Epoch 735/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7920 - val_loss: 85.5226\n",
      "Epoch 736/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7936 - val_loss: 85.5238\n",
      "Epoch 737/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7927 - val_loss: 85.5226\n",
      "Epoch 738/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7932 - val_loss: 85.5202\n",
      "Epoch 739/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7927 - val_loss: 85.5213\n",
      "Epoch 740/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7923 - val_loss: 85.5206\n",
      "Epoch 741/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5215\n",
      "Epoch 742/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7936 - val_loss: 85.5202\n",
      "Epoch 743/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5203\n",
      "Epoch 744/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7938 - val_loss: 85.5233\n",
      "Epoch 745/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7931 - val_loss: 85.5208\n",
      "Epoch 746/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7920 - val_loss: 85.5211\n",
      "Epoch 747/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7925 - val_loss: 85.5228\n",
      "Epoch 748/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7928 - val_loss: 85.5234\n",
      "Epoch 749/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 83.7958 - val_loss: 85.5193\n",
      "Epoch 750/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7918 - val_loss: 85.5203\n",
      "Epoch 751/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7941 - val_loss: 85.5241\n",
      "Epoch 752/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5228\n",
      "Epoch 753/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5213\n",
      "Epoch 754/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7920 - val_loss: 85.5212\n",
      "Epoch 755/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5214\n",
      "Epoch 756/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7919 - val_loss: 85.5230\n",
      "Epoch 757/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7923 - val_loss: 85.5229\n",
      "Epoch 758/2000\n",
      "13621/13621 [==============================] - ETA: 0s - loss: 83.45 - 0s 16us/step - loss: 83.7929 - val_loss: 85.5219\n",
      "Epoch 759/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7922 - val_loss: 85.5248\n",
      "Epoch 760/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 83.7931 - val_loss: 85.5246\n",
      "Epoch 761/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7926 - val_loss: 85.5220\n",
      "Epoch 762/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7928 - val_loss: 85.5212\n",
      "Epoch 763/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7928 - val_loss: 85.5231\n",
      "Epoch 764/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5227\n",
      "Epoch 765/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5232\n",
      "Epoch 766/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7939 - val_loss: 85.5216\n",
      "Epoch 767/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5219\n",
      "Epoch 768/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5228\n",
      "Epoch 769/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7925 - val_loss: 85.5237\n",
      "Epoch 770/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7919 - val_loss: 85.5221\n",
      "Epoch 771/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7920 - val_loss: 85.5209\n",
      "Epoch 772/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7926 - val_loss: 85.5220\n",
      "Epoch 773/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7918 - val_loss: 85.5208\n",
      "Epoch 774/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5206\n",
      "Epoch 775/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7927 - val_loss: 85.5207\n",
      "Epoch 776/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7931 - val_loss: 85.5194\n",
      "Epoch 777/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5207\n",
      "Epoch 778/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5224\n",
      "Epoch 779/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7925 - val_loss: 85.5231\n",
      "Epoch 780/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5225\n",
      "Epoch 781/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7942 - val_loss: 85.5191\n",
      "Epoch 782/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7929 - val_loss: 85.5220\n",
      "Epoch 783/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7922 - val_loss: 85.5217\n",
      "Epoch 784/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5206\n",
      "Epoch 785/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7923 - val_loss: 85.5214\n",
      "Epoch 786/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7931 - val_loss: 85.5234\n",
      "Epoch 787/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7922 - val_loss: 85.5207\n",
      "Epoch 788/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5219\n",
      "Epoch 789/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5228\n",
      "Epoch 790/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5222\n",
      "Epoch 791/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7923 - val_loss: 85.5229\n",
      "Epoch 792/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7939 - val_loss: 85.5204\n",
      "Epoch 793/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7940 - val_loss: 85.5230\n",
      "Epoch 794/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7927 - val_loss: 85.5221\n",
      "Epoch 795/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5222\n",
      "Epoch 796/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7933 - val_loss: 85.5198\n",
      "Epoch 797/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13621/13621 [==============================] - ETA: 0s - loss: 84.05 - 0s 15us/step - loss: 83.7920 - val_loss: 85.5205\n",
      "Epoch 798/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7928 - val_loss: 85.5223\n",
      "Epoch 799/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7939 - val_loss: 85.5237\n",
      "Epoch 800/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7918 - val_loss: 85.5216\n",
      "Epoch 801/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5215\n",
      "Epoch 802/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7927 - val_loss: 85.5203\n",
      "Epoch 803/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7928 - val_loss: 85.5214\n",
      "Epoch 804/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5213\n",
      "Epoch 805/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7955 - val_loss: 85.5190\n",
      "Epoch 806/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7913 - val_loss: 85.5218\n",
      "Epoch 807/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 83.7919 - val_loss: 85.5240\n",
      "Epoch 808/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7929 - val_loss: 85.5238\n",
      "Epoch 809/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5229\n",
      "Epoch 810/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5228\n",
      "Epoch 811/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7925 - val_loss: 85.5226\n",
      "Epoch 812/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 83.7925 - val_loss: 85.5201\n",
      "Epoch 813/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7925 - val_loss: 85.5195\n",
      "Epoch 814/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7921 - val_loss: 85.5218\n",
      "Epoch 815/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5232\n",
      "Epoch 816/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7928 - val_loss: 85.5240\n",
      "Epoch 817/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7929 - val_loss: 85.5205\n",
      "Epoch 818/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5212\n",
      "Epoch 819/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7928 - val_loss: 85.5207\n",
      "Epoch 820/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7941 - val_loss: 85.5192\n",
      "Epoch 821/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7925 - val_loss: 85.5201\n",
      "Epoch 822/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7919 - val_loss: 85.5233\n",
      "Epoch 823/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7926 - val_loss: 85.5245\n",
      "Epoch 824/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7927 - val_loss: 85.5248\n",
      "Epoch 825/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7925 - val_loss: 85.5249\n",
      "Epoch 826/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7932 - val_loss: 85.5256\n",
      "Epoch 827/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7930 - val_loss: 85.5206\n",
      "Epoch 828/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7940 - val_loss: 85.5223\n",
      "Epoch 829/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7928 - val_loss: 85.5215\n",
      "Epoch 830/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7918 - val_loss: 85.5223\n",
      "Epoch 831/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5214\n",
      "Epoch 832/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5229\n",
      "Epoch 833/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7925 - val_loss: 85.5229\n",
      "Epoch 834/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5220\n",
      "Epoch 835/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7932 - val_loss: 85.5192\n",
      "Epoch 836/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5199\n",
      "Epoch 837/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5216\n",
      "Epoch 838/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7934 - val_loss: 85.5198\n",
      "Epoch 839/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8011 - val_loss: 85.5277\n",
      "Epoch 840/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7957 - val_loss: 85.5217\n",
      "Epoch 841/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7926 - val_loss: 85.5200\n",
      "Epoch 842/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7926 - val_loss: 85.5219\n",
      "Epoch 843/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7931 - val_loss: 85.5218\n",
      "Epoch 844/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7937 - val_loss: 85.5241\n",
      "Epoch 845/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7929 - val_loss: 85.5201\n",
      "Epoch 846/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7927 - val_loss: 85.5224\n",
      "Epoch 847/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5205\n",
      "Epoch 848/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5199\n",
      "Epoch 849/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7920 - val_loss: 85.5198\n",
      "Epoch 850/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5201\n",
      "Epoch 851/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7932 - val_loss: 85.5250\n",
      "Epoch 852/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7927 - val_loss: 85.5223\n",
      "Epoch 853/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7932 - val_loss: 85.5239\n",
      "Epoch 854/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5214\n",
      "Epoch 855/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7927 - val_loss: 85.5213\n",
      "Epoch 856/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7924 - val_loss: 85.5204\n",
      "Epoch 857/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7933 - val_loss: 85.5186\n",
      "Epoch 858/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7936 - val_loss: 85.5183\n",
      "Epoch 859/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7914 - val_loss: 85.5220\n",
      "Epoch 860/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7918 - val_loss: 85.5251\n",
      "Epoch 861/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7931 - val_loss: 85.5257\n",
      "Epoch 862/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7936 - val_loss: 85.5269\n",
      "Epoch 863/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7936 - val_loss: 85.5200\n",
      "Epoch 864/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7920 - val_loss: 85.5218\n",
      "Epoch 865/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7950 - val_loss: 85.5256\n",
      "Epoch 866/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7919 - val_loss: 85.5213\n",
      "Epoch 867/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7935 - val_loss: 85.5197\n",
      "Epoch 868/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7926 - val_loss: 85.5224\n",
      "Epoch 869/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7928 - val_loss: 85.5197\n",
      "Epoch 870/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7918 - val_loss: 85.5210\n",
      "Epoch 871/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7939 - val_loss: 85.5264\n",
      "Epoch 872/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7932 - val_loss: 85.5240\n",
      "Epoch 873/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7939 - val_loss: 85.5195\n",
      "Epoch 874/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5207\n",
      "Epoch 875/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7928 - val_loss: 85.5200\n",
      "Epoch 876/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7935 - val_loss: 85.5231\n",
      "Epoch 877/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7931 - val_loss: 85.5193\n",
      "Epoch 878/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5200\n",
      "Epoch 879/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5204\n",
      "Epoch 880/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7946 - val_loss: 85.5227\n",
      "Epoch 881/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7930 - val_loss: 85.5185\n",
      "Epoch 882/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7950 - val_loss: 85.5236\n",
      "Epoch 883/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7950 - val_loss: 85.5176\n",
      "Epoch 884/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5201\n",
      "Epoch 885/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7952 - val_loss: 85.5236\n",
      "Epoch 886/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7929 - val_loss: 85.5240\n",
      "Epoch 887/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7919 - val_loss: 85.5225\n",
      "Epoch 888/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5205\n",
      "Epoch 889/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7924 - val_loss: 85.5192\n",
      "Epoch 890/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7929 - val_loss: 85.5191\n",
      "Epoch 891/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5218\n",
      "Epoch 892/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7929 - val_loss: 85.5214\n",
      "Epoch 893/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7926 - val_loss: 85.5227\n",
      "Epoch 894/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7928 - val_loss: 85.5241\n",
      "Epoch 895/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7929 - val_loss: 85.5200\n",
      "Epoch 896/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7955 - val_loss: 85.5246\n",
      "Epoch 897/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7935 - val_loss: 85.5255\n",
      "Epoch 898/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7930 - val_loss: 85.5186\n",
      "Epoch 899/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7938 - val_loss: 85.5183\n",
      "Epoch 900/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7931 - val_loss: 85.5241\n",
      "Epoch 901/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7948 - val_loss: 85.5206\n",
      "Epoch 902/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 83.7945 - val_loss: 85.5232\n",
      "Epoch 903/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 83.7945 - val_loss: 85.5208\n",
      "Epoch 904/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 83.7947 - val_loss: 85.5179\n",
      "Epoch 905/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7924 - val_loss: 85.5197\n",
      "Epoch 906/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7918 - val_loss: 85.5220\n",
      "Epoch 907/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7926 - val_loss: 85.5227\n",
      "Epoch 908/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7938 - val_loss: 85.5199\n",
      "Epoch 909/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7914 - val_loss: 85.5228\n",
      "Epoch 910/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5273\n",
      "Epoch 911/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7930 - val_loss: 85.5234\n",
      "Epoch 912/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7949 - val_loss: 85.5221\n",
      "Epoch 913/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7944 - val_loss: 85.5200\n",
      "Epoch 914/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7920 - val_loss: 85.5249\n",
      "Epoch 915/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7928 - val_loss: 85.5223\n",
      "Epoch 916/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7944 - val_loss: 85.5263\n",
      "Epoch 917/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7933 - val_loss: 85.5235\n",
      "Epoch 918/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5181\n",
      "Epoch 919/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7942 - val_loss: 85.5163\n",
      "Epoch 920/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7961 - val_loss: 85.5228\n",
      "Epoch 921/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7944 - val_loss: 85.5225\n",
      "Epoch 922/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7992 - val_loss: 85.5284\n",
      "Epoch 923/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7951 - val_loss: 85.5175\n",
      "Epoch 924/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7949 - val_loss: 85.5226\n",
      "Epoch 925/2000\n",
      "13621/13621 [==============================] - ETA: 0s - loss: 83.41 - 0s 15us/step - loss: 83.7929 - val_loss: 85.5225\n",
      "Epoch 926/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7938 - val_loss: 85.5201\n",
      "Epoch 927/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7952 - val_loss: 85.5275\n",
      "Epoch 928/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7954 - val_loss: 85.5201\n",
      "Epoch 929/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7938 - val_loss: 85.5183\n",
      "Epoch 930/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7920 - val_loss: 85.5221\n",
      "Epoch 931/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7934 - val_loss: 85.5215\n",
      "Epoch 932/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7952 - val_loss: 85.5283\n",
      "Epoch 933/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7937 - val_loss: 85.5212\n",
      "Epoch 934/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7942 - val_loss: 85.5181\n",
      "Epoch 935/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7931 - val_loss: 85.5193\n",
      "Epoch 936/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5240\n",
      "Epoch 937/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7944 - val_loss: 85.5275\n",
      "Epoch 938/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7914 - val_loss: 85.5221\n",
      "Epoch 939/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5199\n",
      "Epoch 940/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7941 - val_loss: 85.5177\n",
      "Epoch 941/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7960 - val_loss: 85.5243\n",
      "Epoch 942/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7934 - val_loss: 85.5220\n",
      "Epoch 943/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7926 - val_loss: 85.5194\n",
      "Epoch 944/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7923 - val_loss: 85.5225\n",
      "Epoch 945/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7920 - val_loss: 85.5210\n",
      "Epoch 946/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7953 - val_loss: 85.5210\n",
      "Epoch 947/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7954 - val_loss: 85.5209\n",
      "Epoch 948/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8010 - val_loss: 85.5157\n",
      "Epoch 949/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7937 - val_loss: 85.5270\n",
      "Epoch 950/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7971 - val_loss: 85.5273\n",
      "Epoch 951/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7921 - val_loss: 85.5178\n",
      "Epoch 952/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7930 - val_loss: 85.5192\n",
      "Epoch 953/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7935 - val_loss: 85.5171\n",
      "Epoch 954/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7930 - val_loss: 85.5213\n",
      "Epoch 955/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 83.7933 - val_loss: 85.5246\n",
      "Epoch 956/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7985 - val_loss: 85.5166\n",
      "Epoch 957/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7935 - val_loss: 85.5263\n",
      "Epoch 958/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7951 - val_loss: 85.5218\n",
      "Epoch 959/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7956 - val_loss: 85.5218\n",
      "Epoch 960/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7959 - val_loss: 85.5181\n",
      "Epoch 961/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7944 - val_loss: 85.5232\n",
      "Epoch 962/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5210\n",
      "Epoch 963/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7938 - val_loss: 85.5218\n",
      "Epoch 964/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7943 - val_loss: 85.5174\n",
      "Epoch 965/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7951 - val_loss: 85.5197\n",
      "Epoch 966/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7974 - val_loss: 85.5288\n",
      "Epoch 967/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7968 - val_loss: 85.5243\n",
      "Epoch 968/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7916 - val_loss: 85.5177\n",
      "Epoch 969/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7925 - val_loss: 85.5179\n",
      "Epoch 970/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8001 - val_loss: 85.5250\n",
      "Epoch 971/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7926 - val_loss: 85.5230\n",
      "Epoch 972/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7925 - val_loss: 85.5171\n",
      "Epoch 973/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7950 - val_loss: 85.5196\n",
      "Epoch 974/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7938 - val_loss: 85.5218\n",
      "Epoch 975/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7930 - val_loss: 85.5205\n",
      "Epoch 976/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7930 - val_loss: 85.5234\n",
      "Epoch 977/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.8085 - val_loss: 85.5369\n",
      "Epoch 978/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7961 - val_loss: 85.5184\n",
      "Epoch 979/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7930 - val_loss: 85.5177\n",
      "Epoch 980/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7935 - val_loss: 85.5218\n",
      "Epoch 981/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7937 - val_loss: 85.5178\n",
      "Epoch 982/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7925 - val_loss: 85.5192\n",
      "Epoch 983/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7918 - val_loss: 85.5213\n",
      "Epoch 984/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7962 - val_loss: 85.5203\n",
      "Epoch 985/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7928 - val_loss: 85.5234\n",
      "Epoch 986/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7934 - val_loss: 85.5249\n",
      "Epoch 987/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7955 - val_loss: 85.5168\n",
      "Epoch 988/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7929 - val_loss: 85.5192\n",
      "Epoch 989/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7935 - val_loss: 85.5269\n",
      "Epoch 990/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7961 - val_loss: 85.5178\n",
      "Epoch 991/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7948 - val_loss: 85.5220\n",
      "Epoch 992/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7936 - val_loss: 85.5198\n",
      "Epoch 993/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7940 - val_loss: 85.5226\n",
      "Epoch 994/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7976 - val_loss: 85.5237\n",
      "Epoch 995/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7908 - val_loss: 85.5177\n",
      "Epoch 996/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7949 - val_loss: 85.5154\n",
      "Epoch 997/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7930 - val_loss: 85.5205\n",
      "Epoch 998/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5262\n",
      "Epoch 999/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7940 - val_loss: 85.5209\n",
      "Epoch 1000/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7927 - val_loss: 85.5221\n",
      "Epoch 1001/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7937 - val_loss: 85.5235\n",
      "Epoch 1002/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7921 - val_loss: 85.5217\n",
      "Epoch 1003/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7956 - val_loss: 85.5251\n",
      "Epoch 1004/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7953 - val_loss: 85.5150\n",
      "Epoch 1005/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7941 - val_loss: 85.5183\n",
      "Epoch 1006/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7946 - val_loss: 85.5315\n",
      "Epoch 1007/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7935 - val_loss: 85.5199\n",
      "Epoch 1008/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7977 - val_loss: 85.5169\n",
      "Epoch 1009/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7998 - val_loss: 85.5291\n",
      "Epoch 1010/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7942 - val_loss: 85.5221\n",
      "Epoch 1011/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8021 - val_loss: 85.5175\n",
      "Epoch 1012/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7917 - val_loss: 85.5232\n",
      "Epoch 1013/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7936 - val_loss: 85.5272\n",
      "Epoch 1014/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7921 - val_loss: 85.5222\n",
      "Epoch 1015/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7929 - val_loss: 85.5172\n",
      "Epoch 1016/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7962 - val_loss: 85.5177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1017/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7918 - val_loss: 85.5324\n",
      "Epoch 1018/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7930 - val_loss: 85.5233\n",
      "Epoch 1019/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 83.7931 - val_loss: 85.5179\n",
      "Epoch 1020/2000\n",
      "13621/13621 [==============================] - 0s 11us/step - loss: 83.7959 - val_loss: 85.5173\n",
      "Epoch 1021/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 83.7922 - val_loss: 85.5321\n",
      "Epoch 1022/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7925 - val_loss: 85.5228\n",
      "Epoch 1023/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7988 - val_loss: 85.5152\n",
      "Epoch 1024/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7902 - val_loss: 85.5278\n",
      "Epoch 1025/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7946 - val_loss: 85.5244\n",
      "Epoch 1026/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8036 - val_loss: 85.5222\n",
      "Epoch 1027/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7906 - val_loss: 85.5237\n",
      "Epoch 1028/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7957 - val_loss: 85.5179\n",
      "Epoch 1029/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7904 - val_loss: 85.5278\n",
      "Epoch 1030/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7936 - val_loss: 85.5262\n",
      "Epoch 1031/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7915 - val_loss: 85.5234\n",
      "Epoch 1032/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7947 - val_loss: 85.5156\n",
      "Epoch 1033/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7965 - val_loss: 85.5263\n",
      "Epoch 1034/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7935 - val_loss: 85.5200\n",
      "Epoch 1035/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7968 - val_loss: 85.5179\n",
      "Epoch 1036/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.8023 - val_loss: 85.5317\n",
      "Epoch 1037/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7911 - val_loss: 85.5175\n",
      "Epoch 1038/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7935 - val_loss: 85.5170\n",
      "Epoch 1039/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7916 - val_loss: 85.5212\n",
      "Epoch 1040/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8064 - val_loss: 85.5389\n",
      "Epoch 1041/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8036 - val_loss: 85.5166\n",
      "Epoch 1042/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7904 - val_loss: 85.5265\n",
      "Epoch 1043/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8005 - val_loss: 85.5185\n",
      "Epoch 1044/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7853 - val_loss: 85.5326\n",
      "Epoch 1045/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7893 - val_loss: 85.5288\n",
      "Epoch 1046/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7868 - val_loss: 85.5214\n",
      "Epoch 1047/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 83.7884 - val_loss: 85.5249\n",
      "Epoch 1048/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 83.7872 - val_loss: 85.5238\n",
      "Epoch 1049/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7862 - val_loss: 85.5247\n",
      "Epoch 1050/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7899 - val_loss: 85.5219\n",
      "Epoch 1051/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7867 - val_loss: 85.5309\n",
      "Epoch 1052/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7880 - val_loss: 85.5291\n",
      "Epoch 1053/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7858 - val_loss: 85.5237\n",
      "Epoch 1054/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7919 - val_loss: 85.5169\n",
      "Epoch 1055/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.8067 - val_loss: 85.5415\n",
      "Epoch 1056/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7918 - val_loss: 85.5192\n",
      "Epoch 1057/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7881 - val_loss: 85.5248\n",
      "Epoch 1058/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7866 - val_loss: 85.5267\n",
      "Epoch 1059/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 83.7800 - val_loss: 85.5281\n",
      "Epoch 1060/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.8954 - val_loss: 85.5231\n",
      "Epoch 1061/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7868 - val_loss: 85.5230\n",
      "Epoch 1062/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7922 - val_loss: 85.5180\n",
      "Epoch 1063/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7903 - val_loss: 85.5278\n",
      "Epoch 1064/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 83.7957 - val_loss: 85.5190\n",
      "Epoch 1065/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7932 - val_loss: 85.5294\n",
      "Epoch 1066/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7895 - val_loss: 85.5263\n",
      "Epoch 1067/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7924 - val_loss: 85.5178\n",
      "Epoch 1068/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7872 - val_loss: 85.5227\n",
      "Epoch 1069/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7891 - val_loss: 85.5257\n",
      "Epoch 1070/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7882 - val_loss: 85.5194\n",
      "Epoch 1071/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7867 - val_loss: 85.5214\n",
      "Epoch 1072/2000\n",
      "13621/13621 [==============================] - 0s 17us/step - loss: 83.7905 - val_loss: 85.5215\n",
      "Epoch 1073/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 83.7882 - val_loss: 85.5222\n",
      "Epoch 1074/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7857 - val_loss: 85.5225\n",
      "Epoch 1075/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7869 - val_loss: 85.5250\n",
      "Epoch 1076/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7894 - val_loss: 85.5226\n",
      "Epoch 1077/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7858 - val_loss: 85.5188\n",
      "Epoch 1078/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7887 - val_loss: 85.5182\n",
      "Epoch 1079/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7891 - val_loss: 85.5324\n",
      "Epoch 1080/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7876 - val_loss: 85.5237\n",
      "Epoch 1081/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7886 - val_loss: 85.5180\n",
      "Epoch 1082/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7929 - val_loss: 85.5325\n",
      "Epoch 1083/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7916 - val_loss: 85.5192\n",
      "Epoch 1084/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7852 - val_loss: 85.5220\n",
      "Epoch 1085/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7814 - val_loss: 85.5292\n",
      "Epoch 1086/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7859 - val_loss: 85.5183\n",
      "Epoch 1087/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.8005 - val_loss: 85.5367\n",
      "Epoch 1088/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7810 - val_loss: 85.5179\n",
      "Epoch 1089/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7813 - val_loss: 85.5254\n",
      "Epoch 1090/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7830 - val_loss: 85.5192\n",
      "Epoch 1091/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7853 - val_loss: 85.5240\n",
      "Epoch 1092/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7777 - val_loss: 85.5364\n",
      "Epoch 1093/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7905 - val_loss: 85.5311\n",
      "Epoch 1094/2000\n",
      "13621/13621 [==============================] - 0s 17us/step - loss: 83.7773 - val_loss: 85.5213\n",
      "Epoch 1095/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 83.7783 - val_loss: 85.5277\n",
      "Epoch 1096/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7812 - val_loss: 85.5217\n",
      "Epoch 1097/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7743 - val_loss: 85.5278\n",
      "Epoch 1098/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7741 - val_loss: 85.5327\n",
      "Epoch 1099/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 83.7745 - val_loss: 85.5273\n",
      "Epoch 1100/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 83.7686 - val_loss: 85.5544\n",
      "Epoch 1101/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 83.7701 - val_loss: 85.5353\n",
      "Epoch 1102/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.7646 - val_loss: 85.5077\n",
      "Epoch 1103/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 83.4426 - val_loss: 81.7828\n",
      "Epoch 1104/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 64.7379 - val_loss: 50.2315\n",
      "Epoch 1105/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 38.3609 - val_loss: 30.1287\n",
      "Epoch 1106/2000\n",
      "13621/13621 [==============================] - 0s 17us/step - loss: 23.4496 - val_loss: 21.1397\n",
      "Epoch 1107/2000\n",
      "13621/13621 [==============================] - 0s 11us/step - loss: 16.4657 - val_loss: 15.8564\n",
      "Epoch 1108/2000\n",
      "13621/13621 [==============================] - 0s 11us/step - loss: 12.6113 - val_loss: 13.0575\n",
      "Epoch 1109/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 10.3144 - val_loss: 11.7215\n",
      "Epoch 1110/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 8.9514 - val_loss: 10.7039\n",
      "Epoch 1111/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 7.8541 - val_loss: 9.8479\n",
      "Epoch 1112/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 6.9910 - val_loss: 9.1321\n",
      "Epoch 1113/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 6.4109 - val_loss: 8.5976\n",
      "Epoch 1114/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 5.8812 - val_loss: 8.0281\n",
      "Epoch 1115/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 5.3307 - val_loss: 7.6888\n",
      "Epoch 1116/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 5.0001 - val_loss: 7.2925\n",
      "Epoch 1117/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 4.6828 - val_loss: 7.0823\n",
      "Epoch 1118/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 4.4427 - val_loss: 7.1167\n",
      "Epoch 1119/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 4.1940 - val_loss: 6.9261\n",
      "Epoch 1120/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 4.0057 - val_loss: 6.8544\n",
      "Epoch 1121/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 3.8006 - val_loss: 6.6935\n",
      "Epoch 1122/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 3.6254 - val_loss: 6.6421\n",
      "Epoch 1123/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 3.5509 - val_loss: 6.6702\n",
      "Epoch 1124/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 3.3577 - val_loss: 6.6089\n",
      "Epoch 1125/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 3.2235 - val_loss: 6.5683\n",
      "Epoch 1126/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 3.1359 - val_loss: 6.5612\n",
      "Epoch 1127/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 3.0234 - val_loss: 6.5003\n",
      "Epoch 1128/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2.9285 - val_loss: 6.5211\n",
      "Epoch 1129/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2.8257 - val_loss: 6.5170\n",
      "Epoch 1130/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2.7341 - val_loss: 6.4821\n",
      "Epoch 1131/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2.6557 - val_loss: 6.5791\n",
      "Epoch 1132/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2.5900 - val_loss: 6.6061\n",
      "Epoch 1133/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2.5021 - val_loss: 6.3908\n",
      "Epoch 1134/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2.4404 - val_loss: 6.5806\n",
      "Epoch 1135/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2.3893 - val_loss: 6.4005\n",
      "Epoch 1136/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2.3145 - val_loss: 6.4851\n",
      "Epoch 1137/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 2.2520 - val_loss: 6.3504\n",
      "Epoch 1138/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2.2079 - val_loss: 6.4257\n",
      "Epoch 1139/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2.1680 - val_loss: 6.4675\n",
      "Epoch 1140/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2.0895 - val_loss: 6.4323\n",
      "Epoch 1141/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2.0669 - val_loss: 6.5110\n",
      "Epoch 1142/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 2.0279 - val_loss: 6.4405\n",
      "Epoch 1143/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.9842 - val_loss: 6.6043\n",
      "Epoch 1144/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.9365 - val_loss: 6.4899\n",
      "Epoch 1145/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.9090 - val_loss: 6.4175\n",
      "Epoch 1146/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 1.8596 - val_loss: 6.3596\n",
      "Epoch 1147/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.8178 - val_loss: 6.3970\n",
      "Epoch 1148/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.7911 - val_loss: 6.4182\n",
      "Epoch 1149/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 1.7595 - val_loss: 6.4034\n",
      "Epoch 1150/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.7111 - val_loss: 6.4003\n",
      "Epoch 1151/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.6711 - val_loss: 6.4372\n",
      "Epoch 1152/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.6356 - val_loss: 6.4350\n",
      "Epoch 1153/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.6139 - val_loss: 6.4260\n",
      "Epoch 1154/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.5851 - val_loss: 6.5072\n",
      "Epoch 1155/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.5565 - val_loss: 6.4910\n",
      "Epoch 1156/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 1.5364 - val_loss: 6.4868\n",
      "Epoch 1157/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.5078 - val_loss: 6.5293\n",
      "Epoch 1158/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.4816 - val_loss: 6.5094\n",
      "Epoch 1159/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.4651 - val_loss: 6.4523\n",
      "Epoch 1160/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.4358 - val_loss: 6.4927\n",
      "Epoch 1161/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.4291 - val_loss: 6.4942\n",
      "Epoch 1162/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 1.3982 - val_loss: 6.4788\n",
      "Epoch 1163/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 1.3737 - val_loss: 6.5401\n",
      "Epoch 1164/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.3599 - val_loss: 6.5478\n",
      "Epoch 1165/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 1.3419 - val_loss: 6.5382\n",
      "Epoch 1166/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 1.3266 - val_loss: 6.5618\n",
      "Epoch 1167/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 1.3199 - val_loss: 6.5539\n",
      "Epoch 1168/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 1.3064 - val_loss: 6.5070\n",
      "Epoch 1169/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.2857 - val_loss: 6.5424\n",
      "Epoch 1170/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 1.2618 - val_loss: 6.6054\n",
      "Epoch 1171/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.2479 - val_loss: 6.6328\n",
      "Epoch 1172/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.2295 - val_loss: 6.6708\n",
      "Epoch 1173/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.2203 - val_loss: 6.7060\n",
      "Epoch 1174/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.2064 - val_loss: 6.7247\n",
      "Epoch 1175/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.1931 - val_loss: 6.7985\n",
      "Epoch 1176/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.1806 - val_loss: 6.7905\n",
      "Epoch 1177/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.1585 - val_loss: 6.7328\n",
      "Epoch 1178/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.1510 - val_loss: 6.9026\n",
      "Epoch 1179/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.1429 - val_loss: 6.8817\n",
      "Epoch 1180/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.1239 - val_loss: 7.1431\n",
      "Epoch 1181/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.1048 - val_loss: 7.1207\n",
      "Epoch 1182/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.0883 - val_loss: 7.0807\n",
      "Epoch 1183/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.0833 - val_loss: 7.2555\n",
      "Epoch 1184/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.0670 - val_loss: 7.3985\n",
      "Epoch 1185/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.0599 - val_loss: 7.1067\n",
      "Epoch 1186/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 1.0460 - val_loss: 7.2691\n",
      "Epoch 1187/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.0407 - val_loss: 7.3954\n",
      "Epoch 1188/2000\n",
      "13621/13621 [==============================] - ETA: 0s - loss: 1.038 - 0s 15us/step - loss: 1.0247 - val_loss: 7.3174\n",
      "Epoch 1189/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.0154 - val_loss: 7.2486\n",
      "Epoch 1190/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 1.0037 - val_loss: 7.2278\n",
      "Epoch 1191/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.9977 - val_loss: 7.4684\n",
      "Epoch 1192/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.9906 - val_loss: 7.5758\n",
      "Epoch 1193/2000\n",
      "13621/13621 [==============================] - 0s 11us/step - loss: 0.9736 - val_loss: 7.3277\n",
      "Epoch 1194/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 0.9611 - val_loss: 7.2260\n",
      "Epoch 1195/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.9506 - val_loss: 7.6137\n",
      "Epoch 1196/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.9448 - val_loss: 7.1701\n",
      "Epoch 1197/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.9408 - val_loss: 7.5010\n",
      "Epoch 1198/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.9296 - val_loss: 8.1285\n",
      "Epoch 1199/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.9199 - val_loss: 7.3459\n",
      "Epoch 1200/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.9091 - val_loss: 7.3366\n",
      "Epoch 1201/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.9072 - val_loss: 7.2013\n",
      "Epoch 1202/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.8863 - val_loss: 7.3892\n",
      "Epoch 1203/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.8785 - val_loss: 7.2562\n",
      "Epoch 1204/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.8690 - val_loss: 7.2756\n",
      "Epoch 1205/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.8580 - val_loss: 7.3885\n",
      "Epoch 1206/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.8393 - val_loss: 7.3396\n",
      "Epoch 1207/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.8349 - val_loss: 7.2884\n",
      "Epoch 1208/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.8284 - val_loss: 7.0638\n",
      "Epoch 1209/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.8251 - val_loss: 7.1480\n",
      "Epoch 1210/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.8143 - val_loss: 7.2320\n",
      "Epoch 1211/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.8225 - val_loss: 7.4956\n",
      "Epoch 1212/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.8081 - val_loss: 7.1400\n",
      "Epoch 1213/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.8023 - val_loss: 7.0993\n",
      "Epoch 1214/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.7891 - val_loss: 7.1989\n",
      "Epoch 1215/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.7746 - val_loss: 7.2621\n",
      "Epoch 1216/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.7609 - val_loss: 7.2003\n",
      "Epoch 1217/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.7590 - val_loss: 7.2918\n",
      "Epoch 1218/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.7514 - val_loss: 7.3880\n",
      "Epoch 1219/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.7430 - val_loss: 7.3260\n",
      "Epoch 1220/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.7356 - val_loss: 7.3524\n",
      "Epoch 1221/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.7434 - val_loss: 7.4120\n",
      "Epoch 1222/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.7314 - val_loss: 7.5052\n",
      "Epoch 1223/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.7145 - val_loss: 7.5310\n",
      "Epoch 1224/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.7027 - val_loss: 7.4510\n",
      "Epoch 1225/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.7036 - val_loss: 7.5286\n",
      "Epoch 1226/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.6905 - val_loss: 7.3734\n",
      "Epoch 1227/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.6820 - val_loss: 7.4856\n",
      "Epoch 1228/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.6747 - val_loss: 7.5079\n",
      "Epoch 1229/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.6733 - val_loss: 7.5849\n",
      "Epoch 1230/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.6626 - val_loss: 7.4174\n",
      "Epoch 1231/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.6647 - val_loss: 7.4788\n",
      "Epoch 1232/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.6550 - val_loss: 7.4627\n",
      "Epoch 1233/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.6458 - val_loss: 7.4480\n",
      "Epoch 1234/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.6418 - val_loss: 7.4297\n",
      "Epoch 1235/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.6320 - val_loss: 7.4069\n",
      "Epoch 1236/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.6335 - val_loss: 7.4040\n",
      "Epoch 1237/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.6251 - val_loss: 7.3549\n",
      "Epoch 1238/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.6204 - val_loss: 7.3674\n",
      "Epoch 1239/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.6112 - val_loss: 7.5051\n",
      "Epoch 1240/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.6095 - val_loss: 7.4502\n",
      "Epoch 1241/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.6029 - val_loss: 7.4488\n",
      "Epoch 1242/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.5964 - val_loss: 7.4868\n",
      "Epoch 1243/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.5922 - val_loss: 7.5080\n",
      "Epoch 1244/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.5902 - val_loss: 7.4428\n",
      "Epoch 1245/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.5875 - val_loss: 7.5708\n",
      "Epoch 1246/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 0.5836 - val_loss: 7.4116\n",
      "Epoch 1247/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 0.5829 - val_loss: 7.4274\n",
      "Epoch 1248/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 0.5829 - val_loss: 7.5012\n",
      "Epoch 1249/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.5687 - val_loss: 7.3851\n",
      "Epoch 1250/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.5636 - val_loss: 7.4489\n",
      "Epoch 1251/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.5620 - val_loss: 7.4419\n",
      "Epoch 1252/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.5570 - val_loss: 7.5646\n",
      "Epoch 1253/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.5554 - val_loss: 7.3662\n",
      "Epoch 1254/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.5549 - val_loss: 7.5532\n",
      "Epoch 1255/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.5510 - val_loss: 7.4560\n",
      "Epoch 1256/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.5430 - val_loss: 7.5368\n",
      "Epoch 1257/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.5392 - val_loss: 7.5500\n",
      "Epoch 1258/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.5367 - val_loss: 7.5288\n",
      "Epoch 1259/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.5325 - val_loss: 7.4610\n",
      "Epoch 1260/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.5263 - val_loss: 7.4622\n",
      "Epoch 1261/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.5267 - val_loss: 7.4550\n",
      "Epoch 1262/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.5226 - val_loss: 7.4478\n",
      "Epoch 1263/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.5240 - val_loss: 7.4103\n",
      "Epoch 1264/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.5271 - val_loss: 7.5076\n",
      "Epoch 1265/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.5182 - val_loss: 7.4393\n",
      "Epoch 1266/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.5249 - val_loss: 7.4890\n",
      "Epoch 1267/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.5191 - val_loss: 7.4015\n",
      "Epoch 1268/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.5156 - val_loss: 7.4728\n",
      "Epoch 1269/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.5072 - val_loss: 7.4659\n",
      "Epoch 1270/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.4984 - val_loss: 7.6048\n",
      "Epoch 1271/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.5006 - val_loss: 7.4111\n",
      "Epoch 1272/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4948 - val_loss: 7.4282\n",
      "Epoch 1273/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4900 - val_loss: 7.5696\n",
      "Epoch 1274/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4855 - val_loss: 7.4595\n",
      "Epoch 1275/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4853 - val_loss: 7.5675\n",
      "Epoch 1276/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4803 - val_loss: 7.5386\n",
      "Epoch 1277/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4801 - val_loss: 7.5131\n",
      "Epoch 1278/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.4820 - val_loss: 7.4690\n",
      "Epoch 1279/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4742 - val_loss: 7.5579\n",
      "Epoch 1280/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4774 - val_loss: 7.5239\n",
      "Epoch 1281/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4692 - val_loss: 7.5804\n",
      "Epoch 1282/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4660 - val_loss: 7.4998\n",
      "Epoch 1283/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.4593 - val_loss: 7.5397\n",
      "Epoch 1284/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4492 - val_loss: 7.5502\n",
      "Epoch 1285/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4475 - val_loss: 7.6399\n",
      "Epoch 1286/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.4482 - val_loss: 7.5342\n",
      "Epoch 1287/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4450 - val_loss: 7.6707\n",
      "Epoch 1288/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4431 - val_loss: 7.5453\n",
      "Epoch 1289/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4408 - val_loss: 7.5519\n",
      "Epoch 1290/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4440 - val_loss: 7.6186\n",
      "Epoch 1291/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.4386 - val_loss: 7.5860\n",
      "Epoch 1292/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.4364 - val_loss: 7.6005\n",
      "Epoch 1293/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.4327 - val_loss: 7.5997\n",
      "Epoch 1294/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4368 - val_loss: 7.6732\n",
      "Epoch 1295/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.4329 - val_loss: 7.7098\n",
      "Epoch 1296/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4300 - val_loss: 7.6386\n",
      "Epoch 1297/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4259 - val_loss: 7.6842\n",
      "Epoch 1298/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4209 - val_loss: 7.6746\n",
      "Epoch 1299/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4194 - val_loss: 7.6601\n",
      "Epoch 1300/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4139 - val_loss: 7.6100\n",
      "Epoch 1301/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4074 - val_loss: 7.6981\n",
      "Epoch 1302/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4102 - val_loss: 7.6945\n",
      "Epoch 1303/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4048 - val_loss: 7.6456\n",
      "Epoch 1304/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4025 - val_loss: 7.6849\n",
      "Epoch 1305/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.4023 - val_loss: 7.6656\n",
      "Epoch 1306/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3963 - val_loss: 7.6196\n",
      "Epoch 1307/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3975 - val_loss: 7.7066\n",
      "Epoch 1308/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3952 - val_loss: 7.6640\n",
      "Epoch 1309/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3965 - val_loss: 7.7314\n",
      "Epoch 1310/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 0.3956 - val_loss: 7.7016\n",
      "Epoch 1311/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.3894 - val_loss: 7.7131\n",
      "Epoch 1312/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.3921 - val_loss: 7.6372\n",
      "Epoch 1313/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3935 - val_loss: 7.6900\n",
      "Epoch 1314/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.3851 - val_loss: 7.6755\n",
      "Epoch 1315/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3856 - val_loss: 7.6993\n",
      "Epoch 1316/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3894 - val_loss: 7.7097\n",
      "Epoch 1317/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.3921 - val_loss: 7.7550\n",
      "Epoch 1318/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3851 - val_loss: 7.6735\n",
      "Epoch 1319/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3796 - val_loss: 7.7708\n",
      "Epoch 1320/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.3893 - val_loss: 7.6435\n",
      "Epoch 1321/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3816 - val_loss: 7.6710\n",
      "Epoch 1322/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.3724 - val_loss: 7.6704\n",
      "Epoch 1323/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.3701 - val_loss: 7.7285\n",
      "Epoch 1324/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3682 - val_loss: 7.6929\n",
      "Epoch 1325/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.3646 - val_loss: 7.6907\n",
      "Epoch 1326/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.3618 - val_loss: 7.7040\n",
      "Epoch 1327/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3656 - val_loss: 7.6615\n",
      "Epoch 1328/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3666 - val_loss: 7.8401\n",
      "Epoch 1329/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3630 - val_loss: 7.6401\n",
      "Epoch 1330/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.3580 - val_loss: 7.7320\n",
      "Epoch 1331/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3570 - val_loss: 7.6917\n",
      "Epoch 1332/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3586 - val_loss: 7.8283\n",
      "Epoch 1333/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3580 - val_loss: 7.7319\n",
      "Epoch 1334/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3565 - val_loss: 7.7794\n",
      "Epoch 1335/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.3579 - val_loss: 7.6927\n",
      "Epoch 1336/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3618 - val_loss: 7.7944\n",
      "Epoch 1337/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 0.3533 - val_loss: 7.7845\n",
      "Epoch 1338/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 0.3514 - val_loss: 7.9058\n",
      "Epoch 1339/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3512 - val_loss: 7.6516\n",
      "Epoch 1340/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3464 - val_loss: 7.7136\n",
      "Epoch 1341/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3465 - val_loss: 7.6491\n",
      "Epoch 1342/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3544 - val_loss: 7.6315\n",
      "Epoch 1343/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3567 - val_loss: 7.6783\n",
      "Epoch 1344/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3471 - val_loss: 7.6865\n",
      "Epoch 1345/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3441 - val_loss: 7.7376\n",
      "Epoch 1346/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3390 - val_loss: 7.7232\n",
      "Epoch 1347/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3346 - val_loss: 7.7708\n",
      "Epoch 1348/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.3349 - val_loss: 7.7442\n",
      "Epoch 1349/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3384 - val_loss: 7.8062\n",
      "Epoch 1350/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.3359 - val_loss: 7.7751\n",
      "Epoch 1351/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3333 - val_loss: 7.7566\n",
      "Epoch 1352/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3267 - val_loss: 7.7535\n",
      "Epoch 1353/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3264 - val_loss: 7.8031\n",
      "Epoch 1354/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3222 - val_loss: 7.7342\n",
      "Epoch 1355/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.3221 - val_loss: 7.7825\n",
      "Epoch 1356/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3205 - val_loss: 7.7927\n",
      "Epoch 1357/2000\n",
      "13621/13621 [==============================] - ETA: 0s - loss: 0.308 - 0s 15us/step - loss: 0.3196 - val_loss: 7.8084\n",
      "Epoch 1358/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3201 - val_loss: 7.7540\n",
      "Epoch 1359/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3167 - val_loss: 7.7450\n",
      "Epoch 1360/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3128 - val_loss: 7.7823\n",
      "Epoch 1361/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3124 - val_loss: 7.7068\n",
      "Epoch 1362/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.3136 - val_loss: 7.8231\n",
      "Epoch 1363/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 0.3087 - val_loss: 7.7249\n",
      "Epoch 1364/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.3101 - val_loss: 7.8404\n",
      "Epoch 1365/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.3115 - val_loss: 7.7910\n",
      "Epoch 1366/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3112 - val_loss: 7.7917\n",
      "Epoch 1367/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3152 - val_loss: 7.8336\n",
      "Epoch 1368/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3178 - val_loss: 7.8267\n",
      "Epoch 1369/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3107 - val_loss: 7.7596\n",
      "Epoch 1370/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.3094 - val_loss: 7.7869\n",
      "Epoch 1371/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.3139 - val_loss: 7.7509\n",
      "Epoch 1372/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3100 - val_loss: 7.8153\n",
      "Epoch 1373/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3045 - val_loss: 7.7578\n",
      "Epoch 1374/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3094 - val_loss: 7.7590\n",
      "Epoch 1375/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3008 - val_loss: 7.8273\n",
      "Epoch 1376/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2964 - val_loss: 7.8341\n",
      "Epoch 1377/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2966 - val_loss: 7.8052\n",
      "Epoch 1378/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2929 - val_loss: 7.7759\n",
      "Epoch 1379/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.3001 - val_loss: 7.8643\n",
      "Epoch 1380/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2943 - val_loss: 7.8097\n",
      "Epoch 1381/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.2917 - val_loss: 7.7780\n",
      "Epoch 1382/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2905 - val_loss: 7.8064\n",
      "Epoch 1383/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2916 - val_loss: 7.8273\n",
      "Epoch 1384/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2882 - val_loss: 7.8405\n",
      "Epoch 1385/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.2915 - val_loss: 7.8477\n",
      "Epoch 1386/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2893 - val_loss: 7.7985\n",
      "Epoch 1387/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.2840 - val_loss: 7.8051\n",
      "Epoch 1388/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.2840 - val_loss: 7.8009\n",
      "Epoch 1389/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2907 - val_loss: 7.8605\n",
      "Epoch 1390/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2978 - val_loss: 7.8388\n",
      "Epoch 1391/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2929 - val_loss: 7.9080\n",
      "Epoch 1392/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2892 - val_loss: 7.7928\n",
      "Epoch 1393/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.2883 - val_loss: 7.8983\n",
      "Epoch 1394/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2903 - val_loss: 7.8052\n",
      "Epoch 1395/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2828 - val_loss: 7.8546\n",
      "Epoch 1396/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2780 - val_loss: 7.8939\n",
      "Epoch 1397/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2748 - val_loss: 7.9026\n",
      "Epoch 1398/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2741 - val_loss: 7.8343\n",
      "Epoch 1399/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2716 - val_loss: 7.8506\n",
      "Epoch 1400/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2694 - val_loss: 7.8246\n",
      "Epoch 1401/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2654 - val_loss: 7.8347\n",
      "Epoch 1402/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2682 - val_loss: 7.9717\n",
      "Epoch 1403/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2718 - val_loss: 7.9036\n",
      "Epoch 1404/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2814 - val_loss: 7.8770\n",
      "Epoch 1405/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2749 - val_loss: 7.8353\n",
      "Epoch 1406/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2675 - val_loss: 7.8995\n",
      "Epoch 1407/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2665 - val_loss: 7.9928\n",
      "Epoch 1408/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2712 - val_loss: 7.9653\n",
      "Epoch 1409/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2680 - val_loss: 7.9250\n",
      "Epoch 1410/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2659 - val_loss: 8.0192\n",
      "Epoch 1411/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.2641 - val_loss: 7.9330\n",
      "Epoch 1412/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2629 - val_loss: 7.9709\n",
      "Epoch 1413/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2589 - val_loss: 7.9628\n",
      "Epoch 1414/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2628 - val_loss: 8.0027\n",
      "Epoch 1415/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2626 - val_loss: 7.9206\n",
      "Epoch 1416/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2625 - val_loss: 8.0512\n",
      "Epoch 1417/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2618 - val_loss: 7.9097\n",
      "Epoch 1418/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2619 - val_loss: 7.9821\n",
      "Epoch 1419/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2639 - val_loss: 7.9734\n",
      "Epoch 1420/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.2620 - val_loss: 8.0301\n",
      "Epoch 1421/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2534 - val_loss: 7.9550\n",
      "Epoch 1422/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2487 - val_loss: 7.9966\n",
      "Epoch 1423/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2525 - val_loss: 7.8823\n",
      "Epoch 1424/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2552 - val_loss: 8.0220\n",
      "Epoch 1425/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2545 - val_loss: 8.0344\n",
      "Epoch 1426/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2555 - val_loss: 8.0278\n",
      "Epoch 1427/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2579 - val_loss: 8.0176\n",
      "Epoch 1428/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2566 - val_loss: 7.9802\n",
      "Epoch 1429/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2495 - val_loss: 8.0373\n",
      "Epoch 1430/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2487 - val_loss: 7.9661\n",
      "Epoch 1431/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2496 - val_loss: 8.0181\n",
      "Epoch 1432/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2506 - val_loss: 7.9743\n",
      "Epoch 1433/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2453 - val_loss: 8.0181\n",
      "Epoch 1434/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.2444 - val_loss: 8.0712\n",
      "Epoch 1435/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.2453 - val_loss: 8.0795\n",
      "Epoch 1436/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2454 - val_loss: 8.0546\n",
      "Epoch 1437/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2408 - val_loss: 8.0430\n",
      "Epoch 1438/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2366 - val_loss: 8.1390\n",
      "Epoch 1439/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2389 - val_loss: 8.0002\n",
      "Epoch 1440/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2380 - val_loss: 8.0776\n",
      "Epoch 1441/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.2372 - val_loss: 8.0881\n",
      "Epoch 1442/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2358 - val_loss: 8.0824\n",
      "Epoch 1443/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.2364 - val_loss: 8.0644\n",
      "Epoch 1444/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2369 - val_loss: 8.0906\n",
      "Epoch 1445/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2385 - val_loss: 8.0299\n",
      "Epoch 1446/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2366 - val_loss: 8.0947\n",
      "Epoch 1447/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2371 - val_loss: 8.0538\n",
      "Epoch 1448/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2380 - val_loss: 8.1018\n",
      "Epoch 1449/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.2394 - val_loss: 8.0757\n",
      "Epoch 1450/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2339 - val_loss: 8.0772\n",
      "Epoch 1451/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.2385 - val_loss: 8.1030\n",
      "Epoch 1452/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.2341 - val_loss: 8.1979\n",
      "Epoch 1453/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2304 - val_loss: 8.1275\n",
      "Epoch 1454/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 0.2317 - val_loss: 8.1550\n",
      "Epoch 1455/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.2338 - val_loss: 8.1826\n",
      "Epoch 1456/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.2241 - val_loss: 8.1559\n",
      "Epoch 1457/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2197 - val_loss: 8.1225\n",
      "Epoch 1458/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2220 - val_loss: 8.1795\n",
      "Epoch 1459/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2234 - val_loss: 8.1846\n",
      "Epoch 1460/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.2273 - val_loss: 8.2467\n",
      "Epoch 1461/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2245 - val_loss: 8.2532\n",
      "Epoch 1462/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2296 - val_loss: 8.1971\n",
      "Epoch 1463/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.2285 - val_loss: 8.2478\n",
      "Epoch 1464/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2258 - val_loss: 8.2385\n",
      "Epoch 1465/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2199 - val_loss: 8.2016\n",
      "Epoch 1466/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2217 - val_loss: 8.2173\n",
      "Epoch 1467/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2238 - val_loss: 8.2162\n",
      "Epoch 1468/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2172 - val_loss: 8.1545\n",
      "Epoch 1469/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2149 - val_loss: 8.2179\n",
      "Epoch 1470/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2159 - val_loss: 8.1657\n",
      "Epoch 1471/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.2183 - val_loss: 8.2333\n",
      "Epoch 1472/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2170 - val_loss: 8.1935\n",
      "Epoch 1473/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.2112 - val_loss: 8.2615\n",
      "Epoch 1474/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2063 - val_loss: 8.2800\n",
      "Epoch 1475/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2102 - val_loss: 8.2279\n",
      "Epoch 1476/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2122 - val_loss: 8.2787\n",
      "Epoch 1477/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2124 - val_loss: 8.2889\n",
      "Epoch 1478/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2074 - val_loss: 8.3316\n",
      "Epoch 1479/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2075 - val_loss: 8.2804\n",
      "Epoch 1480/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2137 - val_loss: 8.2840\n",
      "Epoch 1481/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.2124 - val_loss: 8.2863\n",
      "Epoch 1482/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 0.2149 - val_loss: 8.3178\n",
      "Epoch 1483/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 0.2119 - val_loss: 8.3362\n",
      "Epoch 1484/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.2116 - val_loss: 8.2794\n",
      "Epoch 1485/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.2176 - val_loss: 8.3079\n",
      "Epoch 1486/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2186 - val_loss: 8.2606\n",
      "Epoch 1487/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2144 - val_loss: 8.2277\n",
      "Epoch 1488/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2107 - val_loss: 8.3286\n",
      "Epoch 1489/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2109 - val_loss: 8.3292\n",
      "Epoch 1490/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2145 - val_loss: 8.2842\n",
      "Epoch 1491/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.2212 - val_loss: 8.3169\n",
      "Epoch 1492/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2208 - val_loss: 8.3051\n",
      "Epoch 1493/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2206 - val_loss: 8.2541\n",
      "Epoch 1494/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2149 - val_loss: 8.3132\n",
      "Epoch 1495/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2110 - val_loss: 8.2566\n",
      "Epoch 1496/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2151 - val_loss: 8.2981\n",
      "Epoch 1497/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2129 - val_loss: 8.2001\n",
      "Epoch 1498/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2095 - val_loss: 8.3541\n",
      "Epoch 1499/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2044 - val_loss: 8.3213\n",
      "Epoch 1500/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.2012 - val_loss: 8.3107\n",
      "Epoch 1501/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2061 - val_loss: 8.3207\n",
      "Epoch 1502/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2082 - val_loss: 8.3517\n",
      "Epoch 1503/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2031 - val_loss: 8.3242\n",
      "Epoch 1504/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1961 - val_loss: 8.3580\n",
      "Epoch 1505/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1960 - val_loss: 8.3286\n",
      "Epoch 1506/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1975 - val_loss: 8.3400\n",
      "Epoch 1507/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1959 - val_loss: 8.3935\n",
      "Epoch 1508/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1920 - val_loss: 8.3781\n",
      "Epoch 1509/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1953 - val_loss: 8.3745\n",
      "Epoch 1510/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1957 - val_loss: 8.3182\n",
      "Epoch 1511/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1939 - val_loss: 8.4043\n",
      "Epoch 1512/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1948 - val_loss: 8.4059\n",
      "Epoch 1513/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1985 - val_loss: 8.3231\n",
      "Epoch 1514/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1960 - val_loss: 8.3955\n",
      "Epoch 1515/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1946 - val_loss: 8.3454\n",
      "Epoch 1516/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.2008 - val_loss: 8.2970\n",
      "Epoch 1517/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1974 - val_loss: 8.3941\n",
      "Epoch 1518/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1960 - val_loss: 8.3861\n",
      "Epoch 1519/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1967 - val_loss: 8.3521\n",
      "Epoch 1520/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1984 - val_loss: 8.3955\n",
      "Epoch 1521/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.2027 - val_loss: 8.3393\n",
      "Epoch 1522/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1975 - val_loss: 8.3638\n",
      "Epoch 1523/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1898 - val_loss: 8.3241\n",
      "Epoch 1524/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1957 - val_loss: 8.4553\n",
      "Epoch 1525/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1953 - val_loss: 8.4759\n",
      "Epoch 1526/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1931 - val_loss: 8.4447\n",
      "Epoch 1527/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1963 - val_loss: 8.4195\n",
      "Epoch 1528/2000\n",
      "13621/13621 [==============================] - 0s 18us/step - loss: 0.1923 - val_loss: 8.4378\n",
      "Epoch 1529/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 0.1920 - val_loss: 8.3965\n",
      "Epoch 1530/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1901 - val_loss: 8.3877\n",
      "Epoch 1531/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1907 - val_loss: 8.4280\n",
      "Epoch 1532/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1858 - val_loss: 8.4535\n",
      "Epoch 1533/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1823 - val_loss: 8.4071\n",
      "Epoch 1534/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1838 - val_loss: 8.5570\n",
      "Epoch 1535/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1833 - val_loss: 8.3923\n",
      "Epoch 1536/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1847 - val_loss: 8.4256\n",
      "Epoch 1537/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1843 - val_loss: 8.4143\n",
      "Epoch 1538/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1809 - val_loss: 8.4452\n",
      "Epoch 1539/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1781 - val_loss: 8.5160\n",
      "Epoch 1540/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1895 - val_loss: 8.4533\n",
      "Epoch 1541/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1903 - val_loss: 8.4753\n",
      "Epoch 1542/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1915 - val_loss: 8.4335\n",
      "Epoch 1543/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1879 - val_loss: 8.5194\n",
      "Epoch 1544/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1864 - val_loss: 8.4241\n",
      "Epoch 1545/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1887 - val_loss: 8.5035\n",
      "Epoch 1546/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1861 - val_loss: 8.4797\n",
      "Epoch 1547/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1820 - val_loss: 8.4498\n",
      "Epoch 1548/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1783 - val_loss: 8.4629\n",
      "Epoch 1549/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1770 - val_loss: 8.4800\n",
      "Epoch 1550/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1784 - val_loss: 8.4582\n",
      "Epoch 1551/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1764 - val_loss: 8.4664\n",
      "Epoch 1552/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1773 - val_loss: 8.5140\n",
      "Epoch 1553/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1780 - val_loss: 8.5217\n",
      "Epoch 1554/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1803 - val_loss: 8.5362\n",
      "Epoch 1555/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1858 - val_loss: 8.4687\n",
      "Epoch 1556/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1864 - val_loss: 8.5085\n",
      "Epoch 1557/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1817 - val_loss: 8.4803\n",
      "Epoch 1558/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 0.1842 - val_loss: 8.4939\n",
      "Epoch 1559/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1888 - val_loss: 8.5185\n",
      "Epoch 1560/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1862 - val_loss: 8.5000\n",
      "Epoch 1561/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1875 - val_loss: 8.4945\n",
      "Epoch 1562/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1809 - val_loss: 8.4817\n",
      "Epoch 1563/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1830 - val_loss: 8.4964\n",
      "Epoch 1564/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1782 - val_loss: 8.4963\n",
      "Epoch 1565/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1781 - val_loss: 8.5024\n",
      "Epoch 1566/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1746 - val_loss: 8.5363\n",
      "Epoch 1567/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1772 - val_loss: 8.5208\n",
      "Epoch 1568/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1717 - val_loss: 8.5082\n",
      "Epoch 1569/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1703 - val_loss: 8.5096\n",
      "Epoch 1570/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1757 - val_loss: 8.5273\n",
      "Epoch 1571/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1730 - val_loss: 8.5502\n",
      "Epoch 1572/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1765 - val_loss: 8.4701\n",
      "Epoch 1573/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1756 - val_loss: 8.5854\n",
      "Epoch 1574/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1710 - val_loss: 8.5120\n",
      "Epoch 1575/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1714 - val_loss: 8.5105\n",
      "Epoch 1576/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1680 - val_loss: 8.5928\n",
      "Epoch 1577/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1662 - val_loss: 8.5570\n",
      "Epoch 1578/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1664 - val_loss: 8.5534\n",
      "Epoch 1579/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1710 - val_loss: 8.5742\n",
      "Epoch 1580/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1699 - val_loss: 8.6727\n",
      "Epoch 1581/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1686 - val_loss: 8.5666\n",
      "Epoch 1582/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 0.1705 - val_loss: 8.5902\n",
      "Epoch 1583/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1695 - val_loss: 8.6447\n",
      "Epoch 1584/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1709 - val_loss: 8.6007\n",
      "Epoch 1585/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1652 - val_loss: 8.5326\n",
      "Epoch 1586/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1661 - val_loss: 8.5936\n",
      "Epoch 1587/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1710 - val_loss: 8.6104\n",
      "Epoch 1588/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1680 - val_loss: 8.5400\n",
      "Epoch 1589/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1666 - val_loss: 8.5399\n",
      "Epoch 1590/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1649 - val_loss: 8.6723\n",
      "Epoch 1591/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1649 - val_loss: 8.5983\n",
      "Epoch 1592/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1664 - val_loss: 8.6794\n",
      "Epoch 1593/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1766 - val_loss: 8.5627\n",
      "Epoch 1594/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1717 - val_loss: 8.6224\n",
      "Epoch 1595/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1666 - val_loss: 8.6317\n",
      "Epoch 1596/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1699 - val_loss: 8.5925\n",
      "Epoch 1597/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1675 - val_loss: 8.6250\n",
      "Epoch 1598/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1625 - val_loss: 8.6205\n",
      "Epoch 1599/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 0.1602 - val_loss: 8.5917\n",
      "Epoch 1600/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1657 - val_loss: 8.6349\n",
      "Epoch 1601/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1720 - val_loss: 8.6062\n",
      "Epoch 1602/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1680 - val_loss: 8.6269\n",
      "Epoch 1603/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1691 - val_loss: 8.6195\n",
      "Epoch 1604/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1636 - val_loss: 8.5799\n",
      "Epoch 1605/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1602 - val_loss: 8.6361\n",
      "Epoch 1606/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1599 - val_loss: 8.6136\n",
      "Epoch 1607/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1599 - val_loss: 8.6895\n",
      "Epoch 1608/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1617 - val_loss: 8.6409\n",
      "Epoch 1609/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1623 - val_loss: 8.6842\n",
      "Epoch 1610/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1605 - val_loss: 8.6015\n",
      "Epoch 1611/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1627 - val_loss: 8.7385\n",
      "Epoch 1612/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1592 - val_loss: 8.6611\n",
      "Epoch 1613/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1608 - val_loss: 8.6584\n",
      "Epoch 1614/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1594 - val_loss: 8.6782\n",
      "Epoch 1615/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1585 - val_loss: 8.5918\n",
      "Epoch 1616/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1595 - val_loss: 8.6785\n",
      "Epoch 1617/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1601 - val_loss: 8.6771\n",
      "Epoch 1618/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1632 - val_loss: 8.6792\n",
      "Epoch 1619/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1585 - val_loss: 8.6530\n",
      "Epoch 1620/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1521 - val_loss: 8.6620\n",
      "Epoch 1621/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1501 - val_loss: 8.6769\n",
      "Epoch 1622/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1525 - val_loss: 8.6795\n",
      "Epoch 1623/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1536 - val_loss: 8.7011\n",
      "Epoch 1624/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1527 - val_loss: 8.7197\n",
      "Epoch 1625/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1525 - val_loss: 8.6652\n",
      "Epoch 1626/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1513 - val_loss: 8.7797\n",
      "Epoch 1627/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 0.1528 - val_loss: 8.7028\n",
      "Epoch 1628/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 0.1550 - val_loss: 8.7499\n",
      "Epoch 1629/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1536 - val_loss: 8.7682\n",
      "Epoch 1630/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1497 - val_loss: 8.7143\n",
      "Epoch 1631/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1501 - val_loss: 8.7075\n",
      "Epoch 1632/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1486 - val_loss: 8.7773\n",
      "Epoch 1633/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1493 - val_loss: 8.7435\n",
      "Epoch 1634/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1499 - val_loss: 8.7636\n",
      "Epoch 1635/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1489 - val_loss: 8.7644\n",
      "Epoch 1636/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1483 - val_loss: 8.7859\n",
      "Epoch 1637/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1465 - val_loss: 8.7311\n",
      "Epoch 1638/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1447 - val_loss: 8.7635\n",
      "Epoch 1639/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1464 - val_loss: 8.7127\n",
      "Epoch 1640/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1445 - val_loss: 8.7374\n",
      "Epoch 1641/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1457 - val_loss: 8.8181\n",
      "Epoch 1642/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1449 - val_loss: 8.8220\n",
      "Epoch 1643/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1448 - val_loss: 8.7991\n",
      "Epoch 1644/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1438 - val_loss: 8.8137\n",
      "Epoch 1645/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1431 - val_loss: 8.7159\n",
      "Epoch 1646/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1435 - val_loss: 8.7847\n",
      "Epoch 1647/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1435 - val_loss: 8.7850\n",
      "Epoch 1648/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1454 - val_loss: 8.8187\n",
      "Epoch 1649/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1455 - val_loss: 8.7294\n",
      "Epoch 1650/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1518 - val_loss: 8.7846\n",
      "Epoch 1651/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1599 - val_loss: 8.7848\n",
      "Epoch 1652/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1576 - val_loss: 8.8188\n",
      "Epoch 1653/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1573 - val_loss: 8.8190\n",
      "Epoch 1654/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1547 - val_loss: 8.9073\n",
      "Epoch 1655/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1631 - val_loss: 8.7481\n",
      "Epoch 1656/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1653 - val_loss: 8.8201\n",
      "Epoch 1657/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1678 - val_loss: 8.7449\n",
      "Epoch 1658/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1637 - val_loss: 8.8086\n",
      "Epoch 1659/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1595 - val_loss: 8.7561\n",
      "Epoch 1660/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1548 - val_loss: 8.8903\n",
      "Epoch 1661/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1548 - val_loss: 8.7563\n",
      "Epoch 1662/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1498 - val_loss: 8.8146\n",
      "Epoch 1663/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1516 - val_loss: 8.8263\n",
      "Epoch 1664/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1529 - val_loss: 8.8059\n",
      "Epoch 1665/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1474 - val_loss: 8.7900\n",
      "Epoch 1666/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1426 - val_loss: 8.8593\n",
      "Epoch 1667/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1386 - val_loss: 8.8587\n",
      "Epoch 1668/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1374 - val_loss: 8.8752\n",
      "Epoch 1669/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1356 - val_loss: 8.8791\n",
      "Epoch 1670/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1408 - val_loss: 8.8707\n",
      "Epoch 1671/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1414 - val_loss: 8.8382\n",
      "Epoch 1672/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1415 - val_loss: 8.9171\n",
      "Epoch 1673/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1429 - val_loss: 8.8821\n",
      "Epoch 1674/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 0.1422 - val_loss: 8.8572\n",
      "Epoch 1675/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1389 - val_loss: 8.8827\n",
      "Epoch 1676/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1355 - val_loss: 9.0010\n",
      "Epoch 1677/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1389 - val_loss: 8.9249\n",
      "Epoch 1678/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1380 - val_loss: 8.8975\n",
      "Epoch 1679/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1379 - val_loss: 8.9642\n",
      "Epoch 1680/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 0.1368 - val_loss: 8.8803\n",
      "Epoch 1681/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1370 - val_loss: 8.9122\n",
      "Epoch 1682/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1408 - val_loss: 8.9314\n",
      "Epoch 1683/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1405 - val_loss: 8.9644\n",
      "Epoch 1684/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1486 - val_loss: 8.9037\n",
      "Epoch 1685/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1428 - val_loss: 8.8931\n",
      "Epoch 1686/2000\n",
      "13621/13621 [==============================] - 0s 11us/step - loss: 0.1453 - val_loss: 8.9546\n",
      "Epoch 1687/2000\n",
      "13621/13621 [==============================] - 0s 11us/step - loss: 0.1422 - val_loss: 8.8965\n",
      "Epoch 1688/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 0.1428 - val_loss: 8.9709\n",
      "Epoch 1689/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1434 - val_loss: 8.9442\n",
      "Epoch 1690/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1416 - val_loss: 8.9257\n",
      "Epoch 1691/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1422 - val_loss: 9.0232\n",
      "Epoch 1692/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1373 - val_loss: 8.9446\n",
      "Epoch 1693/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1370 - val_loss: 8.9808\n",
      "Epoch 1694/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1363 - val_loss: 9.0014\n",
      "Epoch 1695/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1382 - val_loss: 8.9547\n",
      "Epoch 1696/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1408 - val_loss: 8.9524\n",
      "Epoch 1697/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1393 - val_loss: 8.9263\n",
      "Epoch 1698/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1404 - val_loss: 8.9519\n",
      "Epoch 1699/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1382 - val_loss: 8.9681\n",
      "Epoch 1700/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1395 - val_loss: 8.9887\n",
      "Epoch 1701/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1372 - val_loss: 8.9788\n",
      "Epoch 1702/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1408 - val_loss: 9.0940\n",
      "Epoch 1703/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1555 - val_loss: 8.9811\n",
      "Epoch 1704/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1620 - val_loss: 8.9763\n",
      "Epoch 1705/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 0.1630 - val_loss: 8.9674\n",
      "Epoch 1706/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1610 - val_loss: 8.9114\n",
      "Epoch 1707/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1522 - val_loss: 8.9338\n",
      "Epoch 1708/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1459 - val_loss: 9.0332\n",
      "Epoch 1709/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1436 - val_loss: 9.0304\n",
      "Epoch 1710/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1484 - val_loss: 9.0310\n",
      "Epoch 1711/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1429 - val_loss: 8.9579\n",
      "Epoch 1712/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1424 - val_loss: 8.9822\n",
      "Epoch 1713/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1375 - val_loss: 9.0718\n",
      "Epoch 1714/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1355 - val_loss: 8.9693\n",
      "Epoch 1715/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1311 - val_loss: 8.9920\n",
      "Epoch 1716/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1317 - val_loss: 9.0576\n",
      "Epoch 1717/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1334 - val_loss: 9.0128\n",
      "Epoch 1718/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1304 - val_loss: 8.9988\n",
      "Epoch 1719/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1268 - val_loss: 9.0045\n",
      "Epoch 1720/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1264 - val_loss: 9.0164\n",
      "Epoch 1721/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1272 - val_loss: 9.1022\n",
      "Epoch 1722/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1259 - val_loss: 9.0216\n",
      "Epoch 1723/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1270 - val_loss: 8.9878\n",
      "Epoch 1724/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1294 - val_loss: 9.0697\n",
      "Epoch 1725/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1273 - val_loss: 9.0078\n",
      "Epoch 1726/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1275 - val_loss: 9.0603\n",
      "Epoch 1727/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1280 - val_loss: 9.0448\n",
      "Epoch 1728/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1286 - val_loss: 9.0251\n",
      "Epoch 1729/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1263 - val_loss: 9.0394\n",
      "Epoch 1730/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1249 - val_loss: 9.0071\n",
      "Epoch 1731/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1261 - val_loss: 9.0741\n",
      "Epoch 1732/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1294 - val_loss: 9.0888\n",
      "Epoch 1733/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1334 - val_loss: 9.0807\n",
      "Epoch 1734/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1319 - val_loss: 9.0622\n",
      "Epoch 1735/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1303 - val_loss: 9.1065\n",
      "Epoch 1736/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1325 - val_loss: 9.0815\n",
      "Epoch 1737/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1322 - val_loss: 9.0878\n",
      "Epoch 1738/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1314 - val_loss: 9.1026\n",
      "Epoch 1739/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1328 - val_loss: 9.0617\n",
      "Epoch 1740/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1298 - val_loss: 9.1348\n",
      "Epoch 1741/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1299 - val_loss: 9.0789\n",
      "Epoch 1742/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1250 - val_loss: 9.0843\n",
      "Epoch 1743/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1262 - val_loss: 9.0210\n",
      "Epoch 1744/2000\n",
      "13621/13621 [==============================] - 0s 12us/step - loss: 0.1254 - val_loss: 9.0061\n",
      "Epoch 1745/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 0.1276 - val_loss: 9.1260\n",
      "Epoch 1746/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1299 - val_loss: 9.1037\n",
      "Epoch 1747/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1324 - val_loss: 9.0178\n",
      "Epoch 1748/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1340 - val_loss: 9.0189\n",
      "Epoch 1749/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1375 - val_loss: 9.0863\n",
      "Epoch 1750/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1388 - val_loss: 9.0695\n",
      "Epoch 1751/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1388 - val_loss: 9.0665\n",
      "Epoch 1752/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1445 - val_loss: 9.0010\n",
      "Epoch 1753/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1377 - val_loss: 9.0831\n",
      "Epoch 1754/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1355 - val_loss: 9.0672\n",
      "Epoch 1755/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1390 - val_loss: 9.0983\n",
      "Epoch 1756/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1408 - val_loss: 8.9676\n",
      "Epoch 1757/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1360 - val_loss: 9.1509\n",
      "Epoch 1758/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1280 - val_loss: 9.0670\n",
      "Epoch 1759/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1287 - val_loss: 9.0853\n",
      "Epoch 1760/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1288 - val_loss: 9.0694\n",
      "Epoch 1761/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1321 - val_loss: 9.1515\n",
      "Epoch 1762/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1283 - val_loss: 9.0503\n",
      "Epoch 1763/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1247 - val_loss: 9.1114\n",
      "Epoch 1764/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1232 - val_loss: 9.1167\n",
      "Epoch 1765/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1224 - val_loss: 9.0752\n",
      "Epoch 1766/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1202 - val_loss: 9.1391\n",
      "Epoch 1767/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1186 - val_loss: 9.2306\n",
      "Epoch 1768/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1201 - val_loss: 9.1392\n",
      "Epoch 1769/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1187 - val_loss: 9.1942\n",
      "Epoch 1770/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1187 - val_loss: 9.1018\n",
      "Epoch 1771/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1205 - val_loss: 9.1848\n",
      "Epoch 1772/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1193 - val_loss: 9.1282\n",
      "Epoch 1773/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 0.1168 - val_loss: 9.2446\n",
      "Epoch 1774/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 0.1185 - val_loss: 9.0691\n",
      "Epoch 1775/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1189 - val_loss: 9.1004\n",
      "Epoch 1776/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1182 - val_loss: 9.1322\n",
      "Epoch 1777/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1191 - val_loss: 9.2384\n",
      "Epoch 1778/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1228 - val_loss: 9.2260\n",
      "Epoch 1779/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1236 - val_loss: 9.1940\n",
      "Epoch 1780/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1247 - val_loss: 9.1967\n",
      "Epoch 1781/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1267 - val_loss: 9.1846\n",
      "Epoch 1782/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1278 - val_loss: 9.2313\n",
      "Epoch 1783/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1344 - val_loss: 9.1582\n",
      "Epoch 1784/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1357 - val_loss: 9.2331\n",
      "Epoch 1785/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1332 - val_loss: 9.1442\n",
      "Epoch 1786/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1307 - val_loss: 9.1632\n",
      "Epoch 1787/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1288 - val_loss: 9.1175\n",
      "Epoch 1788/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1284 - val_loss: 9.1216\n",
      "Epoch 1789/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1250 - val_loss: 9.1081\n",
      "Epoch 1790/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1237 - val_loss: 9.1024\n",
      "Epoch 1791/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1201 - val_loss: 9.1906\n",
      "Epoch 1792/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1228 - val_loss: 9.1209\n",
      "Epoch 1793/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1191 - val_loss: 9.1954\n",
      "Epoch 1794/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1214 - val_loss: 9.1677\n",
      "Epoch 1795/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1200 - val_loss: 9.1539\n",
      "Epoch 1796/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1180 - val_loss: 9.2132\n",
      "Epoch 1797/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1151 - val_loss: 9.2602\n",
      "Epoch 1798/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1133 - val_loss: 9.0885\n",
      "Epoch 1799/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1121 - val_loss: 9.1845\n",
      "Epoch 1800/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1122 - val_loss: 9.2435\n",
      "Epoch 1801/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1140 - val_loss: 9.2705\n",
      "Epoch 1802/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1154 - val_loss: 9.1410\n",
      "Epoch 1803/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1150 - val_loss: 9.2608\n",
      "Epoch 1804/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1178 - val_loss: 9.3049\n",
      "Epoch 1805/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1212 - val_loss: 9.1861\n",
      "Epoch 1806/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1310 - val_loss: 9.1927\n",
      "Epoch 1807/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1279 - val_loss: 9.2184\n",
      "Epoch 1808/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1283 - val_loss: 9.2004\n",
      "Epoch 1809/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1259 - val_loss: 9.2190\n",
      "Epoch 1810/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1230 - val_loss: 9.2349\n",
      "Epoch 1811/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1202 - val_loss: 9.1475\n",
      "Epoch 1812/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1178 - val_loss: 9.1858\n",
      "Epoch 1813/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1162 - val_loss: 9.2079\n",
      "Epoch 1814/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1141 - val_loss: 9.3413\n",
      "Epoch 1815/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1132 - val_loss: 9.2508\n",
      "Epoch 1816/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1195 - val_loss: 9.2271\n",
      "Epoch 1817/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1178 - val_loss: 9.2349\n",
      "Epoch 1818/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1186 - val_loss: 9.2403\n",
      "Epoch 1819/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 0.1172 - val_loss: 9.2402\n",
      "Epoch 1820/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1165 - val_loss: 9.2213\n",
      "Epoch 1821/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1201 - val_loss: 9.1625\n",
      "Epoch 1822/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1199 - val_loss: 9.2638\n",
      "Epoch 1823/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1151 - val_loss: 9.2650\n",
      "Epoch 1824/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1205 - val_loss: 9.2195\n",
      "Epoch 1825/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1210 - val_loss: 9.2083\n",
      "Epoch 1826/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1222 - val_loss: 9.2376\n",
      "Epoch 1827/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1255 - val_loss: 9.2803\n",
      "Epoch 1828/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1248 - val_loss: 9.2244\n",
      "Epoch 1829/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1211 - val_loss: 9.2133\n",
      "Epoch 1830/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1177 - val_loss: 9.2224\n",
      "Epoch 1831/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1165 - val_loss: 9.1418\n",
      "Epoch 1832/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1135 - val_loss: 9.1796\n",
      "Epoch 1833/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1137 - val_loss: 9.2837\n",
      "Epoch 1834/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1152 - val_loss: 9.2393\n",
      "Epoch 1835/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1091 - val_loss: 9.2597\n",
      "Epoch 1836/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1073 - val_loss: 9.2550\n",
      "Epoch 1837/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1063 - val_loss: 9.2815\n",
      "Epoch 1838/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1045 - val_loss: 9.2698\n",
      "Epoch 1839/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1024 - val_loss: 9.2659\n",
      "Epoch 1840/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1044 - val_loss: 9.2967\n",
      "Epoch 1841/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1060 - val_loss: 9.2857\n",
      "Epoch 1842/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1068 - val_loss: 9.3209\n",
      "Epoch 1843/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1079 - val_loss: 9.2937\n",
      "Epoch 1844/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1070 - val_loss: 9.3388\n",
      "Epoch 1845/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1070 - val_loss: 9.3097\n",
      "Epoch 1846/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1085 - val_loss: 9.2487\n",
      "Epoch 1847/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1166 - val_loss: 9.4158\n",
      "Epoch 1848/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1124 - val_loss: 9.3168\n",
      "Epoch 1849/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1095 - val_loss: 9.2551\n",
      "Epoch 1850/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1099 - val_loss: 9.3228\n",
      "Epoch 1851/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1085 - val_loss: 9.2755\n",
      "Epoch 1852/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1091 - val_loss: 9.3319\n",
      "Epoch 1853/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1089 - val_loss: 9.3514\n",
      "Epoch 1854/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1077 - val_loss: 9.3484\n",
      "Epoch 1855/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1066 - val_loss: 9.2731\n",
      "Epoch 1856/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1087 - val_loss: 9.2529\n",
      "Epoch 1857/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1114 - val_loss: 9.2944\n",
      "Epoch 1858/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1200 - val_loss: 9.2461\n",
      "Epoch 1859/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1243 - val_loss: 9.2956\n",
      "Epoch 1860/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1173 - val_loss: 9.3170\n",
      "Epoch 1861/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1184 - val_loss: 9.2238\n",
      "Epoch 1862/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1185 - val_loss: 9.2787\n",
      "Epoch 1863/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1160 - val_loss: 9.2719\n",
      "Epoch 1864/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1130 - val_loss: 9.2250\n",
      "Epoch 1865/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1159 - val_loss: 9.2255\n",
      "Epoch 1866/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1191 - val_loss: 9.1863\n",
      "Epoch 1867/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1172 - val_loss: 9.3457\n",
      "Epoch 1868/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1192 - val_loss: 9.3354\n",
      "Epoch 1869/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1154 - val_loss: 9.2859\n",
      "Epoch 1870/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1145 - val_loss: 9.3888\n",
      "Epoch 1871/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1108 - val_loss: 9.2393\n",
      "Epoch 1872/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1088 - val_loss: 9.3661\n",
      "Epoch 1873/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1111 - val_loss: 9.3000\n",
      "Epoch 1874/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1161 - val_loss: 9.3371\n",
      "Epoch 1875/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1141 - val_loss: 9.2672\n",
      "Epoch 1876/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1134 - val_loss: 9.3919\n",
      "Epoch 1877/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1141 - val_loss: 9.2986\n",
      "Epoch 1878/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1154 - val_loss: 9.3517\n",
      "Epoch 1879/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1138 - val_loss: 9.3063\n",
      "Epoch 1880/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1116 - val_loss: 9.2527\n",
      "Epoch 1881/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1127 - val_loss: 9.2435\n",
      "Epoch 1882/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1122 - val_loss: 9.3123\n",
      "Epoch 1883/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1118 - val_loss: 9.2876\n",
      "Epoch 1884/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1097 - val_loss: 9.3922\n",
      "Epoch 1885/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1082 - val_loss: 9.2986\n",
      "Epoch 1886/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1048 - val_loss: 9.3300\n",
      "Epoch 1887/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1047 - val_loss: 9.2853\n",
      "Epoch 1888/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 0.1029 - val_loss: 9.2596\n",
      "Epoch 1889/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 0.1077 - val_loss: 9.3462\n",
      "Epoch 1890/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1087 - val_loss: 9.3874\n",
      "Epoch 1891/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1088 - val_loss: 9.3454\n",
      "Epoch 1892/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1107 - val_loss: 9.4033\n",
      "Epoch 1893/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1114 - val_loss: 9.3103\n",
      "Epoch 1894/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1130 - val_loss: 9.3735\n",
      "Epoch 1895/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1100 - val_loss: 9.3476\n",
      "Epoch 1896/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1063 - val_loss: 9.2808\n",
      "Epoch 1897/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1033 - val_loss: 9.3036\n",
      "Epoch 1898/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1031 - val_loss: 9.3402\n",
      "Epoch 1899/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1013 - val_loss: 9.3805\n",
      "Epoch 1900/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1035 - val_loss: 9.3885\n",
      "Epoch 1901/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1080 - val_loss: 9.3509\n",
      "Epoch 1902/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1059 - val_loss: 9.4147\n",
      "Epoch 1903/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1046 - val_loss: 9.3888\n",
      "Epoch 1904/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1035 - val_loss: 9.3581\n",
      "Epoch 1905/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1022 - val_loss: 9.3532\n",
      "Epoch 1906/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1044 - val_loss: 9.3553\n",
      "Epoch 1907/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1027 - val_loss: 9.3703\n",
      "Epoch 1908/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1035 - val_loss: 9.3639\n",
      "Epoch 1909/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1029 - val_loss: 9.3300\n",
      "Epoch 1910/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1056 - val_loss: 9.4479\n",
      "Epoch 1911/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1032 - val_loss: 9.2861\n",
      "Epoch 1912/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1063 - val_loss: 9.3639\n",
      "Epoch 1913/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1069 - val_loss: 9.3529\n",
      "Epoch 1914/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1027 - val_loss: 9.3357\n",
      "Epoch 1915/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1049 - val_loss: 9.3174\n",
      "Epoch 1916/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 0.1025 - val_loss: 9.2905\n",
      "Epoch 1917/2000\n",
      "13621/13621 [==============================] - 0s 13us/step - loss: 0.1008 - val_loss: 9.3609\n",
      "Epoch 1918/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1062 - val_loss: 9.3553\n",
      "Epoch 1919/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1074 - val_loss: 9.4405\n",
      "Epoch 1920/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1165 - val_loss: 9.2826\n",
      "Epoch 1921/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1162 - val_loss: 9.3146\n",
      "Epoch 1922/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1149 - val_loss: 9.4768\n",
      "Epoch 1923/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1145 - val_loss: 9.3798\n",
      "Epoch 1924/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1113 - val_loss: 9.3949\n",
      "Epoch 1925/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1124 - val_loss: 9.3276\n",
      "Epoch 1926/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1133 - val_loss: 9.3705\n",
      "Epoch 1927/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1146 - val_loss: 9.2966\n",
      "Epoch 1928/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1110 - val_loss: 9.3586\n",
      "Epoch 1929/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1117 - val_loss: 9.3171\n",
      "Epoch 1930/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1030 - val_loss: 9.3635\n",
      "Epoch 1931/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1040 - val_loss: 9.3340\n",
      "Epoch 1932/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1014 - val_loss: 9.2753\n",
      "Epoch 1933/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1062 - val_loss: 9.3712\n",
      "Epoch 1934/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1058 - val_loss: 9.2976\n",
      "Epoch 1935/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1040 - val_loss: 9.3151\n",
      "Epoch 1936/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1053 - val_loss: 9.3491\n",
      "Epoch 1937/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1028 - val_loss: 9.3337\n",
      "Epoch 1938/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1015 - val_loss: 9.3823\n",
      "Epoch 1939/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1026 - val_loss: 9.3044\n",
      "Epoch 1940/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1047 - val_loss: 9.3499\n",
      "Epoch 1941/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1010 - val_loss: 9.3912\n",
      "Epoch 1942/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1001 - val_loss: 9.3010\n",
      "Epoch 1943/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.0968 - val_loss: 9.3996\n",
      "Epoch 1944/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.0969 - val_loss: 9.4159\n",
      "Epoch 1945/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.0972 - val_loss: 9.4048\n",
      "Epoch 1946/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.0953 - val_loss: 9.3575\n",
      "Epoch 1947/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.0966 - val_loss: 9.3416\n",
      "Epoch 1948/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.0969 - val_loss: 9.3676\n",
      "Epoch 1949/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.0967 - val_loss: 9.3717\n",
      "Epoch 1950/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.0945 - val_loss: 9.3751\n",
      "Epoch 1951/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.0948 - val_loss: 9.3984\n",
      "Epoch 1952/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.0994 - val_loss: 9.4378\n",
      "Epoch 1953/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.0987 - val_loss: 9.3970\n",
      "Epoch 1954/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.0983 - val_loss: 9.4447\n",
      "Epoch 1955/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.0947 - val_loss: 9.3753\n",
      "Epoch 1956/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1000 - val_loss: 9.5205\n",
      "Epoch 1957/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1157 - val_loss: 9.3881\n",
      "Epoch 1958/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1109 - val_loss: 9.4113\n",
      "Epoch 1959/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1059 - val_loss: 9.4339\n",
      "Epoch 1960/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1051 - val_loss: 9.4102\n",
      "Epoch 1961/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1060 - val_loss: 9.3448\n",
      "Epoch 1962/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1067 - val_loss: 9.3912\n",
      "Epoch 1963/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1028 - val_loss: 9.3297\n",
      "Epoch 1964/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1032 - val_loss: 9.3839\n",
      "Epoch 1965/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1027 - val_loss: 9.3360\n",
      "Epoch 1966/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.0987 - val_loss: 9.4093\n",
      "Epoch 1967/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.0968 - val_loss: 9.3691\n",
      "Epoch 1968/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.0991 - val_loss: 9.3659\n",
      "Epoch 1969/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.0990 - val_loss: 9.3920\n",
      "Epoch 1970/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1001 - val_loss: 9.4250\n",
      "Epoch 1971/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1002 - val_loss: 9.4539\n",
      "Epoch 1972/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1026 - val_loss: 9.4574\n",
      "Epoch 1973/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1061 - val_loss: 9.3847\n",
      "Epoch 1974/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1024 - val_loss: 9.4223\n",
      "Epoch 1975/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1039 - val_loss: 9.4368\n",
      "Epoch 1976/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1050 - val_loss: 9.3919\n",
      "Epoch 1977/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1122 - val_loss: 9.4464\n",
      "Epoch 1978/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1144 - val_loss: 9.3921\n",
      "Epoch 1979/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1088 - val_loss: 9.4386\n",
      "Epoch 1980/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1069 - val_loss: 9.3045\n",
      "Epoch 1981/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1108 - val_loss: 9.3274\n",
      "Epoch 1982/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1175 - val_loss: 9.4105\n",
      "Epoch 1983/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1087 - val_loss: 9.3985\n",
      "Epoch 1984/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1059 - val_loss: 9.3663\n",
      "Epoch 1985/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1042 - val_loss: 9.4437\n",
      "Epoch 1986/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1018 - val_loss: 9.3505\n",
      "Epoch 1987/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1036 - val_loss: 9.3941\n",
      "Epoch 1988/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1026 - val_loss: 9.3637\n",
      "Epoch 1989/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1067 - val_loss: 9.4091\n",
      "Epoch 1990/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1015 - val_loss: 9.3237\n",
      "Epoch 1991/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1008 - val_loss: 9.4368\n",
      "Epoch 1992/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1035 - val_loss: 9.4128\n",
      "Epoch 1993/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1085 - val_loss: 9.3365\n",
      "Epoch 1994/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1135 - val_loss: 9.3569\n",
      "Epoch 1995/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1105 - val_loss: 9.3288\n",
      "Epoch 1996/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1089 - val_loss: 9.3676\n",
      "Epoch 1997/2000\n",
      "13621/13621 [==============================] - 0s 14us/step - loss: 0.1056 - val_loss: 9.3861\n",
      "Epoch 1998/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1053 - val_loss: 9.3878\n",
      "Epoch 1999/2000\n",
      "13621/13621 [==============================] - 0s 16us/step - loss: 0.1064 - val_loss: 9.3498\n",
      "Epoch 2000/2000\n",
      "13621/13621 [==============================] - 0s 15us/step - loss: 0.1044 - val_loss: 9.3130\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, Y_train, batch_size=batch_size, epochs=nb_epoch,\n",
    "          verbose=1, validation_data=(x_val, Y_val),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test mse: 9.39912279457418\n",
      "(4542,)\n",
      "(4542,)\n",
      "[-3.51691322  0.40490345  0.41366203 -1.45130845 -1.18864487  9.36288287\n",
      " -0.29320377 -6.48862827 -0.82203995  4.83103795]\n",
      "(4542,)\n",
      "(4542, 1)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, Y_test, verbose=0)\n",
    "print('Test mse:', score)\n",
    "# print('Test mae:', score[1])\n",
    "Y_test_predicted=model.predict(x_test)\n",
    "x_test_array=np.asarray(Y_test)\n",
    "print(x_test_array.shape)\n",
    "error_prediction=Y_test-Y_test_predicted.flatten()\n",
    "print(error_prediction.shape)\n",
    "print(error_prediction[:10])\n",
    "print(Y_test.shape)\n",
    "print(Y_test_predicted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XucXXV57/HPdy65TK6TZHIPmQABkwiEEEKQ1heghASrwWopUGrq8Rjbwqn21B6gPYpa8eA5FT1UBaHmCC0KiFJjDYVAQUS5JRAhIcBMQiCThMllcs9kksw854+9Bjdh7rP3XnP5vl+vnb32s39rrWevmdlP1lq/9VuKCMzMzHKhKO0EzMys73BRMTOznHFRMTOznHFRMTOznHFRMTOznHFRMTOznHFRMcsjST+Q9NUOtt0k6YP5zsksn1xUzMwsZ1xUzPoYSSUdiXV2GWYd4aJi/V5y2OlvJb0o6aCk70saJ+lBSfslPSKpPKv9RyStk7RH0uOSZmS9d6ak55P57gUGHbeuP5C0Jpn3N5JO72COAyX9o6Q3JdVKuk3S4OS98yXVSLpW0lvA/2splrT9tKRqSXWSlkuamLWOkHS1pCqgqjvb1PovFxWzjI8BFwGnAB8GHgT+DhhD5u/krwAknQL8CPgcUAGsAH4uaYCkAcC/Af8CjAJ+nCyXZN45wDLgM8Bo4HvAckkDO5Df15PcZgMnA5OAL2a9Pz5Z51RgaUsxSRcC/wu4DJgAvAHcc9x6LgXOAWZ2ICezd3FRMcv4p4iojYgtwK+AZyLihYhoAB4Azkza/THwi4hYGRFHgX8EBgPvA+YDpcC3IuJoRNwPPJe1jk8D34uIZyKiMSLuBBqS+VolScm8fx0RdRGxH/gacHlWsybghohoiIj6VmJ/AiyLiOeTz3U9cK6kyqzl/K9kHfWYdYGPm5pl1GZN17fwemgyPZHM//ABiIgmSZvJ7Dk0AlvinaO0vpE1PRVYIum/ZcUGJMtsSwVQBqzO1BcABBRntdkREYePm+/42ETg+azcD0jaleS+KQlvbicXsza5qJh1zlbgtOYXyV7EFGALEMAkScoqLCcAG5LpzcCNEXFjJ9e5k0xhm5XsSbWkpeHGj49tJVPYmnMfQuYw3JY25jHrFB/+Muuc+4APSfqApFLgb8gcwvoN8BRwDPgrSSWS/hCYlzXvHcCfSzpHGUMkfUjSsLZWGBFNybzflDQWQNIkSRd3MvcfAp+UNDs5j/M1Mof5NnVyOWatclEx64SIeBW4CvgnMnsQHwY+HBFHIuII8IfAnwG7yZx/+WnWvKvInBv5dvJ+ddK2I65N2j8taR/wCHBqJ3N/FPgC8BNgG3AS7zwvY9Zt8k26zMwsV7ynYmZmOeOiYmZmOeOiYmZmOeOiYmZmOdPvrlMZM2ZMVFZWpp2GmVmvsnr16p0RUdFeu35XVCorK1m1alXaaZiZ9SqS3mi/lQ9/mZlZDrmomJlZzriomJlZzvS7cyotOXr0KDU1NRw+fPwgr33LoEGDmDx5MqWlpWmnYmZ9lIsKUFNTw7Bhw6isrCRraPE+JSLYtWsXNTU1TJs2Le10zKyPytvhL0mDJD0r6bfJrVe/nMSnSXpGUpWke5O75TXfLvXe5Fanz2TfOEjS9Un81eyRWSUtTGLVkq7raq6HDx9m9OjRfbagAEhi9OjRfX5vzMzSlc9zKg3AhRFxBplboC6UNJ/MbVG/GRHTyYzU+qmk/aeA3RFxMvDNpB2SZpIZSXUWsBD4rqRiScXAd4BFZG59ekXStkv6ckFp1h8+o5mlK29FJTIOJC9Lk0cAFwL3J/E7ydwTG2Bx8prk/Q8kN0BaDNyT3BL1dTLDf89LHtURsTEZcvyepG1e7DzQwJ5DR/K1eDOzPiGvvb+SPYo1wHZgJZk74O2JiGNJkxoytzIled4MkLy/l8xd6d6OHzdPa/G8qDt4hL31R/Oy7D179vDd73630/Ndcskl7NmzJw8ZmZl1TV6LSkQ0RsRsYDKZPYsZLTVLnls6NhNdiL+LpKWSVklatWPHjvYTb2kZQL5uPdNaUWlsbGxzvhUrVjBy5Mj8JGVm1gUFuU4lIvYAjwPzgZGSmnudTSZz32zI7GlMAUjeHwHUZcePm6e1eEvrvz0i5kbE3IqKdoeuaZGkvN28+7rrrmPDhg3Mnj2bs88+mwsuuIArr7yS007L3Ar90ksv5ayzzmLWrFncfvvtb89XWVnJzp072bRpEzNmzODTn/40s2bNYsGCBdTX1+cpWzOz1uWtS7GkCuBoROyRNBj4IJmT748BHydzDmQJ8LNkluXJ66eS9/8zIkLScuCHkm4GJgLTgWfJ7DxMlzQN2ELmZP6V3c37yz9fx8tb970rfvhoZq9hUGlxp5c5c+JwbvjwrFbfv+mmm1i7di1r1qzh8ccf50Mf+hBr1659u+vvsmXLGDVqFPX19Zx99tl87GMfY/To0e9YRlVVFT/60Y+44447uOyyy/jJT37CVVdd1elczcy6I5/XqUwA7kx6aRUB90XEv0t6GbhH0leBF4DvJ+2/D/yLpGoyeyiXA0TEOkn3AS8Dx4CrI6IRQNI1wENAMbAsItbl8fMUzLx5895xLcktt9zCAw88AMDmzZupqqp6V1GZNm0as2fPBuCss85i06ZNBcvXzKxZ3opKRLwInNlCfCOZ8yvHxw8Df9TKsm4EbmwhvgJY0e1ks7S2R7GjditHo4iJ48fncnUtGjJkyNvTjz/+OI888ghPPfUUZWVlnH/++S1eazJw4MC3p4uLi334y8xS4bG/OmhE026Gx7sPi+XCsGHD2L9/f4vv7d27l/LycsrKynjllVd4+umn85KDmVkueJiWDgqKUJ66f40ePZrzzjuP9773vQwePJhx48a9/d7ChQu57bbbOP300zn11FOZP39+XnIwM8sFRb76yfZQc+fOjeNv0rV+/XpmzGipt/PvHN72Co0BQya+J5/p5V1HPquZ2fEkrY6Iue218+GvjpIoointLMzMejQXlQ4KisjflSpmZn2Di0oHheSiYmbWDheVDlPeTtSbmfUVLiodJR/+MjNrj4tKR6mIIoKmJhcWM7PWuKh0kFREEU005qGodHXoe4BvfetbHDp0KMcZmZl1jYtKRxWXIEFj47H223aSi4qZ9RW+or6DVJTZVE2Nx4ABOV129tD3F110EWPHjuW+++6joaGBj370o3z5y1/m4MGDXHbZZdTU1NDY2MgXvvAFamtr2bp1KxdccAFjxozhsccey2leZmad5aJyvAevg7deeld4QONRaDzMwOLBUNzJzTb+NFh0U6tvZw99//DDD3P//ffz7LPPEhF85CMf4YknnmDHjh1MnDiRX/ziF0BmTLARI0Zw880389hjjzFmzJjO5WRmlgc+/NVRytxoMvLcA+zhhx/m4Ycf5swzz2TOnDm88sorVFVVcdppp/HII49w7bXX8qtf/YoRI0bkNQ8zs67wnsrxWtmjiCOHYed66gdNZNiocS22yYWI4Prrr+czn/nMu95bvXo1K1as4Prrr2fBggV88YtfzFseZmZd4T2VDioqydTfaMr9ifrsoe8vvvhili1bxoEDBwDYsmUL27dvZ+vWrZSVlXHVVVfx+c9/nueff/5d85qZpc17Kh0kFWcOfOWh91f20PeLFi3iyiuv5NxzzwVg6NCh/Ou//ivV1dX87d/+LUVFRZSWlnLrrbcCsHTpUhYtWsSECRN8ot7MUueh7+n4cPDHtr5IfdEQho0/KV/p5Z2HvjezrvDQ93nQqBKUh8NfZmZ9hYtKJzSphGIa007DzKzHclFJdOgwYFEJJXGsY217oN6at5n1Hi4qwKBBg9i1a1e7X7pRVEoJjRxr7H13gIwIdu3axaBBg9JOxcz6MPf+AiZPnkxNTQ07duxos93RQ3spPbKXo7vWUVpaWqDscmfQoEFMnjw57TTMrA9zUQFKS0uZNm1au+02/PJuTnrsL1m16Oecfvr7C5CZmVnvkrfDX5KmSHpM0npJ6yR9Nol/SdIWSWuSxyVZ81wvqVrSq5IuzoovTGLVkq7Lik+T9IykKkn3SsrtSI/HGTJ6EgD1dVvyuRozs14rn+dUjgF/ExEzgPnA1ZJmJu99MyJmJ48VAMl7lwOzgIXAdyUVSyoGvgMsAmYCV2Qt5+vJsqYDu4FP5fHzMHxM5tDR0T1v5XM1Zma9Vt6KSkRsi4jnk+n9wHpgUhuzLAbuiYiGiHgdqAbmJY/qiNgYEUeAe4DFkgRcCNyfzH8ncGl+Pk1G2aiJmYkDLipmZi0pSO8vSZXAmcAzSegaSS9KWiapPIlNAjZnzVaTxFqLjwb2RMSx4+L5M6CMA5RRdLDtE/pmZv1V3ouKpKHAT4DPRcQ+4FbgJGA2sA34RnPTFmaPLsRbymGppFWSVrXXw6s9e4tHMfDw9m4tw8ysr8prUZFUSqag3B0RPwWIiNqIaIyIJuAOMoe3ILOnMSVr9snA1jbiO4GRkkqOi79LRNweEXMjYm5FRUW3PtOhAaMZcmRnt5ZhZtZX5bP3l4DvA+sj4uas+ISsZh8F1ibTy4HLJQ2UNA2YDjwLPAdMT3p6DSBzMn95ZK5UfAz4eDL/EuBn+fo8zY4MHsvwxt2+Ot3MrAX5vE7lPOBPgZckrUlif0em99ZsMoeqNgGfAYiIdZLuA14m03Ps6ohoBJB0DfAQUAwsi4h1yfKuBe6R9FXgBTJFLK9i6DjG7nqCvYeOMHLIwHyvzsysV8lbUYmIJ2n5vMeKNua5EbixhfiKluaLiI387vBZQRSNmEiZGqjZuZ2RQ6a0P4OZWT/isb86aeCoTCHZU/tmypmYmfU8LiqdNLTiBADqd7qomJkdz0Wlk8rHVwJwtK4m3UTMzHogF5VOGjAyc1V97N+WciZmZj2Pi0pnlQygTiMZcNBFxczseC4qXbCvtIKyw7Vpp2Fm1uO4qHTBoUHjGHHMV9WbmR3PRaULjg6ZQEXsouFYY9qpmJn1KC4qXaDhEynXAXbs2p12KmZmPYqLSheUlmdG2N9T+0bKmZiZ9SwuKl0wJLkAcv+Oze20NDPrX1xUumDkuEoAGna5qJiZZXNR6YJhFZnxv5r2bkk5EzOznsVFpQs0cCj7GULRAV8AaWaWzUWli/aUVjCo3hdAmpllc1HpokMDxzH8qO9Vb2aWzUWli44NGc+YJl8AaWaWzUWlq0ZOZqz28Fbd3rQzMTPrMVxUumjA6KkA7NqyMeVMzMx6DheVLho2bhoA+2tfTzkTM7Oew0Wli8onngTAkZ0eqsXMrJmLShcNLJ9CE0J7fVW9mVkzF5WuKhlAXdEoBhzcmnYmZmY9hotKN+wdMJ5hDb6q3sysWd6KiqQpkh6TtF7SOkmfTeKjJK2UVJU8lydxSbpFUrWkFyXNyVrWkqR9laQlWfGzJL2UzHOLJOXr87Skvmwio4/VEhGFXK2ZWY+Vzz2VY8DfRMQMYD5wtaSZwHXAoxExHXg0eQ2wCJiePJYCt0KmCAE3AOcA84AbmgtR0mZp1nwL8/h53qVp+BTGs4vdBxsKuVozsx4rb0UlIrZFxPPJ9H5gPTAJWAzcmTS7E7g0mV4M3BUZTwMjJU0ALgZWRkRdROwGVgILk/eGR8RTkdlVuCtrWQVRPOoEBqiR7VvdA8zMDAp0TkVSJXAm8AwwLiK2QabwAGOTZpOA7K5UNUmsrXhNC/GW1r9U0ipJq3bs2NHdj/O2IRWVAOzdtiFnyzQz683yXlQkDQV+AnwuIva11bSFWHQh/u5gxO0RMTci5lZUVLSXcoc1X6tSv2NTzpZpZtab5bWoSColU1DujoifJuHa5NAVyXPzUL81wJSs2ScDW9uJT24hXjDDx2euqm/a/WYhV2tm1mPls/eXgO8D6yPi5qy3lgPNPbiWAD/Lin8i6QU2H9ibHB57CFggqTw5Qb8AeCh5b7+k+cm6PpG1rILQwGHsYxgl+2vab2xm1g+U5HHZ5wF/CrwkaU0S+zvgJuA+SZ8C3gT+KHlvBXAJUA0cAj4JEBF1kv4BeC5p95WIqEum/wL4ATAYeDB5FFTdgHEMrvcFkGZmkMeiEhFP0vJ5D4APtNA+gKtbWdYyYFkL8VXAe7uRZrcdGjyR8r0eqdjMDHxFfbc1DpvMhNjB3oNH0k7FzCx1LirdVDLqBIaoga1vbUk7FTOz1LmodNOQ8ScDsLumKuVMzMzS56LSTaMmnwLAodrqlDMxM0ufi0o3DU32VJp2b0o3ETOzHsBFpbsGDGG3RjJwn8f/MjNzUcmB3QMnMvywT9Sbmbmo5MChIVOoOLaNpibfV8XM+jcXlRxoGlnJBHaxfc/+tFMxM0uVi0oODKg4iWIFtZvdrdjM+jcXlRwYPnE6APu3uqiYWf/mopIDo6dkrlU5stNjgJlZ/+aikgMDR0ykgQFoj7sVm1n/5qKSC0VF7CgZT9kB36zLzPo3F5Uc2T94EiMbfF8VM+vfXFRy5OjwSiZGLfvrPQS+mfVfLio5UjpmGsNUT81WX1lvZv1Xu0VFUrGkvy5EMr3ZsAmZgSV3vrk+5UzMzNLTblGJiEZgcQFy6dXGTJ0FQP2211LOxMwsPR29R/2vJX0buBc42ByMiOfzklUvNKjiRI5RBHUb0k7FzCw1HS0q70uev5IVC+DC3KbTi5UMYEfxeIbsfz3tTMzMUtOhohIRF+Q7kb5gb1klo/dvTjsNM7PUdKj3l6QRkm6WtCp5fEPSiHwn19scGTmNE2Ibew81pJ2KmVkqOtqleBmwH7gseewD/l++kuqtSiqmU6YGtrzpMcDMrH/qaFE5KSJuiIiNyePLwIltzSBpmaTtktZmxb4kaYukNcnjkqz3rpdULelVSRdnxRcmsWpJ12XFp0l6RlKVpHslDej4x86P4ZNmALB788spZ2Jmlo6OFpV6Sb/X/ELSeUB9O/P8AFjYQvybETE7eaxIljcTuByYlczz3eT6mGLgO8AiYCZwRdIW4OvJsqYDu4FPdfCz5M2Yykxqh99yt2Iz65862vvrz4G7ss6j7AaWtDVDRDwhqbKDy18M3BMRDcDrkqqBecl71RGxEUDSPcBiSevJ9Dy7MmlzJ/Al4NYOri8vBpVPpp6BFLtbsZn1Ux25or4IODUizgBOB06PiDMj4sUurvMaSS8mh8fKk9gkILvbVE0Say0+GtgTEceOi7f2GZY2dzLYsWNHF9PugKIitpdOYsjBTflbh5lZD9aRK+qbgGuS6X0Rsa8b67sVOAmYDWwDvpHE1dKquxBvUUTcHhFzI2JuRUVF5zLupP1DKqloqCGi1XTMzPqsjp5TWSnp85KmSBrV/OjsyiKiNiIak0J1B787xFUDTMlqOhnY2kZ8JzBSUslx8dQ1lZ/EZGrZvudA2qmYmRVcR4vKfwGuBp4AViePVZ1dmaQJWS8/CjT3DFsOXC5poKRpwHTgWeA5YHrS02sAmZP5yyOzG/AY8PFk/iXAzzqbTz4MmnAKJWqi5vVX0k7FzKzg2j1Rn5xTuSoift2ZBUv6EXA+MEZSDXADcL6k2WQOVW0CPgMQEesk3Qe8DBwDrk4GskTSNcBDQDGwLCLWJau4FrhH0leBF4Dvdya/fBlzwkz4Dex5cx3MOTvtdMzMCqrdohIRTZL+ETi3MwuOiCtaCLf6xR8RNwI3thBfAaxoIb6R3x0+6zHKk9GKj9W+mnImZmaF19HDXw9L+piklk6QWxYNLmdX0WgG7alKOxUzs4Lr6HUq/x0oAxolHSbT+yoiYnjeMuvFdg2expiDHq3YzPqfju6pjAD+DPhqUkhmARflK6nerqF8OpWxmb0Hfb96M+tfOlpUvgPMB5rPk+wHvp2XjPqAkvEzGKIG3tzkHmBm1r90tKicExFXA4cBImI3kPoAjj1V+dTTAKjb9FLKmZiZFVZHi8rRZHDHAJBUATTlLatermLaGQAcfWt9ypmYmRVWR4vKLcADwFhJNwJPAl/LW1a9XPHQ0dRpJAPrPFqxmfUvHb2d8N2SVgMfINPz69KI8H/D27Bj0DRGHXIPMDPrXzrapZiIeAXwmecOqh85nZO2/pxDDUcpG1iadjpmZgXR0cNf1kkDJsxgmOp5/fXqtFMxMysYF5U8GVWZOVm/Y8OalDMxMyscF5U8GXtipqg0bF3XTkszs77DRSVPioaOoa6onIF17s9gZv2Hi0oe7Sybzvj6Kt8F0sz6DReVPDpSMYsTo4a3dnfnDsxmZr2Hi0oeDZp8BgPUyObXfpt2KmZmBeGikkfjpmfu/Lh/0wspZ2JmVhguKnk0bNJ7aKAUbV+bdipmZgXhopJPxSVsGzCNkfs8BpiZ9Q8uKnm2b8SpVB7dwJGjjWmnYmaWdy4qeaYJpzFK+9no4VrMrB9wUcmzMSedBUDta6tSzsTMLP9cVPJs3PRMUTlc427FZtb3uajkWVFZOduLxzGkzmOAmVnfl7eiImmZpO2S1mbFRklaKakqeS5P4pJ0i6RqSS9KmpM1z5KkfZWkJVnxsyS9lMxziyTl67N0167hs5ja8BpHG30HZjPr2/K5p/IDYOFxseuARyNiOvBo8hpgETA9eSwFboVMEQJuAM4B5gE3NBeipM3SrPmOX1ePERPPZIq2s+GNN9JOxcwsr/JWVCLiCaDuuPBi4M5k+k7g0qz4XZHxNDBS0gTgYmBlRNRFxG5gJbAweW94RDwVmdEa78paVo9TPn0+ALXrn0o5EzOz/Cr0OZVxEbENIHkem8QnAZuz2tUksbbiNS3EWyRpqaRVklbt2LGj2x+is8adeg5NIY5uXl3wdZuZFVJPOVHf0vmQ6EK8RRFxe0TMjYi5FRUVXUyx64oGj2Bb6WSG171Y8HWbmRVSoYtKbXLoiuR5exKvAaZktZsMbG0nPrmFeI9VN2IWUxuqfLLezPq0QheV5UBzD64lwM+y4p9IeoHNB/Ymh8ceAhZIKk9O0C8AHkre2y9pftLr6xNZy+qZJs1hnHazYUNV2pmYmeVNPrsU/wh4CjhVUo2kTwE3ARdJqgIuSl4DrAA2AtXAHcBfAkREHfAPwHPJ4ytJDOAvgH9O5tkAPJivz5ILFaecC8Bb63+TciZmZvlTkq8FR8QVrbz1gRbaBnB1K8tZBixrIb4KeG93ciykcafM5RjFHN28Cvhk2umYmeVFTzlR3+dpQBlbB0yjvO6ltFMxM8sbF5UC2l9xJu9pfJVd+w6mnYqZWV64qBTQ4JPOY6gOU/XSs2mnYmaWFy4qBTTx9AsA2PfakylnYmaWHy4qBTRo9FR2Fo1mSO1zaadiZpYXLiqFJFE7YjbT6tf6Ikgz65NcVAptyjlM1C6qq15JOxMzs5xzUSmwce89H4BtLz2eah5mZvngolJgY046i0MMgjefTjsVM7Occ1EptOISaoaexuT9L9DY1OrAymZmvZKLSgqOnfB7nMKbvLZxY9qpmJnllItKCsadsQCArS88nHImZma55aKSgtEnz+MAZRS/8au0UzEzyykXlTQUl7B5+JlM27+aY75excz6EBeVlByb+n6m6i1ee2192qmYmeWMi0pKJp15MQBb1/i8ipn1HS4qKRlVeQZ7NIIBbzyRdipmZjnjopKWoiK2jj6XWfWr2HuoIe1szMxywkUlRQNnLmS09rH2ucfSTsXMLCdcVFI09ewP04g4tPbBtFMxM8sJF5UUlQwbw6ZBM5m881dEeMgWM+v9XFRSdmjqB5gRG6jauCHtVMzMus1FJWWTzl4MwJtP/yzlTMzMus9FJWWjTjqLXUWjKdu0Mu1UzMy6LZWiImmTpJckrZG0KomNkrRSUlXyXJ7EJekWSdWSXpQ0J2s5S5L2VZKWpPFZuk1i28QPMufIKmre2pF2NmZm3ZLmnsoFETE7IuYmr68DHo2I6cCjyWuARcD05LEUuBUyRQi4ATgHmAfc0FyIepuKeZcxSEd59Vf3p52KmVm39KTDX4uBO5PpO4FLs+J3RcbTwEhJE4CLgZURURcRu4GVwMJCJ50L4957AXUaSVn1z9NOxcysW9IqKgE8LGm1pKVJbFxEbANInscm8UnA5qx5a5JYa/F3kbRU0ipJq3bs6IGHmIqKqRl/EbMPP0ftrl1pZ2Nm1mVpFZXzImIOmUNbV0t6fxtt1UIs2oi/Oxhxe0TMjYi5FRUVnc+2AEbP+ziDdYR1j/sQmJn1XqkUlYjYmjxvBx4gc06kNjmsRfK8PWleA0zJmn0ysLWNeK806YyL2K2RDHr139JOxcysywpeVCQNkTSseRpYAKwFlgPNPbiWAM0XbiwHPpH0ApsP7E0Ojz0ELJBUnpygX5DEeqeiYrZM/hBzG56h+o03087GzKxL0thTGQc8Kem3wLPALyLiP4CbgIskVQEXJa8BVgAbgWrgDuAvASKiDvgH4Lnk8ZUk1mtNuuBTDFAjG//zzvYbm5n1QOpvY07NnTs3Vq1alXYarXrja2dx6GhwyhdWU1zU0mkjM7PCk7Q66xKQVvWkLsUGHHjPZcyIDbyw6tdpp2Jm1mkuKj3MyR/8JEcoYe+T/5x2KmZmneai0sMMHD6WqjEfZN7e/2DLW7Vpp2Nm1ikuKj3Q2A9+lmGq5+X/+F7aqZiZdYqLSg9U8Z73sXHgDKZv+iGHjxxNOx0zsw5zUemhGs/+NJVs4zcP/jDtVMzMOsxFpYc6+fyr2F40lnFrvs3RY41pp2Nm1iEuKj2USgZSN+caZsVr/GalxwMzs97BRaUHO/Xiz7BDYxj13Dc55r0VM+sFXFR6MJUOYufsv+S0pvU88eCP0k7HzKxdLio93Hs+dA1biycxbfXX2H/wUNrpmJm1yUWlh1PJQBou/ArT2MIzP/7HtNMxM2uTi0ovMO19H+O1srM4+/XbqN5QnXY6ZmatclHpDSQqLv8nBuooO++9msbGprQzMjNrkYtKL1F+wiyqZ/0V8488zeP3fyftdMzMWuSi0ovM+sPr2TBwJvNevpG1L/bce8KYWf/lotKLqLiEik/eTaNKKHvgz9hZtyvtlMzM3sFFpZcZPv5E9lxyG1Obath42xUcqq9POyUzs7e5qPRClfP+gNfmfIF5R57hhX/6E49kbGY9hotKLzVj8d/w4qmf5bxDj7L6mx+Ipaq5AAAJ4ElEQVRn/4EDaadkZuai0pudfsVXWDfjrzmv/nE2feti3nzzjbRTMrN+zkWll5v1x1/i5XO/wSnHXmXI93+fXz/4QyIi7bTMrJ9yUekDZl78X9lz1cMcKC3nvGf+glU3LeLVtc+nnZaZ9UMuKn3EuJPnMPl/PM2aU/6KmQ0vMP3HF7L6potZ9ch9HD58OO30zKyfUG8/VCJpIfB/gWLgnyPiprbaz507N1at6tsXDu7ftYXXlt/MiW/cRzn72BtDeHXYORybNI9Rp76PiSefwfDhI9NO08x6EUmrI2Juu+16c1GRVAy8BlwE1ADPAVdExMutzdMfikqzYw2HeO3XP6P+xX9j6p5nGMPut9/byUh2lozncOkIjg0YTuOAETSWDkXFpai4lKKSzHOTSkBFoMx8evtfIWVFlJmK5obNlP36uPc6oXu/pV1cr7qTb9fn7Uq+UVzKKb//ccpHjenGes1a19GiUlKIZPJoHlAdERsBJN0DLAZaLSr9ScnAMmZeeAVceAVEUFtTzbZ1T9JQW4X2bKKsfhtDj+yk7PDrDG06QBmHKZEHq+ytjjz/9+zSUJoooklF7yhsnStTXSvh6mbp76rulO/Or6v3/iccYNi1axk4aEhe19Hbi8okYHPW6xrgnOMbSVoKLAU44YQTCpNZTyMxbsp0xk2Z3mazpsZGjhw9QkNDA41HjxCNR97+MwoCmjKvmndwgyCi+WvouD+4d+wFd+OPsRt7013+EujWHnzhP+u+N16k7qWHiaP1KJoQjd1ZXJc/Qff20LqusOtN5zPmwtnK/1d+by8qLf103/X3EBG3A7dD5vBXvpPqzYqKixlUPJhBgwannYp1wvipp8L7/yjtNMx6fe+vGmBK1uvJwNaUcjEz6/d6e1F5DpguaZqkAcDlwPKUczIz67d69eGviDgm6RrgITJdipdFxLqU0zIz67d6dVEBiIgVwIq08zAzs95/+MvMzHoQFxUzM8sZFxUzM8sZFxUzM8uZXj32V1dI2gF09W5WY4CdOUwnV5xX5zivznFendNX85oaERXtNep3RaU7JK3qyIBqhea8Osd5dY7z6pz+npcPf5mZWc64qJiZWc64qHTO7Wkn0Arn1TnOq3OcV+f067x8TsXMzHLGeypmZpYzLipmZpYzLiodIGmhpFclVUu6rsDrniLpMUnrJa2T9Nkk/iVJWyStSR6XZM1zfZLrq5IuzmNumyS9lKx/VRIbJWmlpKrkuTyJS9ItSV4vSpqTp5xOzdomayTtk/S5tLaXpGWStktamxXr9DaStCRpXyVpSZ7y+j+SXknW/YCkkUm8UlJ91ra7LWues5Lfgeok927dFrGVvDr9s8v132wred2bldMmSWuSeCG3V2vfD+n9jkWEH208yAypvwE4ERgA/BaYWcD1TwDmJNPDgNeAmcCXgM+30H5mkuNAYFqSe3GectsEjDku9r+B65Lp64CvJ9OXAA+SuVvnfOCZAv3s3gKmprW9gPcDc4C1Xd1GwChgY/JcnkyX5yGvBUBJMv31rLwqs9sdt5xngXOTnB8EFuUhr0797PLxN9tSXse9/w3giylsr9a+H1L7HfOeSvvmAdURsTEijgD3AIsLtfKI2BYRzyfT+4H1wKQ2ZlkM3BMRDRHxOlBN5jMUymLgzmT6TuDSrPhdkfE0MFLShDzn8gFgQ0S0NYJCXrdXRDwB1LWwzs5so4uBlRFRFxG7gZXAwlznFREPR8Sx5OXTZO6k2qokt+ER8VRkvpnuyvosOcurDa397HL+N9tWXsnexmXAj9paRp62V2vfD6n9jrmotG8SsDnrdQ1tf6nnjaRK4EzgmSR0TbILu6x595bC5hvAw5JWS1qaxMZFxDbI/MIDY1PIq9nlvPMPPe3t1ayz2yiNHP8Lmf/RNpsm6QVJv5T0+0lsUpJLIfLqzM+u0Nvr94HaiKjKihV8ex33/ZDa75iLSvtaOuZZ8H7YkoYCPwE+FxH7gFuBk4DZwDYyu99Q2HzPi4g5wCLgaknvb6NtQbejMreX/gjw4yTUE7ZXe1rLpdDb7u+BY8DdSWgbcEJEnAn8d+CHkoYXMK/O/uwK/TO9gnf+56Xg26uF74dWm7aSQ85yc1FpXw0wJev1ZGBrIROQVErmF+buiPgpQETURkRjRDQBd/C7QzYFyzcitibP24EHkhxqmw9rJc/bC51XYhHwfETUJjmmvr2ydHYbFSzH5ATtHwB/khyiITm8tCuZXk3mfMUpSV7Zh8jyklcXfnaF3F4lwB8C92blW9Dt1dL3Ayn+jrmotO85YLqkacn/fi8Hlhdq5cnx2u8D6yPi5qx49vmIjwLNvVKWA5dLGihpGjCdzMnBXOc1RNKw5mkyJ3nXJutv7jmyBPhZVl6fSHqfzAf2Nu+e58k7/veY9vY6Tme30UPAAknlyaGfBUkspyQtBK4FPhIRh7LiFZKKk+kTyWyjjUlu+yXNT35PP5H1WXKZV2d/doX8m/0g8EpEvH1Yq5Dbq7XvB9L8HetOz4P+8iDTY+I1Mv/j+PsCr/v3yOyGvgisSR6XAP8CvJTElwMTsub5+yTXV+lm75I28jqRTK+a3wLrmrcLMBp4FKhKnkclcQHfSfJ6CZibx21WBuwCRmTFUtleZArbNuAomf8Nfqor24jMOY7q5PHJPOVVTea4evPv2W1J248lP+PfAs8DH85azlwyX/IbgG+TjNKR47w6/bPL9d9sS3kl8R8Af35c20Jur9a+H1L7HfMwLWZmljM+/GVmZjnjomJmZjnjomJmZjnjomJmZjnjomJmZjnjomLWS0g6X9K/p52HWVtcVMzMLGdcVMxyTNJVkp5V5l4a35NULOmApG9Iel7So5IqkrazJT2t393DpPm+FydLekTSb5N5TkoWP1TS/crc9+Tu5Ipqsx7DRcUshyTNAP6YzGCbs4FG4E+AIWTGIpsD/BK4IZnlLuDaiDidzBXOzfG7ge9ExBnA+8hczQ2ZUWg/R+aeGScC5+X9Q5l1QknaCZj1MR8AzgKeS3YiBpMZzK+J3w06+K/ATyWNAEZGxC+T+J3Aj5Mx1SZFxAMAEXEYIFnes5GMM6XMnQYrgSfz/7HMOsZFxSy3BNwZEde/Iyh94bh2bY2P1NYhrYas6Ub8N2w9jA9/meXWo8DHJY2Ft+8VPpXM39rHkzZXAk9GxF5gd9ZNnP4U+GVk7odRI+nSZBkDJZUV9FOYdZH/l2OWQxHxsqT/SeaOmEVkRrW9GjgIzJK0GthL5rwLZIYlvy0pGhuBTybxPwW+J+kryTL+qIAfw6zLPEqxWQFIOhARQ9POwyzffPjLzMxyxnsqZmaWM95TMTOznHFRMTOznHFRMTOznHFRMTOznHFRMTOznPn/9DrWf5p/M4QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model error')\n",
    "plt.ylabel('error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(error_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,)\n",
      "(401,)\n",
      "[[Model]]\n",
      "    Model(gaussian)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 25\n",
      "    # data points      = 400\n",
      "    # variables        = 3\n",
      "    chi-square         = 4655.09024\n",
      "    reduced chi-square = 11.7256681\n",
      "    Akaike info crit   = 987.700812\n",
      "    Bayesian info crit = 999.675205\n",
      "[[Variables]]\n",
      "    amp:  99.3568037 +/- 0.75854847 (0.76%) (init = 1000)\n",
      "    cen: -0.27392505 +/- 0.01823456 (6.66%) (init = 0)\n",
      "    wid:  2.92513794 +/- 0.02578757 (0.88%) (init = 1)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(amp, wid) = -0.577\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl0VfW5//H3kwlIQoAEiIwBFRyw1wFUxNJ6Vayoq6B1aqXlp7Ssq3bUn63ivaXLW29bW7W3Dq30ap1wbLF1/ZyugK0ToFDFoVEEkaGABIiBEAIkeX5/7H3CITkkZ0rOCfm81jor53z3d+/zbDhnP+c77L3N3RERke4nJ9MBiIhIZigBiIh0U0oAIiLdlBKAiEg3pQQgItJNKQGIiHRTSgAiIt2UEoCISDelBCAi0k3lZTqAtvTv399HjBiR6TBERLqUZcuWbXH3Ae3Vy+oEMGLECJYuXZrpMEREuhQzWxNPPXUBiYh0U0oAIiLdlBKAiEg3pQQgItJNtZsAzOw+M9tsZu9FlZWa2Ytm9lH4t19Ybmb2GzNbaWbvmNkJUetMD+t/ZGbTO2Z3REQkXvG0AO4Hzm5Rdj2wwN1HAQvC1wCTgVHhYybwWwgSBjAbOBk4CZgdSRoiIpIZ7SYAd38Z2NaieArwQPj8AWBqVPmDHlgM9DWzQcCXgBfdfZu7VwMv0jqpiIhIJ0p2DKDc3TcChH8HhuVDgHVR9daHZQcqFznozJ8/nyVLlmQ6DJF2pftEMItR5m2Ut96A2UyC7iOGDx+evshEOsGGDRuYNGkS5eXlbNq0KdPhiLQp2RbAp2HXDuHfzWH5emBYVL2hwIY2yltx9znuPs7dxw0Y0O6ZzCJZZfDgwYwePZrq6mrcY/7GEckaySaAp4HITJ7pwF+iyr8RzgYaD9SEXUQvAGeZWb9w8PessEzkoHPVVVexZ88eqqqqMh2KSJva7QIys0eB04D+ZraeYDbPz4EnzGwGsBa4KKz+LHAOsBKoAy4HcPdtZvafwJthvZvcveXAskiXd+2117J161YAKisrGThwYDtriGSOZXMzddy4ca6LwUlX4e4UFRUxZcoU6uvrueGGGzjppJMyHZZ0Q2a2zN3HtVcvq68GKtKVVFVVsWvXLk455RS++93vZjockXbpUhAiabJ27VoAKioqADQILFlPCUAkTdavXw/AsGHDOOWUU7jkkksyHJFI25QARNJkz5499O3bl9LSUvLz8zULSLKeEoBImlx88cVUV1czYsQIysrK2LJlS6ZDEmmTEoBIB+jfv3/zdFCRbKUEIJImd955J9/85jcBmlsAGgiWbKZpoCJp8vrrr/Pmm8G5jhMnTmTXrl00NDSQn5+f4chEYlMCEEmT6upq+vULbnNx7rnncu6552Y4IpG2qQtIJE2iEwDArl272Lt3bwYjEmmbEoBImmzbtq05Abz22msUFhby17/+NbNBibRBCUAkTcrLyxk5ciQAxcXFAOzYsSOTIYm0SWMAImnyyiuvND8vKSkBYPv27ZkKR6RdagGIdIDevXsDagFIdlMCEEmDzZs384UvfIHnnnsO2JcA1AKQbKYEIJIG27Zt45VXXqG6uhqAHj16MGvWLCZMmJDhyEQOTGMAImkQ6eqJ/PIHuPnmmzMVjkhc1AIQSYPa2lpg/wTw2Wef6YJwktWUAETSINICiEz/BDjttNOYMWNGpkISaZcSgEgaFBYWcsIJJ1BaWtpc1rt3bw0CS1bTGIBIGpx55pksW7Zsv7KSkhI+/fTTDEUk0j61AEQ6iFoAku2UAETS4M4772Ts2LH7Xf+/pKREJ4JJVlMXkEgarF69mg8++AAzay676KKLOO644zIYlUjblABE0qC2tna/KaAAkyZNYtKkSRmKSKR96gISSYMdO3a0SgA1NTVUVlbS2NiYoahE2qYEIJIGO3bs2O8cAIC5c+dy9NFH62QwyVrqAhJJgzFjxlBRUbFfWWFhIQB1dXWZCEmkXUoAImnw85//vFVZUVERADt37uzscETioi4gkQ6iFoBkOyUAkTQYP348119//X5lagFItkspAZjZD8zsfTN7z8weNbOeZjbSzJaY2Udm9riZFYR1e4SvV4bLR6RjB0SywapVq1qd9HXkkUcyZ84cRo8enaGoRNqWdAIwsyHAd4Fx7n4MkAtcCvwCuN3dRwHVQORyiDOAanc/HLg9rCdyUKirq2vu8ok45JBD+Na3vsWQIUMyFJVI21LtAsoDeplZHlAIbAROB/4YLn8AmBo+nxK+Jlx+hkWfNinSRbl7zASwd+9eli5dyqZNmzIUmUjbkk4A7v5P4FfAWoIDfw2wDPjM3RvCauuByM+fIcC6cN2GsH5Zy+2a2UwzW2pmS6uqqpINT6TT1NfXA7RKANXV1Zx44onMmzcvE2GJtCuVLqB+BL/qRwKDgSJgcoyqkatjxfq1760K3Oe4+zh3HzdgwIBkwxPpNI2NjVx44YUcddRR+5VrEFiyXSrnAZwJrHb3KgAzmwdMAPqaWV74K38osCGsvx4YBqwPu4z6ANtSeH+RrFBcXMyTTz7ZqrxXr16ApoFK9kplDGAtMN7MCsO+/DOAfwAvAReGdaYDfwmfPx2+Jly+0KOvnStykMnJyaFXr15qAUjWSmUMYAnBYO7fgXfDbc0BfgRcY2YrCfr47w1XuRcoC8uvAa5vtVGRLmj58uWUlpbywgsvtFpWWFioFoBkrZQuBeHus4HZLYo/Bk6KUbceuCiV9xPJRrW1tVRXV5OT0/r31O9///tW1wgSyRa6FpBIiiK/8FvOAgI4//zzOzsckbjpUhAiKWorASxbtoylS5d2dkgicVELQCRFkUHeWAngBz/4AXl5eSxcuLCzwxJpl1oAIimqqKhg+vTplJaWtlqmQWDJZmoBiKTo1FNP5dRTT425rKioiH/+85+dHJFIfNQCEElRW6ezqAUg2UwJQCRFs2fPpmfPnjETQVFRkU4Ek6ylLiCRFO3atYvc3FxiXdz229/+NpdcckkGohJpnxKASIpiXQo64phjjunkaETipy4gkRS1lQBWrVrFk08+SUNDQ8zlIpmkBCCSorYSwDPPPMPFF1/M9u3bOzkqkfapC0gkRWeffTbHH398zGWRxFBXVxfzPAGRTFICEEnR5ZdffsBlkQSgmUCSjdQFJJKinTt3snfv3pjLIncF07kAko2UAERSNGHCBC6++OKYy6K7gESyjbqARFLU1iDwiSeeyGuvvabpoJKVlABEUtRWAujbty8TJkzo5IhE4qMuIJEU7dy584AJoLa2lvvvv58VK1Z0clQi7VMCEElRWy2AmpoaLr/8cv72t791clQi7VMXkEgK3J1Zs2bx+c9/PuZyTQOVbKYEIJICM+MnP/nJAZdrGqhkM3UBiaSgoaGBjRs3Ul9fH3N5fn4+ubm5agFIVlICEEnBunXrGDx4MI8//njM5Wamm8JI1lIXkEgKIgf2Aw0CAyxatIj+/ft3VkgicVMCEElBPAlgzJgxnRWOSELUBSSSgngSwGOPPcaf//znzgpJJG5qAYikIJ4EcPvtt1NaWsrUqVM7KyyRuKgFIJKC0aNHc8stt1BRUXHAOhoElmylFoBICg477DCuu+66NusUFhayefPmTopIJH5qAYikYOvWrXz00Uc0NjYesI5aAJKtUkoAZtbXzP5oZh+YWaWZnWJmpWb2opl9FP7tF9Y1M/uNma00s3fM7IT07IJI5jz44IOMHj2a2traA9ZRApBslWoL4L+B5939SOBYoBK4Hljg7qOABeFrgMnAqPAxE/htiu8tknHxDALfeuutLF68uLNCEolb0gnAzEqALwD3Arj7Hnf/DJgCPBBWewCITH2YAjzogcVAXzMblHTkIlmgrq6OvLw88vPzD1inf//+lJeXd2JUIvFJpQVwKFAF/MHM3jKz/zGzIqDc3TcChH8HhvWHAOui1l8flol0WW1dCjrilVdeYfbs2bh7J0UlEp9UEkAecALwW3c/HtjJvu6eWCxGWatvhJnNNLOlZra0qqoqhfBEOl48CeDVV1/lpptuYs+ePZ0UlUh8UkkA64H17r4kfP1HgoTwaaRrJ/y7Oar+sKj1hwIbWm7U3ee4+zh3HzdgwIAUwhPpeNOmTeOXv/xlm3V0Y3jJVkknAHffBKwzsyPCojOAfwBPA9PDsunAX8LnTwPfCGcDjQdqIl1FIl3VxIkTmTZtWpt1lAAkW6V6Ith3gLlmVgB8DFxOkFSeMLMZwFrgorDus8A5wEqgLqwr0qX94x//IC8vj9GjRx+wjhKAZKuUEoC7vw2Mi7HojBh1Hbg6lfcTyTZXXnklOTk5vPTSSwesowQg2UqXghBJQV1dHQMHDmyzzjnnnENNTQ3FxcWdFJVIfJQARFIQzyygHj160KNHj06KSCR+uhaQSAriSQAbNmzguuuu45133umkqETiowQgkoJ4EkBNTQ2/+tWvqKys7KSoROKjLiCRFNxzzz0MHTq0zToaBJZspQQgkoJ47vKlBCDZSl1AIklqaGjgxRdfZN26dW3WUwKQbKUEIJKkHTt2cNZZZzFv3rw26/Xq1QuA+vr6zghLJG7qAhJJUjz3AgDIyclh79695OXp6ybZRS0AkSTFmwAAHfwlKykBiCQpkgAiXTxtufHGG7n33ns7OiSRhCgBiCQpkRbAH//4R+bPn9/RIYkkRAlAJElHHnkkzz77LGPHjm23rm4ML9lIHZMiSerXrx+TJ0+Oq64SgGQjtQBEkrRmzRqeeuopamtr262rBCDZSAlAJEkLFy7kggsuYMuWLe3W7devn2YCSdbRJ1IkSZFf9EVFRe3WfeKJJzo6HJGEqQUgkqREZgGJZCMlAJEkJXIewEMPPcT06dM7OiSRhCgBiCSprq6Onj17kpPT/tfovffeUzeQZB0lAJEkXX311SxYsCCuuoWFhdTX19PU1NTBUYnET4PAIkkaPnw4w4cPj6tuZJxg165dcQ0ai3QGtQBEkrRgwQKefvrpuOrqngCSjdQCEEnSb37zG9auXcuXv/zlduuWlpYybNgw9uzZ0wmRicRHLQCRJMVzQ/iIr371q6xdu5YhQ4Z0cFQi8VMCEElSIglAJBspAYgkKZEE8O677zJ58mSWL1/ewVGJxE8JQCRJdXV1cZ0EBlBbW8vzzz/Ppk2bOjgqkfhpEFgkSc888wz5+flx1dUsIMlGSgAiSTr88MPjrqsEINlIXUAiSbr99tt544034qqrBCDZKOUEYGa5ZvaWmf2/8PVIM1tiZh+Z2eNmVhCW9whfrwyXj0j1vUUyZc+ePVxzzTVx3+e3qKiII488UmcBS1ZJRwvge0Bl1OtfALe7+yigGpgRls8Aqt39cOD2sJ5IlxS5C1i8B/S+fftSWVnJ1772tY4MSyQhKSUAMxsKnAv8T/jagNOBP4ZVHgCmhs+nhK8Jl58R1hfpcnbu3AlAcXFxhiMRSV6qLYBfAz8EIpc4LAM+c/eG8PV6IHLq4xBgHUC4vCasL9LlJNoCADj77LO5/fbbOyokkYQlnQDM7Dxgs7sviy6OUdXjWBa93ZlmttTMllZVVSUbnkiHiiSARFoAb731FitWrOiokEQSlso00FOBL5vZOUBPoISgRdDXzPLCX/lDgQ1h/fXAMGC9meUBfYBtLTfq7nOAOQDjxo1rlSBEssGxxx7L2rVrKSuLvxFbWFioWUCSVZJuAbj7De4+1N1HAJcCC939MuAl4MKw2nTgL+Hzp8PXhMsXursO8NIlFRQUMGzYsISuBaQEINmmI84D+BFwjZmtJOjjvzcsvxcoC8uvAa7vgPcW6RTLly/npz/9Kdu2tWrEHpASgGSbtJwJ7O5/Bf4aPv8YOClGnXrgonS8n0imvfnmm/zHf/wH06dPp7S0NK51TjjhBHr27NnBkYnET5eCEElCZBpoIrOA7rnnno4KRyQpuhSESBKSmQUkkm2UAESSUFtbS35+PgUFBXGvM3v2bE4//fQOjEokMUoAIkmora1N+Lo+W7Zs4Z133umgiEQSpwQgkoRbb72V1atXJ7ROcXFxc9eRSDbQILBIEgoKChLq/oEgAezevZuGhgby8vTVk8xTC0AkCb/73e+46667ElonMmAcmUEkkmlKACJJePTRR3nyyScTWmfUqFFMnjyZxsbGDopKJDFqh4okoba2lkGDBiW0znnnncd5553XQRGJJE4tAJEk7Ny5U+cASJenBCCShGSmgS5ZsoRhw4bx2muvdVBUIolRAhBJQn19fcItgJycHNavX89nn33WQVGJJEZjACJJqKqqoqmpqf2KUSIJQ+cCSLZQC0AkCWZGbm5uQusoAUi2UQIQSdCOHTuYMWMGf/vb3xJaTwlAso0SgEiCqqurue+++1i1alVC6xUXF3PhhRdy6KGHdlBkIonRGIBIgiK/4BOdBZSfn5/wyWMiHUktAJEERS7loPMApKtTAhBJULItAIDjjjuOGTNmpDskkaQoAYgkaO/evZSUlNC7d++E121qakroRvIiHUljACIJOuuss6ipqUlq3ZKSErZv357miESSoxaASCcqKSlJOnmIpJsSgEiCnnrqKS699FLq6+sTXlctAMkmSgAiCXr77bd5/PHHE74jGATdRxdeeGEHRCWSOI0BiCSopqaG3r17k5OT+O+nK664ogMiEkmOWgAiCdq+fTt9+vRJev29e/fi7mmMSCQ5SgAiCaqpqUk6Adxxxx0UFBToktCSFZQARBLUu3fvpK/nEzl7WAPBkg00BiCSoPvvvz/pdUtKSgAlAMkOagGIdCIlAMkmSgAiCTr//PO5++67k1o3kgB0Mphkg6QTgJkNM7OXzKzSzN43s++F5aVm9qKZfRT+7ReWm5n9xsxWmtk7ZnZCunZCpDM999xzfPLJJ0mtO3z4cK677joqKirSG5RIElJpATQA17r7UcB44GozOxq4Hljg7qOABeFrgMnAqPAxE/htCu8tkhG7d+9m9+7dSc8CGjRoELfccgtjxoxJc2QiiUs6Abj7Rnf/e/h8B1AJDAGmAA+E1R4ApobPpwAPemAx0NfMBiUduUgGRPruUzkPYPv27RoDkKyQljEAMxsBHA8sAcrdfSMESQIYGFYbAqyLWm19WNZyWzPNbKmZLa2qqkpHeCJpE+m7TyUBHHLIIdx0003pCkkkaSknADMrBv4EfN/d2/pZYzHKWp0O6e5z3H2cu48bMGBAquGJpFVTUxPHHXccgwYl33jt168f1dXVaYxKJDkpnQdgZvkEB/+57j4vLP7UzAa5+8awi2dzWL4eGBa1+lBgQyrvL9LZRo8ezVtvvZXSNpQAJFukMgvIgHuBSne/LWrR08D08Pl04C9R5d8IZwONB2oiXUUi3YkSgGSLVLqATgW+DpxuZm+Hj3OAnwOTzOwjYFL4GuBZ4GNgJfB74KoU3lskIx555BHGjx+f0jz+0tJSJQDJCkl3Abn7q8Tu1wc4I0Z9B65O9v1EssGqVatYsmQJhYWFSW9j+vTpSgCSFXQtIJEEbN26lZKSEvLz85PexgUXXJDGiESSp0tBiCRg27ZtlJaWprSN2tpaPvzwQxobG9MUlUhylABEErB169aUE8Af/vAHjjzySLZu3ZqmqESSoy4gkQQcccQRHHbYYSlto3///kCQTAYOHNhObZGOowQgkoDbbrut/UrtiBz0N2/ezFFHHZXy9kSSpS4gkU4WSQC61IlkmhKASJwaGhoYPnw499xzT0rbiW4BiGSSEoBInKqqqli3bh3BKS3JKysr46677uKLX/ximiITSY7GAETitGnTJgDKy8tT2k5eXh5XXaUT4SXz1AIQidOnn34KBJdzjjZ3LowYATk5wd+5c9vf1ooVK3j33XfTH6RIApQAROIU3QKIHPTN4OtfhzVrwD34O20a9OwZLIs8+vffPzHMnDmTq6/WlVEks5QAROI0aNAgxo6dyoknHsK0acHBHoIDf0u7d+//euvWIDFEEsHAgQM1CCwZpwQgEqctW75EZeVTbNuW/IXgtm6FmTOhpmYQGzbodhiSWRoEFonTrFlN1NW1/M3kHMN7jGMp5XxKDk2soYKljGMFR8TcTl0dvPHGMHbs2MH27dspKSnp+OBFYlACEInT2rX/CvQH/kRvtvNt7mQG93IYH8es/wFHcBdXcx9XUEfRfss++yy4Od66desYM2ZMB0cuEpu6gETaMXcuFBcDrMYoZCb38DGH8l/cyCeM4AruZTQf0os6erKLo3mfq7mTbZRyB99lBaO5hMfY/xbYE/nBD/7M0KFDM7NTIgDunrWPsWPHukimPPywe1mZezDMu8fLMJ/PCHfwhZzmY3kzXHbgx+d52d9krDv4E1zofahuXpab627mXlERvJdIugBLPY5jrFoAIlFaTu+MXLF5FK+wCOdU1vMt5nA6C1nGuHa39yoTOZkl/JBfMJU/8xbHM5alADQ2voj7MtasCQaG4zl/QCSdlABEQnPnBgfiltM7J/IyizifvsDp/Ir/4Vsc+G6oUFCw/+smcvklP2Qir2A4L/MFpvIU8H+AO4BgYPjGG9O8QyLtUAIQCd14Y3AgjjaNh5jPmWymjJOZxiK+csD1zeDKK+G++6CiovXyJYznJN5gOcfyJ77CNfQEPmpevnZtmnZEJE5KACKhyC//gPMTZvMQ3+BVPs8ElrGah4B9g7ZnnBEc6M2Cvw89BHffDZddBp98Ag8/HCyLVsVATmchf+Ir3MrH3MkycghuDVlYmPglJURSEs9AQaYeGgSWzvLww8GALLgXUO8P8zV38Hu53PPZ7bDBYW/zAO6VV8a33QMNDhuN/gtOcwd/isnei52t6hQWanBYkoMGgUXi92//Fhx2y9jCfM7kMh5hFjczg3vZSwHwr8AlAJSVBb/04xGrKwjAyeFHXMu3gS/zPAs4gzK27FdH4wLS0ZQApFuLzPGvrYVRrGAx4zmRN7mEx/gZswgGe3cDK4GjKCyE//7v+Ld/881B105sE7mLZVzIIxzH27zOBEa2OKls/24pkfRSApBuae7c4MJs06bBzp1wBvNZzHj6UMPpLOSJ8Nd+4EOgkf79xzBnTtDHH6/LLoM5c/aNFZSVQVHzScF9gBN4iks5k/mUsZVFnMIJLNtvG2YaE5COoQQg3Ur0gT+Y4+/8gNt4gS+xgcGMZzGLmLDfOrm5iwB4/fVxCR38IyKDwk1NsGVL0NooK4ssfQm4hdc5lVN5jV304hUm8lUe2W8ba9YE5yXoPjKSTkoA0m1E5vlHTu4qopYH+Qa3cS1/ZiqnsIiPOWy/dSoqYPz4VykvL+fwww9PWyz7upFeBGYBdXzIkYxnMUsZxyNcxq/5HvnsaV7HHX73O7UEJI3iGSnO1EOzgCQd9r+kQ/A4hdf8Iw7zRsz/nZvcaGw1Cycy0+fVV1/1Rx99NO1xXXmlOzzjgMPzze+bxx6/je+7g7/Nv/i/8PYBZxMVF2umkLRGnLOAMn6Qb+uhBCDJiHXAjzz6ss1/zXe9gRz/mBH+eV6OWa+oqHNi/da36hyKHK5sFcN5PO0bKffd5PtN/LsXsSNmrHl5SgKyPyUA6bIefji4QFp7F0qL1IN9c/gP9Cik1r/H7V5FmTeQ43dxpfemJnbdqPn38+bN81dffbVD9/fEE7/iZuUOu1vFUkZV8zkJ6xnsM/i9F1Df7kXoevSI2kaZEkR3k7UJADibYFrFSuD6tuoqAXR9BzqYt1VeWNj2wS2Rx+Gs8P/kRt9CqTv4fE73z7E8ri6Vbdu2ed++fX3q1Kkd+m/0/PPP+9ChQ/39999396D10TKu8bzuizjZHXwDh/gsfupDWZu2fydwz8nZlzCiY4iVQOJN0pIZWZkAgFxgFXAoUAAsB44+UP1kE8CVV7b/i1CPg/ORz24fz+v+79zkiznJHbwR86eY4uN5vc11o8/ubWpq8hkzZjjgb7/9dlKfw3g1NTX57t27m18//LB7fn6sGJv8TP7Xn+es5sK/MdGv4xc+ljc9N+pMZT0Ojkeyrbd4E0Bn3xHsJGClu38MYGaPAVOAf6TrDa66Cn7723RtTbKF0UQvdlHEToqppQ81DGZD8+NwVnIsyzmKSvJpoAljGWP5v/ySR/kqGxhywG0XFAQXcItM8Vy1ahU//vGPeeSRR5g1axbHHntsx+6bGQUFBTQ2NvL973+fiRMncscdZ/Kzn5W2OBHMmM8k5jOJw1jJpTzGxTzBLfwIgHp68A+O5l0+xwpGs5FBzY9q+lFLMTspYjc9aOtqppI9tm6FK64IniczBbk9FiSLzmFmFwJnu/s3w9dfB05292/Hqj9u3DhfunRpQu+RlwdHNb7L43wJ2LrvvZufVRA0RKoxqvePr3m5AduAmlZfE6MifLYVqG2x7RwiFwsztgB1Uet5+L6Dw5ItGLtabDsPKA9fVQF7Wrx/PjAg3FYV0BC1bYAeQGlYtm/5vhh7AH2bt280tdi7nhi9o94/etsAvYDisGzfZQtsv+WFgGNsoyWjF9ATaCLWvy30wigIl29v3nYBUMSBP6dNwD/J5R2OYzln8XcKeYm72NZqlvMDwJnAC8DlwfYN+vSBXr1g3rx5jB8/njlz5vCd73yHG264gR//+Mfk5HTObOnVq1czadIkVq1aBUDv3r3p06cPRxzxMxYunIb7BwS/l2Dfv7pRzg/5V3oylmf5HE/xOXYzOOr/vqUGoC68BF0jRiMlNNKTRvbSSE1z+b5Px2CCz04tkc/F/oYSfDa3A1tj/E8NJ7j77GcQ43MBI3Byw2XVMZYfGu7vFqBmvyXB1WwODV9tBna0WDcHGBk+3wTsbLE8D5q/0xugxXcy+PQNC5+vJzgrPFpPaP5xsRbY22J5L/Z959dAq/+XIuCQ8PlqaP5Xz+U5ruQ6fgUE05E/+YS4mdkyd2/3hhWd3QKI9bNjv8+Lmc0EZgIMHz484TdobIRd9OI9DiU44LZ8o2MIPqxrgYJWH1bnuHC91cDG1gFyIo4RDGF82mLbucD4sOQDPCoBBXUKgJPDV+8D28JtRfTCOTF8vpzIQXDf+xcDJ4RlfyeSgILXRnBwj/xafQNv8WF2+gOfC1+9DuxpsW/lwNHhtl6G8CqV+2IcDBwBOM6XRhd6AAAFcklEQVRfW2zbCL7ohxN8yF9usW8AI3EOJfgSvdpi2wCjgOE4dcDi5tI95LCTPHZyMjv5HDupYzsvsIFC/kkhmyikgRyCj81JQCXBl62lgc372aPHeUyYANFT+0tLg+R50UUXMWXKFMrLy1tvogONHDmSyspKFi1axKJFi9i0aRM1NTVceulA5s+HNWt6cf31J/DJJ87ixRD5ZHzKoTzGF3mM44F6AHrQyCHUM5hdDOIs+lBOMR9QxHMU00AhDeQCuTi5HE8ufcllI7m8F5Z5VPI/GuhNcICN9RUeQ5D4N2ItvnP7lvcgOIC2PuQYY8LyNQTfzZaOCd/3Y6K/c0F8OWF8EBysWyao/KjlkSQTrWfUciNIUtEKo5Y30TrB9I5avpfoH32BvsBR4fN6WieQMmB0+Hwn+xJEAf+MarV22KXC4+knStcDOAV4Ier1DcANB6qfzBhAbm7m++30yJ5HWVnQt3+wDVg+/LB7QUHm/3316JxHRUVinw+y9GqgbwKjzGykmRUAlwJPp/MNZs5M59akK4n01FRUBNfidw8uvXD33fsuxfDJJx3Tl9rZLrsMdu8O9jP2dYbkYFFQEFxUsCN0agJw9wbg2wSdsJXAE+7+fjrf4+67g7sytbwRh3RdkQN7WVnwiNyAJXKQjzwaG4O/B8tBPh6xrjPU8vdjdJKI/neLlAPkxuq5kYwrK9t/gkK6deogcKKSGQQWEenu4h0E1sXgRES6KSUAEZFuSglARKSbUgIQEemmlABERLqprJ4FZGZVxD6lsyvoT/T1Erof7X/33f/uvO+QHftf4e4D2quU1QmgKzOzpfFMwzpYaf+77/53532HrrX/6gISEemmlABERLopJYCOMyfTAWSY9r/76s77Dl1o/zUGICLSTakFICLSTSkBpJmZ/dLMPjCzd8zsKTPrG7XsBjNbaWYfmtmXMhlnRzGzi8zsfTNrMrNxLZZ1h/0/O9y/lWZ2fabj6Whmdp+ZbTaz96LKSs3sRTP7KPzbL5MxdhQzG2ZmL5lZZfiZ/15Y3mX2Xwkg/V4EjnH3fwFWENz0BjM7muD+B2OAs4G7zexgvAjve8AFBLcUa9Yd9j/cn7uAyQS3ifpquN8Hs/sJ/j+jXQ8scPdRwILw9cGoAbjW3Y8iuBXg1eH/d5fZfyWANHP3/w3vewDBfQ2Hhs+nAI+5+253X01wT8mTMhFjR3L3Snf/MMai7rD/JwEr3f1jd98DPMa+m/gelNz9ZVrfZ3EKwQ2YCf9O7dSgOom7b3T3v4fPdxDc42QIXWj/lQA61hXAc+HzIcC6qGXrIeqmnwe/7rD/3WEf41Hu7hshOEiy72bMBy0zGwEcDyyhC+1/Z98U/qBgZvOBQ2IsutHd/xLWuZGgiTg3slqM+l1yClY8+x9rtRhlXXL/29Ad9lFaMLNi4E/A9919u3Wh2xEqASTB3c9sa7mZTQfOA87wffNs1wPDoqoNBTZ0TIQdq739P4CDZv/b0B32MR6fmtkgd99oZoOAzZkOqKOYWT7BwX+uu88Li7vM/qsLKM3M7GzgR8CX3b0uatHTwKVm1sPMRgKjgDcyEWOGdIf9fxMYZWYjzayAYND76QzHlAlPA9PD59OBA7UKuzQLfurfC1S6+21Ri7rM/utEsDQzs5VAD2BrWLTY3f8tXHYjwbhAA0Fz8bnYW+m6zOx84A5gAPAZ8La7fylc1h32/xzg10AucJ+735zhkDqUmT0KnEZwBcxPgdnAn4EngOHAWuAid285UNzlmdnngVeAd4GmsHgWwThAl9h/JQARkW5KXUAiIt2UEoCISDelBCAi0k0pAYiIdFNKACIi3ZQSgIhIN6UEICLSTSkBiIh0U/8fKpiYDD70tSIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "n, bins, patches = plt.hist(error_prediction, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "plt.title(\"Histogram with 400 bins\")\n",
    "plt.show()\n",
    "x=bins[:400]\n",
    "y=n\n",
    "print(n.shape)\n",
    "print(bins.shape)\n",
    "from numpy import exp, loadtxt, pi, sqrt, log\n",
    "\n",
    "from lmfit import Model\n",
    "def gaussian(x, amp, cen, wid):\n",
    "    \"\"\"1-d gaussian: gaussian(x, amp, cen, wid)\"\"\"\n",
    "    return amp * exp(-((x-cen)/wid)**2 )\n",
    "\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "\n",
    "print(result.fit_report())\n",
    "\n",
    "plt.plot(x, y, 'bo')\n",
    "plt.plot(x, result.init_fit, 'k--')\n",
    "plt.plot(x, result.best_fit, 'r-')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWHM=result.params['wid'].value*2*sqrt(log(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8706741566513925\n"
     ]
    }
   ],
   "source": [
    "print(FWHM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[168.3171 ]\n",
      " [170.14659]\n",
      " [171.0259 ]\n",
      " ...\n",
      " [165.538  ]\n",
      " [171.03104]\n",
      " [170.93594]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.396273662024103\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_bin0_predicted=model.predict(x_test_bin0)\n",
    "print(Y_test_bin0_predicted)\n",
    "error_prediction_bin0=Y_test_bin0-Y_test_bin0_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin0, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin0=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.54515513659975\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_bin1_predicted=model.predict(x_test_bin1)\n",
    "#print(Y_test_bin1_predicted)\n",
    "error_prediction_bin1=Y_test_bin1-Y_test_bin1_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin1, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin1=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.013891333679619\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD8CAYAAACSCdTiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADyBJREFUeJzt3WGMXNdZxvHnwdtQkobGwZPWjSPcSJGlUCElrKK0gVLXaeqaKC6oIEe0mCbIqlBKgkDUUaS2ol8ohQoQ0MgkJgastCJNSBQlNCZtFCE1hrXrOHbt1k5I223ceEpQUuiH1OLlw9xtR8PMzuy9Z2Z2X/9/0mru3HvuPe+emX327p2Zs44IAQBy+rFpFwAAGB9CHgASI+QBIDFCHgASI+QBIDFCHgASI+QBIDFCHgASI+QBILGZSXa2Zs2aWL9+/SS7BIAV78CBA9+NiFadfSca8uvXr9fc3NwkuwSAFc/2N+ruy+UaAEiMkAeAxAh5AEiMkAeAxAh5AEiMkAeAxAh5AEiMkAeAxAh5AEiMkMdZbeOejdMuARgrQh4AEiPkASAxQh4AEiPkASAxQh4AEiPkASAxQh4AEiPkASAxQh4AEiPkASAxQh4AEhsa8rZ32z5t+0jXuk/ZPm77sO0HbF8w3jIBAHWMciZ/j6TNPev2SXpLRPyspK9Lur1wXQCAAoaGfEQ8KemlnnWPRcSZ6u5TktaNoTYAQEMlrsnfJOnRAscBABTWKORt3yHpjKS9i7TZYXvO9ly73W7SHQBgiWqHvO3tkq6X9OsREYPaRcSuiJiNiNlWq1W3OwBADTN1drK9WdJHJP1iRHy/bEkAgFJGeQvlvZK+LGmD7XnbN0v6S0nnS9pn+5DtO8dcJwCghqFn8hFxY5/Vd4+hFgBAYXziFQASI+QBIDFCHgASI+QBIDFCHgASI+QBIDFCHgASI+QBIDFCHgASI+QBIDFCHgASI+Rx1tq4Z+O0SwDGjpAHgMQIeQBIjJAHgMQIeQBIjJAHgMQIeQBIjJAHgMQIeQBIjJAHgMQIeQBIjJAHgMSGhrzt3bZP2z7Ste5C2/tsn6huV4+3TABAHaOcyd8jaXPPup2SHo+IyyQ9Xt0HACwzQ0M+Ip6U9FLP6q2S9lTLeyS9t3BdAIAC6l6Tf0NEnJKk6vaiciUBAEoZ+wuvtnfYnrM91263x90dAKBL3ZB/0fZaSapuTw9qGBG7ImI2ImZbrVbN7gAAddQN+Yckba+Wt0t6sEw5AICSRnkL5b2Svixpg+152zdL+iNJ77J9QtK7qvsAgGVmZliDiLhxwKZNhWsBABTGJ14BIDFCHgASI+QBIDFCHgASI+QBIDFCHgASI+QBIDFCHgASI+QBIDFCHgASI+QBIDFCHgASI+QBIDFCHgASI+QBIDFCHgASI+QBIDFCHgASI+QBIDFCHgASI+QBIDFCHgASI+QBILFGIW/7d20ftX3E9r22X1uqMABAc7VD3vbFkn5H0mxEvEXSKknbShUGAGiu6eWaGUk/YXtG0rmSXmheEgCglNohHxHflvQnkr4p6ZSklyPisd52tnfYnrM9126361eKdDbu2XhW9g1MUpPLNaslbZX0ZklvknSe7ff3touIXRExGxGzrVarfqUAgCVrcrnmWkn/ERHtiPiBpPslva1MWQCAEpqE/DclXW37XNuWtEnSsTJlAQBKaHJNfr+k+yQdlPRMdaxdheoCABQw02TniPiYpI8VqgUAUBifeAWAxAh5AEiMkAeAxAh5AEiMkAeAxAh5AEiMkAeAxAh5AEiMkAeAxAh5AEiMkEdKg+aLLz2PPPPSY7kj5AEgMUIeABIj5AEgMUIeABIj5AEgMUIeABIj5AEgMUIeABIj5AEgMUIeABIj5AEgMUIeABJrFPK2L7B9n+3jto/ZfmupwgAAzc003P/PJf1zRLzP9jmSzi1QEwCgkNohb/snJb1d0m9KUkS8KunVMmUBAEpocrnmUkltSX9r+yu277J9Xm8j2ztsz9mea7fbDbrDSlFijvXuYywsD7od1v9S6mF+eGTTJORnJF0p6TMRcYWk/5G0s7dRROyKiNmImG21Wg26AwAsVZOQn5c0HxH7q/v3qRP6AIBlonbIR8R3JH3L9oZq1SZJXy1SFQCgiKbvrvmwpL3VO2uek/TB5iUBAEppFPIRcUjSbKFaAACF8YlXAEiMkAeAxAh5AEiMkAeAxAh5AEiMkAeAxAh5AEiMkAeAxAh5AEiMkAeAxAh5LMli861PYy72On0uZR76pXy/Jee3751Pn3nuURchDwCJEfIAkBghDwCJEfIAkBghDwCJEfIAkBghDwCJEfIAkBghDwCJEfIAkBghDwCJNQ5526tsf8X2wyUKAgCUU+JM/lZJxwocBwBQWKOQt71O0i9JuqtMOQCAkpqeyf+ZpD+Q9L8FagEAFFY75G1fL+l0RBwY0m6H7Tnbc+12u253Z71JzCe+1D4W2g+a77x3TvTFlof13XT7sDaLzfneZD73pc6/z7zxKK3Jmfw1km6w/bykz0p6p+1/6G0UEbsiYjYiZlutVoPuAABLVTvkI+L2iFgXEeslbZP0xYh4f7HKAACN8T55AEhspsRBIuIJSU+UOBYAoBzO5AEgMUIeABIj5AEgMUIeABIj5AEgMUIeABIj5AEgMUIeABIj5AEgMUIeABIj5AEgMUIeI2kyz/lS5p0fpf2otQ2aw76JpdY/rJ6F73GU76FJTaMci7nscyLkASAxQh4AEiPkASAxQh4AEiPkASAxQh4AEiPkASAxQh4AEiPkASAxQh4AEiPkASCx2iFv+xLbX7J9zPZR27eWLAwA0NxMg33PSPq9iDho+3xJB2zvi4ivFqoNANBQ7TP5iDgVEQer5e9JOibp4lKFAQCaK3JN3vZ6SVdI2l/ieACAMhqHvO3XSfq8pNsi4pU+23fYnrM91263a/czjbmuS/Y5rvqXetxR5y0fNpd707nJ68x3Xmf/JvPRD2rXtPa69Sw2P/1S9x112zgwb/1kNQp5269RJ+D3RsT9/dpExK6ImI2I2Var1aQ7AMASNXl3jSXdLelYRHy6XEkAgFKanMlfI+kDkt5p+1D1taVQXQCAAmq/hTIi/lWSC9YCACiMT7wCQGKEPAAkRsgDQGKEPAAkRsgDQGKEPAAkRsgDQGKEPAAkRsgDQGKEPAAkRsgDQGLpQr57ruo6c2uX6HecfQ2a573f9z1sDvF+7XqP36+/Uca4rqbHK1FPkznoB439KI/JUvuos34pbQbtV+d/GDT5vwdN/3fBcjDNGtOFPADgRwh5AEiMkAeAxAh5AEiMkAeAxAh5AEiMkAeAxAh5AEiMkAeAxAh5AEiMkAeAxBqFvO3Ntr9m+6TtnaWKAgCUUTvkba+S9FeS3iPpckk32r68VGEAgOaanMlfJelkRDwXEa9K+qykrWXKAgCU0CTkL5b0ra7789U6AMAy4Yiot6P9q5LeHRG/Vd3/gKSrIuLDPe12SNpR3d0g6Wv1yx27NZK+O+0ihlgJNUrUWdpKqHMl1CitzDp/OiJadQ4y06CAeUmXdN1fJ+mF3kYRsUvSrgb9TIztuYiYnXYdi1kJNUrUWdpKqHMl1CidfXU2uVzz75Ius/1m2+dI2ibpoaYFAQDKqX0mHxFnbN8i6QuSVknaHRFHi1UGAGisyeUaRcQjkh4pVMtysBIuK62EGiXqLG0l1LkSapTOsjprv/AKAFj+mNYAABI7q0Pe9udsH6q+nrd9aEC7520/U7Wbm3CNH7f97a46twxoN9UpJmx/yvZx24dtP2D7ggHtpjKWw8bH9o9Xz4eTtvfbXj+p2qr+L7H9JdvHbB+1fWufNu+w/XLXc+Gjk6yxq45FH0N3/EU1lodtXzmFGjd0jdMh26/Yvq2nzVTG0/Zu26dtH+lad6HtfbZPVLerB+y7vWpzwvb2kTqMCL46l6z+VNJHB2x7XtKaKdX1cUm/P6TNKknPSrpU0jmSnpZ0+YTrvE7STLX8SUmfXC5jOcr4SPptSXdWy9skfW7CNa6VdGW1fL6kr/ep8R2SHp5kXXUeQ0lbJD0qyZKulrR/yvWukvQddd5rPvXxlPR2SVdKOtK17o8l7ayWd/b7+ZF0oaTnqtvV1fLqYf2d1WfyC2xb0q9JunfatdQ09SkmIuKxiDhT3X1Knc9NLBejjM9WSXuq5fskbaqeFxMREaci4mC1/D1Jx7RyP0G+VdLfRcdTki6wvXaK9WyS9GxEfGOKNfxQRDwp6aWe1d3Pvz2S3ttn13dL2hcRL0XEf0naJ2nzsP4I+Y5fkPRiRJwYsD0kPWb7QPUJ3km7pfqzd/eAP+OW2xQTN6lzJtfPNMZylPH5YZvql9XLkn5qItX1qC4VXSFpf5/Nb7X9tO1Hbf/MRAv7kWGP4XJ7Pm7T4BO45TCekvSGiDgldX7hS7qoT5ta49roLZQrge1/kfTGPpvuiIgHq+UbtfhZ/DUR8YLtiyTts328+m089holfUbSJ9T5wfqEOpeVbuo9RJ99i79tapSxtH2HpDOS9g44zFjHcoBRxmciYziM7ddJ+ryk2yLilZ7NB9W55PDf1Wsz/yTpsknXqOGP4bIYS0mqPqh5g6Tb+2xeLuM5qlrjmj7kI+LaxbbbnpH0K5J+bpFjvFDdnrb9gDp//hcLpmE1LrD9N5Ie7rNppCkmmhphLLdLul7SpqguIvY5xljHcoBRxmehzXz1nHi9/v+f1GNl+zXqBPzeiLi/d3t36EfEI7b/2vaaiJjoPCwjPIYTeT6O6D2SDkbEi70blst4Vl60vTYiTlWXtk73aTOvzusIC9ZJemLYgblcI10r6XhEzPfbaPs82+cvLKvzAuORfm3Hoeda5i8P6HvqU0zY3izpI5JuiIjvD2gzrbEcZXwekrTwboX3SfrioF9U41Bd/79b0rGI+PSANm9ceJ3A9lXq/Pz+56RqrPod5TF8SNJvVO+yuVrSywuXIqZg4F/py2E8u3Q//7ZLerBPmy9Ius726uqy7XXVusVN+pXl5fYl6R5JH+pZ9yZJj1TLl6rzboynJR1V59LEJOv7e0nPSDpcPRHW9tZY3d+izjsynp10jVX/J9W5Xnio+rqzt85pjmW/8ZH0h+r8UpKk10r6x+r7+DdJl054/H5enT+9D3eN4RZJH1p4fkq6pRq3p9V5cfttU3ic+z6GPXVanX8o9Gz13J2ddJ1VHeeqE9qv71o39fFU55fOKUk/UOfs/GZ1Xv95XNKJ6vbCqu2spLu69r2peo6elPTBUfrjE68AkBiXawAgMUIeABIj5AEgMUIeABIj5AEgMUIeABIj5AEgMUIeABL7P0ytPvpQADg1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_bin2_predicted=model.predict(x_test_bin2)\n",
    "#print(Y_test_bin2_predicted)\n",
    "error_prediction_bin2=Y_test_bin2-Y_test_bin2_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin2, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin2=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.080539018702343\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_bin3_predicted=model.predict(x_test_bin3)\n",
    "#print(Y_test_bin3_predicted)\n",
    "error_prediction_bin3=Y_test_bin3-Y_test_bin3_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin3, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin3=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.550721160335922\n",
      "6.080539018702343\n",
      "5.013891333679619\n",
      "4.54515513659975\n",
      "4.396273662024103\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_bin4_predicted=model.predict(x_test_bin4)\n",
    "#print(Y_test_bin4_predicted)\n",
    "error_prediction_bin4=Y_test_bin4-Y_test_bin4_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin4, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin4=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin4)\n",
    "print(FWHM_bin3)\n",
    "print(FWHM_bin2)\n",
    "print(FWHM_bin1)\n",
    "print(FWHM_bin0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "495px",
    "left": "909px",
    "right": "57px",
    "top": "246px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
