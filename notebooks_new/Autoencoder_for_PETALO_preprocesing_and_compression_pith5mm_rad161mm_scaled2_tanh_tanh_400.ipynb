{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple AUTOENCODER for PETALO\n",
    "\n",
    "Esta red la vamos a utilizar para obtener el radio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python36.zip', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/lib-dynload', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/extensions', '/home/rgadea3/.ipython']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#np.random.seed(1337)  # for reproducibility\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append(\"/home/rgadea/lmfit-py/\")\n",
    "import seaborn as sns\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from math import floor\n",
    "from lmfit.models import  GaussianModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos introducir los datos de petalo preprocesados en matlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66498, 640)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import hdf5storage\n",
    "datos_matlab = hdf5storage.loadmat('../datos_octubre_2018/conjunto_entrenamiento_octubre_2018_red_pitch5mm_rad161mm_total.mat')\n",
    "conjunto_datos= datos_matlab.get('photodefA')\n",
    "conjunto_datos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6320, 3840)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "dir_name='../datos_octubre_2018'\n",
    "base_filename='p_OF_5mm_161mm'\n",
    "filename_suffix='.h5'\n",
    "file=os.path.join(dir_name, base_filename+ \"{0:03d}\".format(0) + filename_suffix)\n",
    "conjunto_datos_waves=pd.read_hdf(file,'MC')\n",
    "datos_waves=conjunto_datos_waves.values\n",
    "datos_waves.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12641, 3840)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1,2):\n",
    "    file=os.path.join(dir_name, base_filename+ \"{0:03d}\".format(i) + filename_suffix)\n",
    "    #print(file)\n",
    "    veamos=pd.read_hdf(file,'MC')\n",
    "    veamos_array=veamos.values\n",
    "    datos_waves=np.concatenate((datos_waves,veamos_array),axis=0)\n",
    "datos_waves.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12641, 3840)\n"
     ]
    }
   ],
   "source": [
    "L1A=6;\n",
    "# hay tres L1 con 640 sensores (40*16)\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 16, 40\n",
    "\n",
    "X_trained=datos_waves;\n",
    "x_trained=X_trained;\n",
    "\n",
    "for i in range (X_trained.shape[0]):\n",
    "    idea1=X_trained[i,:].reshape(img_rows,(L1A*img_cols));\n",
    "    ideat=idea1.transpose();\n",
    "    idea2=ideat.reshape(1,(L1A*img_cols)*img_rows);\n",
    "    x_trained[i,:] =idea2;\n",
    "\n",
    "print(x_trained.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_output_dim_A=img_rows*img_cols\n",
    "ideaA=np.zeros((L1A,input_output_dim_A))\n",
    "\n",
    "conjunto_datos=np.zeros((x_trained.shape[0]*L1A,input_output_dim_A))\n",
    "for i in range(x_trained.shape[0]):\n",
    "    for k in range(L1A):\n",
    "        ideaA[k,:]=x_trained[i,k*input_output_dim_A:k*input_output_dim_A+input_output_dim_A]\n",
    "    conjunto_datos[(i)*L1A :(i+1)*L1A,:] = ideaA    \n",
    "    \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_regularizer = True\n",
    "my_regularizer = None\n",
    "my_epochs = 50\n",
    "features_path = 'simple_autoe_features.pickle'\n",
    "labels_path = 'simple_autoe_labels.pickle'\n",
    "\n",
    "if use_regularizer:\n",
    "    # add a sparsity constraint on the encoded representations\n",
    "    # note use of 10e-5 leads to blurred results\n",
    "    my_regularizer = regularizers.l2(0.001)\n",
    "    # and a larger number of epochs as the added regularization the model\n",
    "    # is less likely to overfit and can be trained longer\n",
    "    my_epochs = 100\n",
    "    features_path = 'sparse_autoe_features.pickle'\n",
    "    labels_path = 'sparse_autoe_labels.pickle'\n",
    "\n",
    "   \n",
    "    \n",
    "encoding_dim = 400  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "\n",
    "# this is our input placeholder\n",
    "\n",
    "input_img = Input(shape=(img_rows*img_cols,))\n",
    "\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh', use_bias=False,bias_initializer='random_uniform')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(img_cols*img_rows, activation='tanh',use_bias=True,bias_initializer='random_uniform')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "\n",
    "\n",
    "#autoencoder=Sequential([\n",
    "#    Dense(encoding_dim, kernel_regularizer=regularizers.l2(0.001), use_bias=True,bias_initializer='random_uniform',input_shape=(640,)),\n",
    "#    Activation('sigmoid'),\n",
    "#    Dense(img_cols*img_rows, use_bias=True,bias_initializer='random_uniform'),\n",
    "#    Activation('linear'),\n",
    "#])\n",
    "\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75846\n",
      "conjunto_datos shape: (75846, 640)\n",
      "45507\n",
      "15169\n",
      "15170\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "# (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "numero_muestras=conjunto_datos.shape[0]\n",
    "print(numero_muestras)\n",
    "print('conjunto_datos shape:', conjunto_datos.shape)\n",
    "\n",
    "tr_size=60\n",
    "val_size=20\n",
    "test_size=100-val_size-tr_size\n",
    "\n",
    "tamanyo_tr=floor(tr_size*numero_muestras/100)\n",
    "tamanyo_val=floor(val_size*numero_muestras/100)\n",
    "tamanyo_test=numero_muestras-tamanyo_tr-tamanyo_val\n",
    "print(tamanyo_tr)\n",
    "print(tamanyo_val)\n",
    "print(tamanyo_test)\n",
    "\n",
    "\n",
    "X_train=conjunto_datos[:tamanyo_tr,:]\n",
    "X_val=conjunto_datos[tamanyo_tr:tamanyo_tr+tamanyo_val,:]\n",
    "X_test=conjunto_datos[tamanyo_tr+tamanyo_val:numero_muestras,:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Y_train=conjunto_datos[:tamanyo_tr,1] #elijo la coordenada radius\n",
    "Y_val=conjunto_datos[tamanyo_tr:tamanyo_tr+tamanyo_val,1] #elijo la corrdenada radius\n",
    "Y_test=conjunto_datos[tamanyo_tr+tamanyo_val:numero_muestras,1] #elijo la corrdenada radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], img_cols, img_rows,1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_cols, img_rows,1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_cols, img_rows,1)\n",
    "\n",
    "\n",
    "input_shape = (img_cols, img_rows,1)\n",
    "#input_shape=input_shape.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (45507, 40, 16, 1)\n",
      "45507 train samples\n",
      "15169 validation samples\n",
      "15170 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_val= X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_val.shape[0], 'validation samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display 20 random training images using image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25031\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACoCAYAAADw6BWzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADHtJREFUeJzt3VusHVUdx/Hf7/RCoUUBe4FwkUtIkBCsUMEEQ1AMKcYETCCBxKQPxiqRRBNNqLyARhI0UfTBaKpWeBCQoAgxqNyD+oAclEuRKlAL1JYeCBCRS6Gcvw97jtmWs2fts2fOzOzV7ydp9j4z05n/XnvvX6dz1prliBAAYPxNtF0AAKAeBDoAZIJAB4BMEOgAkAkCHQAyQaADQCYIdADIBIEOAJkg0AEgEwubPNhi7xdLtLTJQwLA2HtVL78YEStS21UKdNtrJX1f0gJJP4mIq8u2X6KlOt1nVzkkAOxz7oqbnxlmu5EvudheIOkHks6VdKKki22fOOr+AADVVLmGfpqkpyJia0S8JelGSefVUxYAYK6qBPrhkp7r+3l7sez/2F5ve9L25NvaXeFwAIAyVQLdsyx71714I2JjRKyJiDWLtF+FwwEAylQJ9O2Sjuz7+QhJO6qVAwAYVZVAf1DS8baPsb1Y0kWSbqunLADAXI3cbTEi9ti+VNLv1eu2uCkiHq+tMgDAnFTqhx4Rt0u6vaZaAAAVMPQfADJBoANAJgh0AMgEgQ4AmSDQASATBDoAZIJAB4BMNDrBhScmNHHA4Akupl97rcFqMIyJpeUTkvCe5Sf1nkv1vO/DHGe+a8gNZ+gAkAkCHQAyQaADQCYIdADIBIEOAJkg0AEgEwQ6AGSi0X7oMT1N39Exs6+8XwsPXZXcZs/zuxqopH1Nvedd+GzlNs6CM3QAyASBDgCZINABIBMEOgBkgkAHgEwQ6ACQCQIdADLRaD90YL5U7U/cVB/zqnU2da/ylHHpv131nuvjhjN0AMgEgQ4AmSDQASATBDoAZIJAB4BMEOgAkAkCHQAyQaADQCYaHVjkiQlNHDC4o39XBiOkdGVwR8q4DP6oQy6vJTXRRh0DoIaZzCMlVUdXviO5fC6GVSnQbW+T9KqkdyTtiYg1dRQFAJi7Os7QPxYRL9awHwBABVxDB4BMVA30kHSH7Ydsr59tA9vrbU/annwr3qx4OADAIFUvuZwRETtsr5R0p+0tEXF//wYRsVHSRkl674LlUfF4AIABKp2hR8SO4nFK0i2STqujKADA3I0c6LaX2j5w5rmkcyRtrqswAMDcVLnkskrSLbZn9nN9RPyu7C/E9HQW/UK78hr2pX7mVdXRVrXsY9WK0vV7tm6rVIMkTRy4rHT99Kv/Se4jpYn+8uOiS9/DkQM9IrZK+mCNtQAAKqDbIgBkgkAHgEwQ6ACQCQIdADJBoANAJgh0AMgEgQ4AmWh0ggvUi4FDw0u1VVMTMkzveqF0fXLyiQP2r1yDahhY1IUJLphE4904QweATBDoAJAJAh0AMkGgA0AmCHQAyASBDgCZINABIBPZ9UPv0s3m59u+9FrnWx0TXKQmlpCGmFwi0c98etmS5DH09HPpbUqkJuGQpOmt1T9bVSfJqOPzndt3iDN0AMgEgQ4AmSDQASATBDoAZIJAB4BMEOgAkAkCHQAy0Wg/dE9MaOKAwf0+a7nf9Jj0G62j/+u4vNaUJvoC13GMVD/zZB9zDdfHu6ph+sOXSd2zXZImTj6hfB+Pbkkf6Lgjy49Rw33bU+9rLt+hGZyhA0AmCHQAyASBDgCZINABIBMEOgBkgkAHgEwQ6ACQCQIdADLR6MCimJ7OriP/qHJph9SAHSn9WpMDdhpoq2FeR2ryiTdOPSq5i/3v+9uwJc2ufM6HntTgpdffqFaDpImpl0vXTw+zk4oTcdRhn5vgwvYm21O2N/ctO8T2nbafLB4Pnt8yAQApw1xyuVbS2r2WbZB0d0QcL+nu4mcAQIuSgR4R90t6aa/F50m6rnh+naTza64LADBHo/5SdFVE7JSk4nHloA1tr7c9aXvybe0e8XAAgJR57+USERsjYk1ErFmk/eb7cACwzxo10HfZPkySisep+koCAIxi1EC/TdK64vk6SbfWUw4AYFTJfui2b5B0lqTltrdLukLS1ZJusv1ZSc9KunA+i8RoapnUoYZ9LDx0Ven6Pc+Xd66upa97om/2nq3bkseYeL28v/wwfcyTdax8T3IfSa+/Vb5+2ZLy9UNMLJGazCP1nkvp9z1lmM/FuEyeUpdkoEfExQNWnV1zLQCAChj6DwCZINABIBMEOgBkgkAHgEwQ6ACQCQIdADLR6P3Q0aw6+r/Wso8h+jVXrSHZF3jXC5X+fl3ePPp9pesXP7CldH3q3vHDqPp+SNX7/UvV27yJPuRN1VEXztABIBMEOgBkgkAHgEwQ6ACQCQIdADJBoANAJgh0AMgEgQ4AmejUwKI6JjLIRU5t0YU6UzUsPPbo9E5ef6NyHQvveah0/USijtQAKSk9+KiOyT5ShqlzHD4XTQ04qwtn6ACQCQIdADJBoANAJgh0AMgEgQ4AmSDQASATBDoAZKJT/dCb6Jc6Lje0r+MYCw9dVbp+z/O7Kh+jCU30yR+m3/Rvn/xT6fpTr7wkuY93lrh0/eG/2VG6fpgJLlITWKTO4upo71omJWmgj3gX+sLXiTN0AMgEgQ4AmSDQASATBDoAZIJAB4BMEOgAkAkCHQAyQaADQCaSA4tsb5L0KUlTEXFSsexKSZ+TNDMa4/KIuH2+iuxXdTBCbgMJynRl4FAT71lqEFVysM0QA3ZOv6x84NC5X/ljch/fXPlY6fpT3yw/xqF37UweQ4nXWsfnIvWeDtOeTXw+Kw84G7O8GOYM/VpJa2dZfk1ErC7+NBLmAIDBkoEeEfdLeqmBWgAAFVS5hn6p7Udtb7J9cG0VAQBGMmqg/1DScZJWS9op6TuDNrS93vak7cm3tXvEwwEAUkYK9IjYFRHvRMS0pB9LOq1k240RsSYi1izSfqPWCQBIGCnQbR/W9+OnJW2upxwAwKiG6bZ4g6SzJC23vV3SFZLOsr1aUkjaJunz81gjAGAIjojmDma/IOmZvkXLJb3YWAGjo856UWd9xqFGiTqren9ErEht1Gigv+vg9mRErGmtgCFRZ72osz7jUKNEnU1h6D8AZIJAB4BMtB3oG1s+/rCos17UWZ9xqFGizka0eg0dAFCfts/QAQA1IdABIBOtBbrttbb/bvsp2xvaqiPF9jbbj9l+2PZk2/XMKG6KNmV7c9+yQ2zfafvJ4rHVm6YNqPFK2/8q2vNh259ss8aipiNt32v7CduP2/5Ssbxr7Tmozk61qe0ltv9s+5Gizq8Xy4+x/UDRnr+wvbijdV5r+5997bm6zTrnJCIa/yNpgaSnJR0rabGkRySd2EYtQ9S6TdLytuuYpa4zJZ0iaXPfsm9L2lA83yDpWx2s8UpJX227/faq8zBJpxTPD5T0D0kndrA9B9XZqTaVZEnLiueLJD0g6SOSbpJ0UbH8R5Iu6Wid10q6oO12HOVPW2fop0l6KiK2RsRbkm6UdF5LtYylmP0+9edJuq54fp2k8xstai8DauyciNgZEX8pnr8q6QlJh6t77Tmozk6JnplpkxYVf0LSxyXdXCzvQnsOqnNstRXoh0t6ru/n7ergB7MQku6w/ZDt9W0Xk7AqInZKvS+/pJUt1zNIZ++lb/toSR9S72yts+25V51Sx9rU9gLbD0uaknSnev8jfyUi9hSbdOI7v3edETHTnlcV7XmN7bG5TWxbge5ZlnX1X8YzIuIUSedK+qLtM9suaMwNfS/9ptleJumXkr4cEf9uu55BZqmzc20avdtrr5Z0hHr/I//AbJs1W9UsBexVp+2TJH1N0gmSPizpEEmXtVjinLQV6NslHdn38xGSdrRUS6mI2FE8Tkm6RSX3fu+AXTO3Ni4ep1qu511iDvfSb5LtReqF5M8j4lfF4s6152x1drVNJSkiXpF0n3rXpg+yPXOH10595/vqXFtc2oqI2C3pZ+pQe6a0FegPSjq++K33YkkXSbqtpVoGsr3U9oEzzyWdo27f+/02SeuK5+sk3dpiLbPq4r30bVvSTyU9ERHf7VvVqfYcVGfX2tT2CtsHFc/3l/QJ9a733yvpgmKzLrTnbHVu6ftH3Opd52/9Mzqs1kaKFl2rvqdej5dNEXFVK4WUsH2semflUu/e8dd3pc7++9RL2qXefep/rV5PgqMkPSvpwoho7ZeSA2o8S71LA/+7l/7Mdeq22P6opD9IekzSdLH4cvWuT3epPQfVebE61Ka2T1bvl54L1DtpvCkivlF8n25U7zLGXyV9pjgL7lqd90haod6l4YclfaHvl6edxtB/AMgEI0UBIBMEOgBkgkAHgEwQ6ACQCQIdADJBoANAJgh0AMjEfwFPduu7M5YxqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25736\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34509\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45207\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "#Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "#Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "for i in range(1,5):\n",
    "    idea=np.random.randint(1,X_train.shape[0])\n",
    "    plt.imshow(np.reshape(X_train[idea].transpose(), [16, 40]), vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    plt.show()\n",
    "    print(idea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a generar las matrices de datos para la red neuronal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45507, 640)\n",
      "(15170, 640)\n",
      "(15170, 640)\n"
     ]
    }
   ],
   "source": [
    "x_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
    "x_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n",
    "prueba=x_train[0:15170,:]\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(prueba.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.98, -1.  , -1.  , -1.  , -0.98, -0.98, -1.  , -0.94, -1.  ,\n",
       "       -0.92, -0.96, -0.98, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -0.96, -0.94, -0.92, -0.98, -1.  , -0.96,\n",
       "       -0.98, -0.96, -0.98, -0.96, -0.98, -1.  , -0.98, -0.98, -0.98,\n",
       "       -0.96, -1.  , -0.92, -0.9 , -0.92, -0.98, -1.  , -1.  , -0.98,\n",
       "       -0.98, -0.96, -0.98, -1.  , -1.  , -0.98, -1.  , -0.98, -0.96,\n",
       "       -0.94, -0.96, -0.98, -1.  , -0.92, -0.92, -0.92, -1.  , -0.98,\n",
       "       -0.98, -0.98, -1.  , -0.98, -1.  , -0.98, -0.94, -0.98, -0.98,\n",
       "       -0.96, -0.98, -0.96, -0.94, -0.98, -1.  , -0.98, -0.98, -1.  ,\n",
       "       -1.  , -1.  , -1.  , -0.98, -0.96, -0.96, -0.98, -0.94, -0.92,\n",
       "       -0.94, -0.94, -0.98, -0.94, -1.  , -0.96, -1.  , -1.  , -0.98,\n",
       "       -1.  , -1.  , -0.96, -0.98, -0.96, -0.98, -0.96, -1.  , -0.94,\n",
       "       -0.96, -0.98, -0.96, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -0.96, -0.94, -0.96, -0.98, -1.  , -0.98, -0.94, -1.  ,\n",
       "       -1.  , -0.98, -1.  , -1.  , -1.  , -0.98, -0.96, -1.  , -1.  ,\n",
       "       -0.98, -0.92, -0.96, -1.  , -0.98, -0.98, -1.  , -1.  , -0.98,\n",
       "       -1.  , -1.  , -1.  , -0.98, -1.  , -1.  , -1.  , -0.96, -0.98,\n",
       "       -1.  , -1.  , -0.98, -0.98, -1.  , -1.  , -1.  , -0.98, -0.98,\n",
       "       -1.  , -1.  , -1.  , -0.96, -1.  , -0.98, -0.96, -1.  , -0.98,\n",
       "       -0.96, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -0.98,\n",
       "       -0.98, -1.  , -1.  , -0.98, -0.98, -1.  , -1.  , -0.98, -1.  ,\n",
       "       -1.  , -0.98, -0.98, -1.  , -1.  , -0.98, -1.  , -1.  , -0.98,\n",
       "       -0.98, -0.96, -1.  , -1.  , -1.  , -1.  , -0.98, -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -0.98, -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -0.98, -1.  , -0.98, -1.  , -0.98,\n",
       "       -1.  , -1.  , -1.  , -1.  , -0.98, -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -0.98, -0.98, -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -0.98, -0.98, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -0.98, -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -0.98,\n",
       "       -1.  , -0.98, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -0.98, -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -0.96, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -0.98, -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -0.98, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -0.98, -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -0.98, -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -0.98, -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -0.98, -1.  , -1.  , -1.  ,\n",
       "       -1.  , -0.98, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  ], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min_max_scaler = preprocessing.QuantileTransformer().fit(x_train)\n",
    "# min_max_scaler = preprocessing.MaxAbsScaler().fit(x_train)\n",
    "# min_max_scaler = preprocessing.StandardScaler(with_mean=False).fit(x_train)\n",
    "min_max_scaler = preprocessing.MinMaxScaler().fit(x_train)\n",
    "#min_max_scaler = preprocessing.RobustScaler().fit(x_train)\n",
    "supermax=100\n",
    "factor_aprendizaje=0.0001\n",
    "print(min_max_scaler)\n",
    "#x_train_scaled = min_max_scaler.transform(x_train)\n",
    "#x_test_scaled = min_max_scaler.transform(x_test)\n",
    "x_train_scaled=(2*x_train/supermax)-1\n",
    "x_test_scaled=(2*x_test/supermax)-1\n",
    "#min_max_scaler.scale_\n",
    "x_train[29413]\n",
    "x_train_scaled[29413]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the autoencoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='RMSprop', loss='mse')\n",
    "\n",
    "autoencoder.optimizer.lr=(factor_aprendizaje)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a summary of the model parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now train the model and evaluate on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45507 samples, validate on 15170 samples\n",
      "Epoch 1/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0530 - val_loss: 0.0012\n",
      "Epoch 2/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 3/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 4/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 5/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 6/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 7/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 8/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 9/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 10/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 11/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 12/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 13/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 14/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 15/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 16/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 17/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 18/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 19/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 20/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 21/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 22/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 23/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 24/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 25/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 26/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 27/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 28/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 29/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 30/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 31/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 32/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 33/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 34/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 35/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 36/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 37/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 38/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 39/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 40/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 41/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 42/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 43/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 44/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 45/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 46/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 47/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 48/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 49/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 50/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 51/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 52/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 53/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 54/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 55/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 56/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 57/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 58/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 59/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 60/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 61/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 62/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 63/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 64/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 65/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 66/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 67/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 68/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 69/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 70/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 71/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 72/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 73/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 74/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 75/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 76/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 77/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 78/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 79/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 80/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 81/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 82/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 83/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 84/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 85/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 86/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 87/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0010 - val_loss: 9.9069e-04\n",
      "Epoch 88/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 9.9696e-04 - val_loss: 9.8049e-04\n",
      "Epoch 89/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 9.8666e-04 - val_loss: 9.7431e-04\n",
      "Epoch 90/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 9.8031e-04 - val_loss: 9.6636e-04\n",
      "Epoch 91/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 9.7176e-04 - val_loss: 9.5979e-04\n",
      "Epoch 92/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 9.6435e-04 - val_loss: 9.4928e-04\n",
      "Epoch 93/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 9.5490e-04 - val_loss: 9.4155e-04\n",
      "Epoch 94/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 9.4759e-04 - val_loss: 9.3521e-04\n",
      "Epoch 95/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 9.3986e-04 - val_loss: 9.2670e-04\n",
      "Epoch 96/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 9.3173e-04 - val_loss: 9.1970e-04\n",
      "Epoch 97/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 9.2295e-04 - val_loss: 9.1295e-04\n",
      "Epoch 98/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 9.1504e-04 - val_loss: 9.0661e-04\n",
      "Epoch 99/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 9.0751e-04 - val_loss: 9.0113e-04\n",
      "Epoch 100/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 8.9979e-04 - val_loss: 8.9382e-04\n",
      "Epoch 101/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 8.9362e-04 - val_loss: 8.8804e-04\n",
      "Epoch 102/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.8875e-04 - val_loss: 8.8108e-04\n",
      "Epoch 103/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 8.8485e-04 - val_loss: 8.7796e-04\n",
      "Epoch 104/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 8.7885e-04 - val_loss: 8.7112e-04\n",
      "Epoch 105/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.7176e-04 - val_loss: 8.6503e-04\n",
      "Epoch 106/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 8.6732e-04 - val_loss: 8.6035e-04\n",
      "Epoch 107/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.6236e-04 - val_loss: 8.5632e-04\n",
      "Epoch 108/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.5735e-04 - val_loss: 8.5259e-04\n",
      "Epoch 109/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.5157e-04 - val_loss: 8.4898e-04\n",
      "Epoch 110/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 8.4820e-04 - val_loss: 8.4559e-04\n",
      "Epoch 111/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 8.4296e-04 - val_loss: 8.4235e-04\n",
      "Epoch 112/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.3861e-04 - val_loss: 8.3969e-04\n",
      "Epoch 113/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.3423e-04 - val_loss: 8.3818e-04\n",
      "Epoch 114/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.3038e-04 - val_loss: 8.3728e-04\n",
      "Epoch 115/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 8.2642e-04 - val_loss: 8.3535e-04\n",
      "Epoch 116/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.2237e-04 - val_loss: 8.3331e-04\n",
      "Epoch 117/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 8.1837e-04 - val_loss: 8.3037e-04\n",
      "Epoch 118/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 8.1423e-04 - val_loss: 8.2760e-04\n",
      "Epoch 119/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 8.1041e-04 - val_loss: 8.2705e-04\n",
      "Epoch 120/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 8.0686e-04 - val_loss: 8.2774e-04\n",
      "Epoch 121/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 8.0388e-04 - val_loss: 8.2520e-04\n",
      "Epoch 122/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 7.9992e-04 - val_loss: 8.2098e-04\n",
      "Epoch 123/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.9764e-04 - val_loss: 8.1604e-04\n",
      "Epoch 124/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.9470e-04 - val_loss: 8.1106e-04\n",
      "Epoch 125/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 7.9179e-04 - val_loss: 8.0625e-04\n",
      "Epoch 126/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.8905e-04 - val_loss: 8.0185e-04\n",
      "Epoch 127/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.8596e-04 - val_loss: 7.9785e-04\n",
      "Epoch 128/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.8308e-04 - val_loss: 7.9420e-04\n",
      "Epoch 129/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.8050e-04 - val_loss: 7.9105e-04\n",
      "Epoch 130/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.7787e-04 - val_loss: 7.8848e-04\n",
      "Epoch 131/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 7.7527e-04 - val_loss: 7.8640e-04\n",
      "Epoch 132/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.7280e-04 - val_loss: 7.8461e-04\n",
      "Epoch 133/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.7043e-04 - val_loss: 7.8294e-04\n",
      "Epoch 134/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 7.6816e-04 - val_loss: 7.8125e-04\n",
      "Epoch 135/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.6599e-04 - val_loss: 7.7955e-04\n",
      "Epoch 136/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.6387e-04 - val_loss: 7.7790e-04\n",
      "Epoch 137/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 7.6182e-04 - val_loss: 7.7626e-04\n",
      "Epoch 138/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 7.5983e-04 - val_loss: 7.7450e-04\n",
      "Epoch 139/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 7.5783e-04 - val_loss: 7.7251e-04\n",
      "Epoch 140/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.5630e-04 - val_loss: 7.7000e-04\n",
      "Epoch 141/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.5456e-04 - val_loss: 7.6725e-04\n",
      "Epoch 142/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.5287e-04 - val_loss: 7.6460e-04\n",
      "Epoch 143/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.5124e-04 - val_loss: 7.6214e-04\n",
      "Epoch 144/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.4963e-04 - val_loss: 7.5986e-04\n",
      "Epoch 145/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.4806e-04 - val_loss: 7.5770e-04\n",
      "Epoch 146/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.4659e-04 - val_loss: 7.5566e-04\n",
      "Epoch 147/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.4516e-04 - val_loss: 7.5374e-04\n",
      "Epoch 148/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.4350e-04 - val_loss: 7.5190e-04\n",
      "Epoch 149/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.4200e-04 - val_loss: 7.5013e-04\n",
      "Epoch 150/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 7.4063e-04 - val_loss: 7.4848e-04\n",
      "Epoch 151/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.3928e-04 - val_loss: 7.4695e-04\n",
      "Epoch 152/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 7.3794e-04 - val_loss: 7.4546e-04\n",
      "Epoch 153/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 7.3663e-04 - val_loss: 7.4397e-04\n",
      "Epoch 154/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.3536e-04 - val_loss: 7.4247e-04\n",
      "Epoch 155/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.3415e-04 - val_loss: 7.4098e-04\n",
      "Epoch 156/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 7.3296e-04 - val_loss: 7.3950e-04\n",
      "Epoch 157/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 7.3179e-04 - val_loss: 7.3800e-04\n",
      "Epoch 158/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 7.3062e-04 - val_loss: 7.3650e-04\n",
      "Epoch 159/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.2943e-04 - val_loss: 7.3503e-04\n",
      "Epoch 160/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 7.2825e-04 - val_loss: 7.3370e-04\n",
      "Epoch 161/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.2713e-04 - val_loss: 7.3259e-04\n",
      "Epoch 162/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 7.2608e-04 - val_loss: 7.3158e-04\n",
      "Epoch 163/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 7.2508e-04 - val_loss: 7.3060e-04\n",
      "Epoch 164/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.2411e-04 - val_loss: 7.2963e-04\n",
      "Epoch 165/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.2335e-04 - val_loss: 7.2874e-04\n",
      "Epoch 166/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 7.2265e-04 - val_loss: 7.2797e-04\n",
      "Epoch 167/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.2173e-04 - val_loss: 7.2726e-04\n",
      "Epoch 168/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.2090e-04 - val_loss: 7.2659e-04\n",
      "Epoch 169/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 7.2019e-04 - val_loss: 7.2593e-04\n",
      "Epoch 170/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.1941e-04 - val_loss: 7.2531e-04\n",
      "Epoch 171/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 7.1860e-04 - val_loss: 7.2470e-04\n",
      "Epoch 172/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 7.1779e-04 - val_loss: 7.2412e-04\n",
      "Epoch 173/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.1698e-04 - val_loss: 7.2356e-04\n",
      "Epoch 174/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.1620e-04 - val_loss: 7.2302e-04\n",
      "Epoch 175/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 7.1545e-04 - val_loss: 7.2251e-04\n",
      "Epoch 176/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 7.1470e-04 - val_loss: 7.2201e-04\n",
      "Epoch 177/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.1396e-04 - val_loss: 7.2153e-04\n",
      "Epoch 178/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.1323e-04 - val_loss: 7.2106e-04\n",
      "Epoch 179/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 7.1248e-04 - val_loss: 7.2063e-04\n",
      "Epoch 180/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.1172e-04 - val_loss: 7.2023e-04\n",
      "Epoch 181/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.1095e-04 - val_loss: 7.1989e-04\n",
      "Epoch 182/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 7.1016e-04 - val_loss: 7.1963e-04\n",
      "Epoch 183/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.0939e-04 - val_loss: 7.1943e-04\n",
      "Epoch 184/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.0890e-04 - val_loss: 7.1930e-04\n",
      "Epoch 185/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.0823e-04 - val_loss: 7.1929e-04\n",
      "Epoch 186/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.0758e-04 - val_loss: 7.1937e-04\n",
      "Epoch 187/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.0687e-04 - val_loss: 7.1956e-04\n",
      "Epoch 188/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.0614e-04 - val_loss: 7.1983e-04\n",
      "Epoch 189/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.0527e-04 - val_loss: 7.2018e-04\n",
      "Epoch 190/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.0440e-04 - val_loss: 7.2116e-04\n",
      "Epoch 191/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.0367e-04 - val_loss: 7.2164e-04\n",
      "Epoch 192/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.0340e-04 - val_loss: 7.2157e-04\n",
      "Epoch 193/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.0264e-04 - val_loss: 7.2159e-04\n",
      "Epoch 194/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 7.0198e-04 - val_loss: 7.2181e-04\n",
      "Epoch 195/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 7.0117e-04 - val_loss: 7.2241e-04\n",
      "Epoch 196/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 7.0053e-04 - val_loss: 7.2309e-04\n",
      "Epoch 197/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.9992e-04 - val_loss: 7.2340e-04\n",
      "Epoch 198/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.9954e-04 - val_loss: 7.2395e-04\n",
      "Epoch 199/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.9873e-04 - val_loss: 7.2486e-04\n",
      "Epoch 200/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.9857e-04 - val_loss: 7.2500e-04\n",
      "Epoch 201/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.9781e-04 - val_loss: 7.2564e-04\n",
      "Epoch 202/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.9723e-04 - val_loss: 7.2694e-04\n",
      "Epoch 203/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.9667e-04 - val_loss: 7.2762e-04\n",
      "Epoch 204/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.9623e-04 - val_loss: 7.2830e-04\n",
      "Epoch 205/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.9566e-04 - val_loss: 7.2845e-04\n",
      "Epoch 206/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.9533e-04 - val_loss: 7.2705e-04\n",
      "Epoch 207/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.9496e-04 - val_loss: 7.2512e-04\n",
      "Epoch 208/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.9456e-04 - val_loss: 7.2414e-04\n",
      "Epoch 209/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.9414e-04 - val_loss: 7.2348e-04\n",
      "Epoch 210/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.9371e-04 - val_loss: 7.2310e-04\n",
      "Epoch 211/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.9323e-04 - val_loss: 7.2292e-04\n",
      "Epoch 212/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.9273e-04 - val_loss: 7.2284e-04\n",
      "Epoch 213/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.9225e-04 - val_loss: 7.2279e-04\n",
      "Epoch 214/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.9178e-04 - val_loss: 7.2275e-04\n",
      "Epoch 215/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.9133e-04 - val_loss: 7.2270e-04\n",
      "Epoch 216/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.9090e-04 - val_loss: 7.2254e-04\n",
      "Epoch 217/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.9047e-04 - val_loss: 7.2214e-04\n",
      "Epoch 218/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.9001e-04 - val_loss: 7.2153e-04\n",
      "Epoch 219/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.8951e-04 - val_loss: 7.2093e-04\n",
      "Epoch 220/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8905e-04 - val_loss: 7.2050e-04\n",
      "Epoch 221/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.8863e-04 - val_loss: 7.2037e-04\n",
      "Epoch 222/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8827e-04 - val_loss: 7.2052e-04\n",
      "Epoch 223/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.8790e-04 - val_loss: 7.2078e-04\n",
      "Epoch 224/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8720e-04 - val_loss: 7.2054e-04\n",
      "Epoch 225/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8689e-04 - val_loss: 7.2053e-04\n",
      "Epoch 226/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.8650e-04 - val_loss: 7.2079e-04\n",
      "Epoch 227/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.8606e-04 - val_loss: 7.2116e-04\n",
      "Epoch 228/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.8569e-04 - val_loss: 7.2159e-04\n",
      "Epoch 229/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.8540e-04 - val_loss: 7.2211e-04\n",
      "Epoch 230/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.8509e-04 - val_loss: 7.2269e-04\n",
      "Epoch 231/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.8476e-04 - val_loss: 7.2329e-04\n",
      "Epoch 232/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 6.8441e-04 - val_loss: 7.2387e-04\n",
      "Epoch 233/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.8405e-04 - val_loss: 7.2439e-04\n",
      "Epoch 234/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8366e-04 - val_loss: 7.2477e-04\n",
      "Epoch 235/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8326e-04 - val_loss: 7.2506e-04\n",
      "Epoch 236/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.8293e-04 - val_loss: 7.2541e-04\n",
      "Epoch 237/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.8267e-04 - val_loss: 7.2597e-04\n",
      "Epoch 238/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.8243e-04 - val_loss: 7.2645e-04\n",
      "Epoch 239/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.8214e-04 - val_loss: 7.2675e-04\n",
      "Epoch 240/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.8180e-04 - val_loss: 7.2684e-04\n",
      "Epoch 241/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.8149e-04 - val_loss: 7.2663e-04\n",
      "Epoch 242/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.8125e-04 - val_loss: 7.2617e-04\n",
      "Epoch 243/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8094e-04 - val_loss: 7.2543e-04\n",
      "Epoch 244/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8067e-04 - val_loss: 7.2321e-04\n",
      "Epoch 245/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.8076e-04 - val_loss: 7.2391e-04\n",
      "Epoch 246/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.8038e-04 - val_loss: 7.2297e-04\n",
      "Epoch 247/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7935e-04 - val_loss: 7.2136e-04\n",
      "Epoch 248/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7923e-04 - val_loss: 7.2280e-04\n",
      "Epoch 249/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.7878e-04 - val_loss: 7.2368e-04\n",
      "Epoch 250/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.7895e-04 - val_loss: 7.2411e-04\n",
      "Epoch 251/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.7891e-04 - val_loss: 7.2089e-04\n",
      "Epoch 252/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.7887e-04 - val_loss: 7.2498e-04\n",
      "Epoch 253/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7871e-04 - val_loss: 7.2516e-04\n",
      "Epoch 254/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7847e-04 - val_loss: 7.2550e-04\n",
      "Epoch 255/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7819e-04 - val_loss: 7.2594e-04\n",
      "Epoch 256/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.7764e-04 - val_loss: 7.2641e-04\n",
      "Epoch 257/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7732e-04 - val_loss: 7.2712e-04\n",
      "Epoch 258/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.7704e-04 - val_loss: 7.2767e-04\n",
      "Epoch 259/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.7669e-04 - val_loss: 7.2831e-04\n",
      "Epoch 260/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7638e-04 - val_loss: 7.2882e-04\n",
      "Epoch 261/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7612e-04 - val_loss: 7.2920e-04\n",
      "Epoch 262/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.7568e-04 - val_loss: 7.2935e-04\n",
      "Epoch 263/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7529e-04 - val_loss: 7.2894e-04\n",
      "Epoch 264/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7476e-04 - val_loss: 7.2971e-04\n",
      "Epoch 265/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.7442e-04 - val_loss: 7.3001e-04\n",
      "Epoch 266/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7381e-04 - val_loss: 7.2861e-04\n",
      "Epoch 267/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7355e-04 - val_loss: 7.2760e-04\n",
      "Epoch 268/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.7406e-04 - val_loss: 7.2913e-04\n",
      "Epoch 269/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.7332e-04 - val_loss: 7.2798e-04\n",
      "Epoch 270/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.7293e-04 - val_loss: 7.2720e-04\n",
      "Epoch 271/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.7262e-04 - val_loss: 7.2649e-04\n",
      "Epoch 272/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7237e-04 - val_loss: 7.2548e-04\n",
      "Epoch 273/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7261e-04 - val_loss: 7.2353e-04\n",
      "Epoch 274/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7167e-04 - val_loss: 7.2203e-04\n",
      "Epoch 275/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.7261e-04 - val_loss: 7.2180e-04\n",
      "Epoch 276/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7158e-04 - val_loss: 7.2136e-04\n",
      "Epoch 277/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7131e-04 - val_loss: 7.2012e-04\n",
      "Epoch 278/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.7170e-04 - val_loss: 7.2214e-04\n",
      "Epoch 279/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7170e-04 - val_loss: 7.2090e-04\n",
      "Epoch 280/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.7148e-04 - val_loss: 7.2052e-04\n",
      "Epoch 281/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.7109e-04 - val_loss: 7.1770e-04\n",
      "Epoch 282/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7008e-04 - val_loss: 7.2271e-04\n",
      "Epoch 283/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7076e-04 - val_loss: 7.2502e-04\n",
      "Epoch 284/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.7035e-04 - val_loss: 7.2334e-04\n",
      "Epoch 285/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6936e-04 - val_loss: 7.2146e-04\n",
      "Epoch 286/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6910e-04 - val_loss: 7.2536e-04\n",
      "Epoch 287/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6950e-04 - val_loss: 7.2591e-04\n",
      "Epoch 288/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.6890e-04 - val_loss: 7.2532e-04\n",
      "Epoch 289/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6921e-04 - val_loss: 7.2523e-04\n",
      "Epoch 290/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6856e-04 - val_loss: 7.2518e-04\n",
      "Epoch 291/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6850e-04 - val_loss: 7.2342e-04\n",
      "Epoch 292/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6915e-04 - val_loss: 7.2709e-04\n",
      "Epoch 293/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6845e-04 - val_loss: 7.2337e-04\n",
      "Epoch 294/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.6868e-04 - val_loss: 7.2665e-04\n",
      "Epoch 295/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6757e-04 - val_loss: 7.3128e-04\n",
      "Epoch 296/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6780e-04 - val_loss: 7.3199e-04\n",
      "Epoch 297/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6777e-04 - val_loss: 7.3013e-04\n",
      "Epoch 298/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6757e-04 - val_loss: 7.2343e-04\n",
      "Epoch 299/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6758e-04 - val_loss: 7.2425e-04\n",
      "Epoch 300/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.6776e-04 - val_loss: 7.2575e-04\n",
      "Epoch 301/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.6753e-04 - val_loss: 7.2600e-04\n",
      "Epoch 302/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6728e-04 - val_loss: 7.2660e-04\n",
      "Epoch 303/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6703e-04 - val_loss: 7.2697e-04\n",
      "Epoch 304/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6680e-04 - val_loss: 7.2682e-04\n",
      "Epoch 305/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6657e-04 - val_loss: 7.2620e-04\n",
      "Epoch 306/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6641e-04 - val_loss: 7.2500e-04\n",
      "Epoch 307/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.6639e-04 - val_loss: 7.2468e-04\n",
      "Epoch 308/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.6639e-04 - val_loss: 7.2472e-04\n",
      "Epoch 309/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6603e-04 - val_loss: 7.3127e-04\n",
      "Epoch 310/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6582e-04 - val_loss: 7.2579e-04\n",
      "Epoch 311/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6568e-04 - val_loss: 7.2928e-04\n",
      "Epoch 312/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6543e-04 - val_loss: 7.2665e-04\n",
      "Epoch 313/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.6519e-04 - val_loss: 7.2573e-04\n",
      "Epoch 314/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6587e-04 - val_loss: 7.2926e-04\n",
      "Epoch 315/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6531e-04 - val_loss: 7.2958e-04\n",
      "Epoch 316/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.6444e-04 - val_loss: 7.2656e-04\n",
      "Epoch 317/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6528e-04 - val_loss: 7.2370e-04\n",
      "Epoch 318/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6479e-04 - val_loss: 7.2424e-04\n",
      "Epoch 319/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6473e-04 - val_loss: 7.2527e-04\n",
      "Epoch 320/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6358e-04 - val_loss: 7.2822e-04\n",
      "Epoch 321/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.6337e-04 - val_loss: 7.3160e-04\n",
      "Epoch 322/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6453e-04 - val_loss: 7.2833e-04\n",
      "Epoch 323/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6334e-04 - val_loss: 7.3455e-04\n",
      "Epoch 324/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6379e-04 - val_loss: 7.3072e-04\n",
      "Epoch 325/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6332e-04 - val_loss: 7.2922e-04\n",
      "Epoch 326/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.6408e-04 - val_loss: 7.2308e-04\n",
      "Epoch 327/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6437e-04 - val_loss: 7.2778e-04\n",
      "Epoch 328/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6322e-04 - val_loss: 7.2705e-04\n",
      "Epoch 329/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6297e-04 - val_loss: 7.2090e-04\n",
      "Epoch 330/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6298e-04 - val_loss: 7.2445e-04\n",
      "Epoch 331/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6201e-04 - val_loss: 7.2854e-04\n",
      "Epoch 332/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6299e-04 - val_loss: 7.2745e-04\n",
      "Epoch 333/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6285e-04 - val_loss: 7.2389e-04\n",
      "Epoch 334/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6281e-04 - val_loss: 7.2797e-04\n",
      "Epoch 335/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6239e-04 - val_loss: 7.3326e-04\n",
      "Epoch 336/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6207e-04 - val_loss: 7.2595e-04\n",
      "Epoch 337/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6262e-04 - val_loss: 7.2264e-04\n",
      "Epoch 338/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 6.6161e-04 - val_loss: 7.4452e-04\n",
      "Epoch 339/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6156e-04 - val_loss: 7.3466e-04\n",
      "Epoch 340/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6153e-04 - val_loss: 7.5061e-04\n",
      "Epoch 341/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6136e-04 - val_loss: 7.4550e-04\n",
      "Epoch 342/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6141e-04 - val_loss: 7.3784e-04\n",
      "Epoch 343/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6117e-04 - val_loss: 7.2570e-04\n",
      "Epoch 344/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.6215e-04 - val_loss: 7.3516e-04\n",
      "Epoch 345/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.6160e-04 - val_loss: 7.3443e-04\n",
      "Epoch 346/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6161e-04 - val_loss: 7.3326e-04\n",
      "Epoch 347/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.6126e-04 - val_loss: 7.4467e-04\n",
      "Epoch 348/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6130e-04 - val_loss: 7.1338e-04\n",
      "Epoch 349/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6141e-04 - val_loss: 7.2435e-04\n",
      "Epoch 350/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6123e-04 - val_loss: 7.3423e-04\n",
      "Epoch 351/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6157e-04 - val_loss: 7.3391e-04\n",
      "Epoch 352/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6028e-04 - val_loss: 7.3753e-04\n",
      "Epoch 353/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6133e-04 - val_loss: 7.3131e-04\n",
      "Epoch 354/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6095e-04 - val_loss: 7.3732e-04\n",
      "Epoch 355/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6024e-04 - val_loss: 7.3526e-04\n",
      "Epoch 356/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6059e-04 - val_loss: 7.2612e-04\n",
      "Epoch 357/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6012e-04 - val_loss: 7.4474e-04\n",
      "Epoch 358/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.6046e-04 - val_loss: 7.3934e-04\n",
      "Epoch 359/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6046e-04 - val_loss: 7.0738e-04\n",
      "Epoch 360/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6023e-04 - val_loss: 7.3013e-04\n",
      "Epoch 361/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6034e-04 - val_loss: 7.1592e-04\n",
      "Epoch 362/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.5975e-04 - val_loss: 7.2492e-04\n",
      "Epoch 363/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 6.5968e-04 - val_loss: 7.4930e-04\n",
      "Epoch 364/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5956e-04 - val_loss: 7.2716e-04\n",
      "Epoch 365/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5959e-04 - val_loss: 7.2912e-04\n",
      "Epoch 366/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5918e-04 - val_loss: 7.2670e-04\n",
      "Epoch 367/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5895e-04 - val_loss: 7.2665e-04\n",
      "Epoch 368/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5887e-04 - val_loss: 7.2941e-04\n",
      "Epoch 369/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5856e-04 - val_loss: 7.2965e-04\n",
      "Epoch 370/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5857e-04 - val_loss: 7.2525e-04\n",
      "Epoch 371/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5882e-04 - val_loss: 7.1940e-04\n",
      "Epoch 372/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5852e-04 - val_loss: 7.1440e-04\n",
      "Epoch 373/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5890e-04 - val_loss: 7.3445e-04\n",
      "Epoch 374/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5819e-04 - val_loss: 7.1139e-04\n",
      "Epoch 375/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5818e-04 - val_loss: 7.4720e-04\n",
      "Epoch 376/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5824e-04 - val_loss: 7.3265e-04\n",
      "Epoch 377/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.5843e-04 - val_loss: 7.4428e-04\n",
      "Epoch 378/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5847e-04 - val_loss: 7.4092e-04\n",
      "Epoch 379/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5785e-04 - val_loss: 7.3074e-04\n",
      "Epoch 380/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5756e-04 - val_loss: 7.3390e-04\n",
      "Epoch 381/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.5740e-04 - val_loss: 7.3921e-04\n",
      "Epoch 382/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.5761e-04 - val_loss: 7.2762e-04\n",
      "Epoch 383/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5753e-04 - val_loss: 7.3886e-04\n",
      "Epoch 384/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5746e-04 - val_loss: 7.4111e-04\n",
      "Epoch 385/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5723e-04 - val_loss: 7.2253e-04\n",
      "Epoch 386/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5696e-04 - val_loss: 7.2334e-04\n",
      "Epoch 387/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5670e-04 - val_loss: 7.3269e-04\n",
      "Epoch 388/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.5713e-04 - val_loss: 7.2221e-04\n",
      "Epoch 389/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5670e-04 - val_loss: 7.2112e-04\n",
      "Epoch 390/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5654e-04 - val_loss: 7.1983e-04\n",
      "Epoch 391/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5759e-04 - val_loss: 7.1165e-04\n",
      "Epoch 392/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5703e-04 - val_loss: 7.3759e-04\n",
      "Epoch 393/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5696e-04 - val_loss: 7.3698e-04\n",
      "Epoch 394/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.5591e-04 - val_loss: 7.1337e-04\n",
      "Epoch 395/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5729e-04 - val_loss: 7.4241e-04\n",
      "Epoch 396/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5653e-04 - val_loss: 7.1608e-04\n",
      "Epoch 397/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.5634e-04 - val_loss: 7.1193e-04\n",
      "Epoch 398/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5636e-04 - val_loss: 7.2186e-04\n",
      "Epoch 399/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5574e-04 - val_loss: 7.1632e-04\n",
      "Epoch 400/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5578e-04 - val_loss: 7.1714e-04\n",
      "Epoch 401/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5662e-04 - val_loss: 7.3464e-04\n",
      "Epoch 402/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5673e-04 - val_loss: 7.2619e-04\n",
      "Epoch 403/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5586e-04 - val_loss: 7.1662e-04\n",
      "Epoch 404/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5614e-04 - val_loss: 7.3064e-04\n",
      "Epoch 405/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5593e-04 - val_loss: 7.2903e-04\n",
      "Epoch 406/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5658e-04 - val_loss: 7.2196e-04\n",
      "Epoch 407/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5618e-04 - val_loss: 7.4821e-04\n",
      "Epoch 408/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5593e-04 - val_loss: 7.1693e-04\n",
      "Epoch 409/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5539e-04 - val_loss: 7.1301e-04\n",
      "Epoch 410/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.5651e-04 - val_loss: 7.4372e-04\n",
      "Epoch 411/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5560e-04 - val_loss: 7.1824e-04\n",
      "Epoch 412/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5636e-04 - val_loss: 7.1525e-04\n",
      "Epoch 413/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.5594e-04 - val_loss: 7.2455e-04\n",
      "Epoch 414/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5603e-04 - val_loss: 7.1715e-04\n",
      "Epoch 415/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5570e-04 - val_loss: 7.2523e-04\n",
      "Epoch 416/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.5587e-04 - val_loss: 7.2662e-04\n",
      "Epoch 417/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5517e-04 - val_loss: 7.1516e-04\n",
      "Epoch 418/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.5490e-04 - val_loss: 7.1686e-04\n",
      "Epoch 419/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.5491e-04 - val_loss: 7.1887e-04\n",
      "Epoch 420/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.5536e-04 - val_loss: 7.2563e-04\n",
      "Epoch 421/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5487e-04 - val_loss: 7.2633e-04\n",
      "Epoch 422/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5436e-04 - val_loss: 7.1375e-04\n",
      "Epoch 423/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5495e-04 - val_loss: 7.3150e-04\n",
      "Epoch 424/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5542e-04 - val_loss: 7.3235e-04\n",
      "Epoch 425/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5437e-04 - val_loss: 7.3718e-04\n",
      "Epoch 426/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5545e-04 - val_loss: 7.1469e-04\n",
      "Epoch 427/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5495e-04 - val_loss: 7.1301e-04\n",
      "Epoch 428/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5434e-04 - val_loss: 7.1802e-04\n",
      "Epoch 429/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5354e-04 - val_loss: 7.1236e-04\n",
      "Epoch 430/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5461e-04 - val_loss: 7.2733e-04\n",
      "Epoch 431/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5461e-04 - val_loss: 7.2357e-04\n",
      "Epoch 432/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5470e-04 - val_loss: 7.2841e-04\n",
      "Epoch 433/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5430e-04 - val_loss: 7.1603e-04\n",
      "Epoch 434/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5435e-04 - val_loss: 7.1281e-04\n",
      "Epoch 435/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5387e-04 - val_loss: 7.1898e-04\n",
      "Epoch 436/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 6.5403e-04 - val_loss: 7.0721e-04\n",
      "Epoch 437/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.5377e-04 - val_loss: 7.1035e-04\n",
      "Epoch 438/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5311e-04 - val_loss: 7.3842e-04\n",
      "Epoch 439/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5385e-04 - val_loss: 7.2285e-04\n",
      "Epoch 440/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5351e-04 - val_loss: 7.2970e-04\n",
      "Epoch 441/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5397e-04 - val_loss: 7.1471e-04\n",
      "Epoch 442/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5333e-04 - val_loss: 7.2513e-04\n",
      "Epoch 443/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5418e-04 - val_loss: 7.1327e-04\n",
      "Epoch 444/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5345e-04 - val_loss: 7.2213e-04\n",
      "Epoch 445/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5329e-04 - val_loss: 7.1758e-04\n",
      "Epoch 446/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5276e-04 - val_loss: 7.4164e-04\n",
      "Epoch 447/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5404e-04 - val_loss: 7.1497e-04\n",
      "Epoch 448/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5373e-04 - val_loss: 7.1677e-04\n",
      "Epoch 449/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5306e-04 - val_loss: 7.1682e-04\n",
      "Epoch 450/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5333e-04 - val_loss: 7.1880e-04\n",
      "Epoch 451/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.5311e-04 - val_loss: 7.1978e-04\n",
      "Epoch 452/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.5346e-04 - val_loss: 7.1981e-04\n",
      "Epoch 453/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5269e-04 - val_loss: 7.2552e-04\n",
      "Epoch 454/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5266e-04 - val_loss: 7.4394e-04\n",
      "Epoch 455/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5284e-04 - val_loss: 7.4433e-04\n",
      "Epoch 456/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.5272e-04 - val_loss: 7.2371e-04\n",
      "Epoch 457/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.5281e-04 - val_loss: 7.2515e-04\n",
      "Epoch 458/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5212e-04 - val_loss: 7.2466e-04\n",
      "Epoch 459/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5322e-04 - val_loss: 7.3183e-04\n",
      "Epoch 460/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5199e-04 - val_loss: 7.2369e-04\n",
      "Epoch 461/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5256e-04 - val_loss: 7.2673e-04\n",
      "Epoch 462/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5165e-04 - val_loss: 7.3333e-04\n",
      "Epoch 463/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5164e-04 - val_loss: 7.2684e-04\n",
      "Epoch 464/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5199e-04 - val_loss: 7.3144e-04\n",
      "Epoch 465/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5176e-04 - val_loss: 7.3216e-04\n",
      "Epoch 466/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5142e-04 - val_loss: 7.3245e-04\n",
      "Epoch 467/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.5167e-04 - val_loss: 7.3201e-04\n",
      "Epoch 468/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5140e-04 - val_loss: 7.1940e-04\n",
      "Epoch 469/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5106e-04 - val_loss: 7.2947e-04\n",
      "Epoch 470/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.5155e-04 - val_loss: 7.3172e-04\n",
      "Epoch 471/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5121e-04 - val_loss: 7.3065e-04\n",
      "Epoch 472/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5124e-04 - val_loss: 7.3118e-04\n",
      "Epoch 473/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5121e-04 - val_loss: 7.2823e-04\n",
      "Epoch 474/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.5149e-04 - val_loss: 7.2273e-04\n",
      "Epoch 475/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.5109e-04 - val_loss: 7.4056e-04\n",
      "Epoch 476/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.5180e-04 - val_loss: 7.3436e-04\n",
      "Epoch 477/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.5207e-04 - val_loss: 7.4275e-04\n",
      "Epoch 478/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5097e-04 - val_loss: 7.3172e-04\n",
      "Epoch 479/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5145e-04 - val_loss: 7.2959e-04\n",
      "Epoch 480/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.5096e-04 - val_loss: 7.3888e-04\n",
      "Epoch 481/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5041e-04 - val_loss: 7.3719e-04\n",
      "Epoch 482/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5067e-04 - val_loss: 7.2838e-04\n",
      "Epoch 483/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.5055e-04 - val_loss: 7.3431e-04\n",
      "Epoch 484/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5033e-04 - val_loss: 7.2795e-04\n",
      "Epoch 485/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5001e-04 - val_loss: 7.3074e-04\n",
      "Epoch 486/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4997e-04 - val_loss: 7.3276e-04\n",
      "Epoch 487/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4997e-04 - val_loss: 7.2691e-04\n",
      "Epoch 488/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4978e-04 - val_loss: 7.2904e-04\n",
      "Epoch 489/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.4989e-04 - val_loss: 7.2657e-04\n",
      "Epoch 490/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4967e-04 - val_loss: 7.2629e-04\n",
      "Epoch 491/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4962e-04 - val_loss: 7.2632e-04\n",
      "Epoch 492/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4931e-04 - val_loss: 7.3109e-04\n",
      "Epoch 493/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.4920e-04 - val_loss: 7.3066e-04\n",
      "Epoch 494/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4900e-04 - val_loss: 7.3151e-04\n",
      "Epoch 495/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4878e-04 - val_loss: 7.3192e-04\n",
      "Epoch 496/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4875e-04 - val_loss: 7.3045e-04\n",
      "Epoch 497/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4872e-04 - val_loss: 7.3215e-04\n",
      "Epoch 498/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4886e-04 - val_loss: 7.2653e-04\n",
      "Epoch 499/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4903e-04 - val_loss: 7.3348e-04\n",
      "Epoch 500/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4845e-04 - val_loss: 7.2958e-04\n",
      "Epoch 501/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4849e-04 - val_loss: 7.1457e-04\n",
      "Epoch 502/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4854e-04 - val_loss: 7.3137e-04\n",
      "Epoch 503/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4825e-04 - val_loss: 7.3087e-04\n",
      "Epoch 504/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4855e-04 - val_loss: 7.2107e-04\n",
      "Epoch 505/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4847e-04 - val_loss: 7.1607e-04\n",
      "Epoch 506/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4895e-04 - val_loss: 7.1907e-04\n",
      "Epoch 507/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.4804e-04 - val_loss: 7.2795e-04\n",
      "Epoch 508/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4802e-04 - val_loss: 7.2160e-04\n",
      "Epoch 509/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4790e-04 - val_loss: 7.2114e-04\n",
      "Epoch 510/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4768e-04 - val_loss: 7.2773e-04\n",
      "Epoch 511/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4761e-04 - val_loss: 7.3454e-04\n",
      "Epoch 512/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.4769e-04 - val_loss: 7.3438e-04\n",
      "Epoch 513/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4742e-04 - val_loss: 7.3563e-04\n",
      "Epoch 514/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4733e-04 - val_loss: 7.3485e-04\n",
      "Epoch 515/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4745e-04 - val_loss: 7.3220e-04\n",
      "Epoch 516/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4745e-04 - val_loss: 7.3241e-04\n",
      "Epoch 517/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4724e-04 - val_loss: 7.3176e-04\n",
      "Epoch 518/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4693e-04 - val_loss: 7.3011e-04\n",
      "Epoch 519/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4700e-04 - val_loss: 7.3092e-04\n",
      "Epoch 520/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4698e-04 - val_loss: 7.3114e-04\n",
      "Epoch 521/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4674e-04 - val_loss: 7.2415e-04\n",
      "Epoch 522/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4683e-04 - val_loss: 7.3041e-04\n",
      "Epoch 523/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4656e-04 - val_loss: 7.2646e-04\n",
      "Epoch 524/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4639e-04 - val_loss: 7.3205e-04\n",
      "Epoch 525/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4643e-04 - val_loss: 7.2728e-04\n",
      "Epoch 526/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4640e-04 - val_loss: 7.2799e-04\n",
      "Epoch 527/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4603e-04 - val_loss: 7.3223e-04\n",
      "Epoch 528/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4591e-04 - val_loss: 7.3095e-04\n",
      "Epoch 529/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4572e-04 - val_loss: 7.3191e-04\n",
      "Epoch 530/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.4556e-04 - val_loss: 7.3016e-04\n",
      "Epoch 531/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.4561e-04 - val_loss: 7.3431e-04\n",
      "Epoch 532/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4620e-04 - val_loss: 7.4625e-04\n",
      "Epoch 533/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4571e-04 - val_loss: 7.2928e-04\n",
      "Epoch 534/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4561e-04 - val_loss: 7.2822e-04\n",
      "Epoch 535/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4552e-04 - val_loss: 7.4848e-04\n",
      "Epoch 536/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4593e-04 - val_loss: 7.5180e-04\n",
      "Epoch 537/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4540e-04 - val_loss: 7.4988e-04\n",
      "Epoch 538/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4514e-04 - val_loss: 7.3711e-04\n",
      "Epoch 539/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4504e-04 - val_loss: 7.4529e-04\n",
      "Epoch 540/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4487e-04 - val_loss: 7.4325e-04\n",
      "Epoch 541/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4503e-04 - val_loss: 7.2903e-04\n",
      "Epoch 542/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4481e-04 - val_loss: 7.2795e-04\n",
      "Epoch 543/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4509e-04 - val_loss: 7.2879e-04\n",
      "Epoch 544/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.4493e-04 - val_loss: 7.2569e-04\n",
      "Epoch 545/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4472e-04 - val_loss: 7.2724e-04\n",
      "Epoch 546/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4456e-04 - val_loss: 7.2569e-04\n",
      "Epoch 547/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4462e-04 - val_loss: 7.2676e-04\n",
      "Epoch 548/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4448e-04 - val_loss: 7.2628e-04\n",
      "Epoch 549/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.4418e-04 - val_loss: 7.3287e-04\n",
      "Epoch 550/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4424e-04 - val_loss: 7.2183e-04\n",
      "Epoch 551/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4417e-04 - val_loss: 7.2211e-04\n",
      "Epoch 552/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4411e-04 - val_loss: 7.2815e-04\n",
      "Epoch 553/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4395e-04 - val_loss: 7.2228e-04\n",
      "Epoch 554/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4384e-04 - val_loss: 7.2297e-04\n",
      "Epoch 555/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4364e-04 - val_loss: 7.2827e-04\n",
      "Epoch 556/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4353e-04 - val_loss: 7.2581e-04\n",
      "Epoch 557/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4343e-04 - val_loss: 7.2660e-04\n",
      "Epoch 558/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4344e-04 - val_loss: 7.2276e-04\n",
      "Epoch 559/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4317e-04 - val_loss: 7.2257e-04\n",
      "Epoch 560/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4290e-04 - val_loss: 7.2378e-04\n",
      "Epoch 561/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4305e-04 - val_loss: 7.2078e-04\n",
      "Epoch 562/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4263e-04 - val_loss: 7.2107e-04\n",
      "Epoch 563/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.4292e-04 - val_loss: 7.2110e-04\n",
      "Epoch 564/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4305e-04 - val_loss: 7.2270e-04\n",
      "Epoch 565/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4256e-04 - val_loss: 7.2186e-04\n",
      "Epoch 566/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4289e-04 - val_loss: 7.1957e-04\n",
      "Epoch 567/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.4270e-04 - val_loss: 7.2173e-04\n",
      "Epoch 568/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.4211e-04 - val_loss: 7.2118e-04\n",
      "Epoch 569/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4227e-04 - val_loss: 7.1879e-04\n",
      "Epoch 570/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4236e-04 - val_loss: 7.1957e-04\n",
      "Epoch 571/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.4218e-04 - val_loss: 7.1946e-04\n",
      "Epoch 572/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4200e-04 - val_loss: 7.1993e-04\n",
      "Epoch 573/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4181e-04 - val_loss: 7.1856e-04\n",
      "Epoch 574/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.4167e-04 - val_loss: 7.1722e-04\n",
      "Epoch 575/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4156e-04 - val_loss: 7.1704e-04\n",
      "Epoch 576/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4150e-04 - val_loss: 7.1767e-04\n",
      "Epoch 577/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4141e-04 - val_loss: 7.1824e-04\n",
      "Epoch 578/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4133e-04 - val_loss: 7.1489e-04\n",
      "Epoch 579/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4121e-04 - val_loss: 7.1425e-04\n",
      "Epoch 580/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4109e-04 - val_loss: 7.3091e-04\n",
      "Epoch 581/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.4127e-04 - val_loss: 7.2948e-04\n",
      "Epoch 582/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4204e-04 - val_loss: 7.2547e-04\n",
      "Epoch 583/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4153e-04 - val_loss: 7.0833e-04\n",
      "Epoch 584/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4070e-04 - val_loss: 7.1751e-04\n",
      "Epoch 585/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4056e-04 - val_loss: 7.1853e-04\n",
      "Epoch 586/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.4036e-04 - val_loss: 7.1672e-04\n",
      "Epoch 587/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4024e-04 - val_loss: 7.1574e-04\n",
      "Epoch 588/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4019e-04 - val_loss: 7.1780e-04\n",
      "Epoch 589/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4016e-04 - val_loss: 7.1582e-04\n",
      "Epoch 590/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4074e-04 - val_loss: 7.1308e-04\n",
      "Epoch 591/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4040e-04 - val_loss: 7.1149e-04\n",
      "Epoch 592/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4020e-04 - val_loss: 7.0947e-04\n",
      "Epoch 593/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4014e-04 - val_loss: 7.0747e-04\n",
      "Epoch 594/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4009e-04 - val_loss: 7.0932e-04\n",
      "Epoch 595/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4007e-04 - val_loss: 7.0958e-04\n",
      "Epoch 596/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3989e-04 - val_loss: 7.0940e-04\n",
      "Epoch 597/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3968e-04 - val_loss: 7.0905e-04\n",
      "Epoch 598/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3969e-04 - val_loss: 7.2334e-04\n",
      "Epoch 599/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3960e-04 - val_loss: 7.1766e-04\n",
      "Epoch 600/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.3938e-04 - val_loss: 7.2414e-04\n",
      "Epoch 601/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3911e-04 - val_loss: 7.2011e-04\n",
      "Epoch 602/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3911e-04 - val_loss: 7.1966e-04\n",
      "Epoch 603/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3893e-04 - val_loss: 7.2021e-04\n",
      "Epoch 604/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.3885e-04 - val_loss: 7.2633e-04\n",
      "Epoch 605/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.3880e-04 - val_loss: 7.2556e-04\n",
      "Epoch 606/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.3868e-04 - val_loss: 7.2211e-04\n",
      "Epoch 607/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3872e-04 - val_loss: 7.1742e-04\n",
      "Epoch 608/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3906e-04 - val_loss: 7.1185e-04\n",
      "Epoch 609/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.3837e-04 - val_loss: 7.2255e-04\n",
      "Epoch 610/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3855e-04 - val_loss: 7.1487e-04\n",
      "Epoch 611/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3841e-04 - val_loss: 7.1283e-04\n",
      "Epoch 612/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3821e-04 - val_loss: 7.0593e-04\n",
      "Epoch 613/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3819e-04 - val_loss: 7.0585e-04\n",
      "Epoch 614/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3840e-04 - val_loss: 7.0670e-04\n",
      "Epoch 615/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3770e-04 - val_loss: 7.0528e-04\n",
      "Epoch 616/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3780e-04 - val_loss: 7.1678e-04\n",
      "Epoch 617/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3754e-04 - val_loss: 7.1107e-04\n",
      "Epoch 618/10000\n",
      "45507/45507 [==============================] - ETA: 0s - loss: 6.3873e-0 - 1s 30us/step - loss: 6.3746e-04 - val_loss: 7.1256e-04\n",
      "Epoch 619/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3729e-04 - val_loss: 7.0991e-04\n",
      "Epoch 620/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3729e-04 - val_loss: 7.1258e-04\n",
      "Epoch 621/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3710e-04 - val_loss: 7.0872e-04\n",
      "Epoch 622/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3701e-04 - val_loss: 7.0793e-04\n",
      "Epoch 623/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.3691e-04 - val_loss: 7.0838e-04\n",
      "Epoch 624/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.3683e-04 - val_loss: 7.0978e-04\n",
      "Epoch 625/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3682e-04 - val_loss: 7.1149e-04\n",
      "Epoch 626/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3708e-04 - val_loss: 7.0589e-04\n",
      "Epoch 627/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3656e-04 - val_loss: 7.1119e-04\n",
      "Epoch 628/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3731e-04 - val_loss: 7.0584e-04\n",
      "Epoch 629/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3678e-04 - val_loss: 7.0725e-04\n",
      "Epoch 630/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3638e-04 - val_loss: 7.1113e-04\n",
      "Epoch 631/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3695e-04 - val_loss: 7.0481e-04\n",
      "Epoch 632/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3630e-04 - val_loss: 7.0760e-04\n",
      "Epoch 633/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3661e-04 - val_loss: 7.0917e-04\n",
      "Epoch 634/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3632e-04 - val_loss: 7.0684e-04\n",
      "Epoch 635/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3593e-04 - val_loss: 7.0493e-04\n",
      "Epoch 636/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3627e-04 - val_loss: 7.0683e-04\n",
      "Epoch 637/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.3578e-04 - val_loss: 7.0506e-04\n",
      "Epoch 638/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3587e-04 - val_loss: 7.0499e-04\n",
      "Epoch 639/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3571e-04 - val_loss: 7.0070e-04\n",
      "Epoch 640/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3565e-04 - val_loss: 7.0441e-04\n",
      "Epoch 641/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.3566e-04 - val_loss: 7.0337e-04\n",
      "Epoch 642/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.3527e-04 - val_loss: 7.0268e-04\n",
      "Epoch 643/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.3523e-04 - val_loss: 7.0031e-04\n",
      "Epoch 644/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3510e-04 - val_loss: 7.0155e-04\n",
      "Epoch 645/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3490e-04 - val_loss: 7.0227e-04\n",
      "Epoch 646/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3490e-04 - val_loss: 7.0104e-04\n",
      "Epoch 647/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3488e-04 - val_loss: 7.0057e-04\n",
      "Epoch 648/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3481e-04 - val_loss: 7.0092e-04\n",
      "Epoch 649/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3452e-04 - val_loss: 7.0150e-04\n",
      "Epoch 650/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3483e-04 - val_loss: 7.0159e-04\n",
      "Epoch 651/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.3467e-04 - val_loss: 7.0062e-04\n",
      "Epoch 652/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3438e-04 - val_loss: 7.0276e-04\n",
      "Epoch 653/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3415e-04 - val_loss: 7.0259e-04\n",
      "Epoch 654/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3392e-04 - val_loss: 7.0153e-04\n",
      "Epoch 655/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3383e-04 - val_loss: 7.0169e-04\n",
      "Epoch 656/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.3384e-04 - val_loss: 7.0114e-04\n",
      "Epoch 657/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3361e-04 - val_loss: 7.0097e-04\n",
      "Epoch 658/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3358e-04 - val_loss: 7.0046e-04\n",
      "Epoch 659/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.3348e-04 - val_loss: 6.9918e-04\n",
      "Epoch 660/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.3332e-04 - val_loss: 6.9939e-04\n",
      "Epoch 661/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3329e-04 - val_loss: 6.9744e-04\n",
      "Epoch 662/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3311e-04 - val_loss: 6.9851e-04\n",
      "Epoch 663/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3302e-04 - val_loss: 6.9763e-04\n",
      "Epoch 664/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3279e-04 - val_loss: 6.9786e-04\n",
      "Epoch 665/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3302e-04 - val_loss: 6.9663e-04\n",
      "Epoch 666/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3367e-04 - val_loss: 6.9883e-04\n",
      "Epoch 667/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3283e-04 - val_loss: 6.9608e-04\n",
      "Epoch 668/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3279e-04 - val_loss: 6.9560e-04\n",
      "Epoch 669/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3273e-04 - val_loss: 6.9659e-04\n",
      "Epoch 670/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3260e-04 - val_loss: 6.9618e-04\n",
      "Epoch 671/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3250e-04 - val_loss: 6.9492e-04\n",
      "Epoch 672/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3240e-04 - val_loss: 6.9318e-04\n",
      "Epoch 673/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3219e-04 - val_loss: 6.9358e-04\n",
      "Epoch 674/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.3223e-04 - val_loss: 6.9395e-04\n",
      "Epoch 675/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.3212e-04 - val_loss: 6.9238e-04\n",
      "Epoch 676/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3176e-04 - val_loss: 6.9452e-04\n",
      "Epoch 677/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3173e-04 - val_loss: 6.9501e-04\n",
      "Epoch 678/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.3237e-04 - val_loss: 6.9123e-04\n",
      "Epoch 679/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.3167e-04 - val_loss: 6.9054e-04\n",
      "Epoch 680/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.3149e-04 - val_loss: 6.9312e-04\n",
      "Epoch 681/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3153e-04 - val_loss: 6.9260e-04\n",
      "Epoch 682/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3141e-04 - val_loss: 6.9092e-04\n",
      "Epoch 683/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3115e-04 - val_loss: 6.9210e-04\n",
      "Epoch 684/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3112e-04 - val_loss: 6.9118e-04\n",
      "Epoch 685/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3087e-04 - val_loss: 6.9184e-04\n",
      "Epoch 686/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3193e-04 - val_loss: 6.9527e-04\n",
      "Epoch 687/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3219e-04 - val_loss: 6.8990e-04\n",
      "Epoch 688/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3178e-04 - val_loss: 6.8951e-04\n",
      "Epoch 689/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3054e-04 - val_loss: 6.9309e-04\n",
      "Epoch 690/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3072e-04 - val_loss: 6.9013e-04\n",
      "Epoch 691/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3050e-04 - val_loss: 6.8936e-04\n",
      "Epoch 692/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3062e-04 - val_loss: 6.8980e-04\n",
      "Epoch 693/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.3030e-04 - val_loss: 6.9083e-04\n",
      "Epoch 694/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3041e-04 - val_loss: 6.9433e-04\n",
      "Epoch 695/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3167e-04 - val_loss: 6.8759e-04\n",
      "Epoch 696/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3027e-04 - val_loss: 6.8777e-04\n",
      "Epoch 697/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.3063e-04 - val_loss: 6.9153e-04\n",
      "Epoch 698/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.3012e-04 - val_loss: 6.8764e-04\n",
      "Epoch 699/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2999e-04 - val_loss: 6.8633e-04\n",
      "Epoch 700/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2980e-04 - val_loss: 6.8552e-04\n",
      "Epoch 701/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2965e-04 - val_loss: 6.8460e-04\n",
      "Epoch 702/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2954e-04 - val_loss: 6.8436e-04\n",
      "Epoch 703/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.2941e-04 - val_loss: 6.8404e-04\n",
      "Epoch 704/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2927e-04 - val_loss: 6.8359e-04\n",
      "Epoch 705/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2995e-04 - val_loss: 6.8615e-04\n",
      "Epoch 706/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2977e-04 - val_loss: 6.8352e-04\n",
      "Epoch 707/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2902e-04 - val_loss: 6.8394e-04\n",
      "Epoch 708/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2911e-04 - val_loss: 6.8452e-04\n",
      "Epoch 709/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.2904e-04 - val_loss: 6.8552e-04\n",
      "Epoch 710/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2910e-04 - val_loss: 6.8437e-04\n",
      "Epoch 711/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2915e-04 - val_loss: 6.8426e-04\n",
      "Epoch 712/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2876e-04 - val_loss: 6.8293e-04\n",
      "Epoch 713/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2853e-04 - val_loss: 6.8304e-04\n",
      "Epoch 714/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2883e-04 - val_loss: 6.8141e-04\n",
      "Epoch 715/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2840e-04 - val_loss: 6.8168e-04\n",
      "Epoch 716/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.2824e-04 - val_loss: 6.8013e-04\n",
      "Epoch 717/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.2799e-04 - val_loss: 6.8047e-04\n",
      "Epoch 718/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2772e-04 - val_loss: 6.8008e-04\n",
      "Epoch 719/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2771e-04 - val_loss: 6.7830e-04\n",
      "Epoch 720/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2761e-04 - val_loss: 6.7980e-04\n",
      "Epoch 721/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2791e-04 - val_loss: 6.7812e-04\n",
      "Epoch 722/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2787e-04 - val_loss: 6.7921e-04\n",
      "Epoch 723/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2760e-04 - val_loss: 6.8395e-04\n",
      "Epoch 724/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2860e-04 - val_loss: 6.7926e-04\n",
      "Epoch 725/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.2744e-04 - val_loss: 6.7673e-04\n",
      "Epoch 726/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2741e-04 - val_loss: 6.9547e-04\n",
      "Epoch 727/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2854e-04 - val_loss: 6.7722e-04\n",
      "Epoch 728/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2697e-04 - val_loss: 6.7736e-04\n",
      "Epoch 729/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2687e-04 - val_loss: 6.8849e-04\n",
      "Epoch 730/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.2808e-04 - val_loss: 6.7818e-04\n",
      "Epoch 731/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2672e-04 - val_loss: 6.7532e-04\n",
      "Epoch 732/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2654e-04 - val_loss: 6.7556e-04\n",
      "Epoch 733/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2672e-04 - val_loss: 6.7669e-04\n",
      "Epoch 734/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.2673e-04 - val_loss: 6.7484e-04\n",
      "Epoch 735/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 6.2648e-04 - val_loss: 6.7274e-04\n",
      "Epoch 736/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2665e-04 - val_loss: 6.7483e-04\n",
      "Epoch 737/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2609e-04 - val_loss: 6.7221e-04\n",
      "Epoch 738/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2602e-04 - val_loss: 6.7393e-04\n",
      "Epoch 739/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2655e-04 - val_loss: 6.7498e-04\n",
      "Epoch 740/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2596e-04 - val_loss: 6.7407e-04\n",
      "Epoch 741/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2585e-04 - val_loss: 6.7255e-04\n",
      "Epoch 742/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2597e-04 - val_loss: 6.7050e-04\n",
      "Epoch 743/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2626e-04 - val_loss: 6.7239e-04\n",
      "Epoch 744/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2568e-04 - val_loss: 6.7276e-04\n",
      "Epoch 745/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2586e-04 - val_loss: 6.6787e-04\n",
      "Epoch 746/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2560e-04 - val_loss: 6.7201e-04\n",
      "Epoch 747/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2542e-04 - val_loss: 6.7295e-04\n",
      "Epoch 748/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2511e-04 - val_loss: 6.8428e-04\n",
      "Epoch 749/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.2589e-04 - val_loss: 6.7349e-04\n",
      "Epoch 750/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2517e-04 - val_loss: 6.7363e-04\n",
      "Epoch 751/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2503e-04 - val_loss: 6.7277e-04\n",
      "Epoch 752/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2507e-04 - val_loss: 6.6762e-04\n",
      "Epoch 753/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.2503e-04 - val_loss: 6.7095e-04\n",
      "Epoch 754/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.2478e-04 - val_loss: 6.7258e-04\n",
      "Epoch 755/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2501e-04 - val_loss: 6.7062e-04\n",
      "Epoch 756/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2452e-04 - val_loss: 6.6864e-04\n",
      "Epoch 757/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2563e-04 - val_loss: 6.6649e-04\n",
      "Epoch 758/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2471e-04 - val_loss: 6.7049e-04\n",
      "Epoch 759/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2451e-04 - val_loss: 6.7030e-04\n",
      "Epoch 760/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2424e-04 - val_loss: 6.6942e-04\n",
      "Epoch 761/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2412e-04 - val_loss: 6.7074e-04\n",
      "Epoch 762/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2410e-04 - val_loss: 6.7031e-04\n",
      "Epoch 763/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2385e-04 - val_loss: 6.6988e-04\n",
      "Epoch 764/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2383e-04 - val_loss: 6.6913e-04\n",
      "Epoch 765/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2383e-04 - val_loss: 6.6418e-04\n",
      "Epoch 766/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2404e-04 - val_loss: 6.6731e-04\n",
      "Epoch 767/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.2346e-04 - val_loss: 6.6838e-04\n",
      "Epoch 768/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2390e-04 - val_loss: 6.6534e-04\n",
      "Epoch 769/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2356e-04 - val_loss: 6.6445e-04\n",
      "Epoch 770/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2436e-04 - val_loss: 6.6557e-04\n",
      "Epoch 771/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2347e-04 - val_loss: 6.6521e-04\n",
      "Epoch 772/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.2346e-04 - val_loss: 6.6532e-04\n",
      "Epoch 773/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2312e-04 - val_loss: 6.6341e-04\n",
      "Epoch 774/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2292e-04 - val_loss: 6.6702e-04\n",
      "Epoch 775/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2401e-04 - val_loss: 6.6374e-04\n",
      "Epoch 776/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2298e-04 - val_loss: 6.6430e-04\n",
      "Epoch 777/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2330e-04 - val_loss: 6.6452e-04\n",
      "Epoch 778/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2296e-04 - val_loss: 6.6209e-04\n",
      "Epoch 779/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2246e-04 - val_loss: 6.6404e-04\n",
      "Epoch 780/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2240e-04 - val_loss: 6.6513e-04\n",
      "Epoch 781/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2268e-04 - val_loss: 6.6458e-04\n",
      "Epoch 782/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2272e-04 - val_loss: 6.5772e-04\n",
      "Epoch 783/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2209e-04 - val_loss: 6.6397e-04\n",
      "Epoch 784/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2222e-04 - val_loss: 6.6370e-04\n",
      "Epoch 785/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2211e-04 - val_loss: 6.6222e-04\n",
      "Epoch 786/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2288e-04 - val_loss: 6.5630e-04\n",
      "Epoch 787/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2221e-04 - val_loss: 6.6070e-04\n",
      "Epoch 788/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.2208e-04 - val_loss: 6.6184e-04\n",
      "Epoch 789/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.2198e-04 - val_loss: 6.6392e-04\n",
      "Epoch 790/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.2184e-04 - val_loss: 6.6158e-04\n",
      "Epoch 791/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.2165e-04 - val_loss: 6.6295e-04\n",
      "Epoch 792/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.2174e-04 - val_loss: 6.6211e-04\n",
      "Epoch 793/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2163e-04 - val_loss: 6.6170e-04\n",
      "Epoch 794/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2151e-04 - val_loss: 6.5851e-04\n",
      "Epoch 795/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.2146e-04 - val_loss: 6.6158e-04\n",
      "Epoch 796/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2151e-04 - val_loss: 6.5889e-04\n",
      "Epoch 797/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2118e-04 - val_loss: 6.6078e-04\n",
      "Epoch 798/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2103e-04 - val_loss: 6.5852e-04\n",
      "Epoch 799/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2099e-04 - val_loss: 6.5975e-04\n",
      "Epoch 800/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2081e-04 - val_loss: 6.5840e-04\n",
      "Epoch 801/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2080e-04 - val_loss: 6.6055e-04\n",
      "Epoch 802/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2058e-04 - val_loss: 6.5762e-04\n",
      "Epoch 803/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2058e-04 - val_loss: 6.5803e-04\n",
      "Epoch 804/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2052e-04 - val_loss: 6.5705e-04\n",
      "Epoch 805/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.2049e-04 - val_loss: 6.5906e-04\n",
      "Epoch 806/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2033e-04 - val_loss: 6.5589e-04\n",
      "Epoch 807/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2027e-04 - val_loss: 6.5798e-04\n",
      "Epoch 808/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2021e-04 - val_loss: 6.5728e-04\n",
      "Epoch 809/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.1979e-04 - val_loss: 6.5559e-04\n",
      "Epoch 810/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1986e-04 - val_loss: 6.5668e-04\n",
      "Epoch 811/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1970e-04 - val_loss: 6.5568e-04\n",
      "Epoch 812/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2033e-04 - val_loss: 6.5504e-04\n",
      "Epoch 813/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1981e-04 - val_loss: 6.5529e-04\n",
      "Epoch 814/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.1965e-04 - val_loss: 6.5554e-04\n",
      "Epoch 815/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1935e-04 - val_loss: 6.5493e-04\n",
      "Epoch 816/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2003e-04 - val_loss: 6.5353e-04\n",
      "Epoch 817/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1946e-04 - val_loss: 6.5336e-04\n",
      "Epoch 818/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1952e-04 - val_loss: 6.5336e-04\n",
      "Epoch 819/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1971e-04 - val_loss: 6.4981e-04\n",
      "Epoch 820/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1933e-04 - val_loss: 6.5263e-04\n",
      "Epoch 821/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 6.1915e-04 - val_loss: 6.5289e-04\n",
      "Epoch 822/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1925e-04 - val_loss: 6.5340e-04\n",
      "Epoch 823/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1887e-04 - val_loss: 6.5242e-04\n",
      "Epoch 824/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1895e-04 - val_loss: 6.5259e-04\n",
      "Epoch 825/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1869e-04 - val_loss: 6.5189e-04\n",
      "Epoch 826/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.1890e-04 - val_loss: 6.5169e-04\n",
      "Epoch 827/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1846e-04 - val_loss: 6.5443e-04\n",
      "Epoch 828/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 6.1874e-04 - val_loss: 6.5181e-04\n",
      "Epoch 829/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.1835e-04 - val_loss: 6.5487e-04\n",
      "Epoch 830/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1836e-04 - val_loss: 6.5473e-04\n",
      "Epoch 831/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1863e-04 - val_loss: 6.4843e-04\n",
      "Epoch 832/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1800e-04 - val_loss: 6.5206e-04\n",
      "Epoch 833/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1791e-04 - val_loss: 6.5213e-04\n",
      "Epoch 834/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1811e-04 - val_loss: 6.4981e-04\n",
      "Epoch 835/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1783e-04 - val_loss: 6.4723e-04\n",
      "Epoch 836/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1742e-04 - val_loss: 6.5028e-04\n",
      "Epoch 837/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1754e-04 - val_loss: 6.5022e-04\n",
      "Epoch 838/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1753e-04 - val_loss: 6.5036e-04\n",
      "Epoch 839/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.1753e-04 - val_loss: 6.4799e-04\n",
      "Epoch 840/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1718e-04 - val_loss: 6.5002e-04\n",
      "Epoch 841/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1716e-04 - val_loss: 6.5138e-04\n",
      "Epoch 842/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.1715e-04 - val_loss: 6.4780e-04\n",
      "Epoch 843/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1769e-04 - val_loss: 6.4916e-04\n",
      "Epoch 844/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1701e-04 - val_loss: 6.4956e-04\n",
      "Epoch 845/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1682e-04 - val_loss: 6.4881e-04\n",
      "Epoch 846/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1677e-04 - val_loss: 6.4814e-04\n",
      "Epoch 847/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.1662e-04 - val_loss: 6.4888e-04\n",
      "Epoch 848/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1667e-04 - val_loss: 6.4834e-04\n",
      "Epoch 849/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.1665e-04 - val_loss: 6.4836e-04\n",
      "Epoch 850/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1641e-04 - val_loss: 6.5043e-04\n",
      "Epoch 851/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1653e-04 - val_loss: 6.4822e-04\n",
      "Epoch 852/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.1616e-04 - val_loss: 6.4883e-04\n",
      "Epoch 853/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1617e-04 - val_loss: 6.4884e-04\n",
      "Epoch 854/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1625e-04 - val_loss: 6.4698e-04\n",
      "Epoch 855/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1623e-04 - val_loss: 6.4717e-04\n",
      "Epoch 856/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1595e-04 - val_loss: 6.4837e-04\n",
      "Epoch 857/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1580e-04 - val_loss: 6.4648e-04\n",
      "Epoch 858/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1573e-04 - val_loss: 6.4588e-04\n",
      "Epoch 859/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1573e-04 - val_loss: 6.4841e-04\n",
      "Epoch 860/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1573e-04 - val_loss: 6.4762e-04\n",
      "Epoch 861/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.1584e-04 - val_loss: 6.4820e-04\n",
      "Epoch 862/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1670e-04 - val_loss: 6.4540e-04\n",
      "Epoch 863/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1656e-04 - val_loss: 6.4437e-04\n",
      "Epoch 864/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1556e-04 - val_loss: 6.4654e-04\n",
      "Epoch 865/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.1570e-04 - val_loss: 6.4442e-04\n",
      "Epoch 866/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.1559e-04 - val_loss: 6.4360e-04\n",
      "Epoch 867/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.1547e-04 - val_loss: 6.4333e-04\n",
      "Epoch 868/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1529e-04 - val_loss: 6.4619e-04\n",
      "Epoch 869/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1517e-04 - val_loss: 6.4544e-04\n",
      "Epoch 870/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1514e-04 - val_loss: 6.4268e-04\n",
      "Epoch 871/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1477e-04 - val_loss: 6.4602e-04\n",
      "Epoch 872/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1484e-04 - val_loss: 6.4064e-04\n",
      "Epoch 873/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 6.1475e-04 - val_loss: 6.4359e-04\n",
      "Epoch 874/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.1457e-04 - val_loss: 6.4561e-04\n",
      "Epoch 875/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1447e-04 - val_loss: 6.4042e-04\n",
      "Epoch 876/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1482e-04 - val_loss: 6.4549e-04\n",
      "Epoch 877/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1464e-04 - val_loss: 6.3883e-04\n",
      "Epoch 878/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1430e-04 - val_loss: 6.3871e-04\n",
      "Epoch 879/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1491e-04 - val_loss: 6.5238e-04\n",
      "Epoch 880/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1443e-04 - val_loss: 6.3974e-04\n",
      "Epoch 881/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1495e-04 - val_loss: 6.3978e-04\n",
      "Epoch 882/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1471e-04 - val_loss: 6.4619e-04\n",
      "Epoch 883/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1413e-04 - val_loss: 6.3970e-04\n",
      "Epoch 884/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.1456e-04 - val_loss: 6.4120e-04\n",
      "Epoch 885/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.1407e-04 - val_loss: 6.4093e-04\n",
      "Epoch 886/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1428e-04 - val_loss: 6.4793e-04\n",
      "Epoch 887/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1439e-04 - val_loss: 6.3817e-04\n",
      "Epoch 888/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1350e-04 - val_loss: 6.4718e-04\n",
      "Epoch 889/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1347e-04 - val_loss: 6.4540e-04\n",
      "Epoch 890/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1368e-04 - val_loss: 6.4122e-04\n",
      "Epoch 891/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1407e-04 - val_loss: 6.3932e-04\n",
      "Epoch 892/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1334e-04 - val_loss: 6.4675e-04\n",
      "Epoch 893/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1382e-04 - val_loss: 6.4076e-04\n",
      "Epoch 894/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1310e-04 - val_loss: 6.3990e-04\n",
      "Epoch 895/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1312e-04 - val_loss: 6.4048e-04\n",
      "Epoch 896/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1291e-04 - val_loss: 6.4165e-04\n",
      "Epoch 897/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1290e-04 - val_loss: 6.3836e-04\n",
      "Epoch 898/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1252e-04 - val_loss: 6.4202e-04\n",
      "Epoch 899/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1269e-04 - val_loss: 6.3910e-04\n",
      "Epoch 900/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1327e-04 - val_loss: 6.4025e-04\n",
      "Epoch 901/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1232e-04 - val_loss: 6.3778e-04\n",
      "Epoch 902/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1254e-04 - val_loss: 6.3836e-04\n",
      "Epoch 903/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.1221e-04 - val_loss: 6.3643e-04\n",
      "Epoch 904/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.1302e-04 - val_loss: 6.3653e-04\n",
      "Epoch 905/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1242e-04 - val_loss: 6.4156e-04\n",
      "Epoch 906/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.1205e-04 - val_loss: 6.3826e-04\n",
      "Epoch 907/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1222e-04 - val_loss: 6.4664e-04\n",
      "Epoch 908/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1224e-04 - val_loss: 6.4191e-04\n",
      "Epoch 909/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1201e-04 - val_loss: 6.3583e-04\n",
      "Epoch 910/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1167e-04 - val_loss: 6.3832e-04\n",
      "Epoch 911/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1174e-04 - val_loss: 6.3973e-04\n",
      "Epoch 912/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1168e-04 - val_loss: 6.4171e-04\n",
      "Epoch 913/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1148e-04 - val_loss: 6.4226e-04\n",
      "Epoch 914/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1229e-04 - val_loss: 6.3718e-04\n",
      "Epoch 915/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1136e-04 - val_loss: 6.3765e-04\n",
      "Epoch 916/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1146e-04 - val_loss: 6.4270e-04\n",
      "Epoch 917/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.1146e-04 - val_loss: 6.3687e-04\n",
      "Epoch 918/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1201e-04 - val_loss: 6.3789e-04\n",
      "Epoch 919/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1136e-04 - val_loss: 6.3740e-04\n",
      "Epoch 920/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1110e-04 - val_loss: 6.3624e-04\n",
      "Epoch 921/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.1100e-04 - val_loss: 6.3605e-04\n",
      "Epoch 922/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.1090e-04 - val_loss: 6.4785e-04\n",
      "Epoch 923/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1181e-04 - val_loss: 6.3670e-04\n",
      "Epoch 924/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1077e-04 - val_loss: 6.3872e-04\n",
      "Epoch 925/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1122e-04 - val_loss: 6.4436e-04\n",
      "Epoch 926/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1064e-04 - val_loss: 6.3521e-04\n",
      "Epoch 927/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1054e-04 - val_loss: 6.4100e-04\n",
      "Epoch 928/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1061e-04 - val_loss: 6.3852e-04\n",
      "Epoch 929/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1028e-04 - val_loss: 6.3695e-04\n",
      "Epoch 930/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1046e-04 - val_loss: 6.4632e-04\n",
      "Epoch 931/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1055e-04 - val_loss: 6.4151e-04\n",
      "Epoch 932/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1011e-04 - val_loss: 6.3629e-04\n",
      "Epoch 933/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1001e-04 - val_loss: 6.3567e-04\n",
      "Epoch 934/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0999e-04 - val_loss: 6.3631e-04\n",
      "Epoch 935/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0977e-04 - val_loss: 6.3570e-04\n",
      "Epoch 936/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.0995e-04 - val_loss: 6.4229e-04\n",
      "Epoch 937/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1059e-04 - val_loss: 6.3947e-04\n",
      "Epoch 938/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0988e-04 - val_loss: 6.3743e-04\n",
      "Epoch 939/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0976e-04 - val_loss: 6.3806e-04\n",
      "Epoch 940/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.0962e-04 - val_loss: 6.3531e-04\n",
      "Epoch 941/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0959e-04 - val_loss: 6.3504e-04\n",
      "Epoch 942/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1027e-04 - val_loss: 6.3693e-04\n",
      "Epoch 943/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0968e-04 - val_loss: 6.4385e-04\n",
      "Epoch 944/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0982e-04 - val_loss: 6.3411e-04\n",
      "Epoch 945/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0944e-04 - val_loss: 6.3499e-04\n",
      "Epoch 946/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0938e-04 - val_loss: 6.3414e-04\n",
      "Epoch 947/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0927e-04 - val_loss: 6.3431e-04\n",
      "Epoch 948/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0916e-04 - val_loss: 6.3536e-04\n",
      "Epoch 949/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0902e-04 - val_loss: 6.3800e-04\n",
      "Epoch 950/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0914e-04 - val_loss: 6.3231e-04\n",
      "Epoch 951/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0885e-04 - val_loss: 6.3874e-04\n",
      "Epoch 952/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0905e-04 - val_loss: 6.3370e-04\n",
      "Epoch 953/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0876e-04 - val_loss: 6.3505e-04\n",
      "Epoch 954/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.0901e-04 - val_loss: 6.3267e-04\n",
      "Epoch 955/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0867e-04 - val_loss: 6.3250e-04\n",
      "Epoch 956/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0893e-04 - val_loss: 6.3106e-04\n",
      "Epoch 957/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0912e-04 - val_loss: 6.3274e-04\n",
      "Epoch 958/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0865e-04 - val_loss: 6.3094e-04\n",
      "Epoch 959/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.0823e-04 - val_loss: 6.3379e-04\n",
      "Epoch 960/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0828e-04 - val_loss: 6.3149e-04\n",
      "Epoch 961/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0838e-04 - val_loss: 6.3154e-04\n",
      "Epoch 962/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0831e-04 - val_loss: 6.3546e-04\n",
      "Epoch 963/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0835e-04 - val_loss: 6.3602e-04\n",
      "Epoch 964/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0852e-04 - val_loss: 6.2961e-04\n",
      "Epoch 965/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0910e-04 - val_loss: 6.3365e-04\n",
      "Epoch 966/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0820e-04 - val_loss: 6.3053e-04\n",
      "Epoch 967/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0808e-04 - val_loss: 6.2993e-04\n",
      "Epoch 968/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0818e-04 - val_loss: 6.2914e-04\n",
      "Epoch 969/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0833e-04 - val_loss: 6.3088e-04\n",
      "Epoch 970/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0776e-04 - val_loss: 6.2994e-04\n",
      "Epoch 971/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0783e-04 - val_loss: 6.3051e-04\n",
      "Epoch 972/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0773e-04 - val_loss: 6.2954e-04\n",
      "Epoch 973/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0746e-04 - val_loss: 6.3555e-04\n",
      "Epoch 974/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0781e-04 - val_loss: 6.3565e-04\n",
      "Epoch 975/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0756e-04 - val_loss: 6.3058e-04\n",
      "Epoch 976/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0788e-04 - val_loss: 6.3313e-04\n",
      "Epoch 977/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.0752e-04 - val_loss: 6.3004e-04\n",
      "Epoch 978/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.0723e-04 - val_loss: 6.2843e-04\n",
      "Epoch 979/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0726e-04 - val_loss: 6.2964e-04\n",
      "Epoch 980/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0703e-04 - val_loss: 6.2943e-04\n",
      "Epoch 981/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0739e-04 - val_loss: 6.3348e-04\n",
      "Epoch 982/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0755e-04 - val_loss: 6.3296e-04\n",
      "Epoch 983/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0707e-04 - val_loss: 6.2873e-04\n",
      "Epoch 984/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0716e-04 - val_loss: 6.2814e-04\n",
      "Epoch 985/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0705e-04 - val_loss: 6.3271e-04\n",
      "Epoch 986/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0691e-04 - val_loss: 6.2843e-04\n",
      "Epoch 987/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0706e-04 - val_loss: 6.3394e-04\n",
      "Epoch 988/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0687e-04 - val_loss: 6.2892e-04\n",
      "Epoch 989/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0667e-04 - val_loss: 6.2932e-04\n",
      "Epoch 990/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0698e-04 - val_loss: 6.3064e-04\n",
      "Epoch 991/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.0678e-04 - val_loss: 6.3318e-04\n",
      "Epoch 992/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0646e-04 - val_loss: 6.3123e-04\n",
      "Epoch 993/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0676e-04 - val_loss: 6.2962e-04\n",
      "Epoch 994/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0653e-04 - val_loss: 6.2960e-04\n",
      "Epoch 995/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0627e-04 - val_loss: 6.2660e-04\n",
      "Epoch 996/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.0620e-04 - val_loss: 6.2733e-04\n",
      "Epoch 997/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0606e-04 - val_loss: 6.2631e-04\n",
      "Epoch 998/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0578e-04 - val_loss: 6.2846e-04\n",
      "Epoch 999/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0639e-04 - val_loss: 6.2794e-04\n",
      "Epoch 1000/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0588e-04 - val_loss: 6.2744e-04\n",
      "Epoch 1001/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0582e-04 - val_loss: 6.2589e-04\n",
      "Epoch 1002/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.0599e-04 - val_loss: 6.2596e-04\n",
      "Epoch 1003/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0559e-04 - val_loss: 6.2696e-04\n",
      "Epoch 1004/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0574e-04 - val_loss: 6.3147e-04\n",
      "Epoch 1005/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0567e-04 - val_loss: 6.3013e-04\n",
      "Epoch 1006/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0588e-04 - val_loss: 6.2849e-04\n",
      "Epoch 1007/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0549e-04 - val_loss: 6.2804e-04\n",
      "Epoch 1008/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0548e-04 - val_loss: 6.2644e-04\n",
      "Epoch 1009/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0527e-04 - val_loss: 6.2943e-04\n",
      "Epoch 1010/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0619e-04 - val_loss: 6.2665e-04\n",
      "Epoch 1011/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0567e-04 - val_loss: 6.2683e-04\n",
      "Epoch 1012/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0512e-04 - val_loss: 6.3172e-04\n",
      "Epoch 1013/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0554e-04 - val_loss: 6.2513e-04\n",
      "Epoch 1014/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.0491e-04 - val_loss: 6.2668e-04\n",
      "Epoch 1015/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.0521e-04 - val_loss: 6.2388e-04\n",
      "Epoch 1016/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0481e-04 - val_loss: 6.2477e-04\n",
      "Epoch 1017/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0484e-04 - val_loss: 6.2455e-04\n",
      "Epoch 1018/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0480e-04 - val_loss: 6.2477e-04\n",
      "Epoch 1019/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0490e-04 - val_loss: 6.2317e-04\n",
      "Epoch 1020/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0478e-04 - val_loss: 6.2444e-04\n",
      "Epoch 1021/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0501e-04 - val_loss: 6.2417e-04\n",
      "Epoch 1022/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0470e-04 - val_loss: 6.2922e-04\n",
      "Epoch 1023/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0452e-04 - val_loss: 6.2399e-04\n",
      "Epoch 1024/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0459e-04 - val_loss: 6.2345e-04\n",
      "Epoch 1025/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0425e-04 - val_loss: 6.2311e-04\n",
      "Epoch 1026/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0404e-04 - val_loss: 6.2354e-04\n",
      "Epoch 1027/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0480e-04 - val_loss: 6.2409e-04\n",
      "Epoch 1028/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0419e-04 - val_loss: 6.2384e-04\n",
      "Epoch 1029/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0399e-04 - val_loss: 6.2297e-04\n",
      "Epoch 1030/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0399e-04 - val_loss: 6.2317e-04\n",
      "Epoch 1031/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0400e-04 - val_loss: 6.2439e-04\n",
      "Epoch 1032/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0427e-04 - val_loss: 6.2538e-04\n",
      "Epoch 1033/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.0403e-04 - val_loss: 6.2596e-04\n",
      "Epoch 1034/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0425e-04 - val_loss: 6.2376e-04\n",
      "Epoch 1035/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0464e-04 - val_loss: 6.2251e-04\n",
      "Epoch 1036/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0424e-04 - val_loss: 6.2473e-04\n",
      "Epoch 1037/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0440e-04 - val_loss: 6.2160e-04\n",
      "Epoch 1038/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0366e-04 - val_loss: 6.2115e-04\n",
      "Epoch 1039/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0366e-04 - val_loss: 6.2504e-04\n",
      "Epoch 1040/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0378e-04 - val_loss: 6.2173e-04\n",
      "Epoch 1041/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0332e-04 - val_loss: 6.2568e-04\n",
      "Epoch 1042/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 38us/step - loss: 6.0363e-04 - val_loss: 6.2147e-04\n",
      "Epoch 1043/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0317e-04 - val_loss: 6.2541e-04\n",
      "Epoch 1044/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0328e-04 - val_loss: 6.2211e-04\n",
      "Epoch 1045/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0363e-04 - val_loss: 6.1962e-04\n",
      "Epoch 1046/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0334e-04 - val_loss: 6.2204e-04\n",
      "Epoch 1047/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.0304e-04 - val_loss: 6.2036e-04\n",
      "Epoch 1048/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0352e-04 - val_loss: 6.2180e-04\n",
      "Epoch 1049/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0289e-04 - val_loss: 6.2043e-04\n",
      "Epoch 1050/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0308e-04 - val_loss: 6.2214e-04\n",
      "Epoch 1051/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.0326e-04 - val_loss: 6.1991e-04\n",
      "Epoch 1052/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.0280e-04 - val_loss: 6.2130e-04\n",
      "Epoch 1053/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0312e-04 - val_loss: 6.2060e-04\n",
      "Epoch 1054/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0304e-04 - val_loss: 6.2137e-04\n",
      "Epoch 1055/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0362e-04 - val_loss: 6.1709e-04\n",
      "Epoch 1056/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0310e-04 - val_loss: 6.1828e-04\n",
      "Epoch 1057/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.0278e-04 - val_loss: 6.2036e-04\n",
      "Epoch 1058/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0253e-04 - val_loss: 6.1787e-04\n",
      "Epoch 1059/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0246e-04 - val_loss: 6.2005e-04\n",
      "Epoch 1060/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0249e-04 - val_loss: 6.1977e-04\n",
      "Epoch 1061/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0284e-04 - val_loss: 6.1863e-04\n",
      "Epoch 1062/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0249e-04 - val_loss: 6.1906e-04\n",
      "Epoch 1063/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0265e-04 - val_loss: 6.1841e-04\n",
      "Epoch 1064/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0240e-04 - val_loss: 6.1854e-04\n",
      "Epoch 1065/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.0233e-04 - val_loss: 6.1640e-04\n",
      "Epoch 1066/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0231e-04 - val_loss: 6.1603e-04\n",
      "Epoch 1067/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0245e-04 - val_loss: 6.1558e-04\n",
      "Epoch 1068/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0228e-04 - val_loss: 6.1580e-04\n",
      "Epoch 1069/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0198e-04 - val_loss: 6.1494e-04\n",
      "Epoch 1070/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.0198e-04 - val_loss: 6.1590e-04\n",
      "Epoch 1071/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0199e-04 - val_loss: 6.1597e-04\n",
      "Epoch 1072/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0200e-04 - val_loss: 6.1597e-04\n",
      "Epoch 1073/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0169e-04 - val_loss: 6.1613e-04\n",
      "Epoch 1074/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0181e-04 - val_loss: 6.1388e-04\n",
      "Epoch 1075/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0184e-04 - val_loss: 6.1618e-04\n",
      "Epoch 1076/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0168e-04 - val_loss: 6.1464e-04\n",
      "Epoch 1077/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0171e-04 - val_loss: 6.1324e-04\n",
      "Epoch 1078/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0197e-04 - val_loss: 6.1732e-04\n",
      "Epoch 1079/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0170e-04 - val_loss: 6.1701e-04\n",
      "Epoch 1080/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0157e-04 - val_loss: 6.1428e-04\n",
      "Epoch 1081/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0184e-04 - val_loss: 6.1380e-04\n",
      "Epoch 1082/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0160e-04 - val_loss: 6.1077e-04\n",
      "Epoch 1083/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0128e-04 - val_loss: 6.1081e-04\n",
      "Epoch 1084/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0126e-04 - val_loss: 6.1105e-04\n",
      "Epoch 1085/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.0144e-04 - val_loss: 6.0940e-04\n",
      "Epoch 1086/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0127e-04 - val_loss: 6.0959e-04\n",
      "Epoch 1087/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0117e-04 - val_loss: 6.1153e-04\n",
      "Epoch 1088/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.0117e-04 - val_loss: 6.1748e-04\n",
      "Epoch 1089/10000\n",
      "45507/45507 [==============================] - 1s 23us/step - loss: 6.0116e-04 - val_loss: 6.1216e-04\n",
      "Epoch 1090/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.0084e-04 - val_loss: 6.1364e-04\n",
      "Epoch 1091/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.0076e-04 - val_loss: 6.1381e-04\n",
      "Epoch 1092/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0171e-04 - val_loss: 6.1286e-04\n",
      "Epoch 1093/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0097e-04 - val_loss: 6.1294e-04\n",
      "Epoch 1094/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0067e-04 - val_loss: 6.0721e-04\n",
      "Epoch 1095/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0070e-04 - val_loss: 6.0665e-04\n",
      "Epoch 1096/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0089e-04 - val_loss: 6.1271e-04\n",
      "Epoch 1097/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0094e-04 - val_loss: 6.0979e-04\n",
      "Epoch 1098/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0087e-04 - val_loss: 6.0854e-04\n",
      "Epoch 1099/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0049e-04 - val_loss: 6.1334e-04\n",
      "Epoch 1100/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0032e-04 - val_loss: 6.0426e-04\n",
      "Epoch 1101/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0078e-04 - val_loss: 6.1073e-04\n",
      "Epoch 1102/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0037e-04 - val_loss: 6.0384e-04\n",
      "Epoch 1103/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0028e-04 - val_loss: 6.0857e-04\n",
      "Epoch 1104/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0030e-04 - val_loss: 6.0895e-04\n",
      "Epoch 1105/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9997e-04 - val_loss: 6.0311e-04\n",
      "Epoch 1106/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0067e-04 - val_loss: 6.0595e-04\n",
      "Epoch 1107/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.0022e-04 - val_loss: 6.0633e-04\n",
      "Epoch 1108/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.0012e-04 - val_loss: 6.0561e-04\n",
      "Epoch 1109/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9986e-04 - val_loss: 6.0800e-04\n",
      "Epoch 1110/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9962e-04 - val_loss: 6.0271e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1111/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9983e-04 - val_loss: 6.0240e-04\n",
      "Epoch 1112/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9973e-04 - val_loss: 6.0625e-04\n",
      "Epoch 1113/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9941e-04 - val_loss: 6.0392e-04\n",
      "Epoch 1114/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9990e-04 - val_loss: 6.0501e-04\n",
      "Epoch 1115/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9935e-04 - val_loss: 6.0213e-04\n",
      "Epoch 1116/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9984e-04 - val_loss: 6.0346e-04\n",
      "Epoch 1117/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9935e-04 - val_loss: 6.0549e-04\n",
      "Epoch 1118/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9928e-04 - val_loss: 6.0185e-04\n",
      "Epoch 1119/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0013e-04 - val_loss: 6.0284e-04\n",
      "Epoch 1120/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9943e-04 - val_loss: 6.0250e-04\n",
      "Epoch 1121/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9949e-04 - val_loss: 6.0369e-04\n",
      "Epoch 1122/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9970e-04 - val_loss: 6.0157e-04\n",
      "Epoch 1123/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9912e-04 - val_loss: 5.9923e-04\n",
      "Epoch 1124/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9957e-04 - val_loss: 6.0115e-04\n",
      "Epoch 1125/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9919e-04 - val_loss: 6.0456e-04\n",
      "Epoch 1126/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.9880e-04 - val_loss: 5.9860e-04\n",
      "Epoch 1127/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.9939e-04 - val_loss: 6.0103e-04\n",
      "Epoch 1128/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9913e-04 - val_loss: 6.0248e-04\n",
      "Epoch 1129/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9846e-04 - val_loss: 6.0189e-04\n",
      "Epoch 1130/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9836e-04 - val_loss: 6.0254e-04\n",
      "Epoch 1131/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9844e-04 - val_loss: 6.0023e-04\n",
      "Epoch 1132/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9876e-04 - val_loss: 6.0188e-04\n",
      "Epoch 1133/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9873e-04 - val_loss: 6.0098e-04\n",
      "Epoch 1134/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9867e-04 - val_loss: 6.0135e-04\n",
      "Epoch 1135/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9844e-04 - val_loss: 6.0056e-04\n",
      "Epoch 1136/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9846e-04 - val_loss: 6.0091e-04\n",
      "Epoch 1137/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9850e-04 - val_loss: 6.0007e-04\n",
      "Epoch 1138/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9815e-04 - val_loss: 5.9985e-04\n",
      "Epoch 1139/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9836e-04 - val_loss: 5.9819e-04\n",
      "Epoch 1140/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.9819e-04 - val_loss: 6.0000e-04\n",
      "Epoch 1141/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9838e-04 - val_loss: 5.9908e-04\n",
      "Epoch 1142/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9794e-04 - val_loss: 5.9855e-04\n",
      "Epoch 1143/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9784e-04 - val_loss: 6.0068e-04\n",
      "Epoch 1144/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9791e-04 - val_loss: 5.9692e-04\n",
      "Epoch 1145/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.9832e-04 - val_loss: 6.0050e-04\n",
      "Epoch 1146/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.9772e-04 - val_loss: 5.9627e-04\n",
      "Epoch 1147/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9829e-04 - val_loss: 5.9977e-04\n",
      "Epoch 1148/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9783e-04 - val_loss: 5.9842e-04\n",
      "Epoch 1149/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9764e-04 - val_loss: 5.9559e-04\n",
      "Epoch 1150/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9764e-04 - val_loss: 5.9448e-04\n",
      "Epoch 1151/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9766e-04 - val_loss: 5.9657e-04\n",
      "Epoch 1152/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9715e-04 - val_loss: 5.9596e-04\n",
      "Epoch 1153/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9733e-04 - val_loss: 5.9560e-04\n",
      "Epoch 1154/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9757e-04 - val_loss: 5.9571e-04\n",
      "Epoch 1155/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9727e-04 - val_loss: 5.9610e-04\n",
      "Epoch 1156/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9709e-04 - val_loss: 5.9787e-04\n",
      "Epoch 1157/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9735e-04 - val_loss: 5.9738e-04\n",
      "Epoch 1158/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9702e-04 - val_loss: 5.9517e-04\n",
      "Epoch 1159/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9707e-04 - val_loss: 5.9555e-04\n",
      "Epoch 1160/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9699e-04 - val_loss: 5.9374e-04\n",
      "Epoch 1161/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9701e-04 - val_loss: 5.9436e-04\n",
      "Epoch 1162/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9687e-04 - val_loss: 5.9393e-04\n",
      "Epoch 1163/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9675e-04 - val_loss: 5.9463e-04\n",
      "Epoch 1164/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.9688e-04 - val_loss: 5.9707e-04\n",
      "Epoch 1165/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.9673e-04 - val_loss: 5.9401e-04\n",
      "Epoch 1166/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9698e-04 - val_loss: 5.9360e-04\n",
      "Epoch 1167/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9670e-04 - val_loss: 5.9434e-04\n",
      "Epoch 1168/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9671e-04 - val_loss: 5.9298e-04\n",
      "Epoch 1169/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9692e-04 - val_loss: 5.9603e-04\n",
      "Epoch 1170/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9668e-04 - val_loss: 5.9633e-04\n",
      "Epoch 1171/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9640e-04 - val_loss: 5.9297e-04\n",
      "Epoch 1172/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9650e-04 - val_loss: 5.9461e-04\n",
      "Epoch 1173/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9641e-04 - val_loss: 5.9473e-04\n",
      "Epoch 1174/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9633e-04 - val_loss: 5.9301e-04\n",
      "Epoch 1175/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9628e-04 - val_loss: 5.9446e-04\n",
      "Epoch 1176/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9620e-04 - val_loss: 5.9186e-04\n",
      "Epoch 1177/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9615e-04 - val_loss: 5.9424e-04\n",
      "Epoch 1178/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9615e-04 - val_loss: 5.9293e-04\n",
      "Epoch 1179/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9605e-04 - val_loss: 5.9201e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1180/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9605e-04 - val_loss: 5.9207e-04\n",
      "Epoch 1181/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9588e-04 - val_loss: 5.9116e-04\n",
      "Epoch 1182/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.9610e-04 - val_loss: 5.9247e-04\n",
      "Epoch 1183/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.9597e-04 - val_loss: 5.8989e-04\n",
      "Epoch 1184/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9578e-04 - val_loss: 5.9060e-04\n",
      "Epoch 1185/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9590e-04 - val_loss: 5.9250e-04\n",
      "Epoch 1186/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9585e-04 - val_loss: 5.9067e-04\n",
      "Epoch 1187/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9569e-04 - val_loss: 5.9133e-04\n",
      "Epoch 1188/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9571e-04 - val_loss: 5.9046e-04\n",
      "Epoch 1189/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9578e-04 - val_loss: 5.9359e-04\n",
      "Epoch 1190/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9559e-04 - val_loss: 5.9042e-04\n",
      "Epoch 1191/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9568e-04 - val_loss: 5.8991e-04\n",
      "Epoch 1192/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9533e-04 - val_loss: 5.9011e-04\n",
      "Epoch 1193/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9536e-04 - val_loss: 5.8975e-04\n",
      "Epoch 1194/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9521e-04 - val_loss: 5.8868e-04\n",
      "Epoch 1195/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9526e-04 - val_loss: 5.9173e-04\n",
      "Epoch 1196/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9536e-04 - val_loss: 5.8896e-04\n",
      "Epoch 1197/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9526e-04 - val_loss: 5.9019e-04\n",
      "Epoch 1198/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9519e-04 - val_loss: 5.8914e-04\n",
      "Epoch 1199/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9522e-04 - val_loss: 5.8895e-04\n",
      "Epoch 1200/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9516e-04 - val_loss: 5.9144e-04\n",
      "Epoch 1201/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.9525e-04 - val_loss: 5.8772e-04\n",
      "Epoch 1202/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9514e-04 - val_loss: 5.9069e-04\n",
      "Epoch 1203/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9486e-04 - val_loss: 5.8984e-04\n",
      "Epoch 1204/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9486e-04 - val_loss: 5.8726e-04\n",
      "Epoch 1205/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9497e-04 - val_loss: 5.9210e-04\n",
      "Epoch 1206/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9486e-04 - val_loss: 5.9094e-04\n",
      "Epoch 1207/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9475e-04 - val_loss: 5.8941e-04\n",
      "Epoch 1208/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9483e-04 - val_loss: 5.8973e-04\n",
      "Epoch 1209/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9464e-04 - val_loss: 5.8777e-04\n",
      "Epoch 1210/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9454e-04 - val_loss: 5.8828e-04\n",
      "Epoch 1211/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9462e-04 - val_loss: 5.8608e-04\n",
      "Epoch 1212/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9438e-04 - val_loss: 5.8618e-04\n",
      "Epoch 1213/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9444e-04 - val_loss: 5.8841e-04\n",
      "Epoch 1214/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9431e-04 - val_loss: 5.8722e-04\n",
      "Epoch 1215/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.9455e-04 - val_loss: 5.8662e-04\n",
      "Epoch 1216/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9451e-04 - val_loss: 5.8671e-04\n",
      "Epoch 1217/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9424e-04 - val_loss: 5.8582e-04\n",
      "Epoch 1218/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9423e-04 - val_loss: 5.8658e-04\n",
      "Epoch 1219/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9426e-04 - val_loss: 5.8569e-04\n",
      "Epoch 1220/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.9415e-04 - val_loss: 5.8653e-04\n",
      "Epoch 1221/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9406e-04 - val_loss: 5.8845e-04\n",
      "Epoch 1222/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.9402e-04 - val_loss: 5.8751e-04\n",
      "Epoch 1223/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9414e-04 - val_loss: 5.8792e-04\n",
      "Epoch 1224/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9388e-04 - val_loss: 5.8616e-04\n",
      "Epoch 1225/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9407e-04 - val_loss: 5.8640e-04\n",
      "Epoch 1226/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9379e-04 - val_loss: 5.8527e-04\n",
      "Epoch 1227/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9400e-04 - val_loss: 5.8581e-04\n",
      "Epoch 1228/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9365e-04 - val_loss: 5.8510e-04\n",
      "Epoch 1229/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9372e-04 - val_loss: 5.8622e-04\n",
      "Epoch 1230/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9368e-04 - val_loss: 5.8463e-04\n",
      "Epoch 1231/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9357e-04 - val_loss: 5.8498e-04\n",
      "Epoch 1232/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9351e-04 - val_loss: 5.8423e-04\n",
      "Epoch 1233/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9386e-04 - val_loss: 5.8425e-04\n",
      "Epoch 1234/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.9356e-04 - val_loss: 5.8623e-04\n",
      "Epoch 1235/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9349e-04 - val_loss: 5.8451e-04\n",
      "Epoch 1236/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9338e-04 - val_loss: 5.8528e-04\n",
      "Epoch 1237/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9345e-04 - val_loss: 5.8317e-04\n",
      "Epoch 1238/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.9348e-04 - val_loss: 5.8421e-04\n",
      "Epoch 1239/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.9340e-04 - val_loss: 5.8280e-04\n",
      "Epoch 1240/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9328e-04 - val_loss: 5.8392e-04\n",
      "Epoch 1241/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9314e-04 - val_loss: 5.8584e-04\n",
      "Epoch 1242/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9336e-04 - val_loss: 5.8257e-04\n",
      "Epoch 1243/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9333e-04 - val_loss: 5.8318e-04\n",
      "Epoch 1244/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9315e-04 - val_loss: 5.8350e-04\n",
      "Epoch 1245/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9305e-04 - val_loss: 5.8270e-04\n",
      "Epoch 1246/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9276e-04 - val_loss: 5.8294e-04\n",
      "Epoch 1247/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9285e-04 - val_loss: 5.8234e-04\n",
      "Epoch 1248/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9300e-04 - val_loss: 5.8380e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1249/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9264e-04 - val_loss: 5.8284e-04\n",
      "Epoch 1250/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9286e-04 - val_loss: 5.8355e-04\n",
      "Epoch 1251/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9261e-04 - val_loss: 5.8253e-04\n",
      "Epoch 1252/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9254e-04 - val_loss: 5.8203e-04\n",
      "Epoch 1253/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.9278e-04 - val_loss: 5.8123e-04\n",
      "Epoch 1254/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.9279e-04 - val_loss: 5.8168e-04\n",
      "Epoch 1255/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9266e-04 - val_loss: 5.8277e-04\n",
      "Epoch 1256/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9245e-04 - val_loss: 5.8134e-04\n",
      "Epoch 1257/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9274e-04 - val_loss: 5.8059e-04\n",
      "Epoch 1258/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.9257e-04 - val_loss: 5.8135e-04\n",
      "Epoch 1259/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.9248e-04 - val_loss: 5.8210e-04\n",
      "Epoch 1260/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9220e-04 - val_loss: 5.8245e-04\n",
      "Epoch 1261/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9257e-04 - val_loss: 5.8208e-04\n",
      "Epoch 1262/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9227e-04 - val_loss: 5.8197e-04\n",
      "Epoch 1263/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9221e-04 - val_loss: 5.8070e-04\n",
      "Epoch 1264/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9208e-04 - val_loss: 5.8147e-04\n",
      "Epoch 1265/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9201e-04 - val_loss: 5.8045e-04\n",
      "Epoch 1266/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9239e-04 - val_loss: 5.8077e-04\n",
      "Epoch 1267/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9252e-04 - val_loss: 5.8217e-04\n",
      "Epoch 1268/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9216e-04 - val_loss: 5.8101e-04\n",
      "Epoch 1269/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9207e-04 - val_loss: 5.7942e-04\n",
      "Epoch 1270/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9208e-04 - val_loss: 5.7975e-04\n",
      "Epoch 1271/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9219e-04 - val_loss: 5.7974e-04\n",
      "Epoch 1272/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9198e-04 - val_loss: 5.8163e-04\n",
      "Epoch 1273/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9170e-04 - val_loss: 5.7969e-04\n",
      "Epoch 1274/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9184e-04 - val_loss: 5.8096e-04\n",
      "Epoch 1275/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9198e-04 - val_loss: 5.8007e-04\n",
      "Epoch 1276/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.9178e-04 - val_loss: 5.7853e-04\n",
      "Epoch 1277/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9195e-04 - val_loss: 5.7938e-04\n",
      "Epoch 1278/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9176e-04 - val_loss: 5.8016e-04\n",
      "Epoch 1279/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9181e-04 - val_loss: 5.7783e-04\n",
      "Epoch 1280/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9172e-04 - val_loss: 5.7891e-04\n",
      "Epoch 1281/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9170e-04 - val_loss: 5.7728e-04\n",
      "Epoch 1282/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9145e-04 - val_loss: 5.7700e-04\n",
      "Epoch 1283/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.9147e-04 - val_loss: 5.7538e-04\n",
      "Epoch 1284/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9135e-04 - val_loss: 5.7534e-04\n",
      "Epoch 1285/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9136e-04 - val_loss: 5.7492e-04\n",
      "Epoch 1286/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9124e-04 - val_loss: 5.7455e-04\n",
      "Epoch 1287/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9114e-04 - val_loss: 5.7419e-04\n",
      "Epoch 1288/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9116e-04 - val_loss: 5.7598e-04\n",
      "Epoch 1289/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9129e-04 - val_loss: 5.7592e-04\n",
      "Epoch 1290/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.9104e-04 - val_loss: 5.7587e-04\n",
      "Epoch 1291/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9093e-04 - val_loss: 5.7474e-04\n",
      "Epoch 1292/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9083e-04 - val_loss: 5.7473e-04\n",
      "Epoch 1293/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9077e-04 - val_loss: 5.7365e-04\n",
      "Epoch 1294/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9101e-04 - val_loss: 5.7410e-04\n",
      "Epoch 1295/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.9085e-04 - val_loss: 5.7454e-04\n",
      "Epoch 1296/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9078e-04 - val_loss: 5.7445e-04\n",
      "Epoch 1297/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9067e-04 - val_loss: 5.7433e-04\n",
      "Epoch 1298/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9063e-04 - val_loss: 5.7410e-04\n",
      "Epoch 1299/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9065e-04 - val_loss: 5.7421e-04\n",
      "Epoch 1300/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9071e-04 - val_loss: 5.7409e-04\n",
      "Epoch 1301/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9070e-04 - val_loss: 5.7394e-04\n",
      "Epoch 1302/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9046e-04 - val_loss: 5.7421e-04\n",
      "Epoch 1303/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9047e-04 - val_loss: 5.7359e-04\n",
      "Epoch 1304/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9030e-04 - val_loss: 5.7347e-04\n",
      "Epoch 1305/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9032e-04 - val_loss: 5.7303e-04\n",
      "Epoch 1306/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9030e-04 - val_loss: 5.7342e-04\n",
      "Epoch 1307/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9048e-04 - val_loss: 5.7492e-04\n",
      "Epoch 1308/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9033e-04 - val_loss: 5.7495e-04\n",
      "Epoch 1309/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9010e-04 - val_loss: 5.7434e-04\n",
      "Epoch 1310/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9039e-04 - val_loss: 5.7405e-04\n",
      "Epoch 1311/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9023e-04 - val_loss: 5.7376e-04\n",
      "Epoch 1312/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9003e-04 - val_loss: 5.7314e-04\n",
      "Epoch 1313/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.9024e-04 - val_loss: 5.7237e-04\n",
      "Epoch 1314/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9006e-04 - val_loss: 5.7349e-04\n",
      "Epoch 1315/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.9010e-04 - val_loss: 5.7325e-04\n",
      "Epoch 1316/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8987e-04 - val_loss: 5.7301e-04\n",
      "Epoch 1317/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8983e-04 - val_loss: 5.7362e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1318/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8975e-04 - val_loss: 5.7283e-04\n",
      "Epoch 1319/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8990e-04 - val_loss: 5.7213e-04\n",
      "Epoch 1320/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8984e-04 - val_loss: 5.7399e-04\n",
      "Epoch 1321/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8963e-04 - val_loss: 5.7352e-04\n",
      "Epoch 1322/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8963e-04 - val_loss: 5.7284e-04\n",
      "Epoch 1323/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9004e-04 - val_loss: 5.7200e-04\n",
      "Epoch 1324/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8950e-04 - val_loss: 5.7262e-04\n",
      "Epoch 1325/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8969e-04 - val_loss: 5.7290e-04\n",
      "Epoch 1326/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8932e-04 - val_loss: 5.7224e-04\n",
      "Epoch 1327/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8981e-04 - val_loss: 5.7194e-04\n",
      "Epoch 1328/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8937e-04 - val_loss: 5.7212e-04\n",
      "Epoch 1329/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8942e-04 - val_loss: 5.7281e-04\n",
      "Epoch 1330/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8928e-04 - val_loss: 5.7192e-04\n",
      "Epoch 1331/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8928e-04 - val_loss: 5.7245e-04\n",
      "Epoch 1332/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.8918e-04 - val_loss: 5.7174e-04\n",
      "Epoch 1333/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.8949e-04 - val_loss: 5.7182e-04\n",
      "Epoch 1334/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8932e-04 - val_loss: 5.7197e-04\n",
      "Epoch 1335/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8911e-04 - val_loss: 5.7167e-04\n",
      "Epoch 1336/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.8910e-04 - val_loss: 5.7082e-04\n",
      "Epoch 1337/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8907e-04 - val_loss: 5.7172e-04\n",
      "Epoch 1338/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8892e-04 - val_loss: 5.7114e-04\n",
      "Epoch 1339/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8920e-04 - val_loss: 5.7092e-04\n",
      "Epoch 1340/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8895e-04 - val_loss: 5.7107e-04\n",
      "Epoch 1341/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8890e-04 - val_loss: 5.7075e-04\n",
      "Epoch 1342/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8877e-04 - val_loss: 5.7126e-04\n",
      "Epoch 1343/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8869e-04 - val_loss: 5.7144e-04\n",
      "Epoch 1344/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8876e-04 - val_loss: 5.7022e-04\n",
      "Epoch 1345/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8873e-04 - val_loss: 5.7012e-04\n",
      "Epoch 1346/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8869e-04 - val_loss: 5.7056e-04\n",
      "Epoch 1347/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8866e-04 - val_loss: 5.6986e-04\n",
      "Epoch 1348/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8852e-04 - val_loss: 5.7150e-04\n",
      "Epoch 1349/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8884e-04 - val_loss: 5.6955e-04\n",
      "Epoch 1350/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8866e-04 - val_loss: 5.6983e-04\n",
      "Epoch 1351/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.8859e-04 - val_loss: 5.6973e-04\n",
      "Epoch 1352/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.8857e-04 - val_loss: 5.6957e-04\n",
      "Epoch 1353/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8839e-04 - val_loss: 5.7006e-04\n",
      "Epoch 1354/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8872e-04 - val_loss: 5.6922e-04\n",
      "Epoch 1355/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8870e-04 - val_loss: 5.6898e-04\n",
      "Epoch 1356/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8840e-04 - val_loss: 5.6877e-04\n",
      "Epoch 1357/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8826e-04 - val_loss: 5.7014e-04\n",
      "Epoch 1358/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8864e-04 - val_loss: 5.6910e-04\n",
      "Epoch 1359/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8823e-04 - val_loss: 5.6957e-04\n",
      "Epoch 1360/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8806e-04 - val_loss: 5.6933e-04\n",
      "Epoch 1361/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8807e-04 - val_loss: 5.6919e-04\n",
      "Epoch 1362/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8827e-04 - val_loss: 5.6882e-04\n",
      "Epoch 1363/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8795e-04 - val_loss: 5.6932e-04\n",
      "Epoch 1364/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8803e-04 - val_loss: 5.6926e-04\n",
      "Epoch 1365/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.8790e-04 - val_loss: 5.6929e-04\n",
      "Epoch 1366/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8774e-04 - val_loss: 5.6861e-04\n",
      "Epoch 1367/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8808e-04 - val_loss: 5.6855e-04\n",
      "Epoch 1368/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8781e-04 - val_loss: 5.6844e-04\n",
      "Epoch 1369/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8768e-04 - val_loss: 5.6902e-04\n",
      "Epoch 1370/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8783e-04 - val_loss: 5.6809e-04\n",
      "Epoch 1371/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8789e-04 - val_loss: 5.6790e-04\n",
      "Epoch 1372/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8764e-04 - val_loss: 5.6902e-04\n",
      "Epoch 1373/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8793e-04 - val_loss: 5.6816e-04\n",
      "Epoch 1374/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8758e-04 - val_loss: 5.6845e-04\n",
      "Epoch 1375/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8751e-04 - val_loss: 5.6765e-04\n",
      "Epoch 1376/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8767e-04 - val_loss: 5.6766e-04\n",
      "Epoch 1377/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8762e-04 - val_loss: 5.6842e-04\n",
      "Epoch 1378/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8753e-04 - val_loss: 5.6948e-04\n",
      "Epoch 1379/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8731e-04 - val_loss: 5.6784e-04\n",
      "Epoch 1380/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8728e-04 - val_loss: 5.6762e-04\n",
      "Epoch 1381/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8740e-04 - val_loss: 5.6747e-04\n",
      "Epoch 1382/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8754e-04 - val_loss: 5.6742e-04\n",
      "Epoch 1383/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.8731e-04 - val_loss: 5.6824e-04\n",
      "Epoch 1384/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8748e-04 - val_loss: 5.6668e-04\n",
      "Epoch 1385/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8719e-04 - val_loss: 5.6716e-04\n",
      "Epoch 1386/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8715e-04 - val_loss: 5.6709e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1387/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8721e-04 - val_loss: 5.6663e-04\n",
      "Epoch 1388/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.8727e-04 - val_loss: 5.6723e-04\n",
      "Epoch 1389/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.8716e-04 - val_loss: 5.6718e-04\n",
      "Epoch 1390/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8709e-04 - val_loss: 5.6657e-04\n",
      "Epoch 1391/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8696e-04 - val_loss: 5.6660e-04\n",
      "Epoch 1392/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8717e-04 - val_loss: 5.6637e-04\n",
      "Epoch 1393/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8696e-04 - val_loss: 5.6597e-04\n",
      "Epoch 1394/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8672e-04 - val_loss: 5.6692e-04\n",
      "Epoch 1395/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8699e-04 - val_loss: 5.6607e-04\n",
      "Epoch 1396/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.8687e-04 - val_loss: 5.6627e-04\n",
      "Epoch 1397/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8672e-04 - val_loss: 5.6641e-04\n",
      "Epoch 1398/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8692e-04 - val_loss: 5.6563e-04\n",
      "Epoch 1399/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8667e-04 - val_loss: 5.6549e-04\n",
      "Epoch 1400/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8694e-04 - val_loss: 5.6579e-04\n",
      "Epoch 1401/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8674e-04 - val_loss: 5.6604e-04\n",
      "Epoch 1402/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8654e-04 - val_loss: 5.6518e-04\n",
      "Epoch 1403/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8646e-04 - val_loss: 5.6547e-04\n",
      "Epoch 1404/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8654e-04 - val_loss: 5.6577e-04\n",
      "Epoch 1405/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8657e-04 - val_loss: 5.6486e-04\n",
      "Epoch 1406/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.8658e-04 - val_loss: 5.6516e-04\n",
      "Epoch 1407/10000\n",
      "45507/45507 [==============================] - 1s 23us/step - loss: 5.8649e-04 - val_loss: 5.6422e-04\n",
      "Epoch 1408/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.8627e-04 - val_loss: 5.6507e-04\n",
      "Epoch 1409/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8659e-04 - val_loss: 5.6471e-04\n",
      "Epoch 1410/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8638e-04 - val_loss: 5.6497e-04\n",
      "Epoch 1411/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8625e-04 - val_loss: 5.6484e-04\n",
      "Epoch 1412/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8628e-04 - val_loss: 5.6457e-04\n",
      "Epoch 1413/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8632e-04 - val_loss: 5.6474e-04\n",
      "Epoch 1414/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.8617e-04 - val_loss: 5.6464e-04\n",
      "Epoch 1415/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8599e-04 - val_loss: 5.6416e-04\n",
      "Epoch 1416/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8611e-04 - val_loss: 5.6413e-04\n",
      "Epoch 1417/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8612e-04 - val_loss: 5.6386e-04\n",
      "Epoch 1418/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8614e-04 - val_loss: 5.6332e-04\n",
      "Epoch 1419/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8596e-04 - val_loss: 5.6364e-04\n",
      "Epoch 1420/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8598e-04 - val_loss: 5.6384e-04\n",
      "Epoch 1421/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8591e-04 - val_loss: 5.6380e-04\n",
      "Epoch 1422/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8596e-04 - val_loss: 5.6357e-04\n",
      "Epoch 1423/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8575e-04 - val_loss: 5.6320e-04\n",
      "Epoch 1424/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8594e-04 - val_loss: 5.6321e-04\n",
      "Epoch 1425/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.8574e-04 - val_loss: 5.6348e-04\n",
      "Epoch 1426/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.8592e-04 - val_loss: 5.6333e-04\n",
      "Epoch 1427/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8589e-04 - val_loss: 5.6303e-04\n",
      "Epoch 1428/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8555e-04 - val_loss: 5.6281e-04\n",
      "Epoch 1429/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8586e-04 - val_loss: 5.6214e-04\n",
      "Epoch 1430/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8551e-04 - val_loss: 5.6216e-04\n",
      "Epoch 1431/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8560e-04 - val_loss: 5.6238e-04\n",
      "Epoch 1432/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8566e-04 - val_loss: 5.6254e-04\n",
      "Epoch 1433/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8543e-04 - val_loss: 5.6228e-04\n",
      "Epoch 1434/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8550e-04 - val_loss: 5.6203e-04\n",
      "Epoch 1435/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8565e-04 - val_loss: 5.6261e-04\n",
      "Epoch 1436/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8545e-04 - val_loss: 5.6231e-04\n",
      "Epoch 1437/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8546e-04 - val_loss: 5.6175e-04\n",
      "Epoch 1438/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8546e-04 - val_loss: 5.6204e-04\n",
      "Epoch 1439/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8539e-04 - val_loss: 5.6193e-04\n",
      "Epoch 1440/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.8522e-04 - val_loss: 5.6178e-04\n",
      "Epoch 1441/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8529e-04 - val_loss: 5.6164e-04\n",
      "Epoch 1442/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8530e-04 - val_loss: 5.6170e-04\n",
      "Epoch 1443/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8518e-04 - val_loss: 5.6142e-04\n",
      "Epoch 1444/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.8512e-04 - val_loss: 5.6193e-04\n",
      "Epoch 1445/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8510e-04 - val_loss: 5.6141e-04\n",
      "Epoch 1446/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8504e-04 - val_loss: 5.6140e-04\n",
      "Epoch 1447/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8501e-04 - val_loss: 5.6130e-04\n",
      "Epoch 1448/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8522e-04 - val_loss: 5.6129e-04\n",
      "Epoch 1449/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8517e-04 - val_loss: 5.6048e-04\n",
      "Epoch 1450/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8501e-04 - val_loss: 5.6126e-04\n",
      "Epoch 1451/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8493e-04 - val_loss: 5.6111e-04\n",
      "Epoch 1452/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8489e-04 - val_loss: 5.6097e-04\n",
      "Epoch 1453/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8505e-04 - val_loss: 5.6018e-04\n",
      "Epoch 1454/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8483e-04 - val_loss: 5.6073e-04\n",
      "Epoch 1455/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8468e-04 - val_loss: 5.6079e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1456/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8486e-04 - val_loss: 5.6058e-04\n",
      "Epoch 1457/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8491e-04 - val_loss: 5.6056e-04\n",
      "Epoch 1458/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8492e-04 - val_loss: 5.6032e-04\n",
      "Epoch 1459/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8472e-04 - val_loss: 5.6076e-04\n",
      "Epoch 1460/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8471e-04 - val_loss: 5.6079e-04\n",
      "Epoch 1461/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8471e-04 - val_loss: 5.6083e-04\n",
      "Epoch 1462/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8453e-04 - val_loss: 5.6041e-04\n",
      "Epoch 1463/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.8473e-04 - val_loss: 5.6173e-04\n",
      "Epoch 1464/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8461e-04 - val_loss: 5.6106e-04\n",
      "Epoch 1465/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8441e-04 - val_loss: 5.6031e-04\n",
      "Epoch 1466/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8453e-04 - val_loss: 5.6099e-04\n",
      "Epoch 1467/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8444e-04 - val_loss: 5.6058e-04\n",
      "Epoch 1468/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8438e-04 - val_loss: 5.6015e-04\n",
      "Epoch 1469/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8427e-04 - val_loss: 5.5959e-04\n",
      "Epoch 1470/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8425e-04 - val_loss: 5.5966e-04\n",
      "Epoch 1471/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8424e-04 - val_loss: 5.5964e-04\n",
      "Epoch 1472/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.8416e-04 - val_loss: 5.5933e-04\n",
      "Epoch 1473/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8432e-04 - val_loss: 5.5981e-04\n",
      "Epoch 1474/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8421e-04 - val_loss: 5.6003e-04\n",
      "Epoch 1475/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8421e-04 - val_loss: 5.5984e-04\n",
      "Epoch 1476/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8403e-04 - val_loss: 5.5934e-04\n",
      "Epoch 1477/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.8396e-04 - val_loss: 5.5933e-04\n",
      "Epoch 1478/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8399e-04 - val_loss: 5.5927e-04\n",
      "Epoch 1479/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8391e-04 - val_loss: 5.5937e-04\n",
      "Epoch 1480/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8403e-04 - val_loss: 5.5932e-04\n",
      "Epoch 1481/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8396e-04 - val_loss: 5.5863e-04\n",
      "Epoch 1482/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.8379e-04 - val_loss: 5.5878e-04\n",
      "Epoch 1483/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8388e-04 - val_loss: 5.5820e-04\n",
      "Epoch 1484/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8379e-04 - val_loss: 5.5853e-04\n",
      "Epoch 1485/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8377e-04 - val_loss: 5.5814e-04\n",
      "Epoch 1486/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8390e-04 - val_loss: 5.5828e-04\n",
      "Epoch 1487/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8386e-04 - val_loss: 5.5817e-04\n",
      "Epoch 1488/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8376e-04 - val_loss: 5.5847e-04\n",
      "Epoch 1489/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8358e-04 - val_loss: 5.5856e-04\n",
      "Epoch 1490/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8362e-04 - val_loss: 5.5839e-04\n",
      "Epoch 1491/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8354e-04 - val_loss: 5.5834e-04\n",
      "Epoch 1492/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8352e-04 - val_loss: 5.5812e-04\n",
      "Epoch 1493/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8354e-04 - val_loss: 5.5758e-04\n",
      "Epoch 1494/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8357e-04 - val_loss: 5.5763e-04\n",
      "Epoch 1495/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8350e-04 - val_loss: 5.5802e-04\n",
      "Epoch 1496/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8336e-04 - val_loss: 5.5758e-04\n",
      "Epoch 1497/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8347e-04 - val_loss: 5.5841e-04\n",
      "Epoch 1498/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8355e-04 - val_loss: 5.5808e-04\n",
      "Epoch 1499/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8338e-04 - val_loss: 5.5793e-04\n",
      "Epoch 1500/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.8342e-04 - val_loss: 5.5792e-04\n",
      "Epoch 1501/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.8310e-04 - val_loss: 5.5806e-04\n",
      "Epoch 1502/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8334e-04 - val_loss: 5.5788e-04\n",
      "Epoch 1503/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8327e-04 - val_loss: 5.5755e-04\n",
      "Epoch 1504/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.8332e-04 - val_loss: 5.5704e-04\n",
      "Epoch 1505/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8314e-04 - val_loss: 5.5736e-04\n",
      "Epoch 1506/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8307e-04 - val_loss: 5.5680e-04\n",
      "Epoch 1507/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8339e-04 - val_loss: 5.5738e-04\n",
      "Epoch 1508/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8317e-04 - val_loss: 5.5675e-04\n",
      "Epoch 1509/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8323e-04 - val_loss: 5.5717e-04\n",
      "Epoch 1510/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8316e-04 - val_loss: 5.5743e-04\n",
      "Epoch 1511/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8287e-04 - val_loss: 5.5683e-04\n",
      "Epoch 1512/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8294e-04 - val_loss: 5.5737e-04\n",
      "Epoch 1513/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8298e-04 - val_loss: 5.5691e-04\n",
      "Epoch 1514/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8288e-04 - val_loss: 5.5701e-04\n",
      "Epoch 1515/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.8273e-04 - val_loss: 5.5663e-04\n",
      "Epoch 1516/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8295e-04 - val_loss: 5.5704e-04\n",
      "Epoch 1517/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8269e-04 - val_loss: 5.5742e-04\n",
      "Epoch 1518/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8278e-04 - val_loss: 5.5647e-04\n",
      "Epoch 1519/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.8275e-04 - val_loss: 5.5647e-04\n",
      "Epoch 1520/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8259e-04 - val_loss: 5.5603e-04\n",
      "Epoch 1521/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8290e-04 - val_loss: 5.5704e-04\n",
      "Epoch 1522/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8277e-04 - val_loss: 5.5682e-04\n",
      "Epoch 1523/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8261e-04 - val_loss: 5.5619e-04\n",
      "Epoch 1524/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8281e-04 - val_loss: 5.5682e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1525/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8266e-04 - val_loss: 5.5634e-04\n",
      "Epoch 1526/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8254e-04 - val_loss: 5.5598e-04\n",
      "Epoch 1527/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8267e-04 - val_loss: 5.5668e-04\n",
      "Epoch 1528/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8258e-04 - val_loss: 5.5654e-04\n",
      "Epoch 1529/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8246e-04 - val_loss: 5.5576e-04\n",
      "Epoch 1530/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8251e-04 - val_loss: 5.5677e-04\n",
      "Epoch 1531/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8237e-04 - val_loss: 5.5582e-04\n",
      "Epoch 1532/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8227e-04 - val_loss: 5.5554e-04\n",
      "Epoch 1533/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8233e-04 - val_loss: 5.5539e-04\n",
      "Epoch 1534/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8242e-04 - val_loss: 5.5653e-04\n",
      "Epoch 1535/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8226e-04 - val_loss: 5.5572e-04\n",
      "Epoch 1536/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8221e-04 - val_loss: 5.5556e-04\n",
      "Epoch 1537/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8230e-04 - val_loss: 5.5650e-04\n",
      "Epoch 1538/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.8213e-04 - val_loss: 5.5532e-04\n",
      "Epoch 1539/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.8205e-04 - val_loss: 5.5553e-04\n",
      "Epoch 1540/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.8217e-04 - val_loss: 5.5578e-04\n",
      "Epoch 1541/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8214e-04 - val_loss: 5.5519e-04\n",
      "Epoch 1542/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8214e-04 - val_loss: 5.5575e-04\n",
      "Epoch 1543/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8204e-04 - val_loss: 5.5564e-04\n",
      "Epoch 1544/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8198e-04 - val_loss: 5.5569e-04\n",
      "Epoch 1545/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8209e-04 - val_loss: 5.5661e-04\n",
      "Epoch 1546/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8193e-04 - val_loss: 5.5492e-04\n",
      "Epoch 1547/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8188e-04 - val_loss: 5.5490e-04\n",
      "Epoch 1548/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8188e-04 - val_loss: 5.5526e-04\n",
      "Epoch 1549/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8198e-04 - val_loss: 5.5711e-04\n",
      "Epoch 1550/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8193e-04 - val_loss: 5.5547e-04\n",
      "Epoch 1551/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8180e-04 - val_loss: 5.5634e-04\n",
      "Epoch 1552/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.8182e-04 - val_loss: 5.5621e-04\n",
      "Epoch 1553/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8183e-04 - val_loss: 5.5507e-04\n",
      "Epoch 1554/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8178e-04 - val_loss: 5.5488e-04\n",
      "Epoch 1555/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8170e-04 - val_loss: 5.5492e-04\n",
      "Epoch 1556/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8170e-04 - val_loss: 5.5540e-04\n",
      "Epoch 1557/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.8163e-04 - val_loss: 5.5512e-04\n",
      "Epoch 1558/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8164e-04 - val_loss: 5.5467e-04\n",
      "Epoch 1559/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8158e-04 - val_loss: 5.5491e-04\n",
      "Epoch 1560/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8152e-04 - val_loss: 5.5517e-04\n",
      "Epoch 1561/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8159e-04 - val_loss: 5.5456e-04\n",
      "Epoch 1562/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8148e-04 - val_loss: 5.5527e-04\n",
      "Epoch 1563/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8142e-04 - val_loss: 5.5476e-04\n",
      "Epoch 1564/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8142e-04 - val_loss: 5.5557e-04\n",
      "Epoch 1565/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8160e-04 - val_loss: 5.5582e-04\n",
      "Epoch 1566/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8143e-04 - val_loss: 5.5490e-04\n",
      "Epoch 1567/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8131e-04 - val_loss: 5.5416e-04\n",
      "Epoch 1568/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8139e-04 - val_loss: 5.5506e-04\n",
      "Epoch 1569/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8130e-04 - val_loss: 5.5438e-04\n",
      "Epoch 1570/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8129e-04 - val_loss: 5.5437e-04\n",
      "Epoch 1571/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8123e-04 - val_loss: 5.5396e-04\n",
      "Epoch 1572/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8129e-04 - val_loss: 5.5431e-04\n",
      "Epoch 1573/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8123e-04 - val_loss: 5.5543e-04\n",
      "Epoch 1574/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8116e-04 - val_loss: 5.5437e-04\n",
      "Epoch 1575/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.8107e-04 - val_loss: 5.5374e-04\n",
      "Epoch 1576/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.8106e-04 - val_loss: 5.5443e-04\n",
      "Epoch 1577/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.8101e-04 - val_loss: 5.5385e-04\n",
      "Epoch 1578/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8100e-04 - val_loss: 5.5463e-04\n",
      "Epoch 1579/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8097e-04 - val_loss: 5.5355e-04\n",
      "Epoch 1580/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8095e-04 - val_loss: 5.5397e-04\n",
      "Epoch 1581/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8089e-04 - val_loss: 5.5454e-04\n",
      "Epoch 1582/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8094e-04 - val_loss: 5.5340e-04\n",
      "Epoch 1583/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8087e-04 - val_loss: 5.5366e-04\n",
      "Epoch 1584/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8082e-04 - val_loss: 5.5444e-04\n",
      "Epoch 1585/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8090e-04 - val_loss: 5.5509e-04\n",
      "Epoch 1586/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8078e-04 - val_loss: 5.5446e-04\n",
      "Epoch 1587/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8077e-04 - val_loss: 5.5392e-04\n",
      "Epoch 1588/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8076e-04 - val_loss: 5.5350e-04\n",
      "Epoch 1589/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8067e-04 - val_loss: 5.5390e-04\n",
      "Epoch 1590/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.8072e-04 - val_loss: 5.5470e-04\n",
      "Epoch 1591/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.8072e-04 - val_loss: 5.5415e-04\n",
      "Epoch 1592/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8071e-04 - val_loss: 5.5323e-04\n",
      "Epoch 1593/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8058e-04 - val_loss: 5.5365e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1594/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8057e-04 - val_loss: 5.5362e-04\n",
      "Epoch 1595/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.8063e-04 - val_loss: 5.5334e-04\n",
      "Epoch 1596/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8044e-04 - val_loss: 5.5359e-04\n",
      "Epoch 1597/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8056e-04 - val_loss: 5.5344e-04\n",
      "Epoch 1598/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.8041e-04 - val_loss: 5.5353e-04\n",
      "Epoch 1599/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8041e-04 - val_loss: 5.5345e-04\n",
      "Epoch 1600/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8029e-04 - val_loss: 5.5296e-04\n",
      "Epoch 1601/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8032e-04 - val_loss: 5.5354e-04\n",
      "Epoch 1602/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8030e-04 - val_loss: 5.5321e-04\n",
      "Epoch 1603/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8031e-04 - val_loss: 5.5374e-04\n",
      "Epoch 1604/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8041e-04 - val_loss: 5.5425e-04\n",
      "Epoch 1605/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8040e-04 - val_loss: 5.5386e-04\n",
      "Epoch 1606/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8025e-04 - val_loss: 5.5296e-04\n",
      "Epoch 1607/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8017e-04 - val_loss: 5.5338e-04\n",
      "Epoch 1608/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8013e-04 - val_loss: 5.5331e-04\n",
      "Epoch 1609/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8011e-04 - val_loss: 5.5391e-04\n",
      "Epoch 1610/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8026e-04 - val_loss: 5.5341e-04\n",
      "Epoch 1611/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.8008e-04 - val_loss: 5.5303e-04\n",
      "Epoch 1612/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8005e-04 - val_loss: 5.5336e-04\n",
      "Epoch 1613/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7998e-04 - val_loss: 5.5345e-04\n",
      "Epoch 1614/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7996e-04 - val_loss: 5.5325e-04\n",
      "Epoch 1615/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.8016e-04 - val_loss: 5.5357e-04\n",
      "Epoch 1616/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8011e-04 - val_loss: 5.5301e-04\n",
      "Epoch 1617/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7995e-04 - val_loss: 5.5304e-04\n",
      "Epoch 1618/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7992e-04 - val_loss: 5.5280e-04\n",
      "Epoch 1619/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7984e-04 - val_loss: 5.5278e-04\n",
      "Epoch 1620/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7978e-04 - val_loss: 5.5331e-04\n",
      "Epoch 1621/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7979e-04 - val_loss: 5.5270e-04\n",
      "Epoch 1622/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7985e-04 - val_loss: 5.5295e-04\n",
      "Epoch 1623/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7981e-04 - val_loss: 5.5316e-04\n",
      "Epoch 1624/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7979e-04 - val_loss: 5.5257e-04\n",
      "Epoch 1625/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7968e-04 - val_loss: 5.5297e-04\n",
      "Epoch 1626/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7968e-04 - val_loss: 5.5337e-04\n",
      "Epoch 1627/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7968e-04 - val_loss: 5.5288e-04\n",
      "Epoch 1628/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7983e-04 - val_loss: 5.5285e-04\n",
      "Epoch 1629/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7964e-04 - val_loss: 5.5225e-04\n",
      "Epoch 1630/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7956e-04 - val_loss: 5.5315e-04\n",
      "Epoch 1631/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7970e-04 - val_loss: 5.5322e-04\n",
      "Epoch 1632/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7958e-04 - val_loss: 5.5251e-04\n",
      "Epoch 1633/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7952e-04 - val_loss: 5.5240e-04\n",
      "Epoch 1634/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7944e-04 - val_loss: 5.5256e-04\n",
      "Epoch 1635/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7957e-04 - val_loss: 5.5329e-04\n",
      "Epoch 1636/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7950e-04 - val_loss: 5.5263e-04\n",
      "Epoch 1637/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7944e-04 - val_loss: 5.5192e-04\n",
      "Epoch 1638/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7950e-04 - val_loss: 5.5245e-04\n",
      "Epoch 1639/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7935e-04 - val_loss: 5.5277e-04\n",
      "Epoch 1640/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7933e-04 - val_loss: 5.5235e-04\n",
      "Epoch 1641/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7938e-04 - val_loss: 5.5175e-04\n",
      "Epoch 1642/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7932e-04 - val_loss: 5.5144e-04\n",
      "Epoch 1643/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7935e-04 - val_loss: 5.5178e-04\n",
      "Epoch 1644/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7922e-04 - val_loss: 5.5245e-04\n",
      "Epoch 1645/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7936e-04 - val_loss: 5.5173e-04\n",
      "Epoch 1646/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7924e-04 - val_loss: 5.5164e-04\n",
      "Epoch 1647/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7918e-04 - val_loss: 5.5158e-04\n",
      "Epoch 1648/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7917e-04 - val_loss: 5.5280e-04\n",
      "Epoch 1649/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7924e-04 - val_loss: 5.5298e-04\n",
      "Epoch 1650/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7916e-04 - val_loss: 5.5158e-04\n",
      "Epoch 1651/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7906e-04 - val_loss: 5.5193e-04\n",
      "Epoch 1652/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7904e-04 - val_loss: 5.5205e-04\n",
      "Epoch 1653/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7896e-04 - val_loss: 5.5140e-04\n",
      "Epoch 1654/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7903e-04 - val_loss: 5.5126e-04\n",
      "Epoch 1655/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7896e-04 - val_loss: 5.5164e-04\n",
      "Epoch 1656/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7899e-04 - val_loss: 5.5217e-04\n",
      "Epoch 1657/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7894e-04 - val_loss: 5.5123e-04\n",
      "Epoch 1658/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7892e-04 - val_loss: 5.5108e-04\n",
      "Epoch 1659/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7885e-04 - val_loss: 5.5149e-04\n",
      "Epoch 1660/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7885e-04 - val_loss: 5.5101e-04\n",
      "Epoch 1661/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7885e-04 - val_loss: 5.5296e-04\n",
      "Epoch 1662/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7882e-04 - val_loss: 5.5224e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1663/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7894e-04 - val_loss: 5.5141e-04\n",
      "Epoch 1664/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7872e-04 - val_loss: 5.5211e-04\n",
      "Epoch 1665/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7877e-04 - val_loss: 5.5076e-04\n",
      "Epoch 1666/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7871e-04 - val_loss: 5.5093e-04\n",
      "Epoch 1667/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7865e-04 - val_loss: 5.5139e-04\n",
      "Epoch 1668/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7868e-04 - val_loss: 5.5182e-04\n",
      "Epoch 1669/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7872e-04 - val_loss: 5.5104e-04\n",
      "Epoch 1670/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7861e-04 - val_loss: 5.5091e-04\n",
      "Epoch 1671/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7860e-04 - val_loss: 5.5149e-04\n",
      "Epoch 1672/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7859e-04 - val_loss: 5.5063e-04\n",
      "Epoch 1673/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7852e-04 - val_loss: 5.5092e-04\n",
      "Epoch 1674/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7864e-04 - val_loss: 5.5193e-04\n",
      "Epoch 1675/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7857e-04 - val_loss: 5.5048e-04\n",
      "Epoch 1676/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7843e-04 - val_loss: 5.5277e-04\n",
      "Epoch 1677/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7848e-04 - val_loss: 5.5034e-04\n",
      "Epoch 1678/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7846e-04 - val_loss: 5.5187e-04\n",
      "Epoch 1679/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7845e-04 - val_loss: 5.5100e-04\n",
      "Epoch 1680/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7836e-04 - val_loss: 5.5227e-04\n",
      "Epoch 1681/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7837e-04 - val_loss: 5.5097e-04\n",
      "Epoch 1682/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7834e-04 - val_loss: 5.5076e-04\n",
      "Epoch 1683/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7825e-04 - val_loss: 5.5130e-04\n",
      "Epoch 1684/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7836e-04 - val_loss: 5.5160e-04\n",
      "Epoch 1685/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7828e-04 - val_loss: 5.5032e-04\n",
      "Epoch 1686/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7833e-04 - val_loss: 5.5211e-04\n",
      "Epoch 1687/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7821e-04 - val_loss: 5.5115e-04\n",
      "Epoch 1688/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7824e-04 - val_loss: 5.5017e-04\n",
      "Epoch 1689/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7828e-04 - val_loss: 5.4998e-04\n",
      "Epoch 1690/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7825e-04 - val_loss: 5.5019e-04\n",
      "Epoch 1691/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7810e-04 - val_loss: 5.5043e-04\n",
      "Epoch 1692/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7809e-04 - val_loss: 5.4992e-04\n",
      "Epoch 1693/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7804e-04 - val_loss: 5.5007e-04\n",
      "Epoch 1694/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7799e-04 - val_loss: 5.5252e-04\n",
      "Epoch 1695/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7816e-04 - val_loss: 5.5084e-04\n",
      "Epoch 1696/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7815e-04 - val_loss: 5.5198e-04\n",
      "Epoch 1697/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7798e-04 - val_loss: 5.5154e-04\n",
      "Epoch 1698/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7798e-04 - val_loss: 5.4983e-04\n",
      "Epoch 1699/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7796e-04 - val_loss: 5.5016e-04\n",
      "Epoch 1700/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7808e-04 - val_loss: 5.5167e-04\n",
      "Epoch 1701/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7792e-04 - val_loss: 5.5044e-04\n",
      "Epoch 1702/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7789e-04 - val_loss: 5.4980e-04\n",
      "Epoch 1703/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.7782e-04 - val_loss: 5.4979e-04\n",
      "Epoch 1704/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7789e-04 - val_loss: 5.5129e-04\n",
      "Epoch 1705/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7783e-04 - val_loss: 5.4950e-04\n",
      "Epoch 1706/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7777e-04 - val_loss: 5.5070e-04\n",
      "Epoch 1707/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7775e-04 - val_loss: 5.4998e-04\n",
      "Epoch 1708/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7775e-04 - val_loss: 5.4962e-04\n",
      "Epoch 1709/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7780e-04 - val_loss: 5.5061e-04\n",
      "Epoch 1710/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7770e-04 - val_loss: 5.4960e-04\n",
      "Epoch 1711/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7768e-04 - val_loss: 5.5053e-04\n",
      "Epoch 1712/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7767e-04 - val_loss: 5.5011e-04\n",
      "Epoch 1713/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7760e-04 - val_loss: 5.5115e-04\n",
      "Epoch 1714/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7759e-04 - val_loss: 5.5012e-04\n",
      "Epoch 1715/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7783e-04 - val_loss: 5.5066e-04\n",
      "Epoch 1716/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7760e-04 - val_loss: 5.4933e-04\n",
      "Epoch 1717/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7748e-04 - val_loss: 5.5017e-04\n",
      "Epoch 1718/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7764e-04 - val_loss: 5.4959e-04\n",
      "Epoch 1719/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7749e-04 - val_loss: 5.4957e-04\n",
      "Epoch 1720/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7749e-04 - val_loss: 5.4923e-04\n",
      "Epoch 1721/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7756e-04 - val_loss: 5.5008e-04\n",
      "Epoch 1722/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7746e-04 - val_loss: 5.5059e-04\n",
      "Epoch 1723/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7739e-04 - val_loss: 5.4951e-04\n",
      "Epoch 1724/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7747e-04 - val_loss: 5.4922e-04\n",
      "Epoch 1725/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7738e-04 - val_loss: 5.4978e-04\n",
      "Epoch 1726/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7734e-04 - val_loss: 5.4924e-04\n",
      "Epoch 1727/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7729e-04 - val_loss: 5.4990e-04\n",
      "Epoch 1728/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7739e-04 - val_loss: 5.5016e-04\n",
      "Epoch 1729/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7728e-04 - val_loss: 5.4924e-04\n",
      "Epoch 1730/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7729e-04 - val_loss: 5.4968e-04\n",
      "Epoch 1731/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7729e-04 - val_loss: 5.4982e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1732/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7732e-04 - val_loss: 5.4942e-04\n",
      "Epoch 1733/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7728e-04 - val_loss: 5.5023e-04\n",
      "Epoch 1734/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7719e-04 - val_loss: 5.4909e-04\n",
      "Epoch 1735/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7734e-04 - val_loss: 5.4876e-04\n",
      "Epoch 1736/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7713e-04 - val_loss: 5.4931e-04\n",
      "Epoch 1737/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7710e-04 - val_loss: 5.4903e-04\n",
      "Epoch 1738/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7704e-04 - val_loss: 5.5009e-04\n",
      "Epoch 1739/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7716e-04 - val_loss: 5.4919e-04\n",
      "Epoch 1740/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7730e-04 - val_loss: 5.5061e-04\n",
      "Epoch 1741/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7712e-04 - val_loss: 5.4983e-04\n",
      "Epoch 1742/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7705e-04 - val_loss: 5.4908e-04\n",
      "Epoch 1743/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7695e-04 - val_loss: 5.4973e-04\n",
      "Epoch 1744/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7704e-04 - val_loss: 5.4891e-04\n",
      "Epoch 1745/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7695e-04 - val_loss: 5.4866e-04\n",
      "Epoch 1746/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7697e-04 - val_loss: 5.4967e-04\n",
      "Epoch 1747/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7684e-04 - val_loss: 5.4984e-04\n",
      "Epoch 1748/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7699e-04 - val_loss: 5.4834e-04\n",
      "Epoch 1749/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7698e-04 - val_loss: 5.4925e-04\n",
      "Epoch 1750/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7696e-04 - val_loss: 5.4861e-04\n",
      "Epoch 1751/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7693e-04 - val_loss: 5.4841e-04\n",
      "Epoch 1752/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7684e-04 - val_loss: 5.4862e-04\n",
      "Epoch 1753/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7683e-04 - val_loss: 5.4859e-04\n",
      "Epoch 1754/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7678e-04 - val_loss: 5.4919e-04\n",
      "Epoch 1755/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7677e-04 - val_loss: 5.4866e-04\n",
      "Epoch 1756/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.7668e-04 - val_loss: 5.4855e-04\n",
      "Epoch 1757/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7674e-04 - val_loss: 5.5000e-04\n",
      "Epoch 1758/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7681e-04 - val_loss: 5.4826e-04\n",
      "Epoch 1759/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7666e-04 - val_loss: 5.4885e-04\n",
      "Epoch 1760/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7667e-04 - val_loss: 5.4905e-04\n",
      "Epoch 1761/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7664e-04 - val_loss: 5.4878e-04\n",
      "Epoch 1762/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7680e-04 - val_loss: 5.4777e-04\n",
      "Epoch 1763/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7672e-04 - val_loss: 5.4825e-04\n",
      "Epoch 1764/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7673e-04 - val_loss: 5.4851e-04\n",
      "Epoch 1765/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7664e-04 - val_loss: 5.4774e-04\n",
      "Epoch 1766/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7659e-04 - val_loss: 5.4899e-04\n",
      "Epoch 1767/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7654e-04 - val_loss: 5.4802e-04\n",
      "Epoch 1768/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7664e-04 - val_loss: 5.4818e-04\n",
      "Epoch 1769/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7651e-04 - val_loss: 5.4849e-04\n",
      "Epoch 1770/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7654e-04 - val_loss: 5.4906e-04\n",
      "Epoch 1771/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7643e-04 - val_loss: 5.4918e-04\n",
      "Epoch 1772/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7661e-04 - val_loss: 5.4798e-04\n",
      "Epoch 1773/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7640e-04 - val_loss: 5.4823e-04\n",
      "Epoch 1774/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7640e-04 - val_loss: 5.4835e-04\n",
      "Epoch 1775/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7640e-04 - val_loss: 5.4803e-04\n",
      "Epoch 1776/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7650e-04 - val_loss: 5.4832e-04\n",
      "Epoch 1777/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7629e-04 - val_loss: 5.4828e-04\n",
      "Epoch 1778/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7637e-04 - val_loss: 5.4782e-04\n",
      "Epoch 1779/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7636e-04 - val_loss: 5.4885e-04\n",
      "Epoch 1780/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7627e-04 - val_loss: 5.4965e-04\n",
      "Epoch 1781/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7633e-04 - val_loss: 5.4841e-04\n",
      "Epoch 1782/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7618e-04 - val_loss: 5.4826e-04\n",
      "Epoch 1783/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7629e-04 - val_loss: 5.4870e-04\n",
      "Epoch 1784/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7622e-04 - val_loss: 5.4825e-04\n",
      "Epoch 1785/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7629e-04 - val_loss: 5.4805e-04\n",
      "Epoch 1786/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7625e-04 - val_loss: 5.4790e-04\n",
      "Epoch 1787/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7620e-04 - val_loss: 5.4805e-04\n",
      "Epoch 1788/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7618e-04 - val_loss: 5.4835e-04\n",
      "Epoch 1789/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7610e-04 - val_loss: 5.4835e-04\n",
      "Epoch 1790/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7613e-04 - val_loss: 5.4759e-04\n",
      "Epoch 1791/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7609e-04 - val_loss: 5.4793e-04\n",
      "Epoch 1792/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7608e-04 - val_loss: 5.4795e-04\n",
      "Epoch 1793/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7603e-04 - val_loss: 5.4854e-04\n",
      "Epoch 1794/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7611e-04 - val_loss: 5.4742e-04\n",
      "Epoch 1795/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7614e-04 - val_loss: 5.4834e-04\n",
      "Epoch 1796/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7595e-04 - val_loss: 5.4868e-04\n",
      "Epoch 1797/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7603e-04 - val_loss: 5.4791e-04\n",
      "Epoch 1798/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7595e-04 - val_loss: 5.4919e-04\n",
      "Epoch 1799/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7596e-04 - val_loss: 5.4821e-04\n",
      "Epoch 1800/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7595e-04 - val_loss: 5.4737e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1801/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7599e-04 - val_loss: 5.4764e-04\n",
      "Epoch 1802/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7588e-04 - val_loss: 5.4800e-04\n",
      "Epoch 1803/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7589e-04 - val_loss: 5.4760e-04\n",
      "Epoch 1804/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7590e-04 - val_loss: 5.4757e-04\n",
      "Epoch 1805/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7578e-04 - val_loss: 5.4849e-04\n",
      "Epoch 1806/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7580e-04 - val_loss: 5.4757e-04\n",
      "Epoch 1807/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7578e-04 - val_loss: 5.4865e-04\n",
      "Epoch 1808/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7581e-04 - val_loss: 5.4773e-04\n",
      "Epoch 1809/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7577e-04 - val_loss: 5.4848e-04\n",
      "Epoch 1810/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7570e-04 - val_loss: 5.4870e-04\n",
      "Epoch 1811/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7575e-04 - val_loss: 5.4733e-04\n",
      "Epoch 1812/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7570e-04 - val_loss: 5.4749e-04\n",
      "Epoch 1813/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7571e-04 - val_loss: 5.4707e-04\n",
      "Epoch 1814/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7571e-04 - val_loss: 5.4738e-04\n",
      "Epoch 1815/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7568e-04 - val_loss: 5.4847e-04\n",
      "Epoch 1816/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7551e-04 - val_loss: 5.4763e-04\n",
      "Epoch 1817/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7559e-04 - val_loss: 5.4746e-04\n",
      "Epoch 1818/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7558e-04 - val_loss: 5.4787e-04\n",
      "Epoch 1819/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7554e-04 - val_loss: 5.4854e-04\n",
      "Epoch 1820/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7553e-04 - val_loss: 5.4771e-04\n",
      "Epoch 1821/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7567e-04 - val_loss: 5.4770e-04\n",
      "Epoch 1822/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7550e-04 - val_loss: 5.4924e-04\n",
      "Epoch 1823/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7539e-04 - val_loss: 5.4833e-04\n",
      "Epoch 1824/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7559e-04 - val_loss: 5.4850e-04\n",
      "Epoch 1825/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7550e-04 - val_loss: 5.4753e-04\n",
      "Epoch 1826/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7556e-04 - val_loss: 5.4760e-04\n",
      "Epoch 1827/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7540e-04 - val_loss: 5.4792e-04\n",
      "Epoch 1828/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7558e-04 - val_loss: 5.4864e-04\n",
      "Epoch 1829/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7547e-04 - val_loss: 5.4923e-04\n",
      "Epoch 1830/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7538e-04 - val_loss: 5.4789e-04\n",
      "Epoch 1831/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7540e-04 - val_loss: 5.4804e-04\n",
      "Epoch 1832/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7536e-04 - val_loss: 5.4884e-04\n",
      "Epoch 1833/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7530e-04 - val_loss: 5.4819e-04\n",
      "Epoch 1834/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7529e-04 - val_loss: 5.4795e-04\n",
      "Epoch 1835/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7530e-04 - val_loss: 5.4779e-04\n",
      "Epoch 1836/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7544e-04 - val_loss: 5.4780e-04\n",
      "Epoch 1837/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7536e-04 - val_loss: 5.4900e-04\n",
      "Epoch 1838/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7523e-04 - val_loss: 5.4780e-04\n",
      "Epoch 1839/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7521e-04 - val_loss: 5.4801e-04\n",
      "Epoch 1840/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7517e-04 - val_loss: 5.4805e-04\n",
      "Epoch 1841/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7522e-04 - val_loss: 5.4796e-04\n",
      "Epoch 1842/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7516e-04 - val_loss: 5.4749e-04\n",
      "Epoch 1843/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7516e-04 - val_loss: 5.4743e-04\n",
      "Epoch 1844/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7527e-04 - val_loss: 5.4743e-04\n",
      "Epoch 1845/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7514e-04 - val_loss: 5.4783e-04\n",
      "Epoch 1846/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7515e-04 - val_loss: 5.4847e-04\n",
      "Epoch 1847/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7504e-04 - val_loss: 5.4761e-04\n",
      "Epoch 1848/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7500e-04 - val_loss: 5.4802e-04\n",
      "Epoch 1849/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7504e-04 - val_loss: 5.4721e-04\n",
      "Epoch 1850/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7513e-04 - val_loss: 5.4786e-04\n",
      "Epoch 1851/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7504e-04 - val_loss: 5.4779e-04\n",
      "Epoch 1852/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7498e-04 - val_loss: 5.4722e-04\n",
      "Epoch 1853/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7502e-04 - val_loss: 5.4857e-04\n",
      "Epoch 1854/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7484e-04 - val_loss: 5.4776e-04\n",
      "Epoch 1855/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7500e-04 - val_loss: 5.4778e-04\n",
      "Epoch 1856/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7494e-04 - val_loss: 5.4733e-04\n",
      "Epoch 1857/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7484e-04 - val_loss: 5.4731e-04\n",
      "Epoch 1858/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7495e-04 - val_loss: 5.4740e-04\n",
      "Epoch 1859/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7484e-04 - val_loss: 5.4710e-04\n",
      "Epoch 1860/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7484e-04 - val_loss: 5.4845e-04\n",
      "Epoch 1861/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7480e-04 - val_loss: 5.4927e-04\n",
      "Epoch 1862/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7484e-04 - val_loss: 5.4787e-04\n",
      "Epoch 1863/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7476e-04 - val_loss: 5.4711e-04\n",
      "Epoch 1864/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7480e-04 - val_loss: 5.4771e-04\n",
      "Epoch 1865/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7483e-04 - val_loss: 5.4811e-04\n",
      "Epoch 1866/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7478e-04 - val_loss: 5.4768e-04\n",
      "Epoch 1867/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7471e-04 - val_loss: 5.4722e-04\n",
      "Epoch 1868/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7471e-04 - val_loss: 5.4727e-04\n",
      "Epoch 1869/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7478e-04 - val_loss: 5.4837e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1870/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7472e-04 - val_loss: 5.4854e-04\n",
      "Epoch 1871/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7464e-04 - val_loss: 5.4727e-04\n",
      "Epoch 1872/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7474e-04 - val_loss: 5.4752e-04\n",
      "Epoch 1873/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7468e-04 - val_loss: 5.4764e-04\n",
      "Epoch 1874/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7467e-04 - val_loss: 5.4708e-04\n",
      "Epoch 1875/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7453e-04 - val_loss: 5.4832e-04\n",
      "Epoch 1876/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7479e-04 - val_loss: 5.4808e-04\n",
      "Epoch 1877/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7454e-04 - val_loss: 5.4720e-04\n",
      "Epoch 1878/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7454e-04 - val_loss: 5.4759e-04\n",
      "Epoch 1879/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7452e-04 - val_loss: 5.4730e-04\n",
      "Epoch 1880/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7456e-04 - val_loss: 5.4729e-04\n",
      "Epoch 1881/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7449e-04 - val_loss: 5.4748e-04\n",
      "Epoch 1882/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7451e-04 - val_loss: 5.4739e-04\n",
      "Epoch 1883/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7446e-04 - val_loss: 5.4857e-04\n",
      "Epoch 1884/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7453e-04 - val_loss: 5.4746e-04\n",
      "Epoch 1885/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7435e-04 - val_loss: 5.4729e-04\n",
      "Epoch 1886/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7450e-04 - val_loss: 5.4794e-04\n",
      "Epoch 1887/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7436e-04 - val_loss: 5.4829e-04\n",
      "Epoch 1888/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7441e-04 - val_loss: 5.4756e-04\n",
      "Epoch 1889/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7431e-04 - val_loss: 5.4840e-04\n",
      "Epoch 1890/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7437e-04 - val_loss: 5.4728e-04\n",
      "Epoch 1891/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7433e-04 - val_loss: 5.4786e-04\n",
      "Epoch 1892/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7427e-04 - val_loss: 5.4692e-04\n",
      "Epoch 1893/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.7429e-04 - val_loss: 5.4837e-04\n",
      "Epoch 1894/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7429e-04 - val_loss: 5.4752e-04\n",
      "Epoch 1895/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7414e-04 - val_loss: 5.4829e-04\n",
      "Epoch 1896/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7418e-04 - val_loss: 5.4811e-04\n",
      "Epoch 1897/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7425e-04 - val_loss: 5.4824e-04\n",
      "Epoch 1898/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7419e-04 - val_loss: 5.4751e-04\n",
      "Epoch 1899/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7425e-04 - val_loss: 5.4769e-04\n",
      "Epoch 1900/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7416e-04 - val_loss: 5.4748e-04\n",
      "Epoch 1901/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7438e-04 - val_loss: 5.4739e-04\n",
      "Epoch 1902/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7426e-04 - val_loss: 5.4707e-04\n",
      "Epoch 1903/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7408e-04 - val_loss: 5.4761e-04\n",
      "Epoch 1904/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7412e-04 - val_loss: 5.4780e-04\n",
      "Epoch 1905/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7406e-04 - val_loss: 5.4832e-04\n",
      "Epoch 1906/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7419e-04 - val_loss: 5.4760e-04\n",
      "Epoch 1907/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7405e-04 - val_loss: 5.4792e-04\n",
      "Epoch 1908/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7396e-04 - val_loss: 5.4658e-04\n",
      "Epoch 1909/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7409e-04 - val_loss: 5.4722e-04\n",
      "Epoch 1910/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7404e-04 - val_loss: 5.4833e-04\n",
      "Epoch 1911/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7405e-04 - val_loss: 5.4697e-04\n",
      "Epoch 1912/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7402e-04 - val_loss: 5.4747e-04\n",
      "Epoch 1913/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7412e-04 - val_loss: 5.4818e-04\n",
      "Epoch 1914/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7411e-04 - val_loss: 5.4830e-04\n",
      "Epoch 1915/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7393e-04 - val_loss: 5.4790e-04\n",
      "Epoch 1916/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7389e-04 - val_loss: 5.4765e-04\n",
      "Epoch 1917/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7395e-04 - val_loss: 5.4716e-04\n",
      "Epoch 1918/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7388e-04 - val_loss: 5.4792e-04\n",
      "Epoch 1919/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7398e-04 - val_loss: 5.4745e-04\n",
      "Epoch 1920/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7384e-04 - val_loss: 5.4789e-04\n",
      "Epoch 1921/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7388e-04 - val_loss: 5.4810e-04\n",
      "Epoch 1922/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7381e-04 - val_loss: 5.4670e-04\n",
      "Epoch 1923/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7386e-04 - val_loss: 5.4731e-04\n",
      "Epoch 1924/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7390e-04 - val_loss: 5.4784e-04\n",
      "Epoch 1925/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7385e-04 - val_loss: 5.4790e-04\n",
      "Epoch 1926/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7388e-04 - val_loss: 5.4751e-04\n",
      "Epoch 1927/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7378e-04 - val_loss: 5.4787e-04\n",
      "Epoch 1928/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7376e-04 - val_loss: 5.4842e-04\n",
      "Epoch 1929/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7384e-04 - val_loss: 5.4837e-04\n",
      "Epoch 1930/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7376e-04 - val_loss: 5.4844e-04\n",
      "Epoch 1931/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7385e-04 - val_loss: 5.4804e-04\n",
      "Epoch 1932/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7376e-04 - val_loss: 5.4710e-04\n",
      "Epoch 1933/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7378e-04 - val_loss: 5.4907e-04\n",
      "Epoch 1934/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7370e-04 - val_loss: 5.4657e-04\n",
      "Epoch 1935/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7365e-04 - val_loss: 5.4719e-04\n",
      "Epoch 1936/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7371e-04 - val_loss: 5.4887e-04\n",
      "Epoch 1937/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7370e-04 - val_loss: 5.4770e-04\n",
      "Epoch 1938/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7382e-04 - val_loss: 5.4756e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1939/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7372e-04 - val_loss: 5.4754e-04\n",
      "Epoch 1940/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7354e-04 - val_loss: 5.4702e-04\n",
      "Epoch 1941/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7361e-04 - val_loss: 5.4788e-04\n",
      "Epoch 1942/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7355e-04 - val_loss: 5.4823e-04\n",
      "Epoch 1943/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7382e-04 - val_loss: 5.4761e-04\n",
      "Epoch 1944/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7376e-04 - val_loss: 5.4730e-04\n",
      "Epoch 1945/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7360e-04 - val_loss: 5.4712e-04\n",
      "Epoch 1946/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7359e-04 - val_loss: 5.4804e-04\n",
      "Epoch 1947/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7363e-04 - val_loss: 5.4784e-04\n",
      "Epoch 1948/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7362e-04 - val_loss: 5.4867e-04\n",
      "Epoch 1949/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7348e-04 - val_loss: 5.4725e-04\n",
      "Epoch 1950/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7354e-04 - val_loss: 5.4638e-04\n",
      "Epoch 1951/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7345e-04 - val_loss: 5.4825e-04\n",
      "Epoch 1952/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7345e-04 - val_loss: 5.4829e-04\n",
      "Epoch 1953/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7344e-04 - val_loss: 5.4836e-04\n",
      "Epoch 1954/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7335e-04 - val_loss: 5.4855e-04\n",
      "Epoch 1955/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7339e-04 - val_loss: 5.4688e-04\n",
      "Epoch 1956/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7349e-04 - val_loss: 5.4767e-04\n",
      "Epoch 1957/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7339e-04 - val_loss: 5.4746e-04\n",
      "Epoch 1958/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7338e-04 - val_loss: 5.4817e-04\n",
      "Epoch 1959/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7335e-04 - val_loss: 5.4764e-04\n",
      "Epoch 1960/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7326e-04 - val_loss: 5.4788e-04\n",
      "Epoch 1961/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7327e-04 - val_loss: 5.4762e-04\n",
      "Epoch 1962/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7330e-04 - val_loss: 5.4749e-04\n",
      "Epoch 1963/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7353e-04 - val_loss: 5.4725e-04\n",
      "Epoch 1964/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7332e-04 - val_loss: 5.4729e-04\n",
      "Epoch 1965/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7315e-04 - val_loss: 5.4660e-04\n",
      "Epoch 1966/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7318e-04 - val_loss: 5.4582e-04\n",
      "Epoch 1967/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7327e-04 - val_loss: 5.4751e-04\n",
      "Epoch 1968/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7322e-04 - val_loss: 5.4798e-04\n",
      "Epoch 1969/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7332e-04 - val_loss: 5.4790e-04\n",
      "Epoch 1970/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7336e-04 - val_loss: 5.4753e-04\n",
      "Epoch 1971/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7328e-04 - val_loss: 5.4711e-04\n",
      "Epoch 1972/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7320e-04 - val_loss: 5.4872e-04\n",
      "Epoch 1973/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7326e-04 - val_loss: 5.4813e-04\n",
      "Epoch 1974/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7329e-04 - val_loss: 5.4776e-04\n",
      "Epoch 1975/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7317e-04 - val_loss: 5.4742e-04\n",
      "Epoch 1976/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7319e-04 - val_loss: 5.4884e-04\n",
      "Epoch 1977/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7309e-04 - val_loss: 5.4821e-04\n",
      "Epoch 1978/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7305e-04 - val_loss: 5.4753e-04\n",
      "Epoch 1979/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7309e-04 - val_loss: 5.4779e-04\n",
      "Epoch 1980/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7312e-04 - val_loss: 5.4863e-04\n",
      "Epoch 1981/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7314e-04 - val_loss: 5.4820e-04\n",
      "Epoch 1982/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7307e-04 - val_loss: 5.4671e-04\n",
      "Epoch 1983/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7294e-04 - val_loss: 5.4762e-04\n",
      "Epoch 1984/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7299e-04 - val_loss: 5.4872e-04\n",
      "Epoch 1985/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7303e-04 - val_loss: 5.4791e-04\n",
      "Epoch 1986/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7300e-04 - val_loss: 5.4758e-04\n",
      "Epoch 1987/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7307e-04 - val_loss: 5.4909e-04\n",
      "Epoch 1988/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7289e-04 - val_loss: 5.4853e-04\n",
      "Epoch 1989/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7307e-04 - val_loss: 5.4702e-04\n",
      "Epoch 1990/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7297e-04 - val_loss: 5.4759e-04\n",
      "Epoch 1991/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7280e-04 - val_loss: 5.4742e-04\n",
      "Epoch 1992/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7288e-04 - val_loss: 5.4667e-04\n",
      "Epoch 1993/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7292e-04 - val_loss: 5.4730e-04\n",
      "Epoch 1994/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7307e-04 - val_loss: 5.4830e-04\n",
      "Epoch 1995/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7278e-04 - val_loss: 5.4647e-04\n",
      "Epoch 1996/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7279e-04 - val_loss: 5.4871e-04\n",
      "Epoch 1997/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7272e-04 - val_loss: 5.4809e-04\n",
      "Epoch 1998/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7300e-04 - val_loss: 5.4708e-04\n",
      "Epoch 1999/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7277e-04 - val_loss: 5.4773e-04\n",
      "Epoch 2000/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7277e-04 - val_loss: 5.4762e-04\n",
      "Epoch 2001/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7270e-04 - val_loss: 5.4816e-04\n",
      "Epoch 2002/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7275e-04 - val_loss: 5.4704e-04\n",
      "Epoch 2003/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7289e-04 - val_loss: 5.4746e-04\n",
      "Epoch 2004/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7286e-04 - val_loss: 5.4775e-04\n",
      "Epoch 2005/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7264e-04 - val_loss: 5.4712e-04\n",
      "Epoch 2006/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7269e-04 - val_loss: 5.4710e-04\n",
      "Epoch 2007/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.7270e-04 - val_loss: 5.4709e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2008/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7282e-04 - val_loss: 5.4676e-04\n",
      "Epoch 2009/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7275e-04 - val_loss: 5.4688e-04\n",
      "Epoch 2010/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7261e-04 - val_loss: 5.4698e-04\n",
      "Epoch 2011/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7266e-04 - val_loss: 5.4905e-04\n",
      "Epoch 2012/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7251e-04 - val_loss: 5.4709e-04\n",
      "Epoch 2013/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7275e-04 - val_loss: 5.4847e-04\n",
      "Epoch 2014/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7253e-04 - val_loss: 5.4754e-04\n",
      "Epoch 2015/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7264e-04 - val_loss: 5.4702e-04\n",
      "Epoch 2016/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7263e-04 - val_loss: 5.4763e-04\n",
      "Epoch 2017/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7248e-04 - val_loss: 5.4687e-04\n",
      "Epoch 2018/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7250e-04 - val_loss: 5.4715e-04\n",
      "Epoch 2019/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7254e-04 - val_loss: 5.4825e-04\n",
      "Epoch 2020/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7250e-04 - val_loss: 5.4710e-04\n",
      "Epoch 2021/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7262e-04 - val_loss: 5.4613e-04\n",
      "Epoch 2022/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7244e-04 - val_loss: 5.4682e-04\n",
      "Epoch 2023/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7249e-04 - val_loss: 5.4752e-04\n",
      "Epoch 2024/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7236e-04 - val_loss: 5.4914e-04\n",
      "Epoch 2025/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7241e-04 - val_loss: 5.4660e-04\n",
      "Epoch 2026/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7259e-04 - val_loss: 5.4621e-04\n",
      "Epoch 2027/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7235e-04 - val_loss: 5.4594e-04\n",
      "Epoch 2028/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7238e-04 - val_loss: 5.4789e-04\n",
      "Epoch 2029/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7258e-04 - val_loss: 5.4676e-04\n",
      "Epoch 2030/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7239e-04 - val_loss: 5.4607e-04\n",
      "Epoch 2031/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7227e-04 - val_loss: 5.4766e-04\n",
      "Epoch 2032/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7233e-04 - val_loss: 5.4653e-04\n",
      "Epoch 2033/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7235e-04 - val_loss: 5.4679e-04\n",
      "Epoch 2034/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7231e-04 - val_loss: 5.4569e-04\n",
      "Epoch 2035/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7231e-04 - val_loss: 5.4909e-04\n",
      "Epoch 2036/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7221e-04 - val_loss: 5.4879e-04\n",
      "Epoch 2037/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7231e-04 - val_loss: 5.4660e-04\n",
      "Epoch 2038/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7242e-04 - val_loss: 5.4679e-04\n",
      "Epoch 2039/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7219e-04 - val_loss: 5.4724e-04\n",
      "Epoch 2040/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7232e-04 - val_loss: 5.4765e-04\n",
      "Epoch 2041/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7226e-04 - val_loss: 5.4678e-04\n",
      "Epoch 2042/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7219e-04 - val_loss: 5.4652e-04\n",
      "Epoch 2043/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7228e-04 - val_loss: 5.4790e-04\n",
      "Epoch 2044/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7221e-04 - val_loss: 5.4781e-04\n",
      "Epoch 2045/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7209e-04 - val_loss: 5.4571e-04\n",
      "Epoch 2046/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7209e-04 - val_loss: 5.4700e-04\n",
      "Epoch 2047/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7236e-04 - val_loss: 5.4823e-04\n",
      "Epoch 2048/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7218e-04 - val_loss: 5.4797e-04\n",
      "Epoch 2049/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7209e-04 - val_loss: 5.4774e-04\n",
      "Epoch 2050/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7221e-04 - val_loss: 5.4761e-04\n",
      "Epoch 2051/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7229e-04 - val_loss: 5.4646e-04\n",
      "Epoch 2052/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7206e-04 - val_loss: 5.4676e-04\n",
      "Epoch 2053/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7207e-04 - val_loss: 5.4607e-04\n",
      "Epoch 2054/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7212e-04 - val_loss: 5.4712e-04\n",
      "Epoch 2055/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7197e-04 - val_loss: 5.4647e-04\n",
      "Epoch 2056/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7209e-04 - val_loss: 5.4740e-04\n",
      "Epoch 2057/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7195e-04 - val_loss: 5.4705e-04\n",
      "Epoch 2058/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7202e-04 - val_loss: 5.4540e-04\n",
      "Epoch 2059/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7217e-04 - val_loss: 5.4605e-04\n",
      "Epoch 2060/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7195e-04 - val_loss: 5.4630e-04\n",
      "Epoch 2061/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7204e-04 - val_loss: 5.4766e-04\n",
      "Epoch 2062/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7192e-04 - val_loss: 5.4554e-04\n",
      "Epoch 2063/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7195e-04 - val_loss: 5.4812e-04\n",
      "Epoch 2064/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7191e-04 - val_loss: 5.4556e-04\n",
      "Epoch 2065/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7187e-04 - val_loss: 5.4648e-04\n",
      "Epoch 2066/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7192e-04 - val_loss: 5.4697e-04\n",
      "Epoch 2067/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7191e-04 - val_loss: 5.4797e-04\n",
      "Epoch 2068/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7193e-04 - val_loss: 5.4576e-04\n",
      "Epoch 2069/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7188e-04 - val_loss: 5.4592e-04\n",
      "Epoch 2070/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7181e-04 - val_loss: 5.4595e-04\n",
      "Epoch 2071/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7183e-04 - val_loss: 5.4563e-04\n",
      "Epoch 2072/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7191e-04 - val_loss: 5.4625e-04\n",
      "Epoch 2073/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7179e-04 - val_loss: 5.4627e-04\n",
      "Epoch 2074/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7175e-04 - val_loss: 5.4758e-04\n",
      "Epoch 2075/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7185e-04 - val_loss: 5.4577e-04\n",
      "Epoch 2076/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7174e-04 - val_loss: 5.4578e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2077/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7175e-04 - val_loss: 5.4739e-04\n",
      "Epoch 2078/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7171e-04 - val_loss: 5.4616e-04\n",
      "Epoch 2079/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7201e-04 - val_loss: 5.4580e-04\n",
      "Epoch 2080/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7184e-04 - val_loss: 5.4676e-04\n",
      "Epoch 2081/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7159e-04 - val_loss: 5.4696e-04\n",
      "Epoch 2082/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.7164e-04 - val_loss: 5.4652e-04\n",
      "Epoch 2083/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.7166e-04 - val_loss: 5.4582e-04\n",
      "Epoch 2084/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7164e-04 - val_loss: 5.4645e-04\n",
      "Epoch 2085/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7166e-04 - val_loss: 5.4868e-04\n",
      "Epoch 2086/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7179e-04 - val_loss: 5.4540e-04\n",
      "Epoch 2087/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7164e-04 - val_loss: 5.4688e-04\n",
      "Epoch 2088/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7164e-04 - val_loss: 5.4554e-04\n",
      "Epoch 2089/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7162e-04 - val_loss: 5.4556e-04\n",
      "Epoch 2090/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7161e-04 - val_loss: 5.4512e-04\n",
      "Epoch 2091/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7163e-04 - val_loss: 5.4624e-04\n",
      "Epoch 2092/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7170e-04 - val_loss: 5.4791e-04\n",
      "Epoch 2093/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7159e-04 - val_loss: 5.4613e-04\n",
      "Epoch 2094/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7151e-04 - val_loss: 5.4679e-04\n",
      "Epoch 2095/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7154e-04 - val_loss: 5.4479e-04\n",
      "Epoch 2096/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7155e-04 - val_loss: 5.4682e-04\n",
      "Epoch 2097/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7149e-04 - val_loss: 5.4663e-04\n",
      "Epoch 2098/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7159e-04 - val_loss: 5.4482e-04\n",
      "Epoch 2099/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7152e-04 - val_loss: 5.4528e-04\n",
      "Epoch 2100/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7160e-04 - val_loss: 5.4601e-04\n",
      "Epoch 2101/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.7160e-04 - val_loss: 5.4537e-04\n",
      "Epoch 2102/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7156e-04 - val_loss: 5.4788e-04\n",
      "Epoch 2103/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7156e-04 - val_loss: 5.4538e-04\n",
      "Epoch 2104/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7139e-04 - val_loss: 5.4612e-04\n",
      "Epoch 2105/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7136e-04 - val_loss: 5.4579e-04\n",
      "Epoch 2106/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7140e-04 - val_loss: 5.4687e-04\n",
      "Epoch 2107/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7136e-04 - val_loss: 5.4476e-04\n",
      "Epoch 2108/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7131e-04 - val_loss: 5.4593e-04\n",
      "Epoch 2109/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7150e-04 - val_loss: 5.4734e-04\n",
      "Epoch 2110/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7139e-04 - val_loss: 5.4514e-04\n",
      "Epoch 2111/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7127e-04 - val_loss: 5.4635e-04\n",
      "Epoch 2112/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7152e-04 - val_loss: 5.4851e-04\n",
      "Epoch 2113/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7134e-04 - val_loss: 5.4586e-04\n",
      "Epoch 2114/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7139e-04 - val_loss: 5.4533e-04\n",
      "Epoch 2115/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7134e-04 - val_loss: 5.4759e-04\n",
      "Epoch 2116/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7130e-04 - val_loss: 5.4618e-04\n",
      "Epoch 2117/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7128e-04 - val_loss: 5.4459e-04\n",
      "Epoch 2118/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7137e-04 - val_loss: 5.4601e-04\n",
      "Epoch 2119/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7136e-04 - val_loss: 5.4583e-04\n",
      "Epoch 2120/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7128e-04 - val_loss: 5.4596e-04\n",
      "Epoch 2121/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7124e-04 - val_loss: 5.4589e-04\n",
      "Epoch 2122/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7118e-04 - val_loss: 5.4513e-04\n",
      "Epoch 2123/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7118e-04 - val_loss: 5.4531e-04\n",
      "Epoch 2124/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7126e-04 - val_loss: 5.4473e-04\n",
      "Epoch 2125/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7119e-04 - val_loss: 5.4560e-04\n",
      "Epoch 2126/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7125e-04 - val_loss: 5.4420e-04\n",
      "Epoch 2127/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7117e-04 - val_loss: 5.4423e-04\n",
      "Epoch 2128/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7114e-04 - val_loss: 5.4554e-04\n",
      "Epoch 2129/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7100e-04 - val_loss: 5.4584e-04\n",
      "Epoch 2130/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7105e-04 - val_loss: 5.4833e-04\n",
      "Epoch 2131/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7124e-04 - val_loss: 5.4486e-04\n",
      "Epoch 2132/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7100e-04 - val_loss: 5.4524e-04\n",
      "Epoch 2133/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7111e-04 - val_loss: 5.4602e-04\n",
      "Epoch 2134/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7108e-04 - val_loss: 5.4517e-04\n",
      "Epoch 2135/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7113e-04 - val_loss: 5.4540e-04\n",
      "Epoch 2136/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.7098e-04 - val_loss: 5.4493e-04\n",
      "Epoch 2137/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7104e-04 - val_loss: 5.4496e-04\n",
      "Epoch 2138/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7101e-04 - val_loss: 5.4395e-04\n",
      "Epoch 2139/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 5.7096e-04 - val_loss: 5.4502e-04\n",
      "Epoch 2140/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7102e-04 - val_loss: 5.4440e-04\n",
      "Epoch 2141/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7111e-04 - val_loss: 5.4478e-04\n",
      "Epoch 2142/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7104e-04 - val_loss: 5.4430e-04\n",
      "Epoch 2143/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7087e-04 - val_loss: 5.4460e-04\n",
      "Epoch 2144/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7108e-04 - val_loss: 5.4728e-04\n",
      "Epoch 2145/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7104e-04 - val_loss: 5.4487e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2146/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7090e-04 - val_loss: 5.4626e-04\n",
      "Epoch 2147/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7095e-04 - val_loss: 5.4481e-04\n",
      "Epoch 2148/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7094e-04 - val_loss: 5.4591e-04\n",
      "Epoch 2149/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7086e-04 - val_loss: 5.4576e-04\n",
      "Epoch 2150/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7100e-04 - val_loss: 5.4509e-04\n",
      "Epoch 2151/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7098e-04 - val_loss: 5.4477e-04\n",
      "Epoch 2152/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7081e-04 - val_loss: 5.4447e-04\n",
      "Epoch 2153/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7085e-04 - val_loss: 5.4478e-04\n",
      "Epoch 2154/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7090e-04 - val_loss: 5.4488e-04\n",
      "Epoch 2155/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7088e-04 - val_loss: 5.4483e-04\n",
      "Epoch 2156/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7075e-04 - val_loss: 5.4460e-04\n",
      "Epoch 2157/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7082e-04 - val_loss: 5.4569e-04\n",
      "Epoch 2158/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.7090e-04 - val_loss: 5.4528e-04\n",
      "Epoch 2159/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7074e-04 - val_loss: 5.4533e-04\n",
      "Epoch 2160/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7064e-04 - val_loss: 5.4542e-04\n",
      "Epoch 2161/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7077e-04 - val_loss: 5.4622e-04\n",
      "Epoch 2162/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7073e-04 - val_loss: 5.4502e-04\n",
      "Epoch 2163/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7072e-04 - val_loss: 5.4445e-04\n",
      "Epoch 2164/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7081e-04 - val_loss: 5.4488e-04\n",
      "Epoch 2165/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7069e-04 - val_loss: 5.4596e-04\n",
      "Epoch 2166/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7071e-04 - val_loss: 5.4423e-04\n",
      "Epoch 2167/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7061e-04 - val_loss: 5.4577e-04\n",
      "Epoch 2168/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7071e-04 - val_loss: 5.4460e-04\n",
      "Epoch 2169/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7068e-04 - val_loss: 5.4457e-04\n",
      "Epoch 2170/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7065e-04 - val_loss: 5.4398e-04\n",
      "Epoch 2171/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7075e-04 - val_loss: 5.4686e-04\n",
      "Epoch 2172/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7075e-04 - val_loss: 5.4529e-04\n",
      "Epoch 2173/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7066e-04 - val_loss: 5.4548e-04\n",
      "Epoch 2174/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7076e-04 - val_loss: 5.4431e-04\n",
      "Epoch 2175/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7064e-04 - val_loss: 5.4410e-04\n",
      "Epoch 2176/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7067e-04 - val_loss: 5.4450e-04\n",
      "Epoch 2177/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7054e-04 - val_loss: 5.4438e-04\n",
      "Epoch 2178/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7057e-04 - val_loss: 5.4419e-04\n",
      "Epoch 2179/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7062e-04 - val_loss: 5.4387e-04\n",
      "Epoch 2180/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7064e-04 - val_loss: 5.4387e-04\n",
      "Epoch 2181/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7058e-04 - val_loss: 5.4488e-04\n",
      "Epoch 2182/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7051e-04 - val_loss: 5.4482e-04\n",
      "Epoch 2183/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7056e-04 - val_loss: 5.4486e-04\n",
      "Epoch 2184/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7044e-04 - val_loss: 5.4415e-04\n",
      "Epoch 2185/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7051e-04 - val_loss: 5.4549e-04\n",
      "Epoch 2186/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7051e-04 - val_loss: 5.4593e-04\n",
      "Epoch 2187/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7050e-04 - val_loss: 5.4385e-04\n",
      "Epoch 2188/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7045e-04 - val_loss: 5.4373e-04\n",
      "Epoch 2189/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7052e-04 - val_loss: 5.4324e-04\n",
      "Epoch 2190/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7062e-04 - val_loss: 5.4499e-04\n",
      "Epoch 2191/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7048e-04 - val_loss: 5.4674e-04\n",
      "Epoch 2192/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7048e-04 - val_loss: 5.4379e-04\n",
      "Epoch 2193/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7041e-04 - val_loss: 5.4434e-04\n",
      "Epoch 2194/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7052e-04 - val_loss: 5.4557e-04\n",
      "Epoch 2195/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7050e-04 - val_loss: 5.4468e-04\n",
      "Epoch 2196/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7037e-04 - val_loss: 5.4474e-04\n",
      "Epoch 2197/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7042e-04 - val_loss: 5.4535e-04\n",
      "Epoch 2198/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7048e-04 - val_loss: 5.4480e-04\n",
      "Epoch 2199/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7032e-04 - val_loss: 5.4554e-04\n",
      "Epoch 2200/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7038e-04 - val_loss: 5.4419e-04\n",
      "Epoch 2201/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7039e-04 - val_loss: 5.4648e-04\n",
      "Epoch 2202/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7024e-04 - val_loss: 5.4387e-04\n",
      "Epoch 2203/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7030e-04 - val_loss: 5.4331e-04\n",
      "Epoch 2204/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7039e-04 - val_loss: 5.4365e-04\n",
      "Epoch 2205/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7034e-04 - val_loss: 5.4337e-04\n",
      "Epoch 2206/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7044e-04 - val_loss: 5.4347e-04\n",
      "Epoch 2207/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7045e-04 - val_loss: 5.4375e-04\n",
      "Epoch 2208/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7035e-04 - val_loss: 5.4443e-04\n",
      "Epoch 2209/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7037e-04 - val_loss: 5.4587e-04\n",
      "Epoch 2210/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7031e-04 - val_loss: 5.4423e-04\n",
      "Epoch 2211/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7015e-04 - val_loss: 5.4446e-04\n",
      "Epoch 2212/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7019e-04 - val_loss: 5.4442e-04\n",
      "Epoch 2213/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7029e-04 - val_loss: 5.4454e-04\n",
      "Epoch 2214/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7013e-04 - val_loss: 5.4413e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2215/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7018e-04 - val_loss: 5.4560e-04\n",
      "Epoch 2216/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7031e-04 - val_loss: 5.4367e-04\n",
      "Epoch 2217/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7018e-04 - val_loss: 5.4371e-04\n",
      "Epoch 2218/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7011e-04 - val_loss: 5.4444e-04\n",
      "Epoch 2219/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7028e-04 - val_loss: 5.4563e-04\n",
      "Epoch 2220/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7013e-04 - val_loss: 5.4428e-04\n",
      "Epoch 2221/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7012e-04 - val_loss: 5.4427e-04\n",
      "Epoch 2222/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7021e-04 - val_loss: 5.4484e-04\n",
      "Epoch 2223/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7011e-04 - val_loss: 5.4446e-04\n",
      "Epoch 2224/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7006e-04 - val_loss: 5.4506e-04\n",
      "Epoch 2225/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7002e-04 - val_loss: 5.4642e-04\n",
      "Epoch 2226/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7010e-04 - val_loss: 5.4438e-04\n",
      "Epoch 2227/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7009e-04 - val_loss: 5.4555e-04\n",
      "Epoch 2228/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7011e-04 - val_loss: 5.4453e-04\n",
      "Epoch 2229/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7006e-04 - val_loss: 5.4319e-04\n",
      "Epoch 2230/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6999e-04 - val_loss: 5.4333e-04\n",
      "Epoch 2231/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7007e-04 - val_loss: 5.4402e-04\n",
      "Epoch 2232/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6997e-04 - val_loss: 5.4391e-04\n",
      "Epoch 2233/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6998e-04 - val_loss: 5.4352e-04\n",
      "Epoch 2234/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7012e-04 - val_loss: 5.4449e-04\n",
      "Epoch 2235/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6998e-04 - val_loss: 5.4337e-04\n",
      "Epoch 2236/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6996e-04 - val_loss: 5.4401e-04\n",
      "Epoch 2237/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7011e-04 - val_loss: 5.4322e-04\n",
      "Epoch 2238/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6992e-04 - val_loss: 5.4343e-04\n",
      "Epoch 2239/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6994e-04 - val_loss: 5.4344e-04\n",
      "Epoch 2240/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6994e-04 - val_loss: 5.4374e-04\n",
      "Epoch 2241/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7012e-04 - val_loss: 5.4331e-04\n",
      "Epoch 2242/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7002e-04 - val_loss: 5.4465e-04\n",
      "Epoch 2243/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6988e-04 - val_loss: 5.4361e-04\n",
      "Epoch 2244/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7002e-04 - val_loss: 5.4416e-04\n",
      "Epoch 2245/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7006e-04 - val_loss: 5.4470e-04\n",
      "Epoch 2246/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6980e-04 - val_loss: 5.4450e-04\n",
      "Epoch 2247/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6985e-04 - val_loss: 5.4378e-04\n",
      "Epoch 2248/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6976e-04 - val_loss: 5.4360e-04\n",
      "Epoch 2249/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6983e-04 - val_loss: 5.4304e-04\n",
      "Epoch 2250/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6994e-04 - val_loss: 5.4396e-04\n",
      "Epoch 2251/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6987e-04 - val_loss: 5.4447e-04\n",
      "Epoch 2252/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6984e-04 - val_loss: 5.4490e-04\n",
      "Epoch 2253/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6987e-04 - val_loss: 5.4380e-04\n",
      "Epoch 2254/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6982e-04 - val_loss: 5.4368e-04\n",
      "Epoch 2255/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6991e-04 - val_loss: 5.4358e-04\n",
      "Epoch 2256/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6984e-04 - val_loss: 5.4365e-04\n",
      "Epoch 2257/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6987e-04 - val_loss: 5.4398e-04\n",
      "Epoch 2258/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6973e-04 - val_loss: 5.4325e-04\n",
      "Epoch 2259/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6979e-04 - val_loss: 5.4455e-04\n",
      "Epoch 2260/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6973e-04 - val_loss: 5.4398e-04\n",
      "Epoch 2261/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6977e-04 - val_loss: 5.4442e-04\n",
      "Epoch 2262/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6984e-04 - val_loss: 5.4351e-04\n",
      "Epoch 2263/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6970e-04 - val_loss: 5.4475e-04\n",
      "Epoch 2264/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6975e-04 - val_loss: 5.4413e-04\n",
      "Epoch 2265/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6977e-04 - val_loss: 5.4519e-04\n",
      "Epoch 2266/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6964e-04 - val_loss: 5.4470e-04\n",
      "Epoch 2267/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6964e-04 - val_loss: 5.4319e-04\n",
      "Epoch 2268/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6971e-04 - val_loss: 5.4330e-04\n",
      "Epoch 2269/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6978e-04 - val_loss: 5.4460e-04\n",
      "Epoch 2270/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6973e-04 - val_loss: 5.4371e-04\n",
      "Epoch 2271/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6959e-04 - val_loss: 5.4346e-04\n",
      "Epoch 2272/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6961e-04 - val_loss: 5.4467e-04\n",
      "Epoch 2273/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6965e-04 - val_loss: 5.4351e-04\n",
      "Epoch 2274/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6964e-04 - val_loss: 5.4371e-04\n",
      "Epoch 2275/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6956e-04 - val_loss: 5.4406e-04\n",
      "Epoch 2276/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6964e-04 - val_loss: 5.4323e-04\n",
      "Epoch 2277/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6970e-04 - val_loss: 5.4380e-04\n",
      "Epoch 2278/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6969e-04 - val_loss: 5.4496e-04\n",
      "Epoch 2279/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6958e-04 - val_loss: 5.4414e-04\n",
      "Epoch 2280/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6959e-04 - val_loss: 5.4442e-04\n",
      "Epoch 2281/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6972e-04 - val_loss: 5.4341e-04\n",
      "Epoch 2282/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6951e-04 - val_loss: 5.4290e-04\n",
      "Epoch 2283/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6953e-04 - val_loss: 5.4301e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2284/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6960e-04 - val_loss: 5.4308e-04\n",
      "Epoch 2285/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6957e-04 - val_loss: 5.4546e-04\n",
      "Epoch 2286/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6954e-04 - val_loss: 5.4427e-04\n",
      "Epoch 2287/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6958e-04 - val_loss: 5.4375e-04\n",
      "Epoch 2288/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6951e-04 - val_loss: 5.4438e-04\n",
      "Epoch 2289/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6961e-04 - val_loss: 5.4411e-04\n",
      "Epoch 2290/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6951e-04 - val_loss: 5.4345e-04\n",
      "Epoch 2291/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6951e-04 - val_loss: 5.4574e-04\n",
      "Epoch 2292/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6940e-04 - val_loss: 5.4300e-04\n",
      "Epoch 2293/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6948e-04 - val_loss: 5.4423e-04\n",
      "Epoch 2294/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6956e-04 - val_loss: 5.4340e-04\n",
      "Epoch 2295/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6945e-04 - val_loss: 5.4346e-04\n",
      "Epoch 2296/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6943e-04 - val_loss: 5.4387e-04\n",
      "Epoch 2297/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6944e-04 - val_loss: 5.4473e-04\n",
      "Epoch 2298/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6944e-04 - val_loss: 5.4450e-04\n",
      "Epoch 2299/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6942e-04 - val_loss: 5.4395e-04\n",
      "Epoch 2300/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6947e-04 - val_loss: 5.4344e-04\n",
      "Epoch 2301/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6949e-04 - val_loss: 5.4480e-04\n",
      "Epoch 2302/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6935e-04 - val_loss: 5.4411e-04\n",
      "Epoch 2303/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6943e-04 - val_loss: 5.4401e-04\n",
      "Epoch 2304/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6932e-04 - val_loss: 5.4383e-04\n",
      "Epoch 2305/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6936e-04 - val_loss: 5.4440e-04\n",
      "Epoch 2306/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6947e-04 - val_loss: 5.4637e-04\n",
      "Epoch 2307/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6937e-04 - val_loss: 5.4331e-04\n",
      "Epoch 2308/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6938e-04 - val_loss: 5.4294e-04\n",
      "Epoch 2309/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6935e-04 - val_loss: 5.4626e-04\n",
      "Epoch 2310/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6936e-04 - val_loss: 5.4325e-04\n",
      "Epoch 2311/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6928e-04 - val_loss: 5.4376e-04\n",
      "Epoch 2312/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6928e-04 - val_loss: 5.4474e-04\n",
      "Epoch 2313/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6939e-04 - val_loss: 5.4392e-04\n",
      "Epoch 2314/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6922e-04 - val_loss: 5.4365e-04\n",
      "Epoch 2315/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6929e-04 - val_loss: 5.4313e-04\n",
      "Epoch 2316/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6930e-04 - val_loss: 5.4340e-04\n",
      "Epoch 2317/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6931e-04 - val_loss: 5.4297e-04\n",
      "Epoch 2318/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6915e-04 - val_loss: 5.4452e-04\n",
      "Epoch 2319/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6921e-04 - val_loss: 5.4529e-04\n",
      "Epoch 2320/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6930e-04 - val_loss: 5.4360e-04\n",
      "Epoch 2321/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6921e-04 - val_loss: 5.4308e-04\n",
      "Epoch 2322/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6922e-04 - val_loss: 5.4444e-04\n",
      "Epoch 2323/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6921e-04 - val_loss: 5.4429e-04\n",
      "Epoch 2324/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6932e-04 - val_loss: 5.4580e-04\n",
      "Epoch 2325/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6923e-04 - val_loss: 5.4376e-04\n",
      "Epoch 2326/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6912e-04 - val_loss: 5.4470e-04\n",
      "Epoch 2327/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6912e-04 - val_loss: 5.4306e-04\n",
      "Epoch 2328/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6918e-04 - val_loss: 5.4341e-04\n",
      "Epoch 2329/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6917e-04 - val_loss: 5.4297e-04\n",
      "Epoch 2330/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6912e-04 - val_loss: 5.4426e-04\n",
      "Epoch 2331/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6912e-04 - val_loss: 5.4338e-04\n",
      "Epoch 2332/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6917e-04 - val_loss: 5.4342e-04\n",
      "Epoch 2333/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6914e-04 - val_loss: 5.4430e-04\n",
      "Epoch 2334/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6908e-04 - val_loss: 5.4272e-04\n",
      "Epoch 2335/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6906e-04 - val_loss: 5.4345e-04\n",
      "Epoch 2336/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6907e-04 - val_loss: 5.4483e-04\n",
      "Epoch 2337/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6895e-04 - val_loss: 5.4366e-04\n",
      "Epoch 2338/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6910e-04 - val_loss: 5.4630e-04\n",
      "Epoch 2339/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6915e-04 - val_loss: 5.4411e-04\n",
      "Epoch 2340/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6915e-04 - val_loss: 5.4545e-04\n",
      "Epoch 2341/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6909e-04 - val_loss: 5.4402e-04\n",
      "Epoch 2342/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6897e-04 - val_loss: 5.4213e-04\n",
      "Epoch 2343/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6907e-04 - val_loss: 5.4420e-04\n",
      "Epoch 2344/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6912e-04 - val_loss: 5.4394e-04\n",
      "Epoch 2345/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6897e-04 - val_loss: 5.4415e-04\n",
      "Epoch 2346/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6900e-04 - val_loss: 5.4367e-04\n",
      "Epoch 2347/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6900e-04 - val_loss: 5.4415e-04\n",
      "Epoch 2348/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6902e-04 - val_loss: 5.4331e-04\n",
      "Epoch 2349/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6894e-04 - val_loss: 5.4372e-04\n",
      "Epoch 2350/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6898e-04 - val_loss: 5.4296e-04\n",
      "Epoch 2351/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6901e-04 - val_loss: 5.4498e-04\n",
      "Epoch 2352/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6891e-04 - val_loss: 5.4440e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2353/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6900e-04 - val_loss: 5.4296e-04\n",
      "Epoch 2354/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6893e-04 - val_loss: 5.4440e-04\n",
      "Epoch 2355/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6898e-04 - val_loss: 5.4478e-04\n",
      "Epoch 2356/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6900e-04 - val_loss: 5.4589e-04\n",
      "Epoch 2357/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6887e-04 - val_loss: 5.4372e-04\n",
      "Epoch 2358/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6891e-04 - val_loss: 5.4472e-04\n",
      "Epoch 2359/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6891e-04 - val_loss: 5.4454e-04\n",
      "Epoch 2360/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6889e-04 - val_loss: 5.4424e-04\n",
      "Epoch 2361/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6887e-04 - val_loss: 5.4527e-04\n",
      "Epoch 2362/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6877e-04 - val_loss: 5.4366e-04\n",
      "Epoch 2363/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6888e-04 - val_loss: 5.4347e-04\n",
      "Epoch 2364/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6886e-04 - val_loss: 5.4471e-04\n",
      "Epoch 2365/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6880e-04 - val_loss: 5.4372e-04\n",
      "Epoch 2366/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6879e-04 - val_loss: 5.4283e-04\n",
      "Epoch 2367/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6887e-04 - val_loss: 5.4461e-04\n",
      "Epoch 2368/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6887e-04 - val_loss: 5.4441e-04\n",
      "Epoch 2369/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6892e-04 - val_loss: 5.4278e-04\n",
      "Epoch 2370/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6884e-04 - val_loss: 5.4452e-04\n",
      "Epoch 2371/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6876e-04 - val_loss: 5.4481e-04\n",
      "Epoch 2372/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6884e-04 - val_loss: 5.4484e-04\n",
      "Epoch 2373/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6882e-04 - val_loss: 5.4369e-04\n",
      "Epoch 2374/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6871e-04 - val_loss: 5.4504e-04\n",
      "Epoch 2375/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6865e-04 - val_loss: 5.4431e-04\n",
      "Epoch 2376/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6879e-04 - val_loss: 5.4341e-04\n",
      "Epoch 2377/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6876e-04 - val_loss: 5.4397e-04\n",
      "Epoch 2378/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6876e-04 - val_loss: 5.4496e-04\n",
      "Epoch 2379/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6877e-04 - val_loss: 5.4373e-04\n",
      "Epoch 2380/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6868e-04 - val_loss: 5.4267e-04\n",
      "Epoch 2381/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6864e-04 - val_loss: 5.4470e-04\n",
      "Epoch 2382/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6863e-04 - val_loss: 5.4402e-04\n",
      "Epoch 2383/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6870e-04 - val_loss: 5.4477e-04\n",
      "Epoch 2384/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6882e-04 - val_loss: 5.4302e-04\n",
      "Epoch 2385/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6868e-04 - val_loss: 5.4451e-04\n",
      "Epoch 2386/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6873e-04 - val_loss: 5.4481e-04\n",
      "Epoch 2387/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6865e-04 - val_loss: 5.4340e-04\n",
      "Epoch 2388/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6868e-04 - val_loss: 5.4537e-04\n",
      "Epoch 2389/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6860e-04 - val_loss: 5.4401e-04\n",
      "Epoch 2390/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6865e-04 - val_loss: 5.4411e-04\n",
      "Epoch 2391/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6863e-04 - val_loss: 5.4314e-04\n",
      "Epoch 2392/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6875e-04 - val_loss: 5.4245e-04\n",
      "Epoch 2393/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6863e-04 - val_loss: 5.4483e-04\n",
      "Epoch 2394/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6861e-04 - val_loss: 5.4546e-04\n",
      "Epoch 2395/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.6862e-04 - val_loss: 5.4452e-04\n",
      "Epoch 2396/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6858e-04 - val_loss: 5.4461e-04\n",
      "Epoch 2397/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6858e-04 - val_loss: 5.4475e-04\n",
      "Epoch 2398/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6859e-04 - val_loss: 5.4369e-04\n",
      "Epoch 2399/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6860e-04 - val_loss: 5.4571e-04\n",
      "Epoch 2400/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6860e-04 - val_loss: 5.4216e-04\n",
      "Epoch 2401/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6863e-04 - val_loss: 5.4461e-04\n",
      "Epoch 2402/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6860e-04 - val_loss: 5.4613e-04\n",
      "Epoch 2403/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6852e-04 - val_loss: 5.4322e-04\n",
      "Epoch 2404/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6852e-04 - val_loss: 5.4386e-04\n",
      "Epoch 2405/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6852e-04 - val_loss: 5.4461e-04\n",
      "Epoch 2406/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6858e-04 - val_loss: 5.4509e-04\n",
      "Epoch 2407/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6844e-04 - val_loss: 5.4415e-04\n",
      "Epoch 2408/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6846e-04 - val_loss: 5.4419e-04\n",
      "Epoch 2409/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6844e-04 - val_loss: 5.4360e-04\n",
      "Epoch 2410/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6853e-04 - val_loss: 5.4559e-04\n",
      "Epoch 2411/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6854e-04 - val_loss: 5.4295e-04\n",
      "Epoch 2412/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6850e-04 - val_loss: 5.4569e-04\n",
      "Epoch 2413/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6857e-04 - val_loss: 5.4548e-04\n",
      "Epoch 2414/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6841e-04 - val_loss: 5.4514e-04\n",
      "Epoch 2415/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6847e-04 - val_loss: 5.4292e-04\n",
      "Epoch 2416/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6842e-04 - val_loss: 5.4486e-04\n",
      "Epoch 2417/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6836e-04 - val_loss: 5.4390e-04\n",
      "Epoch 2418/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6837e-04 - val_loss: 5.4492e-04\n",
      "Epoch 2419/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6850e-04 - val_loss: 5.4427e-04\n",
      "Epoch 2420/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6848e-04 - val_loss: 5.4339e-04\n",
      "Epoch 2421/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6838e-04 - val_loss: 5.4348e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2422/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6837e-04 - val_loss: 5.4296e-04\n",
      "Epoch 2423/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6839e-04 - val_loss: 5.4301e-04\n",
      "Epoch 2424/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6836e-04 - val_loss: 5.4544e-04\n",
      "Epoch 2425/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6838e-04 - val_loss: 5.4580e-04\n",
      "Epoch 2426/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6837e-04 - val_loss: 5.4470e-04\n",
      "Epoch 2427/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6834e-04 - val_loss: 5.4458e-04\n",
      "Epoch 2428/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6833e-04 - val_loss: 5.4418e-04\n",
      "Epoch 2429/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6826e-04 - val_loss: 5.4466e-04\n",
      "Epoch 2430/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6840e-04 - val_loss: 5.4496e-04\n",
      "Epoch 2431/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6829e-04 - val_loss: 5.4511e-04\n",
      "Epoch 2432/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6824e-04 - val_loss: 5.4402e-04\n",
      "Epoch 2433/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6833e-04 - val_loss: 5.4352e-04\n",
      "Epoch 2434/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6831e-04 - val_loss: 5.4721e-04\n",
      "Epoch 2435/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6830e-04 - val_loss: 5.4353e-04\n",
      "Epoch 2436/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6834e-04 - val_loss: 5.4403e-04\n",
      "Epoch 2437/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6818e-04 - val_loss: 5.4514e-04\n",
      "Epoch 2438/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 5.6827e-04 - val_loss: 5.4462e-04\n",
      "Epoch 2439/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6835e-04 - val_loss: 5.4348e-04\n",
      "Epoch 2440/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6821e-04 - val_loss: 5.4437e-04\n",
      "Epoch 2441/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6818e-04 - val_loss: 5.4400e-04\n",
      "Epoch 2442/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6833e-04 - val_loss: 5.4407e-04\n",
      "Epoch 2443/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6818e-04 - val_loss: 5.4416e-04\n",
      "Epoch 2444/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6822e-04 - val_loss: 5.4630e-04\n",
      "Epoch 2445/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6819e-04 - val_loss: 5.4363e-04\n",
      "Epoch 2446/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6816e-04 - val_loss: 5.4506e-04\n",
      "Epoch 2447/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6827e-04 - val_loss: 5.4294e-04\n",
      "Epoch 2448/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6818e-04 - val_loss: 5.4463e-04\n",
      "Epoch 2449/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6816e-04 - val_loss: 5.4553e-04\n",
      "Epoch 2450/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6819e-04 - val_loss: 5.4282e-04\n",
      "Epoch 2451/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6816e-04 - val_loss: 5.4650e-04\n",
      "Epoch 2452/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6822e-04 - val_loss: 5.4451e-04\n",
      "Epoch 2453/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6809e-04 - val_loss: 5.4405e-04\n",
      "Epoch 2454/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6810e-04 - val_loss: 5.4341e-04\n",
      "Epoch 2455/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6809e-04 - val_loss: 5.4462e-04\n",
      "Epoch 2456/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6815e-04 - val_loss: 5.4475e-04\n",
      "Epoch 2457/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6809e-04 - val_loss: 5.4467e-04\n",
      "Epoch 2458/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6808e-04 - val_loss: 5.4419e-04\n",
      "Epoch 2459/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6803e-04 - val_loss: 5.4498e-04\n",
      "Epoch 2460/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6806e-04 - val_loss: 5.4302e-04\n",
      "Epoch 2461/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6804e-04 - val_loss: 5.4394e-04\n",
      "Epoch 2462/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6806e-04 - val_loss: 5.4458e-04\n",
      "Epoch 2463/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6798e-04 - val_loss: 5.4244e-04\n",
      "Epoch 2464/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6809e-04 - val_loss: 5.4398e-04\n",
      "Epoch 2465/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6807e-04 - val_loss: 5.4443e-04\n",
      "Epoch 2466/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6802e-04 - val_loss: 5.4454e-04\n",
      "Epoch 2467/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6813e-04 - val_loss: 5.4487e-04\n",
      "Epoch 2468/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6813e-04 - val_loss: 5.4340e-04\n",
      "Epoch 2469/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6799e-04 - val_loss: 5.4334e-04\n",
      "Epoch 2470/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6813e-04 - val_loss: 5.4465e-04\n",
      "Epoch 2471/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6799e-04 - val_loss: 5.4475e-04\n",
      "Epoch 2472/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6805e-04 - val_loss: 5.4407e-04\n",
      "Epoch 2473/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6800e-04 - val_loss: 5.4481e-04\n",
      "Epoch 2474/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6796e-04 - val_loss: 5.4446e-04\n",
      "Epoch 2475/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6800e-04 - val_loss: 5.4486e-04\n",
      "Epoch 2476/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6800e-04 - val_loss: 5.4452e-04\n",
      "Epoch 2477/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6796e-04 - val_loss: 5.4373e-04\n",
      "Epoch 2478/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6797e-04 - val_loss: 5.4378e-04\n",
      "Epoch 2479/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6788e-04 - val_loss: 5.4426e-04\n",
      "Epoch 2480/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6794e-04 - val_loss: 5.4510e-04\n",
      "Epoch 2481/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6796e-04 - val_loss: 5.4552e-04\n",
      "Epoch 2482/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6803e-04 - val_loss: 5.4246e-04\n",
      "Epoch 2483/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6792e-04 - val_loss: 5.4541e-04\n",
      "Epoch 2484/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6789e-04 - val_loss: 5.4333e-04\n",
      "Epoch 2485/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.6791e-04 - val_loss: 5.4630e-04\n",
      "Epoch 2486/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6792e-04 - val_loss: 5.4553e-04\n",
      "Epoch 2487/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6793e-04 - val_loss: 5.4441e-04\n",
      "Epoch 2488/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6780e-04 - val_loss: 5.4409e-04\n",
      "Epoch 2489/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6785e-04 - val_loss: 5.4522e-04\n",
      "Epoch 2490/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6797e-04 - val_loss: 5.4471e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2491/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6786e-04 - val_loss: 5.4603e-04\n",
      "Epoch 2492/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6794e-04 - val_loss: 5.4279e-04\n",
      "Epoch 2493/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6783e-04 - val_loss: 5.4283e-04\n",
      "Epoch 2494/10000\n",
      "45507/45507 [==============================] - 1s 23us/step - loss: 5.6787e-04 - val_loss: 5.4612e-04\n",
      "Epoch 2495/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6786e-04 - val_loss: 5.4577e-04\n",
      "Epoch 2496/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6789e-04 - val_loss: 5.4539e-04\n",
      "Epoch 2497/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6794e-04 - val_loss: 5.4451e-04\n",
      "Epoch 2498/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6774e-04 - val_loss: 5.4434e-04\n",
      "Epoch 2499/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6771e-04 - val_loss: 5.4491e-04\n",
      "Epoch 2500/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6781e-04 - val_loss: 5.4369e-04\n",
      "Epoch 2501/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6775e-04 - val_loss: 5.4389e-04\n",
      "Epoch 2502/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6776e-04 - val_loss: 5.4486e-04\n",
      "Epoch 2503/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6773e-04 - val_loss: 5.4449e-04\n",
      "Epoch 2504/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6782e-04 - val_loss: 5.4551e-04\n",
      "Epoch 2505/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6781e-04 - val_loss: 5.4520e-04\n",
      "Epoch 2506/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6785e-04 - val_loss: 5.4425e-04\n",
      "Epoch 2507/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6776e-04 - val_loss: 5.4425e-04\n",
      "Epoch 2508/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6781e-04 - val_loss: 5.4267e-04\n",
      "Epoch 2509/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6765e-04 - val_loss: 5.4400e-04\n",
      "Epoch 2510/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6773e-04 - val_loss: 5.4530e-04\n",
      "Epoch 2511/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6764e-04 - val_loss: 5.4590e-04\n",
      "Epoch 2512/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6769e-04 - val_loss: 5.4534e-04\n",
      "Epoch 2513/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6775e-04 - val_loss: 5.4281e-04\n",
      "Epoch 2514/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6765e-04 - val_loss: 5.4483e-04\n",
      "Epoch 2515/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6768e-04 - val_loss: 5.4417e-04\n",
      "Epoch 2516/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6772e-04 - val_loss: 5.4466e-04\n",
      "Epoch 2517/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6771e-04 - val_loss: 5.4385e-04\n",
      "Epoch 2518/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6768e-04 - val_loss: 5.4407e-04\n",
      "Epoch 2519/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6778e-04 - val_loss: 5.4352e-04\n",
      "Epoch 2520/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6761e-04 - val_loss: 5.4468e-04\n",
      "Epoch 2521/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6764e-04 - val_loss: 5.4382e-04\n",
      "Epoch 2522/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6755e-04 - val_loss: 5.4289e-04\n",
      "Epoch 2523/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6764e-04 - val_loss: 5.4607e-04\n",
      "Epoch 2524/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6764e-04 - val_loss: 5.4460e-04\n",
      "Epoch 2525/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6766e-04 - val_loss: 5.4550e-04\n",
      "Epoch 2526/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6766e-04 - val_loss: 5.4476e-04\n",
      "Epoch 2527/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6755e-04 - val_loss: 5.4493e-04\n",
      "Epoch 2528/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6775e-04 - val_loss: 5.4279e-04\n",
      "Epoch 2529/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6757e-04 - val_loss: 5.4413e-04\n",
      "Epoch 2530/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6761e-04 - val_loss: 5.4608e-04\n",
      "Epoch 2531/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6754e-04 - val_loss: 5.4531e-04\n",
      "Epoch 2532/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6746e-04 - val_loss: 5.4358e-04\n",
      "Epoch 2533/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6755e-04 - val_loss: 5.4431e-04\n",
      "Epoch 2534/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6762e-04 - val_loss: 5.4313e-04\n",
      "Epoch 2535/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6752e-04 - val_loss: 5.4412e-04\n",
      "Epoch 2536/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6757e-04 - val_loss: 5.4520e-04\n",
      "Epoch 2537/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6752e-04 - val_loss: 5.4423e-04\n",
      "Epoch 2538/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6750e-04 - val_loss: 5.4544e-04\n",
      "Epoch 2539/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6757e-04 - val_loss: 5.4796e-04\n",
      "Epoch 2540/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6749e-04 - val_loss: 5.4506e-04\n",
      "Epoch 2541/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6744e-04 - val_loss: 5.4389e-04\n",
      "Epoch 2542/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6749e-04 - val_loss: 5.4511e-04\n",
      "Epoch 2543/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6762e-04 - val_loss: 5.4414e-04\n",
      "Epoch 2544/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6744e-04 - val_loss: 5.4456e-04\n",
      "Epoch 2545/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6754e-04 - val_loss: 5.4326e-04\n",
      "Epoch 2546/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6742e-04 - val_loss: 5.4255e-04\n",
      "Epoch 2547/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6746e-04 - val_loss: 5.4402e-04\n",
      "Epoch 2548/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6737e-04 - val_loss: 5.4710e-04\n",
      "Epoch 2549/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6752e-04 - val_loss: 5.4455e-04\n",
      "Epoch 2550/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6742e-04 - val_loss: 5.4482e-04\n",
      "Epoch 2551/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6753e-04 - val_loss: 5.4290e-04\n",
      "Epoch 2552/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6751e-04 - val_loss: 5.4379e-04\n",
      "Epoch 2553/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6738e-04 - val_loss: 5.4469e-04\n",
      "Epoch 2554/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6744e-04 - val_loss: 5.4419e-04\n",
      "Epoch 2555/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6729e-04 - val_loss: 5.4460e-04\n",
      "Epoch 2556/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6741e-04 - val_loss: 5.4303e-04\n",
      "Epoch 2557/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6743e-04 - val_loss: 5.4534e-04\n",
      "Epoch 2558/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6742e-04 - val_loss: 5.4584e-04\n",
      "Epoch 2559/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6742e-04 - val_loss: 5.4457e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2560/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6735e-04 - val_loss: 5.4370e-04\n",
      "Epoch 2561/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6723e-04 - val_loss: 5.4900e-04\n",
      "Epoch 2562/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6734e-04 - val_loss: 5.4620e-04\n",
      "Epoch 2563/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6732e-04 - val_loss: 5.4472e-04\n",
      "Epoch 2564/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6735e-04 - val_loss: 5.4528e-04\n",
      "Epoch 2565/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6738e-04 - val_loss: 5.4463e-04\n",
      "Epoch 2566/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6728e-04 - val_loss: 5.4464e-04\n",
      "Epoch 2567/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6724e-04 - val_loss: 5.4593e-04\n",
      "Epoch 2568/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6726e-04 - val_loss: 5.4404e-04\n",
      "Epoch 2569/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6716e-04 - val_loss: 5.4434e-04\n",
      "Epoch 2570/10000\n",
      "45507/45507 [==============================] - 1s 21us/step - loss: 5.6743e-04 - val_loss: 5.4375e-04\n",
      "Epoch 2571/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6730e-04 - val_loss: 5.4352e-04\n",
      "Epoch 2572/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6726e-04 - val_loss: 5.4517e-04\n",
      "Epoch 2573/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6725e-04 - val_loss: 5.4411e-04\n",
      "Epoch 2574/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6719e-04 - val_loss: 5.4589e-04\n",
      "Epoch 2575/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6721e-04 - val_loss: 5.4482e-04\n",
      "Epoch 2576/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6729e-04 - val_loss: 5.4561e-04\n",
      "Epoch 2577/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6724e-04 - val_loss: 5.4413e-04\n",
      "Epoch 2578/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6730e-04 - val_loss: 5.4593e-04\n",
      "Epoch 2579/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6727e-04 - val_loss: 5.4400e-04\n",
      "Epoch 2580/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6721e-04 - val_loss: 5.4396e-04\n",
      "Epoch 2581/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6719e-04 - val_loss: 5.4367e-04\n",
      "Epoch 2582/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6721e-04 - val_loss: 5.4357e-04\n",
      "Epoch 2583/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6714e-04 - val_loss: 5.4328e-04\n",
      "Epoch 2584/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6709e-04 - val_loss: 5.4443e-04\n",
      "Epoch 2585/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6713e-04 - val_loss: 5.4412e-04\n",
      "Epoch 2586/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6720e-04 - val_loss: 5.4375e-04\n",
      "Epoch 2587/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6709e-04 - val_loss: 5.4397e-04\n",
      "Epoch 2588/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6711e-04 - val_loss: 5.4572e-04\n",
      "Epoch 2589/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6713e-04 - val_loss: 5.4431e-04\n",
      "Epoch 2590/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6712e-04 - val_loss: 5.4386e-04\n",
      "Epoch 2591/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6705e-04 - val_loss: 5.4515e-04\n",
      "Epoch 2592/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6718e-04 - val_loss: 5.4397e-04\n",
      "Epoch 2593/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6715e-04 - val_loss: 5.4368e-04\n",
      "Epoch 2594/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6725e-04 - val_loss: 5.4419e-04\n",
      "Epoch 2595/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6711e-04 - val_loss: 5.4434e-04\n",
      "Epoch 2596/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6706e-04 - val_loss: 5.4350e-04\n",
      "Epoch 2597/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6714e-04 - val_loss: 5.4563e-04\n",
      "Epoch 2598/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6709e-04 - val_loss: 5.4643e-04\n",
      "Epoch 2599/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6702e-04 - val_loss: 5.4465e-04\n",
      "Epoch 2600/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6715e-04 - val_loss: 5.4433e-04\n",
      "Epoch 2601/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6698e-04 - val_loss: 5.4314e-04\n",
      "Epoch 2602/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6711e-04 - val_loss: 5.4341e-04\n",
      "Epoch 2603/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6713e-04 - val_loss: 5.4317e-04\n",
      "Epoch 2604/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6716e-04 - val_loss: 5.4971e-04\n",
      "Epoch 2605/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6709e-04 - val_loss: 5.4330e-04\n",
      "Epoch 2606/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6708e-04 - val_loss: 5.4515e-04\n",
      "Epoch 2607/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6711e-04 - val_loss: 5.4409e-04\n",
      "Epoch 2608/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6697e-04 - val_loss: 5.4441e-04\n",
      "Epoch 2609/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.6699e-04 - val_loss: 5.4376e-04\n",
      "Epoch 2610/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6698e-04 - val_loss: 5.4637e-04\n",
      "Epoch 2611/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6697e-04 - val_loss: 5.4408e-04\n",
      "Epoch 2612/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6709e-04 - val_loss: 5.4436e-04\n",
      "Epoch 2613/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6704e-04 - val_loss: 5.4457e-04\n",
      "Epoch 2614/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6702e-04 - val_loss: 5.4597e-04\n",
      "Epoch 2615/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6693e-04 - val_loss: 5.4565e-04\n",
      "Epoch 2616/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6697e-04 - val_loss: 5.4309e-04\n",
      "Epoch 2617/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6698e-04 - val_loss: 5.4465e-04\n",
      "Epoch 2618/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6688e-04 - val_loss: 5.4415e-04\n",
      "Epoch 2619/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6685e-04 - val_loss: 5.4636e-04\n",
      "Epoch 2620/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6695e-04 - val_loss: 5.4348e-04\n",
      "Epoch 2621/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6690e-04 - val_loss: 5.4398e-04\n",
      "Epoch 2622/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6701e-04 - val_loss: 5.4780e-04\n",
      "Epoch 2623/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6697e-04 - val_loss: 5.4543e-04\n",
      "Epoch 2624/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6695e-04 - val_loss: 5.4460e-04\n",
      "Epoch 2625/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6702e-04 - val_loss: 5.4468e-04\n",
      "Epoch 2626/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6694e-04 - val_loss: 5.4544e-04\n",
      "Epoch 2627/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.6690e-04 - val_loss: 5.4312e-04\n",
      "Epoch 2628/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6692e-04 - val_loss: 5.4341e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2629/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6705e-04 - val_loss: 5.4396e-04\n",
      "Epoch 2630/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6690e-04 - val_loss: 5.4314e-04\n",
      "Epoch 2631/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6688e-04 - val_loss: 5.4580e-04\n",
      "Epoch 2632/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6677e-04 - val_loss: 5.4326e-04\n",
      "Epoch 2633/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6685e-04 - val_loss: 5.4508e-04\n",
      "Epoch 2634/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6680e-04 - val_loss: 5.4486e-04\n",
      "Epoch 2635/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6690e-04 - val_loss: 5.4513e-04\n",
      "Epoch 2636/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6692e-04 - val_loss: 5.4617e-04\n",
      "Epoch 2637/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6681e-04 - val_loss: 5.4375e-04\n",
      "Epoch 2638/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6686e-04 - val_loss: 5.4445e-04\n",
      "Epoch 2639/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6684e-04 - val_loss: 5.4522e-04\n",
      "Epoch 2640/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6688e-04 - val_loss: 5.4419e-04\n",
      "Epoch 2641/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6684e-04 - val_loss: 5.4341e-04\n",
      "Epoch 2642/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6686e-04 - val_loss: 5.4350e-04\n",
      "Epoch 2643/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6675e-04 - val_loss: 5.4334e-04\n",
      "Epoch 2644/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6678e-04 - val_loss: 5.4529e-04\n",
      "Epoch 2645/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6673e-04 - val_loss: 5.4531e-04\n",
      "Epoch 2646/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6686e-04 - val_loss: 5.4498e-04\n",
      "Epoch 2647/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6689e-04 - val_loss: 5.4349e-04\n",
      "Epoch 2648/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6677e-04 - val_loss: 5.4511e-04\n",
      "Epoch 2649/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6683e-04 - val_loss: 5.4394e-04\n",
      "Epoch 2650/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6676e-04 - val_loss: 5.4466e-04\n",
      "Epoch 2651/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6675e-04 - val_loss: 5.4486e-04\n",
      "Epoch 2652/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6672e-04 - val_loss: 5.4379e-04\n",
      "Epoch 2653/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6669e-04 - val_loss: 5.4590e-04\n",
      "Epoch 2654/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6680e-04 - val_loss: 5.4465e-04\n",
      "Epoch 2655/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6676e-04 - val_loss: 5.4501e-04\n",
      "Epoch 2656/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6677e-04 - val_loss: 5.4380e-04\n",
      "Epoch 2657/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6670e-04 - val_loss: 5.4445e-04\n",
      "Epoch 2658/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6678e-04 - val_loss: 5.4400e-04\n",
      "Epoch 2659/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6672e-04 - val_loss: 5.4331e-04\n",
      "Epoch 2660/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6677e-04 - val_loss: 5.4489e-04\n",
      "Epoch 2661/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6676e-04 - val_loss: 5.4388e-04\n",
      "Epoch 2662/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6674e-04 - val_loss: 5.4449e-04\n",
      "Epoch 2663/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6667e-04 - val_loss: 5.4450e-04\n",
      "Epoch 2664/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6661e-04 - val_loss: 5.4345e-04\n",
      "Epoch 2665/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6669e-04 - val_loss: 5.4581e-04\n",
      "Epoch 2666/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6656e-04 - val_loss: 5.4681e-04\n",
      "Epoch 2667/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6664e-04 - val_loss: 5.4272e-04\n",
      "Epoch 2668/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6670e-04 - val_loss: 5.4373e-04\n",
      "Epoch 2669/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6668e-04 - val_loss: 5.4460e-04\n",
      "Epoch 2670/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6662e-04 - val_loss: 5.4523e-04\n",
      "Epoch 2671/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6666e-04 - val_loss: 5.4482e-04\n",
      "Epoch 2672/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6663e-04 - val_loss: 5.4484e-04\n",
      "Epoch 2673/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6669e-04 - val_loss: 5.4398e-04\n",
      "Epoch 2674/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6659e-04 - val_loss: 5.4387e-04\n",
      "Epoch 2675/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6655e-04 - val_loss: 5.4421e-04\n",
      "Epoch 2676/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6657e-04 - val_loss: 5.4328e-04\n",
      "Epoch 2677/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6653e-04 - val_loss: 5.4498e-04\n",
      "Epoch 2678/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6662e-04 - val_loss: 5.4526e-04\n",
      "Epoch 2679/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6667e-04 - val_loss: 5.4480e-04\n",
      "Epoch 2680/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6657e-04 - val_loss: 5.4387e-04\n",
      "Epoch 2681/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6660e-04 - val_loss: 5.4346e-04\n",
      "Epoch 2682/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6660e-04 - val_loss: 5.4304e-04\n",
      "Epoch 2683/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6653e-04 - val_loss: 5.4491e-04\n",
      "Epoch 2684/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6652e-04 - val_loss: 5.4359e-04\n",
      "Epoch 2685/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6661e-04 - val_loss: 5.4437e-04\n",
      "Epoch 2686/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6643e-04 - val_loss: 5.4420e-04\n",
      "Epoch 2687/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6651e-04 - val_loss: 5.4453e-04\n",
      "Epoch 2688/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6654e-04 - val_loss: 5.4546e-04\n",
      "Epoch 2689/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6658e-04 - val_loss: 5.4332e-04\n",
      "Epoch 2690/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6653e-04 - val_loss: 5.4554e-04\n",
      "Epoch 2691/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6659e-04 - val_loss: 5.4551e-04\n",
      "Epoch 2692/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6665e-04 - val_loss: 5.4534e-04\n",
      "Epoch 2693/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6650e-04 - val_loss: 5.4261e-04\n",
      "Epoch 2694/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6646e-04 - val_loss: 5.4386e-04\n",
      "Epoch 2695/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6659e-04 - val_loss: 5.4470e-04\n",
      "Epoch 2696/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6651e-04 - val_loss: 5.4500e-04\n",
      "Epoch 2697/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6661e-04 - val_loss: 5.4439e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2698/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6648e-04 - val_loss: 5.4456e-04\n",
      "Epoch 2699/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6647e-04 - val_loss: 5.4346e-04\n",
      "Epoch 2700/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6640e-04 - val_loss: 5.4269e-04\n",
      "Epoch 2701/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6646e-04 - val_loss: 5.4472e-04\n",
      "Epoch 2702/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6646e-04 - val_loss: 5.4461e-04\n",
      "Epoch 2703/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6654e-04 - val_loss: 5.4403e-04\n",
      "Epoch 2704/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6637e-04 - val_loss: 5.4187e-04\n",
      "Epoch 2705/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6638e-04 - val_loss: 5.4424e-04\n",
      "Epoch 2706/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6652e-04 - val_loss: 5.4557e-04\n",
      "Epoch 2707/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6647e-04 - val_loss: 5.4403e-04\n",
      "Epoch 2708/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6651e-04 - val_loss: 5.4503e-04\n",
      "Epoch 2709/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6644e-04 - val_loss: 5.4299e-04\n",
      "Epoch 2710/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6640e-04 - val_loss: 5.4497e-04\n",
      "Epoch 2711/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6645e-04 - val_loss: 5.4443e-04\n",
      "Epoch 2712/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6633e-04 - val_loss: 5.4401e-04\n",
      "Epoch 2713/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6642e-04 - val_loss: 5.4345e-04\n",
      "Epoch 2714/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6635e-04 - val_loss: 5.4345e-04\n",
      "Epoch 2715/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6641e-04 - val_loss: 5.4379e-04\n",
      "Epoch 2716/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6646e-04 - val_loss: 5.4408e-04\n",
      "Epoch 2717/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.6640e-04 - val_loss: 5.4359e-04\n",
      "Epoch 2718/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6633e-04 - val_loss: 5.4436e-04\n",
      "Epoch 2719/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6635e-04 - val_loss: 5.4307e-04\n",
      "Epoch 2720/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6637e-04 - val_loss: 5.4336e-04\n",
      "Epoch 2721/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.6633e-04 - val_loss: 5.4276e-04\n",
      "Epoch 2722/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6637e-04 - val_loss: 5.4410e-04\n",
      "Epoch 2723/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6637e-04 - val_loss: 5.4564e-04\n",
      "Epoch 2724/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6627e-04 - val_loss: 5.4342e-04\n",
      "Epoch 2725/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6623e-04 - val_loss: 5.4469e-04\n",
      "Epoch 2726/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6620e-04 - val_loss: 5.4380e-04\n",
      "Epoch 2727/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6643e-04 - val_loss: 5.4380e-04\n",
      "Epoch 2728/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6635e-04 - val_loss: 5.4378e-04\n",
      "Epoch 2729/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6630e-04 - val_loss: 5.4481e-04\n",
      "Epoch 2730/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6642e-04 - val_loss: 5.4400e-04\n",
      "Epoch 2731/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6630e-04 - val_loss: 5.4455e-04\n",
      "Epoch 2732/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6624e-04 - val_loss: 5.4208e-04\n",
      "Epoch 2733/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6627e-04 - val_loss: 5.4380e-04\n",
      "Epoch 2734/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6619e-04 - val_loss: 5.4437e-04\n",
      "Epoch 2735/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6627e-04 - val_loss: 5.4469e-04\n",
      "Epoch 2736/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6622e-04 - val_loss: 5.4252e-04\n",
      "Epoch 2737/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6625e-04 - val_loss: 5.4388e-04\n",
      "Epoch 2738/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6624e-04 - val_loss: 5.4704e-04\n",
      "Epoch 2739/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6623e-04 - val_loss: 5.4483e-04\n",
      "Epoch 2740/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6613e-04 - val_loss: 5.4449e-04\n",
      "Epoch 2741/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6632e-04 - val_loss: 5.4428e-04\n",
      "Epoch 2742/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6623e-04 - val_loss: 5.4215e-04\n",
      "Epoch 2743/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6622e-04 - val_loss: 5.4492e-04\n",
      "Epoch 2744/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6620e-04 - val_loss: 5.4543e-04\n",
      "Epoch 2745/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6611e-04 - val_loss: 5.4418e-04\n",
      "Epoch 2746/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6621e-04 - val_loss: 5.4404e-04\n",
      "Epoch 2747/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6618e-04 - val_loss: 5.4349e-04\n",
      "Epoch 2748/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6622e-04 - val_loss: 5.4629e-04\n",
      "Epoch 2749/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6620e-04 - val_loss: 5.4251e-04\n",
      "Epoch 2750/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6615e-04 - val_loss: 5.4352e-04\n",
      "Epoch 2751/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6624e-04 - val_loss: 5.4325e-04\n",
      "Epoch 2752/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6614e-04 - val_loss: 5.4568e-04\n",
      "Epoch 2753/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6616e-04 - val_loss: 5.4512e-04\n",
      "Epoch 2754/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6609e-04 - val_loss: 5.4389e-04\n",
      "Epoch 2755/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6625e-04 - val_loss: 5.4288e-04\n",
      "Epoch 2756/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6612e-04 - val_loss: 5.4548e-04\n",
      "Epoch 2757/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6610e-04 - val_loss: 5.4278e-04\n",
      "Epoch 2758/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6616e-04 - val_loss: 5.4399e-04\n",
      "Epoch 2759/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6618e-04 - val_loss: 5.4333e-04\n",
      "Epoch 2760/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6613e-04 - val_loss: 5.4546e-04\n",
      "Epoch 2761/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6616e-04 - val_loss: 5.4369e-04\n",
      "Epoch 2762/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6625e-04 - val_loss: 5.4445e-04\n",
      "Epoch 2763/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6603e-04 - val_loss: 5.4354e-04\n",
      "Epoch 2764/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6609e-04 - val_loss: 5.4279e-04\n",
      "Epoch 2765/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6606e-04 - val_loss: 5.4315e-04\n",
      "Epoch 2766/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6601e-04 - val_loss: 5.4418e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2767/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6601e-04 - val_loss: 5.4421e-04\n",
      "Epoch 2768/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6615e-04 - val_loss: 5.4439e-04\n",
      "Epoch 2769/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6616e-04 - val_loss: 5.4466e-04\n",
      "Epoch 2770/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6609e-04 - val_loss: 5.4482e-04\n",
      "Epoch 2771/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6611e-04 - val_loss: 5.4361e-04\n",
      "Epoch 2772/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6603e-04 - val_loss: 5.4527e-04\n",
      "Epoch 2773/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6601e-04 - val_loss: 5.4254e-04\n",
      "Epoch 2774/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6602e-04 - val_loss: 5.4357e-04\n",
      "Epoch 2775/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6611e-04 - val_loss: 5.4529e-04\n",
      "Epoch 2776/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6594e-04 - val_loss: 5.4272e-04\n",
      "Epoch 2777/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6602e-04 - val_loss: 5.4414e-04\n",
      "Epoch 2778/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6598e-04 - val_loss: 5.4418e-04\n",
      "Epoch 2779/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6597e-04 - val_loss: 5.4509e-04\n",
      "Epoch 2780/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6599e-04 - val_loss: 5.4512e-04\n",
      "Epoch 2781/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6605e-04 - val_loss: 5.4372e-04\n",
      "Epoch 2782/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6592e-04 - val_loss: 5.4753e-04\n",
      "Epoch 2783/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6595e-04 - val_loss: 5.4276e-04\n",
      "Epoch 2784/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6594e-04 - val_loss: 5.4330e-04\n",
      "Epoch 2785/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6601e-04 - val_loss: 5.4456e-04\n",
      "Epoch 2786/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6602e-04 - val_loss: 5.4482e-04\n",
      "Epoch 2787/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6589e-04 - val_loss: 5.4269e-04\n",
      "Epoch 2788/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6581e-04 - val_loss: 5.4451e-04\n",
      "Epoch 2789/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6587e-04 - val_loss: 5.4586e-04\n",
      "Epoch 2790/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6581e-04 - val_loss: 5.4564e-04\n",
      "Epoch 2791/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6595e-04 - val_loss: 5.4493e-04\n",
      "Epoch 2792/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6596e-04 - val_loss: 5.4458e-04\n",
      "Epoch 2793/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6607e-04 - val_loss: 5.4478e-04\n",
      "Epoch 2794/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6596e-04 - val_loss: 5.4328e-04\n",
      "Epoch 2795/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6597e-04 - val_loss: 5.4273e-04\n",
      "Epoch 2796/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6595e-04 - val_loss: 5.4325e-04\n",
      "Epoch 2797/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6596e-04 - val_loss: 5.4303e-04\n",
      "Epoch 2798/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6586e-04 - val_loss: 5.4318e-04\n",
      "Epoch 2799/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6584e-04 - val_loss: 5.4382e-04\n",
      "Epoch 2800/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6591e-04 - val_loss: 5.4404e-04\n",
      "Epoch 2801/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6594e-04 - val_loss: 5.4447e-04\n",
      "Epoch 2802/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6600e-04 - val_loss: 5.4544e-04\n",
      "Epoch 2803/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6590e-04 - val_loss: 5.4371e-04\n",
      "Epoch 2804/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6587e-04 - val_loss: 5.4381e-04\n",
      "Epoch 2805/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6599e-04 - val_loss: 5.4486e-04\n",
      "Epoch 2806/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6585e-04 - val_loss: 5.4554e-04\n",
      "Epoch 2807/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6586e-04 - val_loss: 5.4398e-04\n",
      "Epoch 2808/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6593e-04 - val_loss: 5.4360e-04\n",
      "Epoch 2809/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6577e-04 - val_loss: 5.4370e-04\n",
      "Epoch 2810/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6587e-04 - val_loss: 5.4388e-04\n",
      "Epoch 2811/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6589e-04 - val_loss: 5.4378e-04\n",
      "Epoch 2812/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6584e-04 - val_loss: 5.4400e-04\n",
      "Epoch 2813/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6576e-04 - val_loss: 5.4360e-04\n",
      "Epoch 2814/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6577e-04 - val_loss: 5.4355e-04\n",
      "Epoch 2815/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6578e-04 - val_loss: 5.4293e-04\n",
      "Epoch 2816/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6589e-04 - val_loss: 5.4451e-04\n",
      "Epoch 2817/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6581e-04 - val_loss: 5.4476e-04\n",
      "Epoch 2818/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6577e-04 - val_loss: 5.4415e-04\n",
      "Epoch 2819/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6578e-04 - val_loss: 5.4380e-04\n",
      "Epoch 2820/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6587e-04 - val_loss: 5.4461e-04\n",
      "Epoch 2821/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6576e-04 - val_loss: 5.4405e-04\n",
      "Epoch 2822/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6578e-04 - val_loss: 5.4475e-04\n",
      "Epoch 2823/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6574e-04 - val_loss: 5.4307e-04\n",
      "Epoch 2824/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6573e-04 - val_loss: 5.4465e-04\n",
      "Epoch 2825/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6578e-04 - val_loss: 5.4197e-04\n",
      "Epoch 2826/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6582e-04 - val_loss: 5.4357e-04\n",
      "Epoch 2827/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6575e-04 - val_loss: 5.4277e-04\n",
      "Epoch 2828/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6565e-04 - val_loss: 5.4524e-04\n",
      "Epoch 2829/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6579e-04 - val_loss: 5.4447e-04\n",
      "Epoch 2830/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6566e-04 - val_loss: 5.4501e-04\n",
      "Epoch 2831/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6572e-04 - val_loss: 5.4188e-04\n",
      "Epoch 2832/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6578e-04 - val_loss: 5.4338e-04\n",
      "Epoch 2833/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6574e-04 - val_loss: 5.4474e-04\n",
      "Epoch 2834/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6577e-04 - val_loss: 5.4468e-04\n",
      "Epoch 2835/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6575e-04 - val_loss: 5.4499e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2836/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6562e-04 - val_loss: 5.4349e-04\n",
      "Epoch 2837/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6576e-04 - val_loss: 5.4543e-04\n",
      "Epoch 2838/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6572e-04 - val_loss: 5.4307e-04\n",
      "Epoch 2839/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6567e-04 - val_loss: 5.4471e-04\n",
      "Epoch 2840/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6572e-04 - val_loss: 5.4348e-04\n",
      "Epoch 2841/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6563e-04 - val_loss: 5.4251e-04\n",
      "Epoch 2842/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6562e-04 - val_loss: 5.4440e-04\n",
      "Epoch 2843/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6567e-04 - val_loss: 5.4318e-04\n",
      "Epoch 2844/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6563e-04 - val_loss: 5.4482e-04\n",
      "Epoch 2845/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6567e-04 - val_loss: 5.4393e-04\n",
      "Epoch 2846/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6572e-04 - val_loss: 5.4373e-04\n",
      "Epoch 2847/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6569e-04 - val_loss: 5.4353e-04\n",
      "Epoch 2848/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6569e-04 - val_loss: 5.4533e-04\n",
      "Epoch 2849/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6567e-04 - val_loss: 5.4468e-04\n",
      "Epoch 2850/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6558e-04 - val_loss: 5.4352e-04\n",
      "Epoch 2851/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6562e-04 - val_loss: 5.4336e-04\n",
      "Epoch 2852/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6559e-04 - val_loss: 5.4475e-04\n",
      "Epoch 2853/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6558e-04 - val_loss: 5.4372e-04\n",
      "Epoch 2854/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6563e-04 - val_loss: 5.4564e-04\n",
      "Epoch 2855/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6561e-04 - val_loss: 5.4322e-04\n",
      "Epoch 2856/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6552e-04 - val_loss: 5.4410e-04\n",
      "Epoch 2857/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6563e-04 - val_loss: 5.4303e-04\n",
      "Epoch 2858/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6558e-04 - val_loss: 5.4299e-04\n",
      "Epoch 2859/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6564e-04 - val_loss: 5.4393e-04\n",
      "Epoch 2860/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6558e-04 - val_loss: 5.4540e-04\n",
      "Epoch 2861/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6549e-04 - val_loss: 5.4467e-04\n",
      "Epoch 2862/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6567e-04 - val_loss: 5.4460e-04\n",
      "Epoch 2863/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6559e-04 - val_loss: 5.4480e-04\n",
      "Epoch 2864/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6555e-04 - val_loss: 5.4235e-04\n",
      "Epoch 2865/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6556e-04 - val_loss: 5.4570e-04\n",
      "Epoch 2866/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6551e-04 - val_loss: 5.4357e-04\n",
      "Epoch 2867/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6548e-04 - val_loss: 5.4450e-04\n",
      "Epoch 2868/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6550e-04 - val_loss: 5.4383e-04\n",
      "Epoch 2869/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6549e-04 - val_loss: 5.4299e-04\n",
      "Epoch 2870/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6561e-04 - val_loss: 5.4369e-04\n",
      "Epoch 2871/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.6549e-04 - val_loss: 5.4497e-04\n",
      "Epoch 2872/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6543e-04 - val_loss: 5.4405e-04\n",
      "Epoch 2873/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6555e-04 - val_loss: 5.4224e-04\n",
      "Epoch 2874/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6549e-04 - val_loss: 5.4370e-04\n",
      "Epoch 2875/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6552e-04 - val_loss: 5.4358e-04\n",
      "Epoch 2876/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6551e-04 - val_loss: 5.4350e-04\n",
      "Epoch 2877/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6546e-04 - val_loss: 5.4325e-04\n",
      "Epoch 2878/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6552e-04 - val_loss: 5.4448e-04\n",
      "Epoch 2879/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6552e-04 - val_loss: 5.4371e-04\n",
      "Epoch 2880/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6553e-04 - val_loss: 5.4473e-04\n",
      "Epoch 2881/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6555e-04 - val_loss: 5.4565e-04\n",
      "Epoch 2882/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6544e-04 - val_loss: 5.4502e-04\n",
      "Epoch 2883/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6554e-04 - val_loss: 5.4313e-04\n",
      "Epoch 2884/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6543e-04 - val_loss: 5.4425e-04\n",
      "Epoch 2885/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6551e-04 - val_loss: 5.4327e-04\n",
      "Epoch 2886/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6545e-04 - val_loss: 5.4628e-04\n",
      "Epoch 2887/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6545e-04 - val_loss: 5.4420e-04\n",
      "Epoch 2888/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6541e-04 - val_loss: 5.4259e-04\n",
      "Epoch 2889/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6540e-04 - val_loss: 5.4232e-04\n",
      "Epoch 2890/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6548e-04 - val_loss: 5.4416e-04\n",
      "Epoch 2891/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6538e-04 - val_loss: 5.4218e-04\n",
      "Epoch 2892/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6540e-04 - val_loss: 5.4207e-04\n",
      "Epoch 2893/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6541e-04 - val_loss: 5.4529e-04\n",
      "Epoch 2894/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6552e-04 - val_loss: 5.4837e-04\n",
      "Epoch 2895/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6537e-04 - val_loss: 5.4516e-04\n",
      "Epoch 2896/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6540e-04 - val_loss: 5.4341e-04\n",
      "Epoch 2897/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6539e-04 - val_loss: 5.4364e-04\n",
      "Epoch 2898/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6545e-04 - val_loss: 5.4232e-04\n",
      "Epoch 2899/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6539e-04 - val_loss: 5.4279e-04\n",
      "Epoch 2900/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6529e-04 - val_loss: 5.4398e-04\n",
      "Epoch 2901/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6537e-04 - val_loss: 5.4403e-04\n",
      "Epoch 2902/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6531e-04 - val_loss: 5.4283e-04\n",
      "Epoch 2903/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6534e-04 - val_loss: 5.4427e-04\n",
      "Epoch 2904/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6533e-04 - val_loss: 5.4307e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2905/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6534e-04 - val_loss: 5.4286e-04\n",
      "Epoch 2906/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6531e-04 - val_loss: 5.4472e-04\n",
      "Epoch 2907/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6536e-04 - val_loss: 5.4464e-04\n",
      "Epoch 2908/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6537e-04 - val_loss: 5.4445e-04\n",
      "Epoch 2909/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6534e-04 - val_loss: 5.4272e-04\n",
      "Epoch 2910/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6532e-04 - val_loss: 5.4392e-04\n",
      "Epoch 2911/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6528e-04 - val_loss: 5.4274e-04\n",
      "Epoch 2912/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6530e-04 - val_loss: 5.4372e-04\n",
      "Epoch 2913/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6523e-04 - val_loss: 5.4435e-04\n",
      "Epoch 2914/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6519e-04 - val_loss: 5.4390e-04\n",
      "Epoch 2915/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6533e-04 - val_loss: 5.4425e-04\n",
      "Epoch 2916/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6531e-04 - val_loss: 5.4274e-04\n",
      "Epoch 2917/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6527e-04 - val_loss: 5.4332e-04\n",
      "Epoch 2918/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6528e-04 - val_loss: 5.4485e-04\n",
      "Epoch 2919/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6523e-04 - val_loss: 5.4531e-04\n",
      "Epoch 2920/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6527e-04 - val_loss: 5.4292e-04\n",
      "Epoch 2921/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6527e-04 - val_loss: 5.4343e-04\n",
      "Epoch 2922/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6529e-04 - val_loss: 5.4328e-04\n",
      "Epoch 2923/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6526e-04 - val_loss: 5.4278e-04\n",
      "Epoch 2924/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6531e-04 - val_loss: 5.4401e-04\n",
      "Epoch 2925/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6526e-04 - val_loss: 5.4585e-04\n",
      "Epoch 2926/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6534e-04 - val_loss: 5.4397e-04\n",
      "Epoch 2927/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6517e-04 - val_loss: 5.4419e-04\n",
      "Epoch 2928/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6526e-04 - val_loss: 5.4296e-04\n",
      "Epoch 2929/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6519e-04 - val_loss: 5.4197e-04\n",
      "Epoch 2930/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6515e-04 - val_loss: 5.4453e-04\n",
      "Epoch 2931/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6516e-04 - val_loss: 5.4484e-04\n",
      "Epoch 2932/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6523e-04 - val_loss: 5.4257e-04\n",
      "Epoch 2933/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6515e-04 - val_loss: 5.4262e-04\n",
      "Epoch 2934/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6524e-04 - val_loss: 5.4465e-04\n",
      "Epoch 2935/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6520e-04 - val_loss: 5.4351e-04\n",
      "Epoch 2936/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6520e-04 - val_loss: 5.4352e-04\n",
      "Epoch 2937/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6527e-04 - val_loss: 5.4381e-04\n",
      "Epoch 2938/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6512e-04 - val_loss: 5.4335e-04\n",
      "Epoch 2939/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6522e-04 - val_loss: 5.4614e-04\n",
      "Epoch 2940/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6523e-04 - val_loss: 5.4375e-04\n",
      "Epoch 2941/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6515e-04 - val_loss: 5.4438e-04\n",
      "Epoch 2942/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6519e-04 - val_loss: 5.4288e-04\n",
      "Epoch 2943/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6518e-04 - val_loss: 5.4445e-04\n",
      "Epoch 2944/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6515e-04 - val_loss: 5.4368e-04\n",
      "Epoch 2945/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6511e-04 - val_loss: 5.4296e-04\n",
      "Epoch 2946/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6511e-04 - val_loss: 5.4312e-04\n",
      "Epoch 2947/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6521e-04 - val_loss: 5.4307e-04\n",
      "Epoch 2948/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6521e-04 - val_loss: 5.4350e-04\n",
      "Epoch 2949/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6516e-04 - val_loss: 5.4350e-04\n",
      "Epoch 2950/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6506e-04 - val_loss: 5.4385e-04\n",
      "Epoch 2951/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6526e-04 - val_loss: 5.4439e-04\n",
      "Epoch 2952/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6516e-04 - val_loss: 5.4445e-04\n",
      "Epoch 2953/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6510e-04 - val_loss: 5.4364e-04\n",
      "Epoch 2954/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6506e-04 - val_loss: 5.4220e-04\n",
      "Epoch 2955/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6513e-04 - val_loss: 5.4263e-04\n",
      "Epoch 2956/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6513e-04 - val_loss: 5.4284e-04\n",
      "Epoch 2957/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6507e-04 - val_loss: 5.4470e-04\n",
      "Epoch 2958/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6519e-04 - val_loss: 5.4353e-04\n",
      "Epoch 2959/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6505e-04 - val_loss: 5.4233e-04\n",
      "Epoch 2960/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6512e-04 - val_loss: 5.4243e-04\n",
      "Epoch 2961/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6509e-04 - val_loss: 5.4352e-04\n",
      "Epoch 2962/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6507e-04 - val_loss: 5.4465e-04\n",
      "Epoch 2963/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6499e-04 - val_loss: 5.4478e-04\n",
      "Epoch 2964/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6520e-04 - val_loss: 5.4926e-04\n",
      "Epoch 2965/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6514e-04 - val_loss: 5.4348e-04\n",
      "Epoch 2966/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6506e-04 - val_loss: 5.4359e-04\n",
      "Epoch 2967/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6510e-04 - val_loss: 5.4155e-04\n",
      "Epoch 2968/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6507e-04 - val_loss: 5.4264e-04\n",
      "Epoch 2969/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6503e-04 - val_loss: 5.4477e-04\n",
      "Epoch 2970/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6505e-04 - val_loss: 5.4482e-04\n",
      "Epoch 2971/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6500e-04 - val_loss: 5.4194e-04\n",
      "Epoch 2972/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6501e-04 - val_loss: 5.4210e-04\n",
      "Epoch 2973/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6504e-04 - val_loss: 5.4575e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2974/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6496e-04 - val_loss: 5.4237e-04\n",
      "Epoch 2975/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6505e-04 - val_loss: 5.4415e-04\n",
      "Epoch 2976/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6501e-04 - val_loss: 5.4439e-04\n",
      "Epoch 2977/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6504e-04 - val_loss: 5.4444e-04\n",
      "Epoch 2978/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6503e-04 - val_loss: 5.4340e-04\n",
      "Epoch 2979/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6503e-04 - val_loss: 5.4406e-04\n",
      "Epoch 2980/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6498e-04 - val_loss: 5.4088e-04\n",
      "Epoch 2981/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6504e-04 - val_loss: 5.4234e-04\n",
      "Epoch 2982/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6506e-04 - val_loss: 5.4302e-04\n",
      "Epoch 2983/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6498e-04 - val_loss: 5.4324e-04\n",
      "Epoch 2984/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6504e-04 - val_loss: 5.4269e-04\n",
      "Epoch 2985/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6495e-04 - val_loss: 5.4296e-04\n",
      "Epoch 2986/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6490e-04 - val_loss: 5.4504e-04\n",
      "Epoch 2987/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6493e-04 - val_loss: 5.4317e-04\n",
      "Epoch 2988/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6497e-04 - val_loss: 5.4437e-04\n",
      "Epoch 2989/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6501e-04 - val_loss: 5.4470e-04\n",
      "Epoch 2990/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6496e-04 - val_loss: 5.4555e-04\n",
      "Epoch 2991/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6488e-04 - val_loss: 5.4284e-04\n",
      "Epoch 2992/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6495e-04 - val_loss: 5.4519e-04\n",
      "Epoch 2993/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6481e-04 - val_loss: 5.4129e-04\n",
      "Epoch 2994/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6497e-04 - val_loss: 5.4310e-04\n",
      "Epoch 2995/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6490e-04 - val_loss: 5.4212e-04\n",
      "Epoch 2996/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6499e-04 - val_loss: 5.4378e-04\n",
      "Epoch 2997/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6499e-04 - val_loss: 5.4359e-04\n",
      "Epoch 2998/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6485e-04 - val_loss: 5.4375e-04\n",
      "Epoch 2999/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6487e-04 - val_loss: 5.4340e-04\n",
      "Epoch 3000/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6493e-04 - val_loss: 5.4286e-04\n",
      "Epoch 3001/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6496e-04 - val_loss: 5.4207e-04\n",
      "Epoch 3002/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6487e-04 - val_loss: 5.4314e-04\n",
      "Epoch 3003/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6485e-04 - val_loss: 5.4442e-04\n",
      "Epoch 3004/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6500e-04 - val_loss: 5.4344e-04\n",
      "Epoch 3005/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6473e-04 - val_loss: 5.4365e-04\n",
      "Epoch 3006/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6497e-04 - val_loss: 5.4508e-04\n",
      "Epoch 3007/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6485e-04 - val_loss: 5.4361e-04\n",
      "Epoch 3008/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6490e-04 - val_loss: 5.4269e-04\n",
      "Epoch 3009/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6487e-04 - val_loss: 5.4354e-04\n",
      "Epoch 3010/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6485e-04 - val_loss: 5.4414e-04\n",
      "Epoch 3011/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6483e-04 - val_loss: 5.4302e-04\n",
      "Epoch 3012/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6484e-04 - val_loss: 5.4423e-04\n",
      "Epoch 3013/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6493e-04 - val_loss: 5.4370e-04\n",
      "Epoch 3014/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6489e-04 - val_loss: 5.4469e-04\n",
      "Epoch 3015/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6494e-04 - val_loss: 5.4581e-04\n",
      "Epoch 3016/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6483e-04 - val_loss: 5.4327e-04\n",
      "Epoch 3017/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6476e-04 - val_loss: 5.4520e-04\n",
      "Epoch 3018/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6483e-04 - val_loss: 5.4327e-04\n",
      "Epoch 3019/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6493e-04 - val_loss: 5.4303e-04\n",
      "Epoch 3020/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6484e-04 - val_loss: 5.4443e-04\n",
      "Epoch 3021/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6480e-04 - val_loss: 5.4173e-04\n",
      "Epoch 3022/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6486e-04 - val_loss: 5.4280e-04\n",
      "Epoch 3023/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6474e-04 - val_loss: 5.4255e-04\n",
      "Epoch 3024/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6478e-04 - val_loss: 5.4404e-04\n",
      "Epoch 3025/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6488e-04 - val_loss: 5.4372e-04\n",
      "Epoch 3026/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6481e-04 - val_loss: 5.4300e-04\n",
      "Epoch 3027/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6485e-04 - val_loss: 5.4440e-04\n",
      "Epoch 3028/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6477e-04 - val_loss: 5.4277e-04\n",
      "Epoch 3029/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6476e-04 - val_loss: 5.4269e-04\n",
      "Epoch 3030/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6475e-04 - val_loss: 5.4211e-04\n",
      "Epoch 3031/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6470e-04 - val_loss: 5.4396e-04\n",
      "Epoch 3032/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6478e-04 - val_loss: 5.4348e-04\n",
      "Epoch 3033/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6469e-04 - val_loss: 5.4370e-04\n",
      "Epoch 3034/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6473e-04 - val_loss: 5.4119e-04\n",
      "Epoch 3035/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6469e-04 - val_loss: 5.4397e-04\n",
      "Epoch 3036/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6475e-04 - val_loss: 5.4499e-04\n",
      "Epoch 3037/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6475e-04 - val_loss: 5.4344e-04\n",
      "Epoch 3038/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6476e-04 - val_loss: 5.4237e-04\n",
      "Epoch 3039/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6475e-04 - val_loss: 5.4253e-04\n",
      "Epoch 3040/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6473e-04 - val_loss: 5.4376e-04\n",
      "Epoch 3041/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6475e-04 - val_loss: 5.4269e-04\n",
      "Epoch 3042/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6476e-04 - val_loss: 5.4201e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3043/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6473e-04 - val_loss: 5.4078e-04\n",
      "Epoch 3044/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6463e-04 - val_loss: 5.4387e-04\n",
      "Epoch 3045/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6460e-04 - val_loss: 5.4603e-04\n",
      "Epoch 3046/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6464e-04 - val_loss: 5.4332e-04\n",
      "Epoch 3047/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6468e-04 - val_loss: 5.4348e-04\n",
      "Epoch 3048/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6467e-04 - val_loss: 5.4289e-04\n",
      "Epoch 3049/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6469e-04 - val_loss: 5.4389e-04\n",
      "Epoch 3050/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6472e-04 - val_loss: 5.4256e-04\n",
      "Epoch 3051/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6477e-04 - val_loss: 5.4405e-04\n",
      "Epoch 3052/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6466e-04 - val_loss: 5.4237e-04\n",
      "Epoch 3053/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6471e-04 - val_loss: 5.4306e-04\n",
      "Epoch 3054/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6474e-04 - val_loss: 5.4142e-04\n",
      "Epoch 3055/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6464e-04 - val_loss: 5.4412e-04\n",
      "Epoch 3056/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 5.6462e-04 - val_loss: 5.4274e-04\n",
      "Epoch 3057/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6464e-04 - val_loss: 5.4250e-04\n",
      "Epoch 3058/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6463e-04 - val_loss: 5.4334e-04\n",
      "Epoch 3059/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6455e-04 - val_loss: 5.4236e-04\n",
      "Epoch 3060/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6458e-04 - val_loss: 5.4239e-04\n",
      "Epoch 3061/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6460e-04 - val_loss: 5.4492e-04\n",
      "Epoch 3062/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6467e-04 - val_loss: 5.4514e-04\n",
      "Epoch 3063/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6465e-04 - val_loss: 5.4147e-04\n",
      "Epoch 3064/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6462e-04 - val_loss: 5.4391e-04\n",
      "Epoch 3065/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6468e-04 - val_loss: 5.4276e-04\n",
      "Epoch 3066/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6465e-04 - val_loss: 5.4363e-04\n",
      "Epoch 3067/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6462e-04 - val_loss: 5.4251e-04\n",
      "Epoch 3068/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6458e-04 - val_loss: 5.4532e-04\n",
      "Epoch 3069/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6461e-04 - val_loss: 5.4305e-04\n",
      "Epoch 3070/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6459e-04 - val_loss: 5.4295e-04\n",
      "Epoch 3071/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6459e-04 - val_loss: 5.4288e-04\n",
      "Epoch 3072/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6461e-04 - val_loss: 5.4377e-04\n",
      "Epoch 3073/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6460e-04 - val_loss: 5.4311e-04\n",
      "Epoch 3074/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6456e-04 - val_loss: 5.4396e-04\n",
      "Epoch 3075/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.6454e-04 - val_loss: 5.4567e-04\n",
      "Epoch 3076/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6458e-04 - val_loss: 5.4341e-04\n",
      "Epoch 3077/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6455e-04 - val_loss: 5.4051e-04\n",
      "Epoch 3078/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6462e-04 - val_loss: 5.4359e-04\n",
      "Epoch 3079/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6445e-04 - val_loss: 5.4064e-04\n",
      "Epoch 3080/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6456e-04 - val_loss: 5.4468e-04\n",
      "Epoch 3081/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6452e-04 - val_loss: 5.4321e-04\n",
      "Epoch 3082/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6446e-04 - val_loss: 5.4447e-04\n",
      "Epoch 3083/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6450e-04 - val_loss: 5.4429e-04\n",
      "Epoch 3084/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6446e-04 - val_loss: 5.4241e-04\n",
      "Epoch 3085/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6444e-04 - val_loss: 5.4312e-04\n",
      "Epoch 3086/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6448e-04 - val_loss: 5.4254e-04\n",
      "Epoch 3087/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6449e-04 - val_loss: 5.4076e-04\n",
      "Epoch 3088/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6454e-04 - val_loss: 5.4492e-04\n",
      "Epoch 3089/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6461e-04 - val_loss: 5.4152e-04\n",
      "Epoch 3090/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6445e-04 - val_loss: 5.4529e-04\n",
      "Epoch 3091/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.6452e-04 - val_loss: 5.4337e-04\n",
      "Epoch 3092/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6450e-04 - val_loss: 5.4174e-04\n",
      "Epoch 3093/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6458e-04 - val_loss: 5.4420e-04\n",
      "Epoch 3094/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6444e-04 - val_loss: 5.4348e-04\n",
      "Epoch 3095/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6450e-04 - val_loss: 5.4566e-04\n",
      "Epoch 3096/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6442e-04 - val_loss: 5.4384e-04\n",
      "Epoch 3097/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6440e-04 - val_loss: 5.4364e-04\n",
      "Epoch 3098/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6451e-04 - val_loss: 5.4303e-04\n",
      "Epoch 3099/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6452e-04 - val_loss: 5.4217e-04\n",
      "Epoch 3100/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6437e-04 - val_loss: 5.4301e-04\n",
      "Epoch 3101/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6439e-04 - val_loss: 5.4196e-04\n",
      "Epoch 3102/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6448e-04 - val_loss: 5.4185e-04\n",
      "Epoch 3103/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6441e-04 - val_loss: 5.4311e-04\n",
      "Epoch 3104/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6441e-04 - val_loss: 5.4444e-04\n",
      "Epoch 3105/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6437e-04 - val_loss: 5.4190e-04\n",
      "Epoch 3106/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6434e-04 - val_loss: 5.4294e-04\n",
      "Epoch 3107/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6443e-04 - val_loss: 5.4226e-04\n",
      "Epoch 3108/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6446e-04 - val_loss: 5.4331e-04\n",
      "Epoch 3109/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6443e-04 - val_loss: 5.4489e-04\n",
      "Epoch 3110/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6444e-04 - val_loss: 5.4486e-04\n",
      "Epoch 3111/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6451e-04 - val_loss: 5.4442e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3112/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6437e-04 - val_loss: 5.4223e-04\n",
      "Epoch 3113/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6446e-04 - val_loss: 5.4162e-04\n",
      "Epoch 3114/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6438e-04 - val_loss: 5.4259e-04\n",
      "Epoch 3115/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6440e-04 - val_loss: 5.4438e-04\n",
      "Epoch 3116/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.6437e-04 - val_loss: 5.4330e-04\n",
      "Epoch 3117/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6438e-04 - val_loss: 5.4322e-04\n",
      "Epoch 3118/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6436e-04 - val_loss: 5.4125e-04\n",
      "Epoch 3119/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6439e-04 - val_loss: 5.4062e-04\n",
      "Epoch 3120/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6435e-04 - val_loss: 5.4346e-04\n",
      "Epoch 3121/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6438e-04 - val_loss: 5.4396e-04\n",
      "Epoch 3122/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6430e-04 - val_loss: 5.4289e-04\n",
      "Epoch 3123/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6429e-04 - val_loss: 5.4392e-04\n",
      "Epoch 3124/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6429e-04 - val_loss: 5.4621e-04\n",
      "Epoch 3125/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6430e-04 - val_loss: 5.4254e-04\n",
      "Epoch 3126/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6439e-04 - val_loss: 5.4291e-04\n",
      "Epoch 3127/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6437e-04 - val_loss: 5.4235e-04\n",
      "Epoch 3128/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6431e-04 - val_loss: 5.4293e-04\n",
      "Epoch 3129/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6432e-04 - val_loss: 5.4428e-04\n",
      "Epoch 3130/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6429e-04 - val_loss: 5.4492e-04\n",
      "Epoch 3131/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6435e-04 - val_loss: 5.4190e-04\n",
      "Epoch 3132/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6434e-04 - val_loss: 5.4408e-04\n",
      "Epoch 3133/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6431e-04 - val_loss: 5.4447e-04\n",
      "Epoch 3134/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6430e-04 - val_loss: 5.4171e-04\n",
      "Epoch 3135/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6430e-04 - val_loss: 5.4267e-04\n",
      "Epoch 3136/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6431e-04 - val_loss: 5.4306e-04\n",
      "Epoch 3137/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6423e-04 - val_loss: 5.4368e-04\n",
      "Epoch 3138/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6426e-04 - val_loss: 5.4440e-04\n",
      "Epoch 3139/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6430e-04 - val_loss: 5.4140e-04\n",
      "Epoch 3140/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6433e-04 - val_loss: 5.4270e-04\n",
      "Epoch 3141/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6426e-04 - val_loss: 5.4384e-04\n",
      "Epoch 3142/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6426e-04 - val_loss: 5.4273e-04\n",
      "Epoch 3143/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6422e-04 - val_loss: 5.4329e-04\n",
      "Epoch 3144/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6425e-04 - val_loss: 5.4249e-04\n",
      "Epoch 3145/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6424e-04 - val_loss: 5.4312e-04\n",
      "Epoch 3146/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6425e-04 - val_loss: 5.4328e-04\n",
      "Epoch 3147/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6424e-04 - val_loss: 5.4241e-04\n",
      "Epoch 3148/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6422e-04 - val_loss: 5.4453e-04\n",
      "Epoch 3149/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6426e-04 - val_loss: 5.4459e-04\n",
      "Epoch 3150/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6412e-04 - val_loss: 5.4036e-04\n",
      "Epoch 3151/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6429e-04 - val_loss: 5.4447e-04\n",
      "Epoch 3152/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6428e-04 - val_loss: 5.4249e-04\n",
      "Epoch 3153/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6432e-04 - val_loss: 5.4499e-04\n",
      "Epoch 3154/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6415e-04 - val_loss: 5.4273e-04\n",
      "Epoch 3155/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6418e-04 - val_loss: 5.4497e-04\n",
      "Epoch 3156/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6430e-04 - val_loss: 5.4191e-04\n",
      "Epoch 3157/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6424e-04 - val_loss: 5.4121e-04\n",
      "Epoch 3158/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6420e-04 - val_loss: 5.4628e-04\n",
      "Epoch 3159/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6420e-04 - val_loss: 5.4225e-04\n",
      "Epoch 3160/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6426e-04 - val_loss: 5.4349e-04\n",
      "Epoch 3161/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6420e-04 - val_loss: 5.4401e-04\n",
      "Epoch 3162/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6423e-04 - val_loss: 5.4181e-04\n",
      "Epoch 3163/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6425e-04 - val_loss: 5.4445e-04\n",
      "Epoch 3164/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6422e-04 - val_loss: 5.4388e-04\n",
      "Epoch 3165/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6414e-04 - val_loss: 5.4425e-04\n",
      "Epoch 3166/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6413e-04 - val_loss: 5.4372e-04\n",
      "Epoch 3167/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6412e-04 - val_loss: 5.4320e-04\n",
      "Epoch 3168/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6420e-04 - val_loss: 5.4658e-04\n",
      "Epoch 3169/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6411e-04 - val_loss: 5.4145e-04\n",
      "Epoch 3170/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6412e-04 - val_loss: 5.4271e-04\n",
      "Epoch 3171/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6405e-04 - val_loss: 5.4418e-04\n",
      "Epoch 3172/10000\n",
      "45507/45507 [==============================] - 1s 23us/step - loss: 5.6406e-04 - val_loss: 5.4346e-04\n",
      "Epoch 3173/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6412e-04 - val_loss: 5.4235e-04\n",
      "Epoch 3174/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6409e-04 - val_loss: 5.4367e-04\n",
      "Epoch 3175/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6416e-04 - val_loss: 5.4270e-04\n",
      "Epoch 3176/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6420e-04 - val_loss: 5.4427e-04\n",
      "Epoch 3177/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6418e-04 - val_loss: 5.4378e-04\n",
      "Epoch 3178/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6415e-04 - val_loss: 5.4192e-04\n",
      "Epoch 3179/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6414e-04 - val_loss: 5.4417e-04\n",
      "Epoch 3180/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6410e-04 - val_loss: 5.4261e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3181/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6407e-04 - val_loss: 5.4507e-04\n",
      "Epoch 3182/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6408e-04 - val_loss: 5.4678e-04\n",
      "Epoch 3183/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6410e-04 - val_loss: 5.4449e-04\n",
      "Epoch 3184/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6409e-04 - val_loss: 5.4659e-04\n",
      "Epoch 3185/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6409e-04 - val_loss: 5.4162e-04\n",
      "Epoch 3186/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6407e-04 - val_loss: 5.4145e-04\n",
      "Epoch 3187/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6410e-04 - val_loss: 5.4172e-04\n",
      "Epoch 3188/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6410e-04 - val_loss: 5.4191e-04\n",
      "Epoch 3189/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6409e-04 - val_loss: 5.4321e-04\n",
      "Epoch 3190/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6407e-04 - val_loss: 5.4418e-04\n",
      "Epoch 3191/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6405e-04 - val_loss: 5.4242e-04\n",
      "Epoch 3192/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6402e-04 - val_loss: 5.4106e-04\n",
      "Epoch 3193/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6404e-04 - val_loss: 5.4411e-04\n",
      "Epoch 3194/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6404e-04 - val_loss: 5.4898e-04\n",
      "Epoch 3195/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6404e-04 - val_loss: 5.4179e-04\n",
      "Epoch 3196/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6416e-04 - val_loss: 5.4278e-04\n",
      "Epoch 3197/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6407e-04 - val_loss: 5.4116e-04\n",
      "Epoch 3198/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6410e-04 - val_loss: 5.4164e-04\n",
      "Epoch 3199/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6412e-04 - val_loss: 5.4400e-04\n",
      "Epoch 3200/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6409e-04 - val_loss: 5.4526e-04\n",
      "Epoch 3201/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6391e-04 - val_loss: 5.4012e-04\n",
      "Epoch 3202/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6405e-04 - val_loss: 5.4147e-04\n",
      "Epoch 3203/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6408e-04 - val_loss: 5.4420e-04\n",
      "Epoch 3204/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6399e-04 - val_loss: 5.4303e-04\n",
      "Epoch 3205/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6406e-04 - val_loss: 5.4428e-04\n",
      "Epoch 3206/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6410e-04 - val_loss: 5.4342e-04\n",
      "Epoch 3207/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6392e-04 - val_loss: 5.4184e-04\n",
      "Epoch 3208/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6401e-04 - val_loss: 5.4223e-04\n",
      "Epoch 3209/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6410e-04 - val_loss: 5.4362e-04\n",
      "Epoch 3210/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6395e-04 - val_loss: 5.4235e-04\n",
      "Epoch 3211/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6400e-04 - val_loss: 5.4411e-04\n",
      "Epoch 3212/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6401e-04 - val_loss: 5.4231e-04\n",
      "Epoch 3213/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6400e-04 - val_loss: 5.4405e-04\n",
      "Epoch 3214/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6410e-04 - val_loss: 5.4588e-04\n",
      "Epoch 3215/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6394e-04 - val_loss: 5.4026e-04\n",
      "Epoch 3216/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6406e-04 - val_loss: 5.4342e-04\n",
      "Epoch 3217/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6398e-04 - val_loss: 5.4406e-04\n",
      "Epoch 3218/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6390e-04 - val_loss: 5.4396e-04\n",
      "Epoch 3219/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6388e-04 - val_loss: 5.4418e-04\n",
      "Epoch 3220/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6389e-04 - val_loss: 5.4211e-04\n",
      "Epoch 3221/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6390e-04 - val_loss: 5.4526e-04\n",
      "Epoch 3222/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6398e-04 - val_loss: 5.4301e-04\n",
      "Epoch 3223/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6385e-04 - val_loss: 5.4308e-04\n",
      "Epoch 3224/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6388e-04 - val_loss: 5.4455e-04\n",
      "Epoch 3225/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.6387e-04 - val_loss: 5.4316e-04\n",
      "Epoch 3226/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6401e-04 - val_loss: 5.4174e-04\n",
      "Epoch 3227/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6392e-04 - val_loss: 5.4242e-04\n",
      "Epoch 3228/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6388e-04 - val_loss: 5.4245e-04\n",
      "Epoch 3229/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6393e-04 - val_loss: 5.4559e-04\n",
      "Epoch 3230/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6393e-04 - val_loss: 5.4244e-04\n",
      "Epoch 3231/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6385e-04 - val_loss: 5.4046e-04\n",
      "Epoch 3232/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6391e-04 - val_loss: 5.4281e-04\n",
      "Epoch 3233/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6392e-04 - val_loss: 5.4293e-04\n",
      "Epoch 3234/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6386e-04 - val_loss: 5.4158e-04\n",
      "Epoch 3235/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6386e-04 - val_loss: 5.4484e-04\n",
      "Epoch 3236/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6386e-04 - val_loss: 5.4228e-04\n",
      "Epoch 3237/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6395e-04 - val_loss: 5.4248e-04\n",
      "Epoch 3238/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6387e-04 - val_loss: 5.4135e-04\n",
      "Epoch 3239/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6389e-04 - val_loss: 5.4344e-04\n",
      "Epoch 3240/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6394e-04 - val_loss: 5.4458e-04\n",
      "Epoch 3241/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6389e-04 - val_loss: 5.4442e-04\n",
      "Epoch 3242/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6382e-04 - val_loss: 5.4329e-04\n",
      "Epoch 3243/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6387e-04 - val_loss: 5.4524e-04\n",
      "Epoch 3244/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6391e-04 - val_loss: 5.4388e-04\n",
      "Epoch 3245/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6393e-04 - val_loss: 5.4400e-04\n",
      "Epoch 3246/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6387e-04 - val_loss: 5.4354e-04\n",
      "Epoch 3247/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6380e-04 - val_loss: 5.4350e-04\n",
      "Epoch 3248/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6387e-04 - val_loss: 5.4226e-04\n",
      "Epoch 3249/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6376e-04 - val_loss: 5.4479e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3250/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6382e-04 - val_loss: 5.4260e-04\n",
      "Epoch 3251/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6391e-04 - val_loss: 5.4208e-04\n",
      "Epoch 3252/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6388e-04 - val_loss: 5.4386e-04\n",
      "Epoch 3253/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6385e-04 - val_loss: 5.4458e-04\n",
      "Epoch 3254/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6380e-04 - val_loss: 5.4635e-04\n",
      "Epoch 3255/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6392e-04 - val_loss: 5.4332e-04\n",
      "Epoch 3256/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6377e-04 - val_loss: 5.4153e-04\n",
      "Epoch 3257/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6380e-04 - val_loss: 5.4159e-04\n",
      "Epoch 3258/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6381e-04 - val_loss: 5.4340e-04\n",
      "Epoch 3259/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6388e-04 - val_loss: 5.4551e-04\n",
      "Epoch 3260/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6388e-04 - val_loss: 5.4376e-04\n",
      "Epoch 3261/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6377e-04 - val_loss: 5.4244e-04\n",
      "Epoch 3262/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6372e-04 - val_loss: 5.4267e-04\n",
      "Epoch 3263/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6382e-04 - val_loss: 5.4313e-04\n",
      "Epoch 3264/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6380e-04 - val_loss: 5.4117e-04\n",
      "Epoch 3265/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6381e-04 - val_loss: 5.4283e-04\n",
      "Epoch 3266/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6379e-04 - val_loss: 5.4299e-04\n",
      "Epoch 3267/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6379e-04 - val_loss: 5.4182e-04\n",
      "Epoch 3268/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6376e-04 - val_loss: 5.4232e-04\n",
      "Epoch 3269/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6377e-04 - val_loss: 5.4450e-04\n",
      "Epoch 3270/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6371e-04 - val_loss: 5.4368e-04\n",
      "Epoch 3271/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6370e-04 - val_loss: 5.4321e-04\n",
      "Epoch 3272/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6367e-04 - val_loss: 5.4338e-04\n",
      "Epoch 3273/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6373e-04 - val_loss: 5.4094e-04\n",
      "Epoch 3274/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6371e-04 - val_loss: 5.4317e-04\n",
      "Epoch 3275/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6369e-04 - val_loss: 5.4054e-04\n",
      "Epoch 3276/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6379e-04 - val_loss: 5.4207e-04\n",
      "Epoch 3277/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6377e-04 - val_loss: 5.4448e-04\n",
      "Epoch 3278/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6373e-04 - val_loss: 5.4334e-04\n",
      "Epoch 3279/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6374e-04 - val_loss: 5.4265e-04\n",
      "Epoch 3280/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6369e-04 - val_loss: 5.4143e-04\n",
      "Epoch 3281/10000\n",
      "45507/45507 [==============================] - 1s 23us/step - loss: 5.6369e-04 - val_loss: 5.4212e-04\n",
      "Epoch 3282/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6374e-04 - val_loss: 5.4106e-04\n",
      "Epoch 3283/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6369e-04 - val_loss: 5.4438e-04\n",
      "Epoch 3284/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6361e-04 - val_loss: 5.4466e-04\n",
      "Epoch 3285/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6369e-04 - val_loss: 5.4376e-04\n",
      "Epoch 3286/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6375e-04 - val_loss: 5.4506e-04\n",
      "Epoch 3287/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6371e-04 - val_loss: 5.4288e-04\n",
      "Epoch 3288/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6371e-04 - val_loss: 5.4250e-04\n",
      "Epoch 3289/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6363e-04 - val_loss: 5.4208e-04\n",
      "Epoch 3290/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6360e-04 - val_loss: 5.4112e-04\n",
      "Epoch 3291/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6366e-04 - val_loss: 5.4440e-04\n",
      "Epoch 3292/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6360e-04 - val_loss: 5.4590e-04\n",
      "Epoch 3293/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6373e-04 - val_loss: 5.4338e-04\n",
      "Epoch 3294/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6368e-04 - val_loss: 5.4332e-04\n",
      "Epoch 3295/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6361e-04 - val_loss: 5.4419e-04\n",
      "Epoch 3296/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6364e-04 - val_loss: 5.4066e-04\n",
      "Epoch 3297/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6365e-04 - val_loss: 5.4662e-04\n",
      "Epoch 3298/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6360e-04 - val_loss: 5.4167e-04\n",
      "Epoch 3299/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6367e-04 - val_loss: 5.4352e-04\n",
      "Epoch 3300/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.6368e-04 - val_loss: 5.4459e-04\n",
      "Epoch 3301/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6368e-04 - val_loss: 5.4445e-04\n",
      "Epoch 3302/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6352e-04 - val_loss: 5.4129e-04\n",
      "Epoch 3303/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6364e-04 - val_loss: 5.4317e-04\n",
      "Epoch 3304/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6357e-04 - val_loss: 5.4189e-04\n",
      "Epoch 3305/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6368e-04 - val_loss: 5.4495e-04\n",
      "Epoch 3306/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6361e-04 - val_loss: 5.4555e-04\n",
      "Epoch 3307/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6358e-04 - val_loss: 5.4087e-04\n",
      "Epoch 3308/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6354e-04 - val_loss: 5.4213e-04\n",
      "Epoch 3309/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6361e-04 - val_loss: 5.4220e-04\n",
      "Epoch 3310/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6365e-04 - val_loss: 5.4498e-04\n",
      "Epoch 3311/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6360e-04 - val_loss: 5.4501e-04\n",
      "Epoch 3312/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6364e-04 - val_loss: 5.4387e-04\n",
      "Epoch 3313/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6357e-04 - val_loss: 5.4979e-04\n",
      "Epoch 3314/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6358e-04 - val_loss: 5.4172e-04\n",
      "Epoch 3315/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6357e-04 - val_loss: 5.4463e-04\n",
      "Epoch 3316/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6360e-04 - val_loss: 5.4332e-04\n",
      "Epoch 3317/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6363e-04 - val_loss: 5.4246e-04\n",
      "Epoch 3318/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6360e-04 - val_loss: 5.4246e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3319/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6351e-04 - val_loss: 5.4414e-04\n",
      "Epoch 3320/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6356e-04 - val_loss: 5.4291e-04\n",
      "Epoch 3321/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6351e-04 - val_loss: 5.4303e-04\n",
      "Epoch 3322/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6351e-04 - val_loss: 5.4341e-04\n",
      "Epoch 3323/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6353e-04 - val_loss: 5.4388e-04\n",
      "Epoch 3324/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6354e-04 - val_loss: 5.4387e-04\n",
      "Epoch 3325/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6353e-04 - val_loss: 5.4272e-04\n",
      "Epoch 3326/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6353e-04 - val_loss: 5.4370e-04\n",
      "Epoch 3327/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6365e-04 - val_loss: 5.4451e-04\n",
      "Epoch 3328/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6351e-04 - val_loss: 5.4375e-04\n",
      "Epoch 3329/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6349e-04 - val_loss: 5.4254e-04\n",
      "Epoch 3330/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6359e-04 - val_loss: 5.4434e-04\n",
      "Epoch 3331/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6352e-04 - val_loss: 5.4296e-04\n",
      "Epoch 3332/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6354e-04 - val_loss: 5.4307e-04\n",
      "Epoch 3333/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6358e-04 - val_loss: 5.4359e-04\n",
      "Epoch 3334/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6335e-04 - val_loss: 5.4581e-04\n",
      "Epoch 3335/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6356e-04 - val_loss: 5.4274e-04\n",
      "Epoch 3336/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6355e-04 - val_loss: 5.4351e-04\n",
      "Epoch 3337/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6353e-04 - val_loss: 5.4434e-04\n",
      "Epoch 3338/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6337e-04 - val_loss: 5.4286e-04\n",
      "Epoch 3339/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6348e-04 - val_loss: 5.4131e-04\n",
      "Epoch 3340/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6355e-04 - val_loss: 5.4455e-04\n",
      "Epoch 3341/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6346e-04 - val_loss: 5.4429e-04\n",
      "Epoch 3342/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6342e-04 - val_loss: 5.4253e-04\n",
      "Epoch 3343/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6346e-04 - val_loss: 5.4226e-04\n",
      "Epoch 3344/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6344e-04 - val_loss: 5.4277e-04\n",
      "Epoch 3345/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6342e-04 - val_loss: 5.4300e-04\n",
      "Epoch 3346/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6346e-04 - val_loss: 5.4185e-04\n",
      "Epoch 3347/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6340e-04 - val_loss: 5.4576e-04\n",
      "Epoch 3348/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6356e-04 - val_loss: 5.4329e-04\n",
      "Epoch 3349/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6356e-04 - val_loss: 5.4214e-04\n",
      "Epoch 3350/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6337e-04 - val_loss: 5.4092e-04\n",
      "Epoch 3351/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6345e-04 - val_loss: 5.4198e-04\n",
      "Epoch 3352/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6350e-04 - val_loss: 5.4410e-04\n",
      "Epoch 3353/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6344e-04 - val_loss: 5.4140e-04\n",
      "Epoch 3354/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6345e-04 - val_loss: 5.4281e-04\n",
      "Epoch 3355/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6346e-04 - val_loss: 5.4363e-04\n",
      "Epoch 3356/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6338e-04 - val_loss: 5.4596e-04\n",
      "Epoch 3357/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6341e-04 - val_loss: 5.4134e-04\n",
      "Epoch 3358/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6342e-04 - val_loss: 5.4044e-04\n",
      "Epoch 3359/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6349e-04 - val_loss: 5.4402e-04\n",
      "Epoch 3360/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6339e-04 - val_loss: 5.4644e-04\n",
      "Epoch 3361/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6336e-04 - val_loss: 5.4365e-04\n",
      "Epoch 3362/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6335e-04 - val_loss: 5.4364e-04\n",
      "Epoch 3363/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6337e-04 - val_loss: 5.4365e-04\n",
      "Epoch 3364/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6343e-04 - val_loss: 5.4304e-04\n",
      "Epoch 3365/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6339e-04 - val_loss: 5.4287e-04\n",
      "Epoch 3366/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6338e-04 - val_loss: 5.4373e-04\n",
      "Epoch 3367/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6332e-04 - val_loss: 5.4544e-04\n",
      "Epoch 3368/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6340e-04 - val_loss: 5.4246e-04\n",
      "Epoch 3369/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6344e-04 - val_loss: 5.4387e-04\n",
      "Epoch 3370/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6330e-04 - val_loss: 5.4225e-04\n",
      "Epoch 3371/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6342e-04 - val_loss: 5.4391e-04\n",
      "Epoch 3372/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6335e-04 - val_loss: 5.4645e-04\n",
      "Epoch 3373/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6338e-04 - val_loss: 5.4423e-04\n",
      "Epoch 3374/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6333e-04 - val_loss: 5.4325e-04\n",
      "Epoch 3375/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6334e-04 - val_loss: 5.4160e-04\n",
      "Epoch 3376/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6338e-04 - val_loss: 5.4407e-04\n",
      "Epoch 3377/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6341e-04 - val_loss: 5.4193e-04\n",
      "Epoch 3378/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6341e-04 - val_loss: 5.4499e-04\n",
      "Epoch 3379/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6338e-04 - val_loss: 5.4337e-04\n",
      "Epoch 3380/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6346e-04 - val_loss: 5.4418e-04\n",
      "Epoch 3381/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6328e-04 - val_loss: 5.4493e-04\n",
      "Epoch 3382/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6342e-04 - val_loss: 5.4261e-04\n",
      "Epoch 3383/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6331e-04 - val_loss: 5.4305e-04\n",
      "Epoch 3384/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6329e-04 - val_loss: 5.4157e-04\n",
      "Epoch 3385/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6335e-04 - val_loss: 5.4254e-04\n",
      "Epoch 3386/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6324e-04 - val_loss: 5.4429e-04\n",
      "Epoch 3387/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6331e-04 - val_loss: 5.4250e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3388/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6335e-04 - val_loss: 5.4347e-04\n",
      "Epoch 3389/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6326e-04 - val_loss: 5.4493e-04\n",
      "Epoch 3390/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6329e-04 - val_loss: 5.4150e-04\n",
      "Epoch 3391/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6335e-04 - val_loss: 5.4415e-04\n",
      "Epoch 3392/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6335e-04 - val_loss: 5.4578e-04\n",
      "Epoch 3393/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6330e-04 - val_loss: 5.4446e-04\n",
      "Epoch 3394/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6325e-04 - val_loss: 5.4483e-04\n",
      "Epoch 3395/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6328e-04 - val_loss: 5.4255e-04\n",
      "Epoch 3396/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6332e-04 - val_loss: 5.4407e-04\n",
      "Epoch 3397/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6336e-04 - val_loss: 5.4296e-04\n",
      "Epoch 3398/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6326e-04 - val_loss: 5.4401e-04\n",
      "Epoch 3399/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6325e-04 - val_loss: 5.4241e-04\n",
      "Epoch 3400/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6325e-04 - val_loss: 5.4189e-04\n",
      "Epoch 3401/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6325e-04 - val_loss: 5.4274e-04\n",
      "Epoch 3402/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6326e-04 - val_loss: 5.4333e-04\n",
      "Epoch 3403/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6323e-04 - val_loss: 5.4264e-04\n",
      "Epoch 3404/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6317e-04 - val_loss: 5.4181e-04\n",
      "Epoch 3405/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6329e-04 - val_loss: 5.4169e-04\n",
      "Epoch 3406/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6329e-04 - val_loss: 5.4599e-04\n",
      "Epoch 3407/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6323e-04 - val_loss: 5.4604e-04\n",
      "Epoch 3408/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6327e-04 - val_loss: 5.4415e-04\n",
      "Epoch 3409/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6318e-04 - val_loss: 5.4221e-04\n",
      "Epoch 3410/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6328e-04 - val_loss: 5.4341e-04\n",
      "Epoch 3411/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6339e-04 - val_loss: 5.4468e-04\n",
      "Epoch 3412/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6322e-04 - val_loss: 5.4072e-04\n",
      "Epoch 3413/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6318e-04 - val_loss: 5.4282e-04\n",
      "Epoch 3414/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6329e-04 - val_loss: 5.4327e-04\n",
      "Epoch 3415/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6328e-04 - val_loss: 5.4620e-04\n",
      "Epoch 3416/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6307e-04 - val_loss: 5.4153e-04\n",
      "Epoch 3417/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6321e-04 - val_loss: 5.4300e-04\n",
      "Epoch 3418/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6328e-04 - val_loss: 5.4283e-04\n",
      "Epoch 3419/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6321e-04 - val_loss: 5.4347e-04\n",
      "Epoch 3420/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6322e-04 - val_loss: 5.4256e-04\n",
      "Epoch 3421/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6319e-04 - val_loss: 5.4162e-04\n",
      "Epoch 3422/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6320e-04 - val_loss: 5.4458e-04\n",
      "Epoch 3423/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6319e-04 - val_loss: 5.4327e-04\n",
      "Epoch 3424/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6317e-04 - val_loss: 5.4327e-04\n",
      "Epoch 3425/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6315e-04 - val_loss: 5.4352e-04\n",
      "Epoch 3426/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6318e-04 - val_loss: 5.4390e-04\n",
      "Epoch 3427/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6315e-04 - val_loss: 5.4137e-04\n",
      "Epoch 3428/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6316e-04 - val_loss: 5.4430e-04\n",
      "Epoch 3429/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6315e-04 - val_loss: 5.4413e-04\n",
      "Epoch 3430/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6313e-04 - val_loss: 5.4362e-04\n",
      "Epoch 3431/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6319e-04 - val_loss: 5.4271e-04\n",
      "Epoch 3432/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6316e-04 - val_loss: 5.4526e-04\n",
      "Epoch 3433/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6321e-04 - val_loss: 5.4316e-04\n",
      "Epoch 3434/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6307e-04 - val_loss: 5.4324e-04\n",
      "Epoch 3435/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6317e-04 - val_loss: 5.4349e-04\n",
      "Epoch 3436/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6311e-04 - val_loss: 5.4408e-04\n",
      "Epoch 3437/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6313e-04 - val_loss: 5.4280e-04\n",
      "Epoch 3438/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6309e-04 - val_loss: 5.4633e-04\n",
      "Epoch 3439/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6320e-04 - val_loss: 5.4283e-04\n",
      "Epoch 3440/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6317e-04 - val_loss: 5.4806e-04\n",
      "Epoch 3441/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6310e-04 - val_loss: 5.4376e-04\n",
      "Epoch 3442/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6317e-04 - val_loss: 5.4273e-04\n",
      "Epoch 3443/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6315e-04 - val_loss: 5.4441e-04\n",
      "Epoch 3444/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6314e-04 - val_loss: 5.4546e-04\n",
      "Epoch 3445/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6310e-04 - val_loss: 5.4405e-04\n",
      "Epoch 3446/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6305e-04 - val_loss: 5.4336e-04\n",
      "Epoch 3447/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6312e-04 - val_loss: 5.4319e-04\n",
      "Epoch 3448/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6313e-04 - val_loss: 5.4289e-04\n",
      "Epoch 3449/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6305e-04 - val_loss: 5.4084e-04\n",
      "Epoch 3450/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6301e-04 - val_loss: 5.4340e-04\n",
      "Epoch 3451/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6306e-04 - val_loss: 5.4455e-04\n",
      "Epoch 3452/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6312e-04 - val_loss: 5.4322e-04\n",
      "Epoch 3453/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6316e-04 - val_loss: 5.4277e-04\n",
      "Epoch 3454/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6297e-04 - val_loss: 5.4630e-04\n",
      "Epoch 3455/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6322e-04 - val_loss: 5.4380e-04\n",
      "Epoch 3456/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6305e-04 - val_loss: 5.4221e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3457/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6310e-04 - val_loss: 5.4130e-04\n",
      "Epoch 3458/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6304e-04 - val_loss: 5.4351e-04\n",
      "Epoch 3459/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6303e-04 - val_loss: 5.4344e-04\n",
      "Epoch 3460/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6298e-04 - val_loss: 5.4522e-04\n",
      "Epoch 3461/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6317e-04 - val_loss: 5.4273e-04\n",
      "Epoch 3462/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6301e-04 - val_loss: 5.4607e-04\n",
      "Epoch 3463/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6298e-04 - val_loss: 5.4310e-04\n",
      "Epoch 3464/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6311e-04 - val_loss: 5.4175e-04\n",
      "Epoch 3465/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6308e-04 - val_loss: 5.4444e-04\n",
      "Epoch 3466/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6304e-04 - val_loss: 5.4599e-04\n",
      "Epoch 3467/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6309e-04 - val_loss: 5.4476e-04\n",
      "Epoch 3468/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.6308e-04 - val_loss: 5.4157e-04\n",
      "Epoch 3469/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6303e-04 - val_loss: 5.4248e-04\n",
      "Epoch 3470/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6301e-04 - val_loss: 5.4497e-04\n",
      "Epoch 3471/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6304e-04 - val_loss: 5.4287e-04\n",
      "Epoch 3472/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6298e-04 - val_loss: 5.4322e-04\n",
      "Epoch 3473/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6302e-04 - val_loss: 5.4067e-04\n",
      "Epoch 3474/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6300e-04 - val_loss: 5.4453e-04\n",
      "Epoch 3475/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6292e-04 - val_loss: 5.4257e-04\n",
      "Epoch 3476/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6299e-04 - val_loss: 5.4290e-04\n",
      "Epoch 3477/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6300e-04 - val_loss: 5.4228e-04\n",
      "Epoch 3478/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6302e-04 - val_loss: 5.4291e-04\n",
      "Epoch 3479/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6301e-04 - val_loss: 5.4483e-04\n",
      "Epoch 3480/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6300e-04 - val_loss: 5.4345e-04\n",
      "Epoch 3481/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6303e-04 - val_loss: 5.4527e-04\n",
      "Epoch 3482/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6304e-04 - val_loss: 5.4493e-04\n",
      "Epoch 3483/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6297e-04 - val_loss: 5.4433e-04\n",
      "Epoch 3484/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6297e-04 - val_loss: 5.4332e-04\n",
      "Epoch 3485/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6302e-04 - val_loss: 5.4322e-04\n",
      "Epoch 3486/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6297e-04 - val_loss: 5.4317e-04\n",
      "Epoch 3487/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6296e-04 - val_loss: 5.4496e-04\n",
      "Epoch 3488/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6297e-04 - val_loss: 5.4522e-04\n",
      "Epoch 3489/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6292e-04 - val_loss: 5.4310e-04\n",
      "Epoch 3490/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6292e-04 - val_loss: 5.4270e-04\n",
      "Epoch 3491/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6295e-04 - val_loss: 5.4711e-04\n",
      "Epoch 3492/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6306e-04 - val_loss: 5.4292e-04\n",
      "Epoch 3493/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6293e-04 - val_loss: 5.4516e-04\n",
      "Epoch 3494/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6297e-04 - val_loss: 5.4525e-04\n",
      "Epoch 3495/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6285e-04 - val_loss: 5.4298e-04\n",
      "Epoch 3496/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6300e-04 - val_loss: 5.4207e-04\n",
      "Epoch 3497/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6295e-04 - val_loss: 5.4405e-04\n",
      "Epoch 3498/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6295e-04 - val_loss: 5.4371e-04\n",
      "Epoch 3499/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6298e-04 - val_loss: 5.4399e-04\n",
      "Epoch 3500/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6288e-04 - val_loss: 5.4369e-04\n",
      "Epoch 3501/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6283e-04 - val_loss: 5.4457e-04\n",
      "Epoch 3502/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6293e-04 - val_loss: 5.4222e-04\n",
      "Epoch 3503/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6293e-04 - val_loss: 5.4382e-04\n",
      "Epoch 3504/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6294e-04 - val_loss: 5.4350e-04\n",
      "Epoch 3505/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6291e-04 - val_loss: 5.4654e-04\n",
      "Epoch 3506/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6288e-04 - val_loss: 5.4420e-04\n",
      "Epoch 3507/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6295e-04 - val_loss: 5.4396e-04\n",
      "Epoch 3508/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6294e-04 - val_loss: 5.4405e-04\n",
      "Epoch 3509/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6291e-04 - val_loss: 5.4378e-04\n",
      "Epoch 3510/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6293e-04 - val_loss: 5.4344e-04\n",
      "Epoch 3511/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6294e-04 - val_loss: 5.4471e-04\n",
      "Epoch 3512/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6292e-04 - val_loss: 5.4521e-04\n",
      "Epoch 3513/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6279e-04 - val_loss: 5.4509e-04\n",
      "Epoch 3514/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6290e-04 - val_loss: 5.4382e-04\n",
      "Epoch 3515/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6291e-04 - val_loss: 5.4263e-04\n",
      "Epoch 3516/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6286e-04 - val_loss: 5.4318e-04\n",
      "Epoch 3517/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6287e-04 - val_loss: 5.4340e-04\n",
      "Epoch 3518/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6276e-04 - val_loss: 5.4745e-04\n",
      "Epoch 3519/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6284e-04 - val_loss: 5.4355e-04\n",
      "Epoch 3520/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6292e-04 - val_loss: 5.4129e-04\n",
      "Epoch 3521/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6285e-04 - val_loss: 5.4681e-04\n",
      "Epoch 3522/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6289e-04 - val_loss: 5.4371e-04\n",
      "Epoch 3523/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6285e-04 - val_loss: 5.4364e-04\n",
      "Epoch 3524/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6278e-04 - val_loss: 5.4461e-04\n",
      "Epoch 3525/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6289e-04 - val_loss: 5.4296e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3526/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6281e-04 - val_loss: 5.4509e-04\n",
      "Epoch 3527/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6279e-04 - val_loss: 5.4369e-04\n",
      "Epoch 3528/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6286e-04 - val_loss: 5.4470e-04\n",
      "Epoch 3529/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6287e-04 - val_loss: 5.4240e-04\n",
      "Epoch 3530/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6288e-04 - val_loss: 5.4369e-04\n",
      "Epoch 3531/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6284e-04 - val_loss: 5.4539e-04\n",
      "Epoch 3532/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6281e-04 - val_loss: 5.4438e-04\n",
      "Epoch 3533/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6278e-04 - val_loss: 5.4505e-04\n",
      "Epoch 3534/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6278e-04 - val_loss: 5.4251e-04\n",
      "Epoch 3535/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6285e-04 - val_loss: 5.4366e-04\n",
      "Epoch 3536/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6275e-04 - val_loss: 5.4526e-04\n",
      "Epoch 3537/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6284e-04 - val_loss: 5.4361e-04\n",
      "Epoch 3538/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6285e-04 - val_loss: 5.4486e-04\n",
      "Epoch 3539/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6285e-04 - val_loss: 5.4326e-04\n",
      "Epoch 3540/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6282e-04 - val_loss: 5.4334e-04\n",
      "Epoch 3541/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6276e-04 - val_loss: 5.4420e-04\n",
      "Epoch 3542/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6284e-04 - val_loss: 5.4458e-04\n",
      "Epoch 3543/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6285e-04 - val_loss: 5.4368e-04\n",
      "Epoch 3544/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6289e-04 - val_loss: 5.4337e-04\n",
      "Epoch 3545/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6286e-04 - val_loss: 5.4583e-04\n",
      "Epoch 3546/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6276e-04 - val_loss: 5.4352e-04\n",
      "Epoch 3547/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6274e-04 - val_loss: 5.4463e-04\n",
      "Epoch 3548/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6280e-04 - val_loss: 5.4249e-04\n",
      "Epoch 3549/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6271e-04 - val_loss: 5.4169e-04\n",
      "Epoch 3550/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6286e-04 - val_loss: 5.4454e-04\n",
      "Epoch 3551/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6271e-04 - val_loss: 5.4338e-04\n",
      "Epoch 3552/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6273e-04 - val_loss: 5.4250e-04\n",
      "Epoch 3553/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6272e-04 - val_loss: 5.4357e-04\n",
      "Epoch 3554/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6278e-04 - val_loss: 5.4187e-04\n",
      "Epoch 3555/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6278e-04 - val_loss: 5.4674e-04\n",
      "Epoch 3556/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6280e-04 - val_loss: 5.4351e-04\n",
      "Epoch 3557/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6261e-04 - val_loss: 5.4697e-04\n",
      "Epoch 3558/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6287e-04 - val_loss: 5.4349e-04\n",
      "Epoch 3559/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6265e-04 - val_loss: 5.4525e-04\n",
      "Epoch 3560/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6270e-04 - val_loss: 5.4441e-04\n",
      "Epoch 3561/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6279e-04 - val_loss: 5.4499e-04\n",
      "Epoch 3562/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6263e-04 - val_loss: 5.4298e-04\n",
      "Epoch 3563/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6265e-04 - val_loss: 5.4376e-04\n",
      "Epoch 3564/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6274e-04 - val_loss: 5.4414e-04\n",
      "Epoch 3565/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6271e-04 - val_loss: 5.4417e-04\n",
      "Epoch 3566/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6272e-04 - val_loss: 5.4375e-04\n",
      "Epoch 3567/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6271e-04 - val_loss: 5.4286e-04\n",
      "Epoch 3568/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6267e-04 - val_loss: 5.4323e-04\n",
      "Epoch 3569/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6270e-04 - val_loss: 5.4323e-04\n",
      "Epoch 3570/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6269e-04 - val_loss: 5.4536e-04\n",
      "Epoch 3571/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6268e-04 - val_loss: 5.4402e-04\n",
      "Epoch 3572/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6276e-04 - val_loss: 5.4627e-04\n",
      "Epoch 3573/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6266e-04 - val_loss: 5.4454e-04\n",
      "Epoch 3574/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6273e-04 - val_loss: 5.4368e-04\n",
      "Epoch 3575/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6270e-04 - val_loss: 5.4603e-04\n",
      "Epoch 3576/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6275e-04 - val_loss: 5.4297e-04\n",
      "Epoch 3577/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6271e-04 - val_loss: 5.4345e-04\n",
      "Epoch 3578/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6271e-04 - val_loss: 5.4431e-04\n",
      "Epoch 3579/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6265e-04 - val_loss: 5.4204e-04\n",
      "Epoch 3580/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6271e-04 - val_loss: 5.4536e-04\n",
      "Epoch 3581/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6266e-04 - val_loss: 5.4525e-04\n",
      "Epoch 3582/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6273e-04 - val_loss: 5.4581e-04\n",
      "Epoch 3583/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6255e-04 - val_loss: 5.4396e-04\n",
      "Epoch 3584/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6274e-04 - val_loss: 5.4531e-04\n",
      "Epoch 3585/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6253e-04 - val_loss: 5.4624e-04\n",
      "Epoch 3586/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6262e-04 - val_loss: 5.4292e-04\n",
      "Epoch 3587/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6279e-04 - val_loss: 5.4546e-04\n",
      "Epoch 3588/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6264e-04 - val_loss: 5.4338e-04\n",
      "Epoch 3589/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6266e-04 - val_loss: 5.4611e-04\n",
      "Epoch 3590/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6262e-04 - val_loss: 5.4289e-04\n",
      "Epoch 3591/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6266e-04 - val_loss: 5.4303e-04\n",
      "Epoch 3592/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6266e-04 - val_loss: 5.4571e-04\n",
      "Epoch 3593/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6261e-04 - val_loss: 5.4618e-04\n",
      "Epoch 3594/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6256e-04 - val_loss: 5.4623e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3595/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6264e-04 - val_loss: 5.4304e-04\n",
      "Epoch 3596/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6259e-04 - val_loss: 5.4401e-04\n",
      "Epoch 3597/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6271e-04 - val_loss: 5.4340e-04\n",
      "Epoch 3598/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6256e-04 - val_loss: 5.4341e-04\n",
      "Epoch 3599/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6253e-04 - val_loss: 5.4289e-04\n",
      "Epoch 3600/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6257e-04 - val_loss: 5.4309e-04\n",
      "Epoch 3601/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6267e-04 - val_loss: 5.4452e-04\n",
      "Epoch 3602/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6262e-04 - val_loss: 5.4646e-04\n",
      "Epoch 3603/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6260e-04 - val_loss: 5.4422e-04\n",
      "Epoch 3604/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6255e-04 - val_loss: 5.4522e-04\n",
      "Epoch 3605/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6254e-04 - val_loss: 5.4273e-04\n",
      "Epoch 3606/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6260e-04 - val_loss: 5.4410e-04\n",
      "Epoch 3607/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6264e-04 - val_loss: 5.4494e-04\n",
      "Epoch 3608/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6263e-04 - val_loss: 5.4547e-04\n",
      "Epoch 3609/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6259e-04 - val_loss: 5.4343e-04\n",
      "Epoch 3610/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6257e-04 - val_loss: 5.4356e-04\n",
      "Epoch 3611/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6264e-04 - val_loss: 5.4441e-04\n",
      "Epoch 3612/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6255e-04 - val_loss: 5.4249e-04\n",
      "Epoch 3613/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6254e-04 - val_loss: 5.4338e-04\n",
      "Epoch 3614/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6252e-04 - val_loss: 5.4387e-04\n",
      "Epoch 3615/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6257e-04 - val_loss: 5.4366e-04\n",
      "Epoch 3616/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6256e-04 - val_loss: 5.4261e-04\n",
      "Epoch 3617/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6261e-04 - val_loss: 5.4423e-04\n",
      "Epoch 3618/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6248e-04 - val_loss: 5.4453e-04\n",
      "Epoch 3619/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6255e-04 - val_loss: 5.4482e-04\n",
      "Epoch 3620/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6253e-04 - val_loss: 5.4325e-04\n",
      "Epoch 3621/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6251e-04 - val_loss: 5.4350e-04\n",
      "Epoch 3622/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6248e-04 - val_loss: 5.4534e-04\n",
      "Epoch 3623/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6243e-04 - val_loss: 5.4456e-04\n",
      "Epoch 3624/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6245e-04 - val_loss: 5.4292e-04\n",
      "Epoch 3625/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6261e-04 - val_loss: 5.4350e-04\n",
      "Epoch 3626/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6249e-04 - val_loss: 5.4505e-04\n",
      "Epoch 3627/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6242e-04 - val_loss: 5.4395e-04\n",
      "Epoch 3628/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6258e-04 - val_loss: 5.4401e-04\n",
      "Epoch 3629/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6244e-04 - val_loss: 5.4336e-04\n",
      "Epoch 3630/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6251e-04 - val_loss: 5.4282e-04\n",
      "Epoch 3631/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6247e-04 - val_loss: 5.4397e-04\n",
      "Epoch 3632/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6256e-04 - val_loss: 5.4420e-04\n",
      "Epoch 3633/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6247e-04 - val_loss: 5.4313e-04\n",
      "Epoch 3634/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6258e-04 - val_loss: 5.4455e-04\n",
      "Epoch 3635/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6242e-04 - val_loss: 5.4441e-04\n",
      "Epoch 3636/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6250e-04 - val_loss: 5.4498e-04\n",
      "Epoch 3637/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6245e-04 - val_loss: 5.4375e-04\n",
      "Epoch 3638/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6242e-04 - val_loss: 5.4352e-04\n",
      "Epoch 3639/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6243e-04 - val_loss: 5.4380e-04\n",
      "Epoch 3640/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6255e-04 - val_loss: 5.4378e-04\n",
      "Epoch 3641/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6250e-04 - val_loss: 5.4432e-04\n",
      "Epoch 3642/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6248e-04 - val_loss: 5.4359e-04\n",
      "Epoch 3643/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6250e-04 - val_loss: 5.4489e-04\n",
      "Epoch 3644/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6239e-04 - val_loss: 5.4436e-04\n",
      "Epoch 3645/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6248e-04 - val_loss: 5.4333e-04\n",
      "Epoch 3646/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6255e-04 - val_loss: 5.4598e-04\n",
      "Epoch 3647/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6248e-04 - val_loss: 5.4442e-04\n",
      "Epoch 3648/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6244e-04 - val_loss: 5.4304e-04\n",
      "Epoch 3649/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6242e-04 - val_loss: 5.4640e-04\n",
      "Epoch 3650/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6244e-04 - val_loss: 5.4266e-04\n",
      "Epoch 3651/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6246e-04 - val_loss: 5.4550e-04\n",
      "Epoch 3652/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6251e-04 - val_loss: 5.4464e-04\n",
      "Epoch 3653/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6245e-04 - val_loss: 5.4356e-04\n",
      "Epoch 3654/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6248e-04 - val_loss: 5.4464e-04\n",
      "Epoch 3655/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6246e-04 - val_loss: 5.4636e-04\n",
      "Epoch 3656/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6244e-04 - val_loss: 5.4703e-04\n",
      "Epoch 3657/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6240e-04 - val_loss: 5.4303e-04\n",
      "Epoch 3658/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6243e-04 - val_loss: 5.4198e-04\n",
      "Epoch 3659/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6237e-04 - val_loss: 5.4258e-04\n",
      "Epoch 3660/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6240e-04 - val_loss: 5.4431e-04\n",
      "Epoch 3661/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6238e-04 - val_loss: 5.4405e-04\n",
      "Epoch 3662/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6243e-04 - val_loss: 5.4701e-04\n",
      "Epoch 3663/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6242e-04 - val_loss: 5.4366e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3664/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6239e-04 - val_loss: 5.4293e-04\n",
      "Epoch 3665/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6237e-04 - val_loss: 5.4485e-04\n",
      "Epoch 3666/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6244e-04 - val_loss: 5.4325e-04\n",
      "Epoch 3667/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.6231e-04 - val_loss: 5.4328e-04\n",
      "Epoch 3668/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6237e-04 - val_loss: 5.4628e-04\n",
      "Epoch 3669/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6243e-04 - val_loss: 5.4498e-04\n",
      "Epoch 3670/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6239e-04 - val_loss: 5.4361e-04\n",
      "Epoch 3671/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6237e-04 - val_loss: 5.4438e-04\n",
      "Epoch 3672/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6240e-04 - val_loss: 5.4543e-04\n",
      "Epoch 3673/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6239e-04 - val_loss: 5.4304e-04\n",
      "Epoch 3674/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6237e-04 - val_loss: 5.4741e-04\n",
      "Epoch 3675/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6248e-04 - val_loss: 5.4373e-04\n",
      "Epoch 3676/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6233e-04 - val_loss: 5.4519e-04\n",
      "Epoch 3677/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6238e-04 - val_loss: 5.4684e-04\n",
      "Epoch 3678/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6240e-04 - val_loss: 5.4459e-04\n",
      "Epoch 3679/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6237e-04 - val_loss: 5.4850e-04\n",
      "Epoch 3680/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6232e-04 - val_loss: 5.4472e-04\n",
      "Epoch 3681/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6236e-04 - val_loss: 5.4370e-04\n",
      "Epoch 3682/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6243e-04 - val_loss: 5.4482e-04\n",
      "Epoch 3683/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6233e-04 - val_loss: 5.4372e-04\n",
      "Epoch 3684/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6240e-04 - val_loss: 5.4457e-04\n",
      "Epoch 3685/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6229e-04 - val_loss: 5.4234e-04\n",
      "Epoch 3686/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6236e-04 - val_loss: 5.4398e-04\n",
      "Epoch 3687/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6240e-04 - val_loss: 5.4641e-04\n",
      "Epoch 3688/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6232e-04 - val_loss: 5.4301e-04\n",
      "Epoch 3689/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6231e-04 - val_loss: 5.4390e-04\n",
      "Epoch 3690/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6234e-04 - val_loss: 5.4204e-04\n",
      "Epoch 3691/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6229e-04 - val_loss: 5.4532e-04\n",
      "Epoch 3692/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6232e-04 - val_loss: 5.4588e-04\n",
      "Epoch 3693/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6230e-04 - val_loss: 5.4347e-04\n",
      "Epoch 3694/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6230e-04 - val_loss: 5.4544e-04\n",
      "Epoch 3695/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6229e-04 - val_loss: 5.4373e-04\n",
      "Epoch 3696/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6239e-04 - val_loss: 5.4685e-04\n",
      "Epoch 3697/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6225e-04 - val_loss: 5.4419e-04\n",
      "Epoch 3698/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6231e-04 - val_loss: 5.4715e-04\n",
      "Epoch 3699/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6231e-04 - val_loss: 5.4529e-04\n",
      "Epoch 3700/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6234e-04 - val_loss: 5.4560e-04\n",
      "Epoch 3701/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6227e-04 - val_loss: 5.4350e-04\n",
      "Epoch 03701: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc370884908>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algoritmo='RMSprop'\n",
    "experimento=\"scaled_{}_encoder_without_bias_tanh_tanh_lr_{}\".format(supermax,factor_aprendizaje)\n",
    "tensorboard=TensorBoard(log_dir=\"/home/rgadea3/EXPERIMENTOS/nuevas_investigaciones_2018/experimentos/logs/{}{}{}{}\".format(encoding_dim,algoritmo,experimento,datetime.now()))\n",
    "#modelCheckpoint=ModelCheckpoint(\"/home/rgadea3/EXPERIMENTOS/nuevas_investigaciones_2018/experimentos/logs/\", monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "early_stop=EarlyStopping(monitor='val_loss', min_delta=0, patience=500, verbose=2, mode='auto', baseline=None)\n",
    "autoencoder.fit(x_train_scaled, x_train_scaled,\n",
    "                epochs=10000,\n",
    "                batch_size=200,\n",
    "                shuffle=False,\n",
    "                callbacks=[tensorboard, early_stop],\n",
    "                validation_data=(x_test_scaled, x_test_scaled))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15170/15170 [==============================] - 1s 71us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0005435026355213842"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.evaluate(x=x_test_scaled,y=x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save_weights('../redes_compresoras/compresor_python_{}{}{}{}'.format(encoding_dim,algoritmo,experimento,datetime.now()))\n",
    "#np.savez('../redes_compresoras/maxmin_python_ver_rms_prop_scaled_min_max_ver2', min_max_scaler.data_max_, min_max_scaler.data_min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc370884780>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl0m+WdL/DvT4u12fIq20m8xsQkIRASnISthCXQlLa0FNqydIUW6DJT7vTennY6M3funfb0dm5bupzScylQ9rVAWYctEKABkjg7SYiTOLbjXXZsS5YtWZae+4cl48SLXtnaXvP9nONjR379+pfX8tePnvdZRCkFIiLSD0O6CyAiovgwuImIdIbBTUSkMwxuIiKdYXATEekMg5uISGcY3EREOsPgJiLSGQY3EZHOmJJx0qKiIlVVVZWMUxMRzUs7duzoUUq5tByblOCuqqpCfX19Mk5NRDQviUiz1mPZVUJEpDMMbiIinWFwExHpDIObiEhnGNxERDrD4CYi0hkGNxGRzjC4iYh0hsFNRKQzSZk5mS6PbG2Z9NgN6yrSUAkRUfKwxU1EpDMMbiIinWFwExHpjKY+bhFpAuAFEAIwqpSqS2ZRREQ0vXhuTl6ilOpJWiVERKQJu0qIiHRGa3ArAK+KyA4RuSWZBRER0cy0dpVcoJRqF5FiAK+JyIdKqbcnHhAJ9FsAoKKCY6eJiJJFU4tbKdUeed8N4BkAa6c45i6lVJ1Sqs7l0rRtGhERzULM4BYRh4jkRD8GcAWAD5JdGBERTU1LV0kJgGdEJHr8I0qpl5NaFRERTStmcCulGgGsTEEtRESkAYcDEhHpDIObiEhnGNxERDrD4CYi0hkGNxGRzjC4iYh0hsFNRKQzDG4iIp1hcBMR6QyDm4hIZxjcREQ6w+AmItIZBjcRkc4wuImIdIbBTUSkMwxuIiKdYXATEekMg5uISGcY3EREOsPgJiLSGQY3EZHOMLiJiHSGwU1EpDMMbiIinWFwExHpDIObiEhnGNxERDrD4CYi0hkGNxGRzjC4iYh0hsFNRKQzmoNbRIwisktEXkhmQURENLN4Wtw/AHAwWYUQEZE2moJbRMoAfBrA3ckth4iIYtHa4v4tgB8BCCexFiIi0iBmcIvIZwB0K6V2xDjuFhGpF5F6t9udsAKJiOhkWlrcFwC4SkSaADwG4FIReejUg5RSdyml6pRSdS6XK8FlEhFRVMzgVkr9RClVppSqAnAdgDeUUl9JemVERDQljuMmItIZUzwHK6U2A9iclEqIiEgTtriJiHSGwU1EpDMMbiIinWFwExHpDIObiEhnGNxERDrD4CYi0hkGNxGRzjC4iYh0Jq6Zk0RE88kjW1smPXbDuoo0VBIftriJiHSGwU1EpDMMbiIinWFwExHpDIObiEhnGNxERDrD4CYi0hkGNxGRzjC4iYh0hsFNRKQzDG4iIp1hcBMR6QyDm4hIZxjcREQ6w+AmItIZBjcRkc4wuImIdIbBTUSkMwxuIiKdYXATEekMg5uISGdiBreIWEVkm4jsEZH9IvK/UlEYERFNzaThmACAS5VSgyJiBvB3EfkvpdT7Sa6NiIimEDO4lVIKwGDkn+bIm0pmUUREND1NfdwiYhSR3QC6AbymlNo6xTG3iEi9iNS73e5E10lERBGaglspFVJKnQ2gDMBaEVkxxTF3KaXqlFJ1Lpcr0XUSEVFEXKNKlFL9ADYD2JiUaoiIKCYto0pcIpIX+dgGYAOAD5NdGBERTU3LqJIFAO4XESPGgv4JpdQLyS2LiIimo2VUyV4Aq1JQCxERacCZk0REOsPgJiLSGQY3EZHOMLiJiHSGwU1EpDMMbiIinWFwExHpDIObiEhnGNxERDrD4CYi0hkGNxGRzjC4iYh0hsFNRKQzDG4iIp1hcBMR6QyDm4hIZxjcREQ6w+AmItIZBjcRkc4wuImIdIbBTUSkMwxuIiKdYXATEemMKd0FJMLQyCg8w6PpLoOIKCXmRYv7V6804PI73sJggOFNRPPfvAjufW398PpH8caH3ekuhYgo6XQf3EopNHQNwmQQbDvWix5vIN0lERElle6Du9sbwMBwEN+5uAYmgwGvHOhMd0lEREml++Bu6PICAM6rKcQnaouwv92Dtv7hNFdFRJQ8ug/uQ51jwX16SQ7OqcgHALT1MbiJaP7SfXAf7hpEoSMLhdkWOG1mGAToGxpJd1lEREkTM7hFpFxE3hSRgyKyX0R+kIrCtDrU5UVtSQ4AwCCCXJsZ/QxuIprHtLS4RwH8UCm1DMC5AL4nIsuTW5Y2Sikc7vKitiR7/LE8exb6h4JprIqIKLliBrdSqkMptTPysRfAQQCLkl2YFm39w/CNhLAk0uIGgHy7Gf3DDG4imr/i6uMWkSoAqwBsneJzt4hIvYjUu93uxFQXw+GuQQDA6aUfBXeePQue4SBCYZWSGoiIUk1zcItINoCnANyulPKc+nml1F1KqTqlVJ3L5UpkjdOKDgWsLZ4Q3DYzFIABtrqJaJ7SFNwiYsZYaD+slHo6uSVpd6jLixKnBbl28/hjefYsAOANSiKat7SMKhEA9wA4qJT6TfJL0u5w1+D4iJKo/EiI8wYlEc1XWlrcFwD4KoBLRWR35O3KJNcVk1IKR7oHcVpx9kmP59rGgrtvmC1uIpqfYq7HrZT6OwBJQS1x8QyPYjgYwqI820mPm4wG5FhNbHET0byl25mT3V4/AMCVY5n0uTybmbMniWje0nFwjy3fWpxjnfQ5TsIhovlMx8E91uIudk5ucefbzRgYDiKsOJabiOYf/Qa3J9rinqKrxJ6FUFhh0M+tzIho/tFvcHsDsJmNyLZMvr+aNz4kkP3cRDT/6Dq4i50WjA0zP1l0Ek4fZ08S0Tyk2+B2e/1TdpMAQL6Nk3CIaP7SbXB3ewNTjigBAIvZCJvZyK4SIpqXdBvcbk9gyjHcUXl2M1vcRDQv6TK4h0dC8AZGZwxup9UMj5/BTUTzjy6De3wM90zBbTPBw+GARBSnYCic7hJi0mlwR8ZwO6fu4waAHKsZQ4FRXfwQiCgz9AwGcN4vNuHPbzemu5QZ6TO4Z5h8E+W0jm2o0DMYSFFVRKRng4FR3PduE3oGR7Dpw650lzMjfQa3hq6SHOvYxJwuD4ObiGYWDIXx0PvN8AwHcd7iQuxq6cfIaOa+WtdlcLu9AZgMgvzIRJupOK1jY7m7PP5UlUVEOrW3tR8tJ4Zw7Tll+Np5lQiMhrGvbSDdZU1Ll8Hd7R0bCmgwTL9MeI7NNH4sEdFM2vv9yDIZsGJRLtZUFwAAtjedSHNV09N1cM8k22KCAOhmi5uIYuj0+FGSY4FBBEXZFix2ObD9GIM7obo90093jzKIINtqYlcJEc1IKYUujx8lE0apra0qQH1zH8LhzFwaWpfB7fYG4JpmuvtETquZXSVENCNvYBRDIyGU5n6UKWuqCjAwHERDtzeNlU1Pd8EdDIXR6xuJ2eIGxkaWcFQJEc2ka2DsVflJLe5IP/e2DO0u0V1wR8dlT7XzzamcVjP7uIloRp2RjCidENxl+TaUOq0M7kRxz7DX5KlyrCb0+kYyejwmEaVXl8ePHIsJjgmbsogI1lQXYEdzXxorm57uglvLrMmo6Fhuzp4koul0evwoyZ3cEFxamoOOAT+GRjJvzSP9BbdXe1dJdCw3R5YQ0VTCSqHbEzipmySqstAOAGjuHUp1WTHpLri7PH6IAEXZ2lvcvEFJRFPpHRzBaFiddGMyqqrQAQBo7vWluqyYdBnchQ4LzMbYpUfXK3F72eImosmmujEZVcEWd+J0efwozY3d2gYAh8UEo0HY4iaiKXV5/BBM3fXqtJpR4MhCE4N77ro8AZRoGFECjM2edGVb2MdNRFPqHPCjwJE17Sv4ykI7Wk6wq2TOur3+GTdQOFWJ04Iuzp4koim4BwNT9m9HVRbY0dTDFvecBENh9AyOoETDiJIoV46Vk3CIaJJQWOGEbwSF2dMvD11Z6ED7wDACo6EUVhZbzOAWkXtFpFtEPkhFQTOJTr6Z6S/kqUqcFq5XQkSTdAwMIxRWKHRM3xCsLLRDKaC1bziFlcWmpcV9H4CNSa5Dk2hfdTwt7hKnFSc4e5KIThHtAonV4gYyb0igKdYBSqm3RaQq+aXE9lFwa29xR4f5dHn8KC+wJ6UuIhrzyNaWSY/dsK4iDZXE1hQJ40LH9MFdFRkSmGn93Lrq444O64snuMvybQCA432ZdeGJKL2aenwwGQROm3naYwocWci2mNByIrPyI2aLWysRuQXALQBQUZGcv7BdHj9MBkHBDHtNnirayj5+YgioSUpZMU3VCgEytyVCNFcjo2HUN59AU+8QXtjbjnx7Fs4qy0WO9aOQTPfzv6l3CAWOLBhk+i0QRQSVhfbx1nmmSFhwK6XuAnAXANTV1SVl24guTwDFMfaaPNWCXCtMBsmYv5gjo2Ec7PSguXcIT9Qfh9EgKHBk4cxFubj5wmo8u7t9yq9L95OcSAulFN5v7MUbh9zwBUaRZzdjKBDCSCiMTR924YrlpVhbXTBjWKZKU69P09IZVYUOHOzwpKAi7RIW3KkQ7xhuADAZDViUb0PLifTeFQ4rhd0t/Xj1QCc8/lFkReoSAVr7hvDagS7c/U4jNq4oxcqyPEgGPLGJ4hEOK7y4rwPvHu3FYpcDly2tQHWRA0opuL0BPL+3Hc/tacfu4/24Mc0NkVBYoaV3COsiGybMpKLQjlcPdGI0FIZJw1IbqRAzuEXkUQAXAygSkVYA/1MpdU+yC5tKl8eP6iJH3F9XUWBPa4s7MBrCA+8141iPD2X5NnyxrhxVhQ4YJ7xyaOn14fm9HXiivhVe/yg+scSVtnqJ4hUKK/z4qb1492gvzq8pxJVnLhhvVYsIip1W3HRBNXYf78ffdrfhzs1HceGSIpyxMDct9XZ6/BgJhVGoqcVtRzCk0DGQOQMcYv75UEpdr5RaoJQyK6XK0hXaQGS6e5wtbmCsn/t4moLbHwzhwfea0dzrw9WrFuG29TWocWWfFNoAUFHowHcursEZC514+YNOHHUPpqVeongppfAvf/sAT+5oxaVLi/HpCaE9kYhgVUU+brlo7GbTtX96Dy9/0JHqcgGM3ZgEZh4KGFVRMNZYzKR+7sxo92vgD4YwMBycVXBXFNhxwjcCrz+YhMqmNzIaxq0P7sCxHh+uPacMa6pm7tsziODa1WVw5Vjw6LYW9A2NpLBaIu0e2doy/vbtB+rx6LYWrK91YcOykpjdfIvybPjOxTU4vTQHtz20E3/YdBhKpXY3dS1DAaOir/IzabEp3fRxz2YMd1TF+MiSYSxfOP3Qn0T7/abDeKvBjatXLcLZ5fmavsZiNuIr51bizs1H8NTOVtx8QTX7uylj1TedwOsHu7GqPA9XLC/R/HVOqxmP3XIufvzUXvz6tQY09Q7hl9eciSfqW6c8PtE355t6fLCYDDMOBYwqcVpgMxtxzM0Wd9w+GsOtfdZkVDS4U9nPvaulD3duPjLe0o5HUbYFG5aVoNHtQ0MXu0woM+053o9ndrWhtiQbX1hdFncDw2o24o4vn43/tqEWT+1sxXcf3onRUGpmODf1DqGy0K5pdIuIoLrIgWM9mfO7qKPgnn2L+6Sx3CngD4bwwyf3oNRpxb99dvmszrG2ugCFjiy8vL8D4RS/jCSK5UD7AJ7ccRxVRQ7csLZy0j0brUQEP9iwBP/+2eV49UAXHni/GaPh5Id3U49vfDq7FtVFjozqKtFfcGtci3uiXJsZuTZzylrcv371EBrdPvzntSvHt0+Ll8lgwBVnlKLLE8DODN1pmj6eNh/qxqPbj2NRng1fO7cSWabZxcjEfvIskxFfWLUIR7oH8cLe5N6wDIcVmk8MxTVCrbrIgZYTQwim6BVBLLoJ7m5vINInNbtu+VQNCfyw04N7tzThujXluHBJ0ZzOtWKhE+X5Nrx+sAv+YGYtK0kfT+8d7cWtD+5ASY4F3zi/GhazMWHnrqsqwEVLirDt2AlsPdabsPOeqsPjx8hoeHwzYC2qixwIhVXaRqedSjfB3TngR4nTOusbdRUpGBKolMKtD+6AxWTAaa7s8dbEbIkIPrmiFB7/KB7bNvvzECXCjuY+3Hz/dlQU2PHNC6phy0pcaEddcUYpakuy8fye9qQ1tBo6vQCAJcU5mr+m2jXWOj/Wkxk3KPUT3B7/rG5MRpUX2NHaN7b+brI8tbMNzb1D2HhGKeyWxAzYWVyUjeoiB/701lG2uilt9rUO4Bv3bkNxjgUPf2sdHAl6fp/KIIIv11XAaTXj6Z2tSenvPhCZvr50gfbgXlzE4J6V5l7f+ED42agosGMkFE7a/pP9QyP4xUsHUVFgx+pKbUP/tLp0aTG6PAE8WX88oecl0uJQpxdfvXcrnDYzHv72uXEvOxEvW5YRV61ciG5vAO8c7kn4+Q92eFCWb4vr/lOePQt5djODOx5efxBdngBqiucW3EDyhgT+7MWDGBgO4nNnL0z4AjqLixyoq8zHnZuPZtwWSjS/tfUP4yv3bIXFZMAj316HRXm2lHzfpQucWLHQiTc/7EbPYGJ3sDrQ4cGyBc64v25sSCCDW7PoxVpclD3rcyQzuN857MZfd7TitvU1WJCb+Ce2iOAfL1uCjgH/tBMUiBLN6w/ipr9sh2c4iOvWVGDLkd4537eJx2dWLoTJKHhud3vCZlYOj4TQ1ONjcKdCdN2O0+bQ4l6QN7a8a6LWAIk+ge/b0oR/fHQXirItcOXMvg8+lk8sKUJdZT7+sOkwhkfY6qbkGg2F8d2Hd+KoexA3rquc1fyJuXJazdiwrARH3IPYdLA7Iec81OVFWAHLZxHci4sc6BjwZ8Tvny6Cu9Htg9Egc+rjNhsNWFmeh62NJxJYGfDivnb0DQVx9apFMCdxyUcRwY82LkW3N4D732tK2vchAoD/fOUQ3jncg59fvQKnFc/+le5crasuhCvbgp+/dDAh+8ZG19WeTXBXFWXOYlO6CO6j7kFUFNhnPdA/6rzFhdjXNpCwxaZ2tfRhe1Mf1te6ZrXcbLzWVhfgktNd+NPmoxgYTu2CWfTx8fIHnbjr7UZ89dxKfHlNetfNNhoEV55ZimM9PjzwXtOcz3eww4Nsi2l8S8N4VGfQyBJdBHej24ca19yD8fyaQoTCCtub5t7q7vb48bfdbagqtGPDMu2L68zVf//k6RgYDuKut4+m7HvSx0dTjw//48k9WFmWi3/5zLJ0lwMAqC3JwUW1Lvx+02Gc8M1txcyDHR4sLc2JaxetqKpCBrdmobBCY48Pi11zf7m2ujIfWUYD3js6t1lZPYMBPLS1BVlGA65bUzHrdRriEe1T33N8ACvLcvH/3mpEI9fspgS6/90mXP/n9zEaVrjijFI8taMtZTciZyIi+JdPL4NvJITfvt4w6/OEwwoHO7yzujEJAA6LCaVOK4Nbi7a+YYyMhhPS4raajVhVkYf3Gmcf3APDQXztnm0YGB7BjesqNS0LmWifOnMBTEbBPz+zL+XrGNP89fyednQM+PGlujLkx7EhdyrUluTgxnUVeHhrCxq6vLM6R2vfMAYDo7MObgBYUpKNA+3p338y44P7aGQpxUS0uAHg/Joi7G/3oH8WmxR4/UHcdN92HO724sZ1leM3K1LNaTVj4xkL8H7jCTzJ4YGUAE/UH0d9cx8uPt2F00tnH2zJdPuGWjiyjPiPFw7MqsESnTG5fOHs/3+ryvPwYacHvsDorM+RCJkf3N1jwV2ToOA+r6YQSgFbj8XXz93U48PVd76LPcf78bvrVqG2RPt02WSoq8rH2qoC/Pylg+gcSM5sUPp42HO8H//6tw+w2OVI6f2aeBU4svCDDbV453AP3jwU//DAA+0DMAhw+hx+d1dX5iOsgD2t/bM+RyJkfHA39viQZzejQMMWQ1qsLM+F1RxfP/fmQ934/J1b0DMYwIM3r8OVZy5ISC1zYRDBL645E8FQGLc+WM91TGhW2vuH8a0H6uHKseC6NRUJn/WbKNF7PGajwJVtwT89vifu0WGvHezGyvK8OS2OtSqyk9WuFgb3jI52DyastQ0AFpMRa6oK8FaDO+baun2+EfzT47vxjb9sR0mOFc9+7wKcV1OYsFrmqsaVjd986WzsaR3AT55mfzdp98jWFvxlyzFc86d34RkO4prVZchO0sJRiWQyGHDtOWUYGA7iZy8c1Px1R7q9ONjhwVUrF87p++fazTitOBs70rxGfsYHd2OPb3xlrkS5cV0FjvX48PMXp/7B+4Mh3P1OIy799WY8t6cdl5zuwg3rUj/lV4uNK0rxw8tr8cyuNtzxeuo3XSV9GhkN48H3m9E54Mf1ayvSMjNytsoL7Lio1oXH64/jzQ+1dZk8t7sdBgE+fdbcXy2fU5GPnS19af1dy+jg9viDcHsDqEnwzK2NKxbgpguqcd+7TXhm10c393oHA7jr7aO45Feb8bMXD2LFolw8/w8X4vLlpUmdFTlX37/0NFx7Thl+v+kw/vXZD5K6dC3pny8wivvfa8Ixtw/XnlOW9vs1s3HZ0mKcXpKDHz21F+39wzMeq5TCc3vace7iQhTPYgetU62uzEP/UBCNaRwWmNGvjaL9SEtLE//E+smVS/FB+wB+/NQ+3P9uMwDgQLsHI6Ew1lYX4NdfWonza4pOqiPTTGz5n12eh26PHw+934KOfj9+ee1ZKMpO3topNHtTvWJL9C7m0+kc8OO7D+9AU48PX6wrx9nleSn5volmMhrwhxtW4Zo738VN923HX79z/rRdPfvaBtDUO4Tb1tck5Huvrhjr597Z3JfQbtx4ZHRwv7K/E44sI85dnPh+ZbPRgD/esBo/f/EATgwFoZRCXVU+1lQVoMRpRVPPEJp6MqdLJBaDCDauWIBcexZe2tuBC3/5BjaesQB1VfkwiKQsGChzvd3gxu2P74Y/GML1ayuwYlFuukuak9qSHPzxxtX45n3b8b2Hd+Ker9fBNMUr4+f3tMNsFHxqRWIGFdS4suG0mrCzpQ9frCtPyDnjlbHBHQ4rvHagCxefXgxrAve1i4q2etZWZ87NxkQ4b3EhalwOPLu7HX/b3Ya3GrqxrroQly8vSerqhZS5jnR78btNR/DC3nbUFo+F3bY4h8NmqotqXfjZ51fgJ0/vwzfv244/XL8KeRMmDzX3+vDMrjasr3Uh156YyXIGg2BVRT52NqfvlXjGBveu431wewO44ozMHVeaqYpzrPjWhdXY3+7Be429eHl/J17e34klxdlYU12AGlc2KgvsqCy0492jvZP679k6T66wUmjq9aHHOwKvPwgRoCzfhpXlechNwExcpRTa+ofxVoMbrx/owlsNbljNRnz34hp8/5IlsGUZ50VwT+xy+sKqRXh2Tzsu+dVm/P76VairLMCR7kF8875tGA0r3L6hNqHfe3VFPn67qQF9vhHkJ2iocjwyNrhf3d8Fs1FwydLidJeiSyKCFYtysWJRLro8fljNRrzf2Ivn97TD6z951pfTakKBIwsFDguqi+wpb52ns883lTz+IP5a34o/vnkEvRMWSxIArx/shkGA9bUufHlNBS5bVhzzhrhSCh0Dfhxo96Ch24sj3YM42j2Io24fBiMz+8oLbLhtfQ2+9YnFCZsLkYnqIl2cD29txlfv2QaTQWAwjI35fuymtQlfmvaTK0pwx+sNeGRbC753yWkJPbcWGRncSim8sr8T59UUxbUvHE2txGnFDesq8J2La6CUQt9QEM29PrScGMLze9pxwhfECV8Ahzo92NnSh6d2tmFleR4uW1qMS5cWY/kCZ9yrqUXDeDQURo9vBG5vAAtzrejw+NE14Eff0Ah8gRCGgyEMjYRgMgjsWUbk2szItZuhoLAwz4ZFkbfo5rRaQ366IZvx/EFI1B+UI91e3P9uM57a2YqhkRAqCuy4bFkJqoscyLaYEAyFUVuSgy1He/D0zlbc9tAOOK0mXLasBOtrXSh2WpBny0Lf0AiOnxjCC3s70D4wjI5+P4YnTLxyWk0ozrFixaJcFOdYUF3kwO0blkAydFJNopUX2HH7hlpUFNixs6UPfUMjuH1DbVKGOi4tdWJ9rQt/2XIMN19YnZTu3JlkZHA3dA2iqXcI375ocbpLmTemC7JLl37UFRVtwVlMBmz6sBt3vN6A37zWgKJsCy6qLcLaqgIsW+DEkpJs2LNOfup4/EEc6R4ca/W5B/HWITfc3gBO+EYwcXBioSMLxU4rChxmuHIssJmNOOr2IRRWGAyMorHHB89wEJsPuU86f67NjEV5NiilxjdudVhMsJuNeO9o7/gKjYHREPzBMPa09mM0FMZoWMFiMsBiMsJiMuCDtgE4LCY4soywZhkRHA1jOBhC7+AIWvuG0dY/hLa+YbT1+3GkexDBUBgiQLbFBKd17A/KqvJ8nF6aM+OqkP5gCG81uPHAe03YcqQXWSYDPnvWQnzj/Crsaxs46VijwYgLlxThwiVF+OHltXirwY2X9nVi04ddeGZX26RzmwyCEqcVKxY5sSDXhoW5VhQ7rVOGx6PbPl4bTFvNRnR7AyjLt6Ms3z6+c04yXsHdun4xbvjzVjy9sy3lrxAzMrgf294CEeDyDF43YT4SESzMs+GGdRX4h8uWoGcwgM2H3Hi7wY03PuzG0zs/CpFoC9lsNIy3mqOyjAbkO8xYkGfDWWV5KM4Z29atKNsy5WYYp94gDoUVLltWjPb+YbT1D6O93z/+8YF2Dxp7fAhM2A3lgfebNf8f7/77sZjHWEwG5NuzYMsyIttiQlgpDAwH0dw7hG2RtdztWUasLMvDWWW5KM21wpVjgS8wis6BAPa1DWDLkR4MB0PItZlxxfIS1FUVINtimhTaUaf+YT2nMh9nl+dhbXUBen0B9A8FkWc3ozzfjs2H3ClZSphmdt7iQpxVlos/v9OIL68pT+nPRFNwi8hGAL8DYARwt1Lq/ySroCfqj+MvW5pw3ZpyFOtoNtd8cmqInLu4EGurC9DnG0HHgB89gwEMjYx1cywtzYHNbERhtgWnFWfjtOJslOfb5rSpsdEgJ7W4c21m5NrMWLbAOb4Ikj8Ygi8wiuFgCBcuKQIUEFaAxWyAzWzE6we6YDYZYBBBcDQc/fNyAAAFYUlEQVQM/2gIgdEw1lUXYDAwCt9ICP6RELJMBuw53g+HxYQ8uxl5tqxp17JQSuHCJUXY1dKPnS192NXSj3u3HEMwdPKEp7J8G645ZxGMIjiteOaWeazrMHFqdf9QEE09QwztDCEiuPWiGnzvkZ14fPvxlLa6Ywa3iBgB/BHA5QBaAWwXkeeUUgcSXcxbDW785Ol9+MSSIvzH51ck5JyZND1dzwwiKMy2oPCUST3puoloNRvHuwaaeoYmfX66P/pXnFE66TGtzxERwZYjY4uTLS11YmmpE2GlMDQSwvpaF+xZRhQ7LbCYjHGdl/Rr44pSnFOZj39+Zh8OdXrwkyuXpaS/W0uLey2AI0qpRgAQkccAfA5AQoO7zzeC7z+8E7UlObjzxtUZPcWcPqK3cEp0vQYRZFtMaV90iNLDaBA88u11+OV/HcK9W46hvrkPT9x63vjN9GTRcvZFACbe4WgFsC7RheQ7svB/v7gSZ5fnIYcjSYgogZLZwLCYjPi3zy7H+TWF2NZ0IumhDWgL7qk61CatYiQitwC4JfLPQRE5NJfCZqkIQE8avm+m4vWYjNdkMl6TCW6c4/X46ey/daXWA7UEdyuAiRPyywC0n3qQUuouAHdp/cbJICL1Sqm6dNaQSXg9JuM1mYzX5GR6uB5aOpK3A1giItUikgXgOgDPJbcsIiKaTswWt1JqVES+D+AVjA0HvFcptT/plRER0ZQ09aIrpV4C8FKSa0mEtHbVZCBej8l4TSbjNTlZxl8P4VZXRET6wsHSREQ6o+vgFpEvish+EQmLyLR3gUVko4gcEpEjIvLjVNaYSiJSICKvicjhyPv8aY4LicjuyNu8vNEc62cuIhYReTzy+a0iUpX6KlNHw/X4hoi4JzwvvpWOOlNFRO4VkW4R+WCaz4uI/D5yvfaKyOpU1zgTXQc3gA8AfAHA29MdMGHK/qcALAdwvYgsT015KfdjAJuUUksAbIr8eyrDSqmzI29Xpa681ND4M78ZQJ9S6jQAdwD4ZWqrTJ04fgcen/C8uDulRabefQA2zvD5TwFYEnm7BcCfUlCTZroObqXUQaVUrIk+41P2lVIjAKJT9uejzwG4P/Lx/QA+n8Za0knLz3zitforgMtk/i5c/XH6HdBEKfU2gJm2AfocgAfUmPcB5IlIYjatTABdB7dGU03ZX5SmWpKtRCnVAQCR99NtH2QVkXoReV9E5mO4a/mZjx+jlBoFMABgfm1A+hGtvwPXRLoF/ioi6dkFN3NkdG5k5HrcE4nI6wAmL+kG/FQp9ayWU0zxmG6H0sx0PeI4TYVSql1EFgN4Q0T2KaWOJqbCjKDlZz6vnhcxaPm/Pg/gUaVUQERuw9irkUuTXlnmyujnR8YHt1JqwxxPoWnKvl7MdD1EpEtEFiilOiIv67qnOUd75H2jiGwGsArAfApuLT/z6DGtImICkIuZXzrrWczroZTqnfDPP2Me9/lrlNG58XHoKvk4Tdl/DsDXIx9/HcCkVyQiki8ilsjHRQAuQIKX6M0AWn7mE6/VtQDeUPN3UkPM63FK/+1VAA6msL5M9ByAr0VGl5wLYCDaDZkRlFK6fQNwNcb+MgYAdAF4JfL4QgAvTTjuSgANGGtV/jTddSfxehRibDTJ4cj7gsjjdRjbuQgAzgewD8CeyPub0113kq7FpJ85gP8N4KrIx1YATwI4AmAbgMXprjnN1+MXAPZHnhdvAlia7pqTfD0eBdABIBjJkJsB3AbgtsjnBWMjcY5Gfk/q0l3zxDfOnCQi0pmPQ1cJEdG8wuAmItIZBjcRkc4wuImIdIbBTUSkMwxuIiKdYXATEekMg5uISGf+P61idDwPENXXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "standard_scores = encoder.predict(x_test_scaled).ravel()\n",
    "#regularized_scores = encoded_regularized.predict(x_test).ravel()\n",
    "sns.distplot(standard_scores, hist=True, label='standard model')\n",
    "#sns.distplot(regularized_scores, hist=False, label='regularized model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some images\n",
    "# note that we take them from the *test* set\n",
    "# encoded_imgs = encoder.predict(x_test_min_max)\n",
    "# decoded_imgs_scaled = decoder.predict(encoded_imgs)\n",
    "#decoded_imgs_scaled = autoencoder.predict(x_test_min_max)\n",
    "decoded_imgs_scaled = autoencoder.predict(x_test_scaled)\n",
    "decoded_imgs = supermax*(decoded_imgs_scaled+1)/2\n",
    "#decoded_imgs = min_max_scaler.inverse_transform(decoded_imgs_scaled)\n",
    "#decoded_imgs = autoencoder.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3389\n"
     ]
    }
   ],
   "source": [
    "n = 6  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    idea=np.random.randint(1,x_test.shape[0])\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[idea].reshape(40, 16).transpose(),vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[idea].reshape(40, 16).transpose(),vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "print(idea)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6296, 3840)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filename = '../datos_octubre_2018/p_OF_5mm_161mm003.h5'\n",
    "conjunto_datos_test=pd.read_hdf(filename,'MC');\n",
    "conjunto_datos_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6296, 3840)\n",
      "(6296, 3840)\n"
     ]
    }
   ],
   "source": [
    "L1A=6;\n",
    "# hay tres L1 con 640 sensores (40*16)\n",
    "L1B=0;\n",
    "# hay dos L1 con 640 sensores (40*16)\n",
    "X_trained=conjunto_datos_test.values;\n",
    "x_trained=X_trained;\n",
    "\n",
    "for i in range (X_trained.shape[0]):\n",
    "    idea1=X_trained[i,:].reshape(img_rows,(L1A*img_cols));\n",
    "    ideat=idea1.transpose();\n",
    "    idea2=ideat.reshape(1,(L1A*img_cols)*img_rows);\n",
    "    x_trained[i,:] =idea2;\n",
    "x_tested = x_trained;\n",
    "print(x_trained.shape)\n",
    "print(x_tested.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vamos a procesar y comprimir con la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora los particionamos y pasamos por las redes de compresin. Hay una red la A que se utiliza 5 veces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(x, derivative=False):\n",
    "  return x*(1-x) if derivative else 1/(1+np.exp(-x))\n",
    "ideaA=np.zeros((L1A,input_output_dim_A))\n",
    "\n",
    "cara_externa=x_tested[:,0: L1A*input_output_dim_A] \n",
    "cara_externa_reconstruida=np.zeros((x_tested.shape[0],L1A*input_output_dim_A))\n",
    "for i in range(x_tested.shape[0]):\n",
    "    for k in range(L1A):\n",
    "        ideaA[k,:]=x_tested[i,k*input_output_dim_A:k*input_output_dim_A+input_output_dim_A]\n",
    "    #ideaA_scaled=min_max_scaler.transform(ideaA)\n",
    "    ideaA_scaled=(2*ideaA/(supermax)) -1\n",
    "    salida_reconstructed_1_scaled = autoencoder.predict(ideaA_scaled)    \n",
    "    salida_reconstructed_1 = supermax*(salida_reconstructed_1_scaled+1)/2\n",
    "    #salida_reconstructed_1 = min_max_scaler.inverse_transform(salida_reconstructed_1_scaled)     \n",
    "    #salida_reconstructed_1 = ideaA\n",
    "    \n",
    "    #entrada_imgs_A=(ideaA-min_A.transpose())/(max_A.transpose()-min_A.transpose())\n",
    "    #entrada_imgs_A=(ideaA) #he quitado el escalado\n",
    "    #encoded_imgs_A = sigmoid(np.dot(entrada_imgs_A, Encoder_weights_A) + Encoder_biases_A)\n",
    "    #decoded_imgs_A= (np.dot(encoded_imgs_A, Decoder_weights_A) + Decoder_biases_A)\n",
    "    #print(decoded_imgs_A.shape)\n",
    "    #salida_reconstructed_1 = decoded_imgs_A*(max_A.transpose()-min_A.transpose())+min_A.transpose();\n",
    "    #salida_reconstructed_1 = decoded_imgs_A #quito el escalado inverso    \n",
    " \n",
    "    hola1=np.reshape(salida_reconstructed_1,(L1A*input_output_dim_A))\n",
    "\n",
    "    #print(hola.shape)\n",
    "    salida_total=hola1\n",
    "    #salida_total[salida_total<0]=0\n",
    "    #print(salida_total.shape)\n",
    "    cara_externa_reconstruida[i]=salida_total\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizamos los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos todos los sensores: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACM0AAAHSCAYAAAD1iK7WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3V2PHNlZB/BT1eWxZ3qcfUmcMSQRS1AQQYgXCRIJaSVQJBDiQyBxB9+AD4LgMuQ6F9yzEki5QkiAglA2Qut4WSWZWXuz2bXbsx53V3GRRLsozpynPTXVL8/vd7uPz3m6qrq6ztF/apthGAoAAAAAAAAAAGTSbroBAAAAAAAAAACYmtAMAAAAAAAAAADpCM0AAAAAAAAAAJCO0AwAAAAAAAAAAOkIzQAAAAAAAAAAkI7QDAAAAAAAAAAA6QjNAAAAAAAAAACQjtAMAAAAAAAAAADpCM0AAAAAAAAAAJBOt07xQXNzuFXm19UL8As0bT3fNvT9BJ0AAADE1iilxNYpobFuBLYvtnVNtKr3NeZ6zvoRAAAAoJRH5f2HwzDcqdWtFZq5Veblq83XXrwr4IW0R/WwWr9YTNAJAABAbI1SSmydEhmrPanub5Ty5DzS0uT6R4/rNSOu56wfAQAAAEp5Y/jm25E6/3smAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADS6TbdAFDXLxabbgEA2ELtfF6t2eXniH3/fLuqu3tSrVmenk3QCS9irO9Ve/s4Nl+k7uiwXvPkvFry49dfq49TSlneqv/90PH3L6o1t+6/F5qvf63+nene/bBas7x3PzRfROQ6iHAPht0XvR/4vgMAAFMYa8+ilFLK4+Cc480IAAAAAAAAAAC7QWgGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEin23QDAAAAz9MvFptugedYnp5tugWuIPK96u6ejDfh0eEow7z9F79WrTm/24fGmn1Ur+k+imyXfDo0X0R79qBeM5+HxtrVe2fk84352aaeb1dNfd3t+3UeMfUx2OdjCQAAl9nGdWjUlGuwqdcMm1ijeNMMAAAAAAAAAADpCM0AAAAAAAAAAJCO0AwAAAAAAAAAAOkIzQAAAAAAAAAAkI7QDAAAAAAAAAAA6QjNAAAAAAAAAACQjtAMAAAAAAAAAADpCM0AAAAAAAAAAJBOt+kGAACAF9MvFptuAbiidj4fZZwx7wfL07NqTXf3ZLT5+uNb1ZrP/cn/Vmteunkemu8zN+vH6uHr9fPyn9/69dB8X/ini2pNe/s4NNZYtvH3Y+qetvEYbCPnZXrbegwiv1fb2jsAADyP9c70PW3rusKbZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdLpNN8B2aefzak2/WEzQyce2sScAgBcVebYpxfMN8LFtvB8sT89CdU///A+qNeevBrYmvv5KteTen51HWir/+Id/V6352wd/XK0ZfiU2X/ekr9YsXzup1rT/9VZovrFYiwOfNNb3vbtbv99Ff2Om5r4IALB5+763uu+fb1v79qYZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANLpNt0Al2vn82pNv1hM0Mnm7PvnAwBy8WzDJkTWFaW4PjdhG49598XXqjX92YPQWIfvPKrWnL/6SrVmeVif63/+6OuBjkr5l/P69+GNN36vWtOEZiullPo5Xh7dqNZ0wWsl+n2HXWa/bHctT8823cILc01Nz3cdAHKZ+rd/G581pv58Y9rl5zJvmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0uk23cA2aefzak2/WEzQSZ75AACA6+c5f1zbuHaM9FRKrK/lvfujzVfeeqda8vLRQbXm7CvH1Zov//1fh1q6eKWv1hycN9WaV7+zCs3XvfthtaY9e1AfaMRz3N09qdYsT89C8+2qbfwe77Kpj6dzAzn4rgPAbhhrPTDmb781Xynt7fpeyjaKnpfQ3tTj2JzeNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApNOtU9zc6Er3mZNLa5anZ6Gx2vl8nal/oX6xGGUcAAAAiNjGdeg29lRKrK/ufn0f4XOBmo9+8/Ohnt77rZvVmpffelatOXznUWi+sYx5jqN7N/tsW78zu8rxjInshzqWAABc1dTPnVM+w0YzBu3t42rN1M/eY56X7u7lmY1t1Z7cqRcFtyzGPH/eNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApNOtVb3qS//o8eUD3j0JDVUbp5RS+sUiNNZYpp4PAAAAptTO59WayNp48vV6YA/h4F/fDI31Sw+/cNV2fuKtd2J1t4+rJWMez7HOMbCeff/u7fvnAwDYJ/v8XLbL6+dRxwrsk4ylDexrlFJKe3KnXvTk/IrdfGK+wPkrwcPkTTMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApNOtUzz0fekXi0trav/9Z9r5fJ2pd0r0s0WPFQAAu2HMZ1zPisA6dnkd2j96PO18335z2vkCxzxy/qLnbspzvMvXHYzNdQ4AsDvGXINt43xMfzzHOsfRdXZ7+7hedHRYLenPHowyTnSsSN+hz1ZKWZ6eheoivGkGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEinW6e4advSHs0vrekXi9BYkbru7km1Znl6Vq1p55f3vE5PkbGixwAAgP0y5nOg505gHdt6P5jyXhZd+09tn+/nu9o3sL4p79XuLQDAdZv6eWPfn2929RlvzL7Hyhm0t49D85Wjw2pJf/agPt/JnWrN8t79SEex4/nocX2c4DEI7QPVp/vJWLEyAAAAAAAAAADYH0IzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACk061TPPR96ReL6+rl5yxPz0YZZ8yexxyrnc8nnY8Y5wUA2AaR541dfW6J9F3KeL1PPR+U4jrfxHzRuaa+d7q3xOzqbxqwHt9jAID9M+Xexi6v10P7vSd3YoM9OR9nvifH1Zru7kmopf6zr9Rrvv1mvWbE/Z0ob5oBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIJ1uneKmbUt7NB9l4n6xGGWc7u5JtWZ5ejbKXGMb6xgwLucFANgVu/rcMnXfu3qc2G2u8+m183H2K9iMqa/hyPUS7WnMsQAAgJz2fV2xq58vutcQ6T0y1vLe/dB8kbFCvR8d1muenAc6KqX/9pvVmki2o3/0ODbfiNeLN80AAAAAAAAAAJCO0AwAAAAAAAAAAOkIzQAAAAAAAAAAkI7QDAAAAAAAAAAA6QjNAAAAAAAAAACQjtAMAAAAAAAAAADpCM0AAAAAAAAAAJCO0AwAAAAAAAAAAOl0m27gMu18Xq3pHz2eoJP1RPoupZR+sbjmTgAA2DbRZ8UIz5OwGaG1qu/n5KLHfMz78DZyfcaMeQwcTwB4MZ5bAD627/e7Xf18U68du7snobGWp2f1sb74Wn2ce/dD80W0v/0b1Zr+rXfqNcFjHjpWPwwN5U0zAAAAAAAAAADkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA63aYbuKp+sdh0Cz9nG3sCAGA7eFaE3ed7vNu28fy183m1Jtr3Nn4+AIDn8dwC8LEx14XsruXpWagucr0s792/Yjfrad99v150+7haEr3Oo8cqwptmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEinW6d46PvSLxaX1rTzeWisSF1trk3Y1b6Jc44BAICpWH/E7Ptx2uXeAQAAuLpdXhfu+5p9LI5TKcvTs9HGCuVSHgfHulorAAAAAAAAAACwe4RmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIpxmGIV7cNA9KKW9fXzsAAAAAAAAAAHAlvzIMw51a0VqhGQAAAAAAAAAA2Af+90wAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDrdOsUHzc3hVplfVy8AAADAdWrGKQoNU0opbaQyUBMZph8CRaWUJtz9pYa+H2Wcn442SgkAAAAAP/GovP9wGIY7tbq1QjO3yrx8tfnai3cFAAAArGekkEcppTSzWb0oUNMEe2oODupFkWBNV9++GJ5eBDoqpZkFXrrb1Gv6x4vQfKHPt1pVS4ZATSkl1HvIMGYoaCSD5BAAAAAQ88bwzbcjdf73TAAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDrdphsAAACeo2nqNcNw/X0ALybyHY6KfNfbWWiopqtvAwyrvj7O4c3YfPOjak3/6Zfr4zy9qNYsf/mlUE83Hj6pF108q5bMAp+tlBI6f6uH71VrolfU0PttAACAX8h+C8B6xtzjmlrwdu5NMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACk0639L5rm8v8+DC/YCgAAAOyJ6Nq4tsYupTRdYOk+m8XmC2hm9b+vaeZHscFCvdePwY++8tn6MBexY/7o9w+rNXf+42m1pnvyLDRfd/ZBtaYJXAdDE/27p1W9ZOjrNZH5IuNE2U8CAAAgu8D+wORG3OMKjbWBY+BNMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOt3a/2IYrqENAADg//HcDfzUsFpVa5roWE39b2eaWb1m6PvYhDdv1Mc6qG9NPPzd+if8yz/951BL3zv/TLXmW5/6nWrNS28dhOb79HuPqzXDKng8A5q2fqyGfgv/hqoJXMV+GwEAuCrPlADraWexumG8vY2pbeEuCQAAAAAAAAAAXC+hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0uk23QAAAKTSNOONNQzjjQVsRjPO37IMq1VsuoNZYKy+Ps7Fs9B8pa1/vouXDqo1Nx7X753/8J2vhlr67uvfqNZ86Utfqtb8qF5SSinl+PuvVGsO3vlBtSZyXkY1BOaL/g5Ffvv8pgEAMAXPppDDWHuwY94PxtwXHktkXyqyPxAdqwTGGmmvbB3eNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOt3a/6JpLv/vw/CCrQAAQALR5+Xaczew3Ub8DjdtZKxZbLDVqj7f4WG1Zjg/D03XPr2o1iyPA70Hbp3fff0bgY5KedLXe7r170fVmpsfxO7nN378Yb2oDfxN03IZmm9S0evcXhEAANvCsymwjl3eo23qew3NLLInEzwGgfmG+rZUWGi/LDifN80AAAAAAAAAAJCO0AwAAAAAAAAAAOkIzQAAAAAAAAAAkI7QDAAAAAAAAAAA6QjNAAAAAAAAAACQjtAMAAAAAAAAAADpCM0AAAAAAAAAAJCO0AwAAAAAAAAAAOl0o4/YNLG6YRh9agAAANgKzXh/ozKsVvXpDg5igwXGCrlxI1Z38axacviD82rNwa/ertZ85W/+KtTSk7v1fYsh8PGOHsSOZXtePwb9s2V9oOA1FbleytCHxgIAAIDJRHMGU4ru70TW2SPuFUW0B8G9m4phCJ6Xvp7/aGazK3bzCSPubXjTDAAAAAAAAAAA6QjNAAAAAAAAAACQjtAMAAAAAAAAAADpCM0AAAAAAAAAAJCO0AwAAAAAAAAAAOkIzQAAAAAAAAAAkI7QDAAAAAAAAAAA6QjNAAAAAAAAAACQTrexmZumXjMM198HAMC+8rw1vTGPuXMDu23oRxuqmc3q0z1bjjZWWa0CAwXud0Gz751Waz7/zoNqzfDy7dB8j778arVmebP++Y7/+2FovubJR/WiwPUy9Fv4u+C3CgDIyH4LwH5oRny/SGCsph1vL6VE9oqWgb2iyDEI9t3cCERPIn1/9DQ035i8aQYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASKdb+180lZzN0L9gK8+bq6nXDMN48wEA7BPPSdNzzIF1Be4bw2o14oSzakX/0dNqTXtwIzRb//6PqzXNwUG1ZhgC8/3og0hL5VP/dl6f72Z9vuHWzdB8w+mDUN3W8ZsGAPB8npMANid6D47kDEbUtIH5ajmLsUXmC/TdjHksA3tczSx2nIYRt8u8aQYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdLrRR2xGzOH0q8B8zXjzRQzDtPMBAOyT6LObZ67YsXKcYHtFv5+B73ozm12xmU8Y+nGGWQXHaeufb3j6tFrTLJf1mqPDUEvDBx/Wiw5v1Wt++G5ovsj56/sR7+eRcxy5Pv0OAQAAMKWp15iR9XMw+zAE1vVNW5+vOTgIzRfSjLMH1BwG91sC+zuhvYY2dsybSN1FaChvmgEAAAAAAAAAIB+hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0unWqm6a0sxml5YMq1VsrKEPzbd1Ij0Nw/X3AXAV7mXAurbxuQxgHwSeuULr7OCzW9PVtwGatn7Pj679m3L5HkLU0C/rRY8XscHa+t8PNU+f1scJHoMhMF9soMA+SinjPcdbDwCsz34LcB3G3JNxDwKyiNzvQs9usbV4LUNRSiklUhO950f2GiLz9fXPN0T2SKKiWZKIGzdGG8qbZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdLr1yodShr5SUvnvfKxp6jXDcP19AADURJ5JIs82xHkOBH5mxHvwsFoFxgr8fU1w7T8EpouM1cxm9WGW0+5HDMH79LB4cs2dvAD7EQAAu8NzGcD6xlr3Rvdb+vpYTROYL7JvE6yL7Fu0h7fq41w8C7XU3LwZGOuiXrNcxuZ7FusrwptmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAOD/2ruD5CZiIAqgku0YLsCa+x+LNWuKxM5MswpQVBH1ECUZ3O9t3ZbkcdKWVT8TAAAAoByhGQAAAAAAAAAAyhGaAQAAAAAAAACgnNOm6mgtHh+frzkcX7CcP+db5421RxHvvQKgKv0HeA16S07vuTrXE3iYIUVrAAADy0lEQVSS6RvZnpH5zr7D7+KxLOOinvu7oMP5bliz3j+MpztOPP9YM68v+fkx8+cFgG1m9lf9HADg32X2Sdnv2bMkzlvWS+J8oOXONjLnFuv3+/E4yesUl0uiaPy+9PM5N1/i7CbLnWYAAAAAAAAAAChHaAYAAAAAAAAAgHKEZgAAAAAAAAAAKEdoBgAAAAAAAACAcoRmAAAAAAAAAAAoR2gGAAAAAAAAAIByhGYAAAAAAAAAAChHaAYAAAAAAAAAgHJOm5/R+/MPH55//Eksy+ap/zJhYrJ1zlyttRYxbyyAPRv0+5/0RYBfMr1T3wS2mtk31lnfxZN7xVnz5SbLVT08DGv68TisieslNV9K9npm+JwB2DfnLQAAtyeRR4h13v1MYkmcgbz1fjKR/+gfPwxr1m/fc/NNzIC40wwAAAAAAAAAAOUIzQAAAAAAAAAAUI7QDAAAAAAAAAAA5QjNAAAAAAAAAABQjtAMAAAAAAAAAADlCM0AAAAAAAAAAFCO0AwAAAAAAAAAAOUIzQAAAAAAAAAAUM5p8zP68zmbWGPKOGmxzhmntdYiufaR3ufNlxlr1roBfjezt+hlrgHs2cy9m99jYO+yPW/kf+53ibWnzjZmfn7M5D0G2DfnLXO5BgDAa8ruI1J7kkSuIZmhiGUZDxWJNWXmOycjJYk1xeU6HueQO9eI67w9njvNAAAAAAAAAABQjtAMAAAAAAAAAADlCM0AAAAAAAAAAFCO0AwAAAAAAAAAAOUIzQAAAAAAAAAAUI7QDAAAAAAAAAAA5QjNAAAAAAAAAABQjtAMAAAAAAAAAADlCM0AAAAAAAAAAFDOafaA/dBTdbFGpuiFq3knkXht7zEWwBY9189TfUovcw1gz/x+ApXccs+b+drWZVyT3S+/tVt+jwFugfOWuVwDAGAPMnuSzD5waj7iOC5JZDvick3NFsv4LKXfJeIpmRxJa60fE68vcbzTmjvNAAAAAAAAAABQkNAMAAAAAAAAAADlCM0AAAAAAAAAAFCO0AwAAAAAAAAAAOUIzQAAAAAAAAAAUI7QDAAAAAAAAAAA5QjNAAAAAAAAAABQjtAMAAAAAAAAAADl9IjIF/f+tbX25fWWAwAAAAAAAAAAL/I5Ij6NijaFZgAAAAAAAAAA4Bb490wAAAAAAAAAAJQjNAMAAAAAAAAAQDlCMwAAAAAAAAAAlCM0AwAAAAAAAABAOUIzAAAAAAAAAACUIzQDAAAAAAAAAEA5QjMAAAAAAAAAAJQjNAMAAAAAAAAAQDlCMwAAAAAAAAAAlPMD51n1ko8twTIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 2880x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 1  # how many digits we will display\n",
    "plt.figure(figsize=(40, 10))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    idea=np.random.randint(1,x_tested.shape[0])\n",
    "    idea=1890\n",
    "    idea= 4299\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(cara_externa[idea].reshape(L1A*img_cols, img_rows).transpose(), vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(cara_externa_reconstruida[idea].reshape(L1A*img_cols, img_rows).transpose(), vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos ahora L1 a L1, teniendo en cuenta que hay de dos tipos:\n",
    "L1A (con 36 columnas )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x720 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = L1A  # how many digits we will display\n",
    "plt.figure(figsize=(40, 10))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(cara_externa[idea].reshape(L1A*img_cols, img_rows).transpose()[:,i*img_cols:(i+1)*img_cols] ,vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax = plt.subplot(2, n, i + 1+n)\n",
    "    plt.imshow(cara_externa_reconstruida[idea].reshape(L1A*img_cols, img_rows).transpose()[:,i*img_cols:(i+1)*img_cols] ,vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  1  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  1  0  1  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  0  3  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  2  2  2  0  1  1  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  3  3  7  4  1  0  0  0  1  0  0  0  0  0]\n",
      " [ 1  3  3  4  9  9  5  2  2  1  0  0  0  0  0  0]\n",
      " [ 3  2 12 21  9 10 11  2  1  1  0  0  0  0  0  1]\n",
      " [ 2  8 15 22 18 31 13  6  1  1  1  0  1  0  0  0]\n",
      " [ 2  9 14 23 28 27 15 11  4  0  0  1  1  1  0  0]\n",
      " [ 2  6  8 22 23 14 13  7  4  0  0  0  0  0  0  0]\n",
      " [ 2  3  6 14 18 14  8  4  1  0  0  0  0  0  0  0]\n",
      " [ 1  5  6  6  5  5  3  3  2  0  1  0  0  0  0  0]]\n",
      "630\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "print(cara_externa[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:])\n",
    "print(np.sum(cara_externa[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  2  1  1  0  1  1  0  0  0  0  0  0  0  0]\n",
      " [ 1  2  2  3  3  2  2  2  0  0  0  0  0  0  0  0]\n",
      " [ 1  3  4  4  6  7  4  1  1  0  0  0  0  0  0  0]\n",
      " [ 1  3  8 14 13 12 11  2  1  0  0  0  0  0  0  0]\n",
      " [ 1  5  7 24 18 32  9  3  1  1  0  0  0  0  0  0]\n",
      " [ 1  3 11 22 36 29 11  7  2  1  0  0  0  0  0  0]\n",
      " [ 1  3  5 13 18 11 12  8  3  1  1  0  0  0  0  0]\n",
      " [ 0  2  4  9 17  9  7  3  3  0  0  0  0  0  0  0]\n",
      " [ 0  2  2  3  6  4  3  2  1  1  1  0  0  0  0  0]]\n",
      "584.9598186016083\n"
     ]
    }
   ],
   "source": [
    "print(cara_externa_reconstruida[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:].astype(int))\n",
    "print(np.sum(cara_externa_reconstruida[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 754.81425726,  983.22551978, 1262.56991053, ...,  531.45512319,\n",
       "        442.91614366,  596.45044398])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(idea)\n",
    "np.sum(cara_externa_reconstruida,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,)\n",
      "(401,)\n",
      "[[Model]]\n",
      "    Model(gaussian)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 38\n",
      "    # data points      = 400\n",
      "    # variables        = 3\n",
      "    chi-square         = 39109.5006\n",
      "    reduced chi-square = 98.5125959\n",
      "    Akaike info crit   = 1839.06246\n",
      "    Bayesian info crit = 1851.03685\n",
      "[[Variables]]\n",
      "    amp:  691.887321 +/- 4.96955075 (0.72%) (init = 200)\n",
      "    cen:  125.185373 +/- 0.55469046 (0.44%) (init = 0)\n",
      "    wid:  94.5849023 +/- 0.78445077 (0.83%) (init = 100)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(amp, wid) = -0.577\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "veamos_energia=(np.sum(cara_externa_reconstruida, axis=1))-(np.sum(cara_externa, axis=1))\n",
    "n, bins, patches = plt.hist(veamos_energia, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "plt.title(\"Histogram with 400 bins\")\n",
    "plt.show()\n",
    "x=bins[:400]\n",
    "y=n\n",
    "print(n.shape)\n",
    "print(bins.shape)\n",
    "from numpy import exp, loadtxt, pi, sqrt, log\n",
    "\n",
    "from lmfit import Model\n",
    "def gaussian(x, amp, cen, wid):\n",
    "    \"\"\"1-d gaussian: gaussian(x, amp, cen, wid)\"\"\"\n",
    "    return amp * exp(-((x-cen)/wid)**2 )\n",
    "\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=200, cen=0, wid=100)\n",
    "\n",
    "print(result.fit_report())\n",
    "\n",
    "plt.plot(x, y, 'bo')\n",
    "plt.plot(x, result.init_fit, 'k--')\n",
    "plt.plot(x, result.best_fit, 'r-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "495px",
    "left": "1249px",
    "right": "57px",
    "top": "240px",
    "width": "390px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
