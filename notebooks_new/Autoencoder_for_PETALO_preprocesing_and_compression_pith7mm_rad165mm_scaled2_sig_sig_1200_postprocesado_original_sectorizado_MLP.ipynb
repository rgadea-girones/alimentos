{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple AUTOENCODER for PETALO\n",
    "\n",
    "Esta red la vamos a utilizar para obtener el radio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python36.zip', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/lib-dynload', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/extensions', '/home/rgadea3/.ipython']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#np.random.seed(1337)  # for reproducibility\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append(\"/home/rgadea/lmfit-py/\")\n",
    "import seaborn as sns\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from math import floor\n",
    "from lmfit.models import  GaussianModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos introducir los datos de petalo preprocesados en pyhton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3518)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import hdf5storage\n",
    "# datos_matlab = hdf5storage.loadmat('../datos_junio_2019/conjunto_entrenamiento_junio_2019_pitch7mm_rad165mm_29_total.mat')\n",
    "npzfile = np.load('../conjuntos_datos_reconstruidos/fil5_pith7mm_rad165mm_scaled2_sig_sig_1200.npz')\n",
    "npzfile.files\n",
    "\n",
    "# conjunto_datos1= npzfile['arr_0']\n",
    "# npzfile = np.load('../conjuntos_datos_reconstruidos/fil2_pith7mm_rad165mm_scaled2_sig_sig_1200.npz')\n",
    "# npzfile.files\n",
    "\n",
    "conjunto_datos= npzfile['arr_0']\n",
    "\n",
    "# conjunto_datos=np.concatenate((conjunto_datos1,conjunto_datos2), axis=0)\n",
    "print(conjunto_datos.shape)\n",
    "# print(conjunto_datos[:10,6:26])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "# aqui no aplicable porque es una regresion\n",
    "# nb_classes = 10 \n",
    "\n",
    "nb_epoch = 2000\n",
    "\n",
    "n_hidden1=80\n",
    "n_hidden2=60\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 20, 31\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "conjunto_datos shape: (50000, 3518)\n",
      "194.99950513267174\n",
      "sector shape: (50000, 20, 31)\n",
      "conjunto_datos_nuevo: (50000, 620)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "# (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# conjunto_datos=photodefbox2_todo_e\n",
    "numero_muestras=conjunto_datos.shape[0]\n",
    "print(numero_muestras)\n",
    "print('conjunto_datos shape:', conjunto_datos.shape)\n",
    "maxInColumns = np.amax(conjunto_datos, axis=0)\n",
    "print (maxInColumns[1])\n",
    "# n, bins, patches = plt.hist(conjunto_datos[:,1], 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "\n",
    "idea=conjunto_datos[:,6:3506]\n",
    "veamos=idea.reshape(idea.shape[0],175, 20)\n",
    "veamos2=np.zeros([idea.shape[0],20,175])\n",
    "veamos2_3=np.zeros([idea.shape[0],20,525])\n",
    "sector2=np.zeros([idea.shape[0],20,31])\n",
    "veamos3=np.zeros([idea.shape[0],175])\n",
    "# for i in range(idea.shape[0]):\n",
    "for i in range(idea.shape[0]):\n",
    "    veamos2[i]=np.reshape(veamos[i].transpose(), [20,175])\n",
    "    veamos3[i]=np.sum(veamos2[i], axis=0)\n",
    "    indice=np.argmax(veamos3[i], axis=0)\n",
    "    veamos2_3[i]=np.concatenate((veamos2[i],veamos2[i],veamos2[i]),axis=1)   \n",
    "    sector2[i]=veamos2_3[i,:,indice-15+175:indice+16+175]\n",
    "    \n",
    "\n",
    "print('sector shape:', sector2.shape)\n",
    "conjunto_datos_nuevo=sector2.reshape(sector2.shape[0], img_rows*img_cols)\n",
    "print('conjunto_datos_nuevo:', conjunto_datos_nuevo.shape)\n",
    "\n",
    "print(idea[:10,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD6CAYAAACmjCyGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAE6dJREFUeJzt3X/sXfV93/Hna7bBjQMFh0L47aRhbFkUSONCEd1EoDCgWUmnpMPaMroxOa0aKVk7qVm3NVmmSe22tNVKF+oEL6RKgaYJKVJpgkUykWQUMMwEU0ghyBnGCC+4QIAGcPLeH99j6dsv92uf+4v7vXyeD+mre+4573vO53zP9758fO79fE6qCklSO/7WrBsgSXplGfyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4JekxqyedQMGOSyH11rWzboZkjQ3vsdzvFgvpE/tigz+tazj7Fww62ZI0ty4o27tXTvWpZ4kFyf5ZpKHk3xowPLDk9zQLb8jyYZxtidJGt/IwZ9kFfB7wCXAm4FNSd68pOxK4K+q6k3AbwO/Oer2JEmTMc4Z/1nAw1X1SFW9CFwPXLak5jLg2m76j4ELkvS6BiVJmo5xgv9E4NFFz3d38wbWVNV+4GngdYNWlmRzku1Jtr/EC2M0S5J0MOME/6Az96WD+/epWZhZtaWqNlbVxjUcPkazJEkHM07w7wZOXvT8JGDPcjVJVgM/DOwbY5uSpDGNE/x3AacleUOSw4DLgZuW1NwEXNFNvxv4cnnLL0maqZG/x19V+5O8H/gSsArYWlX3J/kosL2qbgKuAf4gycMsnOlfPolGS5JGl5V4An5k1pcduCSpvzvqVp6pfb2+NelYPZLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGjNy8Cc5OclXkjyQ5P4kHxhQc16Sp5Ps6H5+fbzmSpLGNfLN1oH9wK9U1T1JjgDuTrKtqv5iSd1Xq+qdY2xHkjRBI5/xV9XjVXVPN/1d4AHgxEk1TJI0HRO5xp9kA/A24I4Bi89Jcm+SP0vy9w6yjs1JtifZ/hIvTKJZkqQBxrnUA0CS1wKfAz5YVc8sWXwPcGpVPZvkUuALwGmD1lNVW4AtAEdmfY3bLknSYGOd8SdZw0Lof6aqPr90eVU9U1XPdtM3A2uSHDPONiVJ4xnnWz0BrgEeqKrfWqbm9V0dSc7qtvfkqNuUJI1vnEs95wLvBe5LsqOb92vAKQBVdTXwbuAXk+wH/hq4vKq8jCNJMzRy8FfV14AcouYq4KpRtyFJmjx77kpSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGjP2zdanIYcfxuqTNvSq3f/Irqm2RZJebTzjl6TGjB38SXYluS/JjiTbByxPkv+e5OEk30jyY+NuU5I0ukld6nlHVX1nmWWXAKd1P2cDH+8eJUkz8Epc6rkM+HQt+HPgqCTHvwLblSQNMIngL+CWJHcn2Txg+YnAo4ue7+7m/Q1JNifZnmT7i99/fgLNkiQNMolLPedW1Z4kxwLbkjxYVbctWp4Br6mXzajaAmwB+OG1r3/ZcknSZIx9xl9Ve7rHvcCNwFlLSnYDJy96fhKwZ9ztSpJGM1bwJ1mX5IgD08BFwM4lZTcB/7z7ds9PAE9X1ePjbFeSNLpxL/UcB9yY5MC6/rCqvpjkFwCq6mrgZuBS4GHgeeBfjLlNSdIYxgr+qnoEOGPA/KsXTRfwS+NsR5I0OStyyIZ64UWHYpCkKXHIBklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWrMyMGf5PQkOxb9PJPkg0tqzkvy9KKaXx+/yZKkcYx868Wq+iZwJkCSVcBjwI0DSr9aVe8cdTuSpMma1KWeC4BvVdW3J7Q+SdKUTOpm65cD1y2z7Jwk9wJ7gH9TVfcPKkqyGdgMsJbXTKhZK8vqN27oXftqvdm8v4P+/F1pWsY+409yGPAzwGcHLL4HOLWqzgB+F/jCcuupqi1VtbGqNq7h8HGbJUlaxiQu9VwC3FNVTyxdUFXPVNWz3fTNwJokx0xgm5KkEU0i+DexzGWeJK9Pkm76rG57T05gm5KkEY11jT/Ja4ALgfctmvcLAFV1NfBu4BeT7Af+Gri8qmqcbUqSxjNW8FfV88Drlsy7etH0VcBV42xDkjRZ9tyVpMYY/JLUGINfkhpj8EtSYwx+SWrMpIZsmJlZd2sfZvsa7hjM+nc7rWEQ+u7XrLc/bBv2n//2/m348t29azV5nvFLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaszcD9kwrW7ts97+NLrVT6ur/tSGAJjCfg3jqfee07v2mK8/3rv2exted+giYG3vNc7+fQCzH4Zh1sO3zBPP+CWpMb2CP8nWJHuT7Fw0b32SbUke6h6PXua1V3Q1DyW5YlINlySNpu8Z/6eAi5fM+xBwa1WdBtzaPf8bkqwHPgycDZwFfHi5fyAkSa+MXsFfVbcB+5bMvgy4tpu+FnjXgJf+Q2BbVe2rqr8CtvHyf0AkSa+gca7xH1dVjwN0j8cOqDkReHTR893dvJdJsjnJ9iTbX+KFMZolSTqYaX+4mwHzalBhVW2pqo1VtXENh0+5WZLUrnGC/4kkxwN0j3sH1OwGTl70/CRgzxjblCSNaZzgvwk48C2dK4A/GVDzJeCiJEd3H+pe1M2TJM1I369zXgfcDpyeZHeSK4HfAC5M8hBwYfecJBuTfBKgqvYB/wm4q/v5aDdPkjQjvXruVtWmZRZdMKB2O/CvFj3fCmwdqXWSpImb+yEb5smsu5SvhGEYprHeaW1/mGEYhmnDMEMx9DXM8BKvfezF3rWrZzwkyTSG+FgJZp0FDtkgSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEO2bBCzbpL97R8+z0n9K5dt+f4iW9/mOEKhvHsuf3b+twJg25T8XLH3dX/hkTD7NfaXU/2rt3fu3K4v9lpmNb2Zz18yv7z396rru68vfc6PeOXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTlk8CfZmmRvkp2L5v3XJA8m+UaSG5MctcxrdyW5L8mOJNsn2XBJ0mj6nPF/Crh4ybxtwFuq6q3AXwL/9iCvf0dVnVlVG0droiRpkg4Z/FV1G7BvybxbqupA344/B06aQtskSVMwiZ67/xK4YZllBdySpIDfr6oty60kyWZgM8BaXtN747Pu4Tqt7fftrQf9b4g9rZ6Nw6z3xN/83xNf7zC9geGw3pV9e9gCvHDG871rT/nkqt61fe36R2t6177pX+/qXTvU3+EQPYK/t+F1/dY5xHum7zoBVn/57t61s9a3ran+f4NjBX+Sf8dCr+7PLFNyblXtSXIssC3Jg93/IF6m+0dhC8CRWV/jtEuStLyRv9WT5ArgncA/raqBQV1Ve7rHvcCNwFmjbk+SNBkjBX+Si4FfBX6mavD/L5KsS3LEgWngImDnoFpJ0iunz9c5rwNuB05PsjvJlcBVwBEsXL7ZkeTqrvaEJDd3Lz0O+FqSe4E7gT+tqi9OZS8kSb0d8hp/VW0aMPuaZWr3AJd2048AZ4zVOknSxNlzV5IaY/BLUmMMfklqjMEvSY0x+CWpMXN/s/VZ32h8WtufRpfyabX1qfee07v2mCHW27cL/ro9/Tt6D3NT8gt/5c7etXc9eWrv2sd+/JRedad+dk/vdf6d3+1dOtQN1Ie5Mfush0yY1k3kX40845ekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUmLkfsmGerH7jht61wwyvMMx6p7H9505I79qjhhk2YoghAPr6D5/4n71rr7xpc+/aN711d+/anR/4H73qfvqz7+q9zmGGSxjm97p6iGEQpmFa75lp2X/+23vVDTW8xBT2yzN+SWpMn3vubk2yN8nORfM+kuSx7n67O5JcusxrL07yzSQPJ/nQJBsuSRpNnzP+TwEXD5j/21V1Zvdz89KFSVYBvwdcArwZ2JTkzeM0VpI0vkMGf1XdBuwbYd1nAQ9X1SNV9SJwPXDZCOuRJE3QONf435/kG92loKMHLD8ReHTR893dvIGSbE6yPcn2l3hhjGZJkg5m1OD/OPCjwJnA48DHBtQM+qrHsnfMqKotVbWxqjau4fARmyVJOpSRgr+qnqiq71fVD4BPsHBZZ6ndwMmLnp8E9L+lkCRpKkYK/iTHL3r6s8DOAWV3AacleUOSw4DLgZtG2Z4kaXIO2YEryXXAecAxSXYDHwbOS3ImC5dudgHv62pPAD5ZVZdW1f4k7we+BKwCtlbV/VPZC0lSb4cM/qraNGD2NcvU7gEuXfT8ZuBlX/WUJM1Oqpb9vHVmjsz6OjsXzLoZTRumq/wwwwUM01X9bZ//Vq+6675ybu91bnrH13vX3vXkqb1rH7vllN61L5zxfO/avv72v3+qd+2shwMZxkoYhmFeho24o27lmdrXa/wUh2yQpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1JhDjtWjg5tWd+556SY+Tbf/8qDRvl9uAy/1Xue2e36yd+1zJ/Tq/T609X/2Q73qjvn6473XOcywGaun9PcyVBu+fPfEtz+t98yr8f3lGb8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqTJ977m4F3gnsraq3dPNuAE7vSo4CnqqqMwe8dhfwXeD7wP6q2jihdkuSRtTne/yfAq4CPn1gRlX9kwPTST4GPH2Q17+jqr4zagMlSZPV52brtyXZMGhZkgA/B5w/2WZJkqZl3J67fx94oqoeWmZ5AbckKeD3q2rLcitKshnYDLCW14zZrFfOSujV17fH4rR6Kw7TE/Q77z2nd+1rH3uxV90TP35473We+tk9vWufe88JvWuH0bdH7jA9Yafl20P8Dob53e7vWfdq7cE+6/0aN/g3AdcdZPm5VbUnybHAtiQPVtVtgwq7fxS2AByZ9TVmuyRJyxj5Wz1JVgP/GLhhuZqq2tM97gVuBPoNviJJmppxvs75U8CDVbV70MIk65IccWAauAjYOcb2JEkTcMjgT3IdcDtwepLdSa7sFl3Okss8SU5IcnP39Djga0nuBe4E/rSqvji5pkuSRtHnWz2blpn/8wPm7QEu7aYfAc4Ys32SpAmz564kNcbgl6TGGPyS1BiDX5IaY/BLUmNStfI6yR6Z9XV2LuhVO42uz95AfThTu8n1+W/vVffsiYf1Xue0bmA+jLW7nuxVN62/rXkyT++DWbujbuWZ2pc+tZ7xS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWrMihyyIcn/A769ZPYxwHdm0Jxpc7/mi/s1X1rar1Or6kf6vHhFBv8gSbZX1cZZt2PS3K/54n7NF/drMC/1SFJjDH5Jasw8Bf+WWTdgStyv+eJ+zRf3a4C5ucYvSZqMeTrjlyRNgMEvSY1Z8cGf5OIk30zycJIPzbo9k5RkV5L7kuxIsn3W7RlVkq1J9ibZuWje+iTbkjzUPR49yzaOYpn9+kiSx7pjtiPJpbNs47CSnJzkK0keSHJ/kg908+f6eB1kv+b9eK1NcmeSe7v9+o/d/DckuaM7Xjck6X//UVb4Nf4kq4C/BC4EdgN3AZuq6i9m2rAJSbIL2FhVc93BJMk/AJ4FPl1Vb+nm/RdgX1X9RvcP9tFV9auzbOewltmvjwDPVtV/m2XbRpXkeOD4qronyRHA3cC7gJ9njo/XQfbr55jv4xVgXVU9m2QN8DXgA8AvA5+vquuTXA3cW1Uf77velX7GfxbwcFU9UlUvAtcDl824TVqiqm4D9i2ZfRlwbTd9LQtvwrmyzH7Ntap6vKru6aa/CzwAnMicH6+D7NdcqwXPdk/XdD8FnA/8cTd/6OO10oP/RODRRc938yo4mIsUcEuSu5NsnnVjJuy4qnocFt6UwLEzbs8kvT/JN7pLQXN1SWSxJBuAtwF38Co6Xkv2C+b8eCVZlWQHsBfYBnwLeKqq9nclQ+fiSg/+DJi3cq9NDe/cqvox4BLgl7pLC1rZPg78KHAm8Djwsdk2ZzRJXgt8DvhgVT0z6/ZMyoD9mvvjVVXfr6ozgZNYuArydweVDbPOlR78u4GTFz0/Cdgzo7ZMXFXt6R73AjeycFBfLZ7orrseuP66d8btmYiqeqJ7I/4A+ARzeMy6a8WfAz5TVZ/vZs/98Rq0X6+G43VAVT0F/C/gJ4CjkqzuFg2diys9+O8CTus+wT4MuBy4acZtmogk67oPoUiyDrgI2HnwV82Vm4AruukrgD+ZYVsm5kA4dn6WOTtm3YeF1wAPVNVvLVo018druf16FRyvH0lyVDf9Q8BPsfD5xVeAd3dlQx+vFf2tHoDu61e/A6wCtlbVf55xkyYiyRtZOMsHWA384bzuW5LrgPNYGCr2CeDDwBeAPwJOAf4v8J6qmqsPSpfZr/NYuGxQwC7gfQeujc+DJD8JfBW4D/hBN/vXWLgePrfH6yD7tYn5Pl5vZeHD21UsnKj/UVV9tMuP64H1wP8B/llVvdB7vSs9+CVJk7XSL/VIkibM4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mN+f9ohB/AqFNRkwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD6CAYAAACmjCyGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAE5RJREFUeJzt3X+sX/V93/HnqzbGDT8KjstPE5ykiC2LAm1d0ohtItBQQKy0U9Jh9QfdsjmpminRNqlZJzVZtkrttrTTShXqBiukSoG2CSlTaIJFUhG6lGCY+VVIcJEzjJG9xAVCfgAO7/1xj7Xby/fa5/uL7/3683xIV/d8z3l/z/mce+59+fh8z+dzUlVIktrxfbNugCTplWXwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhqzetYNGGRNjq21HDfrZkjS3Pgu3+KFej59aldk8K/lON6cS2bdDEmaG3fXHb1rx7rUk+SyJF9JsivJ+wcsPzbJzd3yu5NsHGd7kqTxjRz8SVYBvwdcDrwB2JzkDUvK3gn8bVX9EPA7wG+Nuj1J0mSMc8Z/AbCrqh6vqheAm4CrltRcBdzQTf8pcEmSXtegJEnTMU7wnwk8sej1nm7ewJqqOgg8A7x60MqSbEmyI8mOF3l+jGZJkg5nnOAfdOa+dHD/PjULM6u2VtWmqtp0DMeO0SxJ0uGME/x7gLMWvd4A7F2uJslq4AeAA2NsU5I0pnGC/x7gnCSvTbIGuBq4dUnNrcA13fTbgc+Xj/ySpJka+T7+qjqY5D3A54BVwLaqejjJh4AdVXUrcD3wh0l2sXCmf/UkGi1JGl1W4gn4iVlXduCSpP7urjt4tg70umvSsXokqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDVm5OBPclaSLyR5JMnDSd47oOaiJM8k2dl9/fp4zZUkjWvkh60DB4F/W1X3JTkBuDfJ9qr66yV1X6yqK8fYjiRpgkY+46+qp6rqvm76m8AjwJmTapgkaTomco0/yUbgh4G7Byx+S5L7k/x5kn9wmHVsSbIjyY4XeX4SzZIkDTDOpR4AkhwPfBJ4X1U9u2TxfcDZVfVckiuATwPnDFpPVW0FtgKcmHU1brskSYONdcaf5BgWQv8TVfWppcur6tmqeq6bvg04Jsn6cbYpSRrPOHf1BLgeeKSqfnuZmtO6OpJc0G3vG6NuU5I0vnEu9VwI/ALwYJKd3bxfA14DUFXXAW8HfjnJQeA7wNVV5WUcSZqhkYO/qu4CcoSaa4FrR92GJGny7LkrSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWrM2A9bl45Wq1+3sXftwcd3T60d0qR5xi9JjRk7+JPsTvJgkp1JdgxYniT/I8muJA8k+ZFxtylJGt2kLvW8taq+vsyyy4Fzuq83Ax/pvkuSZuCVuNRzFfDxWvBXwElJTn8FtitJGmASwV/A7UnuTbJlwPIzgScWvd7Tzfs7kmxJsiPJjhd5fgLNkiQNMolLPRdW1d4kpwDbkzxaVXcuWp4B76mXzajaCmwFODHrXrZckjQZY5/xV9Xe7vt+4BbggiUle4CzFr3eAOwdd7uSpNGMFfxJjktywqFp4FLgoSVltwK/2N3d8+PAM1X11DjblSSNbtxLPacCtyQ5tK4/qqrPJnk3QFVdB9wGXAHsAr4N/PMxtylJGsNYwV9VjwPnDZh/3aLpAn5lnO1IkibHIRv0ipqnYRBmvX1pWhyyQZIaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjHLLhFTRPwxVMy9G6X9I88Yxfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNWbk4E9ybpKdi76eTfK+JTUXJXlmUc2vj99kSdI4Rr6Pv6q+ApwPkGQV8CRwy4DSL1bVlaNuR5I0WZO61HMJ8DdV9bUJrU+SNCWT6rl7NXDjMsvekuR+YC/w76rq4UFFSbYAWwDW8qoJNWtlsdeqJJh9L/6xz/iTrAF+CviTAYvvA86uqvOA3wU+vdx6qmprVW2qqk3HcOy4zZIkLWMSl3ouB+6rqn1LF1TVs1X1XDd9G3BMkvUT2KYkaUSTCP7NLHOZJ8lpSdJNX9Bt7xsT2KYkaURjXeNP8irgbcC7Fs17N0BVXQe8HfjlJAeB7wBXV1WNs01J0njGCv6q+jbw6iXzrls0fS1w7TjbkCRNlj13JakxBr8kNcbgl6TGGPyS1BiDX5Ia48PWtWL17da+EobCmHUXfM2XWf8OeMYvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTErcsiGHLuG1Rs29qqddddnTc88Hdth2jpPQ1Ho6OQZvyQ1plfwJ9mWZH+ShxbNW5dke5LHuu8nL/Pea7qax5JcM6mGS5JG0/eM/2PAZUvmvR+4o6rOAe7oXv8dSdYBHwDeDFwAfGC5fyAkSa+MXsFfVXcCB5bMvgq4oZu+AfjpAW/9SWB7VR2oqr8FtvPyf0AkSa+gca7xn1pVTwF0308ZUHMm8MSi13u6eS+TZEuSHUl2vPC9b4/RLEnS4Uz7w90MmFeDCqtqa1VtqqpNa1a9asrNkqR2jRP8+5KcDtB93z+gZg9w1qLXG4C9Y2xTkjSmcYL/VuDQXTrXAH82oOZzwKVJTu4+1L20mydJmpG+t3PeCHwJODfJniTvBH4TeFuSx4C3da9JsinJRwGq6gDwn4B7uq8PdfMkSTPSq+duVW1eZtElA2p3AP9y0ettwLaRWidJmrgVOWRDPf+C3dU1FX2HS4DpDMMw7HrnyTR+Bk//wlt6r/OkP/xS79rWOWSDJDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMasyCEbjlYHL/7R3rVrd3+j/3p7dn9fCcMKDNOGWZtWW6ex3nkbBqLvz8BhGKbDM35JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUmCMGf5JtSfYneWjRvP+a5NEkDyS5JclJy7x3d5IHk+xMsmOSDZckjabPGf/HgMuWzNsOvLGq3gR8Ffj3h3n/W6vq/KraNFoTJUmTdMTgr6o7gQNL5t1eVQe7l38FbJhC2yRJUzCJnrv/Arh5mWUF3J6kgN+vqq3LrSTJFmALwFpeNYFmrTyrP39v79qDRy75/+vt2QtyJTw8fBo9TIdp69cvPH3i24fhepj2fYD4+r98qvc6h+kVPtTv4RDrZQrrXdt/6yvi93tejBX8Sf4DCxn1iWVKLqyqvUlOAbYnebT7H8TLdP8obAU4MetqnHZJkpY38l09Sa4BrgR+rqoGBnVV7e2+7wduAS4YdXuSpMkYKfiTXAb8KvBTVfXtZWqOS3LCoWngUuChQbWSpFdOn9s5bwS+BJybZE+SdwLXAiewcPlmZ5LrutozktzWvfVU4K4k9wNfBj5TVZ+dyl5Ikno74jX+qto8YPb1y9TuBa7oph8HzhurdZKkibPnriQ1xuCXpMYY/JLUGINfkhpj8EtSY1bkw9Zz7BpWb9jYq/Zo7E49LSvh4eHT6FY/zDrX966ER//1ab1rj3+y/9AGfYdi+No7zui9zrP/ZG/v2mGGA3nuzDW9awcO0buMtbu/0avOYRimwzN+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY3JMo/LnakTs67enEtm3YyjzsGL+w8rsPrz906lDcN0q//uxlf3quvb/X+YdQLs+7Fje9cO47i9/f7mjn/yhd7rHGZohWEM04Zhfl5n/tb/GqU5hzWtIUmGGd6h79/YML+zfbd/d93Bs3UgfWo945ekxvR55u62JPuTPLRo3geTPNk9b3dnkiuWee9lSb6SZFeS90+y4ZKk0fQ54/8YcNmA+b9TVed3X7ctXZhkFfB7wOXAG4DNSd4wTmMlSeM7YvBX1Z3AgRHWfQGwq6oer6oXgJuAq0ZYjyRpgsa5xv+eJA90l4JOHrD8TOCJRa/3dPMGSrIlyY4kO17k+TGaJUk6nFGD/yPA64HzgaeADw+oGfTp8rK3M1TV1qraVFWbjmE6d1NIkkYM/qraV1Xfq6qXgD9g4bLOUnuAsxa93gD0f0yQJGkqRgr+JKcvevkzwEMDyu4Bzkny2iRrgKuBW0fZniRpco74zN0kNwIXAeuT7AE+AFyU5HwWLt3sBt7V1Z4BfLSqrqiqg0neA3wOWAVsq6qHp7IXkqTejhj8VbV5wOzrl6ndC1yx6PVtwMtu9ZQkzc4Rg18rX++u6itgGIZhur/Tc3iFr73jjN6rPPWe/neMfee0l3rXbvyfL/au3f1PjulV960z+t/k0HcYCIADl3+ndy1//v29S4f52fb9nRlmiI3VQwyDMIyhhoLo+Td2cLSmTIxDNkhSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjEM2DHDw4h/tXbt6iGEQpja0wRQM09avX3j6kYs6xw/RBb/v0AZ/73f7j/Y9zBAAwwzDsO/H+g+v0Le9n7nr073X+fqb3927dpizvWkN77B2d9+66QzDMK2/r77ZMcx+TaOtnvFLUmMMfklqjMEvSY0x+CWpMQa/JDXG4JekxvR55u424Epgf1W9sZt3M3BuV3IS8HRVnT/gvbuBbwLfAw5W1aYJtVuSNKI+9/F/DLgW+PihGVX1zw5NJ/kw8Mxh3v/Wqvr6qA2UJE1Wn4et35lk46BlSQL8LHDxZJslSZqWcXvu/iNgX1U9tszyAm5PUsDvV9XW5VaUZAuwBWDt6hNYffbGXg2YRq+2oXrVTXzrw+v7M5hWz+H1vSuH6+W7/r7Jr/NbZ6R37bVbrutd+6/u/sXetV8976RedT/5yJW91zmMl/at7V37Q2/a07v2ac7qXTuN39lhTG29PbNj5j3zx3z/ZuDGwyy/sKr2JjkF2J7k0aq6c1Bh94/CVoAfWHtajdkuSdIyRr6rJ8lq4J8CNy9XU1V7u+/7gVuAC0bdniRpMsa5nfMngEerauD/BZMcl+SEQ9PApcBDY2xPkjQBRwz+JDcCXwLOTbInyTu7RVez5DJPkjOS3Na9PBW4K8n9wJeBz1TVZyfXdEnSKPrc1bN5mfm/NGDeXuCKbvpx4Lwx2ydJmjB77kpSYwx+SWqMwS9JjTH4JakxBr8kNWZFPmy9nn9hpl2aZ92dGobrUt73AeJ9u5MPu/1pDe/w1f/cb2iD13x0Ve91Hv/kEA3Y0r/0daf2H4dw1wMbetU9PsRP6/tO/W7v2mHaevA3Tu1du373U71rmcKQCX3/DgBWf/7e3rV9H6AO03s4/KR5xi9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMalaec81T/J/ga8tmb0e6N/XfH64X/PF/ZovLe3X2VX1g33evCKDf5AkO6pq06zbMWnu13xxv+aL+zWYl3okqTEGvyQ1Zp6Cf+usGzAl7td8cb/mi/s1wNxc45ckTcY8nfFLkibA4Jekxqz44E9yWZKvJNmV5P2zbs8kJdmd5MEkO5PsmHV7RpVkW5L9SR5aNG9dku1JHuu+nzzLNo5imf36YJInu2O2M8kVs2zjsJKcleQLSR5J8nCS93bz5/p4HWa/5v14rU3y5ST3d/v1H7v5r01yd3e8bk6yZqj1ruRr/ElWAV8F3gbsAe4BNlfVX8+0YROSZDewqarmuoNJkn8MPAd8vKre2M37L8CBqvrN7h/sk6vqV2fZzmEts18fBJ6rqv82y7aNKsnpwOlVdV+SE4B7gZ8Gfok5Pl6H2a+fZb6PV4Djquq5JMcAdwHvBf4N8KmquinJdcD9VfWRvutd6Wf8FwC7qurxqnoBuAm4asZt0hJVdSdwYMnsq4AbuukbWPgjnCvL7Ndcq6qnquq+bvqbwCPAmcz58TrMfs21WvBc9/KY7quAi4E/7eYPfbxWevCfCTyx6PUejoKDuUgBtye5N8mWWTdmwk6tqqdg4Y8SOGXG7Zmk9yR5oLsUNFeXRBZLshH4YeBujqLjtWS/YM6PV5JVSXYC+4HtwN8AT1fVwa5k6Fxc6cGfAfNW7rWp4V1YVT8CXA78SndpQSvbR4DXA+cDTwEfnm1zRpPkeOCTwPuq6tlZt2dSBuzX3B+vqvpeVZ0PbGDhKsjfH1Q2zDpXevDvAc5a9HoDsHdGbZm4qtrbfd8P3MLCQT1a7Ouuux66/rp/xu2ZiKra1/0hvgT8AXN4zLprxZ8EPlFVn+pmz/3xGrRfR8PxOqSqngb+Avhx4KQkq7tFQ+fiSg/+e4Bzuk+w1wBXA7fOuE0TkeS47kMokhwHXAo8dPh3zZVbgWu66WuAP5thWybmUDh2foY5O2bdh4XXA49U1W8vWjTXx2u5/ToKjtcPJjmpm/5+4CdY+PziC8Dbu7Khj9eKvqsHoLv96r8Dq4BtVfUbM27SRCR5HQtn+QCrgT+a131LciNwEQtDxe4DPgB8Gvhj4DXA/wHeUVVz9UHpMvt1EQuXDQrYDbzr0LXxeZDkHwJfBB4EXupm/xoL18Pn9ngdZr82M9/H600sfHi7ioUT9T+uqg91+XETsA7438DPV9Xzvde70oNfkjRZK/1SjyRpwgx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1Jj/Byj98YNjwU5qAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD6CAYAAACmjCyGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAE3pJREFUeJzt3X+MZeV93/H3x8MumDULrB0IBgyOg2iRZa+t7RKL/sAmpoBQcConBTUtaSytk8aVrTZS3FSyXVeV0jZOqpbIZBNT48gGktg4qKE2K+IGO7Uxa7r8MmAIBjMsYuMs3mVtY1j49o85K02GO7vn/hju3HneL2k1557znXOeM2fuZ84+95znpKqQJLXjFdNugCTp5WXwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpz1LQbMMj6HF3HsGFq28/cXO/aeuGFFWzJ9AzzMxjK+nUTX2XNpXdtfvhc//W+cn3v2hfW9z+Hmtv7/X6Fr3pl73UOtV8r9Dvr+2Zl9P25/vDFZ3juxWd7vRlWZfAfwwbOzQVT2/7c8Sf2rn3h6adXsCXTM8zPYBh1xikTX+fB44/uXbvu7kd71z7/pjN71x44tX8bNn7ma73qXtzylt7rHGa/Vup31vfNyuj7c/3qvht7r3Osrp4kFyV5MMnDST44YPnRSW7olt+e5MxxtidJGt/IwZ9kDvhd4GLgHOCKJOcsKXsP8HRV/STwO8B/HnV7kqTJGOeMfyvwcFU9UlXPAdcDly2puQy4tpv+E+CCJP07ZCVJEzdO8J8KPL7o9Xw3b2BNVR0E9gGvHrSyJNuS7Eyy83l+NEazJEmHM07wDzpzXzq4f5+ahZlV26tqS1VtWUf/D8okScMZJ/jngdMXvT4N2L1cTZKjgOOBvWNsU5I0pnGC/w7grCSvT7IeuBy4aUnNTcCV3fS7gT8vH/klSVM18nX8VXUwyfuALwJzwDVVdV+SjwI7q+om4BPAHyZ5mIUz/csn0WhJ0ujGuoGrqm4Gbl4y70OLpp8Ffm6cbUiSJmtV3rk7bWv1rsK5E1fmbtyV8op9/YY2OHDOxt7r/O7Ff6d37ZWXfKl37V/867f1b8O2frWbHny29zqHuct43d29S2fKML/fs/Qe79vWqv7DYDhImyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGrMohGzI31/sBw7N06/W0rdTP6sV/1P+h4Ou/039U7udet6lX3aue6P/gnqcuXJlznR3X/c/etW/6rX/Vq+6549b1XueGv3yod+0wD7zPY0/2rp32e3GY7a/V4R368oxfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNWbk4E9yepIvJbk/yX1J3j+g5vwk+5Ls6v59aNC6JEkvn3Gu4z8I/NuqujPJccA3kuyoqm8uqftyVV06xnYkSRM08hl/VT1ZVXd2088A9wOnTqphkqSVMZE7d5OcCbwFuH3A4rcluQvYDfxaVd23zDq2AdsAjuHYNXm33Fo1zN24Lx6/oXftUfv63ZH7xDtO6L3OX3rrn/euvfbmt/eu/fQb/l7vWt72TL+6b72y9yq/f95ZvWuPnT/Qu3al7oZdie2vhvWuhL4/1+yb673OsYM/yauAzwIfqKr9SxbfCZxRVQeSXAJ8Hhj4G1pV24HtABuzqcZtlyRpsLGu6kmyjoXQ/3RVfW7p8qraX1UHuumbgXVJXjPONiVJ4xnnqp4AnwDur6rfXqbmx7s6kmzttvc3o25TkjS+cbp6zgP+OXBPkl3dvN8AXgdQVVcD7wZ+JclB4IfA5VVlN44kTdHIwV9VXwFyhJqrgKtG3YYkafK8c1eSGmPwS1JjDH5JaozBL0mNMfglqTFZjVdXbsymOjcXTLsZE9f6A55hZX4Gz166tfc6D7y2/23t6971171r9+w5vnftif93fa+6TQ8+23udfYe3gOEeoJ4TNvauPfjtx3rXztLwDrPi9rqV/bX3sFdaHuIZvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGjP2w9bVopYZWmPYt5athyIg645Teta/oWbv+med7r3P9gf7nOk99+9W9a0/+y153ynf6DZOy/jt7+6/xe/t71w4zDMNKmfZ7oXWe8UtSY8YO/iSPJrknya4kOwcsT5L/nuThJHcneeu425QkjW5SXT1vr6rvLrPsYuCs7t+5wMe7r5KkKXg5unouAz5VC74GnJCkf0evJGmiJhH8BdyS5BtJtg1Yfirw+KLX8928vyXJtiQ7k+x8nv5ji0uShjOJrp7zqmp3kpOAHUkeqKrbFi0fdLnDSy5rqKrtwHZYeBDLBNolSRpg7DP+qtrdfd0D3AgsfRzSPHD6otenAbvH3a4kaTRjBX+SDUmOOzQNXAjcu6TsJuBfdFf3/BSwr6r6P/tNkjRR43b1nAzcmOTQuj5TVV9I8ssAVXU1cDNwCfAw8APgX465TUnSGMYK/qp6BHjzgPlXL5ou4FfH2Y4kaXIcsmGAtXo7+Urt1zBDQfBY/16+vsM7DDO0wfrjTu5de/r/7l3KsfPP9K59xb7v96o7+O3H+q9z8zm9a1/Y9c3etSul7+/MWn0vTptDNkhSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjEM2rFLDDIMwS7e1D9XWnrUZ4md17PyG3rUHjz+6d22GGYqiZ91QvwOrYBiGYczS7+xa5Bm/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaszIwZ/k7CS7Fv3bn+QDS2rOT7JvUc2Hxm+yJGkcI1/HX1UPApsBkswBTwA3Dij9clVdOup2JEmTNamunguAv6qq/g8JlSRNxaTu3L0cuG6ZZW9LchewG/i1qrpvUFGSbcA2gGM4dkLNml2zdGfjtNu6EncDA6yb8t3Tz166tXftMf/r6xPf/rCGudO4r2n/bq1VY5/xJ1kP/AzwxwMW3wmcUVVvBv4H8Pnl1lNV26tqS1VtWUf/W+UlScOZRFfPxcCdVfXU0gVVtb+qDnTTNwPrkrxmAtuUJI1oEsF/Bct08yT58STpprd22/ubCWxTkjSisfr4kxwLvBN476J5vwxQVVcD7wZ+JclB4IfA5VXVd3BCSdIKGCv4q+oHwKuXzLt60fRVwFXjbEOSNFneuStJjTH4JakxBr8kNcbgl6TGGPyS1Bgfti69zPoObbAahmEYhsMrzA7P+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xiEbpGWs1BAEDm2wMvoOhQEeA8/4JakxvYI/yTVJ9iS5d9G8TUl2JHmo+zrwz22SK7uah5JcOamGS5JG0/eM/5PARUvmfRC4tarOAm7tXv8tSTYBHwbOBbYCH17uD4Qk6eXRK/ir6jZg75LZlwHXdtPXAu8a8K3/GNhRVXur6mlgBy/9AyJJehmN08d/clU9CdB9PWlAzanA44tez3fzXiLJtiQ7k+x8nh+N0SxJ0uGs9Ie7GTCvBhVW1faq2lJVW9Zx9Ao3S5LaNU7wP5XkFIDu654BNfPA6YtenwbsHmObkqQxjRP8NwGHrtK5EvjTATVfBC5McmL3oe6F3TxJ0pT0vZzzOuCrwNlJ5pO8B/hN4J1JHgLe2b0myZYkfwBQVXuB/wjc0f37aDdPkjQlqRrY5T5VG7Opzs0F026GpBnS+p27t9et7K+9gz5XfQmHbJC0JqzFMF8pDtkgSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEO2bAG9B2jxFvaJYFn/JLUHINfkhpj8EtSYwx+SWqMwS9JjTH4JakxRwz+JNck2ZPk3kXz/muSB5LcneTGJCcs872PJrknya4kOyfZcEnSaPqc8X8SuGjJvB3AG6vqTcC3gH93mO9/e1VtrqotozVRkjRJRwz+qroN2Ltk3i1VdbB7+TXgtBVomyRpBUzizt1fAm5YZlkBtyQp4PeqavtyK0myDdgGcAzHTqBZ7fCOXEnDGCv4k/x74CDw6WVKzquq3UlOAnYkeaD7H8RLdH8UtgNszKYap12SpOWNfFVPkiuBS4F/VlUDg7qqdndf9wA3AltH3Z4kaTJGCv4kFwG/DvxMVf1gmZoNSY47NA1cCNw7qFaS9PLpcznndcBXgbOTzCd5D3AVcBwL3Te7klzd1b42yc3dt54MfCXJXcDXgT+rqi+syF5IknrLMr00U7Uxm+rcXDDtZkjSzLi9bmV/7U2fWu/claTGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUmD7P3L0myZ4k9y6a95EkT3TP292V5JJlvveiJA8meTjJByfZcEnSaPqc8X8SuGjA/N+pqs3dv5uXLkwyB/wucDFwDnBFknPGaawkaXxHDP6qug3YO8K6twIPV9UjVfUccD1w2QjrkSRN0Dh9/O9LcnfXFXTigOWnAo8vej3fzRsoybYkO5PsfJ4fjdEsSdLhjBr8HwfeAGwGngQ+NqAmA+bVciusqu1VtaWqtqzj6BGbJUk6kpGCv6qeqqoXqupF4PdZ6NZZah44fdHr04Ddo2xPkjQ5IwV/klMWvfxZ4N4BZXcAZyV5fZL1wOXATaNsT5I0OUcdqSDJdcD5wGuSzAMfBs5PspmFrptHgfd2ta8F/qCqLqmqg0neB3wRmAOuqar7VmQvJEm9pWrZbvep2ZhNdW4umHYzJGlm3F63sr/2Dvps9SWOeMYvSS2bO3HQRYuDvfD00yvYkslxyAZJaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjXHIBkk6jFkZhmEYnvFLUmMMfklqjMEvSY0x+CWpMQa/JDXG4JekxvR55u41wKXAnqp6YzfvBuDsruQE4HtVtXnA9z4KPAO8ABysqi0TarckaUR9ruP/JHAV8KlDM6rqnx6aTvIxYN9hvv/tVfXdURsoSZqsIwZ/Vd2W5MxBy5IE+HngHZNtliRppYx75+4/AJ6qqoeWWV7ALUkK+L2q2r7cipJsA7YBHMOxYzZL41qLD5iWtGDc4L8CuO4wy8+rqt1JTgJ2JHmgqm4bVNj9UdgOsDGbasx2SZKWMfJVPUmOAv4JcMNyNVW1u/u6B7gR2Drq9iRJkzHO5Zw/DTxQVfODFibZkOS4Q9PAhcC9Y2xPkjQBRwz+JNcBXwXOTjKf5D3dostZ0s2T5LVJbu5engx8JcldwNeBP6uqL0yu6ZKkUfS5queKZeb/4oB5u4FLuulHgDeP2T5J0oR5564kNcbgl6TGGPyS1BiDX5IaY/BLUmN82LoGchgGae3yjF+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSY1K1+p5rnuSvgceWzH4N8N0pNGeluV+zxf2aLS3t1xlV9WN9vnlVBv8gSXZW1ZZpt2PS3K/Z4n7NFvdrMLt6JKkxBr8kNWaWgn/7tBuwQtyv2eJ+zRb3a4CZ6eOXJE3GLJ3xS5ImwOCXpMas+uBPclGSB5M8nOSD027PJCV5NMk9SXYl2Tnt9owqyTVJ9iS5d9G8TUl2JHmo+3riNNs4imX26yNJnuiO2a4kl0yzjcNKcnqSLyW5P8l9Sd7fzZ/p43WY/Zr143VMkq8nuavbr//QzX99ktu743VDkvVDrXc19/EnmQO+BbwTmAfuAK6oqm9OtWETkuRRYEtVzfQNJkn+IXAA+FRVvbGb91+AvVX1m90f7BOr6ten2c5hLbNfHwEOVNVvTbNto0pyCnBKVd2Z5DjgG8C7gF9kho/XYfbr55nt4xVgQ1UdSLIO+ArwfuDfAJ+rquuTXA3cVVUf77ve1X7GvxV4uKoeqarngOuBy6bcJi1RVbcBe5fMvgy4tpu+loU34UxZZr9mWlU9WVV3dtPPAPcDpzLjx+sw+zXTasGB7uW67l8B7wD+pJs/9PFa7cF/KvD4otfzrIGDuUgBtyT5RpJt027MhJ1cVU/CwpsSOGnK7Zmk9yW5u+sKmqkukcWSnAm8BbidNXS8luwXzPjxSjKXZBewB9gB/BXwvao62JUMnYurPfgzYN7q7Zsa3nlV9VbgYuBXu64FrW4fB94AbAaeBD423eaMJsmrgM8CH6iq/dNuz6QM2K+ZP15V9UJVbQZOY6EX5O8OKhtmnas9+OeB0xe9Pg3YPaW2TFxV7e6+7gFuZOGgrhVPdf2uh/pf90y5PRNRVU91b8QXgd9nBo9Z11f8WeDTVfW5bvbMH69B+7UWjtchVfU94P8APwWckOSobtHQubjag/8O4KzuE+z1wOXATVNu00Qk2dB9CEWSDcCFwL2H/66ZchNwZTd9JfCnU2zLxBwKx87PMmPHrPuw8BPA/VX124sWzfTxWm6/1sDx+rEkJ3TTrwR+moXPL74EvLsrG/p4reqregC6y6/+GzAHXFNV/2nKTZqIJD/Bwlk+wFHAZ2Z135JcB5zPwlCxTwEfBj4P/BHwOuA7wM9V1Ux9ULrMfp3PQrdBAY8C7z3UNz4Lkvx94MvAPcCL3ezfYKE/fGaP12H26wpm+3i9iYUPb+dYOFH/o6r6aJcf1wObgP8H/EJV/aj3eld78EuSJmu1d/VIkibM4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mN+f/M2d1xcxtgZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "#Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "#Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "for i in range(1,5):\n",
    "    idea=np.random.randint(1,sector2.shape[0])\n",
    "    plt.imshow(sector2[idea], cmap='viridis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "10000\n",
      "20000\n",
      "(8655, 620)\n",
      "(3929, 620)\n",
      "(2550, 620)\n",
      "(2132, 620)\n",
      "(2734, 620)\n"
     ]
    }
   ],
   "source": [
    "tr_size=40\n",
    "val_size=20\n",
    "test_size=100-val_size-tr_size\n",
    "conjunto_datos_nuevo2=np.concatenate((conjunto_datos[:,0:3],conjunto_datos_nuevo), axis=1)\n",
    "tamanyo_tr=floor(tr_size*numero_muestras/100)\n",
    "tamanyo_val=floor(val_size*numero_muestras/100)\n",
    "tamanyo_test=numero_muestras-tamanyo_tr-tamanyo_val\n",
    "print(tamanyo_tr)\n",
    "print(tamanyo_val)\n",
    "print(tamanyo_test)\n",
    "\n",
    "\n",
    "XY_test=conjunto_datos_nuevo2[tamanyo_tr+tamanyo_val:numero_muestras,:]\n",
    "\n",
    "\n",
    "XY_test_bin0=XY_test[np.where((XY_test[:,1]>=164.9999) * (XY_test[:,1]<171.000))]\n",
    "XY_test_bin1=XY_test[np.where((XY_test[:,1]>=171.000) * (XY_test[:,1]<177.000))]\n",
    "XY_test_bin2=XY_test[np.where((XY_test[:,1]>=177.000) * (XY_test[:,1]<183.0000))]\n",
    "XY_test_bin3=XY_test[np.where((XY_test[:,1]>=183.000) * (XY_test[:,1]<189.0000))]\n",
    "XY_test_bin4=XY_test[np.where((XY_test[:,1]>=189.0000))]\n",
    "\n",
    "x_train=conjunto_datos_nuevo2[:tamanyo_tr,3:]\n",
    "x_val=conjunto_datos_nuevo2[tamanyo_tr:tamanyo_tr+tamanyo_val,3:]\n",
    "x_test=conjunto_datos_nuevo2[tamanyo_tr+tamanyo_val:numero_muestras,3:]\n",
    "\n",
    "x_test_bin0=XY_test_bin0[:,3:]\n",
    "Y_test_bin0=XY_test_bin0[:,1]\n",
    "print(x_test_bin0.shape)\n",
    "x_test_bin1=XY_test_bin1[:,3:]\n",
    "Y_test_bin1=XY_test_bin1[:,1]\n",
    "print(x_test_bin1.shape)\n",
    "x_test_bin2=XY_test_bin2[:,3:]\n",
    "Y_test_bin2=XY_test_bin2[:,1]\n",
    "print(x_test_bin2.shape)\n",
    "x_test_bin3=XY_test_bin3[:,3:]\n",
    "Y_test_bin3=XY_test_bin3[:,1]\n",
    "print(x_test_bin3.shape)\n",
    "x_test_bin4=XY_test_bin4[:,3:]\n",
    "Y_test_bin4=XY_test_bin4[:,1]\n",
    "print(x_test_bin4.shape)\n",
    "\n",
    "\n",
    "\n",
    "Y_train=conjunto_datos_nuevo2[:tamanyo_tr,1] #elijo la coordenada radius\n",
    "Y_val=conjunto_datos_nuevo2[tamanyo_tr:tamanyo_tr+tamanyo_val,1] #elijo la corrdenada radius\n",
    "Y_test=conjunto_datos_nuevo2[tamanyo_tr+tamanyo_val:numero_muestras,1] #elijo la corrdenada radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cols=31\n",
    "img_rows=20\n",
    "\n",
    "X_train = x_train.reshape(x_train.shape[0], img_rows, img_cols,1)\n",
    "X_val = x_val.reshape(x_val.shape[0], img_rows, img_cols,1)\n",
    "X_test = x_test.reshape(x_test.shape[0], img_rows, img_cols,1)\n",
    "\n",
    "X_test_bin0 = x_test_bin0.reshape(x_test_bin0.shape[0], img_rows, img_cols,1)\n",
    "X_test_bin1 = x_test_bin1.reshape(x_test_bin1.shape[0], img_rows, img_cols,1)\n",
    "X_test_bin2 = x_test_bin2.reshape(x_test_bin2.shape[0], img_rows, img_cols,1)\n",
    "X_test_bin3 = x_test_bin3.reshape(x_test_bin3.shape[0], img_rows, img_cols,1)\n",
    "X_test_bin4 = x_test_bin4.reshape(x_test_bin4.shape[0], img_rows, img_cols,1)\n",
    "\n",
    "input_shape = (img_rows, img_cols,1)\n",
    "#input_shape=input_shape.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (20000, 20, 31, 1)\n",
      "20000 train samples\n",
      "10000 validation samples\n",
      "20000 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_val= X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_val.shape[0], 'validation samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display 20 random training images using image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "#Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "#Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "for i in range(1,5):\n",
    "    idea=np.random.randint(1,X_train.shape[0])\n",
    "    plt.imshow(np.reshape(X_train[idea], [img_rows, img_cols]), cmap='viridis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the MLP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 1. 0. 0. 1. 1. 2. 2. 3.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 3. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "X_train shape: (20000, 20, 31, 1)\n",
      "20000 train samples\n",
      "10000 validation samples\n",
      "20000 test samples\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 1. 0. 0. 1. 1. 2. 2. 3.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 3. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_val[:10,:10])\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler().fit(x_train)\n",
    "#min_max_scaler = preprocessing.RobustScaler().fit(x_train)\n",
    "# supermax=1\n",
    "# factor_aprendizaje=0.0001\n",
    "print(min_max_scaler)\n",
    "# comentar las siguientes lineas si no queremos normalizar\n",
    "# x_train = min_max_scaler.transform(x_train)\n",
    "# x_val = min_max_scaler.transform(x_val)\n",
    "# x_test = min_max_scaler.transform(x_test)\n",
    "# x_test_bin0 = min_max_scaler.transform(x_test_bin0)\n",
    "# x_test_bin1 = min_max_scaler.transform(x_test_bin1)\n",
    "# x_test_bin2 = min_max_scaler.transform(x_test_bin2)\n",
    "# x_test_bin3 = min_max_scaler.transform(x_test_bin3)\n",
    "# x_test_bin4 = min_max_scaler.transform(x_test_bin4)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_val.shape[0], 'validation samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "model=Sequential()\n",
    "# add input layer\n",
    "model.add(Dense(\n",
    "    units=n_hidden1,\n",
    "    input_dim=x_train.shape[1],\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    activation='tanh') \n",
    ")\n",
    "# add hidden layer\n",
    "model.add(\n",
    "    Dense(\n",
    "        units=n_hidden1,\n",
    "        input_dim=n_hidden2,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh')\n",
    "    )\n",
    "# add output layer\n",
    "model.add(\n",
    "    Dense(\n",
    "        units=1,\n",
    "        input_dim=n_hidden2,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='linear')\n",
    "    )\n",
    "\n",
    "# define SGD optimizer\n",
    "sgd_optimizer = SGD(\n",
    "    lr=0.001, decay=1e-7, momentum=0.9\n",
    ")\n",
    "# compile model\n",
    "experimento=\"{}_{}_tanh_tanh_linear_sin_normalizar_original_fil5\".format(n_hidden1,n_hidden2)\n",
    "algoritmo='adam'\n",
    "tensorboard=TensorBoard(log_dir=\"/home/rgadea3/EXPERIMENTOS/nuevas_investigaciones_2018/experimentos/logs/defs/{}{}{}\".format(experimento,algoritmo,datetime.now()))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=algoritmo\n",
    "\n",
    "             )\n",
    "print(x_val[:10,:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a summary of the model parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 80)                49680     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 80)                6480      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 81        \n",
      "=================================================================\n",
      "Total params: 56,241\n",
      "Trainable params: 56,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now train the model and evaluate on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/2000\n",
      "20000/20000 [==============================] - 3s 129us/step - loss: 28885.5120 - val_loss: 27605.1182\n",
      "Epoch 2/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 26907.4034 - val_loss: 26423.6744\n",
      "Epoch 3/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 26001.4469 - val_loss: 25687.4365\n",
      "Epoch 4/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 25333.9652 - val_loss: 25061.6559\n",
      "Epoch 5/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 24738.5932 - val_loss: 24486.7326\n",
      "Epoch 6/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 24180.5471 - val_loss: 23941.2510\n",
      "Epoch 7/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 23645.3798 - val_loss: 23414.9768\n",
      "Epoch 8/2000\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 23127.8307 - val_loss: 22904.8434\n",
      "Epoch 9/2000\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 22624.5242 - val_loss: 22407.8541\n",
      "Epoch 10/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 22133.7887 - val_loss: 21922.4715\n",
      "Epoch 11/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 21653.8480 - val_loss: 21447.3971\n",
      "Epoch 12/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 21183.9670 - val_loss: 20982.1340\n",
      "Epoch 13/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 20723.5871 - val_loss: 20526.1961\n",
      "Epoch 14/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 20272.3584 - val_loss: 20079.1248\n",
      "Epoch 15/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 19829.7972 - val_loss: 19640.4922\n",
      "Epoch 16/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 19395.4942 - val_loss: 19210.0209\n",
      "Epoch 17/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 18969.2313 - val_loss: 18787.5496\n",
      "Epoch 18/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 18550.8017 - val_loss: 18372.7508\n",
      "Epoch 19/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 18139.9344 - val_loss: 17965.4529\n",
      "Epoch 20/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 17736.5125 - val_loss: 17565.3510\n",
      "Epoch 21/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 17340.2908 - val_loss: 17172.4062\n",
      "Epoch 22/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 16951.1063 - val_loss: 16786.5629\n",
      "Epoch 23/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 16568.9216 - val_loss: 16407.6029\n",
      "Epoch 24/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 16193.5811 - val_loss: 16035.3396\n",
      "Epoch 25/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 15824.9406 - val_loss: 15669.6684\n",
      "Epoch 26/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 15462.7128 - val_loss: 15310.7852\n",
      "Epoch 27/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 15107.2448 - val_loss: 14958.0487\n",
      "Epoch 28/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 14757.9649 - val_loss: 14611.6988\n",
      "Epoch 29/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 14414.9451 - val_loss: 14271.6058\n",
      "Epoch 30/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 14078.1262 - val_loss: 13937.6329\n",
      "Epoch 31/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 13747.3478 - val_loss: 13609.7520\n",
      "Epoch 32/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 13422.6387 - val_loss: 13287.7104\n",
      "Epoch 33/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 13103.7885 - val_loss: 12971.5125\n",
      "Epoch 34/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 12790.6895 - val_loss: 12661.2243\n",
      "Epoch 35/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 12483.4567 - val_loss: 12356.4893\n",
      "Epoch 36/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 12181.8014 - val_loss: 12057.4012\n",
      "Epoch 37/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 11885.7470 - val_loss: 11763.8441\n",
      "Epoch 38/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 11595.1403 - val_loss: 11475.8484\n",
      "Epoch 39/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 11310.0493 - val_loss: 11193.1591\n",
      "Epoch 40/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 11030.2958 - val_loss: 10915.7477\n",
      "Epoch 41/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 10755.7499 - val_loss: 10643.6831\n",
      "Epoch 42/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 10486.4926 - val_loss: 10376.7473\n",
      "Epoch 43/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 10222.3303 - val_loss: 10114.9586\n",
      "Epoch 44/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 9963.2678 - val_loss: 9858.1970\n",
      "Epoch 45/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 9709.2330 - val_loss: 9606.3528\n",
      "Epoch 46/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 9460.0922 - val_loss: 9359.4525\n",
      "Epoch 47/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 9215.8502 - val_loss: 9117.3668\n",
      "Epoch 48/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 8976.3748 - val_loss: 8880.1185\n",
      "Epoch 49/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 8741.6948 - val_loss: 8647.5327\n",
      "Epoch 50/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 8511.6567 - val_loss: 8419.6210\n",
      "Epoch 51/2000\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 8286.2476 - val_loss: 8196.2920\n",
      "Epoch 52/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 8065.3914 - val_loss: 7977.4829\n",
      "Epoch 53/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 7849.0394 - val_loss: 7763.1055\n",
      "Epoch 54/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 7637.0984 - val_loss: 7553.1414\n",
      "Epoch 55/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 7429.5394 - val_loss: 7347.5048\n",
      "Epoch 56/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 7226.2511 - val_loss: 7146.2171\n",
      "Epoch 57/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 7027.3065 - val_loss: 6949.0355\n",
      "Epoch 58/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 6832.4535 - val_loss: 6756.1000\n",
      "Epoch 59/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 6641.7775 - val_loss: 6567.2629\n",
      "Epoch 60/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 6455.1394 - val_loss: 6382.5406\n",
      "Epoch 61/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 6272.6374 - val_loss: 6201.6432\n",
      "Epoch 62/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 6093.9685 - val_loss: 6024.7689\n",
      "Epoch 63/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 5919.2217 - val_loss: 5851.8311\n",
      "Epoch 64/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 5748.3676 - val_loss: 5682.6772\n",
      "Epoch 65/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 5581.3025 - val_loss: 5517.2592\n",
      "Epoch 66/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 5417.9625 - val_loss: 5355.5515\n",
      "Epoch 67/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 5258.3124 - val_loss: 5197.4900\n",
      "Epoch 68/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 5102.2810 - val_loss: 5043.0419\n",
      "Epoch 69/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 4949.8093 - val_loss: 4892.1848\n",
      "Epoch 70/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 4800.8723 - val_loss: 4744.8308\n",
      "Epoch 71/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 16us/step - loss: 4655.4416 - val_loss: 4600.8585\n",
      "Epoch 72/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 4513.4013 - val_loss: 4460.2625\n",
      "Epoch 73/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 4374.7016 - val_loss: 4323.0430\n",
      "Epoch 74/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 4239.3192 - val_loss: 4189.1324\n",
      "Epoch 75/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 4107.2065 - val_loss: 4058.4547\n",
      "Epoch 76/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3978.3250 - val_loss: 3930.9144\n",
      "Epoch 77/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3852.5670 - val_loss: 3806.5300\n",
      "Epoch 78/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3729.9112 - val_loss: 3685.2579\n",
      "Epoch 79/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3610.3352 - val_loss: 3567.0020\n",
      "Epoch 80/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3493.7702 - val_loss: 3451.6999\n",
      "Epoch 81/2000\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 3380.1640 - val_loss: 3339.3073\n",
      "Epoch 82/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3269.4259 - val_loss: 3229.8507\n",
      "Epoch 83/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3161.5885 - val_loss: 3123.1978\n",
      "Epoch 84/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 3056.5162 - val_loss: 3019.3876\n",
      "Epoch 85/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 2954.2287 - val_loss: 2918.3228\n",
      "Epoch 86/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 2854.7015 - val_loss: 2819.8675\n",
      "Epoch 87/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 2757.7641 - val_loss: 2724.1258\n",
      "Epoch 88/2000\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 2663.4953 - val_loss: 2630.9478\n",
      "Epoch 89/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 2571.7815 - val_loss: 2540.3224\n",
      "Epoch 90/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 2482.6104 - val_loss: 2452.1708\n",
      "Epoch 91/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 2395.8520 - val_loss: 2366.5768\n",
      "Epoch 92/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 2311.6243 - val_loss: 2283.2990\n",
      "Epoch 93/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 2229.7267 - val_loss: 2202.4057\n",
      "Epoch 94/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 2150.1876 - val_loss: 2123.8255\n",
      "Epoch 95/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 2072.9428 - val_loss: 2047.5190\n",
      "Epoch 96/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1997.9207 - val_loss: 1973.5009\n",
      "Epoch 97/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1925.1458 - val_loss: 1901.6484\n",
      "Epoch 98/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1854.5383 - val_loss: 1831.9085\n",
      "Epoch 99/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1786.0146 - val_loss: 1764.3181\n",
      "Epoch 100/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1719.6352 - val_loss: 1698.6981\n",
      "Epoch 101/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1655.2242 - val_loss: 1635.1454\n",
      "Epoch 102/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 1592.8198 - val_loss: 1573.5856\n",
      "Epoch 103/2000\n",
      "20000/20000 [==============================] - 0s 12us/step - loss: 1532.3827 - val_loss: 1513.9447\n",
      "Epoch 104/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 1473.8448 - val_loss: 1456.2012\n",
      "Epoch 105/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1417.1820 - val_loss: 1400.2962\n",
      "Epoch 106/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1362.3393 - val_loss: 1346.2027\n",
      "Epoch 107/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1309.3039 - val_loss: 1293.8404\n",
      "Epoch 108/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1257.9942 - val_loss: 1243.2078\n",
      "Epoch 109/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1208.3793 - val_loss: 1194.2907\n",
      "Epoch 110/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1160.4254 - val_loss: 1147.0572\n",
      "Epoch 111/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1114.1393 - val_loss: 1101.3872\n",
      "Epoch 112/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1069.4073 - val_loss: 1057.3118\n",
      "Epoch 113/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1026.2662 - val_loss: 1014.7130\n",
      "Epoch 114/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 984.5707 - val_loss: 973.6831\n",
      "Epoch 115/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 944.4141 - val_loss: 934.0635\n",
      "Epoch 116/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 905.6367 - val_loss: 895.9288\n",
      "Epoch 117/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 868.3231 - val_loss: 859.1200\n",
      "Epoch 118/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 832.3157 - val_loss: 823.7170\n",
      "Epoch 119/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 797.7253 - val_loss: 789.5119\n",
      "Epoch 120/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 764.3307 - val_loss: 756.6729\n",
      "Epoch 121/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 732.2411 - val_loss: 725.0694\n",
      "Epoch 122/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 701.4006 - val_loss: 694.6266\n",
      "Epoch 123/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 671.6811 - val_loss: 665.4467\n",
      "Epoch 124/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 643.1937 - val_loss: 637.3544\n",
      "Epoch 125/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 615.7975 - val_loss: 610.3827\n",
      "Epoch 126/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 589.5041 - val_loss: 584.4806\n",
      "Epoch 127/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 564.2604 - val_loss: 559.6403\n",
      "Epoch 128/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 540.0560 - val_loss: 535.8108\n",
      "Epoch 129/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 516.8399 - val_loss: 512.9817\n",
      "Epoch 130/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 494.5883 - val_loss: 491.1273\n",
      "Epoch 131/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 473.3181 - val_loss: 470.1313\n",
      "Epoch 132/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 452.9029 - val_loss: 450.0750\n",
      "Epoch 133/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 433.4083 - val_loss: 430.8488\n",
      "Epoch 134/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 414.7233 - val_loss: 412.5073\n",
      "Epoch 135/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 396.9062 - val_loss: 394.9335\n",
      "Epoch 136/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 379.8265 - val_loss: 378.2157\n",
      "Epoch 137/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 363.5841 - val_loss: 362.1904\n",
      "Epoch 138/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 348.0703 - val_loss: 346.8649\n",
      "Epoch 139/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 333.2068 - val_loss: 332.3452\n",
      "Epoch 140/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 319.1214 - val_loss: 318.4320\n",
      "Epoch 141/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 305.6415 - val_loss: 305.2237\n",
      "Epoch 142/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 292.8492 - val_loss: 292.6073\n",
      "Epoch 143/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 16us/step - loss: 280.6425 - val_loss: 280.6260\n",
      "Epoch 144/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 269.0532 - val_loss: 269.2144\n",
      "Epoch 145/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 258.0310 - val_loss: 258.3627\n",
      "Epoch 146/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 247.5477 - val_loss: 248.0739\n",
      "Epoch 147/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 237.6142 - val_loss: 238.2876\n",
      "Epoch 148/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 228.1730 - val_loss: 229.0144\n",
      "Epoch 149/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 219.2219 - val_loss: 220.2303\n",
      "Epoch 150/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 210.7550 - val_loss: 211.8838\n",
      "Epoch 151/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 202.7252 - val_loss: 203.9816\n",
      "Epoch 152/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 195.1203 - val_loss: 196.5134\n",
      "Epoch 153/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 187.9346 - val_loss: 189.4465\n",
      "Epoch 154/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 181.1546 - val_loss: 182.7420\n",
      "Epoch 155/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 174.7226 - val_loss: 176.4388\n",
      "Epoch 156/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 168.6701 - val_loss: 170.4812\n",
      "Epoch 157/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 162.9573 - val_loss: 164.8615\n",
      "Epoch 158/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 157.5695 - val_loss: 159.5678\n",
      "Epoch 159/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 152.5111 - val_loss: 154.5542\n",
      "Epoch 160/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 147.7180 - val_loss: 149.8706\n",
      "Epoch 161/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 143.2375 - val_loss: 145.4446\n",
      "Epoch 162/2000\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 139.0140 - val_loss: 141.2886\n",
      "Epoch 163/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 135.0522 - val_loss: 137.3796\n",
      "Epoch 164/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 131.3287 - val_loss: 133.7157\n",
      "Epoch 165/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 127.8367 - val_loss: 130.2840\n",
      "Epoch 166/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 124.5741 - val_loss: 127.0525\n",
      "Epoch 167/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 121.5077 - val_loss: 124.0353\n",
      "Epoch 168/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 118.6443 - val_loss: 121.2090\n",
      "Epoch 169/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 115.9666 - val_loss: 118.5647\n",
      "Epoch 170/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 113.4739 - val_loss: 116.0770\n",
      "Epoch 171/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 111.1214 - val_loss: 113.7884\n",
      "Epoch 172/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 108.9628 - val_loss: 111.6167\n",
      "Epoch 173/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 106.9241 - val_loss: 109.6107\n",
      "Epoch 174/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 105.0328 - val_loss: 107.7469\n",
      "Epoch 175/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 103.2757 - val_loss: 106.0107\n",
      "Epoch 176/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 101.6513 - val_loss: 104.3787\n",
      "Epoch 177/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 100.1263 - val_loss: 102.8775\n",
      "Epoch 178/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 98.7244 - val_loss: 101.4728\n",
      "Epoch 179/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 97.4161 - val_loss: 100.1772\n",
      "Epoch 180/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 96.2081 - val_loss: 98.9764\n",
      "Epoch 181/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 95.0930 - val_loss: 97.8587\n",
      "Epoch 182/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 94.0556 - val_loss: 96.8318\n",
      "Epoch 183/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 93.1005 - val_loss: 95.8826\n",
      "Epoch 184/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 92.2241 - val_loss: 94.9967\n",
      "Epoch 185/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 91.4132 - val_loss: 94.1767\n",
      "Epoch 186/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 90.6588 - val_loss: 93.4328\n",
      "Epoch 187/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 89.9723 - val_loss: 92.7433\n",
      "Epoch 188/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 89.3430 - val_loss: 92.1015\n",
      "Epoch 189/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 88.7600 - val_loss: 91.5149\n",
      "Epoch 190/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 88.2246 - val_loss: 90.9808\n",
      "Epoch 191/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 87.7405 - val_loss: 90.4808\n",
      "Epoch 192/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 87.2928 - val_loss: 90.0231\n",
      "Epoch 193/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 86.8835 - val_loss: 89.6047\n",
      "Epoch 194/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 86.5054 - val_loss: 89.2308\n",
      "Epoch 195/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 86.1684 - val_loss: 88.8802\n",
      "Epoch 196/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 85.8596 - val_loss: 88.5553\n",
      "Epoch 197/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 85.5708 - val_loss: 88.2699\n",
      "Epoch 198/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 85.3196 - val_loss: 87.9965\n",
      "Epoch 199/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 85.0790 - val_loss: 87.7605\n",
      "Epoch 200/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 84.8713 - val_loss: 87.5351\n",
      "Epoch 201/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 84.6769 - val_loss: 87.3333\n",
      "Epoch 202/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 84.5038 - val_loss: 87.1472\n",
      "Epoch 203/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 84.3423 - val_loss: 86.9859\n",
      "Epoch 204/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 84.2038 - val_loss: 86.8303\n",
      "Epoch 205/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 84.0742 - val_loss: 86.6909\n",
      "Epoch 206/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.9565 - val_loss: 86.5681\n",
      "Epoch 207/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.8533 - val_loss: 86.4542\n",
      "Epoch 208/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.7591 - val_loss: 86.3519\n",
      "Epoch 209/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.6748 - val_loss: 86.2589\n",
      "Epoch 210/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.5995 - val_loss: 86.1742\n",
      "Epoch 211/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.5333 - val_loss: 86.0947\n",
      "Epoch 212/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.4697 - val_loss: 86.0295\n",
      "Epoch 213/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.4165 - val_loss: 85.9684\n",
      "Epoch 214/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.3685 - val_loss: 85.9124\n",
      "Epoch 215/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.3249 - val_loss: 85.8631\n",
      "Epoch 216/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 14us/step - loss: 83.2876 - val_loss: 85.8163\n",
      "Epoch 217/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 83.2524 - val_loss: 85.7765\n",
      "Epoch 218/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.2221 - val_loss: 85.7405\n",
      "Epoch 219/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.1958 - val_loss: 85.7066\n",
      "Epoch 220/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.1725 - val_loss: 85.6751\n",
      "Epoch 221/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.1519 - val_loss: 85.6467\n",
      "Epoch 222/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.1314 - val_loss: 85.6257\n",
      "Epoch 223/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.1166 - val_loss: 85.6033\n",
      "Epoch 224/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.1011 - val_loss: 85.5864\n",
      "Epoch 225/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0895 - val_loss: 85.5676\n",
      "Epoch 226/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0777 - val_loss: 85.5521\n",
      "Epoch 227/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0682 - val_loss: 85.5376\n",
      "Epoch 228/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0592 - val_loss: 85.5265\n",
      "Epoch 229/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0525 - val_loss: 85.5135\n",
      "Epoch 230/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0455 - val_loss: 85.5039\n",
      "Epoch 231/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0400 - val_loss: 85.4941\n",
      "Epoch 232/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0348 - val_loss: 85.4863\n",
      "Epoch 233/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0307 - val_loss: 85.4793\n",
      "Epoch 234/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0269 - val_loss: 85.4728\n",
      "Epoch 235/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0243 - val_loss: 85.4657\n",
      "Epoch 236/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.0207 - val_loss: 85.4620\n",
      "Epoch 237/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0186 - val_loss: 85.4571\n",
      "Epoch 238/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0167 - val_loss: 85.4518\n",
      "Epoch 239/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0149 - val_loss: 85.4478\n",
      "Epoch 240/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0131 - val_loss: 85.4456\n",
      "Epoch 241/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0120 - val_loss: 85.4417\n",
      "Epoch 242/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0107 - val_loss: 85.4392\n",
      "Epoch 243/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0100 - val_loss: 85.4357\n",
      "Epoch 244/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0088 - val_loss: 85.4342\n",
      "Epoch 245/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.0086 - val_loss: 85.4313\n",
      "Epoch 246/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.0076 - val_loss: 85.4301\n",
      "Epoch 247/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0070 - val_loss: 85.4286\n",
      "Epoch 248/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0066 - val_loss: 85.4274\n",
      "Epoch 249/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0064 - val_loss: 85.4254\n",
      "Epoch 250/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0060 - val_loss: 85.4241\n",
      "Epoch 251/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0057 - val_loss: 85.4226\n",
      "Epoch 252/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0055 - val_loss: 85.4217\n",
      "Epoch 253/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0052 - val_loss: 85.4210\n",
      "Epoch 254/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0052 - val_loss: 85.4198\n",
      "Epoch 255/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0048 - val_loss: 85.4193\n",
      "Epoch 256/2000\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 83.0048 - val_loss: 85.4187\n",
      "Epoch 257/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 83.0046 - val_loss: 85.4182\n",
      "Epoch 258/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0046 - val_loss: 85.4181\n",
      "Epoch 259/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0045 - val_loss: 85.4173\n",
      "Epoch 260/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0046 - val_loss: 85.4160\n",
      "Epoch 261/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.0045 - val_loss: 85.4162\n",
      "Epoch 262/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.0043 - val_loss: 85.4159\n",
      "Epoch 263/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0050 - val_loss: 85.4168\n",
      "Epoch 264/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0043 - val_loss: 85.4148\n",
      "Epoch 265/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0042 - val_loss: 85.4141\n",
      "Epoch 266/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.0049 - val_loss: 85.4155\n",
      "Epoch 267/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0050 - val_loss: 85.4131\n",
      "Epoch 268/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0043 - val_loss: 85.4143\n",
      "Epoch 269/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.0044 - val_loss: 85.4131\n",
      "Epoch 270/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0040 - val_loss: 85.4135\n",
      "Epoch 271/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0041 - val_loss: 85.4128\n",
      "Epoch 272/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0041 - val_loss: 85.4137\n",
      "Epoch 273/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0040 - val_loss: 85.4132\n",
      "Epoch 274/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0039 - val_loss: 85.4130\n",
      "Epoch 275/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0039 - val_loss: 85.4126\n",
      "Epoch 276/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0040 - val_loss: 85.4121\n",
      "Epoch 277/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0039 - val_loss: 85.4127\n",
      "Epoch 278/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.0043 - val_loss: 85.4116\n",
      "Epoch 279/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0038 - val_loss: 85.4120\n",
      "Epoch 280/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0038 - val_loss: 85.4120\n",
      "Epoch 281/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.0039 - val_loss: 85.4125\n",
      "Epoch 282/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0038 - val_loss: 85.4128\n",
      "Epoch 283/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0039 - val_loss: 85.4116\n",
      "Epoch 284/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0036 - val_loss: 85.4120\n",
      "Epoch 285/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0039 - val_loss: 85.4128\n",
      "Epoch 286/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0036 - val_loss: 85.4126\n",
      "Epoch 287/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0036 - val_loss: 85.4125\n",
      "Epoch 288/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0036 - val_loss: 85.4126\n",
      "Epoch 289/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0034 - val_loss: 85.4124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0034 - val_loss: 85.4121\n",
      "Epoch 291/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 83.0038 - val_loss: 85.4113\n",
      "Epoch 292/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.0034 - val_loss: 85.4112\n",
      "Epoch 293/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0039 - val_loss: 85.4122\n",
      "Epoch 294/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.0035 - val_loss: 85.4114\n",
      "Epoch 295/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0035 - val_loss: 85.4109\n",
      "Epoch 296/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0036 - val_loss: 85.4107\n",
      "Epoch 297/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0031 - val_loss: 85.4114\n",
      "Epoch 298/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0035 - val_loss: 85.4126\n",
      "Epoch 299/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0032 - val_loss: 85.4115\n",
      "Epoch 300/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0031 - val_loss: 85.4111\n",
      "Epoch 301/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0038 - val_loss: 85.4128\n",
      "Epoch 302/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0031 - val_loss: 85.4122\n",
      "Epoch 303/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0029 - val_loss: 85.4113\n",
      "Epoch 304/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0033 - val_loss: 85.4101\n",
      "Epoch 305/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0027 - val_loss: 85.4106\n",
      "Epoch 306/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0029 - val_loss: 85.4106\n",
      "Epoch 307/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0030 - val_loss: 85.4120\n",
      "Epoch 308/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0028 - val_loss: 85.4117\n",
      "Epoch 309/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0036 - val_loss: 85.4135\n",
      "Epoch 310/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.0027 - val_loss: 85.4114\n",
      "Epoch 311/2000\n",
      "20000/20000 [==============================] - 0s 12us/step - loss: 83.0024 - val_loss: 85.4119\n",
      "Epoch 312/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 83.0023 - val_loss: 85.4116\n",
      "Epoch 313/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.0023 - val_loss: 85.4116\n",
      "Epoch 314/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0020 - val_loss: 85.4122\n",
      "Epoch 315/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0028 - val_loss: 85.4143\n",
      "Epoch 316/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0018 - val_loss: 85.4122\n",
      "Epoch 317/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0015 - val_loss: 85.4125\n",
      "Epoch 318/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0016 - val_loss: 85.4111\n",
      "Epoch 319/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0016 - val_loss: 85.4138\n",
      "Epoch 320/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0009 - val_loss: 85.4125\n",
      "Epoch 321/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0006 - val_loss: 85.4134\n",
      "Epoch 322/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0001 - val_loss: 85.4133\n",
      "Epoch 323/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9997 - val_loss: 85.4128\n",
      "Epoch 324/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9996 - val_loss: 85.4143\n",
      "Epoch 325/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9990 - val_loss: 85.4131\n",
      "Epoch 326/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9992 - val_loss: 85.4146\n",
      "Epoch 327/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9985 - val_loss: 85.4135\n",
      "Epoch 328/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9983 - val_loss: 85.4130\n",
      "Epoch 329/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9986 - val_loss: 85.4138\n",
      "Epoch 330/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9987 - val_loss: 85.4129\n",
      "Epoch 331/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9982 - val_loss: 85.4133\n",
      "Epoch 332/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9982 - val_loss: 85.4137\n",
      "Epoch 333/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9982 - val_loss: 85.4137\n",
      "Epoch 334/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9983 - val_loss: 85.4150\n",
      "Epoch 335/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9986 - val_loss: 85.4151\n",
      "Epoch 336/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9981 - val_loss: 85.4133\n",
      "Epoch 337/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9981 - val_loss: 85.4136\n",
      "Epoch 338/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9989 - val_loss: 85.4123\n",
      "Epoch 339/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9985 - val_loss: 85.4142\n",
      "Epoch 340/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9982 - val_loss: 85.4131\n",
      "Epoch 341/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9984 - val_loss: 85.4114\n",
      "Epoch 342/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9982 - val_loss: 85.4124\n",
      "Epoch 343/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9983 - val_loss: 85.4131\n",
      "Epoch 344/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9983 - val_loss: 85.4132\n",
      "Epoch 345/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9980 - val_loss: 85.4128\n",
      "Epoch 346/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9978 - val_loss: 85.4134\n",
      "Epoch 347/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9978 - val_loss: 85.4132\n",
      "Epoch 348/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9979 - val_loss: 85.4122\n",
      "Epoch 349/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9980 - val_loss: 85.4125\n",
      "Epoch 350/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9977 - val_loss: 85.4121\n",
      "Epoch 351/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9979 - val_loss: 85.4119\n",
      "Epoch 352/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9978 - val_loss: 85.4126\n",
      "Epoch 353/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9979 - val_loss: 85.4125\n",
      "Epoch 354/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9976 - val_loss: 85.4132\n",
      "Epoch 355/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9983 - val_loss: 85.4123\n",
      "Epoch 356/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9984 - val_loss: 85.4136\n",
      "Epoch 357/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9975 - val_loss: 85.4114\n",
      "Epoch 358/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 82.9974 - val_loss: 85.4121\n",
      "Epoch 359/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9975 - val_loss: 85.4131\n",
      "Epoch 360/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9972 - val_loss: 85.4118\n",
      "Epoch 361/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9973 - val_loss: 85.4126\n",
      "Epoch 362/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9970 - val_loss: 85.4125\n",
      "Epoch 363/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9967 - val_loss: 85.4122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 364/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9967 - val_loss: 85.4107\n",
      "Epoch 365/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9967 - val_loss: 85.4127\n",
      "Epoch 366/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9961 - val_loss: 85.4115\n",
      "Epoch 367/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9958 - val_loss: 85.4145\n",
      "Epoch 368/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9942 - val_loss: 85.4114\n",
      "Epoch 369/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9924 - val_loss: 85.4124\n",
      "Epoch 370/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9928 - val_loss: 85.4139\n",
      "Epoch 371/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9924 - val_loss: 85.4140\n",
      "Epoch 372/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9923 - val_loss: 85.4126\n",
      "Epoch 373/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9922 - val_loss: 85.4120\n",
      "Epoch 374/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9927 - val_loss: 85.4140\n",
      "Epoch 375/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9921 - val_loss: 85.4121\n",
      "Epoch 376/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9921 - val_loss: 85.4121\n",
      "Epoch 377/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9921 - val_loss: 85.4108\n",
      "Epoch 378/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9954 - val_loss: 85.4151\n",
      "Epoch 379/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9920 - val_loss: 85.4125\n",
      "Epoch 380/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9924 - val_loss: 85.4126\n",
      "Epoch 381/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9923 - val_loss: 85.4113\n",
      "Epoch 382/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9927 - val_loss: 85.4085\n",
      "Epoch 383/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9924 - val_loss: 85.4093\n",
      "Epoch 384/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9919 - val_loss: 85.4102\n",
      "Epoch 385/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 82.9919 - val_loss: 85.4112\n",
      "Epoch 386/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 82.9928 - val_loss: 85.4116\n",
      "Epoch 387/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9923 - val_loss: 85.4137\n",
      "Epoch 388/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9920 - val_loss: 85.4117\n",
      "Epoch 389/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9921 - val_loss: 85.4109\n",
      "Epoch 390/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9921 - val_loss: 85.4127\n",
      "Epoch 391/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9924 - val_loss: 85.4099\n",
      "Epoch 392/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9920 - val_loss: 85.4096\n",
      "Epoch 393/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9918 - val_loss: 85.4106\n",
      "Epoch 394/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9921 - val_loss: 85.4111\n",
      "Epoch 395/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 82.9921 - val_loss: 85.4126\n",
      "Epoch 396/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9919 - val_loss: 85.4115\n",
      "Epoch 397/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9926 - val_loss: 85.4091\n",
      "Epoch 398/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9919 - val_loss: 85.4102\n",
      "Epoch 399/2000\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 82.9930 - val_loss: 85.4093\n",
      "Epoch 400/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 82.9916 - val_loss: 85.4109\n",
      "Epoch 401/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9920 - val_loss: 85.4106\n",
      "Epoch 402/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9918 - val_loss: 85.4116\n",
      "Epoch 403/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9918 - val_loss: 85.4117\n",
      "Epoch 404/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9921 - val_loss: 85.4091\n",
      "Epoch 405/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9925 - val_loss: 85.4114\n",
      "Epoch 406/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 82.9912 - val_loss: 85.4103\n",
      "Epoch 407/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9911 - val_loss: 85.4100\n",
      "Epoch 408/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9908 - val_loss: 85.4087\n",
      "Epoch 409/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9899 - val_loss: 85.4093\n",
      "Epoch 410/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9877 - val_loss: 85.4104\n",
      "Epoch 411/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9888 - val_loss: 85.4100\n",
      "Epoch 412/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9912 - val_loss: 85.4082\n",
      "Epoch 413/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9912 - val_loss: 85.4092\n",
      "Epoch 414/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9915 - val_loss: 85.4077\n",
      "Epoch 415/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9925 - val_loss: 85.4120\n",
      "Epoch 416/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9907 - val_loss: 85.4084\n",
      "Epoch 417/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9907 - val_loss: 85.4080\n",
      "Epoch 418/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9883 - val_loss: 85.4107\n",
      "Epoch 419/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9871 - val_loss: 85.4126\n",
      "Epoch 420/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9875 - val_loss: 85.4142\n",
      "Epoch 421/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9870 - val_loss: 85.4081\n",
      "Epoch 422/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9905 - val_loss: 85.4045\n",
      "Epoch 423/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9869 - val_loss: 85.4116\n",
      "Epoch 424/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9924 - val_loss: 85.4104\n",
      "Epoch 425/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9906 - val_loss: 85.4082\n",
      "Epoch 426/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9909 - val_loss: 85.4081\n",
      "Epoch 427/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9917 - val_loss: 85.4103\n",
      "Epoch 428/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9903 - val_loss: 85.4103\n",
      "Epoch 429/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9938 - val_loss: 85.4059\n",
      "Epoch 430/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9944 - val_loss: 85.4083\n",
      "Epoch 431/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9937 - val_loss: 85.4065\n",
      "Epoch 432/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9918 - val_loss: 85.4078\n",
      "Epoch 433/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9896 - val_loss: 85.4125\n",
      "Epoch 434/2000\n",
      "20000/20000 [==============================] - ETA: 0s - loss: 83.28 - 0s 16us/step - loss: 82.9876 - val_loss: 85.4124\n",
      "Epoch 435/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9854 - val_loss: 85.4165\n",
      "Epoch 436/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9847 - val_loss: 85.4108\n",
      "Epoch 437/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9864 - val_loss: 85.4100\n",
      "Epoch 438/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9842 - val_loss: 85.4158\n",
      "Epoch 439/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9811 - val_loss: 85.4121\n",
      "Epoch 440/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9812 - val_loss: 85.4129\n",
      "Epoch 441/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9814 - val_loss: 85.4117\n",
      "Epoch 442/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9831 - val_loss: 85.4098\n",
      "Epoch 443/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9807 - val_loss: 85.4148\n",
      "Epoch 444/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9834 - val_loss: 85.4169\n",
      "Epoch 445/2000\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 82.9821 - val_loss: 85.4130\n",
      "Epoch 446/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 82.9834 - val_loss: 85.4179\n",
      "Epoch 447/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9818 - val_loss: 85.4121\n",
      "Epoch 448/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9830 - val_loss: 85.4108\n",
      "Epoch 449/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9827 - val_loss: 85.4084\n",
      "Epoch 450/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9809 - val_loss: 85.4106\n",
      "Epoch 451/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9808 - val_loss: 85.4152\n",
      "Epoch 452/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9810 - val_loss: 85.4116\n",
      "Epoch 453/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9816 - val_loss: 85.4101\n",
      "Epoch 454/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9824 - val_loss: 85.4167\n",
      "Epoch 455/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9809 - val_loss: 85.4116\n",
      "Epoch 456/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9823 - val_loss: 85.4141\n",
      "Epoch 457/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9813 - val_loss: 85.4151\n",
      "Epoch 458/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9823 - val_loss: 85.4066\n",
      "Epoch 459/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9802 - val_loss: 85.4110\n",
      "Epoch 460/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9795 - val_loss: 85.4107\n",
      "Epoch 461/2000\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 82.9796 - val_loss: 85.4092\n",
      "Epoch 462/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 82.9791 - val_loss: 85.4104\n",
      "Epoch 463/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9797 - val_loss: 85.4079\n",
      "Epoch 464/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9842 - val_loss: 85.4173\n",
      "Epoch 465/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9799 - val_loss: 85.4078\n",
      "Epoch 466/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9807 - val_loss: 85.4076\n",
      "Epoch 467/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 82.9820 - val_loss: 85.4061\n",
      "Epoch 468/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9801 - val_loss: 85.4126\n",
      "Epoch 469/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9791 - val_loss: 85.4092\n",
      "Epoch 470/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9789 - val_loss: 85.4101\n",
      "Epoch 471/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9786 - val_loss: 85.4094\n",
      "Epoch 472/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9792 - val_loss: 85.4078\n",
      "Epoch 473/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9792 - val_loss: 85.4071\n",
      "Epoch 474/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9787 - val_loss: 85.4093\n",
      "Epoch 475/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9794 - val_loss: 85.4079\n",
      "Epoch 476/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9793 - val_loss: 85.4129\n",
      "Epoch 477/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9839 - val_loss: 85.4023\n",
      "Epoch 478/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9800 - val_loss: 85.4101\n",
      "Epoch 479/2000\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 82.9790 - val_loss: 85.4109\n",
      "Epoch 480/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 82.9771 - val_loss: 85.4084\n",
      "Epoch 481/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 82.9786 - val_loss: 85.4026\n",
      "Epoch 482/2000\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 82.9780 - val_loss: 85.4113\n",
      "Epoch 483/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9597 - val_loss: 85.0105\n",
      "Epoch 484/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 71.8643 - val_loss: 64.1404\n",
      "Epoch 485/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 49.9288 - val_loss: 40.7876\n",
      "Epoch 486/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 32.0279 - val_loss: 27.2164\n",
      "Epoch 487/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 21.6479 - val_loss: 18.9214\n",
      "Epoch 488/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 15.3202 - val_loss: 13.9040\n",
      "Epoch 489/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 11.4602 - val_loss: 10.8586\n",
      "Epoch 490/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 9.2001 - val_loss: 9.0624\n",
      "Epoch 491/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 7.8673 - val_loss: 8.0128\n",
      "Epoch 492/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 6.7462 - val_loss: 6.4170\n",
      "Epoch 493/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 5.3490 - val_loss: 5.3620\n",
      "Epoch 494/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 4.4549 - val_loss: 4.5290\n",
      "Epoch 495/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3.7832 - val_loss: 3.9222\n",
      "Epoch 496/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3.2619 - val_loss: 3.4748\n",
      "Epoch 497/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 2.8726 - val_loss: 3.1104\n",
      "Epoch 498/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 2.5642 - val_loss: 2.8509\n",
      "Epoch 499/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 2.3127 - val_loss: 2.6114\n",
      "Epoch 500/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 2.1087 - val_loss: 2.4207\n",
      "Epoch 501/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 1.9247 - val_loss: 2.2594\n",
      "Epoch 502/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1.7900 - val_loss: 2.1332\n",
      "Epoch 503/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 1.6599 - val_loss: 2.0361\n",
      "Epoch 504/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1.5409 - val_loss: 1.9508\n",
      "Epoch 505/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1.4560 - val_loss: 1.8694\n",
      "Epoch 506/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1.3722 - val_loss: 1.8053\n",
      "Epoch 507/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1.2973 - val_loss: 1.7422\n",
      "Epoch 508/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1.2356 - val_loss: 1.7151\n",
      "Epoch 509/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1.1799 - val_loss: 1.6817\n",
      "Epoch 510/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1.1262 - val_loss: 1.6346\n",
      "Epoch 511/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 16us/step - loss: 1.0887 - val_loss: 1.6153\n",
      "Epoch 512/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1.0407 - val_loss: 1.5953\n",
      "Epoch 513/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1.0073 - val_loss: 1.5855\n",
      "Epoch 514/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.9694 - val_loss: 1.5554\n",
      "Epoch 515/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.9410 - val_loss: 1.5425\n",
      "Epoch 516/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.9148 - val_loss: 1.5202\n",
      "Epoch 517/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.8946 - val_loss: 1.5168\n",
      "Epoch 518/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.8678 - val_loss: 1.4996\n",
      "Epoch 519/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.8382 - val_loss: 1.5061\n",
      "Epoch 520/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.8235 - val_loss: 1.4816\n",
      "Epoch 521/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.8045 - val_loss: 1.4850\n",
      "Epoch 522/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.7796 - val_loss: 1.4716\n",
      "Epoch 523/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.7571 - val_loss: 1.4611\n",
      "Epoch 524/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.7455 - val_loss: 1.4605\n",
      "Epoch 525/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.7245 - val_loss: 1.4559\n",
      "Epoch 526/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.7058 - val_loss: 1.4436\n",
      "Epoch 527/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.6887 - val_loss: 1.4316\n",
      "Epoch 528/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.6753 - val_loss: 1.4539\n",
      "Epoch 529/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.6638 - val_loss: 1.4234\n",
      "Epoch 530/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.6488 - val_loss: 1.4308\n",
      "Epoch 531/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.6357 - val_loss: 1.4226\n",
      "Epoch 532/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.6176 - val_loss: 1.4176\n",
      "Epoch 533/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.6025 - val_loss: 1.4127\n",
      "Epoch 534/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.5915 - val_loss: 1.4093\n",
      "Epoch 535/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.5812 - val_loss: 1.4086\n",
      "Epoch 536/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.5699 - val_loss: 1.4086\n",
      "Epoch 537/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.5585 - val_loss: 1.4216\n",
      "Epoch 538/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.5508 - val_loss: 1.4136\n",
      "Epoch 539/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.5434 - val_loss: 1.4129\n",
      "Epoch 540/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.5304 - val_loss: 1.4176\n",
      "Epoch 541/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.5242 - val_loss: 1.4252\n",
      "Epoch 542/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.5154 - val_loss: 1.4170\n",
      "Epoch 543/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.5058 - val_loss: 1.4169\n",
      "Epoch 544/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.5002 - val_loss: 1.4162\n",
      "Epoch 545/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4933 - val_loss: 1.4107\n",
      "Epoch 546/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4869 - val_loss: 1.4148\n",
      "Epoch 547/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4767 - val_loss: 1.4062\n",
      "Epoch 548/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4726 - val_loss: 1.4076\n",
      "Epoch 549/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4668 - val_loss: 1.4201\n",
      "Epoch 550/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.4602 - val_loss: 1.4219\n",
      "Epoch 551/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4573 - val_loss: 1.4250\n",
      "Epoch 552/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4516 - val_loss: 1.4190\n",
      "Epoch 553/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4449 - val_loss: 1.4292\n",
      "Epoch 554/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4394 - val_loss: 1.4240\n",
      "Epoch 555/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4346 - val_loss: 1.4308\n",
      "Epoch 556/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4316 - val_loss: 1.4303\n",
      "Epoch 557/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4284 - val_loss: 1.4393\n",
      "Epoch 558/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4239 - val_loss: 1.4211\n",
      "Epoch 559/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4180 - val_loss: 1.4414\n",
      "Epoch 560/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4144 - val_loss: 1.4505\n",
      "Epoch 561/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4104 - val_loss: 1.4518\n",
      "Epoch 562/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4022 - val_loss: 1.4478\n",
      "Epoch 563/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4032 - val_loss: 1.4476\n",
      "Epoch 564/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3989 - val_loss: 1.4623\n",
      "Epoch 565/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3934 - val_loss: 1.4713\n",
      "Epoch 566/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3903 - val_loss: 1.4732\n",
      "Epoch 567/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.3847 - val_loss: 1.4730\n",
      "Epoch 568/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3809 - val_loss: 1.4825\n",
      "Epoch 569/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3777 - val_loss: 1.4852\n",
      "Epoch 570/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.3729 - val_loss: 1.4923\n",
      "Epoch 571/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3713 - val_loss: 1.4964\n",
      "Epoch 572/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3686 - val_loss: 1.5038\n",
      "Epoch 573/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3691 - val_loss: 1.5108\n",
      "Epoch 574/2000\n",
      "20000/20000 [==============================] - 0s 12us/step - loss: 0.3634 - val_loss: 1.5200\n",
      "Epoch 575/2000\n",
      "20000/20000 [==============================] - 0s 12us/step - loss: 0.3599 - val_loss: 1.5187\n",
      "Epoch 576/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.3580 - val_loss: 1.5266\n",
      "Epoch 577/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3550 - val_loss: 1.5346\n",
      "Epoch 578/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3509 - val_loss: 1.5452\n",
      "Epoch 579/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3483 - val_loss: 1.5617\n",
      "Epoch 580/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3461 - val_loss: 1.5570\n",
      "Epoch 581/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3426 - val_loss: 1.5627\n",
      "Epoch 582/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.3408 - val_loss: 1.5788\n",
      "Epoch 583/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3354 - val_loss: 1.5789\n",
      "Epoch 584/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3311 - val_loss: 1.5920\n",
      "Epoch 585/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3312 - val_loss: 1.5962\n",
      "Epoch 586/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3260 - val_loss: 1.5928\n",
      "Epoch 587/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3253 - val_loss: 1.6191\n",
      "Epoch 588/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3251 - val_loss: 1.6114\n",
      "Epoch 589/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3187 - val_loss: 1.6327\n",
      "Epoch 590/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3196 - val_loss: 1.6337\n",
      "Epoch 591/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3164 - val_loss: 1.6337\n",
      "Epoch 592/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3178 - val_loss: 1.6347\n",
      "Epoch 593/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3113 - val_loss: 1.6625\n",
      "Epoch 594/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.3101 - val_loss: 1.6510\n",
      "Epoch 595/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.3076 - val_loss: 1.6539\n",
      "Epoch 596/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.3067 - val_loss: 1.6841\n",
      "Epoch 597/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.3020 - val_loss: 1.6849\n",
      "Epoch 598/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.3018 - val_loss: 1.6710\n",
      "Epoch 599/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2996 - val_loss: 1.6898\n",
      "Epoch 600/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2960 - val_loss: 1.6906\n",
      "Epoch 601/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2947 - val_loss: 1.6836\n",
      "Epoch 602/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2922 - val_loss: 1.6949\n",
      "Epoch 603/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2920 - val_loss: 1.7023\n",
      "Epoch 604/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2888 - val_loss: 1.7167\n",
      "Epoch 605/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2867 - val_loss: 1.7285\n",
      "Epoch 606/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2856 - val_loss: 1.7205\n",
      "Epoch 607/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2834 - val_loss: 1.7353\n",
      "Epoch 608/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2838 - val_loss: 1.7289\n",
      "Epoch 609/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2788 - val_loss: 1.7476\n",
      "Epoch 610/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2791 - val_loss: 1.7418\n",
      "Epoch 611/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2771 - val_loss: 1.7542\n",
      "Epoch 612/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2780 - val_loss: 1.7651\n",
      "Epoch 613/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2756 - val_loss: 1.7836\n",
      "Epoch 614/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2730 - val_loss: 1.7761\n",
      "Epoch 615/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2700 - val_loss: 1.7835\n",
      "Epoch 616/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2690 - val_loss: 1.7891\n",
      "Epoch 617/2000\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 0.2669 - val_loss: 1.7846\n",
      "Epoch 618/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2646 - val_loss: 1.7987\n",
      "Epoch 619/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2623 - val_loss: 1.7861\n",
      "Epoch 620/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2610 - val_loss: 1.8150\n",
      "Epoch 621/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2593 - val_loss: 1.8049\n",
      "Epoch 622/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2586 - val_loss: 1.8353\n",
      "Epoch 623/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2573 - val_loss: 1.8101\n",
      "Epoch 624/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2581 - val_loss: 1.8332\n",
      "Epoch 625/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2556 - val_loss: 1.8130\n",
      "Epoch 626/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2533 - val_loss: 1.8511\n",
      "Epoch 627/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2522 - val_loss: 1.8256\n",
      "Epoch 628/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2536 - val_loss: 1.8607\n",
      "Epoch 629/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2496 - val_loss: 1.8574\n",
      "Epoch 630/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2489 - val_loss: 1.8526\n",
      "Epoch 631/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2464 - val_loss: 1.9023\n",
      "Epoch 632/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2448 - val_loss: 1.8038\n",
      "Epoch 633/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2411 - val_loss: 1.7959\n",
      "Epoch 634/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2414 - val_loss: 1.8292\n",
      "Epoch 635/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2394 - val_loss: 1.8312\n",
      "Epoch 636/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2392 - val_loss: 1.8405\n",
      "Epoch 637/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2362 - val_loss: 1.8619\n",
      "Epoch 638/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2381 - val_loss: 1.8577\n",
      "Epoch 639/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2364 - val_loss: 1.8718\n",
      "Epoch 640/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2345 - val_loss: 1.8620\n",
      "Epoch 641/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2325 - val_loss: 1.8851\n",
      "Epoch 642/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2328 - val_loss: 1.8556\n",
      "Epoch 643/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2329 - val_loss: 1.9030\n",
      "Epoch 644/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2314 - val_loss: 1.8856\n",
      "Epoch 645/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2273 - val_loss: 1.8851\n",
      "Epoch 646/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2263 - val_loss: 1.9020\n",
      "Epoch 647/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2227 - val_loss: 1.8949\n",
      "Epoch 648/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2243 - val_loss: 1.9063\n",
      "Epoch 649/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2206 - val_loss: 1.9330\n",
      "Epoch 650/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2195 - val_loss: 1.8786\n",
      "Epoch 651/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2207 - val_loss: 1.9093\n",
      "Epoch 652/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2177 - val_loss: 1.9285\n",
      "Epoch 653/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2173 - val_loss: 1.9145\n",
      "Epoch 654/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2170 - val_loss: 1.9267\n",
      "Epoch 655/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2135 - val_loss: 1.9360\n",
      "Epoch 656/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2117 - val_loss: 1.9560\n",
      "Epoch 657/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2123 - val_loss: 1.9598\n",
      "Epoch 658/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2122 - val_loss: 1.9718\n",
      "Epoch 659/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2093 - val_loss: 1.9706\n",
      "Epoch 660/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2081 - val_loss: 1.9719\n",
      "Epoch 661/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2065 - val_loss: 1.9813\n",
      "Epoch 662/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2042 - val_loss: 1.9784\n",
      "Epoch 663/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2048 - val_loss: 1.9987\n",
      "Epoch 664/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2026 - val_loss: 1.9989\n",
      "Epoch 665/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2032 - val_loss: 2.0106\n",
      "Epoch 666/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2042 - val_loss: 2.0105\n",
      "Epoch 667/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2057 - val_loss: 2.0151\n",
      "Epoch 668/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2030 - val_loss: 2.0156\n",
      "Epoch 669/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.2019 - val_loss: 2.0304\n",
      "Epoch 670/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.1998 - val_loss: 2.0226\n",
      "Epoch 671/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1989 - val_loss: 2.0399\n",
      "Epoch 672/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1961 - val_loss: 2.0499\n",
      "Epoch 673/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1953 - val_loss: 2.0457\n",
      "Epoch 674/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1944 - val_loss: 2.0483\n",
      "Epoch 675/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1957 - val_loss: 2.0632\n",
      "Epoch 676/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1950 - val_loss: 2.0568\n",
      "Epoch 677/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1944 - val_loss: 2.0573\n",
      "Epoch 678/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1960 - val_loss: 2.0666\n",
      "Epoch 679/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1934 - val_loss: 2.0775\n",
      "Epoch 680/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1911 - val_loss: 2.0894\n",
      "Epoch 681/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1921 - val_loss: 2.0788\n",
      "Epoch 682/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1933 - val_loss: 2.0921\n",
      "Epoch 683/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1939 - val_loss: 2.0918\n",
      "Epoch 684/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1901 - val_loss: 2.0887\n",
      "Epoch 685/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1923 - val_loss: 2.0884\n",
      "Epoch 686/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1887 - val_loss: 2.0999\n",
      "Epoch 687/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1908 - val_loss: 2.0952\n",
      "Epoch 688/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1887 - val_loss: 2.1116\n",
      "Epoch 689/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.1899 - val_loss: 2.1120\n",
      "Epoch 690/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1877 - val_loss: 2.0999\n",
      "Epoch 691/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1894 - val_loss: 2.1283\n",
      "Epoch 692/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1871 - val_loss: 2.1239\n",
      "Epoch 693/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1861 - val_loss: 2.1389\n",
      "Epoch 694/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1847 - val_loss: 2.1218\n",
      "Epoch 695/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1808 - val_loss: 2.1201\n",
      "Epoch 696/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1789 - val_loss: 2.1727\n",
      "Epoch 697/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1801 - val_loss: 2.1025\n",
      "Epoch 698/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1797 - val_loss: 2.0893\n",
      "Epoch 699/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1794 - val_loss: 2.1185\n",
      "Epoch 700/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1784 - val_loss: 2.1299\n",
      "Epoch 701/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1780 - val_loss: 2.0973\n",
      "Epoch 702/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1769 - val_loss: 2.1131\n",
      "Epoch 703/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1794 - val_loss: 2.0975\n",
      "Epoch 704/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1793 - val_loss: 2.1023\n",
      "Epoch 705/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1745 - val_loss: 2.1101\n",
      "Epoch 706/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1738 - val_loss: 2.1108\n",
      "Epoch 707/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1759 - val_loss: 2.1107\n",
      "Epoch 708/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1777 - val_loss: 2.1046\n",
      "Epoch 709/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1770 - val_loss: 2.1161\n",
      "Epoch 710/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1748 - val_loss: 2.1134\n",
      "Epoch 711/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1746 - val_loss: 2.1134\n",
      "Epoch 712/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1719 - val_loss: 2.1141\n",
      "Epoch 713/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1738 - val_loss: 2.1052\n",
      "Epoch 714/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1724 - val_loss: 2.1085\n",
      "Epoch 715/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1693 - val_loss: 2.1038\n",
      "Epoch 716/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1703 - val_loss: 2.1152\n",
      "Epoch 717/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1704 - val_loss: 2.0967\n",
      "Epoch 718/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1698 - val_loss: 2.1141\n",
      "Epoch 719/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1688 - val_loss: 2.0964\n",
      "Epoch 720/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1659 - val_loss: 2.0940\n",
      "Epoch 721/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1650 - val_loss: 2.0684\n",
      "Epoch 722/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1642 - val_loss: 2.0752\n",
      "Epoch 723/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1664 - val_loss: 2.0963\n",
      "Epoch 724/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1690 - val_loss: 2.0824\n",
      "Epoch 725/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1669 - val_loss: 2.0796\n",
      "Epoch 726/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1632 - val_loss: 2.0872\n",
      "Epoch 727/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1648 - val_loss: 2.0843\n",
      "Epoch 728/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1632 - val_loss: 2.0835\n",
      "Epoch 729/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1620 - val_loss: 2.0789\n",
      "Epoch 730/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1612 - val_loss: 2.0796\n",
      "Epoch 731/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1607 - val_loss: 2.0785\n",
      "Epoch 732/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1607 - val_loss: 2.0794\n",
      "Epoch 733/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1585 - val_loss: 2.0821\n",
      "Epoch 734/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1615 - val_loss: 2.0517\n",
      "Epoch 735/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1647 - val_loss: 2.0931\n",
      "Epoch 736/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1605 - val_loss: 2.0767\n",
      "Epoch 737/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1603 - val_loss: 2.0934\n",
      "Epoch 738/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1594 - val_loss: 2.0834\n",
      "Epoch 739/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1594 - val_loss: 2.0893\n",
      "Epoch 740/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1602 - val_loss: 2.0684\n",
      "Epoch 741/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1598 - val_loss: 2.0841\n",
      "Epoch 742/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1599 - val_loss: 2.0828\n",
      "Epoch 743/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1669 - val_loss: 2.0750\n",
      "Epoch 744/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1658 - val_loss: 2.0828\n",
      "Epoch 745/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1642 - val_loss: 2.0844\n",
      "Epoch 746/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1685 - val_loss: 2.0744\n",
      "Epoch 747/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1619 - val_loss: 2.0867\n",
      "Epoch 748/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1607 - val_loss: 2.0712\n",
      "Epoch 749/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1577 - val_loss: 2.0847\n",
      "Epoch 750/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1574 - val_loss: 2.0704\n",
      "Epoch 751/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1556 - val_loss: 2.0853\n",
      "Epoch 752/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1544 - val_loss: 2.0643\n",
      "Epoch 753/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1530 - val_loss: 2.0674\n",
      "Epoch 754/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1530 - val_loss: 2.0614\n",
      "Epoch 755/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1520 - val_loss: 2.0773\n",
      "Epoch 756/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1510 - val_loss: 2.0963\n",
      "Epoch 757/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1508 - val_loss: 2.0473\n",
      "Epoch 758/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1502 - val_loss: 2.0753\n",
      "Epoch 759/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1518 - val_loss: 2.0355\n",
      "Epoch 760/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1508 - val_loss: 2.0702\n",
      "Epoch 761/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1498 - val_loss: 2.0501\n",
      "Epoch 762/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1494 - val_loss: 2.0783\n",
      "Epoch 763/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.1500 - val_loss: 2.0644\n",
      "Epoch 764/2000\n",
      "20000/20000 [==============================] - 0s 12us/step - loss: 0.1488 - val_loss: 2.0792\n",
      "Epoch 765/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1476 - val_loss: 2.0652\n",
      "Epoch 766/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1479 - val_loss: 2.0750\n",
      "Epoch 767/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1496 - val_loss: 2.0644\n",
      "Epoch 768/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1482 - val_loss: 2.0553\n",
      "Epoch 769/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1472 - val_loss: 2.0625\n",
      "Epoch 770/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1454 - val_loss: 2.0466\n",
      "Epoch 771/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1473 - val_loss: 2.0632\n",
      "Epoch 772/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1467 - val_loss: 2.0571\n",
      "Epoch 773/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1443 - val_loss: 2.0754\n",
      "Epoch 774/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1436 - val_loss: 2.0490\n",
      "Epoch 775/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1446 - val_loss: 2.0562\n",
      "Epoch 776/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1460 - val_loss: 2.0762\n",
      "Epoch 777/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1464 - val_loss: 2.0289\n",
      "Epoch 778/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1458 - val_loss: 2.0687\n",
      "Epoch 779/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1460 - val_loss: 2.0414\n",
      "Epoch 780/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1451 - val_loss: 2.0615\n",
      "Epoch 781/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1427 - val_loss: 2.0570\n",
      "Epoch 782/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1418 - val_loss: 2.0428\n",
      "Epoch 783/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1402 - val_loss: 2.0331\n",
      "Epoch 784/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.1385 - val_loss: 2.0596\n",
      "Epoch 785/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1395 - val_loss: 2.0419\n",
      "Epoch 786/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1397 - val_loss: 2.0535\n",
      "Epoch 787/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1434 - val_loss: 2.0658\n",
      "Epoch 788/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1458 - val_loss: 2.0489\n",
      "Epoch 789/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1434 - val_loss: 2.0470\n",
      "Epoch 790/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1454 - val_loss: 2.0727\n",
      "Epoch 791/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1476 - val_loss: 2.0280\n",
      "Epoch 792/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1443 - val_loss: 2.0504\n",
      "Epoch 793/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1417 - val_loss: 2.0468\n",
      "Epoch 794/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.1418 - val_loss: 2.0455\n",
      "Epoch 795/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1410 - val_loss: 2.0546\n",
      "Epoch 796/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1419 - val_loss: 2.0544\n",
      "Epoch 797/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1414 - val_loss: 2.0576\n",
      "Epoch 798/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1420 - val_loss: 2.0538\n",
      "Epoch 799/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1417 - val_loss: 2.0568\n",
      "Epoch 800/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1410 - val_loss: 2.0565\n",
      "Epoch 801/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1393 - val_loss: 2.0466\n",
      "Epoch 802/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1394 - val_loss: 2.0561\n",
      "Epoch 803/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1373 - val_loss: 2.0628\n",
      "Epoch 804/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1387 - val_loss: 2.0535\n",
      "Epoch 805/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1410 - val_loss: 2.0563\n",
      "Epoch 806/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1388 - val_loss: 2.0683\n",
      "Epoch 807/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.1390 - val_loss: 2.0471\n",
      "Epoch 808/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1369 - val_loss: 2.0584\n",
      "Epoch 809/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1366 - val_loss: 2.0331\n",
      "Epoch 810/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1362 - val_loss: 2.0456\n",
      "Epoch 811/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1356 - val_loss: 2.0448\n",
      "Epoch 812/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1343 - val_loss: 2.0351\n",
      "Epoch 813/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1342 - val_loss: 2.0476\n",
      "Epoch 814/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1364 - val_loss: 2.0421\n",
      "Epoch 815/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1364 - val_loss: 2.0363\n",
      "Epoch 816/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1373 - val_loss: 2.0361\n",
      "Epoch 817/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1347 - val_loss: 2.0377\n",
      "Epoch 818/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1338 - val_loss: 2.0281\n",
      "Epoch 819/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1342 - val_loss: 2.0454\n",
      "Epoch 820/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1342 - val_loss: 2.0300\n",
      "Epoch 821/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1358 - val_loss: 2.0354\n",
      "Epoch 822/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1368 - val_loss: 2.0378\n",
      "Epoch 823/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1380 - val_loss: 2.0376\n",
      "Epoch 824/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1367 - val_loss: 2.0489\n",
      "Epoch 825/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1390 - val_loss: 2.0411\n",
      "Epoch 826/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1358 - val_loss: 2.0649\n",
      "Epoch 827/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1346 - val_loss: 2.0433\n",
      "Epoch 828/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1335 - val_loss: 2.0587\n",
      "Epoch 829/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1307 - val_loss: 2.0592\n",
      "Epoch 830/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1328 - val_loss: 2.0473\n",
      "Epoch 831/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1343 - val_loss: 2.0488\n",
      "Epoch 832/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1338 - val_loss: 2.0425\n",
      "Epoch 833/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1362 - val_loss: 2.0502\n",
      "Epoch 834/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1372 - val_loss: 2.0332\n",
      "Epoch 835/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1366 - val_loss: 2.0388\n",
      "Epoch 836/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1333 - val_loss: 2.0384\n",
      "Epoch 837/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1337 - val_loss: 2.0444\n",
      "Epoch 838/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1329 - val_loss: 2.0572\n",
      "Epoch 839/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1347 - val_loss: 2.0413\n",
      "Epoch 840/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1348 - val_loss: 2.0547\n",
      "Epoch 841/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1314 - val_loss: 2.0546\n",
      "Epoch 842/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1308 - val_loss: 2.0638\n",
      "Epoch 843/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1290 - val_loss: 2.0552\n",
      "Epoch 844/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1297 - val_loss: 2.0551\n",
      "Epoch 845/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.1297 - val_loss: 2.0684\n",
      "Epoch 846/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1268 - val_loss: 2.0639\n",
      "Epoch 847/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1265 - val_loss: 2.0564\n",
      "Epoch 848/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1286 - val_loss: 2.0526\n",
      "Epoch 849/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.1289 - val_loss: 2.0578\n",
      "Epoch 850/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1264 - val_loss: 2.0531\n",
      "Epoch 851/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1263 - val_loss: 2.0544\n",
      "Epoch 852/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1277 - val_loss: 2.0724\n",
      "Epoch 853/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1291 - val_loss: 2.0606\n",
      "Epoch 854/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.1293 - val_loss: 2.0789\n",
      "Epoch 855/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1278 - val_loss: 2.0687\n",
      "Epoch 856/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1243 - val_loss: 2.0666\n",
      "Epoch 857/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1249 - val_loss: 2.0584\n",
      "Epoch 858/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.1233 - val_loss: 2.0637\n",
      "Epoch 859/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.1234 - val_loss: 2.0515\n",
      "Epoch 860/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1221 - val_loss: 2.0578\n",
      "Epoch 861/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1233 - val_loss: 2.0521\n",
      "Epoch 862/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1232 - val_loss: 2.0505\n",
      "Epoch 863/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1209 - val_loss: 2.0426\n",
      "Epoch 864/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1223 - val_loss: 2.0464\n",
      "Epoch 865/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1243 - val_loss: 2.0585\n",
      "Epoch 866/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1260 - val_loss: 2.0749\n",
      "Epoch 867/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1260 - val_loss: 2.0696\n",
      "Epoch 868/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1254 - val_loss: 2.0570\n",
      "Epoch 869/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1241 - val_loss: 2.0637\n",
      "Epoch 870/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1241 - val_loss: 2.0446\n",
      "Epoch 871/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1265 - val_loss: 2.0649\n",
      "Epoch 872/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1253 - val_loss: 2.0529\n",
      "Epoch 873/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1250 - val_loss: 2.0751\n",
      "Epoch 874/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1258 - val_loss: 2.0472\n",
      "Epoch 875/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1265 - val_loss: 2.0409\n",
      "Epoch 876/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1272 - val_loss: 2.0955\n",
      "Epoch 877/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1285 - val_loss: 1.9646\n",
      "Epoch 878/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.1278 - val_loss: 1.9504\n",
      "Epoch 879/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.1260 - val_loss: 1.9647\n",
      "Epoch 880/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.1249 - val_loss: 1.9788\n",
      "Epoch 881/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1240 - val_loss: 1.9660\n",
      "Epoch 882/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1230 - val_loss: 1.9796\n",
      "Epoch 883/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1221 - val_loss: 1.9849\n",
      "Epoch 884/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1213 - val_loss: 1.9819\n",
      "Epoch 885/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1234 - val_loss: 1.9774\n",
      "Epoch 886/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1215 - val_loss: 1.9899\n",
      "Epoch 887/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1198 - val_loss: 1.9767\n",
      "Epoch 888/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1193 - val_loss: 1.9869\n",
      "Epoch 889/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1204 - val_loss: 1.9906\n",
      "Epoch 890/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1266 - val_loss: 1.9784\n",
      "Epoch 891/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1243 - val_loss: 1.9748\n",
      "Epoch 892/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1215 - val_loss: 1.9798\n",
      "Epoch 893/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1191 - val_loss: 1.9789\n",
      "Epoch 894/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1206 - val_loss: 1.9952\n",
      "Epoch 895/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1218 - val_loss: 1.9863\n",
      "Epoch 896/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1224 - val_loss: 1.9893\n",
      "Epoch 897/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1218 - val_loss: 1.9793\n",
      "Epoch 898/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1190 - val_loss: 1.9844\n",
      "Epoch 899/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1207 - val_loss: 1.9864\n",
      "Epoch 900/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1263 - val_loss: 2.0010\n",
      "Epoch 901/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1283 - val_loss: 2.0106\n",
      "Epoch 902/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1193 - val_loss: 2.0007\n",
      "Epoch 903/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1194 - val_loss: 2.0056\n",
      "Epoch 904/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1167 - val_loss: 2.0025\n",
      "Epoch 905/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1169 - val_loss: 2.0001\n",
      "Epoch 906/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1181 - val_loss: 2.0172\n",
      "Epoch 907/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1186 - val_loss: 2.0029\n",
      "Epoch 908/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1193 - val_loss: 2.0044\n",
      "Epoch 909/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1199 - val_loss: 2.0137\n",
      "Epoch 910/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1158 - val_loss: 2.0120\n",
      "Epoch 911/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1167 - val_loss: 2.0264\n",
      "Epoch 912/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1185 - val_loss: 2.0284\n",
      "Epoch 913/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1207 - val_loss: 2.0344\n",
      "Epoch 914/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1206 - val_loss: 2.0324\n",
      "Epoch 915/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1217 - val_loss: 2.0230\n",
      "Epoch 916/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1220 - val_loss: 2.0405\n",
      "Epoch 917/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1172 - val_loss: 2.0278\n",
      "Epoch 918/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1166 - val_loss: 2.0429\n",
      "Epoch 919/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1140 - val_loss: 2.0344\n",
      "Epoch 920/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1241 - val_loss: 2.0535\n",
      "Epoch 921/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1165 - val_loss: 2.0424\n",
      "Epoch 922/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1178 - val_loss: 2.0353\n",
      "Epoch 923/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1210 - val_loss: 2.0540\n",
      "Epoch 924/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1186 - val_loss: 2.0348\n",
      "Epoch 925/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1254 - val_loss: 2.0610\n",
      "Epoch 926/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1213 - val_loss: 2.0552\n",
      "Epoch 927/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1204 - val_loss: 2.0437\n",
      "Epoch 928/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1181 - val_loss: 2.0338\n",
      "Epoch 929/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1155 - val_loss: 2.0500\n",
      "Epoch 930/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1168 - val_loss: 2.0458\n",
      "Epoch 931/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1178 - val_loss: 2.0462\n",
      "Epoch 932/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1195 - val_loss: 2.0710\n",
      "Epoch 933/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1225 - val_loss: 2.0524\n",
      "Epoch 934/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1219 - val_loss: 2.0648\n",
      "Epoch 935/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1179 - val_loss: 2.0757\n",
      "Epoch 936/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1174 - val_loss: 2.0907\n",
      "Epoch 937/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1184 - val_loss: 2.0548\n",
      "Epoch 938/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1168 - val_loss: 2.0792\n",
      "Epoch 939/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1180 - val_loss: 2.0516\n",
      "Epoch 940/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1134 - val_loss: 2.0673\n",
      "Epoch 941/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1113 - val_loss: 2.0638\n",
      "Epoch 942/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1107 - val_loss: 2.0597\n",
      "Epoch 943/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1129 - val_loss: 2.0713\n",
      "Epoch 944/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1083 - val_loss: 2.0670\n",
      "Epoch 945/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1101 - val_loss: 2.0691\n",
      "Epoch 946/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1092 - val_loss: 2.0701\n",
      "Epoch 947/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1080 - val_loss: 2.0608\n",
      "Epoch 948/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1085 - val_loss: 2.0679\n",
      "Epoch 949/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1071 - val_loss: 2.0486\n",
      "Epoch 950/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1071 - val_loss: 2.0684\n",
      "Epoch 951/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1075 - val_loss: 2.0753\n",
      "Epoch 952/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1081 - val_loss: 2.0767\n",
      "Epoch 953/2000\n",
      "20000/20000 [==============================] - 0s 12us/step - loss: 0.1059 - val_loss: 2.0907\n",
      "Epoch 954/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.1097 - val_loss: 2.0991\n",
      "Epoch 955/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1168 - val_loss: 2.0859\n",
      "Epoch 956/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1176 - val_loss: 2.0957\n",
      "Epoch 957/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1226 - val_loss: 2.1072\n",
      "Epoch 958/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1207 - val_loss: 2.0939\n",
      "Epoch 959/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1118 - val_loss: 2.1140\n",
      "Epoch 960/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1113 - val_loss: 2.1107\n",
      "Epoch 961/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1092 - val_loss: 2.1060\n",
      "Epoch 962/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1084 - val_loss: 2.1084\n",
      "Epoch 963/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1069 - val_loss: 2.1245\n",
      "Epoch 964/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1066 - val_loss: 2.1391\n",
      "Epoch 965/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1072 - val_loss: 2.1204\n",
      "Epoch 966/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1096 - val_loss: 2.1247\n",
      "Epoch 967/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1050 - val_loss: 2.0857\n",
      "Epoch 968/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1036 - val_loss: 2.0994\n",
      "Epoch 969/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1041 - val_loss: 2.1018\n",
      "Epoch 970/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1057 - val_loss: 2.0835\n",
      "Epoch 971/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1070 - val_loss: 2.0945\n",
      "Epoch 972/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1045 - val_loss: 2.0941\n",
      "Epoch 973/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.1051 - val_loss: 2.1041\n",
      "Epoch 974/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.1054 - val_loss: 2.0974\n",
      "Epoch 975/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1086 - val_loss: 2.0976\n",
      "Epoch 976/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1066 - val_loss: 2.0884\n",
      "Epoch 977/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1082 - val_loss: 2.1163\n",
      "Epoch 978/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1071 - val_loss: 2.0989\n",
      "Epoch 979/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1080 - val_loss: 2.1020\n",
      "Epoch 980/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1044 - val_loss: 2.0907\n",
      "Epoch 981/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1052 - val_loss: 2.1083\n",
      "Epoch 982/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1060 - val_loss: 2.1015\n",
      "Epoch 983/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1020 - val_loss: 2.0879\n",
      "Epoch 984/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1019 - val_loss: 2.1033\n",
      "Epoch 985/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1032 - val_loss: 2.1085\n",
      "Epoch 986/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1017 - val_loss: 2.0861\n",
      "Epoch 987/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1017 - val_loss: 2.0905\n",
      "Epoch 988/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1024 - val_loss: 2.1054\n",
      "Epoch 989/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1048 - val_loss: 2.0909\n",
      "Epoch 990/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1069 - val_loss: 2.0906\n",
      "Epoch 991/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1040 - val_loss: 2.0823\n",
      "Epoch 992/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1017 - val_loss: 2.0931\n",
      "Epoch 993/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1068 - val_loss: 2.0708\n",
      "Epoch 994/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1034 - val_loss: 2.0730\n",
      "Epoch 995/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1013 - val_loss: 2.0817\n",
      "Epoch 996/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0988 - val_loss: 2.0645\n",
      "Epoch 997/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1013 - val_loss: 2.0951\n",
      "Epoch 998/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0991 - val_loss: 2.0603\n",
      "Epoch 999/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0968 - val_loss: 2.0701\n",
      "Epoch 1000/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0951 - val_loss: 2.0818\n",
      "Epoch 1001/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0956 - val_loss: 2.0761\n",
      "Epoch 1002/2000\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 0.0938 - val_loss: 2.0731\n",
      "Epoch 1003/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0991 - val_loss: 2.0931\n",
      "Epoch 1004/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0998 - val_loss: 2.0847\n",
      "Epoch 1005/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1000 - val_loss: 2.0843\n",
      "Epoch 1006/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0991 - val_loss: 2.0826\n",
      "Epoch 1007/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0965 - val_loss: 2.0636\n",
      "Epoch 1008/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0951 - val_loss: 2.0847\n",
      "Epoch 1009/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0946 - val_loss: 2.0820\n",
      "Epoch 1010/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0942 - val_loss: 2.0752\n",
      "Epoch 1011/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0940 - val_loss: 2.0954\n",
      "Epoch 1012/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0967 - val_loss: 2.0937\n",
      "Epoch 1013/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0941 - val_loss: 2.0766\n",
      "Epoch 1014/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0950 - val_loss: 2.0597\n",
      "Epoch 1015/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0928 - val_loss: 2.0800\n",
      "Epoch 1016/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0932 - val_loss: 2.0806\n",
      "Epoch 1017/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0934 - val_loss: 2.0757\n",
      "Epoch 1018/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0917 - val_loss: 2.0825\n",
      "Epoch 1019/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0943 - val_loss: 2.1041\n",
      "Epoch 1020/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0962 - val_loss: 2.0802\n",
      "Epoch 1021/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0941 - val_loss: 2.0815\n",
      "Epoch 1022/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0918 - val_loss: 2.0713\n",
      "Epoch 1023/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0942 - val_loss: 2.0770\n",
      "Epoch 1024/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0927 - val_loss: 2.0907\n",
      "Epoch 1025/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0918 - val_loss: 2.0658\n",
      "Epoch 1026/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0922 - val_loss: 2.0637\n",
      "Epoch 1027/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0949 - val_loss: 2.0607\n",
      "Epoch 1028/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0963 - val_loss: 2.0678\n",
      "Epoch 1029/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0942 - val_loss: 2.0887\n",
      "Epoch 1030/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0927 - val_loss: 2.0710\n",
      "Epoch 1031/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0904 - val_loss: 2.1156\n",
      "Epoch 1032/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0917 - val_loss: 2.0181\n",
      "Epoch 1033/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0914 - val_loss: 2.0241\n",
      "Epoch 1034/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0898 - val_loss: 2.0463\n",
      "Epoch 1035/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0918 - val_loss: 2.0430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1036/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0916 - val_loss: 2.0389\n",
      "Epoch 1037/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0904 - val_loss: 2.0259\n",
      "Epoch 1038/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0902 - val_loss: 2.0516\n",
      "Epoch 1039/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0886 - val_loss: 2.0418\n",
      "Epoch 1040/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0888 - val_loss: 2.0226\n",
      "Epoch 1041/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0894 - val_loss: 2.0321\n",
      "Epoch 1042/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0894 - val_loss: 2.0672\n",
      "Epoch 1043/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0907 - val_loss: 2.0429\n",
      "Epoch 1044/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0896 - val_loss: 2.0426\n",
      "Epoch 1045/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0912 - val_loss: 2.0362\n",
      "Epoch 1046/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0946 - val_loss: 2.0304\n",
      "Epoch 1047/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0965 - val_loss: 2.0473\n",
      "Epoch 01047: early stopping\n"
     ]
    }
   ],
   "source": [
    "early_stop=EarlyStopping(monitor='val_loss', min_delta=0, patience=500, verbose=2, mode='auto', baseline=None)\n",
    "history = model.fit(x_train, Y_train, batch_size=batch_size, epochs=nb_epoch,\n",
    "          verbose=1, validation_data=(x_val, Y_val),\n",
    "          callbacks=[tensorboard,early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test mse: 1.6425318989753723\n",
      "(20000,)\n",
      "(20000,)\n",
      "[ 0.95002664  1.23109237 -0.38287052  0.71376599 -1.72783679  0.42551722\n",
      "  0.08668747  3.77832088  0.05249884  1.34751165]\n",
      "(20000,)\n",
      "(20000, 1)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, Y_test, verbose=0)\n",
    "print('Test mse:', score)\n",
    "# print('Test mae:', score[1])\n",
    "Y_test_predicted=model.predict(x_test)\n",
    "x_test_array=np.asarray(Y_test)\n",
    "print(x_test_array.shape)\n",
    "error_prediction=Y_test-Y_test_predicted.flatten()\n",
    "print(error_prediction.shape)\n",
    "print(error_prediction[:10])\n",
    "print(Y_test.shape)\n",
    "print(Y_test_predicted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model error')\n",
    "plt.ylabel('error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(error_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,)\n",
      "(401,)\n",
      "[[Model]]\n",
      "    Model(gaussian)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 25\n",
      "    # data points      = 400\n",
      "    # variables        = 3\n",
      "    chi-square         = 44724.9983\n",
      "    reduced chi-square = 112.657426\n",
      "    Akaike info crit   = 1892.72933\n",
      "    Bayesian info crit = 1904.70372\n",
      "[[Variables]]\n",
      "    amp:  738.576548 +/- 3.02697532 (0.41%) (init = 1000)\n",
      "    cen: -0.08309576 +/- 0.00497075 (5.98%) (init = 0)\n",
      "    wid:  1.48548765 +/- 0.00702970 (0.47%) (init = 1)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(amp, wid) = -0.577\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "n, bins, patches = plt.hist(error_prediction, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "plt.title(\"Histogram with 400 bins\")\n",
    "plt.show()\n",
    "x=bins[:400]\n",
    "y=n\n",
    "print(n.shape)\n",
    "print(bins.shape)\n",
    "from numpy import exp, loadtxt, pi, sqrt, log\n",
    "\n",
    "from lmfit import Model\n",
    "def gaussian(x, amp, cen, wid):\n",
    "    \"\"\"1-d gaussian: gaussian(x, amp, cen, wid)\"\"\"\n",
    "    return amp * exp(-((x-cen)/wid)**2 )\n",
    "\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "\n",
    "print(result.fit_report())\n",
    "\n",
    "plt.plot(x, y, 'bo')\n",
    "plt.plot(x, result.init_fit, 'k--')\n",
    "plt.plot(x, result.best_fit, 'r-')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWHM=result.params['wid'].value*2*sqrt(log(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4734991824949977\n"
     ]
    }
   ],
   "source": [
    "print(FWHM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[166.59288]\n",
      " [168.67853]\n",
      " [165.72136]\n",
      " ...\n",
      " [165.59842]\n",
      " [165.63261]\n",
      " [165.86102]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8917422026346444\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_bin0_predicted=model.predict(x_test_bin0)\n",
    "print(Y_test_bin0_predicted)\n",
    "error_prediction_bin0=Y_test_bin0-Y_test_bin0_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin0, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin0=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7057386592603034\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_bin1_predicted=model.predict(x_test_bin1)\n",
    "#print(Y_test_bin1_predicted)\n",
    "error_prediction_bin1=Y_test_bin1-Y_test_bin1_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin1, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin1=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.279496416098469\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_bin2_predicted=model.predict(x_test_bin2)\n",
    "#print(Y_test_bin2_predicted)\n",
    "error_prediction_bin2=Y_test_bin2-Y_test_bin2_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin2, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin2=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8225194349467602\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_bin3_predicted=model.predict(x_test_bin3)\n",
    "#print(Y_test_bin3_predicted)\n",
    "error_prediction_bin3=Y_test_bin3-Y_test_bin3_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin3, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin3=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9932654218651418\n",
      "1.8225194349467602\n",
      "2.279496416098469\n",
      "2.7057386592603034\n",
      "2.8917422026346444\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_bin4_predicted=model.predict(x_test_bin4)\n",
    "#print(Y_test_bin4_predicted)\n",
    "error_prediction_bin4=Y_test_bin4-Y_test_bin4_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin4, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin4=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin4)\n",
    "print(FWHM_bin3)\n",
    "print(FWHM_bin2)\n",
    "print(FWHM_bin1)\n",
    "print(FWHM_bin0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "495px",
    "left": "909px",
    "right": "57px",
    "top": "246px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
