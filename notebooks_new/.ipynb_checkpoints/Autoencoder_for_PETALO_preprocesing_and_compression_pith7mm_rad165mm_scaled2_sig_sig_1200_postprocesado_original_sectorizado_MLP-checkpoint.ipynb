{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple AUTOENCODER for PETALO\n",
    "\n",
    "Esta red la vamos a utilizar para obtener el radio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python36.zip', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/lib-dynload', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/extensions', '/home/rgadea3/.ipython']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#np.random.seed(1337)  # for reproducibility\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append(\"/home/rgadea/lmfit-py/\")\n",
    "import seaborn as sns\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from math import floor\n",
    "from lmfit.models import  GaussianModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos introducir los datos de petalo preprocesados en pyhton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3518)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import hdf5storage\n",
    "# datos_matlab = hdf5storage.loadmat('../datos_junio_2019/conjunto_entrenamiento_junio_2019_pitch7mm_rad165mm_29_total.mat')\n",
    "npzfile = np.load('../conjuntos_datos_reconstruidos/fil5_pith7mm_rad165mm_scaled2_sig_sig_1200.npz')\n",
    "npzfile.files\n",
    "\n",
    "# conjunto_datos1= npzfile['arr_0']\n",
    "# npzfile = np.load('../conjuntos_datos_reconstruidos/fil2_pith7mm_rad165mm_scaled2_sig_sig_1200.npz')\n",
    "# npzfile.files\n",
    "\n",
    "conjunto_datos= npzfile['arr_0']\n",
    "\n",
    "# conjunto_datos=np.concatenate((conjunto_datos1,conjunto_datos2), axis=0)\n",
    "print(conjunto_datos.shape)\n",
    "# print(conjunto_datos[:10,6:26])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "# aqui no aplicable porque es una regresion\n",
    "# nb_classes = 10 \n",
    "\n",
    "nb_epoch = 2000\n",
    "\n",
    "n_hidden1=80\n",
    "n_hidden2=60\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 20, 31\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "conjunto_datos shape: (50000, 3518)\n",
      "194.99950513267174\n",
      "sector shape: (50000, 20, 31)\n",
      "conjunto_datos_nuevo: (50000, 620)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "# (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# conjunto_datos=photodefbox2_todo_e\n",
    "numero_muestras=conjunto_datos.shape[0]\n",
    "print(numero_muestras)\n",
    "print('conjunto_datos shape:', conjunto_datos.shape)\n",
    "maxInColumns = np.amax(conjunto_datos, axis=0)\n",
    "print (maxInColumns[1])\n",
    "# n, bins, patches = plt.hist(conjunto_datos[:,1], 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "\n",
    "idea=conjunto_datos[:,6:3506]\n",
    "veamos=idea.reshape(idea.shape[0],175, 20)\n",
    "veamos2=np.zeros([idea.shape[0],20,175])\n",
    "veamos2_3=np.zeros([idea.shape[0],20,525])\n",
    "sector2=np.zeros([idea.shape[0],20,31])\n",
    "veamos3=np.zeros([idea.shape[0],175])\n",
    "# for i in range(idea.shape[0]):\n",
    "for i in range(idea.shape[0]):\n",
    "    veamos2[i]=np.reshape(veamos[i].transpose(), [20,175])\n",
    "    veamos3[i]=np.sum(veamos2[i], axis=0)\n",
    "    indice=np.argmax(veamos3[i], axis=0)\n",
    "    veamos2_3[i]=np.concatenate((veamos2[i],veamos2[i],veamos2[i]),axis=1)   \n",
    "    sector2[i]=veamos2_3[i,:,indice-15+175:indice+16+175]\n",
    "    \n",
    "\n",
    "print('sector shape:', sector2.shape)\n",
    "conjunto_datos_nuevo=sector2.reshape(sector2.shape[0], img_rows*img_cols)\n",
    "print('conjunto_datos_nuevo:', conjunto_datos_nuevo.shape)\n",
    "\n",
    "print(idea[:10,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "#Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "#Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "for i in range(1,5):\n",
    "    idea=np.random.randint(1,sector2.shape[0])\n",
    "    plt.imshow(sector2[idea], cmap='viridis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "10000\n",
      "20000\n",
      "(8655, 620)\n",
      "(3929, 620)\n",
      "(2550, 620)\n",
      "(2132, 620)\n",
      "(2734, 620)\n"
     ]
    }
   ],
   "source": [
    "tr_size=40\n",
    "val_size=20\n",
    "test_size=100-val_size-tr_size\n",
    "conjunto_datos_nuevo2=np.concatenate((conjunto_datos[:,0:3],conjunto_datos_nuevo), axis=1)\n",
    "tamanyo_tr=floor(tr_size*numero_muestras/100)\n",
    "tamanyo_val=floor(val_size*numero_muestras/100)\n",
    "tamanyo_test=numero_muestras-tamanyo_tr-tamanyo_val\n",
    "print(tamanyo_tr)\n",
    "print(tamanyo_val)\n",
    "print(tamanyo_test)\n",
    "\n",
    "\n",
    "XY_test=conjunto_datos_nuevo2[tamanyo_tr+tamanyo_val:numero_muestras,:]\n",
    "\n",
    "\n",
    "XY_test_bin0=XY_test[np.where((XY_test[:,1]>=164.9999) * (XY_test[:,1]<171.000))]\n",
    "XY_test_bin1=XY_test[np.where((XY_test[:,1]>=171.000) * (XY_test[:,1]<177.000))]\n",
    "XY_test_bin2=XY_test[np.where((XY_test[:,1]>=177.000) * (XY_test[:,1]<183.0000))]\n",
    "XY_test_bin3=XY_test[np.where((XY_test[:,1]>=183.000) * (XY_test[:,1]<189.0000))]\n",
    "XY_test_bin4=XY_test[np.where((XY_test[:,1]>=189.0000))]\n",
    "\n",
    "x_train=conjunto_datos_nuevo2[:tamanyo_tr,3:]\n",
    "x_val=conjunto_datos_nuevo2[tamanyo_tr:tamanyo_tr+tamanyo_val,3:]\n",
    "x_test=conjunto_datos_nuevo2[tamanyo_tr+tamanyo_val:numero_muestras,3:]\n",
    "\n",
    "x_test_bin0=XY_test_bin0[:,3:]\n",
    "Y_test_bin0=XY_test_bin0[:,1]\n",
    "print(x_test_bin0.shape)\n",
    "x_test_bin1=XY_test_bin1[:,3:]\n",
    "Y_test_bin1=XY_test_bin1[:,1]\n",
    "print(x_test_bin1.shape)\n",
    "x_test_bin2=XY_test_bin2[:,3:]\n",
    "Y_test_bin2=XY_test_bin2[:,1]\n",
    "print(x_test_bin2.shape)\n",
    "x_test_bin3=XY_test_bin3[:,3:]\n",
    "Y_test_bin3=XY_test_bin3[:,1]\n",
    "print(x_test_bin3.shape)\n",
    "x_test_bin4=XY_test_bin4[:,3:]\n",
    "Y_test_bin4=XY_test_bin4[:,1]\n",
    "print(x_test_bin4.shape)\n",
    "\n",
    "\n",
    "\n",
    "Y_train=conjunto_datos_nuevo2[:tamanyo_tr,1] #elijo la coordenada radius\n",
    "Y_val=conjunto_datos_nuevo2[tamanyo_tr:tamanyo_tr+tamanyo_val,1] #elijo la corrdenada radius\n",
    "Y_test=conjunto_datos_nuevo2[tamanyo_tr+tamanyo_val:numero_muestras,1] #elijo la corrdenada radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cols=31\n",
    "img_rows=20\n",
    "\n",
    "X_train = x_train.reshape(x_train.shape[0], img_rows, img_cols,1)\n",
    "X_val = x_val.reshape(x_val.shape[0], img_rows, img_cols,1)\n",
    "X_test = x_test.reshape(x_test.shape[0], img_rows, img_cols,1)\n",
    "\n",
    "X_test_bin0 = x_test_bin0.reshape(x_test_bin0.shape[0], img_rows, img_cols,1)\n",
    "X_test_bin1 = x_test_bin1.reshape(x_test_bin1.shape[0], img_rows, img_cols,1)\n",
    "X_test_bin2 = x_test_bin2.reshape(x_test_bin2.shape[0], img_rows, img_cols,1)\n",
    "X_test_bin3 = x_test_bin3.reshape(x_test_bin3.shape[0], img_rows, img_cols,1)\n",
    "X_test_bin4 = x_test_bin4.reshape(x_test_bin4.shape[0], img_rows, img_cols,1)\n",
    "\n",
    "input_shape = (img_rows, img_cols,1)\n",
    "#input_shape=input_shape.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (20000, 20, 31, 1)\n",
      "20000 train samples\n",
      "10000 validation samples\n",
      "20000 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_val= X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_val.shape[0], 'validation samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display 20 random training images using image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "#Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "#Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "for i in range(1,5):\n",
    "    idea=np.random.randint(1,X_train.shape[0])\n",
    "    plt.imshow(np.reshape(X_train[idea], [img_rows, img_cols]), cmap='viridis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the MLP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 1. 0. 0. 1. 1. 2. 2. 3.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 3. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "X_train shape: (20000, 20, 31, 1)\n",
      "20000 train samples\n",
      "10000 validation samples\n",
      "20000 test samples\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 1. 0. 0. 1. 1. 2. 2. 3.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 3. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_val[:10,:10])\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler().fit(x_train)\n",
    "#min_max_scaler = preprocessing.RobustScaler().fit(x_train)\n",
    "# supermax=1\n",
    "# factor_aprendizaje=0.0001\n",
    "print(min_max_scaler)\n",
    "# comentar las siguientes lineas si no queremos normalizar\n",
    "# x_train = min_max_scaler.transform(x_train)\n",
    "# x_val = min_max_scaler.transform(x_val)\n",
    "# x_test = min_max_scaler.transform(x_test)\n",
    "# x_test_bin0 = min_max_scaler.transform(x_test_bin0)\n",
    "# x_test_bin1 = min_max_scaler.transform(x_test_bin1)\n",
    "# x_test_bin2 = min_max_scaler.transform(x_test_bin2)\n",
    "# x_test_bin3 = min_max_scaler.transform(x_test_bin3)\n",
    "# x_test_bin4 = min_max_scaler.transform(x_test_bin4)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_val.shape[0], 'validation samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "model=Sequential()\n",
    "# add input layer\n",
    "model.add(Dense(\n",
    "    units=n_hidden1,\n",
    "    input_dim=x_train.shape[1],\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    activation='tanh') \n",
    ")\n",
    "# add hidden layer\n",
    "model.add(\n",
    "    Dense(\n",
    "        units=n_hidden1,\n",
    "        input_dim=n_hidden2,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh')\n",
    "    )\n",
    "# add output layer\n",
    "model.add(\n",
    "    Dense(\n",
    "        units=1,\n",
    "        input_dim=n_hidden2,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='linear')\n",
    "    )\n",
    "\n",
    "# define SGD optimizer\n",
    "sgd_optimizer = SGD(\n",
    "    lr=0.001, decay=1e-7, momentum=0.9\n",
    ")\n",
    "# compile model\n",
    "experimento=\"{}_{}_tanh_tanh_linear_sin_normalizar_original_fil5\".format(n_hidden1,n_hidden2)\n",
    "algoritmo='adam'\n",
    "tensorboard=TensorBoard(log_dir=\"/home/rgadea3/EXPERIMENTOS/nuevas_investigaciones_2018/experimentos/logs/defs/{}{}{}\".format(experimento,algoritmo,datetime.now()))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=algoritmo\n",
    "\n",
    "             )\n",
    "print(x_val[:10,:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a summary of the model parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                31050     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 33,651\n",
      "Trainable params: 33,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now train the model and evaluate on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/2000\n",
      "20000/20000 [==============================] - 5s 240us/step - loss: 29651.9435 - val_loss: 28904.2123\n",
      "Epoch 2/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 28433.5275 - val_loss: 28090.4756\n",
      "Epoch 3/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 27755.4044 - val_loss: 27530.1836\n",
      "Epoch 4/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 27255.6160 - val_loss: 27071.7180\n",
      "Epoch 5/2000\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 26827.6477 - val_loss: 26665.6611\n",
      "Epoch 6/2000\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 26436.6766 - val_loss: 26285.9846\n",
      "Epoch 7/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 26065.7204 - val_loss: 25922.2611\n",
      "Epoch 8/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 25708.2028 - val_loss: 25569.7162\n",
      "Epoch 9/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 25360.2961 - val_loss: 25225.7250\n",
      "Epoch 10/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 25019.9349 - val_loss: 24888.4402\n",
      "Epoch 11/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 24685.9318 - val_loss: 24557.2125\n",
      "Epoch 12/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 24357.6406 - val_loss: 24231.3559\n",
      "Epoch 13/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 24034.4665 - val_loss: 23910.4443\n",
      "Epoch 14/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 23716.0432 - val_loss: 23594.0664\n",
      "Epoch 15/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 23401.9946 - val_loss: 23282.0687\n",
      "Epoch 16/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 23092.2383 - val_loss: 22973.9723\n",
      "Epoch 17/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 22786.2625 - val_loss: 22669.8547\n",
      "Epoch 18/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 22484.1517 - val_loss: 22369.3826\n",
      "Epoch 19/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 22185.6505 - val_loss: 22072.5246\n",
      "Epoch 20/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 21890.7013 - val_loss: 21779.0650\n",
      "Epoch 21/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 21599.1320 - val_loss: 21488.9887\n",
      "Epoch 22/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 21310.8834 - val_loss: 21202.2166\n",
      "Epoch 23/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 21025.9061 - val_loss: 20918.6303\n",
      "Epoch 24/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 20744.1183 - val_loss: 20638.1246\n",
      "Epoch 25/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 20465.3479 - val_loss: 20360.8543\n",
      "Epoch 26/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 20189.7260 - val_loss: 20086.5508\n",
      "Epoch 27/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 19917.1168 - val_loss: 19815.1621\n",
      "Epoch 28/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 19647.3965 - val_loss: 19546.7537\n",
      "Epoch 29/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 19380.6032 - val_loss: 19281.2311\n",
      "Epoch 30/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 19116.6821 - val_loss: 19018.5326\n",
      "Epoch 31/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 18855.5737 - val_loss: 18758.6320\n",
      "Epoch 32/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 18597.2419 - val_loss: 18501.4959\n",
      "Epoch 33/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 18341.6529 - val_loss: 18247.0998\n",
      "Epoch 34/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 18088.8216 - val_loss: 17995.3168\n",
      "Epoch 35/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 17838.5854 - val_loss: 17746.2889\n",
      "Epoch 36/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 17591.0512 - val_loss: 17499.8959\n",
      "Epoch 37/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 17346.1169 - val_loss: 17256.1465\n",
      "Epoch 38/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 17103.8144 - val_loss: 17014.9305\n",
      "Epoch 39/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 16864.0506 - val_loss: 16776.2707\n",
      "Epoch 40/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 16626.8616 - val_loss: 16540.0705\n",
      "Epoch 41/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 16392.1202 - val_loss: 16306.4312\n",
      "Epoch 42/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 16159.8942 - val_loss: 16075.2812\n",
      "Epoch 43/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 15930.1706 - val_loss: 15846.5244\n",
      "Epoch 44/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 15702.8299 - val_loss: 15620.2582\n",
      "Epoch 45/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 15477.9345 - val_loss: 15396.4066\n",
      "Epoch 46/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 15255.4518 - val_loss: 15174.9119\n",
      "Epoch 47/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 15035.3052 - val_loss: 14955.8284\n",
      "Epoch 48/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 14817.5841 - val_loss: 14738.9939\n",
      "Epoch 49/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 14602.0927 - val_loss: 14524.5957\n",
      "Epoch 50/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 14389.0146 - val_loss: 14312.4176\n",
      "Epoch 51/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 14178.1822 - val_loss: 14102.5324\n",
      "Epoch 52/2000\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 13969.6108 - val_loss: 13894.9499\n",
      "Epoch 53/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 13763.3172 - val_loss: 13689.5951\n",
      "Epoch 54/2000\n",
      "20000/20000 [==============================] - 0s 11us/step - loss: 13559.2681 - val_loss: 13486.4364\n",
      "Epoch 55/2000\n",
      "20000/20000 [==============================] - 0s 10us/step - loss: 13357.4139 - val_loss: 13285.5037\n",
      "Epoch 56/2000\n",
      "20000/20000 [==============================] - 0s 10us/step - loss: 13157.7496 - val_loss: 13086.7917\n",
      "Epoch 57/2000\n",
      "20000/20000 [==============================] - 0s 10us/step - loss: 12960.2867 - val_loss: 12890.2442\n",
      "Epoch 58/2000\n",
      "20000/20000 [==============================] - 0s 12us/step - loss: 12764.9797 - val_loss: 12695.8610\n",
      "Epoch 59/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 12571.8778 - val_loss: 12503.5076\n",
      "Epoch 60/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 12380.7760 - val_loss: 12313.4244\n",
      "Epoch 61/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 12191.8740 - val_loss: 12125.4209\n",
      "Epoch 62/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 12005.0836 - val_loss: 11939.4445\n",
      "Epoch 63/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 11820.3273 - val_loss: 11755.5721\n",
      "Epoch 64/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 11637.6639 - val_loss: 11573.7297\n",
      "Epoch 65/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 11457.0307 - val_loss: 11393.9357\n",
      "Epoch 66/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 11278.4273 - val_loss: 11216.1760\n",
      "Epoch 67/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 11101.8334 - val_loss: 11040.4525\n",
      "Epoch 68/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 10927.2800 - val_loss: 10866.6691\n",
      "Epoch 69/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 10754.6811 - val_loss: 10694.8718\n",
      "Epoch 70/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 10584.0406 - val_loss: 10525.0666\n",
      "Epoch 71/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 16us/step - loss: 10415.3769 - val_loss: 10357.1950\n",
      "Epoch 72/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 10248.6548 - val_loss: 10191.2440\n",
      "Epoch 73/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 10083.8218 - val_loss: 10027.2666\n",
      "Epoch 74/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 9920.9674 - val_loss: 9865.1120\n",
      "Epoch 75/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 9759.9486 - val_loss: 9704.8897\n",
      "Epoch 76/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 9600.8317 - val_loss: 9546.5471\n",
      "Epoch 77/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 9443.6021 - val_loss: 9390.0315\n",
      "Epoch 78/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 9288.1789 - val_loss: 9235.4228\n",
      "Epoch 79/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 9134.6446 - val_loss: 9082.6094\n",
      "Epoch 80/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 8982.8978 - val_loss: 8931.6510\n",
      "Epoch 81/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 8833.0303 - val_loss: 8782.4083\n",
      "Epoch 82/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 8684.8738 - val_loss: 8635.0361\n",
      "Epoch 83/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 8538.5400 - val_loss: 8489.4493\n",
      "Epoch 84/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 8394.0148 - val_loss: 8345.5639\n",
      "Epoch 85/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 8251.1927 - val_loss: 8203.4731\n",
      "Epoch 86/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 8110.1096 - val_loss: 8063.1780\n",
      "Epoch 87/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 7970.8372 - val_loss: 7924.5084\n",
      "Epoch 88/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 7833.1984 - val_loss: 7787.6224\n",
      "Epoch 89/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 7697.3368 - val_loss: 7652.3669\n",
      "Epoch 90/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 7563.1095 - val_loss: 7518.8500\n",
      "Epoch 91/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 7430.5636 - val_loss: 7387.0489\n",
      "Epoch 92/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 7299.7596 - val_loss: 7256.8128\n",
      "Epoch 93/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 7170.5363 - val_loss: 7128.2708\n",
      "Epoch 94/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 7042.9757 - val_loss: 7001.3778\n",
      "Epoch 95/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 6917.0533 - val_loss: 6876.1031\n",
      "Epoch 96/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 6792.7439 - val_loss: 6752.4396\n",
      "Epoch 97/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 6670.0397 - val_loss: 6630.3801\n",
      "Epoch 98/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 6548.9467 - val_loss: 6509.8753\n",
      "Epoch 99/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 6429.3935 - val_loss: 6390.9938\n",
      "Epoch 100/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 6311.4446 - val_loss: 6273.6584\n",
      "Epoch 101/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 6195.0586 - val_loss: 6157.8401\n",
      "Epoch 102/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 6080.2095 - val_loss: 6043.5476\n",
      "Epoch 103/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 5966.8470 - val_loss: 5930.8605\n",
      "Epoch 104/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 5855.0597 - val_loss: 5819.6562\n",
      "Epoch 105/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 5744.7470 - val_loss: 5709.9914\n",
      "Epoch 106/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 5635.9484 - val_loss: 5601.8169\n",
      "Epoch 107/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 5528.6795 - val_loss: 5495.0375\n",
      "Epoch 108/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 5422.8050 - val_loss: 5389.7982\n",
      "Epoch 109/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 5318.4366 - val_loss: 5285.9972\n",
      "Epoch 110/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 5215.5449 - val_loss: 5183.5772\n",
      "Epoch 111/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 5114.0061 - val_loss: 5082.6928\n",
      "Epoch 112/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 5013.9782 - val_loss: 4983.1682\n",
      "Epoch 113/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 4915.3145 - val_loss: 4885.0947\n",
      "Epoch 114/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 4818.1099 - val_loss: 4788.3562\n",
      "Epoch 115/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 4722.2192 - val_loss: 4693.0915\n",
      "Epoch 116/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 4627.7741 - val_loss: 4599.1654\n",
      "Epoch 117/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 4534.6945 - val_loss: 4506.5760\n",
      "Epoch 118/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 4442.9437 - val_loss: 4415.3709\n",
      "Epoch 119/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 4352.5445 - val_loss: 4325.5304\n",
      "Epoch 120/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 4263.5327 - val_loss: 4236.9475\n",
      "Epoch 121/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 4175.7992 - val_loss: 4149.7041\n",
      "Epoch 122/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 4089.3381 - val_loss: 4063.8689\n",
      "Epoch 123/2000\n",
      "20000/20000 [==============================] - ETA: 0s - loss: 4011.69 - 0s 16us/step - loss: 4004.2834 - val_loss: 3979.2265\n",
      "Epoch 124/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3920.4619 - val_loss: 3895.8852\n",
      "Epoch 125/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3837.9160 - val_loss: 3813.8439\n",
      "Epoch 126/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3756.6422 - val_loss: 3733.0834\n",
      "Epoch 127/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3676.6491 - val_loss: 3653.5504\n",
      "Epoch 128/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3597.8998 - val_loss: 3575.2444\n",
      "Epoch 129/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3520.3391 - val_loss: 3498.2468\n",
      "Epoch 130/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3444.0745 - val_loss: 3422.4068\n",
      "Epoch 131/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3368.9887 - val_loss: 3347.7850\n",
      "Epoch 132/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3295.1110 - val_loss: 3274.3613\n",
      "Epoch 133/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3222.4226 - val_loss: 3202.1359\n",
      "Epoch 134/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3150.9421 - val_loss: 3131.0428\n",
      "Epoch 135/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3080.5926 - val_loss: 3061.1583\n",
      "Epoch 136/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3011.4309 - val_loss: 2992.4117\n",
      "Epoch 137/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 2943.4122 - val_loss: 2924.8084\n",
      "Epoch 138/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 2876.5354 - val_loss: 2858.3332\n",
      "Epoch 139/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 2810.7535 - val_loss: 2793.0422\n",
      "Epoch 140/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 2746.1490 - val_loss: 2728.8003\n",
      "Epoch 141/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 2682.6004 - val_loss: 2665.7006\n",
      "Epoch 142/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 16us/step - loss: 2620.1652 - val_loss: 2603.6974\n",
      "Epoch 143/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 2558.8396 - val_loss: 2542.7292\n",
      "Epoch 144/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 2498.5550 - val_loss: 2482.8515\n",
      "Epoch 145/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 2439.3556 - val_loss: 2424.0162\n",
      "Epoch 146/2000\n",
      "20000/20000 [==============================] - 0s 12us/step - loss: 2381.1770 - val_loss: 2366.2721\n",
      "Epoch 147/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 2324.0815 - val_loss: 2309.5297\n",
      "Epoch 148/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 2268.0018 - val_loss: 2253.8116\n",
      "Epoch 149/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 2212.9216 - val_loss: 2199.1486\n",
      "Epoch 150/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 2158.8979 - val_loss: 2145.4393\n",
      "Epoch 151/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 2105.8215 - val_loss: 2092.7755\n",
      "Epoch 152/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 2053.7843 - val_loss: 2041.0499\n",
      "Epoch 153/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 2002.6942 - val_loss: 1990.3138\n",
      "Epoch 154/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1952.5715 - val_loss: 1940.5600\n",
      "Epoch 155/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1903.4219 - val_loss: 1891.7460\n",
      "Epoch 156/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1855.2118 - val_loss: 1843.8747\n",
      "Epoch 157/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1807.9235 - val_loss: 1796.9679\n",
      "Epoch 158/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1761.5967 - val_loss: 1750.9360\n",
      "Epoch 159/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1716.1437 - val_loss: 1705.8591\n",
      "Epoch 160/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1671.6445 - val_loss: 1661.6238\n",
      "Epoch 161/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1627.9827 - val_loss: 1618.3352\n",
      "Epoch 162/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1585.2579 - val_loss: 1575.8776\n",
      "Epoch 163/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1543.3694 - val_loss: 1534.3151\n",
      "Epoch 164/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1502.3687 - val_loss: 1493.5865\n",
      "Epoch 165/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1462.1959 - val_loss: 1453.7333\n",
      "Epoch 166/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1422.8901 - val_loss: 1414.6963\n",
      "Epoch 167/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1384.3837 - val_loss: 1376.5207\n",
      "Epoch 168/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1346.7316 - val_loss: 1339.1380\n",
      "Epoch 169/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1309.8757 - val_loss: 1302.5630\n",
      "Epoch 170/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1273.8109 - val_loss: 1266.8043\n",
      "Epoch 171/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 1238.5612 - val_loss: 1231.8000\n",
      "Epoch 172/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1204.0610 - val_loss: 1197.6036\n",
      "Epoch 173/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1170.3707 - val_loss: 1164.1225\n",
      "Epoch 174/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1137.3799 - val_loss: 1131.4623\n",
      "Epoch 175/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1105.1938 - val_loss: 1099.5004\n",
      "Epoch 176/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1073.7255 - val_loss: 1068.2714\n",
      "Epoch 177/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1042.9717 - val_loss: 1037.7899\n",
      "Epoch 178/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1012.9613 - val_loss: 1007.9942\n",
      "Epoch 179/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 983.6383 - val_loss: 978.9158\n",
      "Epoch 180/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 955.0198 - val_loss: 950.5281\n",
      "Epoch 181/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 927.0949 - val_loss: 922.8133\n",
      "Epoch 182/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 899.8256 - val_loss: 895.7982\n",
      "Epoch 183/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 873.2449 - val_loss: 869.4310\n",
      "Epoch 184/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 847.3173 - val_loss: 843.7108\n",
      "Epoch 185/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 822.0290 - val_loss: 818.6409\n",
      "Epoch 186/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 797.3733 - val_loss: 794.2161\n",
      "Epoch 187/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 773.3660 - val_loss: 770.3886\n",
      "Epoch 188/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 749.9528 - val_loss: 747.1895\n",
      "Epoch 189/2000\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 727.1691 - val_loss: 724.5647\n",
      "Epoch 190/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 704.9480 - val_loss: 702.5692\n",
      "Epoch 191/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 683.3445 - val_loss: 681.1352\n",
      "Epoch 192/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 662.3047 - val_loss: 660.2797\n",
      "Epoch 193/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 641.8270 - val_loss: 639.9986\n",
      "Epoch 194/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 621.9212 - val_loss: 620.2565\n",
      "Epoch 195/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 602.5428 - val_loss: 601.0796\n",
      "Epoch 196/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 583.7360 - val_loss: 582.3928\n",
      "Epoch 197/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 565.4122 - val_loss: 564.2765\n",
      "Epoch 198/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 547.6451 - val_loss: 546.6428\n",
      "Epoch 199/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 530.3647 - val_loss: 529.5289\n",
      "Epoch 200/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 513.5969 - val_loss: 512.8975\n",
      "Epoch 201/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 497.3140 - val_loss: 496.7505\n",
      "Epoch 202/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 481.5012 - val_loss: 481.0995\n",
      "Epoch 203/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 466.1651 - val_loss: 465.9206\n",
      "Epoch 204/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 451.3110 - val_loss: 451.1663\n",
      "Epoch 205/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 436.8796 - val_loss: 436.8866\n",
      "Epoch 206/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 422.9051 - val_loss: 423.0445\n",
      "Epoch 207/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 409.3691 - val_loss: 409.6217\n",
      "Epoch 208/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 396.2559 - val_loss: 396.6147\n",
      "Epoch 209/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 383.5398 - val_loss: 384.0523\n",
      "Epoch 210/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 371.2465 - val_loss: 371.8907\n",
      "Epoch 211/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 359.3687 - val_loss: 360.0880\n",
      "Epoch 212/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 347.8575 - val_loss: 348.6811\n",
      "Epoch 213/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 336.7175 - val_loss: 337.6791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 325.9749 - val_loss: 327.0218\n",
      "Epoch 215/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 315.5882 - val_loss: 316.7166\n",
      "Epoch 216/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 305.5426 - val_loss: 306.7830\n",
      "Epoch 217/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 295.8618 - val_loss: 297.1753\n",
      "Epoch 218/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 286.5090 - val_loss: 287.9054\n",
      "Epoch 219/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 277.4806 - val_loss: 278.9753\n",
      "Epoch 220/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 268.7876 - val_loss: 270.3492\n",
      "Epoch 221/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 260.3900 - val_loss: 262.0546\n",
      "Epoch 222/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 252.3248 - val_loss: 254.0292\n",
      "Epoch 223/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 244.5241 - val_loss: 246.3323\n",
      "Epoch 224/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 237.0345 - val_loss: 238.9117\n",
      "Epoch 225/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 229.8271 - val_loss: 231.7592\n",
      "Epoch 226/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 222.8913 - val_loss: 224.8743\n",
      "Epoch 227/2000\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 216.2094 - val_loss: 218.2737\n",
      "Epoch 228/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 209.8009 - val_loss: 211.9220\n",
      "Epoch 229/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 203.6423 - val_loss: 205.8153\n",
      "Epoch 230/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 197.7239 - val_loss: 199.9559\n",
      "Epoch 231/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 192.0481 - val_loss: 194.3277\n",
      "Epoch 232/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 186.6008 - val_loss: 188.9262\n",
      "Epoch 233/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 181.3817 - val_loss: 183.7378\n",
      "Epoch 234/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 176.3626 - val_loss: 178.7877\n",
      "Epoch 235/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 171.5774 - val_loss: 174.0219\n",
      "Epoch 236/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 166.9795 - val_loss: 169.4672\n",
      "Epoch 237/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 162.5866 - val_loss: 165.1017\n",
      "Epoch 238/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 158.3695 - val_loss: 160.9482\n",
      "Epoch 239/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 154.3615 - val_loss: 156.9510\n",
      "Epoch 240/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 150.5108 - val_loss: 153.1465\n",
      "Epoch 241/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 146.8434 - val_loss: 149.5058\n",
      "Epoch 242/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 143.3443 - val_loss: 146.0207\n",
      "Epoch 243/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 140.0022 - val_loss: 142.6932\n",
      "Epoch 244/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 136.8056 - val_loss: 139.5371\n",
      "Epoch 245/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 133.7696 - val_loss: 136.5237\n",
      "Epoch 246/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 130.8770 - val_loss: 133.6482\n",
      "Epoch 247/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 128.1258 - val_loss: 130.9022\n",
      "Epoch 248/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 125.4956 - val_loss: 128.3054\n",
      "Epoch 249/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 123.0086 - val_loss: 125.8225\n",
      "Epoch 250/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 120.6399 - val_loss: 123.4615\n",
      "Epoch 251/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 118.3883 - val_loss: 121.2196\n",
      "Epoch 252/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 116.2486 - val_loss: 119.0974\n",
      "Epoch 253/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 114.2243 - val_loss: 117.0787\n",
      "Epoch 254/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 112.2968 - val_loss: 115.1754\n",
      "Epoch 255/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 110.4900 - val_loss: 113.3436\n",
      "Epoch 256/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 108.7561 - val_loss: 111.6275\n",
      "Epoch 257/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 107.1257 - val_loss: 110.0004\n",
      "Epoch 258/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 105.5791 - val_loss: 108.4679\n",
      "Epoch 259/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 104.1259 - val_loss: 107.0078\n",
      "Epoch 260/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 102.7445 - val_loss: 105.6349\n",
      "Epoch 261/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 101.4490 - val_loss: 104.3286\n",
      "Epoch 262/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 100.2185 - val_loss: 103.1040\n",
      "Epoch 263/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 99.0684 - val_loss: 101.9372\n",
      "Epoch 264/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 97.9750 - val_loss: 100.8467\n",
      "Epoch 265/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 96.9483 - val_loss: 99.8229\n",
      "Epoch 266/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 95.9844 - val_loss: 98.8588\n",
      "Epoch 267/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 95.0860 - val_loss: 97.9365\n",
      "Epoch 268/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 94.2272 - val_loss: 97.0846\n",
      "Epoch 269/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 93.4314 - val_loss: 96.2783\n",
      "Epoch 270/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 92.6814 - val_loss: 95.5229\n",
      "Epoch 271/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 91.9768 - val_loss: 94.8188\n",
      "Epoch 272/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 91.3195 - val_loss: 94.1581\n",
      "Epoch 273/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 90.7064 - val_loss: 93.5340\n",
      "Epoch 274/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 90.1318 - val_loss: 92.9475\n",
      "Epoch 275/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 89.5917 - val_loss: 92.4033\n",
      "Epoch 276/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 89.0919 - val_loss: 91.8900\n",
      "Epoch 277/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 88.6230 - val_loss: 91.4116\n",
      "Epoch 278/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 88.1853 - val_loss: 90.9676\n",
      "Epoch 279/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 87.7786 - val_loss: 90.5535\n",
      "Epoch 280/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 87.4012 - val_loss: 90.1655\n",
      "Epoch 281/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 87.0496 - val_loss: 89.8034\n",
      "Epoch 282/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 86.7207 - val_loss: 89.4703\n",
      "Epoch 283/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 86.4190 - val_loss: 89.1571\n",
      "Epoch 284/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 86.1364 - val_loss: 88.8680\n",
      "Epoch 285/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 85.8790 - val_loss: 88.5925\n",
      "Epoch 286/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 85.6361 - val_loss: 88.3400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 85.4098 - val_loss: 88.1119\n",
      "Epoch 288/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 85.2060 - val_loss: 87.8951\n",
      "Epoch 289/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 85.0135 - val_loss: 87.6981\n",
      "Epoch 290/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 84.8414 - val_loss: 87.5081\n",
      "Epoch 291/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 84.6763 - val_loss: 87.3389\n",
      "Epoch 292/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 84.5287 - val_loss: 87.1791\n",
      "Epoch 293/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 84.3911 - val_loss: 87.0325\n",
      "Epoch 294/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 84.2642 - val_loss: 86.8990\n",
      "Epoch 295/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 84.1485 - val_loss: 86.7759\n",
      "Epoch 296/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 84.0443 - val_loss: 86.6580\n",
      "Epoch 297/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.9445 - val_loss: 86.5548\n",
      "Epoch 298/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.8566 - val_loss: 86.4574\n",
      "Epoch 299/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.7754 - val_loss: 86.3671\n",
      "Epoch 300/2000\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 83.7010 - val_loss: 86.2841\n",
      "Epoch 301/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 83.6326 - val_loss: 86.2094\n",
      "Epoch 302/2000\n",
      "20000/20000 [==============================] - 0s 12us/step - loss: 83.5701 - val_loss: 86.1421\n",
      "Epoch 303/2000\n",
      "20000/20000 [==============================] - 0s 12us/step - loss: 83.5147 - val_loss: 86.0775\n",
      "Epoch 304/2000\n",
      "20000/20000 [==============================] - 0s 12us/step - loss: 83.4633 - val_loss: 86.0184\n",
      "Epoch 305/2000\n",
      "20000/20000 [==============================] - 0s 11us/step - loss: 83.4162 - val_loss: 85.9654\n",
      "Epoch 306/2000\n",
      "20000/20000 [==============================] - 0s 12us/step - loss: 83.3746 - val_loss: 85.9150\n",
      "Epoch 307/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 83.3365 - val_loss: 85.8685\n",
      "Epoch 308/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 83.3006 - val_loss: 85.8289\n",
      "Epoch 309/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.2697 - val_loss: 85.7913\n",
      "Epoch 310/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.2413 - val_loss: 85.7572\n",
      "Epoch 311/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.2156 - val_loss: 85.7261\n",
      "Epoch 312/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.1925 - val_loss: 85.6975\n",
      "Epoch 313/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.1719 - val_loss: 85.6707\n",
      "Epoch 314/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.1530 - val_loss: 85.6469\n",
      "Epoch 315/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.1360 - val_loss: 85.6258\n",
      "Epoch 316/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.1215 - val_loss: 85.6051\n",
      "Epoch 317/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.1076 - val_loss: 85.5873\n",
      "Epoch 318/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0956 - val_loss: 85.5708\n",
      "Epoch 319/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0851 - val_loss: 85.5552\n",
      "Epoch 320/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0751 - val_loss: 85.5421\n",
      "Epoch 321/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0661 - val_loss: 85.5309\n",
      "Epoch 322/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0591 - val_loss: 85.5190\n",
      "Epoch 323/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.0521 - val_loss: 85.5085\n",
      "Epoch 324/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0459 - val_loss: 85.4996\n",
      "Epoch 325/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0407 - val_loss: 85.4907\n",
      "Epoch 326/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0357 - val_loss: 85.4841\n",
      "Epoch 327/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0321 - val_loss: 85.4757\n",
      "Epoch 328/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0279 - val_loss: 85.4692\n",
      "Epoch 329/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0247 - val_loss: 85.4631\n",
      "Epoch 330/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0219 - val_loss: 85.4579\n",
      "Epoch 331/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0191 - val_loss: 85.4536\n",
      "Epoch 332/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0169 - val_loss: 85.4497\n",
      "Epoch 333/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0152 - val_loss: 85.4455\n",
      "Epoch 334/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0136 - val_loss: 85.4411\n",
      "Epoch 335/2000\n",
      "20000/20000 [==============================] - 0s 12us/step - loss: 83.0117 - val_loss: 85.4389\n",
      "Epoch 336/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 83.0106 - val_loss: 85.4353\n",
      "Epoch 337/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.0093 - val_loss: 85.4329\n",
      "Epoch 338/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0083 - val_loss: 85.4302\n",
      "Epoch 339/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0074 - val_loss: 85.4279\n",
      "Epoch 340/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0069 - val_loss: 85.4251\n",
      "Epoch 341/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0060 - val_loss: 85.4235\n",
      "Epoch 342/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0054 - val_loss: 85.4221\n",
      "Epoch 343/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0051 - val_loss: 85.4201\n",
      "Epoch 344/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0046 - val_loss: 85.4199\n",
      "Epoch 345/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0043 - val_loss: 85.4177\n",
      "Epoch 346/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0039 - val_loss: 85.4169\n",
      "Epoch 347/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0043 - val_loss: 85.4145\n",
      "Epoch 348/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0034 - val_loss: 85.4147\n",
      "Epoch 349/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0032 - val_loss: 85.4138\n",
      "Epoch 350/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0031 - val_loss: 85.4128\n",
      "Epoch 351/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0031 - val_loss: 85.4114\n",
      "Epoch 352/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0029 - val_loss: 85.4115\n",
      "Epoch 353/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0027 - val_loss: 85.4103\n",
      "Epoch 354/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0027 - val_loss: 85.4104\n",
      "Epoch 355/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0024 - val_loss: 85.4095\n",
      "Epoch 356/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0023 - val_loss: 85.4089\n",
      "Epoch 357/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0024 - val_loss: 85.4080\n",
      "Epoch 358/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0024 - val_loss: 85.4083\n",
      "Epoch 359/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0022 - val_loss: 85.4076\n",
      "Epoch 360/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0025 - val_loss: 85.4065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0022 - val_loss: 85.4067\n",
      "Epoch 362/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0022 - val_loss: 85.4068\n",
      "Epoch 363/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.0023 - val_loss: 85.4058\n",
      "Epoch 364/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0024 - val_loss: 85.4068\n",
      "Epoch 365/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.0022 - val_loss: 85.4059\n",
      "Epoch 366/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0021 - val_loss: 85.4058\n",
      "Epoch 367/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0021 - val_loss: 85.4057\n",
      "Epoch 368/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0022 - val_loss: 85.4060\n",
      "Epoch 369/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0021 - val_loss: 85.4051\n",
      "Epoch 370/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0023 - val_loss: 85.4043\n",
      "Epoch 371/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0019 - val_loss: 85.4047\n",
      "Epoch 372/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0020 - val_loss: 85.4047\n",
      "Epoch 373/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0020 - val_loss: 85.4051\n",
      "Epoch 374/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0022 - val_loss: 85.4057\n",
      "Epoch 375/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0024 - val_loss: 85.4044\n",
      "Epoch 376/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0021 - val_loss: 85.4049\n",
      "Epoch 377/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0020 - val_loss: 85.4047\n",
      "Epoch 378/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0020 - val_loss: 85.4043\n",
      "Epoch 379/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0021 - val_loss: 85.4037\n",
      "Epoch 380/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0020 - val_loss: 85.4040\n",
      "Epoch 381/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.0020 - val_loss: 85.4041\n",
      "Epoch 382/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0027 - val_loss: 85.4053\n",
      "Epoch 383/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0020 - val_loss: 85.4039\n",
      "Epoch 384/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0019 - val_loss: 85.4043\n",
      "Epoch 385/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0019 - val_loss: 85.4040\n",
      "Epoch 386/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.0020 - val_loss: 85.4033\n",
      "Epoch 387/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0020 - val_loss: 85.4045\n",
      "Epoch 388/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0019 - val_loss: 85.4037\n",
      "Epoch 389/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0019 - val_loss: 85.4043\n",
      "Epoch 390/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0018 - val_loss: 85.4039\n",
      "Epoch 391/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0018 - val_loss: 85.4040\n",
      "Epoch 392/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0018 - val_loss: 85.4040\n",
      "Epoch 393/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0018 - val_loss: 85.4035\n",
      "Epoch 394/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0019 - val_loss: 85.4031\n",
      "Epoch 395/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.0017 - val_loss: 85.4042\n",
      "Epoch 396/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.0017 - val_loss: 85.4044\n",
      "Epoch 397/2000\n",
      "20000/20000 [==============================] - 0s 12us/step - loss: 83.0020 - val_loss: 85.4052\n",
      "Epoch 398/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 83.0016 - val_loss: 85.4039\n",
      "Epoch 399/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0016 - val_loss: 85.4037\n",
      "Epoch 400/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0016 - val_loss: 85.4036\n",
      "Epoch 401/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0019 - val_loss: 85.4026\n",
      "Epoch 402/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0014 - val_loss: 85.4035\n",
      "Epoch 403/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0016 - val_loss: 85.4040\n",
      "Epoch 404/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0017 - val_loss: 85.4032\n",
      "Epoch 405/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0015 - val_loss: 85.4045\n",
      "Epoch 406/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0018 - val_loss: 85.4053\n",
      "Epoch 407/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0014 - val_loss: 85.4046\n",
      "Epoch 408/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0012 - val_loss: 85.4042\n",
      "Epoch 409/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0014 - val_loss: 85.4044\n",
      "Epoch 410/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0012 - val_loss: 85.4037\n",
      "Epoch 411/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 83.0011 - val_loss: 85.4046\n",
      "Epoch 412/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0012 - val_loss: 85.4035\n",
      "Epoch 413/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0008 - val_loss: 85.4045\n",
      "Epoch 414/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0003 - val_loss: 85.4043\n",
      "Epoch 415/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0001 - val_loss: 85.4042\n",
      "Epoch 416/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9997 - val_loss: 85.4036\n",
      "Epoch 417/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9989 - val_loss: 85.4037\n",
      "Epoch 418/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9978 - val_loss: 85.4044\n",
      "Epoch 419/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9967 - val_loss: 85.4061\n",
      "Epoch 420/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9966 - val_loss: 85.4055\n",
      "Epoch 421/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9967 - val_loss: 85.4048\n",
      "Epoch 422/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9974 - val_loss: 85.4068\n",
      "Epoch 423/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9968 - val_loss: 85.4049\n",
      "Epoch 424/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9975 - val_loss: 85.4036\n",
      "Epoch 425/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9966 - val_loss: 85.4057\n",
      "Epoch 426/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9965 - val_loss: 85.4052\n",
      "Epoch 427/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9969 - val_loss: 85.4042\n",
      "Epoch 428/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9964 - val_loss: 85.4049\n",
      "Epoch 429/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 82.9969 - val_loss: 85.4057\n",
      "Epoch 430/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 82.9966 - val_loss: 85.4058\n",
      "Epoch 431/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9965 - val_loss: 85.4052\n",
      "Epoch 432/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9965 - val_loss: 85.4049\n",
      "Epoch 433/2000\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 82.9966 - val_loss: 85.4048\n",
      "Epoch 434/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 82.9967 - val_loss: 85.4053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 435/2000\n",
      "20000/20000 [==============================] - 0s 12us/step - loss: 82.9965 - val_loss: 85.4052\n",
      "Epoch 436/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9967 - val_loss: 85.4038\n",
      "Epoch 437/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9971 - val_loss: 85.4052\n",
      "Epoch 438/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9967 - val_loss: 85.4053\n",
      "Epoch 439/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9969 - val_loss: 85.4041\n",
      "Epoch 440/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9966 - val_loss: 85.4049\n",
      "Epoch 441/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9964 - val_loss: 85.4040\n",
      "Epoch 442/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9967 - val_loss: 85.4034\n",
      "Epoch 443/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9966 - val_loss: 85.4034\n",
      "Epoch 444/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9964 - val_loss: 85.4047\n",
      "Epoch 445/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9969 - val_loss: 85.4034\n",
      "Epoch 446/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9966 - val_loss: 85.4034\n",
      "Epoch 447/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9963 - val_loss: 85.4047\n",
      "Epoch 448/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9964 - val_loss: 85.4059\n",
      "Epoch 449/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9969 - val_loss: 85.4038\n",
      "Epoch 450/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9964 - val_loss: 85.4054\n",
      "Epoch 451/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9964 - val_loss: 85.4054\n",
      "Epoch 452/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9965 - val_loss: 85.4044\n",
      "Epoch 453/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9964 - val_loss: 85.4049\n",
      "Epoch 454/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9964 - val_loss: 85.4043\n",
      "Epoch 455/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9964 - val_loss: 85.4054\n",
      "Epoch 456/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9963 - val_loss: 85.4056\n",
      "Epoch 457/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9970 - val_loss: 85.4031\n",
      "Epoch 458/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9964 - val_loss: 85.4053\n",
      "Epoch 459/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9963 - val_loss: 85.4047\n",
      "Epoch 460/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9962 - val_loss: 85.4043\n",
      "Epoch 461/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9963 - val_loss: 85.4031\n",
      "Epoch 462/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9960 - val_loss: 85.4046\n",
      "Epoch 463/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9961 - val_loss: 85.4041\n",
      "Epoch 464/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9961 - val_loss: 85.4037\n",
      "Epoch 465/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9958 - val_loss: 85.4036\n",
      "Epoch 466/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9956 - val_loss: 85.4057\n",
      "Epoch 467/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9950 - val_loss: 85.4053\n",
      "Epoch 468/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9917 - val_loss: 85.4056\n",
      "Epoch 469/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9959 - val_loss: 85.4053\n",
      "Epoch 470/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9964 - val_loss: 85.4028\n",
      "Epoch 471/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9964 - val_loss: 85.4044\n",
      "Epoch 472/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9963 - val_loss: 85.4045\n",
      "Epoch 473/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9964 - val_loss: 85.4038\n",
      "Epoch 474/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9956 - val_loss: 85.4041\n",
      "Epoch 475/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9961 - val_loss: 85.4029\n",
      "Epoch 476/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9960 - val_loss: 85.4010\n",
      "Epoch 477/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9959 - val_loss: 85.4050\n",
      "Epoch 478/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9951 - val_loss: 85.4056\n",
      "Epoch 479/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9955 - val_loss: 85.4020\n",
      "Epoch 480/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9943 - val_loss: 85.4046\n",
      "Epoch 481/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9919 - val_loss: 85.4044\n",
      "Epoch 482/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9914 - val_loss: 85.4045\n",
      "Epoch 483/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9911 - val_loss: 85.4037\n",
      "Epoch 484/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9911 - val_loss: 85.4041\n",
      "Epoch 485/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9909 - val_loss: 85.4038\n",
      "Epoch 486/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9909 - val_loss: 85.4040\n",
      "Epoch 487/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9908 - val_loss: 85.4048\n",
      "Epoch 488/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9916 - val_loss: 85.4030\n",
      "Epoch 489/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9916 - val_loss: 85.4037\n",
      "Epoch 490/2000\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 82.9909 - val_loss: 85.4044\n",
      "Epoch 491/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 82.9911 - val_loss: 85.4064\n",
      "Epoch 492/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9923 - val_loss: 85.4033\n",
      "Epoch 493/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9909 - val_loss: 85.4045\n",
      "Epoch 494/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 82.9912 - val_loss: 85.4043\n",
      "Epoch 495/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 82.9912 - val_loss: 85.4058\n",
      "Epoch 496/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9914 - val_loss: 85.4053\n",
      "Epoch 497/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9914 - val_loss: 85.4061\n",
      "Epoch 498/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9913 - val_loss: 85.4036\n",
      "Epoch 499/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9915 - val_loss: 85.4062\n",
      "Epoch 500/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9921 - val_loss: 85.4060\n",
      "Epoch 501/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9918 - val_loss: 85.4037\n",
      "Epoch 502/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9921 - val_loss: 85.4018\n",
      "Epoch 503/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9911 - val_loss: 85.4049\n",
      "Epoch 504/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9916 - val_loss: 85.4039\n",
      "Epoch 505/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9911 - val_loss: 85.4045\n",
      "Epoch 506/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9922 - val_loss: 85.4062\n",
      "Epoch 507/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9910 - val_loss: 85.4030\n",
      "Epoch 508/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9912 - val_loss: 85.4014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 509/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9914 - val_loss: 85.4045\n",
      "Epoch 510/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9914 - val_loss: 85.4063\n",
      "Epoch 511/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9908 - val_loss: 85.4045\n",
      "Epoch 512/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9910 - val_loss: 85.4040\n",
      "Epoch 513/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9911 - val_loss: 85.4030\n",
      "Epoch 514/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9916 - val_loss: 85.4052\n",
      "Epoch 515/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9923 - val_loss: 85.4032\n",
      "Epoch 516/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9911 - val_loss: 85.4040\n",
      "Epoch 517/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9942 - val_loss: 85.4022\n",
      "Epoch 518/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9907 - val_loss: 85.4045\n",
      "Epoch 519/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0411 - val_loss: 85.3995\n",
      "Epoch 520/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9972 - val_loss: 85.4054\n",
      "Epoch 521/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9965 - val_loss: 85.4038\n",
      "Epoch 522/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9957 - val_loss: 85.4089\n",
      "Epoch 523/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9946 - val_loss: 85.4064\n",
      "Epoch 524/2000\n",
      "20000/20000 [==============================] - 0s 12us/step - loss: 82.9943 - val_loss: 85.4034\n",
      "Epoch 525/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 82.9922 - val_loss: 85.4056\n",
      "Epoch 526/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9912 - val_loss: 85.4048\n",
      "Epoch 527/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9908 - val_loss: 85.4047\n",
      "Epoch 528/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9912 - val_loss: 85.4039\n",
      "Epoch 529/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9911 - val_loss: 85.4036\n",
      "Epoch 530/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9910 - val_loss: 85.4051\n",
      "Epoch 531/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9911 - val_loss: 85.4038\n",
      "Epoch 532/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9916 - val_loss: 85.4036\n",
      "Epoch 533/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9924 - val_loss: 85.4087\n",
      "Epoch 534/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9911 - val_loss: 85.4049\n",
      "Epoch 535/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9915 - val_loss: 85.4021\n",
      "Epoch 536/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9918 - val_loss: 85.4081\n",
      "Epoch 537/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9912 - val_loss: 85.4036\n",
      "Epoch 538/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9918 - val_loss: 85.4060\n",
      "Epoch 539/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9913 - val_loss: 85.4031\n",
      "Epoch 540/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9912 - val_loss: 85.4059\n",
      "Epoch 541/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9916 - val_loss: 85.4036\n",
      "Epoch 542/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9918 - val_loss: 85.4024\n",
      "Epoch 543/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9915 - val_loss: 85.4080\n",
      "Epoch 544/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9912 - val_loss: 85.4047\n",
      "Epoch 545/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9903 - val_loss: 85.4046\n",
      "Epoch 546/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9886 - val_loss: 85.4032\n",
      "Epoch 547/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 83.0022 - val_loss: 85.4066\n",
      "Epoch 548/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9924 - val_loss: 85.4023\n",
      "Epoch 549/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9928 - val_loss: 85.4070\n",
      "Epoch 550/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9936 - val_loss: 85.4056\n",
      "Epoch 551/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9939 - val_loss: 85.4026\n",
      "Epoch 552/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9932 - val_loss: 85.4065\n",
      "Epoch 553/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9932 - val_loss: 85.4105\n",
      "Epoch 554/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9925 - val_loss: 85.4039\n",
      "Epoch 555/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9921 - val_loss: 85.4020\n",
      "Epoch 556/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9910 - val_loss: 85.4051\n",
      "Epoch 557/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9934 - val_loss: 85.4105\n",
      "Epoch 558/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9906 - val_loss: 85.4049\n",
      "Epoch 559/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9916 - val_loss: 85.4059\n",
      "Epoch 560/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9915 - val_loss: 85.4026\n",
      "Epoch 561/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9924 - val_loss: 85.4038\n",
      "Epoch 562/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9909 - val_loss: 85.4064\n",
      "Epoch 563/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9918 - val_loss: 85.4044\n",
      "Epoch 564/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9916 - val_loss: 85.4083\n",
      "Epoch 565/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9909 - val_loss: 85.4068\n",
      "Epoch 566/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9920 - val_loss: 85.4067\n",
      "Epoch 567/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9924 - val_loss: 85.4042\n",
      "Epoch 568/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9923 - val_loss: 85.4086\n",
      "Epoch 569/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9922 - val_loss: 85.4015\n",
      "Epoch 570/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9936 - val_loss: 85.4049\n",
      "Epoch 571/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9949 - val_loss: 85.4095\n",
      "Epoch 572/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9915 - val_loss: 85.4013\n",
      "Epoch 573/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9924 - val_loss: 85.4050\n",
      "Epoch 574/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9924 - val_loss: 85.4024\n",
      "Epoch 575/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9914 - val_loss: 85.4034\n",
      "Epoch 576/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9924 - val_loss: 85.4109\n",
      "Epoch 577/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9912 - val_loss: 85.4066\n",
      "Epoch 578/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9911 - val_loss: 85.4029\n",
      "Epoch 579/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9991 - val_loss: 85.3982\n",
      "Epoch 580/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9983 - val_loss: 85.4135\n",
      "Epoch 581/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9919 - val_loss: 85.4052\n",
      "Epoch 582/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9922 - val_loss: 85.4058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 583/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9910 - val_loss: 85.4039\n",
      "Epoch 584/2000\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 82.9928 - val_loss: 85.4040\n",
      "Epoch 585/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9910 - val_loss: 85.4076\n",
      "Epoch 586/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9908 - val_loss: 85.4074\n",
      "Epoch 587/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9930 - val_loss: 85.4028\n",
      "Epoch 588/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9908 - val_loss: 85.4052\n",
      "Epoch 589/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9914 - val_loss: 85.4068\n",
      "Epoch 590/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9917 - val_loss: 85.4070\n",
      "Epoch 591/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 82.9928 - val_loss: 85.4036\n",
      "Epoch 592/2000\n",
      "20000/20000 [==============================] - 0s 12us/step - loss: 82.9960 - val_loss: 85.4146\n",
      "Epoch 593/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9923 - val_loss: 85.4100\n",
      "Epoch 594/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9933 - val_loss: 85.4029\n",
      "Epoch 595/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9924 - val_loss: 85.3999\n",
      "Epoch 596/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9918 - val_loss: 85.4066\n",
      "Epoch 597/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9933 - val_loss: 85.4025\n",
      "Epoch 598/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9926 - val_loss: 85.4031\n",
      "Epoch 599/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9934 - val_loss: 85.4078\n",
      "Epoch 600/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9937 - val_loss: 85.4046\n",
      "Epoch 601/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9931 - val_loss: 85.4080\n",
      "Epoch 602/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9927 - val_loss: 85.4015\n",
      "Epoch 603/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9922 - val_loss: 85.4052\n",
      "Epoch 604/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9924 - val_loss: 85.4050\n",
      "Epoch 605/2000\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 82.9928 - val_loss: 85.4051\n",
      "Epoch 606/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 82.9914 - val_loss: 85.4067\n",
      "Epoch 607/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9935 - val_loss: 85.4101\n",
      "Epoch 608/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9961 - val_loss: 85.4089\n",
      "Epoch 609/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9918 - val_loss: 85.4036\n",
      "Epoch 610/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9938 - val_loss: 85.4052\n",
      "Epoch 611/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9968 - val_loss: 85.3962\n",
      "Epoch 612/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9913 - val_loss: 85.4039\n",
      "Epoch 613/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9953 - val_loss: 85.4118\n",
      "Epoch 614/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9902 - val_loss: 85.4020\n",
      "Epoch 615/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9928 - val_loss: 85.3997\n",
      "Epoch 616/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9911 - val_loss: 85.4061\n",
      "Epoch 617/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9938 - val_loss: 85.4045\n",
      "Epoch 618/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 82.9926 - val_loss: 85.4095\n",
      "Epoch 619/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9923 - val_loss: 85.4057\n",
      "Epoch 620/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9955 - val_loss: 85.4025\n",
      "Epoch 621/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9945 - val_loss: 85.4068\n",
      "Epoch 622/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9956 - val_loss: 85.4076\n",
      "Epoch 623/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9940 - val_loss: 85.4069\n",
      "Epoch 624/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9908 - val_loss: 85.3995\n",
      "Epoch 625/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9943 - val_loss: 85.4005\n",
      "Epoch 626/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9931 - val_loss: 85.4129\n",
      "Epoch 627/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9930 - val_loss: 85.4075\n",
      "Epoch 628/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9953 - val_loss: 85.3959\n",
      "Epoch 629/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9967 - val_loss: 85.4144\n",
      "Epoch 630/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9943 - val_loss: 85.3996\n",
      "Epoch 631/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 82.9959 - val_loss: 85.4006\n",
      "Epoch 632/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9950 - val_loss: 85.4197\n",
      "Epoch 633/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9895 - val_loss: 85.4027\n",
      "Epoch 634/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9972 - val_loss: 85.3962\n",
      "Epoch 635/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9910 - val_loss: 85.4125\n",
      "Epoch 636/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9886 - val_loss: 85.4022\n",
      "Epoch 637/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9921 - val_loss: 85.3899\n",
      "Epoch 638/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9828 - val_loss: 85.3924\n",
      "Epoch 639/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 82.9550 - val_loss: 85.0996\n",
      "Epoch 640/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 69.4113 - val_loss: 54.0798\n",
      "Epoch 641/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 40.1525 - val_loss: 31.0700\n",
      "Epoch 642/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 23.7264 - val_loss: 19.6186\n",
      "Epoch 643/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 15.1827 - val_loss: 13.0642\n",
      "Epoch 644/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 10.5019 - val_loss: 9.4308\n",
      "Epoch 645/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 7.6349 - val_loss: 7.0736\n",
      "Epoch 646/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 5.7921 - val_loss: 5.6020\n",
      "Epoch 647/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 4.6268 - val_loss: 4.5400\n",
      "Epoch 648/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3.7847 - val_loss: 3.8163\n",
      "Epoch 649/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 3.1865 - val_loss: 3.3169\n",
      "Epoch 650/2000\n",
      "20000/20000 [==============================] - 0s 12us/step - loss: 2.7255 - val_loss: 2.8960\n",
      "Epoch 651/2000\n",
      "20000/20000 [==============================] - 0s 10us/step - loss: 2.3664 - val_loss: 2.5966\n",
      "Epoch 652/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 2.1074 - val_loss: 2.3753\n",
      "Epoch 653/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1.8983 - val_loss: 2.2072\n",
      "Epoch 654/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1.7291 - val_loss: 2.0386\n",
      "Epoch 655/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1.5884 - val_loss: 1.9305\n",
      "Epoch 656/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1.4827 - val_loss: 1.8515\n",
      "Epoch 657/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 16us/step - loss: 1.3914 - val_loss: 1.7796\n",
      "Epoch 658/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1.3005 - val_loss: 1.7206\n",
      "Epoch 659/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1.2401 - val_loss: 1.6487\n",
      "Epoch 660/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1.1808 - val_loss: 1.6075\n",
      "Epoch 661/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1.1297 - val_loss: 1.5918\n",
      "Epoch 662/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1.0813 - val_loss: 1.5581\n",
      "Epoch 663/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 1.0404 - val_loss: 1.5208\n",
      "Epoch 664/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.9986 - val_loss: 1.5165\n",
      "Epoch 665/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.9735 - val_loss: 1.5107\n",
      "Epoch 666/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.9473 - val_loss: 1.4847\n",
      "Epoch 667/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.9158 - val_loss: 1.4539\n",
      "Epoch 668/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.9009 - val_loss: 1.4492\n",
      "Epoch 669/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.8759 - val_loss: 1.4605\n",
      "Epoch 670/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.8554 - val_loss: 1.4196\n",
      "Epoch 671/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.8283 - val_loss: 1.4306\n",
      "Epoch 672/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.8217 - val_loss: 1.4134\n",
      "Epoch 673/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.7862 - val_loss: 1.4262\n",
      "Epoch 674/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.7689 - val_loss: 1.4251\n",
      "Epoch 675/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.7628 - val_loss: 1.4273\n",
      "Epoch 676/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.7380 - val_loss: 1.3971\n",
      "Epoch 677/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.7256 - val_loss: 1.3895\n",
      "Epoch 678/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.7116 - val_loss: 1.3956\n",
      "Epoch 679/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.6982 - val_loss: 1.3922\n",
      "Epoch 680/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.6794 - val_loss: 1.3706\n",
      "Epoch 681/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.6714 - val_loss: 1.3795\n",
      "Epoch 682/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.6587 - val_loss: 1.3802\n",
      "Epoch 683/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.6467 - val_loss: 1.3764\n",
      "Epoch 684/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.6352 - val_loss: 1.3989\n",
      "Epoch 685/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.6292 - val_loss: 1.3640\n",
      "Epoch 686/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.6152 - val_loss: 1.3802\n",
      "Epoch 687/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.6077 - val_loss: 1.3672\n",
      "Epoch 688/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.5995 - val_loss: 1.3847\n",
      "Epoch 689/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.5948 - val_loss: 1.3771\n",
      "Epoch 690/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.5885 - val_loss: 1.3794\n",
      "Epoch 691/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.5796 - val_loss: 1.3757\n",
      "Epoch 692/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.5673 - val_loss: 1.3729\n",
      "Epoch 693/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.5607 - val_loss: 1.3717\n",
      "Epoch 694/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.5541 - val_loss: 1.3807\n",
      "Epoch 695/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.5504 - val_loss: 1.3862\n",
      "Epoch 696/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.5464 - val_loss: 1.3831\n",
      "Epoch 697/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.5348 - val_loss: 1.3714\n",
      "Epoch 698/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.5290 - val_loss: 1.3756\n",
      "Epoch 699/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.5257 - val_loss: 1.3805\n",
      "Epoch 700/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.5198 - val_loss: 1.3950\n",
      "Epoch 701/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.5123 - val_loss: 1.3881\n",
      "Epoch 702/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.5076 - val_loss: 1.3815\n",
      "Epoch 703/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.5035 - val_loss: 1.4039\n",
      "Epoch 704/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4998 - val_loss: 1.3766\n",
      "Epoch 705/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4959 - val_loss: 1.4088\n",
      "Epoch 706/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4899 - val_loss: 1.3774\n",
      "Epoch 707/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4845 - val_loss: 1.3902\n",
      "Epoch 708/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4778 - val_loss: 1.3964\n",
      "Epoch 709/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4761 - val_loss: 1.3904\n",
      "Epoch 710/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4741 - val_loss: 1.3962\n",
      "Epoch 711/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4661 - val_loss: 1.4045\n",
      "Epoch 712/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.4577 - val_loss: 1.4031\n",
      "Epoch 713/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.4586 - val_loss: 1.4110\n",
      "Epoch 714/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.4592 - val_loss: 1.4143\n",
      "Epoch 715/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.4541 - val_loss: 1.4167\n",
      "Epoch 716/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4467 - val_loss: 1.4042\n",
      "Epoch 717/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4437 - val_loss: 1.4075\n",
      "Epoch 718/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4403 - val_loss: 1.4198\n",
      "Epoch 719/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4357 - val_loss: 1.4382\n",
      "Epoch 720/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4310 - val_loss: 1.4360\n",
      "Epoch 721/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4264 - val_loss: 1.4302\n",
      "Epoch 722/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4248 - val_loss: 1.4316\n",
      "Epoch 723/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4238 - val_loss: 1.4414\n",
      "Epoch 724/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4194 - val_loss: 1.4440\n",
      "Epoch 725/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4160 - val_loss: 1.4479\n",
      "Epoch 726/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4119 - val_loss: 1.4464\n",
      "Epoch 727/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4090 - val_loss: 1.4589\n",
      "Epoch 728/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4076 - val_loss: 1.4593\n",
      "Epoch 729/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4092 - val_loss: 1.4499\n",
      "Epoch 730/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.4027 - val_loss: 1.4634\n",
      "Epoch 731/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3987 - val_loss: 1.4494\n",
      "Epoch 732/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3945 - val_loss: 1.4644\n",
      "Epoch 733/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3929 - val_loss: 1.4593\n",
      "Epoch 734/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3912 - val_loss: 1.4669\n",
      "Epoch 735/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3911 - val_loss: 1.4694\n",
      "Epoch 736/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3905 - val_loss: 1.5070\n",
      "Epoch 737/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3912 - val_loss: 1.4709\n",
      "Epoch 738/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3879 - val_loss: 1.4782\n",
      "Epoch 739/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3805 - val_loss: 1.4713\n",
      "Epoch 740/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3772 - val_loss: 1.4699\n",
      "Epoch 741/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3764 - val_loss: 1.4968\n",
      "Epoch 742/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3765 - val_loss: 1.4803\n",
      "Epoch 743/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3701 - val_loss: 1.4782\n",
      "Epoch 744/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3693 - val_loss: 1.4901\n",
      "Epoch 745/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3681 - val_loss: 1.5085\n",
      "Epoch 746/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.3660 - val_loss: 1.4967\n",
      "Epoch 747/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3617 - val_loss: 1.4968\n",
      "Epoch 748/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3599 - val_loss: 1.5027\n",
      "Epoch 749/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3596 - val_loss: 1.5189\n",
      "Epoch 750/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3565 - val_loss: 1.5028\n",
      "Epoch 751/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3566 - val_loss: 1.5127\n",
      "Epoch 752/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3525 - val_loss: 1.5076\n",
      "Epoch 753/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3532 - val_loss: 1.5125\n",
      "Epoch 754/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3528 - val_loss: 1.5381\n",
      "Epoch 755/2000\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 0.3503 - val_loss: 1.5204\n",
      "Epoch 756/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.3465 - val_loss: 1.5148\n",
      "Epoch 757/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3432 - val_loss: 1.5306\n",
      "Epoch 758/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3424 - val_loss: 1.5207\n",
      "Epoch 759/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3410 - val_loss: 1.5297\n",
      "Epoch 760/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3396 - val_loss: 1.5411\n",
      "Epoch 761/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3405 - val_loss: 1.5268\n",
      "Epoch 762/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.3381 - val_loss: 1.5460\n",
      "Epoch 763/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3373 - val_loss: 1.5364\n",
      "Epoch 764/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3383 - val_loss: 1.5267\n",
      "Epoch 765/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3323 - val_loss: 1.5432\n",
      "Epoch 766/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3326 - val_loss: 1.5547\n",
      "Epoch 767/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3316 - val_loss: 1.5439\n",
      "Epoch 768/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3295 - val_loss: 1.5510\n",
      "Epoch 769/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3296 - val_loss: 1.5487\n",
      "Epoch 770/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3290 - val_loss: 1.5400\n",
      "Epoch 771/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3288 - val_loss: 1.5604\n",
      "Epoch 772/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3241 - val_loss: 1.5586\n",
      "Epoch 773/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3201 - val_loss: 1.5474\n",
      "Epoch 774/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3204 - val_loss: 1.5669\n",
      "Epoch 775/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3184 - val_loss: 1.5658\n",
      "Epoch 776/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3198 - val_loss: 1.5652\n",
      "Epoch 777/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3201 - val_loss: 1.5615\n",
      "Epoch 778/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.3183 - val_loss: 1.5886\n",
      "Epoch 779/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3136 - val_loss: 1.5769\n",
      "Epoch 780/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3159 - val_loss: 1.5565\n",
      "Epoch 781/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3154 - val_loss: 1.5781\n",
      "Epoch 782/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3112 - val_loss: 1.5724\n",
      "Epoch 783/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3090 - val_loss: 1.5795\n",
      "Epoch 784/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3120 - val_loss: 1.5837\n",
      "Epoch 785/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3070 - val_loss: 1.5696\n",
      "Epoch 786/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.3073 - val_loss: 1.5814\n",
      "Epoch 787/2000\n",
      "20000/20000 [==============================] - 0s 12us/step - loss: 0.3037 - val_loss: 1.5851\n",
      "Epoch 788/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.3020 - val_loss: 1.5920\n",
      "Epoch 789/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3016 - val_loss: 1.5944\n",
      "Epoch 790/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.3012 - val_loss: 1.5975\n",
      "Epoch 791/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2977 - val_loss: 1.5913\n",
      "Epoch 792/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2958 - val_loss: 1.6108\n",
      "Epoch 793/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2966 - val_loss: 1.5871\n",
      "Epoch 794/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2972 - val_loss: 1.6152\n",
      "Epoch 795/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2988 - val_loss: 1.6044\n",
      "Epoch 796/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2966 - val_loss: 1.6116\n",
      "Epoch 797/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2929 - val_loss: 1.6131\n",
      "Epoch 798/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2918 - val_loss: 1.5941\n",
      "Epoch 799/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2912 - val_loss: 1.6011\n",
      "Epoch 800/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2893 - val_loss: 1.6114\n",
      "Epoch 801/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2893 - val_loss: 1.6114\n",
      "Epoch 802/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2891 - val_loss: 1.6310\n",
      "Epoch 803/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2892 - val_loss: 1.6120\n",
      "Epoch 804/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2860 - val_loss: 1.6072\n",
      "Epoch 805/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2844 - val_loss: 1.6275\n",
      "Epoch 806/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2834 - val_loss: 1.6306\n",
      "Epoch 807/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.2841 - val_loss: 1.6120\n",
      "Epoch 808/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2858 - val_loss: 1.6166\n",
      "Epoch 809/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2821 - val_loss: 1.6255\n",
      "Epoch 810/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2789 - val_loss: 1.6397\n",
      "Epoch 811/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2814 - val_loss: 1.6260\n",
      "Epoch 812/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2801 - val_loss: 1.6404\n",
      "Epoch 813/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2801 - val_loss: 1.6364\n",
      "Epoch 814/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2789 - val_loss: 1.6420\n",
      "Epoch 815/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2808 - val_loss: 1.6400\n",
      "Epoch 816/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2772 - val_loss: 1.6510\n",
      "Epoch 817/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2736 - val_loss: 1.6632\n",
      "Epoch 818/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2743 - val_loss: 1.6725\n",
      "Epoch 819/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2734 - val_loss: 1.6561\n",
      "Epoch 820/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2694 - val_loss: 1.6514\n",
      "Epoch 821/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2689 - val_loss: 1.6624\n",
      "Epoch 822/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2695 - val_loss: 1.6758\n",
      "Epoch 823/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2723 - val_loss: 1.6843\n",
      "Epoch 824/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2716 - val_loss: 1.6566\n",
      "Epoch 825/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2693 - val_loss: 1.6586\n",
      "Epoch 826/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2683 - val_loss: 1.6600\n",
      "Epoch 827/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2674 - val_loss: 1.6578\n",
      "Epoch 828/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2624 - val_loss: 1.6644\n",
      "Epoch 829/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2623 - val_loss: 1.6635\n",
      "Epoch 830/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2628 - val_loss: 1.6803\n",
      "Epoch 831/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2634 - val_loss: 1.6684\n",
      "Epoch 832/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2608 - val_loss: 1.6927\n",
      "Epoch 833/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2600 - val_loss: 1.6790\n",
      "Epoch 834/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2591 - val_loss: 1.6982\n",
      "Epoch 835/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2580 - val_loss: 1.6770\n",
      "Epoch 836/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2565 - val_loss: 1.6913\n",
      "Epoch 837/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2574 - val_loss: 1.6880\n",
      "Epoch 838/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2576 - val_loss: 1.6939\n",
      "Epoch 839/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2610 - val_loss: 1.6857\n",
      "Epoch 840/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2585 - val_loss: 1.6937\n",
      "Epoch 841/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2572 - val_loss: 1.6972\n",
      "Epoch 842/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2549 - val_loss: 1.7071\n",
      "Epoch 843/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2539 - val_loss: 1.6896\n",
      "Epoch 844/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2519 - val_loss: 1.7121\n",
      "Epoch 845/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2517 - val_loss: 1.7071\n",
      "Epoch 846/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2494 - val_loss: 1.6975\n",
      "Epoch 847/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2492 - val_loss: 1.7173\n",
      "Epoch 848/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2530 - val_loss: 1.7304\n",
      "Epoch 849/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2519 - val_loss: 1.6973\n",
      "Epoch 850/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2503 - val_loss: 1.7112\n",
      "Epoch 851/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2474 - val_loss: 1.7107\n",
      "Epoch 852/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2489 - val_loss: 1.7168\n",
      "Epoch 853/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2463 - val_loss: 1.7190\n",
      "Epoch 854/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2460 - val_loss: 1.7136\n",
      "Epoch 855/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2461 - val_loss: 1.7222\n",
      "Epoch 856/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2429 - val_loss: 1.7298\n",
      "Epoch 857/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2456 - val_loss: 1.7391\n",
      "Epoch 858/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2461 - val_loss: 1.7228\n",
      "Epoch 859/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2423 - val_loss: 1.7202\n",
      "Epoch 860/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2398 - val_loss: 1.7097\n",
      "Epoch 861/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2385 - val_loss: 1.7220\n",
      "Epoch 862/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2381 - val_loss: 1.7280\n",
      "Epoch 863/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2397 - val_loss: 1.7136\n",
      "Epoch 864/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2415 - val_loss: 1.7169\n",
      "Epoch 865/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2402 - val_loss: 1.7263\n",
      "Epoch 866/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2397 - val_loss: 1.7291\n",
      "Epoch 867/2000\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 0.2374 - val_loss: 1.7277\n",
      "Epoch 868/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2370 - val_loss: 1.7315\n",
      "Epoch 869/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2369 - val_loss: 1.7391\n",
      "Epoch 870/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2349 - val_loss: 1.7419\n",
      "Epoch 871/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2349 - val_loss: 1.7569\n",
      "Epoch 872/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2382 - val_loss: 1.7500\n",
      "Epoch 873/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2367 - val_loss: 1.7570\n",
      "Epoch 874/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2347 - val_loss: 1.7479\n",
      "Epoch 875/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2351 - val_loss: 1.7467\n",
      "Epoch 876/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2341 - val_loss: 1.7649\n",
      "Epoch 877/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2330 - val_loss: 1.7611\n",
      "Epoch 878/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2361 - val_loss: 1.7744\n",
      "Epoch 879/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2365 - val_loss: 1.7653\n",
      "Epoch 880/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2327 - val_loss: 1.7631\n",
      "Epoch 881/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2300 - val_loss: 1.7696\n",
      "Epoch 882/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2302 - val_loss: 1.7756\n",
      "Epoch 883/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.2289 - val_loss: 1.7873\n",
      "Epoch 884/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.2336 - val_loss: 1.7645\n",
      "Epoch 885/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.2308 - val_loss: 1.7765\n",
      "Epoch 886/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2296 - val_loss: 1.7748\n",
      "Epoch 887/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2274 - val_loss: 1.7880\n",
      "Epoch 888/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2280 - val_loss: 1.7973\n",
      "Epoch 889/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2275 - val_loss: 1.7763\n",
      "Epoch 890/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2294 - val_loss: 1.7955\n",
      "Epoch 891/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2296 - val_loss: 1.7874\n",
      "Epoch 892/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2258 - val_loss: 1.8006\n",
      "Epoch 893/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2267 - val_loss: 1.8013\n",
      "Epoch 894/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2244 - val_loss: 1.8022\n",
      "Epoch 895/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2232 - val_loss: 1.8146\n",
      "Epoch 896/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2267 - val_loss: 1.8070\n",
      "Epoch 897/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2221 - val_loss: 1.8156\n",
      "Epoch 898/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2227 - val_loss: 1.8276\n",
      "Epoch 899/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2263 - val_loss: 1.8166\n",
      "Epoch 900/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.2227 - val_loss: 1.8329\n",
      "Epoch 901/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.2221 - val_loss: 1.8494\n",
      "Epoch 902/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2212 - val_loss: 1.8415\n",
      "Epoch 903/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2192 - val_loss: 1.8316\n",
      "Epoch 904/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2192 - val_loss: 1.8345\n",
      "Epoch 905/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2182 - val_loss: 1.8192\n",
      "Epoch 906/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2171 - val_loss: 1.8245\n",
      "Epoch 907/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2179 - val_loss: 1.8295\n",
      "Epoch 908/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2189 - val_loss: 1.8261\n",
      "Epoch 909/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2165 - val_loss: 1.8424\n",
      "Epoch 910/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2137 - val_loss: 1.8421\n",
      "Epoch 911/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2140 - val_loss: 1.8534\n",
      "Epoch 912/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2154 - val_loss: 1.8528\n",
      "Epoch 913/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2167 - val_loss: 1.8333\n",
      "Epoch 914/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2178 - val_loss: 1.8464\n",
      "Epoch 915/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2148 - val_loss: 1.8406\n",
      "Epoch 916/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2154 - val_loss: 1.8568\n",
      "Epoch 917/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2158 - val_loss: 1.8416\n",
      "Epoch 918/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2146 - val_loss: 1.8588\n",
      "Epoch 919/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2125 - val_loss: 1.8521\n",
      "Epoch 920/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2137 - val_loss: 1.8564\n",
      "Epoch 921/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2127 - val_loss: 1.8543\n",
      "Epoch 922/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2133 - val_loss: 1.8686\n",
      "Epoch 923/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2112 - val_loss: 1.8860\n",
      "Epoch 924/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2098 - val_loss: 1.8686\n",
      "Epoch 925/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2101 - val_loss: 1.8675\n",
      "Epoch 926/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2125 - val_loss: 1.8731\n",
      "Epoch 927/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2125 - val_loss: 1.8935\n",
      "Epoch 928/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2086 - val_loss: 1.8705\n",
      "Epoch 929/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2087 - val_loss: 1.8791\n",
      "Epoch 930/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2103 - val_loss: 1.8785\n",
      "Epoch 931/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2115 - val_loss: 1.9006\n",
      "Epoch 932/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2112 - val_loss: 1.8937\n",
      "Epoch 933/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2101 - val_loss: 1.8911\n",
      "Epoch 934/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2064 - val_loss: 1.8645\n",
      "Epoch 935/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2080 - val_loss: 1.8804\n",
      "Epoch 936/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2071 - val_loss: 1.8835\n",
      "Epoch 937/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2060 - val_loss: 1.8816\n",
      "Epoch 938/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2097 - val_loss: 1.9002\n",
      "Epoch 939/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2123 - val_loss: 1.8915\n",
      "Epoch 940/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2112 - val_loss: 1.8839\n",
      "Epoch 941/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2071 - val_loss: 1.8824\n",
      "Epoch 942/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2087 - val_loss: 1.8991\n",
      "Epoch 943/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2073 - val_loss: 1.8800\n",
      "Epoch 944/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2054 - val_loss: 1.8878\n",
      "Epoch 945/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2032 - val_loss: 1.8961\n",
      "Epoch 946/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1996 - val_loss: 1.8881\n",
      "Epoch 947/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2032 - val_loss: 1.9068\n",
      "Epoch 948/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2030 - val_loss: 1.8794\n",
      "Epoch 949/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2062 - val_loss: 1.8846\n",
      "Epoch 950/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2044 - val_loss: 1.9070\n",
      "Epoch 951/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2058 - val_loss: 1.9060\n",
      "Epoch 952/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2046 - val_loss: 1.9110\n",
      "Epoch 953/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2026 - val_loss: 1.9052\n",
      "Epoch 954/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2006 - val_loss: 1.9201\n",
      "Epoch 955/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1992 - val_loss: 1.9048\n",
      "Epoch 956/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.2004 - val_loss: 1.9095\n",
      "Epoch 957/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2009 - val_loss: 1.9185\n",
      "Epoch 958/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2018 - val_loss: 1.9025\n",
      "Epoch 959/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2054 - val_loss: 1.9033\n",
      "Epoch 960/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2030 - val_loss: 1.9098\n",
      "Epoch 961/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1997 - val_loss: 1.9061\n",
      "Epoch 962/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2009 - val_loss: 1.9188\n",
      "Epoch 963/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2013 - val_loss: 1.9074\n",
      "Epoch 964/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2010 - val_loss: 1.9143\n",
      "Epoch 965/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.2010 - val_loss: 1.9154\n",
      "Epoch 966/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1985 - val_loss: 1.9070\n",
      "Epoch 967/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1969 - val_loss: 1.9163\n",
      "Epoch 968/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1951 - val_loss: 1.9162\n",
      "Epoch 969/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1966 - val_loss: 1.9178\n",
      "Epoch 970/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1953 - val_loss: 1.9194\n",
      "Epoch 971/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1983 - val_loss: 1.9081\n",
      "Epoch 972/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1965 - val_loss: 1.8953\n",
      "Epoch 973/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1994 - val_loss: 1.9020\n",
      "Epoch 974/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1989 - val_loss: 1.9138\n",
      "Epoch 975/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1971 - val_loss: 1.9049\n",
      "Epoch 976/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1953 - val_loss: 1.9123\n",
      "Epoch 977/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1946 - val_loss: 1.9183\n",
      "Epoch 978/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1940 - val_loss: 1.9078\n",
      "Epoch 979/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1948 - val_loss: 1.9194\n",
      "Epoch 980/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.1945 - val_loss: 1.9318\n",
      "Epoch 981/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.1950 - val_loss: 1.9257\n",
      "Epoch 982/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.1973 - val_loss: 1.9124\n",
      "Epoch 983/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1977 - val_loss: 1.9339\n",
      "Epoch 984/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1946 - val_loss: 1.9159\n",
      "Epoch 985/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1931 - val_loss: 1.9236\n",
      "Epoch 986/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1941 - val_loss: 1.9082\n",
      "Epoch 987/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1933 - val_loss: 1.9184\n",
      "Epoch 988/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1923 - val_loss: 1.9129\n",
      "Epoch 989/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1917 - val_loss: 1.9235\n",
      "Epoch 990/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1906 - val_loss: 1.9206\n",
      "Epoch 991/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1918 - val_loss: 1.9401\n",
      "Epoch 992/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1927 - val_loss: 1.9319\n",
      "Epoch 993/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1900 - val_loss: 1.9199\n",
      "Epoch 994/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.1909 - val_loss: 1.9207\n",
      "Epoch 995/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.1943 - val_loss: 1.9267\n",
      "Epoch 996/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1947 - val_loss: 1.9201\n",
      "Epoch 997/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1926 - val_loss: 1.9404\n",
      "Epoch 998/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1926 - val_loss: 1.9346\n",
      "Epoch 999/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1972 - val_loss: 1.9293\n",
      "Epoch 1000/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1982 - val_loss: 1.9214\n",
      "Epoch 1001/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1932 - val_loss: 1.9169\n",
      "Epoch 1002/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1922 - val_loss: 1.9306\n",
      "Epoch 1003/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1936 - val_loss: 1.9194\n",
      "Epoch 1004/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1940 - val_loss: 1.9196\n",
      "Epoch 1005/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1939 - val_loss: 1.9169\n",
      "Epoch 1006/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1912 - val_loss: 1.9199\n",
      "Epoch 1007/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1872 - val_loss: 1.9316\n",
      "Epoch 1008/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1866 - val_loss: 1.9337\n",
      "Epoch 1009/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1849 - val_loss: 1.9351\n",
      "Epoch 1010/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1836 - val_loss: 1.9387\n",
      "Epoch 1011/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1834 - val_loss: 1.9352\n",
      "Epoch 1012/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1848 - val_loss: 1.9357\n",
      "Epoch 1013/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1875 - val_loss: 1.9382\n",
      "Epoch 1014/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1896 - val_loss: 1.9370\n",
      "Epoch 1015/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1886 - val_loss: 1.9556\n",
      "Epoch 1016/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1879 - val_loss: 1.9263\n",
      "Epoch 1017/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1857 - val_loss: 1.9280\n",
      "Epoch 1018/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1869 - val_loss: 1.9557\n",
      "Epoch 1019/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1860 - val_loss: 1.9569\n",
      "Epoch 1020/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1858 - val_loss: 1.9639\n",
      "Epoch 1021/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1856 - val_loss: 1.9497\n",
      "Epoch 1022/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1842 - val_loss: 1.9544\n",
      "Epoch 1023/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1873 - val_loss: 1.9629\n",
      "Epoch 1024/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1858 - val_loss: 1.9596\n",
      "Epoch 1025/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1874 - val_loss: 1.9728\n",
      "Epoch 1026/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1883 - val_loss: 1.9399\n",
      "Epoch 1027/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1851 - val_loss: 1.9457\n",
      "Epoch 1028/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1848 - val_loss: 1.9648\n",
      "Epoch 1029/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1827 - val_loss: 1.9444\n",
      "Epoch 1030/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1830 - val_loss: 1.9697\n",
      "Epoch 1031/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1832 - val_loss: 1.9477\n",
      "Epoch 1032/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1825 - val_loss: 1.9708\n",
      "Epoch 1033/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1836 - val_loss: 1.9512\n",
      "Epoch 1034/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1831 - val_loss: 1.9681\n",
      "Epoch 1035/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1839 - val_loss: 1.9560\n",
      "Epoch 1036/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1828 - val_loss: 1.9354\n",
      "Epoch 1037/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1828 - val_loss: 1.9528\n",
      "Epoch 1038/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1812 - val_loss: 1.9427\n",
      "Epoch 1039/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1794 - val_loss: 1.9509\n",
      "Epoch 1040/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1812 - val_loss: 1.9657\n",
      "Epoch 1041/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1833 - val_loss: 1.9521\n",
      "Epoch 1042/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1861 - val_loss: 1.9819\n",
      "Epoch 1043/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1849 - val_loss: 1.9485\n",
      "Epoch 1044/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1850 - val_loss: 1.9687\n",
      "Epoch 1045/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1828 - val_loss: 1.9661\n",
      "Epoch 1046/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1798 - val_loss: 1.9755\n",
      "Epoch 1047/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1826 - val_loss: 1.9609\n",
      "Epoch 1048/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1823 - val_loss: 1.9517\n",
      "Epoch 1049/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1806 - val_loss: 1.9517\n",
      "Epoch 1050/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1791 - val_loss: 1.9621\n",
      "Epoch 1051/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1776 - val_loss: 1.9515\n",
      "Epoch 1052/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1795 - val_loss: 1.9666\n",
      "Epoch 1053/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1859 - val_loss: 1.9783\n",
      "Epoch 1054/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1858 - val_loss: 1.9559\n",
      "Epoch 1055/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1858 - val_loss: 1.9552\n",
      "Epoch 1056/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1817 - val_loss: 1.9763\n",
      "Epoch 1057/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1800 - val_loss: 1.9477\n",
      "Epoch 1058/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1808 - val_loss: 1.9385\n",
      "Epoch 1059/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1808 - val_loss: 1.9522\n",
      "Epoch 1060/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1787 - val_loss: 1.9815\n",
      "Epoch 1061/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1782 - val_loss: 1.9434\n",
      "Epoch 1062/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1774 - val_loss: 1.9430\n",
      "Epoch 1063/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1789 - val_loss: 1.9559\n",
      "Epoch 1064/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1832 - val_loss: 1.9291\n",
      "Epoch 1065/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1790 - val_loss: 1.9294\n",
      "Epoch 1066/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1793 - val_loss: 1.9300\n",
      "Epoch 1067/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1770 - val_loss: 1.9716\n",
      "Epoch 1068/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1764 - val_loss: 1.9273\n",
      "Epoch 1069/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1785 - val_loss: 1.9436\n",
      "Epoch 1070/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1760 - val_loss: 1.9438\n",
      "Epoch 1071/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1767 - val_loss: 1.9581\n",
      "Epoch 1072/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1740 - val_loss: 1.9486\n",
      "Epoch 1073/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1749 - val_loss: 1.9536\n",
      "Epoch 1074/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1740 - val_loss: 1.9582\n",
      "Epoch 1075/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1729 - val_loss: 1.9598\n",
      "Epoch 1076/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1736 - val_loss: 1.9654\n",
      "Epoch 1077/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.1722 - val_loss: 1.9772\n",
      "Epoch 1078/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.1807 - val_loss: 1.9739\n",
      "Epoch 1079/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1776 - val_loss: 1.9690\n",
      "Epoch 1080/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1740 - val_loss: 1.9632\n",
      "Epoch 1081/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1728 - val_loss: 1.9543\n",
      "Epoch 1082/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1736 - val_loss: 1.9812\n",
      "Epoch 1083/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1726 - val_loss: 1.9789\n",
      "Epoch 1084/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1756 - val_loss: 1.9703\n",
      "Epoch 1085/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1757 - val_loss: 1.9938\n",
      "Epoch 1086/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1781 - val_loss: 1.9640\n",
      "Epoch 1087/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1746 - val_loss: 1.9688\n",
      "Epoch 1088/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.1739 - val_loss: 1.9618\n",
      "Epoch 1089/2000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.1727 - val_loss: 1.9568\n",
      "Epoch 1090/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1734 - val_loss: 1.9533\n",
      "Epoch 1091/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1719 - val_loss: 1.9682\n",
      "Epoch 1092/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1744 - val_loss: 1.9806\n",
      "Epoch 1093/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1729 - val_loss: 1.9874\n",
      "Epoch 1094/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1717 - val_loss: 1.9616\n",
      "Epoch 1095/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1732 - val_loss: 1.9882\n",
      "Epoch 1096/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1768 - val_loss: 1.9689\n",
      "Epoch 1097/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1762 - val_loss: 1.9706\n",
      "Epoch 1098/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1731 - val_loss: 1.9682\n",
      "Epoch 1099/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1742 - val_loss: 1.9785\n",
      "Epoch 1100/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1751 - val_loss: 1.9864\n",
      "Epoch 1101/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1727 - val_loss: 1.9943\n",
      "Epoch 1102/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1696 - val_loss: 1.9813\n",
      "Epoch 1103/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1699 - val_loss: 1.9777\n",
      "Epoch 1104/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1711 - val_loss: 1.9938\n",
      "Epoch 1105/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1717 - val_loss: 1.9867\n",
      "Epoch 1106/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1724 - val_loss: 2.0138\n",
      "Epoch 1107/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1713 - val_loss: 1.9867\n",
      "Epoch 1108/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1712 - val_loss: 1.9938\n",
      "Epoch 1109/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1698 - val_loss: 2.0001\n",
      "Epoch 1110/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1711 - val_loss: 1.9961\n",
      "Epoch 1111/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1708 - val_loss: 2.0037\n",
      "Epoch 1112/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1707 - val_loss: 2.0131\n",
      "Epoch 1113/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1706 - val_loss: 1.9917\n",
      "Epoch 1114/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1721 - val_loss: 2.0172\n",
      "Epoch 1115/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1723 - val_loss: 1.9930\n",
      "Epoch 1116/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1736 - val_loss: 2.0060\n",
      "Epoch 1117/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1687 - val_loss: 2.0123\n",
      "Epoch 1118/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1678 - val_loss: 2.0065\n",
      "Epoch 1119/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1670 - val_loss: 2.0262\n",
      "Epoch 1120/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1670 - val_loss: 2.0075\n",
      "Epoch 1121/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1682 - val_loss: 2.0171\n",
      "Epoch 1122/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1670 - val_loss: 2.0184\n",
      "Epoch 1123/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1705 - val_loss: 2.0268\n",
      "Epoch 1124/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1710 - val_loss: 2.0282\n",
      "Epoch 1125/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1705 - val_loss: 2.0284\n",
      "Epoch 1126/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1727 - val_loss: 2.0274\n",
      "Epoch 1127/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1680 - val_loss: 2.0212\n",
      "Epoch 1128/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1664 - val_loss: 2.0216\n",
      "Epoch 1129/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1695 - val_loss: 2.0130\n",
      "Epoch 1130/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1696 - val_loss: 2.0433\n",
      "Epoch 1131/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1686 - val_loss: 2.0334\n",
      "Epoch 1132/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1683 - val_loss: 2.0327\n",
      "Epoch 1133/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1688 - val_loss: 2.0123\n",
      "Epoch 1134/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1709 - val_loss: 2.0350\n",
      "Epoch 1135/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1707 - val_loss: 2.0338\n",
      "Epoch 1136/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1687 - val_loss: 2.0344\n",
      "Epoch 1137/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1662 - val_loss: 2.0426\n",
      "Epoch 1138/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1664 - val_loss: 2.0333\n",
      "Epoch 1139/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1657 - val_loss: 2.0404\n",
      "Epoch 1140/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1662 - val_loss: 2.0230\n",
      "Epoch 1141/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1675 - val_loss: 2.0316\n",
      "Epoch 1142/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1649 - val_loss: 2.0414\n",
      "Epoch 1143/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1652 - val_loss: 2.0506\n",
      "Epoch 1144/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1676 - val_loss: 2.0529\n",
      "Epoch 1145/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1691 - val_loss: 2.0331\n",
      "Epoch 1146/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1691 - val_loss: 2.0421\n",
      "Epoch 1147/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1681 - val_loss: 2.0374\n",
      "Epoch 1148/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1656 - val_loss: 2.0582\n",
      "Epoch 1149/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1667 - val_loss: 2.0584\n",
      "Epoch 1150/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1666 - val_loss: 2.0568\n",
      "Epoch 1151/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1680 - val_loss: 2.0594\n",
      "Epoch 1152/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1669 - val_loss: 2.0803\n",
      "Epoch 1153/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1656 - val_loss: 2.0502\n",
      "Epoch 1154/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1646 - val_loss: 2.0630\n",
      "Epoch 1155/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1666 - val_loss: 2.0576\n",
      "Epoch 1156/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1687 - val_loss: 2.0491\n",
      "Epoch 1157/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1682 - val_loss: 2.0501\n",
      "Epoch 1158/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1704 - val_loss: 2.0636\n",
      "Epoch 1159/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1657 - val_loss: 2.0500\n",
      "Epoch 1160/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1632 - val_loss: 2.0308\n",
      "Epoch 1161/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1630 - val_loss: 2.0444\n",
      "Epoch 1162/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1625 - val_loss: 2.0467\n",
      "Epoch 1163/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1620 - val_loss: 2.0436\n",
      "Epoch 1164/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1632 - val_loss: 2.0438\n",
      "Epoch 1165/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1658 - val_loss: 2.0511\n",
      "Epoch 1166/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1628 - val_loss: 2.0413\n",
      "Epoch 1167/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1639 - val_loss: 2.0329\n",
      "Epoch 1168/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1647 - val_loss: 2.0473\n",
      "Epoch 1169/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1685 - val_loss: 2.0472\n",
      "Epoch 1170/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1687 - val_loss: 2.0417\n",
      "Epoch 1171/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1686 - val_loss: 2.0305\n",
      "Epoch 1172/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1652 - val_loss: 2.0439\n",
      "Epoch 1173/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1660 - val_loss: 2.0563\n",
      "Epoch 1174/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1642 - val_loss: 2.0660\n",
      "Epoch 1175/2000\n",
      "20000/20000 [==============================] - 0s 12us/step - loss: 0.1660 - val_loss: 2.0540\n",
      "Epoch 1176/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1661 - val_loss: 2.0491\n",
      "Epoch 1177/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1654 - val_loss: 2.0311\n",
      "Epoch 1178/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1677 - val_loss: 2.0720\n",
      "Epoch 1179/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1675 - val_loss: 2.0469\n",
      "Epoch 1180/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1636 - val_loss: 2.0395\n",
      "Epoch 1181/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1624 - val_loss: 2.0350\n",
      "Epoch 1182/2000\n",
      "20000/20000 [==============================] - 0s 12us/step - loss: 0.1617 - val_loss: 2.0459\n",
      "Epoch 1183/2000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.1601 - val_loss: 2.0491\n",
      "Epoch 1184/2000\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.1607 - val_loss: 2.0637\n",
      "Epoch 1185/2000\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1583 - val_loss: 2.0418\n",
      "Epoch 01185: early stopping\n"
     ]
    }
   ],
   "source": [
    "early_stop=EarlyStopping(monitor='val_loss', min_delta=0, patience=500, verbose=2, mode='auto', baseline=None)\n",
    "history = model.fit(x_train, Y_train, batch_size=batch_size, epochs=nb_epoch,\n",
    "          verbose=1, validation_data=(x_val, Y_val),\n",
    "          callbacks=[tensorboard,early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test mse: 1.844283432483673\n",
      "(20000,)\n",
      "(20000,)\n",
      "[ 0.6148826   0.77969161 -0.71206363  0.02911938 -1.41692371 -0.35783849\n",
      "  2.06195298  2.52703914  1.25229743  0.60913885]\n",
      "(20000,)\n",
      "(20000, 1)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, Y_test, verbose=0)\n",
    "print('Test mse:', score)\n",
    "# print('Test mae:', score[1])\n",
    "Y_test_predicted=model.predict(x_test)\n",
    "x_test_array=np.asarray(Y_test)\n",
    "print(x_test_array.shape)\n",
    "error_prediction=Y_test-Y_test_predicted.flatten()\n",
    "print(error_prediction.shape)\n",
    "print(error_prediction[:10])\n",
    "print(Y_test.shape)\n",
    "print(Y_test_predicted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model error')\n",
    "plt.ylabel('error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(error_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,)\n",
      "(401,)\n",
      "[[Model]]\n",
      "    Model(gaussian)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 25\n",
      "    # data points      = 400\n",
      "    # variables        = 3\n",
      "    chi-square         = 46320.1503\n",
      "    reduced chi-square = 116.675442\n",
      "    Akaike info crit   = 1906.74712\n",
      "    Bayesian info crit = 1918.72152\n",
      "[[Variables]]\n",
      "    amp:  804.373734 +/- 3.21352601 (0.40%) (init = 1000)\n",
      "    cen: -0.11375305 +/- 0.00491255 (4.32%) (init = 0)\n",
      "    wid:  1.50602776 +/- 0.00694739 (0.46%) (init = 1)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(amp, wid) = -0.577\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8nGW9///XJ2uzNF2ytEnbJC2U0lIWMUpZDiiIIhy+IKLH47B45BihckDwcFji7+BCOHr0J8LvcViqFOqXqWhBj+hB+WJBwC8UKJWtFNpCm25pkknTJmmaZrt+f9z3ZJ02k8wkMyXv5+Mxj8xc93blTmbec9/3dV+XOecQEZGJJyXRFRARkcRQAIiITFAKABGRCUoBICIyQSkAREQmKAWAiMgEpQAQEZmgFAAiIhOUAkBEZIJKS3QFDqegoMCVl5cnuhoiIkeU1157LeScKxxuvqQOgPLyctauXZvoaoiIHFHMrCaa+XQKSERkglIAiIhMUAoAEZEJSgEgIjJBDRsAZrbczOrN7O1+ZdPN7Gkz2+T/nOaXm5ndY2abzexNMzu53zJX+vNvMrMrx+bXERGRaEVzBPAwcN6gsluA1c65+cBq/zXAZ4H5/qMSuA+8wABuB04BPg7cHg4NERFJjGEDwDn3PLBnUPFFwAr/+Qrg4n7lv3CeNcBUMysGPgM87Zzb45xrAp5maKiIiMg4Gu01gBnOuVoA/2eRXz4L2N5vvh1+2aHKRT6U2tvbeeCBB+jo6Eh0VUQOKd4XgS1CmTtM+dAVmFWa2VozW9vQ0BDXyomMl5tuuomrr76aVatWJboqIoc02gCo80/t4P+s98t3AHP6zTcb2HWY8iGcc8uccxXOuYrCwmHvZBZJSmlp3k3269atS3BNRA5ttAHwBBBuyXMl8Lt+5Vf4rYGWAPv8U0RPAZ82s2n+xd9P+2UiH0p33XUXp512Gi+++GKiqyJySNE0A/0l8BKwwMx2mNlVwA+Ac81sE3Cu/xrgSeADYDPwM2ApgHNuD/B94FX/8T2/TORD6/TTT2fdunV0dXUluioiEZlzEU/FJ4WKigqnzuDkSLNy5Upuuukmnn76aebNm8ekSZMSXSWZYMzsNedcxXDz6U5gkTjbsmULu3btYu7cufrwl6SmABCJs5qaGoqKimhqauL666/XhWBJWgoAkTirqamhrKyMjo4O7rnnHl5//fVEV0kkIgWASJzt3r2b4uJiZs6cCUBtbW2CayQSWVKPCCZyJLrggguYPXs2kyZNYurUqezevTvRVRKJSAEgEmd33nln7/OZM2fqCECSlk4BicSRc47u7u7e17NmzWL//v0JrJHIoSkAROJo165dpKen89BDDwHw9NNP88c//jHBtRKJTAEgEkd79uzBOcfkyZMBMIvUD6JIclAAiMRRY2MjANOnTwfgscceIxAIJLJKIoekABCJo3AA5OfnA/Duu++ycuVKDh48mMhqiUSkABCJoz17vD4OwwEwdepUAPbt25ewOokcigJAJI4WLVrEdddd1xsA06Z5Q1/v3bs3kdUSiUj3AYjE0emnn87pp5/e+zp8BKAAkGSkIwCROGppaeHAgQO9r/Pz8ykuLtbYwJKUdAQgEkdf//rXefXVV9m0aRMAS5YsYdeuiKOfiiScjgBE4qi5ubn3HgCRZKcAEImjlpYW8vLyel93dnZy4YUXEgwGE1grkcgUACJx1NzcPCAA0tLSeOqpp3jrrbcSWCuRyBQAInE0OADMjMmTJ9Pa2prAWolEpovAInF0ww03MGfOnAFlubm56hFUkpICQCSOrr322iFlubm5OgKQpKRTQCJx0tPTw5YtW4Z821+4cCFFRUUJqpXIoSkAROKksbGRefPmsXz58gHljz32GP/1X/+VoFqJHJoCQCROWlpaAAZcBBZJZgoAkThpbm4GhgbAHXfcwSWXXJKIKokclgJAJE7CAfDKK3mUl0NKCpSXwzPPbOOll15KaN1EIlErIJE4CQfAj340mfC48DU1sH17LhkZagUkyUdHACJxsmjRIrKz76a7e+6A8p6eXNrb99PT05OgmolEpgAQiZN58+bR1nYdUDhoSi7gBnQTLZIMFAAicVJXVwe8DXQPmlIOnKYxASTpxBQAZnaDma03s7fN7JdmNsnM5prZy2a2ycx+ZWYZ/ryZ/uvN/vTyePwCIskgGIRjj30IOB4YPAD8F8nP/7+9w0OKJItRB4CZzQKuAyqcc4uBVOBLwA+Bu5xz84Em4Cp/kauAJufc0cBd/nwiR7ylS+Hyy2Hv3jbAgKwB0zMy4O67E1I1kcOK9RRQGpBlZmlANlALnA085k9fAVzsP7/If40//Rwzsxi3L5JQwSDcfz84B7AfyOYj/I1n+QSX8DhlZXDbbS9z553HsXbt2gTXVmSgUQeAc24n8GNgG94H/z7gNWCvc67Ln20HMMt/PgvY7i/b5c+fP9rtiySDqqrwhz+EA+DXfJFP8Bw/55+Z0r2H73ynm3feeYdVqxoTWFORoWI5BTQN71v9XKAEyAE+G2HW8Nsj0rd9N7jAzCrNbK2ZrW1oaBht9UTGxbZt/V/tp4I0juZ97uNqprGXk3b8Hq8VEPz0p61oYDBJJrGcAvoUsMU51+Cc6wR+A5wGTPVPCQHMBsIjYu8A5gD406cAewav1Dm3zDlX4ZyrKCwc3JxOJLmUlvZ/9XUuYQkdpHMbd1JPIeewmnAAdHS0UlWViFqKRBZLAGwDlphZtn8u/xzgHeBZ4FJ/niuB3/nPn/Bf409/xjk35AhA5EhSXQ3Z2eFXZ/Bx9vEGJ7KXaTzLJ/0AyPGn7x90xCCSWLFcA3gZ72LuOuAtf13LgJuBG81sM945/gf9RR4E8v3yG4FbYqi3SFIIBGDZMkhNBXiNk1nLOk4G4K+cwSx2MZP9wLlAMdOnJ7CyIoPE1BeQc+524PZBxR8AH48wbzvwhVi2J5KMAgGvGehcrmAazbzGRwFYz3EAHMcH7Ob/ANDS4rUcCgQSVl2RXroTWCQOSkvhRJoAeJ2TgL4AWMzbvfN1dKDrAJI0FAAicVBdDfPxhoJ8jwUA1FNEiHyOYz1wCvAtYHDLIZHEUQCIxEEgAMemtlNPFs1MASAlxVjPcSxkA95N8bXA4JZDIomjABCJk3k9nRwomYZz3s1hv/gF1KQexTw+wGsJ1Ep2tne0IJIMFAAiceCc45T8fKZ89KO9ZYEAnHhxOSXUkkk2mZmtLFumC8CSPBQAInHwq4fbyQqFuOv3FZSX03vH74kXeYPDXHZGCiec0KoPf0kqGhJSJEbBIPzgms18CdhKHjU1UFnpTQvM9QLgMwsWkJ+vrq8kuegIQCRGVVUw/eCbAOz0L/S2tfnNPcvLAfhCRQU//KF6QJfkogAQidG2bTALr23nzt7Ob/3mniUlkJ4OW7cmpnIih6EAEIlRaSnMYicAu5g9oJyUFCgu5s0//YmpU6cmqIYikSkARGJUXQ2lqbtoBZr9AeEHNPcsLia3tZV9+/ZpXGBJKgoAkRgFAvB38+r8Y4BcysoY2NyzuJi8/d5dwq2trQmqpchQCgCRODhuaidFJ55IS8t8tm4d2NZ/Y0sxKXUtAJxwwn4NCiNJQwEgEgfp9fVMW7yY3NzcAeXBIDz6fDHT3X4ygJ0726isRCEgSUEBIBKDYBDKyxwdNTu55zfNrFjROWB6VRVs6ywGYCb/COT0NREVSTAFgMgoBYPeDV/7t4XIoIvNB37PNde4Ad/ut22DWrwAKOY68FsJqUdQSQYKAJFRqqrybvjqawKawoEDGQO+3ZeW9gVACTuA7t5ykURTAIiMUvhbfAm7ANjJpAHl4DUF3ZtVAkAxXwD+Wz2CStJQX0Aio1RaCjU1fUcAO8ntLQ8LBMB6Cum+IoViesjP38/dd6tHUEkOOgIQGaXqau+Gr3AA7CY34rf7L1+eCjMKKQbuuKNNH/6SNHQEIDJK4Q9yu7qW+tZ8Cop/y49+dIhv9zNnUlxXxwb/hjCRZKAAEIlBIAA83gAbZ7Lr7RMOOZ/NmkXxG2+wVgEgSUSngERiFQpR7xx/+tOfDjlLSkkJR2dns2TJknGsmMjhKQBEYhUK8cbOndx///2Hnqe4mMkHDvDps88ev3qJDEMBIBKrUIgG58jOzj70PDNngnO0btkyfvUSGYYCQCQWPT3Q2Ehddzc5OTmHnq/Q6yb6O9deO04VExmeAkAkFk1N0NPD7q6uwwdAQQEAGfv2jVPFRIanABCJRSgEwK6OjkMGQDAInw54RwDbXmtRT6CSNNQMVCQWfgD86KGHSD3//CGTwx3G5bZ5ATC1q5XKSm+abgiTRNMRgEgs/ACYuXgxhf55/v7CHcY1kg9AAW3qDlqShgJAJBZ+ANy7ahXr168fMjncMVw3aTSSSyGLBpSLJFJMAWBmU83sMTN718w2mNmpZjbdzJ42s03+z2n+vGZm95jZZjN708xOjs+vIJJADQ0A/OsPf8gbb7wxZHL/juFClFDIjCHlIokS6xHA3cCfnHPHAicCG4BbgNXOufnAav81wGeB+f6jErgvxm2LJF4oRE9mJgcg4kXgcIdxAA1Mp5Dt6g5aksaoA8DM8oAzgQcBnHMdzrm9wEXACn+2FcDF/vOLgF84zxpgqpkVj7rmIskgFKJjyhQgcgAEArBsGZSVQQNNFLKG++/v0QVgSQqxHAHMAxqAh8zsb2b2czPLAWY452oB/J9F/vyzgO39lt/hlw1gZpVmttbM1jb4h9ciSSsU4uDkyUDkAAAvBLZuhbkfn0IBcMklB8avfiKHEUsApAEnA/c55z4C7KfvdE8kFqHMDSlwbplzrsI5VxGpVYVIUgmFaM/1BoI5XFcQwSCsfnMqBcDCBboXQJJDLAGwA9jhnHvZf/0YXiDUhU/t+D/r+80/p9/ys8EfS0/kSNXQQOHChdTV1bFo0aKIs4TvBdjePp00oHXnbiorUQhIwo06AJxzu4HtZrbALzoHeAd4ArjSL7sS+J3//AngCr810BJgX/hUkcgRKxQipaiIoqIi0tPTI84SvhcghNcdRCE7dC+AJIVYWwH9CxA0szeBk4A7gR8A55rZJuBc/zXAk8AHwGbgZ8DSGLctklC/XNEBzc38P/e0MGXKt1mxoiPifOE2/w14LZ8LBpWLJEpMXUE4514HKiJMOifCvA74RizbE0kWwSD8+zWN/CMQooHm5oe45prvkpY2tIuH8ODxDZwIQCFdveUiiaQ7gUVGoaoKsg94dwGHSAUyOXAgNeJpnfC9AA14rYUKqdG9AJIUFAAio1BTA4V4zZQbMCC7t3yw8L0A6TObASjPXsOyZeoMThJPvYGKjEJqKhR0h48AAHJ6yyMJBOD00/NpnQsXn7GH4/ThL0lARwAio9DdDQWEA6CHcAB0dx96mZycHBqAtKamsa+gSBQUACKjUFbWFwCN/Br4W2/5oWRnZxMC0jUqmCQJBYDIKFRXw8y0EHuZQheZQNawF3azsrIIAZmtreNVTZHDUgCIjEIgAOd/LERTWiHwA6ZPXzbshd2UlBSOOfXU3vsARBJNASAySuU5DcytKOC44x7hrLP+FFWrnqNOOYXM5uaxr5xIFBQAIqMVCkFBAfv37z9kT6CD1XZ2QmsrtLePceVEhqcAEBmtEQZAMAjfu/c3AMzKaqSgQB3CSWIpAERGw7neAGhraxs2AIJB+Kd/gnrn3TBWQIjGRvjqVxUCkjgKAJHRaGuD9nZcQQFmRq4/JsChVFVBZyeE/O4gwk1IOzrUK6gkju4EFhkNf7Q6KyykpaVl2NnDPX+GyAP6AqD/NJHxpiMAkVH44//2PsAvuqqA8vLhT+OEe/4MMRUYGADqFVQSRQEgMkLBIDxQ7X2AN5BKTc1lXHXV/z1sCFRXQ3o67OFmoC8AMjLUK6gkjgJAZISqqiD3YLgfIAOCHDy447Dn8gMBeOghmJJ/Gk1MpYAQ+fmwfLl6BZXE0TUAkRHatq3vG3wDmX5pzrDn8gMBOOWUzWScmcW/nBXiX345tvUUGY6OAERGqLTUGwugi1T2YX5pTlTn8leuXMmbtbU4/yKySCIpAERGKNwRXCP5OA4AkJmZHdW5/PfeyyEEvL66PqqLxyJjSQEgMkKBAJz7kRD70gsAR0pKAd/73uRhz+UHg7BqlRcABTRSUwOVlQoBSRxdAxAZhdKsEJxagHvu74HoTud4N4P1BQA42tqMqipdCJbE0BGAyGiEQlBYOKJFvIvEXgBkcZBs2vqVi4w/BYDIaPj9AD366KN87nOfo7Ozc9hFvIvEZxDiX4G+lkS6EUwSRQEgMlI9PdDYCAUFvP322zzxxBOkpQ1/NrW6GrKziwhxBuAFwHCjiImMJQWAyAit+tle6O7mhuoC7rmnlczMXMxs2OUCAfjpT/fRNeV1AI4rCg07ipjIWFIAiIxAMAh3fDN8E1gBLS2ttLfnRt2S58wzd7N533cA+MVPQvrwl4RSAIiMQFUV5LSHA6AQaMW53Ki7dM7JyenrBi4UOtysImNOASAyAjU1fRdvQxQA04H5UbfkycnJYS/QY6YAkITTfQAiUQoGwQwKndfu3wuAe4HoW/JkZ2fTA7RnZZGtAJAE0xGASJSqqryRIAceAXihEG1LnoyMDFJTU2nNytIRgCRczAFgZqlm9jcz+4P/eq6ZvWxmm8zsV2aW4Zdn+q83+9PLY922yHgKn+YpIMQBJtFGNvBlnKuO+mKumbFmzRqmHnWUAkASLh5HANcDG/q9/iFwl3NuPtAEXOWXXwU0OeeOBu7y5xM5YoRP8xQQ8r/9G/ACOTkfjGg9FRUVZJSUKAAk4WIKADObDVwA/Nx/bcDZwGP+LCuAi/3nF/mv8aefY9E0nhZJEt6NXF4AeC2AAFo5/fTDDwg/2KpVq9jR3q4AkISL9Qjgp8C/AT3+63xgr3Ouy3+9A5jlP58FbAfwp+/z5xc5IgQCsGwZzM5oIEQBpaWO1NRWKipGFgB33HEHa95/3wsA58aotiLDG3UAmNnfA/XOudf6F0eY1UUxrf96K81srZmtbdCgGZJkAgH4yJwQn/7HAjZu7KC7u4vc3JEFQHZ2No0AXV3Q3Dwm9RSJRixHAKcD/8vMtgKP4p36+Skw1czCzUtnA7v85zuAOQD+9CnAnsErdc4tc85VOOcqCkfY26LIuPA7guvo6OBjH/sYpSPszS0nJ4f6np6+dYkkyKgDwDl3q3NutnOuHPgS8IxzLgA8C1zqz3Yl8Dv/+RP+a/zpzzin4185wnR2wr59UFDA5MmTeeWVVwiMsD8HBYAki7G4D+Bm4EYz24x3jv9Bv/xBIN8vvxG4ZQy2LTKmHl/WCMDS2wtHPaRjTk4OteHuoxUAkkBxuRPYOfcX4C/+8w+Aj0eYpx34Qjy2J5IIwSDc/a8NfB4IkU9NzRtcfvmVbNx4L9/97mlRr+fHP/4xvP8+nHmmAkASSncCi0Spqgpy272GCfUUASGce4MHHug6/IKDlJSUUHLCCd4LBYAkkAJAJErbtkER9UA4APYDUFeXM6L1fOc7LzGt7F46SePe74U0KLwkjAJAJEqlpVDoDwAf7goaoKQk+magwSDceecz7N13GyEKSG8OUVk5umsJIrFSAIhEqboaZqXV000Ke5hOOABuuSX6AKiqgs5O74ghxDQKCNHWRtTjCYjEkwJAJEqBAHz+zAaaUvJxlkphYRELF36Cr3wlL+p1eB3KhQNgam/PojU1Y1BhkWEoAERGYP6UegoWFtHTA/X1F/POO88yefLkqJf37hnzAqOBvN4AMNNpIBl/CgCRKAWD8MqTDTy7fvT3AHjjBkwBIERObwA4p9NAMv4UACJRCAahshKmHKynniJqauArX6ni6KOXjGg93k3DnwDqCbGQ6ewhhW6AqIeVFIkXBYBIFKqqoK3NawUU7gq6q2sHW7fWjXhdZWWTgEJCFJFKD1PZC0Q/rKRIvCgARKKwbRuk0cl0mvx7AABa6e4eWU+gAN/+dgtpad8mRBPgjS+QnR39sJIi8aIAEIlCaWnfWMD9B4PJyBjZTWAAl17aTVdXNQdzawFYPCPEsmVEPaykSLwoAESiUF0NZZP63wUMKSmtzJ8/8iOAcKuhT3/Z6wz38QdC+vCXhFAAiEQhEIDqb3p3AYcopKwMzj//DP7hH84a8bpSU1PJzc3lxY1el9Bfu7hh1K2KRGIRl95ARSaCc473jgCe21AExwL8cNTrSk/P47HnO1kBFFFHTY3Xygh0KkjGj44ARKIVHqK0qOjw80WhpSWPtp429jKFGXgtidQlhIw3BYBItOrrITUVpk4FoLCwkOpRNt3p6loH/IrdzGQmu3vLdS+AjCcFgEgUgkFYeU8Dtd2FlM9L4eGHDxIKhTCzUa2vrCwLsCEBoHsBZDwpAESGEb4LOLu1ngYKqamBpUubAZgyZcqo1vmZz6wgLe3fBwSA7gWQ8aYAEBlG+C7gYmrZzUwADhzYB0BeXvQ9gfbX2fkceXkP0TbZC4CyMnQvgIw7tQISGUb4vHwxtbzrNf8BYjsCyMvLo6urma/eNhNubWHr+v2QM/KbykRioSMAkWF45+UdM9lNLcV+aR45Of/EvHnzRrXOvLw8Wlpa6Am3KKobeZ9CIrFSAIgMo7oa5mQ1kkEnuygBIDv7aB54YDmLFy8e1Trz8vJwztEePoJQAEgCKABEhhEIwH3/7vXbs5tiysrg/vu7+bLflcNoTJkyhUmTcvncNV63EF+/aLfuBJZxpwAQicIFJ3sB8OsXitm6Ffbtu4+MjAxCodCo1ped/TVSUlp4s+F4AFIadnP55bB0abxqLDI8BYDIMIJB+NaXvQA48x+KCQZh3759dHV1jWg4yP7CLYsaKKQHYya7cQ7uv199Asn4UQCIHEb4HoD0Ri8A1u4qprIS1qxpJjMzk8zMzFGtt6bmfSBAN2/SQGHvvQAaGlLGkwJA5DD63wOwjzwOkE1bG/zlL82jvgcAoLi4DVgJfKDuICRhFAAihxH+MC5hV78moNDaui+mALj55vCyzeoOQhJGASByGOEP42Jqe5uAAuTnn8fXvva1Ua/3yivDN5A1qzsISRgFgMhhVFd7H8rF1PYeAWRnw913X8HNN9886vWGLx5//vPNtOUVU0wt5aU96g5CxpW6ghA5jEAAcI6SK2rZ7bx7AKqr4fzzm+jqmkxa2ujeQqmpqZSVlXHyyWlc88k5cG0nW9bUQXHx8AuLxMmojwDMbI6ZPWtmG8xsvZld75dPN7OnzWyT/3OaX25mdo+ZbTazN83s5Hj9EiJjKXBhM1nuAN/6sXcPQCAAxxxzDNddd11M6926dSu33XYbzJnjFWzfHntlRUYgllNAXcC3nHMLgSXAN8xsEXALsNo5Nx9Y7b8G+Cww339UAvfFsG2R8VPrNQENfzt3ztHU1MS0adPis/7whQYFgIyzUQeAc67WObfOf94CbABmARcBK/zZVgAX+88vAn7hPGuAqWam411Jen9esROATwZKKC+Hn/+8he7u7pgD4Nvf/jY33ngjq9Z4RwDfvHQ7ZlBQoJvBZHzE5SKwmZUDHwFeBmY452rBCwkgPIDqLKD/V5wdftngdVWa2VozW9sQHoNVJEGCQXj8J1sB2EI5NTVw3XVNADEHwFtvvcXjjz9D4F+m00YWc/y3R2MjfPWrCgEZezEHgJnlAo8D33TONR9u1ghlQ3rTcs4tc85VOOcqCgsLY62eSEyqqqC4o4ZuUtjpf19pb49PAEyfPp2dOxvp7DK2M6c3AAA6OnRHsIy9mALAzNLxPvyDzrnf+MV14VM7/s96v3wHMKff4rOBXbFsX2Ss1dRAGTXsZBZdpPulhcD3Of7442Nad35+Pt3dewDYzhxKGXgLsO4IlrEWSysgAx4ENjjnftJv0hPAlf7zK4Hf9Su/wm8NtATYFz5VJJKMgkEw8wKghrJ+U2ZRVvZt5s+fH9P6p0+fDrQB7UOOAEB3BMvYi+UI4HTgcuBsM3vdf5wP/AA418w2Aef6rwGeBD4ANgM/A9TxrSS166/3OmcbGgB7uPHGHfT09MS0/rKyMubMOZ60tFa2M4diakmjE4CMDN0RLGMvllZAf3XOmXPuBOfcSf7jSedco3PuHOfcfP/nHn9+55z7hnPuKOfc8c65tfH7NUTiKxj0Lsam0sUctrOV8n5Tf8b118/hwIEDMW0jEAiwbdubPPxwAXtySknBUcIu8vNh+XLdESxjT3cCi0QQvgBbwi7S6B5wBDB5cj1dXVnkxGkQ90AAAgVz4DyoeWE7nFE2/EIicaC+gEQiCF+ALaMGYEAAnHhiA/FoobZlyxZOPfVUnn76ad0NLAmhABCJIHwBdnAA5OdDbm58AiAtLY01a9awZcuWvg3W1MS8XpFoKQBEIgj3AlrOVgC2Uer3AgoNDQ0UFRUdfgVRCIdIfX095ObCzJmwaVPM6xWJlq4BiBxCVhaUtdWwmxnk5Gdx993e+frMzFvIysqKef2TJk1iypQp1NXVEQzC0U3H0LF8I5ev9gJIF4FlrCkARAYJjwPc1tbXBLR/g59LL700btuaMWMGr7xSx/LlcPfB+VzI76mp8bYPCgEZWzoFJDJIeBxggPlsYjNH09bmlXd2dvLyyy/T1NQUl22dddZZvPvuXNraYCPHMIN6prC3d3siY0kBIDJIuAVQJu2UUcNGjukt37lzJ0uWLOG3v/1tXLa1bNkyWlp+CNC7nflsGlAPkbGiABAZJNwg52g2k4Lr/WAuLYXdu72xe2fMmBH37Q0OAHUFIWNNASAySLgF0DFsBOA9FvQO1r5zpzc2wOzZs+OyrQcffJDW1lKystp5n6PowTiGjRocXsaFAkBkkEAAli2DJVPfA+DgnPm9g7WHA2DWrCFDWYxKT08PjY3b+Y//qKe4LJMayvhI9kYNDi/jQq2ARCIIBIA/vQN/mc36bZN7y3fu3ElmZib5+flx2U5JSQkAp5yyi+rqUrb/8zHMatvIpVX96iEyRnQEIDJIMAjl5fD6I2/xbOj4ASNzXXHFFaxcuRKvN/TYlfon+leu3E5lJbzRfgzHsJGaGsdll8HkyRoZTMaOAkCkn6VL4fLLYUdNFwvZwKvti6ms7PtNYAKWAAANUElEQVQQPu6447jkkkvitr05fh9AjzyyjbY2WM9x5NHS2wVFa6uGh5SxowAQ8QWDcP/93hgA89lEJh28xfED2uQ/+eSTvPfee3Hb5pQpU7j00ktpavKOBF7nJABO5I3eeTo6vLEJROJNASDiCw8AA30fwG/hDfu4bRs457j00ktZtmxZ3LZpZqxatYqysi/0bq8H4yReHzBfY6OOAiT+FAAi9A0AE/YxXuUAk1jPcQBMnw61tbUcOHCAo446Ku7b//73uzGDNnLYxHw+wt+GzKM7gyXeFAAiDP1wrWAtr3NSv4Hg4f333weIewDcfPPN3HTTLK6+2nu9lgo+ziuAGzCfeoqWeFMAiDCw24UUujmZdbzKx3rL9uwZuwAoKCigrq6O6uomHnkE1rCEEmqHDBKfmhrXzYooAETAO8UTdiJvMJlW1rCkt6y01AuA1NRUysriO2TjscceC8B7771HIAAvcSoAS1gzYL7u7rhuVkQBIBIMQnNz3+uzeA6A5zgLoLdbhmuvvZa//OUvpKenR1rNqC1YsACAd999F4C9pSeyn2z+jhcGzGemC8ESXwoAmfC8bp77Xp/J82zmKHYxi7IyertlmDFjBmeccUbctz937lzS0tJ6m5d+9850nudMzmH1gPmcU3NQiS8FgEx4/c//p9PBOazmGc7GDLZu9T7829vb+cEPfhDXewB6t5mezi233MJpp50GeNv7M59iERsoYeeAeRsbvZvVROJBASATXk5O3/O/4wXyaOEP/P2A6wLvvPMOt956K2+++eaY1OH73/8+F154Ye/rt4s/DcAF/M+Qee+7T6eCJD4UADKhBYNedwthF/PftJPJas4ZMN8bb3g3hp144oljUg/nHJs3b6bVr8wV/7mYTRzN53k84vxXXKEQkNgpAGTCWroULrus73UanXyJR/k9F9JGDnv29E3761//yrRp0zj66KPHpC5r1qxh/vz5rF7tnfcPXGY8OenznM0zFFI/ZP6eHgb0USQyGgoAmZA+9SnvVEp/F/A/FBLif3M5MHBErmeffZZPfOITpKSMzVvmpJNOIiMjg+eee663bN53rySdLr7CwxGXaWvTRWGJjQJAJpylS2H16qHlN/ITaijlSc7HrG9ErsbGRkKhEGefffaY1SkrK4tPfvKT/M//9J3zv/DfFvLXlDNZyr2k0xFxucZGKCjQkYCMjgJAJpSlS4d+8wc4hz9zJi9wFzfQTRpXX903GEt+fj67d+/m8ssvH9O6XXDBBWzcuHFAS6POb91COTV8leWHXK6xkd6xA1JSvLEMFAgSDXPODT9XglRUVLi1a9cmuhpyhAsGvVMl/Tt76y+LNtZSwSTaWcQ75OZPIhTypjnn6OrqivvNX5Hs2rWLsrIybrjhBv7zP/8zXAFeyjiLBV1vs5AN1BP9YPS5uV731hpVbOIxs9eccxXDzTfuRwBmdp6ZvWdmm83slvHevnx4hEfuSknxPuxSU727ZQc/Lrvs0B/+Rg/LqGQRG7ia++lOm8Tdd/dNf+yxx1i8eDE149ATW0lJCU8++SS33357vwoaoeoHyOIAq/gCkzgQ9fpaW73fffD+0Chj0ss5N24PIBV4H5gHZABvAIsONf9HP/pRNxrXXOOcmXPevZN66BH5MZ2QW8XnnQN3G3e4SZOce+SRvv+j7du3u+LiYrd48WLX1dU1qv/F0dq1a5fr7Ozsff3CN37pujH3Eqe4Y3kn4ftOj/F55OcP/J+MFrDWuSg+k6OZKV4P4FTgqX6vbwVuPdT8owmAa65J/B9Nj+R8ZHLAlfOBu4jfuvupdM3kug7S3I382F1zdU/v/9CePXvc8uXL3axZs1xubq576623Rvx/GIu9e/e60tJSd9ZZZ7mnnnrK7d271znn3HPXrXKNTHPtZLiVfMl9kUfdfN5zWexP+L7VY+weGRkjD4FoA2BcrwGY2aXAec65f/ZfXw6c4py7NtL8o7kGkJYGC7vf4ld8Bhh43O8N412GdyDSBDQxdGjvcr9sD7AvwvLl/qtGoGXQ8inAHAwHhID9g5ZNBWb5JQ3AgUHLpwMz/eUbgIP9lnd4B01Ffkk90DFo+UygwJ+3HugatP1JwDS/pA7oGbT8JGCqv3wd9OuP3psvG5jcb3kGLZ8N5GL0+L9/n77ls4EeYI+/nf5ygUkYXcDeCMvn+L9jN7Avwt8uB8jA6ARaB0xJA/L6ba8N+BUZ/L9MYj2pTJsGf/jDHzjttNP42c9+RmVlJSeccAIrVqzgpJNOGrKlsfbwww9z44030tTUBEBeXh4/+clPeO+FCyld8U2+xK8ooKd3/v0YLUyhixy66KGLEF1D9vBMvP3fBuyOsNViIAvv/7YuwvRZOCYBzXj/n4PNwfsf3cfgv7+nDO8v0YT3/gI34K84F+891Mjgv78n3A13g1+H/gzvxAJ+3VsHTU+l771bi7cP+kvz6wewC4acasvA+/0AdtD/vemZRN97exvQOWh6Nt7+BdiK9z/cXy70Xt/ZAhh/5Bpu4scAlJV53ZJEK9prAGnRrzIuhr5nGfg/amaVQCVAaf+G2FHq7oYDZPE28/D+6IM3thjvg3Y73h9yUAU4AUjFsRXvH2Xw8uF9+j7hN0nf8qnAx/2yjQx+EzgyobeP+Xfw3gj9l88CPuqXvcXgf3LHZCD8YfQ3wgHTt/xU8IcwdLzG4H9iRz74I1zBy+A3Lex7ExYCx/plLzL4n9RRAsz3t/hCv/Lw8rPx3oRdOF5iMEc53pvsoL/9wfv+KH8dbTiGBr9jAd6bqAVYN2jbAAvxArIJx8AuG3owGjiLOk5gPZN4nRdpJw0z+PS5sGABFBV54Xreeefx4osvcsopp4xZu//hfOUrX+GLX/wizz//POvWraOuro4FCxZw1VVF/PSkOyn7tx6O7WziePYykwMUcpAcjiWNQtJoJI11pPcLCM8xwHS8/7vB08D720/B+78d+sXQOBbvg6qOyG/lhXj/w7uIfHlxEd4H6Q4gLcIXgGPxPpJqiPzRtNDf7gcMDagUf/342xgcUOn9pqcSDqA+k/pNh8Ff/rwvF+Hp3QwNmLx+0zsYGiDTCL+3vGmDm/UW4L23wHtfp7CzN1AG9lcVT+N9BHAq8B3n3Gf817cCOOf+I9L8oz0CUL/pEo38fLj77iO3lUwwCF//OuzfP/y8cmQbqyOA8f568yow38zmmlkG8CXgiXhuoLIynmuTD5v8fHjkEe/saih05H74g1f31lbv9ykr81r4lJXBOecMv6wcOTIy+m5KjLdxDQDnXBdwLfAUsAH4tXNufTy3ce+9cM013ptBJp7wGZuysr4P+v6PI/1DP5JAwPt22NPj/fzzn4eGwiOPeI/+PZ9K8svPh+XLx+5/VjeCiYh8yCTrKSAREUkSCgARkQlKASAiMkEpAEREJigFgIjIBJXUrYDMrAHvtsBkVEDk+90nMu2TgbQ/htI+GWis9keZc65wuJmSOgCSmZmtjaaZ1USifTKQ9sdQ2icDJXp/6BSQiMgEpQAQEZmgFACjtyzRFUhC2icDaX8MpX0yUEL3h64BiIhMUDoCEBGZoBQAI2RmPzKzd83sTTP7rZlN7TftVn+w+/fM7DOJrOd4MbMvmNl6M+sxs4pB0ybc/ggzs/P833uzmd2S6PokgpktN7N6M3u7X9l0M3vazDb5P6cdbh0fJmY2x8yeNbMN/nvmer88YftEATByTwOLnXMnABvxxjXGzBbhjW9wHHAecK+ZDR2S7MPnbeAS4Pn+hRN4f+D/nv8FfBZvmKh/9PfHRPMw3t++v1uA1c65+cBq//VE0QV8yzm3EFgCfMP/v0jYPlEAjJBz7v/44xoArMEbwxDgIuBR59xB59wWYDPh8SE/xJxzG5xz70WYNCH3h+/jwGbn3AfOuQ7gUbz9MaE4555n6NiLFwEr/OcrgIvHtVIJ5Jyrdc6t85+34I2JMosE7hMFQGy+CvzRfz4Lb6DhsB3Qb1DPiWci74+J/LsPZ4Zzrha8D0S8QZwnHDMrBz6CNzh2wvbJeA8Kf0Qwsz8DMyNMqnLO/c6fpwrvkC4YXizC/B+KJlbR7I9Ii0Uo+1DsjyhM5N9dhmFmucDjwDedc82WwOELFQAROOc+dbjpZnYl8PfAOa6vHe0OYE6/2WYDu8amhuNruP1xCB/a/RGFify7D6fOzIqdc7VmVgzUJ7pC48nM0vE+/IPOud/4xQnbJzoFNEJmdh5wM/C/nHNt/SY9AXzJzDLNbC4wH3glEXVMEhN5f7wKzDezuWaWgXcx/IkE1ylZPAFc6T+/EjjUEeSHjnlf9R8ENjjnftJvUsL2iW4EGyEz2wxkAo1+0Rrn3NX+tCq86wJdeId3f4y8lg8PM/sc8P8BhcBe4HXn3Gf8aRNuf4SZ2fnAT4FUYLlzrjrBVRp3ZvZL4BN4PV7WAbcD/w38GigFtgFfcM4NvlD8oWRmZwAvAG8BPX7xbXjXARKyTxQAIiITlE4BiYhMUAoAEZEJSgEgIjJBKQBERCYoBYCIyASlABARmaAUACIiE5QCQERkgvr/AdUoYJqHomsfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "n, bins, patches = plt.hist(error_prediction, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "plt.title(\"Histogram with 400 bins\")\n",
    "plt.show()\n",
    "x=bins[:400]\n",
    "y=n\n",
    "print(n.shape)\n",
    "print(bins.shape)\n",
    "from numpy import exp, loadtxt, pi, sqrt, log\n",
    "\n",
    "from lmfit import Model\n",
    "def gaussian(x, amp, cen, wid):\n",
    "    \"\"\"1-d gaussian: gaussian(x, amp, cen, wid)\"\"\"\n",
    "    return amp * exp(-((x-cen)/wid)**2 )\n",
    "\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "\n",
    "print(result.fit_report())\n",
    "\n",
    "plt.plot(x, y, 'bo')\n",
    "plt.plot(x, result.init_fit, 'k--')\n",
    "plt.plot(x, result.best_fit, 'r-')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWHM=result.params['wid'].value*2*sqrt(log(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5077007164045413\n"
     ]
    }
   ],
   "source": [
    "print(FWHM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[166.92802]\n",
      " [168.36761]\n",
      " [163.7461 ]\n",
      " ...\n",
      " [168.1886 ]\n",
      " [166.15027]\n",
      " [165.54758]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0249105258111473\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_bin0_predicted=model.predict(x_test_bin0)\n",
    "print(Y_test_bin0_predicted)\n",
    "error_prediction_bin0=Y_test_bin0-Y_test_bin0_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin0, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin0=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3702963079408725\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_bin1_predicted=model.predict(x_test_bin1)\n",
    "#print(Y_test_bin1_predicted)\n",
    "error_prediction_bin1=Y_test_bin1-Y_test_bin1_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin1, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin1=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.305192143334716\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_bin2_predicted=model.predict(x_test_bin2)\n",
    "#print(Y_test_bin2_predicted)\n",
    "error_prediction_bin2=Y_test_bin2-Y_test_bin2_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin2, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin2=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9472445402220906\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_bin3_predicted=model.predict(x_test_bin3)\n",
    "#print(Y_test_bin3_predicted)\n",
    "error_prediction_bin3=Y_test_bin3-Y_test_bin3_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin3, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin3=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1333396378976137\n",
      "1.9472445402220906\n",
      "2.305192143334716\n",
      "2.3702963079408725\n",
      "3.0249105258111473\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_bin4_predicted=model.predict(x_test_bin4)\n",
    "#print(Y_test_bin4_predicted)\n",
    "error_prediction_bin4=Y_test_bin4-Y_test_bin4_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin4, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin4=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin4)\n",
    "print(FWHM_bin3)\n",
    "print(FWHM_bin2)\n",
    "print(FWHM_bin1)\n",
    "print(FWHM_bin0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "495px",
    "left": "909px",
    "right": "57px",
    "top": "246px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
