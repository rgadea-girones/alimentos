{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple AUTOENCODER for PETALO\n",
    "\n",
    "Esta red la vamos a utilizar para obtener el radio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python36.zip', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/lib-dynload', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/extensions', '/home/rgadea3/.ipython']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#np.random.seed(1337)  # for reproducibility\n",
    "from time import time\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append(\"/home/rgadea/lmfit-py/\")\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from math import floor\n",
    "#from lmfit.models import  GaussianModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos introducir los datos de petalo preprocesados en matlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import hdf5storage\n",
    "datos_matlab = hdf5storage.loadmat('../datos_octubre_2018/conjunto_entrenamiento_octubre_2018_red_pitch5mm_rad161mm_total.mat')\n",
    "conjunto_datos= datos_matlab.get('photodefA')\n",
    "print(conjunto_datos[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_regularizer = True\n",
    "my_regularizer = None\n",
    "my_epochs = 50\n",
    "features_path = 'simple_autoe_features.pickle'\n",
    "labels_path = 'simple_autoe_labels.pickle'\n",
    "\n",
    "if use_regularizer:\n",
    "    # add a sparsity constraint on the encoded representations\n",
    "    # note use of 10e-5 leads to blurred results\n",
    "    my_regularizer = regularizers.l2(0.001)\n",
    "    # and a larger number of epochs as the added regularization the model\n",
    "    # is less likely to overfit and can be trained longer\n",
    "    my_epochs = 100\n",
    "    features_path = 'sparse_autoe_features.pickle'\n",
    "    labels_path = 'sparse_autoe_labels.pickle'\n",
    "\n",
    "   \n",
    "    \n",
    "encoding_dim = 320  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 16, 40\n",
    "# this is our input placeholder\n",
    "input_output_dim_A=img_rows*img_cols\n",
    "input_img = Input(shape=(img_rows*img_cols,))\n",
    "\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='sigmoid',activity_regularizer=regularizers.l2(0.0000001))(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(img_cols*img_rows, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "\n",
    "\n",
    "autoencoder=Sequential([\n",
    "    Dense(encoding_dim, kernel_regularizer=regularizers.l2(0.001), use_bias=True,bias_initializer='random_uniform',input_shape=(640,)),\n",
    "    Activation('sigmoid'),\n",
    "    Dense(img_cols*img_rows, use_bias=True,bias_initializer='random_uniform'),\n",
    "    Activation('linear'),\n",
    "])\n",
    "\n",
    "# autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66498\n",
      "conjunto_datos shape: (66498, 640)\n",
      "39898\n",
      "13299\n",
      "13301\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "# (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "numero_muestras=conjunto_datos.shape[0]\n",
    "print(numero_muestras)\n",
    "print('conjunto_datos shape:', conjunto_datos.shape)\n",
    "\n",
    "tr_size=60\n",
    "val_size=20\n",
    "test_size=100-val_size-tr_size\n",
    "\n",
    "tamanyo_tr=floor(tr_size*numero_muestras/100)\n",
    "tamanyo_val=floor(val_size*numero_muestras/100)\n",
    "tamanyo_test=numero_muestras-tamanyo_tr-tamanyo_val\n",
    "print(tamanyo_tr)\n",
    "print(tamanyo_val)\n",
    "print(tamanyo_test)\n",
    "\n",
    "\n",
    "X_train=conjunto_datos[:tamanyo_tr,:]\n",
    "X_val=conjunto_datos[tamanyo_tr:tamanyo_tr+tamanyo_val,:]\n",
    "X_test=conjunto_datos[tamanyo_tr+tamanyo_val:numero_muestras,:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Y_train=conjunto_datos[:tamanyo_tr,1] #elijo la coordenada radius\n",
    "Y_val=conjunto_datos[tamanyo_tr:tamanyo_tr+tamanyo_val,1] #elijo la corrdenada radius\n",
    "Y_test=conjunto_datos[tamanyo_tr+tamanyo_val:numero_muestras,1] #elijo la corrdenada radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], img_cols, img_rows,1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_cols, img_rows,1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_cols, img_rows,1)\n",
    "\n",
    "\n",
    "input_shape = (img_cols, img_rows,1)\n",
    "#input_shape=input_shape.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (39898, 40, 16, 1)\n",
      "39898 train samples\n",
      "13299 validation samples\n",
      "13301 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_val= X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_val.shape[0], 'validation samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display 20 random training images using image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "#Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "#Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "for i in range(1,5):\n",
    "    idea=np.random.randint(1,X_train.shape[0])\n",
    "    plt.imshow(np.reshape(X_train[idea].transpose(), [16, 40]), vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a generar las matrices de datos para la red neuronal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39898, 640)\n",
      "(13301, 640)\n"
     ]
    }
   ],
   "source": [
    "x_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
    "x_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the autoencoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='sgd', loss='mse')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a summary of the model parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now train the model and evaluate on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39898 samples, validate on 13301 samples\n",
      "Epoch 1/5000\n",
      "39898/39898 [==============================] - 1s 29us/step - loss: 8.1220 - val_loss: 7.3084\n",
      "Epoch 2/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 8.0688 - val_loss: 7.2650\n",
      "Epoch 3/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 8.0319 - val_loss: 7.2348\n",
      "Epoch 4/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 8.0059 - val_loss: 7.2132\n",
      "Epoch 5/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.9871 - val_loss: 7.1975\n",
      "Epoch 6/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.9731 - val_loss: 7.1857\n",
      "Epoch 7/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.9624 - val_loss: 7.1764\n",
      "Epoch 8/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.9538 - val_loss: 7.1689\n",
      "Epoch 9/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.9466 - val_loss: 7.1626\n",
      "Epoch 10/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.9404 - val_loss: 7.1570\n",
      "Epoch 11/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.9349 - val_loss: 7.1520\n",
      "Epoch 12/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 7.9299 - val_loss: 7.1473\n",
      "Epoch 13/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.9251 - val_loss: 7.1429\n",
      "Epoch 14/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.9206 - val_loss: 7.1387\n",
      "Epoch 15/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.9162 - val_loss: 7.1346\n",
      "Epoch 16/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.9120 - val_loss: 7.1306\n",
      "Epoch 17/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.9078 - val_loss: 7.1266\n",
      "Epoch 18/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.9037 - val_loss: 7.1227\n",
      "Epoch 19/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.8996 - val_loss: 7.1188\n",
      "Epoch 20/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.8956 - val_loss: 7.1150\n",
      "Epoch 21/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.8916 - val_loss: 7.1112\n",
      "Epoch 22/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.8876 - val_loss: 7.1074\n",
      "Epoch 23/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.8836 - val_loss: 7.1036\n",
      "Epoch 24/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.8797 - val_loss: 7.0999\n",
      "Epoch 25/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.8758 - val_loss: 7.0961\n",
      "Epoch 26/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.8719 - val_loss: 7.0924\n",
      "Epoch 27/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.8680 - val_loss: 7.0887\n",
      "Epoch 28/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.8642 - val_loss: 7.0850\n",
      "Epoch 29/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.8603 - val_loss: 7.0814\n",
      "Epoch 30/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.8565 - val_loss: 7.0777\n",
      "Epoch 31/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.8527 - val_loss: 7.0741\n",
      "Epoch 32/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.8489 - val_loss: 7.0705\n",
      "Epoch 33/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.8452 - val_loss: 7.0669\n",
      "Epoch 34/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.8414 - val_loss: 7.0633\n",
      "Epoch 35/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.8377 - val_loss: 7.0597\n",
      "Epoch 36/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.8340 - val_loss: 7.0562\n",
      "Epoch 37/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.8303 - val_loss: 7.0526\n",
      "Epoch 38/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.8266 - val_loss: 7.0491\n",
      "Epoch 39/5000\n",
      "39898/39898 [==============================] - 0s 12us/step - loss: 7.8229 - val_loss: 7.0456\n",
      "Epoch 40/5000\n",
      "39898/39898 [==============================] - 0s 11us/step - loss: 7.8193 - val_loss: 7.0421\n",
      "Epoch 41/5000\n",
      "39898/39898 [==============================] - 1s 18us/step - loss: 7.8157 - val_loss: 7.0386\n",
      "Epoch 42/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.8120 - val_loss: 7.0352\n",
      "Epoch 43/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.8084 - val_loss: 7.0317\n",
      "Epoch 44/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.8048 - val_loss: 7.0283\n",
      "Epoch 45/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.8012 - val_loss: 7.0248\n",
      "Epoch 46/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7977 - val_loss: 7.0214\n",
      "Epoch 47/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7941 - val_loss: 7.0180\n",
      "Epoch 48/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7906 - val_loss: 7.0146\n",
      "Epoch 49/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7871 - val_loss: 7.0112\n",
      "Epoch 50/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7835 - val_loss: 7.0079\n",
      "Epoch 51/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7800 - val_loss: 7.0045\n",
      "Epoch 52/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7766 - val_loss: 7.0011\n",
      "Epoch 53/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7731 - val_loss: 6.9978\n",
      "Epoch 54/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7696 - val_loss: 6.9945\n",
      "Epoch 55/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7661 - val_loss: 6.9911\n",
      "Epoch 56/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7627 - val_loss: 6.9878\n",
      "Epoch 57/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7592 - val_loss: 6.9845\n",
      "Epoch 58/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7558 - val_loss: 6.9812\n",
      "Epoch 59/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7524 - val_loss: 6.9780\n",
      "Epoch 60/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7490 - val_loss: 6.9747\n",
      "Epoch 61/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.7456 - val_loss: 6.9714\n",
      "Epoch 62/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7422 - val_loss: 6.9682\n",
      "Epoch 63/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7388 - val_loss: 6.9649\n",
      "Epoch 64/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7355 - val_loss: 6.9617\n",
      "Epoch 65/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7321 - val_loss: 6.9585\n",
      "Epoch 66/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7288 - val_loss: 6.9553\n",
      "Epoch 67/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7254 - val_loss: 6.9521\n",
      "Epoch 68/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.7221 - val_loss: 6.9489\n",
      "Epoch 69/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7188 - val_loss: 6.9457\n",
      "Epoch 70/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7155 - val_loss: 6.9426\n",
      "Epoch 71/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7122 - val_loss: 6.9394\n",
      "Epoch 72/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.7089 - val_loss: 6.9363\n",
      "Epoch 73/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7056 - val_loss: 6.9331\n",
      "Epoch 74/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.7024 - val_loss: 6.9300\n",
      "Epoch 75/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6991 - val_loss: 6.9269\n",
      "Epoch 76/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6959 - val_loss: 6.9238\n",
      "Epoch 77/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6927 - val_loss: 6.9207\n",
      "Epoch 78/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6895 - val_loss: 6.9176\n",
      "Epoch 79/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6863 - val_loss: 6.9145\n",
      "Epoch 80/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6831 - val_loss: 6.9115\n",
      "Epoch 81/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6799 - val_loss: 6.9084\n",
      "Epoch 82/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6767 - val_loss: 6.9054\n",
      "Epoch 83/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6736 - val_loss: 6.9024\n",
      "Epoch 84/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6704 - val_loss: 6.8993\n",
      "Epoch 85/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6673 - val_loss: 6.8963\n",
      "Epoch 86/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.6642 - val_loss: 6.8933\n",
      "Epoch 87/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6610 - val_loss: 6.8903\n",
      "Epoch 88/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6579 - val_loss: 6.8873\n",
      "Epoch 89/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.6548 - val_loss: 6.8844\n",
      "Epoch 90/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6517 - val_loss: 6.8814\n",
      "Epoch 91/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6487 - val_loss: 6.8784\n",
      "Epoch 92/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.6456 - val_loss: 6.8755\n",
      "Epoch 93/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6425 - val_loss: 6.8726\n",
      "Epoch 94/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6395 - val_loss: 6.8696\n",
      "Epoch 95/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6365 - val_loss: 6.8667\n",
      "Epoch 96/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.6334 - val_loss: 6.8638\n",
      "Epoch 97/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 7.6304 - val_loss: 6.8609\n",
      "Epoch 98/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6274 - val_loss: 6.8580\n",
      "Epoch 99/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6244 - val_loss: 6.8551\n",
      "Epoch 100/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6215 - val_loss: 6.8523\n",
      "Epoch 101/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.6185 - val_loss: 6.8494\n",
      "Epoch 102/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6155 - val_loss: 6.8466\n",
      "Epoch 103/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6126 - val_loss: 6.8437\n",
      "Epoch 104/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6096 - val_loss: 6.8409\n",
      "Epoch 105/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6067 - val_loss: 6.8381\n",
      "Epoch 106/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6038 - val_loss: 6.8353\n",
      "Epoch 107/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.6009 - val_loss: 6.8325\n",
      "Epoch 108/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5980 - val_loss: 6.8297\n",
      "Epoch 109/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5951 - val_loss: 6.8269\n",
      "Epoch 110/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.5922 - val_loss: 6.8242\n",
      "Epoch 111/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5893 - val_loss: 6.8214\n",
      "Epoch 112/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5865 - val_loss: 6.8187\n",
      "Epoch 113/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5836 - val_loss: 6.8159\n",
      "Epoch 114/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5808 - val_loss: 6.8132\n",
      "Epoch 115/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5780 - val_loss: 6.8105\n",
      "Epoch 116/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5751 - val_loss: 6.8078\n",
      "Epoch 117/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.5723 - val_loss: 6.8051\n",
      "Epoch 118/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5695 - val_loss: 6.8024\n",
      "Epoch 119/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5667 - val_loss: 6.7997\n",
      "Epoch 120/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5639 - val_loss: 6.7970\n",
      "Epoch 121/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5612 - val_loss: 6.7943\n",
      "Epoch 122/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5584 - val_loss: 6.7917\n",
      "Epoch 123/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5557 - val_loss: 6.7890\n",
      "Epoch 124/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5529 - val_loss: 6.7864\n",
      "Epoch 125/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5502 - val_loss: 6.7838\n",
      "Epoch 126/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5474 - val_loss: 6.7811\n",
      "Epoch 127/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5447 - val_loss: 6.7785\n",
      "Epoch 128/5000\n",
      "39898/39898 [==============================] - ETA: 0s - loss: 7.209 - 1s 22us/step - loss: 7.5420 - val_loss: 6.7759\n",
      "Epoch 129/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5393 - val_loss: 6.7733\n",
      "Epoch 130/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5366 - val_loss: 6.7707\n",
      "Epoch 131/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5339 - val_loss: 6.7682\n",
      "Epoch 132/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5313 - val_loss: 6.7656\n",
      "Epoch 133/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5286 - val_loss: 6.7630\n",
      "Epoch 134/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5260 - val_loss: 6.7605\n",
      "Epoch 135/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5233 - val_loss: 6.7580\n",
      "Epoch 136/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5207 - val_loss: 6.7554\n",
      "Epoch 137/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5181 - val_loss: 6.7529\n",
      "Epoch 138/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5155 - val_loss: 6.7504\n",
      "Epoch 139/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5129 - val_loss: 6.7479\n",
      "Epoch 140/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5103 - val_loss: 6.7454\n",
      "Epoch 141/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5077 - val_loss: 6.7429\n",
      "Epoch 142/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5052 - val_loss: 6.7405\n",
      "Epoch 143/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5026 - val_loss: 6.7380\n",
      "Epoch 144/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.5001 - val_loss: 6.7356\n",
      "Epoch 145/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4975 - val_loss: 6.7331\n",
      "Epoch 146/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4950 - val_loss: 6.7307\n",
      "Epoch 147/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4925 - val_loss: 6.7283\n",
      "Epoch 148/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4899 - val_loss: 6.7259\n",
      "Epoch 149/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4874 - val_loss: 6.7235\n",
      "Epoch 150/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4849 - val_loss: 6.7211\n",
      "Epoch 151/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4824 - val_loss: 6.7187\n",
      "Epoch 152/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4800 - val_loss: 6.7163\n",
      "Epoch 153/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4775 - val_loss: 6.7139\n",
      "Epoch 154/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4750 - val_loss: 6.7116\n",
      "Epoch 155/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4726 - val_loss: 6.7092\n",
      "Epoch 156/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4702 - val_loss: 6.7069\n",
      "Epoch 157/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4677 - val_loss: 6.7045\n",
      "Epoch 158/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4653 - val_loss: 6.7022\n",
      "Epoch 159/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4629 - val_loss: 6.6999\n",
      "Epoch 160/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4605 - val_loss: 6.6976\n",
      "Epoch 161/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4581 - val_loss: 6.6953\n",
      "Epoch 162/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4557 - val_loss: 6.6930\n",
      "Epoch 163/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4533 - val_loss: 6.6907\n",
      "Epoch 164/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4509 - val_loss: 6.6884\n",
      "Epoch 165/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4485 - val_loss: 6.6861\n",
      "Epoch 166/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4462 - val_loss: 6.6839\n",
      "Epoch 167/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 7.4438 - val_loss: 6.6816\n",
      "Epoch 168/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4415 - val_loss: 6.6793\n",
      "Epoch 169/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4392 - val_loss: 6.6771\n",
      "Epoch 170/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4368 - val_loss: 6.6749\n",
      "Epoch 171/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4345 - val_loss: 6.6726\n",
      "Epoch 172/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4322 - val_loss: 6.6704\n",
      "Epoch 173/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4299 - val_loss: 6.6682\n",
      "Epoch 174/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4276 - val_loss: 6.6660\n",
      "Epoch 175/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4253 - val_loss: 6.6638\n",
      "Epoch 176/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4230 - val_loss: 6.6616\n",
      "Epoch 177/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4207 - val_loss: 6.6594\n",
      "Epoch 178/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4185 - val_loss: 6.6573\n",
      "Epoch 179/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4162 - val_loss: 6.6551\n",
      "Epoch 180/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4140 - val_loss: 6.6529\n",
      "Epoch 181/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4118 - val_loss: 6.6508\n",
      "Epoch 182/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4095 - val_loss: 6.6486\n",
      "Epoch 183/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4073 - val_loss: 6.6465\n",
      "Epoch 184/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4051 - val_loss: 6.6444\n",
      "Epoch 185/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4029 - val_loss: 6.6423\n",
      "Epoch 186/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.4007 - val_loss: 6.6402\n",
      "Epoch 187/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3985 - val_loss: 6.6380\n",
      "Epoch 188/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3963 - val_loss: 6.6359\n",
      "Epoch 189/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3941 - val_loss: 6.6339\n",
      "Epoch 190/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3920 - val_loss: 6.6318\n",
      "Epoch 191/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3898 - val_loss: 6.6297\n",
      "Epoch 192/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3876 - val_loss: 6.6276\n",
      "Epoch 193/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3855 - val_loss: 6.6256\n",
      "Epoch 194/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3833 - val_loss: 6.6235\n",
      "Epoch 195/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3812 - val_loss: 6.6215\n",
      "Epoch 196/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3791 - val_loss: 6.6195\n",
      "Epoch 197/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3770 - val_loss: 6.6174\n",
      "Epoch 198/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3749 - val_loss: 6.6154\n",
      "Epoch 199/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3727 - val_loss: 6.6134\n",
      "Epoch 200/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3706 - val_loss: 6.6114\n",
      "Epoch 201/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3686 - val_loss: 6.6094\n",
      "Epoch 202/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3665 - val_loss: 6.6074\n",
      "Epoch 203/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3644 - val_loss: 6.6054\n",
      "Epoch 204/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3623 - val_loss: 6.6034\n",
      "Epoch 205/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3602 - val_loss: 6.6014\n",
      "Epoch 206/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3582 - val_loss: 6.5995\n",
      "Epoch 207/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3561 - val_loss: 6.5975\n",
      "Epoch 208/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3541 - val_loss: 6.5955\n",
      "Epoch 209/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.3520 - val_loss: 6.5936\n",
      "Epoch 210/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3500 - val_loss: 6.5917\n",
      "Epoch 211/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3480 - val_loss: 6.5897\n",
      "Epoch 212/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3460 - val_loss: 6.5878\n",
      "Epoch 213/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3440 - val_loss: 6.5859\n",
      "Epoch 214/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3420 - val_loss: 6.5840\n",
      "Epoch 215/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3400 - val_loss: 6.5820\n",
      "Epoch 216/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3380 - val_loss: 6.5801\n",
      "Epoch 217/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 7.3360 - val_loss: 6.5782\n",
      "Epoch 218/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 7.3340 - val_loss: 6.5763\n",
      "Epoch 219/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 7.3320 - val_loss: 6.5744\n",
      "Epoch 220/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.3301 - val_loss: 6.5726\n",
      "Epoch 221/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3281 - val_loss: 6.5707\n",
      "Epoch 222/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.3262 - val_loss: 6.5688\n",
      "Epoch 223/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3242 - val_loss: 6.5670\n",
      "Epoch 224/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 7.3223 - val_loss: 6.5651\n",
      "Epoch 225/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 7.3203 - val_loss: 6.5632\n",
      "Epoch 226/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.3184 - val_loss: 6.5614\n",
      "Epoch 227/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3165 - val_loss: 6.5595\n",
      "Epoch 228/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.3146 - val_loss: 6.5577\n",
      "Epoch 229/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 7.3126 - val_loss: 6.5559\n",
      "Epoch 230/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.3107 - val_loss: 6.5540\n",
      "Epoch 231/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3088 - val_loss: 6.5522\n",
      "Epoch 232/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3069 - val_loss: 6.5504\n",
      "Epoch 233/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.3050 - val_loss: 6.5486\n",
      "Epoch 234/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3031 - val_loss: 6.5468\n",
      "Epoch 235/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.3012 - val_loss: 6.5450\n",
      "Epoch 236/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2993 - val_loss: 6.5432\n",
      "Epoch 237/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2975 - val_loss: 6.5414\n",
      "Epoch 238/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2956 - val_loss: 6.5396\n",
      "Epoch 239/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2938 - val_loss: 6.5379\n",
      "Epoch 240/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.2919 - val_loss: 6.5361\n",
      "Epoch 241/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2901 - val_loss: 6.5343\n",
      "Epoch 242/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2882 - val_loss: 6.5326\n",
      "Epoch 243/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2864 - val_loss: 6.5309\n",
      "Epoch 244/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2846 - val_loss: 6.5291\n",
      "Epoch 245/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2827 - val_loss: 6.5274\n",
      "Epoch 246/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.2809 - val_loss: 6.5256\n",
      "Epoch 247/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2791 - val_loss: 6.5239\n",
      "Epoch 248/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2773 - val_loss: 6.5222\n",
      "Epoch 249/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2755 - val_loss: 6.5205\n",
      "Epoch 250/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2737 - val_loss: 6.5188\n",
      "Epoch 251/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2719 - val_loss: 6.5171\n",
      "Epoch 252/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2701 - val_loss: 6.5154\n",
      "Epoch 253/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2683 - val_loss: 6.5137\n",
      "Epoch 254/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2666 - val_loss: 6.5120\n",
      "Epoch 255/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2648 - val_loss: 6.5103\n",
      "Epoch 256/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2630 - val_loss: 6.5086\n",
      "Epoch 257/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2613 - val_loss: 6.5069\n",
      "Epoch 258/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2595 - val_loss: 6.5053\n",
      "Epoch 259/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2578 - val_loss: 6.5036\n",
      "Epoch 260/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2560 - val_loss: 6.5019\n",
      "Epoch 261/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2543 - val_loss: 6.5003\n",
      "Epoch 262/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2525 - val_loss: 6.4986\n",
      "Epoch 263/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2508 - val_loss: 6.4970\n",
      "Epoch 264/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2491 - val_loss: 6.4954\n",
      "Epoch 265/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2474 - val_loss: 6.4937\n",
      "Epoch 266/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2457 - val_loss: 6.4921\n",
      "Epoch 267/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2440 - val_loss: 6.4905\n",
      "Epoch 268/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2423 - val_loss: 6.4888\n",
      "Epoch 269/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2406 - val_loss: 6.4872\n",
      "Epoch 270/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2389 - val_loss: 6.4856\n",
      "Epoch 271/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2372 - val_loss: 6.4840\n",
      "Epoch 272/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2355 - val_loss: 6.4824\n",
      "Epoch 273/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2338 - val_loss: 6.4808\n",
      "Epoch 274/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2321 - val_loss: 6.4792\n",
      "Epoch 275/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2305 - val_loss: 6.4776\n",
      "Epoch 276/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2288 - val_loss: 6.4760\n",
      "Epoch 277/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2272 - val_loss: 6.4744\n",
      "Epoch 278/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2255 - val_loss: 6.4728\n",
      "Epoch 279/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2239 - val_loss: 6.4713\n",
      "Epoch 280/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2222 - val_loss: 6.4697\n",
      "Epoch 281/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2206 - val_loss: 6.4682\n",
      "Epoch 282/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2190 - val_loss: 6.4666\n",
      "Epoch 283/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2173 - val_loss: 6.4651\n",
      "Epoch 284/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2157 - val_loss: 6.4635\n",
      "Epoch 285/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2141 - val_loss: 6.4620\n",
      "Epoch 286/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2125 - val_loss: 6.4604\n",
      "Epoch 287/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2109 - val_loss: 6.4589\n",
      "Epoch 288/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.2093 - val_loss: 6.4574\n",
      "Epoch 289/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2077 - val_loss: 6.4559\n",
      "Epoch 290/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2061 - val_loss: 6.4543\n",
      "Epoch 291/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2045 - val_loss: 6.4528\n",
      "Epoch 292/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2029 - val_loss: 6.4513\n",
      "Epoch 293/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.2013 - val_loss: 6.4498\n",
      "Epoch 294/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1998 - val_loss: 6.4483\n",
      "Epoch 295/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1982 - val_loss: 6.4468\n",
      "Epoch 296/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1966 - val_loss: 6.4453\n",
      "Epoch 297/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1951 - val_loss: 6.4439\n",
      "Epoch 298/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.1935 - val_loss: 6.4424\n",
      "Epoch 299/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1920 - val_loss: 6.4409\n",
      "Epoch 300/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1904 - val_loss: 6.4394\n",
      "Epoch 301/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1889 - val_loss: 6.4380\n",
      "Epoch 302/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1874 - val_loss: 6.4365\n",
      "Epoch 303/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1858 - val_loss: 6.4350\n",
      "Epoch 304/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1843 - val_loss: 6.4336\n",
      "Epoch 305/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1828 - val_loss: 6.4321\n",
      "Epoch 306/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1812 - val_loss: 6.4307\n",
      "Epoch 307/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1797 - val_loss: 6.4292\n",
      "Epoch 308/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.1782 - val_loss: 6.4278\n",
      "Epoch 309/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1767 - val_loss: 6.4263\n",
      "Epoch 310/5000\n",
      "39898/39898 [==============================] - 1s 19us/step - loss: 7.1752 - val_loss: 6.4249\n",
      "Epoch 311/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 7.1737 - val_loss: 6.4235\n",
      "Epoch 312/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1722 - val_loss: 6.4221\n",
      "Epoch 313/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1707 - val_loss: 6.4206\n",
      "Epoch 314/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1692 - val_loss: 6.4192\n",
      "Epoch 315/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1678 - val_loss: 6.4178\n",
      "Epoch 316/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1663 - val_loss: 6.4164\n",
      "Epoch 317/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1648 - val_loss: 6.4150\n",
      "Epoch 318/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1633 - val_loss: 6.4136\n",
      "Epoch 319/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1619 - val_loss: 6.4122\n",
      "Epoch 320/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1604 - val_loss: 6.4108\n",
      "Epoch 321/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1590 - val_loss: 6.4095\n",
      "Epoch 322/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1575 - val_loss: 6.4081\n",
      "Epoch 323/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1561 - val_loss: 6.4067\n",
      "Epoch 324/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1546 - val_loss: 6.4053\n",
      "Epoch 325/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1532 - val_loss: 6.4039\n",
      "Epoch 326/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1518 - val_loss: 6.4026\n",
      "Epoch 327/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1503 - val_loss: 6.4012\n",
      "Epoch 328/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1489 - val_loss: 6.3999\n",
      "Epoch 329/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1475 - val_loss: 6.3985\n",
      "Epoch 330/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1461 - val_loss: 6.3972\n",
      "Epoch 331/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1446 - val_loss: 6.3958\n",
      "Epoch 332/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1432 - val_loss: 6.3945\n",
      "Epoch 333/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1418 - val_loss: 6.3932\n",
      "Epoch 334/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1404 - val_loss: 6.3918\n",
      "Epoch 335/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1390 - val_loss: 6.3905\n",
      "Epoch 336/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1376 - val_loss: 6.3892\n",
      "Epoch 337/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1362 - val_loss: 6.3878\n",
      "Epoch 338/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1348 - val_loss: 6.3865\n",
      "Epoch 339/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1334 - val_loss: 6.3852\n",
      "Epoch 340/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1320 - val_loss: 6.3839\n",
      "Epoch 341/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1306 - val_loss: 6.3826\n",
      "Epoch 342/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1293 - val_loss: 6.3813\n",
      "Epoch 343/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1279 - val_loss: 6.3800\n",
      "Epoch 344/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1265 - val_loss: 6.3787\n",
      "Epoch 345/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1251 - val_loss: 6.3774\n",
      "Epoch 346/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1238 - val_loss: 6.3761\n",
      "Epoch 347/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1224 - val_loss: 6.3748\n",
      "Epoch 348/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1210 - val_loss: 6.3735\n",
      "Epoch 349/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.1197 - val_loss: 6.3722\n",
      "Epoch 350/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 7.1183 - val_loss: 6.3709\n",
      "Epoch 351/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1169 - val_loss: 6.3697\n",
      "Epoch 352/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1156 - val_loss: 6.3684\n",
      "Epoch 353/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1143 - val_loss: 6.3671\n",
      "Epoch 354/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1129 - val_loss: 6.3658\n",
      "Epoch 355/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1116 - val_loss: 6.3646\n",
      "Epoch 356/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.1103 - val_loss: 6.3633\n",
      "Epoch 357/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.1090 - val_loss: 6.3621\n",
      "Epoch 358/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.1077 - val_loss: 6.3608\n",
      "Epoch 359/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1063 - val_loss: 6.3596\n",
      "Epoch 360/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.1050 - val_loss: 6.3583\n",
      "Epoch 361/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 7.1037 - val_loss: 6.3571\n",
      "Epoch 362/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.1024 - val_loss: 6.3558\n",
      "Epoch 363/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.1011 - val_loss: 6.3546\n",
      "Epoch 364/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0998 - val_loss: 6.3534\n",
      "Epoch 365/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0985 - val_loss: 6.3521\n",
      "Epoch 366/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0972 - val_loss: 6.3509\n",
      "Epoch 367/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0959 - val_loss: 6.3497\n",
      "Epoch 368/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0947 - val_loss: 6.3485\n",
      "Epoch 369/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0934 - val_loss: 6.3472\n",
      "Epoch 370/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0921 - val_loss: 6.3460\n",
      "Epoch 371/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0908 - val_loss: 6.3448\n",
      "Epoch 372/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0895 - val_loss: 6.3436\n",
      "Epoch 373/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0883 - val_loss: 6.3424\n",
      "Epoch 374/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0870 - val_loss: 6.3412\n",
      "Epoch 375/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0857 - val_loss: 6.3400\n",
      "Epoch 376/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0844 - val_loss: 6.3388\n",
      "Epoch 377/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0832 - val_loss: 6.3376\n",
      "Epoch 378/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0819 - val_loss: 6.3364\n",
      "Epoch 379/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0807 - val_loss: 6.3352\n",
      "Epoch 380/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0794 - val_loss: 6.3340\n",
      "Epoch 381/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0781 - val_loss: 6.3329\n",
      "Epoch 382/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0769 - val_loss: 6.3317\n",
      "Epoch 383/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0757 - val_loss: 6.3305\n",
      "Epoch 384/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0744 - val_loss: 6.3293\n",
      "Epoch 385/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0732 - val_loss: 6.3282\n",
      "Epoch 386/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0720 - val_loss: 6.3270\n",
      "Epoch 387/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0707 - val_loss: 6.3258\n",
      "Epoch 388/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0695 - val_loss: 6.3247\n",
      "Epoch 389/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0683 - val_loss: 6.3235\n",
      "Epoch 390/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0670 - val_loss: 6.3224\n",
      "Epoch 391/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0658 - val_loss: 6.3212\n",
      "Epoch 392/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0646 - val_loss: 6.3201\n",
      "Epoch 393/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0634 - val_loss: 6.3189\n",
      "Epoch 394/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0622 - val_loss: 6.3178\n",
      "Epoch 395/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0610 - val_loss: 6.3166\n",
      "Epoch 396/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0598 - val_loss: 6.3155\n",
      "Epoch 397/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.0586 - val_loss: 6.3143\n",
      "Epoch 398/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0574 - val_loss: 6.3132\n",
      "Epoch 399/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0562 - val_loss: 6.3121\n",
      "Epoch 400/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0550 - val_loss: 6.3110\n",
      "Epoch 401/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0538 - val_loss: 6.3098\n",
      "Epoch 402/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0526 - val_loss: 6.3087\n",
      "Epoch 403/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0514 - val_loss: 6.3076\n",
      "Epoch 404/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0503 - val_loss: 6.3065\n",
      "Epoch 405/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0491 - val_loss: 6.3054\n",
      "Epoch 406/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0479 - val_loss: 6.3043\n",
      "Epoch 407/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0468 - val_loss: 6.3032\n",
      "Epoch 408/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0456 - val_loss: 6.3021\n",
      "Epoch 409/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0444 - val_loss: 6.3010\n",
      "Epoch 410/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0433 - val_loss: 6.2999\n",
      "Epoch 411/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0421 - val_loss: 6.2988\n",
      "Epoch 412/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0409 - val_loss: 6.2977\n",
      "Epoch 413/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0398 - val_loss: 6.2966\n",
      "Epoch 414/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0386 - val_loss: 6.2955\n",
      "Epoch 415/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0375 - val_loss: 6.2944\n",
      "Epoch 416/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0364 - val_loss: 6.2933\n",
      "Epoch 417/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0352 - val_loss: 6.2923\n",
      "Epoch 418/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0341 - val_loss: 6.2912\n",
      "Epoch 419/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0329 - val_loss: 6.2901\n",
      "Epoch 420/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0318 - val_loss: 6.2890\n",
      "Epoch 421/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0307 - val_loss: 6.2880\n",
      "Epoch 422/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0296 - val_loss: 6.2869\n",
      "Epoch 423/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0284 - val_loss: 6.2858\n",
      "Epoch 424/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0273 - val_loss: 6.2848\n",
      "Epoch 425/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0262 - val_loss: 6.2837\n",
      "Epoch 426/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0251 - val_loss: 6.2827\n",
      "Epoch 427/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.0240 - val_loss: 6.2816\n",
      "Epoch 428/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0229 - val_loss: 6.2805\n",
      "Epoch 429/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0218 - val_loss: 6.2795\n",
      "Epoch 430/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0206 - val_loss: 6.2784\n",
      "Epoch 431/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0195 - val_loss: 6.2774\n",
      "Epoch 432/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0184 - val_loss: 6.2763\n",
      "Epoch 433/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0173 - val_loss: 6.2753\n",
      "Epoch 434/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0162 - val_loss: 6.2742\n",
      "Epoch 435/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0151 - val_loss: 6.2732\n",
      "Epoch 436/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0140 - val_loss: 6.2722\n",
      "Epoch 437/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0130 - val_loss: 6.2712\n",
      "Epoch 438/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0119 - val_loss: 6.2701\n",
      "Epoch 439/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0108 - val_loss: 6.2691\n",
      "Epoch 440/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 7.0097 - val_loss: 6.2681\n",
      "Epoch 441/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0086 - val_loss: 6.2670\n",
      "Epoch 442/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0075 - val_loss: 6.2660\n",
      "Epoch 443/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0065 - val_loss: 6.2650\n",
      "Epoch 444/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0054 - val_loss: 6.2640\n",
      "Epoch 445/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0043 - val_loss: 6.2630\n",
      "Epoch 446/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0033 - val_loss: 6.2620\n",
      "Epoch 447/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0022 - val_loss: 6.2610\n",
      "Epoch 448/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0011 - val_loss: 6.2600\n",
      "Epoch 449/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 7.0001 - val_loss: 6.2590\n",
      "Epoch 450/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.9990 - val_loss: 6.2580\n",
      "Epoch 451/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9980 - val_loss: 6.2570\n",
      "Epoch 452/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9969 - val_loss: 6.2560\n",
      "Epoch 453/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9959 - val_loss: 6.2550\n",
      "Epoch 454/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9948 - val_loss: 6.2540\n",
      "Epoch 455/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9938 - val_loss: 6.2530\n",
      "Epoch 456/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9927 - val_loss: 6.2520\n",
      "Epoch 457/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9917 - val_loss: 6.2511\n",
      "Epoch 458/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9906 - val_loss: 6.2501\n",
      "Epoch 459/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9896 - val_loss: 6.2491\n",
      "Epoch 460/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9886 - val_loss: 6.2481\n",
      "Epoch 461/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9875 - val_loss: 6.2472\n",
      "Epoch 462/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9865 - val_loss: 6.2462\n",
      "Epoch 463/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.9855 - val_loss: 6.2452\n",
      "Epoch 464/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9845 - val_loss: 6.2443\n",
      "Epoch 465/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9834 - val_loss: 6.2433\n",
      "Epoch 466/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9824 - val_loss: 6.2424\n",
      "Epoch 467/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9814 - val_loss: 6.2414\n",
      "Epoch 468/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9804 - val_loss: 6.2405\n",
      "Epoch 469/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9794 - val_loss: 6.2395\n",
      "Epoch 470/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9784 - val_loss: 6.2386\n",
      "Epoch 471/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9774 - val_loss: 6.2376\n",
      "Epoch 472/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9764 - val_loss: 6.2367\n",
      "Epoch 473/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9754 - val_loss: 6.2357\n",
      "Epoch 474/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9744 - val_loss: 6.2348\n",
      "Epoch 475/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9734 - val_loss: 6.2338\n",
      "Epoch 476/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9724 - val_loss: 6.2329\n",
      "Epoch 477/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9714 - val_loss: 6.2319\n",
      "Epoch 478/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9704 - val_loss: 6.2310\n",
      "Epoch 479/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9694 - val_loss: 6.2301\n",
      "Epoch 480/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9684 - val_loss: 6.2291\n",
      "Epoch 481/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.9674 - val_loss: 6.2282\n",
      "Epoch 482/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.9664 - val_loss: 6.2273\n",
      "Epoch 483/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9655 - val_loss: 6.2263\n",
      "Epoch 484/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.9645 - val_loss: 6.2254\n",
      "Epoch 485/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9635 - val_loss: 6.2245\n",
      "Epoch 486/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.9625 - val_loss: 6.2236\n",
      "Epoch 487/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9615 - val_loss: 6.2227\n",
      "Epoch 488/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.9606 - val_loss: 6.2217\n",
      "Epoch 489/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9596 - val_loss: 6.2208\n",
      "Epoch 490/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.9586 - val_loss: 6.2199\n",
      "Epoch 491/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.9577 - val_loss: 6.2190\n",
      "Epoch 492/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.9567 - val_loss: 6.2181\n",
      "Epoch 493/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9558 - val_loss: 6.2172\n",
      "Epoch 494/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9548 - val_loss: 6.2163\n",
      "Epoch 495/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9538 - val_loss: 6.2154\n",
      "Epoch 496/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.9529 - val_loss: 6.2145\n",
      "Epoch 497/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9519 - val_loss: 6.2136\n",
      "Epoch 498/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9510 - val_loss: 6.2127\n",
      "Epoch 499/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9500 - val_loss: 6.2118\n",
      "Epoch 500/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9491 - val_loss: 6.2109\n",
      "Epoch 501/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9482 - val_loss: 6.2101\n",
      "Epoch 502/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9472 - val_loss: 6.2092\n",
      "Epoch 503/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.9463 - val_loss: 6.2083\n",
      "Epoch 504/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9453 - val_loss: 6.2074\n",
      "Epoch 505/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.9444 - val_loss: 6.2065\n",
      "Epoch 506/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9435 - val_loss: 6.2056\n",
      "Epoch 507/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9425 - val_loss: 6.2048\n",
      "Epoch 508/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9416 - val_loss: 6.2039\n",
      "Epoch 509/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9407 - val_loss: 6.2030\n",
      "Epoch 510/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9398 - val_loss: 6.2022\n",
      "Epoch 511/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9389 - val_loss: 6.2013\n",
      "Epoch 512/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9380 - val_loss: 6.2004\n",
      "Epoch 513/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9370 - val_loss: 6.1996\n",
      "Epoch 514/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9361 - val_loss: 6.1987\n",
      "Epoch 515/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.9352 - val_loss: 6.1978\n",
      "Epoch 516/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9343 - val_loss: 6.1970\n",
      "Epoch 517/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9334 - val_loss: 6.1961\n",
      "Epoch 518/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9325 - val_loss: 6.1953\n",
      "Epoch 519/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9316 - val_loss: 6.1944\n",
      "Epoch 520/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9306 - val_loss: 6.1936\n",
      "Epoch 521/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9297 - val_loss: 6.1927\n",
      "Epoch 522/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9288 - val_loss: 6.1919\n",
      "Epoch 523/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9280 - val_loss: 6.1910\n",
      "Epoch 524/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9271 - val_loss: 6.1902\n",
      "Epoch 525/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9262 - val_loss: 6.1893\n",
      "Epoch 526/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9253 - val_loss: 6.1885\n",
      "Epoch 527/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9244 - val_loss: 6.1876\n",
      "Epoch 528/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9235 - val_loss: 6.1868\n",
      "Epoch 529/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.9226 - val_loss: 6.1860\n",
      "Epoch 530/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9217 - val_loss: 6.1851\n",
      "Epoch 531/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9208 - val_loss: 6.1843\n",
      "Epoch 532/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9199 - val_loss: 6.1835\n",
      "Epoch 533/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9191 - val_loss: 6.1826\n",
      "Epoch 534/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9182 - val_loss: 6.1818\n",
      "Epoch 535/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9173 - val_loss: 6.1810\n",
      "Epoch 536/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9164 - val_loss: 6.1801\n",
      "Epoch 537/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9156 - val_loss: 6.1793\n",
      "Epoch 538/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.9147 - val_loss: 6.1785\n",
      "Epoch 539/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9138 - val_loss: 6.1777\n",
      "Epoch 540/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9130 - val_loss: 6.1768\n",
      "Epoch 541/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9121 - val_loss: 6.1760\n",
      "Epoch 542/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9112 - val_loss: 6.1752\n",
      "Epoch 543/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9104 - val_loss: 6.1744\n",
      "Epoch 544/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9095 - val_loss: 6.1736\n",
      "Epoch 545/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9087 - val_loss: 6.1728\n",
      "Epoch 546/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9078 - val_loss: 6.1720\n",
      "Epoch 547/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9069 - val_loss: 6.1712\n",
      "Epoch 548/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9061 - val_loss: 6.1704\n",
      "Epoch 549/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9052 - val_loss: 6.1696\n",
      "Epoch 550/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9044 - val_loss: 6.1688\n",
      "Epoch 551/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9035 - val_loss: 6.1680\n",
      "Epoch 552/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9027 - val_loss: 6.1672\n",
      "Epoch 553/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9018 - val_loss: 6.1664\n",
      "Epoch 554/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9010 - val_loss: 6.1656\n",
      "Epoch 555/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.9001 - val_loss: 6.1648\n",
      "Epoch 556/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8993 - val_loss: 6.1640\n",
      "Epoch 557/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8984 - val_loss: 6.1632\n",
      "Epoch 558/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8976 - val_loss: 6.1624\n",
      "Epoch 559/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.8968 - val_loss: 6.1616\n",
      "Epoch 560/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8959 - val_loss: 6.1608\n",
      "Epoch 561/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8951 - val_loss: 6.1600\n",
      "Epoch 562/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8943 - val_loss: 6.1593\n",
      "Epoch 563/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8934 - val_loss: 6.1585\n",
      "Epoch 564/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8926 - val_loss: 6.1577\n",
      "Epoch 565/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8918 - val_loss: 6.1569\n",
      "Epoch 566/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8909 - val_loss: 6.1561\n",
      "Epoch 567/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8901 - val_loss: 6.1554\n",
      "Epoch 568/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8893 - val_loss: 6.1546\n",
      "Epoch 569/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8885 - val_loss: 6.1538\n",
      "Epoch 570/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8876 - val_loss: 6.1530\n",
      "Epoch 571/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.8868 - val_loss: 6.1523\n",
      "Epoch 572/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8860 - val_loss: 6.1515\n",
      "Epoch 573/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8852 - val_loss: 6.1507\n",
      "Epoch 574/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8844 - val_loss: 6.1500\n",
      "Epoch 575/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8836 - val_loss: 6.1492\n",
      "Epoch 576/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8828 - val_loss: 6.1484\n",
      "Epoch 577/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8820 - val_loss: 6.1477\n",
      "Epoch 578/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8812 - val_loss: 6.1469\n",
      "Epoch 579/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8804 - val_loss: 6.1461\n",
      "Epoch 580/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8796 - val_loss: 6.1454\n",
      "Epoch 581/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8788 - val_loss: 6.1446\n",
      "Epoch 582/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8780 - val_loss: 6.1439\n",
      "Epoch 583/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8772 - val_loss: 6.1431\n",
      "Epoch 584/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8764 - val_loss: 6.1424\n",
      "Epoch 585/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8756 - val_loss: 6.1416\n",
      "Epoch 586/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8748 - val_loss: 6.1409\n",
      "Epoch 587/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8740 - val_loss: 6.1401\n",
      "Epoch 588/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.8732 - val_loss: 6.1394\n",
      "Epoch 589/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8724 - val_loss: 6.1386\n",
      "Epoch 590/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8716 - val_loss: 6.1379\n",
      "Epoch 591/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8709 - val_loss: 6.1371\n",
      "Epoch 592/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.8701 - val_loss: 6.1364\n",
      "Epoch 593/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8693 - val_loss: 6.1356\n",
      "Epoch 594/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.8685 - val_loss: 6.1349\n",
      "Epoch 595/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8677 - val_loss: 6.1342\n",
      "Epoch 596/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8670 - val_loss: 6.1335\n",
      "Epoch 597/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8662 - val_loss: 6.1327\n",
      "Epoch 598/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8654 - val_loss: 6.1320\n",
      "Epoch 599/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8646 - val_loss: 6.1313\n",
      "Epoch 600/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8639 - val_loss: 6.1305\n",
      "Epoch 601/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8631 - val_loss: 6.1298\n",
      "Epoch 602/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8624 - val_loss: 6.1291\n",
      "Epoch 603/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8616 - val_loss: 6.1284\n",
      "Epoch 604/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8608 - val_loss: 6.1277\n",
      "Epoch 605/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8601 - val_loss: 6.1270\n",
      "Epoch 606/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8593 - val_loss: 6.1262\n",
      "Epoch 607/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8585 - val_loss: 6.1255\n",
      "Epoch 608/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8578 - val_loss: 6.1248\n",
      "Epoch 609/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8570 - val_loss: 6.1241\n",
      "Epoch 610/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8563 - val_loss: 6.1234\n",
      "Epoch 611/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8555 - val_loss: 6.1227\n",
      "Epoch 612/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.8548 - val_loss: 6.1220\n",
      "Epoch 613/5000\n",
      "39898/39898 [==============================] - 1s 19us/step - loss: 6.8540 - val_loss: 6.1213\n",
      "Epoch 614/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.8533 - val_loss: 6.1206\n",
      "Epoch 615/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8525 - val_loss: 6.1199\n",
      "Epoch 616/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8518 - val_loss: 6.1192\n",
      "Epoch 617/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8510 - val_loss: 6.1184\n",
      "Epoch 618/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8503 - val_loss: 6.1177\n",
      "Epoch 619/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8496 - val_loss: 6.1170\n",
      "Epoch 620/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8488 - val_loss: 6.1163\n",
      "Epoch 621/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8481 - val_loss: 6.1156\n",
      "Epoch 622/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8473 - val_loss: 6.1150\n",
      "Epoch 623/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8466 - val_loss: 6.1143\n",
      "Epoch 624/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.8459 - val_loss: 6.1136\n",
      "Epoch 625/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8451 - val_loss: 6.1129\n",
      "Epoch 626/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8444 - val_loss: 6.1122\n",
      "Epoch 627/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8437 - val_loss: 6.1115\n",
      "Epoch 628/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8429 - val_loss: 6.1108\n",
      "Epoch 629/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8422 - val_loss: 6.1101\n",
      "Epoch 630/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8415 - val_loss: 6.1094\n",
      "Epoch 631/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8407 - val_loss: 6.1087\n",
      "Epoch 632/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8400 - val_loss: 6.1080\n",
      "Epoch 633/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8393 - val_loss: 6.1073\n",
      "Epoch 634/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8385 - val_loss: 6.1066\n",
      "Epoch 635/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8378 - val_loss: 6.1060\n",
      "Epoch 636/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8371 - val_loss: 6.1053\n",
      "Epoch 637/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.8364 - val_loss: 6.1046\n",
      "Epoch 638/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8356 - val_loss: 6.1039\n",
      "Epoch 639/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8349 - val_loss: 6.1032\n",
      "Epoch 640/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8342 - val_loss: 6.1025\n",
      "Epoch 641/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.8335 - val_loss: 6.1019\n",
      "Epoch 642/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8328 - val_loss: 6.1012\n",
      "Epoch 643/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8320 - val_loss: 6.1005\n",
      "Epoch 644/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8313 - val_loss: 6.0998\n",
      "Epoch 645/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8306 - val_loss: 6.0992\n",
      "Epoch 646/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8299 - val_loss: 6.0985\n",
      "Epoch 647/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8292 - val_loss: 6.0978\n",
      "Epoch 648/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8285 - val_loss: 6.0972\n",
      "Epoch 649/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8278 - val_loss: 6.0965\n",
      "Epoch 650/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8271 - val_loss: 6.0959\n",
      "Epoch 651/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8264 - val_loss: 6.0952\n",
      "Epoch 652/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8257 - val_loss: 6.0945\n",
      "Epoch 653/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8250 - val_loss: 6.0939\n",
      "Epoch 654/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8243 - val_loss: 6.0932\n",
      "Epoch 655/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8236 - val_loss: 6.0926\n",
      "Epoch 656/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8229 - val_loss: 6.0919\n",
      "Epoch 657/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8222 - val_loss: 6.0913\n",
      "Epoch 658/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8216 - val_loss: 6.0906\n",
      "Epoch 659/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8209 - val_loss: 6.0900\n",
      "Epoch 660/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8202 - val_loss: 6.0893\n",
      "Epoch 661/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8195 - val_loss: 6.0887\n",
      "Epoch 662/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8188 - val_loss: 6.0880\n",
      "Epoch 663/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8181 - val_loss: 6.0874\n",
      "Epoch 664/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8174 - val_loss: 6.0867\n",
      "Epoch 665/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8167 - val_loss: 6.0861\n",
      "Epoch 666/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8161 - val_loss: 6.0854\n",
      "Epoch 667/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8154 - val_loss: 6.0848\n",
      "Epoch 668/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8147 - val_loss: 6.0841\n",
      "Epoch 669/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8140 - val_loss: 6.0835\n",
      "Epoch 670/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8133 - val_loss: 6.0828\n",
      "Epoch 671/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8126 - val_loss: 6.0822\n",
      "Epoch 672/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8119 - val_loss: 6.0816\n",
      "Epoch 673/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8112 - val_loss: 6.0809\n",
      "Epoch 674/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8106 - val_loss: 6.0803\n",
      "Epoch 675/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8099 - val_loss: 6.0797\n",
      "Epoch 676/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8092 - val_loss: 6.0790\n",
      "Epoch 677/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8086 - val_loss: 6.0784\n",
      "Epoch 678/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8079 - val_loss: 6.0778\n",
      "Epoch 679/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8072 - val_loss: 6.0771\n",
      "Epoch 680/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8066 - val_loss: 6.0765\n",
      "Epoch 681/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8059 - val_loss: 6.0759\n",
      "Epoch 682/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8052 - val_loss: 6.0753\n",
      "Epoch 683/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.8046 - val_loss: 6.0746\n",
      "Epoch 684/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8039 - val_loss: 6.0740\n",
      "Epoch 685/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8032 - val_loss: 6.0734\n",
      "Epoch 686/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8026 - val_loss: 6.0728\n",
      "Epoch 687/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8019 - val_loss: 6.0721\n",
      "Epoch 688/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8013 - val_loss: 6.0715\n",
      "Epoch 689/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.8006 - val_loss: 6.0709\n",
      "Epoch 690/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7999 - val_loss: 6.0703\n",
      "Epoch 691/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7993 - val_loss: 6.0697\n",
      "Epoch 692/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7986 - val_loss: 6.0690\n",
      "Epoch 693/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7980 - val_loss: 6.0684\n",
      "Epoch 694/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7973 - val_loss: 6.0678\n",
      "Epoch 695/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7967 - val_loss: 6.0672\n",
      "Epoch 696/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7960 - val_loss: 6.0666\n",
      "Epoch 697/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7954 - val_loss: 6.0660\n",
      "Epoch 698/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7947 - val_loss: 6.0654\n",
      "Epoch 699/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7941 - val_loss: 6.0648\n",
      "Epoch 700/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7934 - val_loss: 6.0641\n",
      "Epoch 701/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7928 - val_loss: 6.0635\n",
      "Epoch 702/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7922 - val_loss: 6.0629\n",
      "Epoch 703/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.7915 - val_loss: 6.0623\n",
      "Epoch 704/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7909 - val_loss: 6.0617\n",
      "Epoch 705/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7902 - val_loss: 6.0611\n",
      "Epoch 706/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7896 - val_loss: 6.0605\n",
      "Epoch 707/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7890 - val_loss: 6.0599\n",
      "Epoch 708/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7883 - val_loss: 6.0593\n",
      "Epoch 709/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.7877 - val_loss: 6.0587\n",
      "Epoch 710/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7871 - val_loss: 6.0581\n",
      "Epoch 711/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7864 - val_loss: 6.0575\n",
      "Epoch 712/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7858 - val_loss: 6.0569\n",
      "Epoch 713/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7851 - val_loss: 6.0563\n",
      "Epoch 714/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7845 - val_loss: 6.0557\n",
      "Epoch 715/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7839 - val_loss: 6.0551\n",
      "Epoch 716/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7833 - val_loss: 6.0545\n",
      "Epoch 717/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7826 - val_loss: 6.0539\n",
      "Epoch 718/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7820 - val_loss: 6.0534\n",
      "Epoch 719/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7814 - val_loss: 6.0528\n",
      "Epoch 720/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7808 - val_loss: 6.0522\n",
      "Epoch 721/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7801 - val_loss: 6.0516\n",
      "Epoch 722/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7795 - val_loss: 6.0510\n",
      "Epoch 723/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7789 - val_loss: 6.0504\n",
      "Epoch 724/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7783 - val_loss: 6.0498\n",
      "Epoch 725/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.7777 - val_loss: 6.0492\n",
      "Epoch 726/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.7770 - val_loss: 6.0487\n",
      "Epoch 727/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7764 - val_loss: 6.0481\n",
      "Epoch 728/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7758 - val_loss: 6.0475\n",
      "Epoch 729/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7752 - val_loss: 6.0469\n",
      "Epoch 730/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7746 - val_loss: 6.0463\n",
      "Epoch 731/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.7740 - val_loss: 6.0458\n",
      "Epoch 732/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7734 - val_loss: 6.0452\n",
      "Epoch 733/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7727 - val_loss: 6.0446\n",
      "Epoch 734/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7721 - val_loss: 6.0440\n",
      "Epoch 735/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.7715 - val_loss: 6.0434\n",
      "Epoch 736/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.7709 - val_loss: 6.0429\n",
      "Epoch 737/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7703 - val_loss: 6.0423\n",
      "Epoch 738/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7697 - val_loss: 6.0417\n",
      "Epoch 739/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7691 - val_loss: 6.0411\n",
      "Epoch 740/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7685 - val_loss: 6.0406\n",
      "Epoch 741/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7679 - val_loss: 6.0400\n",
      "Epoch 742/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7673 - val_loss: 6.0394\n",
      "Epoch 743/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7667 - val_loss: 6.0388\n",
      "Epoch 744/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.7661 - val_loss: 6.0383\n",
      "Epoch 745/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.7655 - val_loss: 6.0377\n",
      "Epoch 746/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7649 - val_loss: 6.0371\n",
      "Epoch 747/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.7643 - val_loss: 6.0365\n",
      "Epoch 748/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7637 - val_loss: 6.0360\n",
      "Epoch 749/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.7631 - val_loss: 6.0354\n",
      "Epoch 750/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.7625 - val_loss: 6.0348\n",
      "Epoch 751/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.7619 - val_loss: 6.0343\n",
      "Epoch 752/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.7613 - val_loss: 6.0337\n",
      "Epoch 753/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.7607 - val_loss: 6.0332\n",
      "Epoch 754/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7601 - val_loss: 6.0326\n",
      "Epoch 755/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.7596 - val_loss: 6.0320\n",
      "Epoch 756/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.7590 - val_loss: 6.0315\n",
      "Epoch 757/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7584 - val_loss: 6.0309\n",
      "Epoch 758/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7578 - val_loss: 6.0304\n",
      "Epoch 759/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.7572 - val_loss: 6.0298\n",
      "Epoch 760/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7566 - val_loss: 6.0293\n",
      "Epoch 761/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7561 - val_loss: 6.0287\n",
      "Epoch 762/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7555 - val_loss: 6.0282\n",
      "Epoch 763/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7549 - val_loss: 6.0276\n",
      "Epoch 764/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7543 - val_loss: 6.0271\n",
      "Epoch 765/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7537 - val_loss: 6.0265\n",
      "Epoch 766/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7532 - val_loss: 6.0260\n",
      "Epoch 767/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7526 - val_loss: 6.0254\n",
      "Epoch 768/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7520 - val_loss: 6.0249\n",
      "Epoch 769/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7514 - val_loss: 6.0244\n",
      "Epoch 770/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7508 - val_loss: 6.0238\n",
      "Epoch 771/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7503 - val_loss: 6.0233\n",
      "Epoch 772/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7497 - val_loss: 6.0227\n",
      "Epoch 773/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7491 - val_loss: 6.0222\n",
      "Epoch 774/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7486 - val_loss: 6.0217\n",
      "Epoch 775/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7480 - val_loss: 6.0211\n",
      "Epoch 776/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7474 - val_loss: 6.0206\n",
      "Epoch 777/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7469 - val_loss: 6.0200\n",
      "Epoch 778/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7463 - val_loss: 6.0195\n",
      "Epoch 779/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7457 - val_loss: 6.0190\n",
      "Epoch 780/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7452 - val_loss: 6.0184\n",
      "Epoch 781/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7446 - val_loss: 6.0179\n",
      "Epoch 782/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7441 - val_loss: 6.0174\n",
      "Epoch 783/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7435 - val_loss: 6.0169\n",
      "Epoch 784/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7430 - val_loss: 6.0163\n",
      "Epoch 785/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7424 - val_loss: 6.0158\n",
      "Epoch 786/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7418 - val_loss: 6.0153\n",
      "Epoch 787/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7413 - val_loss: 6.0147\n",
      "Epoch 788/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7407 - val_loss: 6.0142\n",
      "Epoch 789/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7402 - val_loss: 6.0137\n",
      "Epoch 790/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7396 - val_loss: 6.0132\n",
      "Epoch 791/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7391 - val_loss: 6.0126\n",
      "Epoch 792/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.7385 - val_loss: 6.0121\n",
      "Epoch 793/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7380 - val_loss: 6.0116\n",
      "Epoch 794/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7374 - val_loss: 6.0111\n",
      "Epoch 795/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7369 - val_loss: 6.0106\n",
      "Epoch 796/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7363 - val_loss: 6.0100\n",
      "Epoch 797/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7358 - val_loss: 6.0095\n",
      "Epoch 798/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7352 - val_loss: 6.0090\n",
      "Epoch 799/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7347 - val_loss: 6.0085\n",
      "Epoch 800/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7342 - val_loss: 6.0080\n",
      "Epoch 801/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7336 - val_loss: 6.0075\n",
      "Epoch 802/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7331 - val_loss: 6.0070\n",
      "Epoch 803/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7325 - val_loss: 6.0065\n",
      "Epoch 804/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7320 - val_loss: 6.0059\n",
      "Epoch 805/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7314 - val_loss: 6.0054\n",
      "Epoch 806/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7309 - val_loss: 6.0049\n",
      "Epoch 807/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7303 - val_loss: 6.0044\n",
      "Epoch 808/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7298 - val_loss: 6.0039\n",
      "Epoch 809/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7293 - val_loss: 6.0034\n",
      "Epoch 810/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7287 - val_loss: 6.0029\n",
      "Epoch 811/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7282 - val_loss: 6.0024\n",
      "Epoch 812/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7277 - val_loss: 6.0019\n",
      "Epoch 813/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7271 - val_loss: 6.0014\n",
      "Epoch 814/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7266 - val_loss: 6.0009\n",
      "Epoch 815/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7261 - val_loss: 6.0004\n",
      "Epoch 816/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7255 - val_loss: 5.9999\n",
      "Epoch 817/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7250 - val_loss: 5.9994\n",
      "Epoch 818/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7245 - val_loss: 5.9989\n",
      "Epoch 819/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7239 - val_loss: 5.9984\n",
      "Epoch 820/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7234 - val_loss: 5.9979\n",
      "Epoch 821/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7229 - val_loss: 5.9974\n",
      "Epoch 822/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7223 - val_loss: 5.9969\n",
      "Epoch 823/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7218 - val_loss: 5.9964\n",
      "Epoch 824/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7213 - val_loss: 5.9959\n",
      "Epoch 825/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7207 - val_loss: 5.9954\n",
      "Epoch 826/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7202 - val_loss: 5.9949\n",
      "Epoch 827/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7197 - val_loss: 5.9944\n",
      "Epoch 828/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7192 - val_loss: 5.9939\n",
      "Epoch 829/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7187 - val_loss: 5.9934\n",
      "Epoch 830/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7181 - val_loss: 5.9929\n",
      "Epoch 831/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7176 - val_loss: 5.9924\n",
      "Epoch 832/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7171 - val_loss: 5.9919\n",
      "Epoch 833/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7166 - val_loss: 5.9914\n",
      "Epoch 834/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.7161 - val_loss: 5.9909\n",
      "Epoch 835/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7155 - val_loss: 5.9904\n",
      "Epoch 836/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7150 - val_loss: 5.9899\n",
      "Epoch 837/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7145 - val_loss: 5.9894\n",
      "Epoch 838/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7140 - val_loss: 5.9889\n",
      "Epoch 839/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7135 - val_loss: 5.9884\n",
      "Epoch 840/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7129 - val_loss: 5.9879\n",
      "Epoch 841/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7124 - val_loss: 5.9875\n",
      "Epoch 842/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7119 - val_loss: 5.9870\n",
      "Epoch 843/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7114 - val_loss: 5.9865\n",
      "Epoch 844/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7109 - val_loss: 5.9860\n",
      "Epoch 845/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7104 - val_loss: 5.9855\n",
      "Epoch 846/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7099 - val_loss: 5.9850\n",
      "Epoch 847/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7094 - val_loss: 5.9846\n",
      "Epoch 848/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7089 - val_loss: 5.9841\n",
      "Epoch 849/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7083 - val_loss: 5.9836\n",
      "Epoch 850/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7078 - val_loss: 5.9831\n",
      "Epoch 851/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7073 - val_loss: 5.9827\n",
      "Epoch 852/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7068 - val_loss: 5.9822\n",
      "Epoch 853/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.7063 - val_loss: 5.9817\n",
      "Epoch 854/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7058 - val_loss: 5.9812\n",
      "Epoch 855/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7053 - val_loss: 5.9808\n",
      "Epoch 856/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7048 - val_loss: 5.9803\n",
      "Epoch 857/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7043 - val_loss: 5.9798\n",
      "Epoch 858/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7038 - val_loss: 5.9793\n",
      "Epoch 859/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7033 - val_loss: 5.9789\n",
      "Epoch 860/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7028 - val_loss: 5.9784\n",
      "Epoch 861/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7023 - val_loss: 5.9779\n",
      "Epoch 862/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7018 - val_loss: 5.9775\n",
      "Epoch 863/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7013 - val_loss: 5.9770\n",
      "Epoch 864/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.7008 - val_loss: 5.9765\n",
      "Epoch 865/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.7003 - val_loss: 5.9761\n",
      "Epoch 866/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6998 - val_loss: 5.9756\n",
      "Epoch 867/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.6993 - val_loss: 5.9751\n",
      "Epoch 868/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6989 - val_loss: 5.9747\n",
      "Epoch 869/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6984 - val_loss: 5.9742\n",
      "Epoch 870/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6979 - val_loss: 5.9737\n",
      "Epoch 871/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6974 - val_loss: 5.9733\n",
      "Epoch 872/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6969 - val_loss: 5.9728\n",
      "Epoch 873/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6964 - val_loss: 5.9724\n",
      "Epoch 874/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6959 - val_loss: 5.9719\n",
      "Epoch 875/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6954 - val_loss: 5.9715\n",
      "Epoch 876/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.6949 - val_loss: 5.9710\n",
      "Epoch 877/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6944 - val_loss: 5.9705\n",
      "Epoch 878/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6939 - val_loss: 5.9701\n",
      "Epoch 879/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6934 - val_loss: 5.9696\n",
      "Epoch 880/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6930 - val_loss: 5.9692\n",
      "Epoch 881/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.6925 - val_loss: 5.9687\n",
      "Epoch 882/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.6920 - val_loss: 5.9683\n",
      "Epoch 883/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6915 - val_loss: 5.9678\n",
      "Epoch 884/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.6910 - val_loss: 5.9674\n",
      "Epoch 885/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.6906 - val_loss: 5.9669\n",
      "Epoch 886/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.6901 - val_loss: 5.9665\n",
      "Epoch 887/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.6896 - val_loss: 5.9660\n",
      "Epoch 888/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6891 - val_loss: 5.9656\n",
      "Epoch 889/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6886 - val_loss: 5.9651\n",
      "Epoch 890/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6882 - val_loss: 5.9647\n",
      "Epoch 891/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6877 - val_loss: 5.9643\n",
      "Epoch 892/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6872 - val_loss: 5.9638\n",
      "Epoch 893/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6867 - val_loss: 5.9634\n",
      "Epoch 894/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6863 - val_loss: 5.9629\n",
      "Epoch 895/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6858 - val_loss: 5.9625\n",
      "Epoch 896/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6853 - val_loss: 5.9620\n",
      "Epoch 897/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6848 - val_loss: 5.9616\n",
      "Epoch 898/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6844 - val_loss: 5.9612\n",
      "Epoch 899/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6839 - val_loss: 5.9607\n",
      "Epoch 900/5000\n",
      "39898/39898 [==============================] - ETA: 0s - loss: 6.591 - 1s 22us/step - loss: 6.6834 - val_loss: 5.9603\n",
      "Epoch 901/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6829 - val_loss: 5.9598\n",
      "Epoch 902/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6825 - val_loss: 5.9594\n",
      "Epoch 903/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6820 - val_loss: 5.9590\n",
      "Epoch 904/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6815 - val_loss: 5.9585\n",
      "Epoch 905/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6811 - val_loss: 5.9581\n",
      "Epoch 906/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6806 - val_loss: 5.9577\n",
      "Epoch 907/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6802 - val_loss: 5.9572\n",
      "Epoch 908/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.6797 - val_loss: 5.9568\n",
      "Epoch 909/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6792 - val_loss: 5.9563\n",
      "Epoch 910/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6788 - val_loss: 5.9559\n",
      "Epoch 911/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6783 - val_loss: 5.9555\n",
      "Epoch 912/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6778 - val_loss: 5.9550\n",
      "Epoch 913/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6774 - val_loss: 5.9546\n",
      "Epoch 914/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.6769 - val_loss: 5.9542\n",
      "Epoch 915/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6764 - val_loss: 5.9537\n",
      "Epoch 916/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6760 - val_loss: 5.9533\n",
      "Epoch 917/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6755 - val_loss: 5.9529\n",
      "Epoch 918/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6751 - val_loss: 5.9524\n",
      "Epoch 919/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6746 - val_loss: 5.9520\n",
      "Epoch 920/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6741 - val_loss: 5.9516\n",
      "Epoch 921/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6737 - val_loss: 5.9512\n",
      "Epoch 922/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6732 - val_loss: 5.9507\n",
      "Epoch 923/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6728 - val_loss: 5.9503\n",
      "Epoch 924/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6723 - val_loss: 5.9499\n",
      "Epoch 925/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6719 - val_loss: 5.9495\n",
      "Epoch 926/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6714 - val_loss: 5.9490\n",
      "Epoch 927/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6709 - val_loss: 5.9486\n",
      "Epoch 928/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6705 - val_loss: 5.9482\n",
      "Epoch 929/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6700 - val_loss: 5.9478\n",
      "Epoch 930/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6696 - val_loss: 5.9474\n",
      "Epoch 931/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6691 - val_loss: 5.9469\n",
      "Epoch 932/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6687 - val_loss: 5.9465\n",
      "Epoch 933/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6682 - val_loss: 5.9461\n",
      "Epoch 934/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6678 - val_loss: 5.9457\n",
      "Epoch 935/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6673 - val_loss: 5.9453\n",
      "Epoch 936/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6669 - val_loss: 5.9448\n",
      "Epoch 937/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6664 - val_loss: 5.9444\n",
      "Epoch 938/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6660 - val_loss: 5.9440\n",
      "Epoch 939/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6655 - val_loss: 5.9436\n",
      "Epoch 940/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6651 - val_loss: 5.9432\n",
      "Epoch 941/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6647 - val_loss: 5.9428\n",
      "Epoch 942/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6642 - val_loss: 5.9423\n",
      "Epoch 943/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6638 - val_loss: 5.9419\n",
      "Epoch 944/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6633 - val_loss: 5.9415\n",
      "Epoch 945/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6629 - val_loss: 5.9411\n",
      "Epoch 946/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6625 - val_loss: 5.9407\n",
      "Epoch 947/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6620 - val_loss: 5.9403\n",
      "Epoch 948/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6616 - val_loss: 5.9399\n",
      "Epoch 949/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6611 - val_loss: 5.9395\n",
      "Epoch 950/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6607 - val_loss: 5.9390\n",
      "Epoch 951/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6603 - val_loss: 5.9386\n",
      "Epoch 952/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6598 - val_loss: 5.9382\n",
      "Epoch 953/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6594 - val_loss: 5.9378\n",
      "Epoch 954/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6589 - val_loss: 5.9374\n",
      "Epoch 955/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6585 - val_loss: 5.9370\n",
      "Epoch 956/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.6581 - val_loss: 5.9366\n",
      "Epoch 957/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6576 - val_loss: 5.9362\n",
      "Epoch 958/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6572 - val_loss: 5.9358\n",
      "Epoch 959/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6568 - val_loss: 5.9354\n",
      "Epoch 960/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6563 - val_loss: 5.9350\n",
      "Epoch 961/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6559 - val_loss: 5.9346\n",
      "Epoch 962/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6555 - val_loss: 5.9342\n",
      "Epoch 963/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6550 - val_loss: 5.9338\n",
      "Epoch 964/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6546 - val_loss: 5.9334\n",
      "Epoch 965/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6542 - val_loss: 5.9330\n",
      "Epoch 966/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6538 - val_loss: 5.9326\n",
      "Epoch 967/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.6533 - val_loss: 5.9322\n",
      "Epoch 968/5000\n",
      "39898/39898 [==============================] - 1s 18us/step - loss: 6.6529 - val_loss: 5.9318\n",
      "Epoch 969/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6525 - val_loss: 5.9314\n",
      "Epoch 970/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6520 - val_loss: 5.9310\n",
      "Epoch 971/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6516 - val_loss: 5.9306\n",
      "Epoch 972/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6512 - val_loss: 5.9302\n",
      "Epoch 973/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.6507 - val_loss: 5.9298\n",
      "Epoch 974/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6503 - val_loss: 5.9294\n",
      "Epoch 975/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6499 - val_loss: 5.9290\n",
      "Epoch 976/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6495 - val_loss: 5.9286\n",
      "Epoch 977/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6490 - val_loss: 5.9282\n",
      "Epoch 978/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6486 - val_loss: 5.9278\n",
      "Epoch 979/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6482 - val_loss: 5.9274\n",
      "Epoch 980/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6478 - val_loss: 5.9270\n",
      "Epoch 981/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6473 - val_loss: 5.9267\n",
      "Epoch 982/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6469 - val_loss: 5.9263\n",
      "Epoch 983/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6465 - val_loss: 5.9259\n",
      "Epoch 984/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6461 - val_loss: 5.9255\n",
      "Epoch 985/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6457 - val_loss: 5.9251\n",
      "Epoch 986/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6452 - val_loss: 5.9247\n",
      "Epoch 987/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6448 - val_loss: 5.9243\n",
      "Epoch 988/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6444 - val_loss: 5.9239\n",
      "Epoch 989/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6440 - val_loss: 5.9235\n",
      "Epoch 990/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6435 - val_loss: 5.9232\n",
      "Epoch 991/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6431 - val_loss: 5.9228\n",
      "Epoch 992/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6427 - val_loss: 5.9224\n",
      "Epoch 993/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6423 - val_loss: 5.9220\n",
      "Epoch 994/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6419 - val_loss: 5.9216\n",
      "Epoch 995/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6415 - val_loss: 5.9212\n",
      "Epoch 996/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6410 - val_loss: 5.9208\n",
      "Epoch 997/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6406 - val_loss: 5.9205\n",
      "Epoch 998/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6402 - val_loss: 5.9201\n",
      "Epoch 999/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6398 - val_loss: 5.9197\n",
      "Epoch 1000/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6394 - val_loss: 5.9193\n",
      "Epoch 1001/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6390 - val_loss: 5.9189\n",
      "Epoch 1002/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6386 - val_loss: 5.9186\n",
      "Epoch 1003/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6382 - val_loss: 5.9182\n",
      "Epoch 1004/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6377 - val_loss: 5.9178\n",
      "Epoch 1005/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6373 - val_loss: 5.9174\n",
      "Epoch 1006/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6369 - val_loss: 5.9170\n",
      "Epoch 1007/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 6.6365 - val_loss: 5.9166\n",
      "Epoch 1008/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.6361 - val_loss: 5.9163\n",
      "Epoch 1009/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.6357 - val_loss: 5.9159\n",
      "Epoch 1010/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.6353 - val_loss: 5.9155\n",
      "Epoch 1011/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.6349 - val_loss: 5.9151\n",
      "Epoch 1012/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6344 - val_loss: 5.9148\n",
      "Epoch 1013/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.6340 - val_loss: 5.9144\n",
      "Epoch 1014/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6336 - val_loss: 5.9140\n",
      "Epoch 1015/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6332 - val_loss: 5.9136\n",
      "Epoch 1016/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6328 - val_loss: 5.9132\n",
      "Epoch 1017/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.6324 - val_loss: 5.9129\n",
      "Epoch 1018/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6320 - val_loss: 5.9125\n",
      "Epoch 1019/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6316 - val_loss: 5.9121\n",
      "Epoch 1020/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6312 - val_loss: 5.9118\n",
      "Epoch 1021/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6308 - val_loss: 5.9114\n",
      "Epoch 1022/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6304 - val_loss: 5.9110\n",
      "Epoch 1023/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6300 - val_loss: 5.9106\n",
      "Epoch 1024/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6296 - val_loss: 5.9103\n",
      "Epoch 1025/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6292 - val_loss: 5.9099\n",
      "Epoch 1026/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6288 - val_loss: 5.9095\n",
      "Epoch 1027/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6284 - val_loss: 5.9092\n",
      "Epoch 1028/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6280 - val_loss: 5.9088\n",
      "Epoch 1029/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6276 - val_loss: 5.9084\n",
      "Epoch 1030/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6272 - val_loss: 5.9080\n",
      "Epoch 1031/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6268 - val_loss: 5.9077\n",
      "Epoch 1032/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.6264 - val_loss: 5.9073\n",
      "Epoch 1033/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6260 - val_loss: 5.9069\n",
      "Epoch 1034/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6256 - val_loss: 5.9066\n",
      "Epoch 1035/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6252 - val_loss: 5.9062\n",
      "Epoch 1036/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6248 - val_loss: 5.9059\n",
      "Epoch 1037/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6244 - val_loss: 5.9055\n",
      "Epoch 1038/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6240 - val_loss: 5.9051\n",
      "Epoch 1039/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6236 - val_loss: 5.9048\n",
      "Epoch 1040/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6232 - val_loss: 5.9044\n",
      "Epoch 1041/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6228 - val_loss: 5.9040\n",
      "Epoch 1042/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6224 - val_loss: 5.9037\n",
      "Epoch 1043/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6220 - val_loss: 5.9033\n",
      "Epoch 1044/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6216 - val_loss: 5.9030\n",
      "Epoch 1045/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6212 - val_loss: 5.9026\n",
      "Epoch 1046/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6208 - val_loss: 5.9022\n",
      "Epoch 1047/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6204 - val_loss: 5.9019\n",
      "Epoch 1048/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6200 - val_loss: 5.9015\n",
      "Epoch 1049/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6196 - val_loss: 5.9012\n",
      "Epoch 1050/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6193 - val_loss: 5.9008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1051/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6189 - val_loss: 5.9004\n",
      "Epoch 1052/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6185 - val_loss: 5.9001\n",
      "Epoch 1053/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6181 - val_loss: 5.8997\n",
      "Epoch 1054/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6177 - val_loss: 5.8994\n",
      "Epoch 1055/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.6173 - val_loss: 5.8990\n",
      "Epoch 1056/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6169 - val_loss: 5.8987\n",
      "Epoch 1057/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.6165 - val_loss: 5.8983\n",
      "Epoch 1058/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6161 - val_loss: 5.8979\n",
      "Epoch 1059/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6157 - val_loss: 5.8976\n",
      "Epoch 1060/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6154 - val_loss: 5.8972\n",
      "Epoch 1061/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6150 - val_loss: 5.8969\n",
      "Epoch 1062/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6146 - val_loss: 5.8965\n",
      "Epoch 1063/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6142 - val_loss: 5.8962\n",
      "Epoch 1064/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.6138 - val_loss: 5.8958\n",
      "Epoch 1065/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.6134 - val_loss: 5.8955\n",
      "Epoch 1066/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6130 - val_loss: 5.8951\n",
      "Epoch 1067/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6127 - val_loss: 5.8948\n",
      "Epoch 1068/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6123 - val_loss: 5.8944\n",
      "Epoch 1069/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.6119 - val_loss: 5.8941\n",
      "Epoch 1070/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6115 - val_loss: 5.8937\n",
      "Epoch 1071/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6111 - val_loss: 5.8934\n",
      "Epoch 1072/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6108 - val_loss: 5.8930\n",
      "Epoch 1073/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6104 - val_loss: 5.8927\n",
      "Epoch 1074/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6100 - val_loss: 5.8923\n",
      "Epoch 1075/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6096 - val_loss: 5.8920\n",
      "Epoch 1076/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6092 - val_loss: 5.8916\n",
      "Epoch 1077/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6088 - val_loss: 5.8913\n",
      "Epoch 1078/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6085 - val_loss: 5.8909\n",
      "Epoch 1079/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6081 - val_loss: 5.8906\n",
      "Epoch 1080/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6077 - val_loss: 5.8902\n",
      "Epoch 1081/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6073 - val_loss: 5.8899\n",
      "Epoch 1082/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6069 - val_loss: 5.8895\n",
      "Epoch 1083/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6066 - val_loss: 5.8892\n",
      "Epoch 1084/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6062 - val_loss: 5.8888\n",
      "Epoch 1085/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6058 - val_loss: 5.8885\n",
      "Epoch 1086/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6054 - val_loss: 5.8881\n",
      "Epoch 1087/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6050 - val_loss: 5.8878\n",
      "Epoch 1088/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6047 - val_loss: 5.8875\n",
      "Epoch 1089/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6043 - val_loss: 5.8871\n",
      "Epoch 1090/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6039 - val_loss: 5.8868\n",
      "Epoch 1091/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6035 - val_loss: 5.8864\n",
      "Epoch 1092/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6032 - val_loss: 5.8861\n",
      "Epoch 1093/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6028 - val_loss: 5.8858\n",
      "Epoch 1094/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6024 - val_loss: 5.8854\n",
      "Epoch 1095/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6020 - val_loss: 5.8851\n",
      "Epoch 1096/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6017 - val_loss: 5.8847\n",
      "Epoch 1097/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.6013 - val_loss: 5.8844\n",
      "Epoch 1098/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.6009 - val_loss: 5.8841\n",
      "Epoch 1099/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6006 - val_loss: 5.8837\n",
      "Epoch 1100/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.6002 - val_loss: 5.8834\n",
      "Epoch 1101/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5998 - val_loss: 5.8830\n",
      "Epoch 1102/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5994 - val_loss: 5.8827\n",
      "Epoch 1103/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5991 - val_loss: 5.8824\n",
      "Epoch 1104/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5987 - val_loss: 5.8820\n",
      "Epoch 1105/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5983 - val_loss: 5.8817\n",
      "Epoch 1106/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5980 - val_loss: 5.8814\n",
      "Epoch 1107/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5976 - val_loss: 5.8810\n",
      "Epoch 1108/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5972 - val_loss: 5.8807\n",
      "Epoch 1109/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5968 - val_loss: 5.8804\n",
      "Epoch 1110/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5965 - val_loss: 5.8800\n",
      "Epoch 1111/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5961 - val_loss: 5.8797\n",
      "Epoch 1112/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5957 - val_loss: 5.8794\n",
      "Epoch 1113/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5954 - val_loss: 5.8790\n",
      "Epoch 1114/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5950 - val_loss: 5.8787\n",
      "Epoch 1115/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5946 - val_loss: 5.8784\n",
      "Epoch 1116/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5943 - val_loss: 5.8780\n",
      "Epoch 1117/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5939 - val_loss: 5.8777\n",
      "Epoch 1118/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5935 - val_loss: 5.8774\n",
      "Epoch 1119/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5932 - val_loss: 5.8770\n",
      "Epoch 1120/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5928 - val_loss: 5.8767\n",
      "Epoch 1121/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5924 - val_loss: 5.8764\n",
      "Epoch 1122/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5921 - val_loss: 5.8760\n",
      "Epoch 1123/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5917 - val_loss: 5.8757\n",
      "Epoch 1124/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5913 - val_loss: 5.8754\n",
      "Epoch 1125/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5910 - val_loss: 5.8751\n",
      "Epoch 1126/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5906 - val_loss: 5.8747\n",
      "Epoch 1127/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5903 - val_loss: 5.8744\n",
      "Epoch 1128/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5899 - val_loss: 5.8741\n",
      "Epoch 1129/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5895 - val_loss: 5.8737\n",
      "Epoch 1130/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5892 - val_loss: 5.8734\n",
      "Epoch 1131/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5888 - val_loss: 5.8731\n",
      "Epoch 1132/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5885 - val_loss: 5.8728\n",
      "Epoch 1133/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5881 - val_loss: 5.8724\n",
      "Epoch 1134/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5877 - val_loss: 5.8721\n",
      "Epoch 1135/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5874 - val_loss: 5.8718\n",
      "Epoch 1136/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5870 - val_loss: 5.8715\n",
      "Epoch 1137/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5867 - val_loss: 5.8711\n",
      "Epoch 1138/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.5863 - val_loss: 5.8708\n",
      "Epoch 1139/5000\n",
      "39898/39898 [==============================] - 1s 19us/step - loss: 6.5859 - val_loss: 5.8705\n",
      "Epoch 1140/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5856 - val_loss: 5.8702\n",
      "Epoch 1141/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5852 - val_loss: 5.8698\n",
      "Epoch 1142/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5849 - val_loss: 5.8695\n",
      "Epoch 1143/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.5845 - val_loss: 5.8692\n",
      "Epoch 1144/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5841 - val_loss: 5.8689\n",
      "Epoch 1145/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5838 - val_loss: 5.8686\n",
      "Epoch 1146/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5834 - val_loss: 5.8682\n",
      "Epoch 1147/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5831 - val_loss: 5.8679\n",
      "Epoch 1148/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5827 - val_loss: 5.8676\n",
      "Epoch 1149/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5824 - val_loss: 5.8673\n",
      "Epoch 1150/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5820 - val_loss: 5.8670\n",
      "Epoch 1151/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5817 - val_loss: 5.8666\n",
      "Epoch 1152/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5813 - val_loss: 5.8663\n",
      "Epoch 1153/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5810 - val_loss: 5.8660\n",
      "Epoch 1154/5000\n",
      "39898/39898 [==============================] - 1s 19us/step - loss: 6.5806 - val_loss: 5.8657\n",
      "Epoch 1155/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5802 - val_loss: 5.8654\n",
      "Epoch 1156/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5799 - val_loss: 5.8650\n",
      "Epoch 1157/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5795 - val_loss: 5.8647\n",
      "Epoch 1158/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5792 - val_loss: 5.8644\n",
      "Epoch 1159/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5788 - val_loss: 5.8641\n",
      "Epoch 1160/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5785 - val_loss: 5.8638\n",
      "Epoch 1161/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5781 - val_loss: 5.8635\n",
      "Epoch 1162/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5778 - val_loss: 5.8632\n",
      "Epoch 1163/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5774 - val_loss: 5.8628\n",
      "Epoch 1164/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.5771 - val_loss: 5.8625\n",
      "Epoch 1165/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5767 - val_loss: 5.8622\n",
      "Epoch 1166/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5764 - val_loss: 5.8619\n",
      "Epoch 1167/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5760 - val_loss: 5.8616\n",
      "Epoch 1168/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5757 - val_loss: 5.8613\n",
      "Epoch 1169/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5753 - val_loss: 5.8610\n",
      "Epoch 1170/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5750 - val_loss: 5.8606\n",
      "Epoch 1171/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5746 - val_loss: 5.8603\n",
      "Epoch 1172/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5743 - val_loss: 5.8600\n",
      "Epoch 1173/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5739 - val_loss: 5.8597\n",
      "Epoch 1174/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5736 - val_loss: 5.8594\n",
      "Epoch 1175/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5733 - val_loss: 5.8591\n",
      "Epoch 1176/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5729 - val_loss: 5.8588\n",
      "Epoch 1177/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5726 - val_loss: 5.8585\n",
      "Epoch 1178/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5722 - val_loss: 5.8582\n",
      "Epoch 1179/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5719 - val_loss: 5.8579\n",
      "Epoch 1180/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5715 - val_loss: 5.8575\n",
      "Epoch 1181/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5712 - val_loss: 5.8572\n",
      "Epoch 1182/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5708 - val_loss: 5.8569\n",
      "Epoch 1183/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5705 - val_loss: 5.8566\n",
      "Epoch 1184/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5701 - val_loss: 5.8563\n",
      "Epoch 1185/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5698 - val_loss: 5.8560\n",
      "Epoch 1186/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5695 - val_loss: 5.8557\n",
      "Epoch 1187/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5691 - val_loss: 5.8554\n",
      "Epoch 1188/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5688 - val_loss: 5.8551\n",
      "Epoch 1189/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5684 - val_loss: 5.8548\n",
      "Epoch 1190/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5681 - val_loss: 5.8545\n",
      "Epoch 1191/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5677 - val_loss: 5.8542\n",
      "Epoch 1192/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5674 - val_loss: 5.8538\n",
      "Epoch 1193/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5670 - val_loss: 5.8535\n",
      "Epoch 1194/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5667 - val_loss: 5.8532\n",
      "Epoch 1195/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5664 - val_loss: 5.8529\n",
      "Epoch 1196/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5660 - val_loss: 5.8526\n",
      "Epoch 1197/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5657 - val_loss: 5.8523\n",
      "Epoch 1198/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5653 - val_loss: 5.8520\n",
      "Epoch 1199/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5650 - val_loss: 5.8517\n",
      "Epoch 1200/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5647 - val_loss: 5.8514\n",
      "Epoch 1201/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5643 - val_loss: 5.8511\n",
      "Epoch 1202/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5640 - val_loss: 5.8508\n",
      "Epoch 1203/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5636 - val_loss: 5.8505\n",
      "Epoch 1204/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5633 - val_loss: 5.8502\n",
      "Epoch 1205/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5630 - val_loss: 5.8499\n",
      "Epoch 1206/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5626 - val_loss: 5.8496\n",
      "Epoch 1207/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5623 - val_loss: 5.8493\n",
      "Epoch 1208/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5620 - val_loss: 5.8490\n",
      "Epoch 1209/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5616 - val_loss: 5.8487\n",
      "Epoch 1210/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5613 - val_loss: 5.8484\n",
      "Epoch 1211/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5609 - val_loss: 5.8481\n",
      "Epoch 1212/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5606 - val_loss: 5.8478\n",
      "Epoch 1213/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5603 - val_loss: 5.8475\n",
      "Epoch 1214/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5599 - val_loss: 5.8472\n",
      "Epoch 1215/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5596 - val_loss: 5.8469\n",
      "Epoch 1216/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5593 - val_loss: 5.8466\n",
      "Epoch 1217/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5589 - val_loss: 5.8463\n",
      "Epoch 1218/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5586 - val_loss: 5.8460\n",
      "Epoch 1219/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5583 - val_loss: 5.8457\n",
      "Epoch 1220/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5579 - val_loss: 5.8454\n",
      "Epoch 1221/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5576 - val_loss: 5.8452\n",
      "Epoch 1222/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5573 - val_loss: 5.8449\n",
      "Epoch 1223/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5569 - val_loss: 5.8446\n",
      "Epoch 1224/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5566 - val_loss: 5.8443\n",
      "Epoch 1225/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5563 - val_loss: 5.8440\n",
      "Epoch 1226/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5559 - val_loss: 5.8437\n",
      "Epoch 1227/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5556 - val_loss: 5.8434\n",
      "Epoch 1228/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5553 - val_loss: 5.8431\n",
      "Epoch 1229/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5549 - val_loss: 5.8428\n",
      "Epoch 1230/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5546 - val_loss: 5.8425\n",
      "Epoch 1231/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5543 - val_loss: 5.8422\n",
      "Epoch 1232/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5539 - val_loss: 5.8419\n",
      "Epoch 1233/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5536 - val_loss: 5.8416\n",
      "Epoch 1234/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5533 - val_loss: 5.8413\n",
      "Epoch 1235/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5529 - val_loss: 5.8410\n",
      "Epoch 1236/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5526 - val_loss: 5.8408\n",
      "Epoch 1237/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5523 - val_loss: 5.8405\n",
      "Epoch 1238/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5520 - val_loss: 5.8402\n",
      "Epoch 1239/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5516 - val_loss: 5.8399\n",
      "Epoch 1240/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5513 - val_loss: 5.8396\n",
      "Epoch 1241/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5510 - val_loss: 5.8393\n",
      "Epoch 1242/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5506 - val_loss: 5.8390\n",
      "Epoch 1243/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5503 - val_loss: 5.8387\n",
      "Epoch 1244/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5500 - val_loss: 5.8384\n",
      "Epoch 1245/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5497 - val_loss: 5.8381\n",
      "Epoch 1246/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5493 - val_loss: 5.8379\n",
      "Epoch 1247/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5490 - val_loss: 5.8376\n",
      "Epoch 1248/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5487 - val_loss: 5.8373\n",
      "Epoch 1249/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5484 - val_loss: 5.8370\n",
      "Epoch 1250/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5480 - val_loss: 5.8367\n",
      "Epoch 1251/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5477 - val_loss: 5.8364\n",
      "Epoch 1252/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5474 - val_loss: 5.8361\n",
      "Epoch 1253/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5471 - val_loss: 5.8358\n",
      "Epoch 1254/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5467 - val_loss: 5.8356\n",
      "Epoch 1255/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5464 - val_loss: 5.8353\n",
      "Epoch 1256/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5461 - val_loss: 5.8350\n",
      "Epoch 1257/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5458 - val_loss: 5.8347\n",
      "Epoch 1258/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5454 - val_loss: 5.8344\n",
      "Epoch 1259/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5451 - val_loss: 5.8341\n",
      "Epoch 1260/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5448 - val_loss: 5.8338\n",
      "Epoch 1261/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5445 - val_loss: 5.8336\n",
      "Epoch 1262/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5441 - val_loss: 5.8333\n",
      "Epoch 1263/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5438 - val_loss: 5.8330\n",
      "Epoch 1264/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5435 - val_loss: 5.8327\n",
      "Epoch 1265/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5432 - val_loss: 5.8324\n",
      "Epoch 1266/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5428 - val_loss: 5.8321\n",
      "Epoch 1267/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5425 - val_loss: 5.8319\n",
      "Epoch 1268/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5422 - val_loss: 5.8316\n",
      "Epoch 1269/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5419 - val_loss: 5.8313\n",
      "Epoch 1270/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.5416 - val_loss: 5.8310\n",
      "Epoch 1271/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 6.5412 - val_loss: 5.8307\n",
      "Epoch 1272/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.5409 - val_loss: 5.8304\n",
      "Epoch 1273/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5406 - val_loss: 5.8302\n",
      "Epoch 1274/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5403 - val_loss: 5.8299\n",
      "Epoch 1275/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5400 - val_loss: 5.8296\n",
      "Epoch 1276/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5396 - val_loss: 5.8293\n",
      "Epoch 1277/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5393 - val_loss: 5.8290\n",
      "Epoch 1278/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5390 - val_loss: 5.8288\n",
      "Epoch 1279/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5387 - val_loss: 5.8285\n",
      "Epoch 1280/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.5384 - val_loss: 5.8282\n",
      "Epoch 1281/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5380 - val_loss: 5.8279\n",
      "Epoch 1282/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5377 - val_loss: 5.8276\n",
      "Epoch 1283/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5374 - val_loss: 5.8274\n",
      "Epoch 1284/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5371 - val_loss: 5.8271\n",
      "Epoch 1285/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5368 - val_loss: 5.8268\n",
      "Epoch 1286/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5365 - val_loss: 5.8265\n",
      "Epoch 1287/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5361 - val_loss: 5.8263\n",
      "Epoch 1288/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5358 - val_loss: 5.8260\n",
      "Epoch 1289/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5355 - val_loss: 5.8257\n",
      "Epoch 1290/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5352 - val_loss: 5.8254\n",
      "Epoch 1291/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5349 - val_loss: 5.8251\n",
      "Epoch 1292/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5346 - val_loss: 5.8249\n",
      "Epoch 1293/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5342 - val_loss: 5.8246\n",
      "Epoch 1294/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5339 - val_loss: 5.8243\n",
      "Epoch 1295/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.5336 - val_loss: 5.8240\n",
      "Epoch 1296/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5333 - val_loss: 5.8238\n",
      "Epoch 1297/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5330 - val_loss: 5.8235\n",
      "Epoch 1298/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5327 - val_loss: 5.8232\n",
      "Epoch 1299/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5324 - val_loss: 5.8229\n",
      "Epoch 1300/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5320 - val_loss: 5.8227\n",
      "Epoch 1301/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5317 - val_loss: 5.8224\n",
      "Epoch 1302/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5314 - val_loss: 5.8221\n",
      "Epoch 1303/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5311 - val_loss: 5.8218\n",
      "Epoch 1304/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5308 - val_loss: 5.8216\n",
      "Epoch 1305/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5305 - val_loss: 5.8213\n",
      "Epoch 1306/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5302 - val_loss: 5.8210\n",
      "Epoch 1307/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5299 - val_loss: 5.8208\n",
      "Epoch 1308/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5295 - val_loss: 5.8205\n",
      "Epoch 1309/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5292 - val_loss: 5.8202\n",
      "Epoch 1310/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5289 - val_loss: 5.8199\n",
      "Epoch 1311/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5286 - val_loss: 5.8197\n",
      "Epoch 1312/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5283 - val_loss: 5.8194\n",
      "Epoch 1313/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5280 - val_loss: 5.8191\n",
      "Epoch 1314/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5277 - val_loss: 5.8189\n",
      "Epoch 1315/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5274 - val_loss: 5.8186\n",
      "Epoch 1316/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5271 - val_loss: 5.8183\n",
      "Epoch 1317/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5267 - val_loss: 5.8180\n",
      "Epoch 1318/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5264 - val_loss: 5.8178\n",
      "Epoch 1319/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5261 - val_loss: 5.8175\n",
      "Epoch 1320/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5258 - val_loss: 5.8172\n",
      "Epoch 1321/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5255 - val_loss: 5.8170\n",
      "Epoch 1322/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5252 - val_loss: 5.8167\n",
      "Epoch 1323/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5249 - val_loss: 5.8164\n",
      "Epoch 1324/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5246 - val_loss: 5.8162\n",
      "Epoch 1325/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5243 - val_loss: 5.8159\n",
      "Epoch 1326/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5240 - val_loss: 5.8156\n",
      "Epoch 1327/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5237 - val_loss: 5.8154\n",
      "Epoch 1328/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5233 - val_loss: 5.8151\n",
      "Epoch 1329/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5230 - val_loss: 5.8148\n",
      "Epoch 1330/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5227 - val_loss: 5.8146\n",
      "Epoch 1331/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5224 - val_loss: 5.8143\n",
      "Epoch 1332/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5221 - val_loss: 5.8140\n",
      "Epoch 1333/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5218 - val_loss: 5.8138\n",
      "Epoch 1334/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5215 - val_loss: 5.8135\n",
      "Epoch 1335/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5212 - val_loss: 5.8132\n",
      "Epoch 1336/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5209 - val_loss: 5.8130\n",
      "Epoch 1337/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5206 - val_loss: 5.8127\n",
      "Epoch 1338/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5203 - val_loss: 5.8124\n",
      "Epoch 1339/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5200 - val_loss: 5.8122\n",
      "Epoch 1340/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5197 - val_loss: 5.8119\n",
      "Epoch 1341/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5194 - val_loss: 5.8116\n",
      "Epoch 1342/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5191 - val_loss: 5.8114\n",
      "Epoch 1343/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5188 - val_loss: 5.8111\n",
      "Epoch 1344/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5185 - val_loss: 5.8108\n",
      "Epoch 1345/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5181 - val_loss: 5.8106\n",
      "Epoch 1346/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5178 - val_loss: 5.8103\n",
      "Epoch 1347/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5175 - val_loss: 5.8100\n",
      "Epoch 1348/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5172 - val_loss: 5.8098\n",
      "Epoch 1349/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5169 - val_loss: 5.8095\n",
      "Epoch 1350/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5166 - val_loss: 5.8093\n",
      "Epoch 1351/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5163 - val_loss: 5.8090\n",
      "Epoch 1352/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5160 - val_loss: 5.8087\n",
      "Epoch 1353/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5157 - val_loss: 5.8085\n",
      "Epoch 1354/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5154 - val_loss: 5.8082\n",
      "Epoch 1355/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5151 - val_loss: 5.8079\n",
      "Epoch 1356/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5148 - val_loss: 5.8077\n",
      "Epoch 1357/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5145 - val_loss: 5.8074\n",
      "Epoch 1358/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5142 - val_loss: 5.8072\n",
      "Epoch 1359/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5139 - val_loss: 5.8069\n",
      "Epoch 1360/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5136 - val_loss: 5.8066\n",
      "Epoch 1361/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5133 - val_loss: 5.8064\n",
      "Epoch 1362/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5130 - val_loss: 5.8061\n",
      "Epoch 1363/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5127 - val_loss: 5.8059\n",
      "Epoch 1364/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5124 - val_loss: 5.8056\n",
      "Epoch 1365/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5121 - val_loss: 5.8053\n",
      "Epoch 1366/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5118 - val_loss: 5.8051\n",
      "Epoch 1367/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5115 - val_loss: 5.8048\n",
      "Epoch 1368/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5112 - val_loss: 5.8046\n",
      "Epoch 1369/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5109 - val_loss: 5.8043\n",
      "Epoch 1370/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5106 - val_loss: 5.8041\n",
      "Epoch 1371/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5103 - val_loss: 5.8038\n",
      "Epoch 1372/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5100 - val_loss: 5.8035\n",
      "Epoch 1373/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5097 - val_loss: 5.8033\n",
      "Epoch 1374/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5094 - val_loss: 5.8030\n",
      "Epoch 1375/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5091 - val_loss: 5.8028\n",
      "Epoch 1376/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5088 - val_loss: 5.8025\n",
      "Epoch 1377/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5085 - val_loss: 5.8023\n",
      "Epoch 1378/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5082 - val_loss: 5.8020\n",
      "Epoch 1379/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5079 - val_loss: 5.8017\n",
      "Epoch 1380/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5076 - val_loss: 5.8015\n",
      "Epoch 1381/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5073 - val_loss: 5.8012\n",
      "Epoch 1382/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5070 - val_loss: 5.8010\n",
      "Epoch 1383/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5067 - val_loss: 5.8007\n",
      "Epoch 1384/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5064 - val_loss: 5.8005\n",
      "Epoch 1385/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5061 - val_loss: 5.8002\n",
      "Epoch 1386/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5058 - val_loss: 5.8000\n",
      "Epoch 1387/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5055 - val_loss: 5.7997\n",
      "Epoch 1388/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5053 - val_loss: 5.7994\n",
      "Epoch 1389/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5050 - val_loss: 5.7992\n",
      "Epoch 1390/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5047 - val_loss: 5.7989\n",
      "Epoch 1391/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5044 - val_loss: 5.7987\n",
      "Epoch 1392/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5041 - val_loss: 5.7984\n",
      "Epoch 1393/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5038 - val_loss: 5.7982\n",
      "Epoch 1394/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5035 - val_loss: 5.7979\n",
      "Epoch 1395/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5032 - val_loss: 5.7977\n",
      "Epoch 1396/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5029 - val_loss: 5.7974\n",
      "Epoch 1397/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5026 - val_loss: 5.7972\n",
      "Epoch 1398/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5023 - val_loss: 5.7969\n",
      "Epoch 1399/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5020 - val_loss: 5.7967\n",
      "Epoch 1400/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5017 - val_loss: 5.7964\n",
      "Epoch 1401/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5014 - val_loss: 5.7962\n",
      "Epoch 1402/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.5011 - val_loss: 5.7959\n",
      "Epoch 1403/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5008 - val_loss: 5.7957\n",
      "Epoch 1404/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.5005 - val_loss: 5.7954\n",
      "Epoch 1405/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5003 - val_loss: 5.7952\n",
      "Epoch 1406/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.5000 - val_loss: 5.7949\n",
      "Epoch 1407/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4997 - val_loss: 5.7947\n",
      "Epoch 1408/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.4994 - val_loss: 5.7944\n",
      "Epoch 1409/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4991 - val_loss: 5.7942\n",
      "Epoch 1410/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4988 - val_loss: 5.7939\n",
      "Epoch 1411/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4985 - val_loss: 5.7937\n",
      "Epoch 1412/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4982 - val_loss: 5.7934\n",
      "Epoch 1413/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4979 - val_loss: 5.7932\n",
      "Epoch 1414/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4976 - val_loss: 5.7929\n",
      "Epoch 1415/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4973 - val_loss: 5.7927\n",
      "Epoch 1416/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4970 - val_loss: 5.7924\n",
      "Epoch 1417/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4968 - val_loss: 5.7922\n",
      "Epoch 1418/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4965 - val_loss: 5.7919\n",
      "Epoch 1419/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4962 - val_loss: 5.7917\n",
      "Epoch 1420/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4959 - val_loss: 5.7914\n",
      "Epoch 1421/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4956 - val_loss: 5.7912\n",
      "Epoch 1422/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4953 - val_loss: 5.7909\n",
      "Epoch 1423/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4950 - val_loss: 5.7907\n",
      "Epoch 1424/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4947 - val_loss: 5.7904\n",
      "Epoch 1425/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4944 - val_loss: 5.7902\n",
      "Epoch 1426/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4941 - val_loss: 5.7899\n",
      "Epoch 1427/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4939 - val_loss: 5.7897\n",
      "Epoch 1428/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4936 - val_loss: 5.7894\n",
      "Epoch 1429/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4933 - val_loss: 5.7892\n",
      "Epoch 1430/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4930 - val_loss: 5.7889\n",
      "Epoch 1431/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4927 - val_loss: 5.7887\n",
      "Epoch 1432/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4924 - val_loss: 5.7885\n",
      "Epoch 1433/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4921 - val_loss: 5.7882\n",
      "Epoch 1434/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4918 - val_loss: 5.7880\n",
      "Epoch 1435/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4915 - val_loss: 5.7877\n",
      "Epoch 1436/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4913 - val_loss: 5.7875\n",
      "Epoch 1437/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4910 - val_loss: 5.7872\n",
      "Epoch 1438/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4907 - val_loss: 5.7870\n",
      "Epoch 1439/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4904 - val_loss: 5.7867\n",
      "Epoch 1440/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4901 - val_loss: 5.7865\n",
      "Epoch 1441/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4898 - val_loss: 5.7862\n",
      "Epoch 1442/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4895 - val_loss: 5.7860\n",
      "Epoch 1443/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4893 - val_loss: 5.7858\n",
      "Epoch 1444/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4890 - val_loss: 5.7855\n",
      "Epoch 1445/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4887 - val_loss: 5.7853\n",
      "Epoch 1446/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4884 - val_loss: 5.7850\n",
      "Epoch 1447/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4881 - val_loss: 5.7848\n",
      "Epoch 1448/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4878 - val_loss: 5.7845\n",
      "Epoch 1449/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.4875 - val_loss: 5.7843\n",
      "Epoch 1450/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4873 - val_loss: 5.7841\n",
      "Epoch 1451/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4870 - val_loss: 5.7838\n",
      "Epoch 1452/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4867 - val_loss: 5.7836\n",
      "Epoch 1453/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4864 - val_loss: 5.7833\n",
      "Epoch 1454/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4861 - val_loss: 5.7831\n",
      "Epoch 1455/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4858 - val_loss: 5.7828\n",
      "Epoch 1456/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4855 - val_loss: 5.7826\n",
      "Epoch 1457/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4853 - val_loss: 5.7824\n",
      "Epoch 1458/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4850 - val_loss: 5.7821\n",
      "Epoch 1459/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4847 - val_loss: 5.7819\n",
      "Epoch 1460/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.4844 - val_loss: 5.7816\n",
      "Epoch 1461/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4841 - val_loss: 5.7814\n",
      "Epoch 1462/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4839 - val_loss: 5.7812\n",
      "Epoch 1463/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4836 - val_loss: 5.7809\n",
      "Epoch 1464/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4833 - val_loss: 5.7807\n",
      "Epoch 1465/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4830 - val_loss: 5.7804\n",
      "Epoch 1466/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4827 - val_loss: 5.7802\n",
      "Epoch 1467/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4824 - val_loss: 5.7800\n",
      "Epoch 1468/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4822 - val_loss: 5.7797\n",
      "Epoch 1469/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4819 - val_loss: 5.7795\n",
      "Epoch 1470/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4816 - val_loss: 5.7792\n",
      "Epoch 1471/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4813 - val_loss: 5.7790\n",
      "Epoch 1472/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4810 - val_loss: 5.7788\n",
      "Epoch 1473/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4807 - val_loss: 5.7785\n",
      "Epoch 1474/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4805 - val_loss: 5.7783\n",
      "Epoch 1475/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4802 - val_loss: 5.7780\n",
      "Epoch 1476/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4799 - val_loss: 5.7778\n",
      "Epoch 1477/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4796 - val_loss: 5.7776\n",
      "Epoch 1478/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4793 - val_loss: 5.7773\n",
      "Epoch 1479/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4791 - val_loss: 5.7771\n",
      "Epoch 1480/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4788 - val_loss: 5.7769\n",
      "Epoch 1481/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4785 - val_loss: 5.7766\n",
      "Epoch 1482/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.4782 - val_loss: 5.7764\n",
      "Epoch 1483/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4779 - val_loss: 5.7761\n",
      "Epoch 1484/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4777 - val_loss: 5.7759\n",
      "Epoch 1485/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4774 - val_loss: 5.7757\n",
      "Epoch 1486/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4771 - val_loss: 5.7754\n",
      "Epoch 1487/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4768 - val_loss: 5.7752\n",
      "Epoch 1488/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4766 - val_loss: 5.7750\n",
      "Epoch 1489/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4763 - val_loss: 5.7747\n",
      "Epoch 1490/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4760 - val_loss: 5.7745\n",
      "Epoch 1491/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4757 - val_loss: 5.7743\n",
      "Epoch 1492/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4754 - val_loss: 5.7740\n",
      "Epoch 1493/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4752 - val_loss: 5.7738\n",
      "Epoch 1494/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4749 - val_loss: 5.7735\n",
      "Epoch 1495/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4746 - val_loss: 5.7733\n",
      "Epoch 1496/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4743 - val_loss: 5.7731\n",
      "Epoch 1497/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4741 - val_loss: 5.7728\n",
      "Epoch 1498/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4738 - val_loss: 5.7726\n",
      "Epoch 1499/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4735 - val_loss: 5.7724\n",
      "Epoch 1500/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4732 - val_loss: 5.7721\n",
      "Epoch 1501/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4729 - val_loss: 5.7719\n",
      "Epoch 1502/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4727 - val_loss: 5.7717\n",
      "Epoch 1503/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4724 - val_loss: 5.7714\n",
      "Epoch 1504/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4721 - val_loss: 5.7712\n",
      "Epoch 1505/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4718 - val_loss: 5.7710\n",
      "Epoch 1506/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4716 - val_loss: 5.7707\n",
      "Epoch 1507/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4713 - val_loss: 5.7705\n",
      "Epoch 1508/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4710 - val_loss: 5.7703\n",
      "Epoch 1509/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4707 - val_loss: 5.7700\n",
      "Epoch 1510/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4705 - val_loss: 5.7698\n",
      "Epoch 1511/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4702 - val_loss: 5.7696\n",
      "Epoch 1512/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4699 - val_loss: 5.7693\n",
      "Epoch 1513/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4696 - val_loss: 5.7691\n",
      "Epoch 1514/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4694 - val_loss: 5.7689\n",
      "Epoch 1515/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4691 - val_loss: 5.7686\n",
      "Epoch 1516/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4688 - val_loss: 5.7684\n",
      "Epoch 1517/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4685 - val_loss: 5.7682\n",
      "Epoch 1518/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4683 - val_loss: 5.7680\n",
      "Epoch 1519/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4680 - val_loss: 5.7677\n",
      "Epoch 1520/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4677 - val_loss: 5.7675\n",
      "Epoch 1521/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4674 - val_loss: 5.7673\n",
      "Epoch 1522/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4672 - val_loss: 5.7670\n",
      "Epoch 1523/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4669 - val_loss: 5.7668\n",
      "Epoch 1524/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4666 - val_loss: 5.7666\n",
      "Epoch 1525/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4664 - val_loss: 5.7663\n",
      "Epoch 1526/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4661 - val_loss: 5.7661\n",
      "Epoch 1527/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4658 - val_loss: 5.7659\n",
      "Epoch 1528/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4655 - val_loss: 5.7656\n",
      "Epoch 1529/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4653 - val_loss: 5.7654\n",
      "Epoch 1530/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4650 - val_loss: 5.7652\n",
      "Epoch 1531/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4647 - val_loss: 5.7650\n",
      "Epoch 1532/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4644 - val_loss: 5.7647\n",
      "Epoch 1533/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.4642 - val_loss: 5.7645\n",
      "Epoch 1534/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 6.4639 - val_loss: 5.7643\n",
      "Epoch 1535/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4636 - val_loss: 5.7640\n",
      "Epoch 1536/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4634 - val_loss: 5.7638\n",
      "Epoch 1537/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4631 - val_loss: 5.7636\n",
      "Epoch 1538/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4628 - val_loss: 5.7634\n",
      "Epoch 1539/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4625 - val_loss: 5.7631\n",
      "Epoch 1540/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.4623 - val_loss: 5.7629\n",
      "Epoch 1541/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4620 - val_loss: 5.7627\n",
      "Epoch 1542/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4617 - val_loss: 5.7624\n",
      "Epoch 1543/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4615 - val_loss: 5.7622\n",
      "Epoch 1544/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4612 - val_loss: 5.7620\n",
      "Epoch 1545/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 6.4609 - val_loss: 5.7618\n",
      "Epoch 1546/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4607 - val_loss: 5.7615\n",
      "Epoch 1547/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4604 - val_loss: 5.7613\n",
      "Epoch 1548/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4601 - val_loss: 5.7611\n",
      "Epoch 1549/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4598 - val_loss: 5.7609\n",
      "Epoch 1550/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4596 - val_loss: 5.7606\n",
      "Epoch 1551/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4593 - val_loss: 5.7604\n",
      "Epoch 1552/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4590 - val_loss: 5.7602\n",
      "Epoch 1553/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4588 - val_loss: 5.7600\n",
      "Epoch 1554/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4585 - val_loss: 5.7597\n",
      "Epoch 1555/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4582 - val_loss: 5.7595\n",
      "Epoch 1556/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4580 - val_loss: 5.7593\n",
      "Epoch 1557/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4577 - val_loss: 5.7591\n",
      "Epoch 1558/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4574 - val_loss: 5.7588\n",
      "Epoch 1559/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.4572 - val_loss: 5.7586\n",
      "Epoch 1560/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4569 - val_loss: 5.7584\n",
      "Epoch 1561/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4566 - val_loss: 5.7582\n",
      "Epoch 1562/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4564 - val_loss: 5.7579\n",
      "Epoch 1563/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4561 - val_loss: 5.7577\n",
      "Epoch 1564/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4558 - val_loss: 5.7575\n",
      "Epoch 1565/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4556 - val_loss: 5.7573\n",
      "Epoch 1566/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4553 - val_loss: 5.7570\n",
      "Epoch 1567/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4550 - val_loss: 5.7568\n",
      "Epoch 1568/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4548 - val_loss: 5.7566\n",
      "Epoch 1569/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4545 - val_loss: 5.7564\n",
      "Epoch 1570/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4542 - val_loss: 5.7561\n",
      "Epoch 1571/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4540 - val_loss: 5.7559\n",
      "Epoch 1572/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4537 - val_loss: 5.7557\n",
      "Epoch 1573/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4534 - val_loss: 5.7555\n",
      "Epoch 1574/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4532 - val_loss: 5.7552\n",
      "Epoch 1575/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4529 - val_loss: 5.7550\n",
      "Epoch 1576/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4526 - val_loss: 5.7548\n",
      "Epoch 1577/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4524 - val_loss: 5.7546\n",
      "Epoch 1578/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4521 - val_loss: 5.7544\n",
      "Epoch 1579/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4518 - val_loss: 5.7541\n",
      "Epoch 1580/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4516 - val_loss: 5.7539\n",
      "Epoch 1581/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4513 - val_loss: 5.7537\n",
      "Epoch 1582/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4510 - val_loss: 5.7535\n",
      "Epoch 1583/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4508 - val_loss: 5.7532\n",
      "Epoch 1584/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4505 - val_loss: 5.7530\n",
      "Epoch 1585/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4502 - val_loss: 5.7528\n",
      "Epoch 1586/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4500 - val_loss: 5.7526\n",
      "Epoch 1587/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4497 - val_loss: 5.7524\n",
      "Epoch 1588/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4494 - val_loss: 5.7521\n",
      "Epoch 1589/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4492 - val_loss: 5.7519\n",
      "Epoch 1590/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4489 - val_loss: 5.7517\n",
      "Epoch 1591/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4487 - val_loss: 5.7515\n",
      "Epoch 1592/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4484 - val_loss: 5.7513\n",
      "Epoch 1593/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4481 - val_loss: 5.7510\n",
      "Epoch 1594/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4479 - val_loss: 5.7508\n",
      "Epoch 1595/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4476 - val_loss: 5.7506\n",
      "Epoch 1596/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4473 - val_loss: 5.7504\n",
      "Epoch 1597/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4471 - val_loss: 5.7502\n",
      "Epoch 1598/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4468 - val_loss: 5.7499\n",
      "Epoch 1599/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4465 - val_loss: 5.7497\n",
      "Epoch 1600/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4463 - val_loss: 5.7495\n",
      "Epoch 1601/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4460 - val_loss: 5.7493\n",
      "Epoch 1602/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4458 - val_loss: 5.7491\n",
      "Epoch 1603/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4455 - val_loss: 5.7488\n",
      "Epoch 1604/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4452 - val_loss: 5.7486\n",
      "Epoch 1605/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4450 - val_loss: 5.7484\n",
      "Epoch 1606/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4447 - val_loss: 5.7482\n",
      "Epoch 1607/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4445 - val_loss: 5.7480\n",
      "Epoch 1608/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4442 - val_loss: 5.7478\n",
      "Epoch 1609/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4439 - val_loss: 5.7475\n",
      "Epoch 1610/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.4437 - val_loss: 5.7473\n",
      "Epoch 1611/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.4434 - val_loss: 5.7471\n",
      "Epoch 1612/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4431 - val_loss: 5.7469\n",
      "Epoch 1613/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4429 - val_loss: 5.7467\n",
      "Epoch 1614/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4426 - val_loss: 5.7464\n",
      "Epoch 1615/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4424 - val_loss: 5.7462\n",
      "Epoch 1616/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4421 - val_loss: 5.7460\n",
      "Epoch 1617/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4418 - val_loss: 5.7458\n",
      "Epoch 1618/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4416 - val_loss: 5.7456\n",
      "Epoch 1619/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4413 - val_loss: 5.7454\n",
      "Epoch 1620/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4411 - val_loss: 5.7451\n",
      "Epoch 1621/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4408 - val_loss: 5.7449\n",
      "Epoch 1622/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4405 - val_loss: 5.7447\n",
      "Epoch 1623/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4403 - val_loss: 5.7445\n",
      "Epoch 1624/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4400 - val_loss: 5.7443\n",
      "Epoch 1625/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4398 - val_loss: 5.7441\n",
      "Epoch 1626/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.4395 - val_loss: 5.7438\n",
      "Epoch 1627/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4392 - val_loss: 5.7436\n",
      "Epoch 1628/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4390 - val_loss: 5.7434\n",
      "Epoch 1629/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4387 - val_loss: 5.7432\n",
      "Epoch 1630/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4385 - val_loss: 5.7430\n",
      "Epoch 1631/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4382 - val_loss: 5.7428\n",
      "Epoch 1632/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4380 - val_loss: 5.7426\n",
      "Epoch 1633/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4377 - val_loss: 5.7423\n",
      "Epoch 1634/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4374 - val_loss: 5.7421\n",
      "Epoch 1635/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4372 - val_loss: 5.7419\n",
      "Epoch 1636/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4369 - val_loss: 5.7417\n",
      "Epoch 1637/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4367 - val_loss: 5.7415\n",
      "Epoch 1638/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4364 - val_loss: 5.7413\n",
      "Epoch 1639/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4362 - val_loss: 5.7411\n",
      "Epoch 1640/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4359 - val_loss: 5.7408\n",
      "Epoch 1641/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4356 - val_loss: 5.7406\n",
      "Epoch 1642/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4354 - val_loss: 5.7404\n",
      "Epoch 1643/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4351 - val_loss: 5.7402\n",
      "Epoch 1644/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4349 - val_loss: 5.7400\n",
      "Epoch 1645/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4346 - val_loss: 5.7398\n",
      "Epoch 1646/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4344 - val_loss: 5.7396\n",
      "Epoch 1647/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4341 - val_loss: 5.7393\n",
      "Epoch 1648/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4338 - val_loss: 5.7391\n",
      "Epoch 1649/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4336 - val_loss: 5.7389\n",
      "Epoch 1650/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4333 - val_loss: 5.7387\n",
      "Epoch 1651/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4331 - val_loss: 5.7385\n",
      "Epoch 1652/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4328 - val_loss: 5.7383\n",
      "Epoch 1653/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4326 - val_loss: 5.7381\n",
      "Epoch 1654/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4323 - val_loss: 5.7379\n",
      "Epoch 1655/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4320 - val_loss: 5.7376\n",
      "Epoch 1656/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4318 - val_loss: 5.7374\n",
      "Epoch 1657/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4315 - val_loss: 5.7372\n",
      "Epoch 1658/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4313 - val_loss: 5.7370\n",
      "Epoch 1659/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4310 - val_loss: 5.7368\n",
      "Epoch 1660/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4308 - val_loss: 5.7366\n",
      "Epoch 1661/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4305 - val_loss: 5.7364\n",
      "Epoch 1662/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4303 - val_loss: 5.7362\n",
      "Epoch 1663/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4300 - val_loss: 5.7360\n",
      "Epoch 1664/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4298 - val_loss: 5.7357\n",
      "Epoch 1665/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4295 - val_loss: 5.7355\n",
      "Epoch 1666/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 6.4292 - val_loss: 5.7353\n",
      "Epoch 1667/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4290 - val_loss: 5.7351\n",
      "Epoch 1668/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4287 - val_loss: 5.7349\n",
      "Epoch 1669/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4285 - val_loss: 5.7347\n",
      "Epoch 1670/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4282 - val_loss: 5.7345\n",
      "Epoch 1671/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4280 - val_loss: 5.7343\n",
      "Epoch 1672/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4277 - val_loss: 5.7341\n",
      "Epoch 1673/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4275 - val_loss: 5.7339\n",
      "Epoch 1674/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4272 - val_loss: 5.7336\n",
      "Epoch 1675/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4270 - val_loss: 5.7334\n",
      "Epoch 1676/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4267 - val_loss: 5.7332\n",
      "Epoch 1677/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4265 - val_loss: 5.7330\n",
      "Epoch 1678/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4262 - val_loss: 5.7328\n",
      "Epoch 1679/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4259 - val_loss: 5.7326\n",
      "Epoch 1680/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4257 - val_loss: 5.7324\n",
      "Epoch 1681/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4254 - val_loss: 5.7322\n",
      "Epoch 1682/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4252 - val_loss: 5.7320\n",
      "Epoch 1683/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4249 - val_loss: 5.7318\n",
      "Epoch 1684/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4247 - val_loss: 5.7316\n",
      "Epoch 1685/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4244 - val_loss: 5.7313\n",
      "Epoch 1686/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4242 - val_loss: 5.7311\n",
      "Epoch 1687/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4239 - val_loss: 5.7309\n",
      "Epoch 1688/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4237 - val_loss: 5.7307\n",
      "Epoch 1689/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4234 - val_loss: 5.7305\n",
      "Epoch 1690/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4232 - val_loss: 5.7303\n",
      "Epoch 1691/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4229 - val_loss: 5.7301\n",
      "Epoch 1692/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4227 - val_loss: 5.7299\n",
      "Epoch 1693/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4224 - val_loss: 5.7297\n",
      "Epoch 1694/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4222 - val_loss: 5.7295\n",
      "Epoch 1695/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4219 - val_loss: 5.7293\n",
      "Epoch 1696/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4217 - val_loss: 5.7291\n",
      "Epoch 1697/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4214 - val_loss: 5.7289\n",
      "Epoch 1698/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4212 - val_loss: 5.7286\n",
      "Epoch 1699/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4209 - val_loss: 5.7284\n",
      "Epoch 1700/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4207 - val_loss: 5.7282\n",
      "Epoch 1701/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4204 - val_loss: 5.7280\n",
      "Epoch 1702/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4202 - val_loss: 5.7278\n",
      "Epoch 1703/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4199 - val_loss: 5.7276\n",
      "Epoch 1704/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4197 - val_loss: 5.7274\n",
      "Epoch 1705/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4194 - val_loss: 5.7272\n",
      "Epoch 1706/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4192 - val_loss: 5.7270\n",
      "Epoch 1707/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4189 - val_loss: 5.7268\n",
      "Epoch 1708/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4187 - val_loss: 5.7266\n",
      "Epoch 1709/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4184 - val_loss: 5.7264\n",
      "Epoch 1710/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4182 - val_loss: 5.7262\n",
      "Epoch 1711/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4179 - val_loss: 5.7260\n",
      "Epoch 1712/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4177 - val_loss: 5.7258\n",
      "Epoch 1713/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4174 - val_loss: 5.7256\n",
      "Epoch 1714/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4172 - val_loss: 5.7254\n",
      "Epoch 1715/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4169 - val_loss: 5.7251\n",
      "Epoch 1716/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4167 - val_loss: 5.7249\n",
      "Epoch 1717/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4164 - val_loss: 5.7247\n",
      "Epoch 1718/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4162 - val_loss: 5.7245\n",
      "Epoch 1719/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4159 - val_loss: 5.7243\n",
      "Epoch 1720/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4157 - val_loss: 5.7241\n",
      "Epoch 1721/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4154 - val_loss: 5.7239\n",
      "Epoch 1722/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4152 - val_loss: 5.7237\n",
      "Epoch 1723/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4149 - val_loss: 5.7235\n",
      "Epoch 1724/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4147 - val_loss: 5.7233\n",
      "Epoch 1725/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4144 - val_loss: 5.7231\n",
      "Epoch 1726/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4142 - val_loss: 5.7229\n",
      "Epoch 1727/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4140 - val_loss: 5.7227\n",
      "Epoch 1728/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4137 - val_loss: 5.7225\n",
      "Epoch 1729/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4135 - val_loss: 5.7223\n",
      "Epoch 1730/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4132 - val_loss: 5.7221\n",
      "Epoch 1731/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4130 - val_loss: 5.7219\n",
      "Epoch 1732/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4127 - val_loss: 5.7217\n",
      "Epoch 1733/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4125 - val_loss: 5.7215\n",
      "Epoch 1734/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4122 - val_loss: 5.7213\n",
      "Epoch 1735/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4120 - val_loss: 5.7211\n",
      "Epoch 1736/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4117 - val_loss: 5.7209\n",
      "Epoch 1737/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4115 - val_loss: 5.7207\n",
      "Epoch 1738/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4112 - val_loss: 5.7205\n",
      "Epoch 1739/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4110 - val_loss: 5.7203\n",
      "Epoch 1740/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4107 - val_loss: 5.7201\n",
      "Epoch 1741/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4105 - val_loss: 5.7199\n",
      "Epoch 1742/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4103 - val_loss: 5.7197\n",
      "Epoch 1743/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4100 - val_loss: 5.7195\n",
      "Epoch 1744/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4098 - val_loss: 5.7192\n",
      "Epoch 1745/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4095 - val_loss: 5.7190\n",
      "Epoch 1746/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4093 - val_loss: 5.7188\n",
      "Epoch 1747/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4090 - val_loss: 5.7186\n",
      "Epoch 1748/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4088 - val_loss: 5.7184\n",
      "Epoch 1749/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4085 - val_loss: 5.7182\n",
      "Epoch 1750/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4083 - val_loss: 5.7180\n",
      "Epoch 1751/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4080 - val_loss: 5.7178\n",
      "Epoch 1752/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4078 - val_loss: 5.7176\n",
      "Epoch 1753/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4076 - val_loss: 5.7174\n",
      "Epoch 1754/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4073 - val_loss: 5.7172\n",
      "Epoch 1755/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4071 - val_loss: 5.7170\n",
      "Epoch 1756/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4068 - val_loss: 5.7168\n",
      "Epoch 1757/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4066 - val_loss: 5.7166\n",
      "Epoch 1758/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4063 - val_loss: 5.7164\n",
      "Epoch 1759/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4061 - val_loss: 5.7162\n",
      "Epoch 1760/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4058 - val_loss: 5.7160\n",
      "Epoch 1761/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4056 - val_loss: 5.7158\n",
      "Epoch 1762/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4054 - val_loss: 5.7156\n",
      "Epoch 1763/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4051 - val_loss: 5.7154\n",
      "Epoch 1764/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4049 - val_loss: 5.7152\n",
      "Epoch 1765/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4046 - val_loss: 5.7150\n",
      "Epoch 1766/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4044 - val_loss: 5.7148\n",
      "Epoch 1767/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4041 - val_loss: 5.7146\n",
      "Epoch 1768/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4039 - val_loss: 5.7144\n",
      "Epoch 1769/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4037 - val_loss: 5.7142\n",
      "Epoch 1770/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4034 - val_loss: 5.7140\n",
      "Epoch 1771/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4032 - val_loss: 5.7138\n",
      "Epoch 1772/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4029 - val_loss: 5.7136\n",
      "Epoch 1773/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4027 - val_loss: 5.7134\n",
      "Epoch 1774/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4024 - val_loss: 5.7132\n",
      "Epoch 1775/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4022 - val_loss: 5.7130\n",
      "Epoch 1776/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4020 - val_loss: 5.7128\n",
      "Epoch 1777/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4017 - val_loss: 5.7126\n",
      "Epoch 1778/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4015 - val_loss: 5.7124\n",
      "Epoch 1779/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.4012 - val_loss: 5.7122\n",
      "Epoch 1780/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4010 - val_loss: 5.7120\n",
      "Epoch 1781/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4008 - val_loss: 5.7119\n",
      "Epoch 1782/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4005 - val_loss: 5.7117\n",
      "Epoch 1783/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.4003 - val_loss: 5.7115\n",
      "Epoch 1784/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.4000 - val_loss: 5.7113\n",
      "Epoch 1785/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3998 - val_loss: 5.7111\n",
      "Epoch 1786/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3995 - val_loss: 5.7109\n",
      "Epoch 1787/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3993 - val_loss: 5.7107\n",
      "Epoch 1788/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3991 - val_loss: 5.7105\n",
      "Epoch 1789/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.3988 - val_loss: 5.7103\n",
      "Epoch 1790/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3986 - val_loss: 5.7101\n",
      "Epoch 1791/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3983 - val_loss: 5.7099\n",
      "Epoch 1792/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3981 - val_loss: 5.7097\n",
      "Epoch 1793/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3979 - val_loss: 5.7095\n",
      "Epoch 1794/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3976 - val_loss: 5.7093\n",
      "Epoch 1795/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3974 - val_loss: 5.7091\n",
      "Epoch 1796/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3971 - val_loss: 5.7089\n",
      "Epoch 1797/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.3969 - val_loss: 5.7087\n",
      "Epoch 1798/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3967 - val_loss: 5.7085\n",
      "Epoch 1799/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3964 - val_loss: 5.7083\n",
      "Epoch 1800/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3962 - val_loss: 5.7081\n",
      "Epoch 1801/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3959 - val_loss: 5.7079\n",
      "Epoch 1802/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3957 - val_loss: 5.7077\n",
      "Epoch 1803/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3955 - val_loss: 5.7075\n",
      "Epoch 1804/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3952 - val_loss: 5.7073\n",
      "Epoch 1805/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3950 - val_loss: 5.7071\n",
      "Epoch 1806/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3947 - val_loss: 5.7069\n",
      "Epoch 1807/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3945 - val_loss: 5.7067\n",
      "Epoch 1808/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3943 - val_loss: 5.7065\n",
      "Epoch 1809/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3940 - val_loss: 5.7063\n",
      "Epoch 1810/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3938 - val_loss: 5.7061\n",
      "Epoch 1811/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3935 - val_loss: 5.7060\n",
      "Epoch 1812/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.3933 - val_loss: 5.7058\n",
      "Epoch 1813/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3931 - val_loss: 5.7056\n",
      "Epoch 1814/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3928 - val_loss: 5.7054\n",
      "Epoch 1815/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3926 - val_loss: 5.7052\n",
      "Epoch 1816/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3924 - val_loss: 5.7050\n",
      "Epoch 1817/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3921 - val_loss: 5.7048\n",
      "Epoch 1818/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3919 - val_loss: 5.7046\n",
      "Epoch 1819/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3916 - val_loss: 5.7044\n",
      "Epoch 1820/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3914 - val_loss: 5.7042\n",
      "Epoch 1821/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3912 - val_loss: 5.7040\n",
      "Epoch 1822/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3909 - val_loss: 5.7038\n",
      "Epoch 1823/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3907 - val_loss: 5.7036\n",
      "Epoch 1824/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3905 - val_loss: 5.7034\n",
      "Epoch 1825/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3902 - val_loss: 5.7032\n",
      "Epoch 1826/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3900 - val_loss: 5.7030\n",
      "Epoch 1827/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3897 - val_loss: 5.7028\n",
      "Epoch 1828/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3895 - val_loss: 5.7026\n",
      "Epoch 1829/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3893 - val_loss: 5.7025\n",
      "Epoch 1830/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3890 - val_loss: 5.7023\n",
      "Epoch 1831/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3888 - val_loss: 5.7021\n",
      "Epoch 1832/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3886 - val_loss: 5.7019\n",
      "Epoch 1833/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3883 - val_loss: 5.7017\n",
      "Epoch 1834/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3881 - val_loss: 5.7015\n",
      "Epoch 1835/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3878 - val_loss: 5.7013\n",
      "Epoch 1836/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3876 - val_loss: 5.7011\n",
      "Epoch 1837/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3874 - val_loss: 5.7009\n",
      "Epoch 1838/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3871 - val_loss: 5.7007\n",
      "Epoch 1839/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3869 - val_loss: 5.7005\n",
      "Epoch 1840/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3867 - val_loss: 5.7003\n",
      "Epoch 1841/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3864 - val_loss: 5.7001\n",
      "Epoch 1842/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3862 - val_loss: 5.6999\n",
      "Epoch 1843/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3860 - val_loss: 5.6998\n",
      "Epoch 1844/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3857 - val_loss: 5.6996\n",
      "Epoch 1845/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3855 - val_loss: 5.6994\n",
      "Epoch 1846/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3853 - val_loss: 5.6992\n",
      "Epoch 1847/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3850 - val_loss: 5.6990\n",
      "Epoch 1848/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3848 - val_loss: 5.6988\n",
      "Epoch 1849/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3845 - val_loss: 5.6986\n",
      "Epoch 1850/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3843 - val_loss: 5.6984\n",
      "Epoch 1851/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3841 - val_loss: 5.6982\n",
      "Epoch 1852/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3838 - val_loss: 5.6980\n",
      "Epoch 1853/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3836 - val_loss: 5.6978\n",
      "Epoch 1854/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3834 - val_loss: 5.6976\n",
      "Epoch 1855/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.3831 - val_loss: 5.6975\n",
      "Epoch 1856/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3829 - val_loss: 5.6973\n",
      "Epoch 1857/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3827 - val_loss: 5.6971\n",
      "Epoch 1858/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3824 - val_loss: 5.6969\n",
      "Epoch 1859/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3822 - val_loss: 5.6967\n",
      "Epoch 1860/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3820 - val_loss: 5.6965\n",
      "Epoch 1861/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3817 - val_loss: 5.6963\n",
      "Epoch 1862/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3815 - val_loss: 5.6961\n",
      "Epoch 1863/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3813 - val_loss: 5.6959\n",
      "Epoch 1864/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3810 - val_loss: 5.6957\n",
      "Epoch 1865/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3808 - val_loss: 5.6955\n",
      "Epoch 1866/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3806 - val_loss: 5.6954\n",
      "Epoch 1867/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3803 - val_loss: 5.6952\n",
      "Epoch 1868/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3801 - val_loss: 5.6950\n",
      "Epoch 1869/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3799 - val_loss: 5.6948\n",
      "Epoch 1870/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3796 - val_loss: 5.6946\n",
      "Epoch 1871/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3794 - val_loss: 5.6944\n",
      "Epoch 1872/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3792 - val_loss: 5.6942\n",
      "Epoch 1873/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3789 - val_loss: 5.6940\n",
      "Epoch 1874/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3787 - val_loss: 5.6938\n",
      "Epoch 1875/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3785 - val_loss: 5.6936\n",
      "Epoch 1876/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3782 - val_loss: 5.6935\n",
      "Epoch 1877/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3780 - val_loss: 5.6933\n",
      "Epoch 1878/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3778 - val_loss: 5.6931\n",
      "Epoch 1879/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3775 - val_loss: 5.6929\n",
      "Epoch 1880/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3773 - val_loss: 5.6927\n",
      "Epoch 1881/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3771 - val_loss: 5.6925\n",
      "Epoch 1882/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3768 - val_loss: 5.6923\n",
      "Epoch 1883/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3766 - val_loss: 5.6921\n",
      "Epoch 1884/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3764 - val_loss: 5.6919\n",
      "Epoch 1885/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3761 - val_loss: 5.6918\n",
      "Epoch 1886/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3759 - val_loss: 5.6916\n",
      "Epoch 1887/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3757 - val_loss: 5.6914\n",
      "Epoch 1888/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3755 - val_loss: 5.6912\n",
      "Epoch 1889/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3752 - val_loss: 5.6910\n",
      "Epoch 1890/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3750 - val_loss: 5.6908\n",
      "Epoch 1891/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3748 - val_loss: 5.6906\n",
      "Epoch 1892/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3745 - val_loss: 5.6904\n",
      "Epoch 1893/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3743 - val_loss: 5.6903\n",
      "Epoch 1894/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3741 - val_loss: 5.6901\n",
      "Epoch 1895/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3738 - val_loss: 5.6899\n",
      "Epoch 1896/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3736 - val_loss: 5.6897\n",
      "Epoch 1897/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3734 - val_loss: 5.6895\n",
      "Epoch 1898/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3731 - val_loss: 5.6893\n",
      "Epoch 1899/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3729 - val_loss: 5.6891\n",
      "Epoch 1900/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3727 - val_loss: 5.6889\n",
      "Epoch 1901/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3724 - val_loss: 5.6888\n",
      "Epoch 1902/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3722 - val_loss: 5.6886\n",
      "Epoch 1903/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3720 - val_loss: 5.6884\n",
      "Epoch 1904/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3718 - val_loss: 5.6882\n",
      "Epoch 1905/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3715 - val_loss: 5.6880\n",
      "Epoch 1906/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3713 - val_loss: 5.6878\n",
      "Epoch 1907/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3711 - val_loss: 5.6876\n",
      "Epoch 1908/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3708 - val_loss: 5.6874\n",
      "Epoch 1909/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3706 - val_loss: 5.6873\n",
      "Epoch 1910/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3704 - val_loss: 5.6871\n",
      "Epoch 1911/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3702 - val_loss: 5.6869\n",
      "Epoch 1912/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3699 - val_loss: 5.6867\n",
      "Epoch 1913/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3697 - val_loss: 5.6865\n",
      "Epoch 1914/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3695 - val_loss: 5.6863\n",
      "Epoch 1915/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3692 - val_loss: 5.6861\n",
      "Epoch 1916/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3690 - val_loss: 5.6860\n",
      "Epoch 1917/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3688 - val_loss: 5.6858\n",
      "Epoch 1918/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3685 - val_loss: 5.6856\n",
      "Epoch 1919/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3683 - val_loss: 5.6854\n",
      "Epoch 1920/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3681 - val_loss: 5.6852\n",
      "Epoch 1921/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3679 - val_loss: 5.6850\n",
      "Epoch 1922/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3676 - val_loss: 5.6848\n",
      "Epoch 1923/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3674 - val_loss: 5.6847\n",
      "Epoch 1924/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3672 - val_loss: 5.6845\n",
      "Epoch 1925/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3669 - val_loss: 5.6843\n",
      "Epoch 1926/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3667 - val_loss: 5.6841\n",
      "Epoch 1927/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3665 - val_loss: 5.6839\n",
      "Epoch 1928/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.3663 - val_loss: 5.6837\n",
      "Epoch 1929/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 6.3660 - val_loss: 5.6835\n",
      "Epoch 1930/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3658 - val_loss: 5.6834\n",
      "Epoch 1931/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3656 - val_loss: 5.6832\n",
      "Epoch 1932/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3654 - val_loss: 5.6830\n",
      "Epoch 1933/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3651 - val_loss: 5.6828\n",
      "Epoch 1934/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3649 - val_loss: 5.6826\n",
      "Epoch 1935/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3647 - val_loss: 5.6824\n",
      "Epoch 1936/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3644 - val_loss: 5.6823\n",
      "Epoch 1937/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3642 - val_loss: 5.6821\n",
      "Epoch 1938/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3640 - val_loss: 5.6819\n",
      "Epoch 1939/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3638 - val_loss: 5.6817\n",
      "Epoch 1940/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.3635 - val_loss: 5.6815\n",
      "Epoch 1941/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.3633 - val_loss: 5.6813\n",
      "Epoch 1942/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3631 - val_loss: 5.6812\n",
      "Epoch 1943/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3629 - val_loss: 5.6810\n",
      "Epoch 1944/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3626 - val_loss: 5.6808\n",
      "Epoch 1945/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3624 - val_loss: 5.6806\n",
      "Epoch 1946/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3622 - val_loss: 5.6804\n",
      "Epoch 1947/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3619 - val_loss: 5.6802\n",
      "Epoch 1948/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3617 - val_loss: 5.6801\n",
      "Epoch 1949/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3615 - val_loss: 5.6799\n",
      "Epoch 1950/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3613 - val_loss: 5.6797\n",
      "Epoch 1951/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3610 - val_loss: 5.6795\n",
      "Epoch 1952/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3608 - val_loss: 5.6793\n",
      "Epoch 1953/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3606 - val_loss: 5.6791\n",
      "Epoch 1954/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3604 - val_loss: 5.6790\n",
      "Epoch 1955/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3601 - val_loss: 5.6788\n",
      "Epoch 1956/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3599 - val_loss: 5.6786\n",
      "Epoch 1957/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3597 - val_loss: 5.6784\n",
      "Epoch 1958/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3595 - val_loss: 5.6782\n",
      "Epoch 1959/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3592 - val_loss: 5.6780\n",
      "Epoch 1960/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3590 - val_loss: 5.6779\n",
      "Epoch 1961/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3588 - val_loss: 5.6777\n",
      "Epoch 1962/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3586 - val_loss: 5.6775\n",
      "Epoch 1963/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3583 - val_loss: 5.6773\n",
      "Epoch 1964/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3581 - val_loss: 5.6771\n",
      "Epoch 1965/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3579 - val_loss: 5.6770\n",
      "Epoch 1966/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3577 - val_loss: 5.6768\n",
      "Epoch 1967/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3574 - val_loss: 5.6766\n",
      "Epoch 1968/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3572 - val_loss: 5.6764\n",
      "Epoch 1969/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3570 - val_loss: 5.6762\n",
      "Epoch 1970/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3568 - val_loss: 5.6760\n",
      "Epoch 1971/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3565 - val_loss: 5.6759\n",
      "Epoch 1972/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3563 - val_loss: 5.6757\n",
      "Epoch 1973/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3561 - val_loss: 5.6755\n",
      "Epoch 1974/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3559 - val_loss: 5.6753\n",
      "Epoch 1975/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3556 - val_loss: 5.6751\n",
      "Epoch 1976/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3554 - val_loss: 5.6750\n",
      "Epoch 1977/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3552 - val_loss: 5.6748\n",
      "Epoch 1978/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3550 - val_loss: 5.6746\n",
      "Epoch 1979/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3547 - val_loss: 5.6744\n",
      "Epoch 1980/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3545 - val_loss: 5.6742\n",
      "Epoch 1981/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3543 - val_loss: 5.6741\n",
      "Epoch 1982/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3541 - val_loss: 5.6739\n",
      "Epoch 1983/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3538 - val_loss: 5.6737\n",
      "Epoch 1984/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 6.3536 - val_loss: 5.6735\n",
      "Epoch 1985/5000\n",
      "39898/39898 [==============================] - 0s 12us/step - loss: 6.3534 - val_loss: 5.6733\n",
      "Epoch 1986/5000\n",
      "39898/39898 [==============================] - 0s 12us/step - loss: 6.3532 - val_loss: 5.6732\n",
      "Epoch 1987/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 6.3530 - val_loss: 5.6730\n",
      "Epoch 1988/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.3527 - val_loss: 5.6728\n",
      "Epoch 1989/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3525 - val_loss: 5.6726\n",
      "Epoch 1990/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3523 - val_loss: 5.6724\n",
      "Epoch 1991/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3521 - val_loss: 5.6723\n",
      "Epoch 1992/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3518 - val_loss: 5.6721\n",
      "Epoch 1993/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3516 - val_loss: 5.6719\n",
      "Epoch 1994/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3514 - val_loss: 5.6717\n",
      "Epoch 1995/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3512 - val_loss: 5.6715\n",
      "Epoch 1996/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3510 - val_loss: 5.6714\n",
      "Epoch 1997/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3507 - val_loss: 5.6712\n",
      "Epoch 1998/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3505 - val_loss: 5.6710\n",
      "Epoch 1999/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3503 - val_loss: 5.6708\n",
      "Epoch 2000/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3501 - val_loss: 5.6706\n",
      "Epoch 2001/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3498 - val_loss: 5.6705\n",
      "Epoch 2002/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3496 - val_loss: 5.6703\n",
      "Epoch 2003/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3494 - val_loss: 5.6701\n",
      "Epoch 2004/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3492 - val_loss: 5.6699\n",
      "Epoch 2005/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3490 - val_loss: 5.6697\n",
      "Epoch 2006/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3487 - val_loss: 5.6696\n",
      "Epoch 2007/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3485 - val_loss: 5.6694\n",
      "Epoch 2008/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3483 - val_loss: 5.6692\n",
      "Epoch 2009/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3481 - val_loss: 5.6690\n",
      "Epoch 2010/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3478 - val_loss: 5.6688\n",
      "Epoch 2011/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3476 - val_loss: 5.6687\n",
      "Epoch 2012/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3474 - val_loss: 5.6685\n",
      "Epoch 2013/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3472 - val_loss: 5.6683\n",
      "Epoch 2014/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3470 - val_loss: 5.6681\n",
      "Epoch 2015/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3467 - val_loss: 5.6680\n",
      "Epoch 2016/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3465 - val_loss: 5.6678\n",
      "Epoch 2017/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3463 - val_loss: 5.6676\n",
      "Epoch 2018/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3461 - val_loss: 5.6674\n",
      "Epoch 2019/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3459 - val_loss: 5.6672\n",
      "Epoch 2020/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.3456 - val_loss: 5.6671\n",
      "Epoch 2021/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3454 - val_loss: 5.6669\n",
      "Epoch 2022/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3452 - val_loss: 5.6667\n",
      "Epoch 2023/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3450 - val_loss: 5.6665\n",
      "Epoch 2024/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3448 - val_loss: 5.6664\n",
      "Epoch 2025/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3445 - val_loss: 5.6662\n",
      "Epoch 2026/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3443 - val_loss: 5.6660\n",
      "Epoch 2027/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3441 - val_loss: 5.6658\n",
      "Epoch 2028/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3439 - val_loss: 5.6657\n",
      "Epoch 2029/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3437 - val_loss: 5.6655\n",
      "Epoch 2030/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3434 - val_loss: 5.6653\n",
      "Epoch 2031/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3432 - val_loss: 5.6651\n",
      "Epoch 2032/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3430 - val_loss: 5.6649\n",
      "Epoch 2033/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3428 - val_loss: 5.6648\n",
      "Epoch 2034/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3426 - val_loss: 5.6646\n",
      "Epoch 2035/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3423 - val_loss: 5.6644\n",
      "Epoch 2036/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3421 - val_loss: 5.6642\n",
      "Epoch 2037/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3419 - val_loss: 5.6641\n",
      "Epoch 2038/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3417 - val_loss: 5.6639\n",
      "Epoch 2039/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3415 - val_loss: 5.6637\n",
      "Epoch 2040/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3412 - val_loss: 5.6635\n",
      "Epoch 2041/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3410 - val_loss: 5.6634\n",
      "Epoch 2042/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3408 - val_loss: 5.6632\n",
      "Epoch 2043/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3406 - val_loss: 5.6630\n",
      "Epoch 2044/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3404 - val_loss: 5.6628\n",
      "Epoch 2045/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3401 - val_loss: 5.6627\n",
      "Epoch 2046/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3399 - val_loss: 5.6625\n",
      "Epoch 2047/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3397 - val_loss: 5.6623\n",
      "Epoch 2048/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3395 - val_loss: 5.6621\n",
      "Epoch 2049/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3393 - val_loss: 5.6620\n",
      "Epoch 2050/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3391 - val_loss: 5.6618\n",
      "Epoch 2051/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3388 - val_loss: 5.6616\n",
      "Epoch 2052/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3386 - val_loss: 5.6614\n",
      "Epoch 2053/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3384 - val_loss: 5.6613\n",
      "Epoch 2054/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3382 - val_loss: 5.6611\n",
      "Epoch 2055/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3380 - val_loss: 5.6609\n",
      "Epoch 2056/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3377 - val_loss: 5.6607\n",
      "Epoch 2057/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3375 - val_loss: 5.6606\n",
      "Epoch 2058/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3373 - val_loss: 5.6604\n",
      "Epoch 2059/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3371 - val_loss: 5.6602\n",
      "Epoch 2060/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3369 - val_loss: 5.6600\n",
      "Epoch 2061/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3367 - val_loss: 5.6599\n",
      "Epoch 2062/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 6.3364 - val_loss: 5.6597\n",
      "Epoch 2063/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3362 - val_loss: 5.6595\n",
      "Epoch 2064/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.3360 - val_loss: 5.6593\n",
      "Epoch 2065/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.3358 - val_loss: 5.6592\n",
      "Epoch 2066/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3356 - val_loss: 5.6590\n",
      "Epoch 2067/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3354 - val_loss: 5.6588\n",
      "Epoch 2068/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3351 - val_loss: 5.6586\n",
      "Epoch 2069/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3349 - val_loss: 5.6585\n",
      "Epoch 2070/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3347 - val_loss: 5.6583\n",
      "Epoch 2071/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3345 - val_loss: 5.6581\n",
      "Epoch 2072/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.3343 - val_loss: 5.6579\n",
      "Epoch 2073/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3341 - val_loss: 5.6578\n",
      "Epoch 2074/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3338 - val_loss: 5.6576\n",
      "Epoch 2075/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3336 - val_loss: 5.6574\n",
      "Epoch 2076/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3334 - val_loss: 5.6572\n",
      "Epoch 2077/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3332 - val_loss: 5.6571\n",
      "Epoch 2078/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3330 - val_loss: 5.6569\n",
      "Epoch 2079/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3328 - val_loss: 5.6567\n",
      "Epoch 2080/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3325 - val_loss: 5.6565\n",
      "Epoch 2081/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3323 - val_loss: 5.6564\n",
      "Epoch 2082/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3321 - val_loss: 5.6562\n",
      "Epoch 2083/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3319 - val_loss: 5.6560\n",
      "Epoch 2084/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3317 - val_loss: 5.6559\n",
      "Epoch 2085/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3315 - val_loss: 5.6557\n",
      "Epoch 2086/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3312 - val_loss: 5.6555\n",
      "Epoch 2087/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.3310 - val_loss: 5.6553\n",
      "Epoch 2088/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3308 - val_loss: 5.6552\n",
      "Epoch 2089/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3306 - val_loss: 5.6550\n",
      "Epoch 2090/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3304 - val_loss: 5.6548\n",
      "Epoch 2091/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3302 - val_loss: 5.6546\n",
      "Epoch 2092/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3299 - val_loss: 5.6545\n",
      "Epoch 2093/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3297 - val_loss: 5.6543\n",
      "Epoch 2094/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3295 - val_loss: 5.6541\n",
      "Epoch 2095/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3293 - val_loss: 5.6540\n",
      "Epoch 2096/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3291 - val_loss: 5.6538\n",
      "Epoch 2097/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3289 - val_loss: 5.6536\n",
      "Epoch 2098/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3287 - val_loss: 5.6534\n",
      "Epoch 2099/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3284 - val_loss: 5.6533\n",
      "Epoch 2100/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3282 - val_loss: 5.6531\n",
      "Epoch 2101/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3280 - val_loss: 5.6529\n",
      "Epoch 2102/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3278 - val_loss: 5.6528\n",
      "Epoch 2103/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3276 - val_loss: 5.6526\n",
      "Epoch 2104/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3274 - val_loss: 5.6524\n",
      "Epoch 2105/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3272 - val_loss: 5.6522\n",
      "Epoch 2106/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3269 - val_loss: 5.6521\n",
      "Epoch 2107/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3267 - val_loss: 5.6519\n",
      "Epoch 2108/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3265 - val_loss: 5.6517\n",
      "Epoch 2109/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3263 - val_loss: 5.6516\n",
      "Epoch 2110/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3261 - val_loss: 5.6514\n",
      "Epoch 2111/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3259 - val_loss: 5.6512\n",
      "Epoch 2112/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3257 - val_loss: 5.6510\n",
      "Epoch 2113/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3254 - val_loss: 5.6509\n",
      "Epoch 2114/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3252 - val_loss: 5.6507\n",
      "Epoch 2115/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3250 - val_loss: 5.6505\n",
      "Epoch 2116/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3248 - val_loss: 5.6504\n",
      "Epoch 2117/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3246 - val_loss: 5.6502\n",
      "Epoch 2118/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3244 - val_loss: 5.6500\n",
      "Epoch 2119/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3242 - val_loss: 5.6498\n",
      "Epoch 2120/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3240 - val_loss: 5.6497\n",
      "Epoch 2121/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3237 - val_loss: 5.6495\n",
      "Epoch 2122/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3235 - val_loss: 5.6493\n",
      "Epoch 2123/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3233 - val_loss: 5.6492\n",
      "Epoch 2124/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3231 - val_loss: 5.6490\n",
      "Epoch 2125/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3229 - val_loss: 5.6488\n",
      "Epoch 2126/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3227 - val_loss: 5.6487\n",
      "Epoch 2127/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3225 - val_loss: 5.6485\n",
      "Epoch 2128/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3222 - val_loss: 5.6483\n",
      "Epoch 2129/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3220 - val_loss: 5.6481\n",
      "Epoch 2130/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3218 - val_loss: 5.6480\n",
      "Epoch 2131/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3216 - val_loss: 5.6478\n",
      "Epoch 2132/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3214 - val_loss: 5.6476\n",
      "Epoch 2133/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3212 - val_loss: 5.6475\n",
      "Epoch 2134/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3210 - val_loss: 5.6473\n",
      "Epoch 2135/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3208 - val_loss: 5.6471\n",
      "Epoch 2136/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3205 - val_loss: 5.6470\n",
      "Epoch 2137/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3203 - val_loss: 5.6468\n",
      "Epoch 2138/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3201 - val_loss: 5.6466\n",
      "Epoch 2139/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3199 - val_loss: 5.6465\n",
      "Epoch 2140/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3197 - val_loss: 5.6463\n",
      "Epoch 2141/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3195 - val_loss: 5.6461\n",
      "Epoch 2142/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3193 - val_loss: 5.6459\n",
      "Epoch 2143/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3191 - val_loss: 5.6458\n",
      "Epoch 2144/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3189 - val_loss: 5.6456\n",
      "Epoch 2145/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3186 - val_loss: 5.6454\n",
      "Epoch 2146/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3184 - val_loss: 5.6453\n",
      "Epoch 2147/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3182 - val_loss: 5.6451\n",
      "Epoch 2148/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3180 - val_loss: 5.6449\n",
      "Epoch 2149/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3178 - val_loss: 5.6448\n",
      "Epoch 2150/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3176 - val_loss: 5.6446\n",
      "Epoch 2151/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3174 - val_loss: 5.6444\n",
      "Epoch 2152/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3172 - val_loss: 5.6443\n",
      "Epoch 2153/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3170 - val_loss: 5.6441\n",
      "Epoch 2154/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3167 - val_loss: 5.6439\n",
      "Epoch 2155/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3165 - val_loss: 5.6438\n",
      "Epoch 2156/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3163 - val_loss: 5.6436\n",
      "Epoch 2157/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3161 - val_loss: 5.6434\n",
      "Epoch 2158/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3159 - val_loss: 5.6432\n",
      "Epoch 2159/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3157 - val_loss: 5.6431\n",
      "Epoch 2160/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3155 - val_loss: 5.6429\n",
      "Epoch 2161/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3153 - val_loss: 5.6427\n",
      "Epoch 2162/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3151 - val_loss: 5.6426\n",
      "Epoch 2163/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3148 - val_loss: 5.6424\n",
      "Epoch 2164/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3146 - val_loss: 5.6422\n",
      "Epoch 2165/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3144 - val_loss: 5.6421\n",
      "Epoch 2166/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3142 - val_loss: 5.6419\n",
      "Epoch 2167/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3140 - val_loss: 5.6417\n",
      "Epoch 2168/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3138 - val_loss: 5.6416\n",
      "Epoch 2169/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3136 - val_loss: 5.6414\n",
      "Epoch 2170/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3134 - val_loss: 5.6412\n",
      "Epoch 2171/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3132 - val_loss: 5.6411\n",
      "Epoch 2172/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3130 - val_loss: 5.6409\n",
      "Epoch 2173/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3127 - val_loss: 5.6407\n",
      "Epoch 2174/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3125 - val_loss: 5.6406\n",
      "Epoch 2175/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3123 - val_loss: 5.6404\n",
      "Epoch 2176/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3121 - val_loss: 5.6402\n",
      "Epoch 2177/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3119 - val_loss: 5.6401\n",
      "Epoch 2178/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3117 - val_loss: 5.6399\n",
      "Epoch 2179/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3115 - val_loss: 5.6397\n",
      "Epoch 2180/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3113 - val_loss: 5.6396\n",
      "Epoch 2181/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3111 - val_loss: 5.6394\n",
      "Epoch 2182/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3109 - val_loss: 5.6392\n",
      "Epoch 2183/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3107 - val_loss: 5.6391\n",
      "Epoch 2184/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3104 - val_loss: 5.6389\n",
      "Epoch 2185/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3102 - val_loss: 5.6387\n",
      "Epoch 2186/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3100 - val_loss: 5.6386\n",
      "Epoch 2187/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3098 - val_loss: 5.6384\n",
      "Epoch 2188/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3096 - val_loss: 5.6382\n",
      "Epoch 2189/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3094 - val_loss: 5.6381\n",
      "Epoch 2190/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3092 - val_loss: 5.6379\n",
      "Epoch 2191/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3090 - val_loss: 5.6377\n",
      "Epoch 2192/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3088 - val_loss: 5.6376\n",
      "Epoch 2193/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.3086 - val_loss: 5.6374\n",
      "Epoch 2194/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3084 - val_loss: 5.6372\n",
      "Epoch 2195/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3081 - val_loss: 5.6371\n",
      "Epoch 2196/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.3079 - val_loss: 5.6369\n",
      "Epoch 2197/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3077 - val_loss: 5.6367\n",
      "Epoch 2198/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3075 - val_loss: 5.6366\n",
      "Epoch 2199/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3073 - val_loss: 5.6364\n",
      "Epoch 2200/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3071 - val_loss: 5.6363\n",
      "Epoch 2201/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3069 - val_loss: 5.6361\n",
      "Epoch 2202/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3067 - val_loss: 5.6359\n",
      "Epoch 2203/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3065 - val_loss: 5.6358\n",
      "Epoch 2204/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3063 - val_loss: 5.6356\n",
      "Epoch 2205/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.3061 - val_loss: 5.6354\n",
      "Epoch 2206/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3059 - val_loss: 5.6353\n",
      "Epoch 2207/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3057 - val_loss: 5.6351\n",
      "Epoch 2208/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.3054 - val_loss: 5.6349\n",
      "Epoch 2209/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3052 - val_loss: 5.6348\n",
      "Epoch 2210/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3050 - val_loss: 5.6346\n",
      "Epoch 2211/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3048 - val_loss: 5.6344\n",
      "Epoch 2212/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3046 - val_loss: 5.6343\n",
      "Epoch 2213/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3044 - val_loss: 5.6341\n",
      "Epoch 2214/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3042 - val_loss: 5.6339\n",
      "Epoch 2215/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3040 - val_loss: 5.6338\n",
      "Epoch 2216/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3038 - val_loss: 5.6336\n",
      "Epoch 2217/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3036 - val_loss: 5.6334\n",
      "Epoch 2218/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3034 - val_loss: 5.6333\n",
      "Epoch 2219/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3032 - val_loss: 5.6331\n",
      "Epoch 2220/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3030 - val_loss: 5.6330\n",
      "Epoch 2221/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3028 - val_loss: 5.6328\n",
      "Epoch 2222/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3026 - val_loss: 5.6326\n",
      "Epoch 2223/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3023 - val_loss: 5.6325\n",
      "Epoch 2224/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3021 - val_loss: 5.6323\n",
      "Epoch 2225/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3019 - val_loss: 5.6321\n",
      "Epoch 2226/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3017 - val_loss: 5.6320\n",
      "Epoch 2227/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3015 - val_loss: 5.6318\n",
      "Epoch 2228/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3013 - val_loss: 5.6316\n",
      "Epoch 2229/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3011 - val_loss: 5.6315\n",
      "Epoch 2230/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3009 - val_loss: 5.6313\n",
      "Epoch 2231/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3007 - val_loss: 5.6312\n",
      "Epoch 2232/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3005 - val_loss: 5.6310\n",
      "Epoch 2233/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3003 - val_loss: 5.6308\n",
      "Epoch 2234/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.3001 - val_loss: 5.6307\n",
      "Epoch 2235/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2999 - val_loss: 5.6305\n",
      "Epoch 2236/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2997 - val_loss: 5.6303\n",
      "Epoch 2237/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2995 - val_loss: 5.6302\n",
      "Epoch 2238/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2993 - val_loss: 5.6300\n",
      "Epoch 2239/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2991 - val_loss: 5.6299\n",
      "Epoch 2240/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2988 - val_loss: 5.6297\n",
      "Epoch 2241/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 6.2986 - val_loss: 5.6295\n",
      "Epoch 2242/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2984 - val_loss: 5.6294\n",
      "Epoch 2243/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2982 - val_loss: 5.6292\n",
      "Epoch 2244/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2980 - val_loss: 5.6290\n",
      "Epoch 2245/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2978 - val_loss: 5.6289\n",
      "Epoch 2246/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2976 - val_loss: 5.6287\n",
      "Epoch 2247/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2974 - val_loss: 5.6285\n",
      "Epoch 2248/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2972 - val_loss: 5.6284\n",
      "Epoch 2249/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2970 - val_loss: 5.6282\n",
      "Epoch 2250/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2968 - val_loss: 5.6281\n",
      "Epoch 2251/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2966 - val_loss: 5.6279\n",
      "Epoch 2252/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2964 - val_loss: 5.6277\n",
      "Epoch 2253/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2962 - val_loss: 5.6276\n",
      "Epoch 2254/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2960 - val_loss: 5.6274\n",
      "Epoch 2255/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2958 - val_loss: 5.6273\n",
      "Epoch 2256/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2956 - val_loss: 5.6271\n",
      "Epoch 2257/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2954 - val_loss: 5.6269\n",
      "Epoch 2258/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2952 - val_loss: 5.6268\n",
      "Epoch 2259/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2950 - val_loss: 5.6266\n",
      "Epoch 2260/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2948 - val_loss: 5.6264\n",
      "Epoch 2261/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2945 - val_loss: 5.6263\n",
      "Epoch 2262/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2943 - val_loss: 5.6261\n",
      "Epoch 2263/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2941 - val_loss: 5.6260\n",
      "Epoch 2264/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2939 - val_loss: 5.6258\n",
      "Epoch 2265/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2937 - val_loss: 5.6256\n",
      "Epoch 2266/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2935 - val_loss: 5.6255\n",
      "Epoch 2267/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2933 - val_loss: 5.6253\n",
      "Epoch 2268/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2931 - val_loss: 5.6252\n",
      "Epoch 2269/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2929 - val_loss: 5.6250\n",
      "Epoch 2270/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2927 - val_loss: 5.6248\n",
      "Epoch 2271/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2925 - val_loss: 5.6247\n",
      "Epoch 2272/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2923 - val_loss: 5.6245\n",
      "Epoch 2273/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.2921 - val_loss: 5.6243\n",
      "Epoch 2274/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2919 - val_loss: 5.6242\n",
      "Epoch 2275/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2917 - val_loss: 5.6240\n",
      "Epoch 2276/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2915 - val_loss: 5.6239\n",
      "Epoch 2277/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2913 - val_loss: 5.6237\n",
      "Epoch 2278/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2911 - val_loss: 5.6235\n",
      "Epoch 2279/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2909 - val_loss: 5.6234\n",
      "Epoch 2280/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2907 - val_loss: 5.6232\n",
      "Epoch 2281/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2905 - val_loss: 5.6231\n",
      "Epoch 2282/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2903 - val_loss: 5.6229\n",
      "Epoch 2283/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2901 - val_loss: 5.6227\n",
      "Epoch 2284/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2899 - val_loss: 5.6226\n",
      "Epoch 2285/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2897 - val_loss: 5.6224\n",
      "Epoch 2286/5000\n",
      "39898/39898 [==============================] - 1s 18us/step - loss: 6.2895 - val_loss: 5.6223\n",
      "Epoch 2287/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2893 - val_loss: 5.6221\n",
      "Epoch 2288/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2891 - val_loss: 5.6219\n",
      "Epoch 2289/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2889 - val_loss: 5.6218\n",
      "Epoch 2290/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2887 - val_loss: 5.6216\n",
      "Epoch 2291/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2885 - val_loss: 5.6215\n",
      "Epoch 2292/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2883 - val_loss: 5.6213\n",
      "Epoch 2293/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2880 - val_loss: 5.6211\n",
      "Epoch 2294/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2878 - val_loss: 5.6210\n",
      "Epoch 2295/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2876 - val_loss: 5.6208\n",
      "Epoch 2296/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2874 - val_loss: 5.6207\n",
      "Epoch 2297/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2872 - val_loss: 5.6205\n",
      "Epoch 2298/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2870 - val_loss: 5.6203\n",
      "Epoch 2299/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2868 - val_loss: 5.6202\n",
      "Epoch 2300/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2866 - val_loss: 5.6200\n",
      "Epoch 2301/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2864 - val_loss: 5.6199\n",
      "Epoch 2302/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2862 - val_loss: 5.6197\n",
      "Epoch 2303/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2860 - val_loss: 5.6195\n",
      "Epoch 2304/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2858 - val_loss: 5.6194\n",
      "Epoch 2305/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2856 - val_loss: 5.6192\n",
      "Epoch 2306/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.2854 - val_loss: 5.6191\n",
      "Epoch 2307/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2852 - val_loss: 5.6189\n",
      "Epoch 2308/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2850 - val_loss: 5.6188\n",
      "Epoch 2309/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2848 - val_loss: 5.6186\n",
      "Epoch 2310/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2846 - val_loss: 5.6184\n",
      "Epoch 2311/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2844 - val_loss: 5.6183\n",
      "Epoch 2312/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2842 - val_loss: 5.6181\n",
      "Epoch 2313/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2840 - val_loss: 5.6180\n",
      "Epoch 2314/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2838 - val_loss: 5.6178\n",
      "Epoch 2315/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2836 - val_loss: 5.6176\n",
      "Epoch 2316/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2834 - val_loss: 5.6175\n",
      "Epoch 2317/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2832 - val_loss: 5.6173\n",
      "Epoch 2318/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2830 - val_loss: 5.6172\n",
      "Epoch 2319/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2828 - val_loss: 5.6170\n",
      "Epoch 2320/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2826 - val_loss: 5.6168\n",
      "Epoch 2321/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2824 - val_loss: 5.6167\n",
      "Epoch 2322/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2822 - val_loss: 5.6165\n",
      "Epoch 2323/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2820 - val_loss: 5.6164\n",
      "Epoch 2324/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2818 - val_loss: 5.6162\n",
      "Epoch 2325/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.2816 - val_loss: 5.6161\n",
      "Epoch 2326/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2814 - val_loss: 5.6159\n",
      "Epoch 2327/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.2812 - val_loss: 5.6157\n",
      "Epoch 2328/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.2810 - val_loss: 5.6156\n",
      "Epoch 2329/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2808 - val_loss: 5.6154\n",
      "Epoch 2330/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2806 - val_loss: 5.6153\n",
      "Epoch 2331/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2804 - val_loss: 5.6151\n",
      "Epoch 2332/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2802 - val_loss: 5.6150\n",
      "Epoch 2333/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2800 - val_loss: 5.6148\n",
      "Epoch 2334/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2798 - val_loss: 5.6146\n",
      "Epoch 2335/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2796 - val_loss: 5.6145\n",
      "Epoch 2336/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2794 - val_loss: 5.6143\n",
      "Epoch 2337/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2792 - val_loss: 5.6142\n",
      "Epoch 2338/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2790 - val_loss: 5.6140\n",
      "Epoch 2339/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2788 - val_loss: 5.6139\n",
      "Epoch 2340/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.2786 - val_loss: 5.6137\n",
      "Epoch 2341/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2784 - val_loss: 5.6135\n",
      "Epoch 2342/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2782 - val_loss: 5.6134\n",
      "Epoch 2343/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2780 - val_loss: 5.6132\n",
      "Epoch 2344/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2778 - val_loss: 5.6131\n",
      "Epoch 2345/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2776 - val_loss: 5.6129\n",
      "Epoch 2346/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2774 - val_loss: 5.6128\n",
      "Epoch 2347/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2772 - val_loss: 5.6126\n",
      "Epoch 2348/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2770 - val_loss: 5.6124\n",
      "Epoch 2349/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2768 - val_loss: 5.6123\n",
      "Epoch 2350/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2766 - val_loss: 5.6121\n",
      "Epoch 2351/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2764 - val_loss: 5.6120\n",
      "Epoch 2352/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2762 - val_loss: 5.6118\n",
      "Epoch 2353/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2760 - val_loss: 5.6117\n",
      "Epoch 2354/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2758 - val_loss: 5.6115\n",
      "Epoch 2355/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2756 - val_loss: 5.6113\n",
      "Epoch 2356/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2754 - val_loss: 5.6112\n",
      "Epoch 2357/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2752 - val_loss: 5.6110\n",
      "Epoch 2358/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2750 - val_loss: 5.6109\n",
      "Epoch 2359/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2748 - val_loss: 5.6107\n",
      "Epoch 2360/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2746 - val_loss: 5.6106\n",
      "Epoch 2361/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2744 - val_loss: 5.6104\n",
      "Epoch 2362/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2742 - val_loss: 5.6103\n",
      "Epoch 2363/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2740 - val_loss: 5.6101\n",
      "Epoch 2364/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2738 - val_loss: 5.6099\n",
      "Epoch 2365/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2736 - val_loss: 5.6098\n",
      "Epoch 2366/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2735 - val_loss: 5.6096\n",
      "Epoch 2367/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2733 - val_loss: 5.6095\n",
      "Epoch 2368/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2731 - val_loss: 5.6093\n",
      "Epoch 2369/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2729 - val_loss: 5.6092\n",
      "Epoch 2370/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2727 - val_loss: 5.6090\n",
      "Epoch 2371/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2725 - val_loss: 5.6089\n",
      "Epoch 2372/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2723 - val_loss: 5.6087\n",
      "Epoch 2373/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2721 - val_loss: 5.6085\n",
      "Epoch 2374/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2719 - val_loss: 5.6084\n",
      "Epoch 2375/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2717 - val_loss: 5.6082\n",
      "Epoch 2376/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2715 - val_loss: 5.6081\n",
      "Epoch 2377/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2713 - val_loss: 5.6079\n",
      "Epoch 2378/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2711 - val_loss: 5.6078\n",
      "Epoch 2379/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2709 - val_loss: 5.6076\n",
      "Epoch 2380/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2707 - val_loss: 5.6075\n",
      "Epoch 2381/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2705 - val_loss: 5.6073\n",
      "Epoch 2382/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2703 - val_loss: 5.6071\n",
      "Epoch 2383/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2701 - val_loss: 5.6070\n",
      "Epoch 2384/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2699 - val_loss: 5.6068\n",
      "Epoch 2385/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2697 - val_loss: 5.6067\n",
      "Epoch 2386/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2695 - val_loss: 5.6065\n",
      "Epoch 2387/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2693 - val_loss: 5.6064\n",
      "Epoch 2388/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2691 - val_loss: 5.6062\n",
      "Epoch 2389/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2689 - val_loss: 5.6061\n",
      "Epoch 2390/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2687 - val_loss: 5.6059\n",
      "Epoch 2391/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2685 - val_loss: 5.6058\n",
      "Epoch 2392/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2683 - val_loss: 5.6056\n",
      "Epoch 2393/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2681 - val_loss: 5.6054\n",
      "Epoch 2394/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2679 - val_loss: 5.6053\n",
      "Epoch 2395/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2677 - val_loss: 5.6051\n",
      "Epoch 2396/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2675 - val_loss: 5.6050\n",
      "Epoch 2397/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2673 - val_loss: 5.6048\n",
      "Epoch 2398/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2671 - val_loss: 5.6047\n",
      "Epoch 2399/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2670 - val_loss: 5.6045\n",
      "Epoch 2400/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2668 - val_loss: 5.6044\n",
      "Epoch 2401/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2666 - val_loss: 5.6042\n",
      "Epoch 2402/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2664 - val_loss: 5.6041\n",
      "Epoch 2403/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2662 - val_loss: 5.6039\n",
      "Epoch 2404/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2660 - val_loss: 5.6038\n",
      "Epoch 2405/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2658 - val_loss: 5.6036\n",
      "Epoch 2406/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2656 - val_loss: 5.6035\n",
      "Epoch 2407/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2654 - val_loss: 5.6033\n",
      "Epoch 2408/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2652 - val_loss: 5.6031\n",
      "Epoch 2409/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2650 - val_loss: 5.6030\n",
      "Epoch 2410/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2648 - val_loss: 5.6028\n",
      "Epoch 2411/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2646 - val_loss: 5.6027\n",
      "Epoch 2412/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2644 - val_loss: 5.6025\n",
      "Epoch 2413/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2642 - val_loss: 5.6024\n",
      "Epoch 2414/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2640 - val_loss: 5.6022\n",
      "Epoch 2415/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2638 - val_loss: 5.6021\n",
      "Epoch 2416/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.2636 - val_loss: 5.6019\n",
      "Epoch 2417/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2634 - val_loss: 5.6018\n",
      "Epoch 2418/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2632 - val_loss: 5.6016\n",
      "Epoch 2419/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2630 - val_loss: 5.6015\n",
      "Epoch 2420/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2628 - val_loss: 5.6013\n",
      "Epoch 2421/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2627 - val_loss: 5.6012\n",
      "Epoch 2422/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2625 - val_loss: 5.6010\n",
      "Epoch 2423/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2623 - val_loss: 5.6008\n",
      "Epoch 2424/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2621 - val_loss: 5.6007\n",
      "Epoch 2425/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2619 - val_loss: 5.6005\n",
      "Epoch 2426/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2617 - val_loss: 5.6004\n",
      "Epoch 2427/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2615 - val_loss: 5.6002\n",
      "Epoch 2428/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2613 - val_loss: 5.6001\n",
      "Epoch 2429/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2611 - val_loss: 5.5999\n",
      "Epoch 2430/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2609 - val_loss: 5.5998\n",
      "Epoch 2431/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2607 - val_loss: 5.5996\n",
      "Epoch 2432/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2605 - val_loss: 5.5995\n",
      "Epoch 2433/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2603 - val_loss: 5.5993\n",
      "Epoch 2434/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2601 - val_loss: 5.5992\n",
      "Epoch 2435/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2599 - val_loss: 5.5990\n",
      "Epoch 2436/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2597 - val_loss: 5.5989\n",
      "Epoch 2437/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2595 - val_loss: 5.5987\n",
      "Epoch 2438/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2593 - val_loss: 5.5986\n",
      "Epoch 2439/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2592 - val_loss: 5.5984\n",
      "Epoch 2440/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2590 - val_loss: 5.5983\n",
      "Epoch 2441/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2588 - val_loss: 5.5981\n",
      "Epoch 2442/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2586 - val_loss: 5.5980\n",
      "Epoch 2443/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2584 - val_loss: 5.5978\n",
      "Epoch 2444/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2582 - val_loss: 5.5977\n",
      "Epoch 2445/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2580 - val_loss: 5.5975\n",
      "Epoch 2446/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2578 - val_loss: 5.5974\n",
      "Epoch 2447/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2576 - val_loss: 5.5972\n",
      "Epoch 2448/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2574 - val_loss: 5.5970\n",
      "Epoch 2449/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2572 - val_loss: 5.5969\n",
      "Epoch 2450/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2570 - val_loss: 5.5967\n",
      "Epoch 2451/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2568 - val_loss: 5.5966\n",
      "Epoch 2452/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2566 - val_loss: 5.5964\n",
      "Epoch 2453/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2564 - val_loss: 5.5963\n",
      "Epoch 2454/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2563 - val_loss: 5.5961\n",
      "Epoch 2455/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2561 - val_loss: 5.5960\n",
      "Epoch 2456/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2559 - val_loss: 5.5958\n",
      "Epoch 2457/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2557 - val_loss: 5.5957\n",
      "Epoch 2458/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2555 - val_loss: 5.5955\n",
      "Epoch 2459/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2553 - val_loss: 5.5954\n",
      "Epoch 2460/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2551 - val_loss: 5.5952\n",
      "Epoch 2461/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2549 - val_loss: 5.5951\n",
      "Epoch 2462/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2547 - val_loss: 5.5949\n",
      "Epoch 2463/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2545 - val_loss: 5.5948\n",
      "Epoch 2464/5000\n",
      "39898/39898 [==============================] - ETA: 0s - loss: 5.929 - 1s 23us/step - loss: 6.2543 - val_loss: 5.5946\n",
      "Epoch 2465/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2541 - val_loss: 5.5945\n",
      "Epoch 2466/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2539 - val_loss: 5.5943\n",
      "Epoch 2467/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2537 - val_loss: 5.5942\n",
      "Epoch 2468/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2536 - val_loss: 5.5940\n",
      "Epoch 2469/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2534 - val_loss: 5.5939\n",
      "Epoch 2470/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2532 - val_loss: 5.5937\n",
      "Epoch 2471/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2530 - val_loss: 5.5936\n",
      "Epoch 2472/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2528 - val_loss: 5.5934\n",
      "Epoch 2473/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2526 - val_loss: 5.5933\n",
      "Epoch 2474/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2524 - val_loss: 5.5931\n",
      "Epoch 2475/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2522 - val_loss: 5.5930\n",
      "Epoch 2476/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2520 - val_loss: 5.5928\n",
      "Epoch 2477/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2518 - val_loss: 5.5927\n",
      "Epoch 2478/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2516 - val_loss: 5.5925\n",
      "Epoch 2479/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2514 - val_loss: 5.5924\n",
      "Epoch 2480/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2512 - val_loss: 5.5922\n",
      "Epoch 2481/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2511 - val_loss: 5.5921\n",
      "Epoch 2482/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2509 - val_loss: 5.5919\n",
      "Epoch 2483/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2507 - val_loss: 5.5918\n",
      "Epoch 2484/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2505 - val_loss: 5.5916\n",
      "Epoch 2485/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2503 - val_loss: 5.5915\n",
      "Epoch 2486/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2501 - val_loss: 5.5913\n",
      "Epoch 2487/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2499 - val_loss: 5.5912\n",
      "Epoch 2488/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2497 - val_loss: 5.5910\n",
      "Epoch 2489/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2495 - val_loss: 5.5909\n",
      "Epoch 2490/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2493 - val_loss: 5.5907\n",
      "Epoch 2491/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2491 - val_loss: 5.5906\n",
      "Epoch 2492/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2489 - val_loss: 5.5904\n",
      "Epoch 2493/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2488 - val_loss: 5.5903\n",
      "Epoch 2494/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2486 - val_loss: 5.5901\n",
      "Epoch 2495/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2484 - val_loss: 5.5900\n",
      "Epoch 2496/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2482 - val_loss: 5.5898\n",
      "Epoch 2497/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2480 - val_loss: 5.5897\n",
      "Epoch 2498/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2478 - val_loss: 5.5895\n",
      "Epoch 2499/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2476 - val_loss: 5.5894\n",
      "Epoch 2500/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2474 - val_loss: 5.5892\n",
      "Epoch 2501/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2472 - val_loss: 5.5891\n",
      "Epoch 2502/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2470 - val_loss: 5.5889\n",
      "Epoch 2503/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2468 - val_loss: 5.5888\n",
      "Epoch 2504/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2467 - val_loss: 5.5887\n",
      "Epoch 2505/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2465 - val_loss: 5.5885\n",
      "Epoch 2506/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2463 - val_loss: 5.5884\n",
      "Epoch 2507/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2461 - val_loss: 5.5882\n",
      "Epoch 2508/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2459 - val_loss: 5.5881\n",
      "Epoch 2509/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2457 - val_loss: 5.5879\n",
      "Epoch 2510/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2455 - val_loss: 5.5878\n",
      "Epoch 2511/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2453 - val_loss: 5.5876\n",
      "Epoch 2512/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2451 - val_loss: 5.5875\n",
      "Epoch 2513/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2449 - val_loss: 5.5873\n",
      "Epoch 2514/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2448 - val_loss: 5.5872\n",
      "Epoch 2515/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2446 - val_loss: 5.5870\n",
      "Epoch 2516/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2444 - val_loss: 5.5869\n",
      "Epoch 2517/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2442 - val_loss: 5.5867\n",
      "Epoch 2518/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2440 - val_loss: 5.5866\n",
      "Epoch 2519/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2438 - val_loss: 5.5864\n",
      "Epoch 2520/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2436 - val_loss: 5.5863\n",
      "Epoch 2521/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2434 - val_loss: 5.5861\n",
      "Epoch 2522/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2432 - val_loss: 5.5860\n",
      "Epoch 2523/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2430 - val_loss: 5.5858\n",
      "Epoch 2524/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2429 - val_loss: 5.5857\n",
      "Epoch 2525/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2427 - val_loss: 5.5855\n",
      "Epoch 2526/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2425 - val_loss: 5.5854\n",
      "Epoch 2527/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2423 - val_loss: 5.5852\n",
      "Epoch 2528/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2421 - val_loss: 5.5851\n",
      "Epoch 2529/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2419 - val_loss: 5.5850\n",
      "Epoch 2530/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2417 - val_loss: 5.5848\n",
      "Epoch 2531/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2415 - val_loss: 5.5847\n",
      "Epoch 2532/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2413 - val_loss: 5.5845\n",
      "Epoch 2533/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2412 - val_loss: 5.5844\n",
      "Epoch 2534/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2410 - val_loss: 5.5842\n",
      "Epoch 2535/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2408 - val_loss: 5.5841\n",
      "Epoch 2536/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2406 - val_loss: 5.5839\n",
      "Epoch 2537/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2404 - val_loss: 5.5838\n",
      "Epoch 2538/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2402 - val_loss: 5.5836\n",
      "Epoch 2539/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2400 - val_loss: 5.5835\n",
      "Epoch 2540/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2398 - val_loss: 5.5833\n",
      "Epoch 2541/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2396 - val_loss: 5.5832\n",
      "Epoch 2542/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2395 - val_loss: 5.5830\n",
      "Epoch 2543/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2393 - val_loss: 5.5829\n",
      "Epoch 2544/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2391 - val_loss: 5.5827\n",
      "Epoch 2545/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2389 - val_loss: 5.5826\n",
      "Epoch 2546/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2387 - val_loss: 5.5825\n",
      "Epoch 2547/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2385 - val_loss: 5.5823\n",
      "Epoch 2548/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2383 - val_loss: 5.5822\n",
      "Epoch 2549/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.2381 - val_loss: 5.5820\n",
      "Epoch 2550/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2379 - val_loss: 5.5819\n",
      "Epoch 2551/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2378 - val_loss: 5.5817\n",
      "Epoch 2552/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2376 - val_loss: 5.5816\n",
      "Epoch 2553/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2374 - val_loss: 5.5814\n",
      "Epoch 2554/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2372 - val_loss: 5.5813\n",
      "Epoch 2555/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2370 - val_loss: 5.5811\n",
      "Epoch 2556/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2368 - val_loss: 5.5810\n",
      "Epoch 2557/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2366 - val_loss: 5.5808\n",
      "Epoch 2558/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2364 - val_loss: 5.5807\n",
      "Epoch 2559/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2363 - val_loss: 5.5805\n",
      "Epoch 2560/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2361 - val_loss: 5.5804\n",
      "Epoch 2561/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2359 - val_loss: 5.5803\n",
      "Epoch 2562/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2357 - val_loss: 5.5801\n",
      "Epoch 2563/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2355 - val_loss: 5.5800\n",
      "Epoch 2564/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2353 - val_loss: 5.5798\n",
      "Epoch 2565/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2351 - val_loss: 5.5797\n",
      "Epoch 2566/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2349 - val_loss: 5.5795\n",
      "Epoch 2567/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2348 - val_loss: 5.5794\n",
      "Epoch 2568/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2346 - val_loss: 5.5792\n",
      "Epoch 2569/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2344 - val_loss: 5.5791\n",
      "Epoch 2570/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2342 - val_loss: 5.5789\n",
      "Epoch 2571/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2340 - val_loss: 5.5788\n",
      "Epoch 2572/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2338 - val_loss: 5.5787\n",
      "Epoch 2573/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2336 - val_loss: 5.5785\n",
      "Epoch 2574/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2334 - val_loss: 5.5784\n",
      "Epoch 2575/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2333 - val_loss: 5.5782\n",
      "Epoch 2576/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2331 - val_loss: 5.5781\n",
      "Epoch 2577/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2329 - val_loss: 5.5779\n",
      "Epoch 2578/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2327 - val_loss: 5.5778\n",
      "Epoch 2579/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2325 - val_loss: 5.5776\n",
      "Epoch 2580/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2323 - val_loss: 5.5775\n",
      "Epoch 2581/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2321 - val_loss: 5.5773\n",
      "Epoch 2582/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2319 - val_loss: 5.5772\n",
      "Epoch 2583/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2318 - val_loss: 5.5771\n",
      "Epoch 2584/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2316 - val_loss: 5.5769\n",
      "Epoch 2585/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2314 - val_loss: 5.5768\n",
      "Epoch 2586/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2312 - val_loss: 5.5766\n",
      "Epoch 2587/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2310 - val_loss: 5.5765\n",
      "Epoch 2588/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2308 - val_loss: 5.5763\n",
      "Epoch 2589/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2306 - val_loss: 5.5762\n",
      "Epoch 2590/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 6.2305 - val_loss: 5.5760\n",
      "Epoch 2591/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2303 - val_loss: 5.5759\n",
      "Epoch 2592/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2301 - val_loss: 5.5757\n",
      "Epoch 2593/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.2299 - val_loss: 5.5756\n",
      "Epoch 2594/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2297 - val_loss: 5.5755\n",
      "Epoch 2595/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2295 - val_loss: 5.5753\n",
      "Epoch 2596/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2293 - val_loss: 5.5752\n",
      "Epoch 2597/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2291 - val_loss: 5.5750\n",
      "Epoch 2598/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2290 - val_loss: 5.5749\n",
      "Epoch 2599/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.2288 - val_loss: 5.5747\n",
      "Epoch 2600/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2286 - val_loss: 5.5746\n",
      "Epoch 2601/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.2284 - val_loss: 5.5744\n",
      "Epoch 2602/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.2282 - val_loss: 5.5743\n",
      "Epoch 2603/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2280 - val_loss: 5.5742\n",
      "Epoch 2604/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2278 - val_loss: 5.5740\n",
      "Epoch 2605/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2277 - val_loss: 5.5739\n",
      "Epoch 2606/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2275 - val_loss: 5.5737\n",
      "Epoch 2607/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2273 - val_loss: 5.5736\n",
      "Epoch 2608/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2271 - val_loss: 5.5734\n",
      "Epoch 2609/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2269 - val_loss: 5.5733\n",
      "Epoch 2610/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2267 - val_loss: 5.5732\n",
      "Epoch 2611/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2265 - val_loss: 5.5730\n",
      "Epoch 2612/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2264 - val_loss: 5.5729\n",
      "Epoch 2613/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2262 - val_loss: 5.5727\n",
      "Epoch 2614/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2260 - val_loss: 5.5726\n",
      "Epoch 2615/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2258 - val_loss: 5.5724\n",
      "Epoch 2616/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2256 - val_loss: 5.5723\n",
      "Epoch 2617/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2254 - val_loss: 5.5721\n",
      "Epoch 2618/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2253 - val_loss: 5.5720\n",
      "Epoch 2619/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2251 - val_loss: 5.5719\n",
      "Epoch 2620/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2249 - val_loss: 5.5717\n",
      "Epoch 2621/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.2247 - val_loss: 5.5716\n",
      "Epoch 2622/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2245 - val_loss: 5.5714\n",
      "Epoch 2623/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2243 - val_loss: 5.5713\n",
      "Epoch 2624/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2241 - val_loss: 5.5711\n",
      "Epoch 2625/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2240 - val_loss: 5.5710\n",
      "Epoch 2626/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2238 - val_loss: 5.5709\n",
      "Epoch 2627/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2236 - val_loss: 5.5707\n",
      "Epoch 2628/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2234 - val_loss: 5.5706\n",
      "Epoch 2629/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2232 - val_loss: 5.5704\n",
      "Epoch 2630/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2230 - val_loss: 5.5703\n",
      "Epoch 2631/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2229 - val_loss: 5.5701\n",
      "Epoch 2632/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2227 - val_loss: 5.5700\n",
      "Epoch 2633/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2225 - val_loss: 5.5699\n",
      "Epoch 2634/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2223 - val_loss: 5.5697\n",
      "Epoch 2635/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2221 - val_loss: 5.5696\n",
      "Epoch 2636/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2219 - val_loss: 5.5694\n",
      "Epoch 2637/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2217 - val_loss: 5.5693\n",
      "Epoch 2638/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2216 - val_loss: 5.5691\n",
      "Epoch 2639/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2214 - val_loss: 5.5690\n",
      "Epoch 2640/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2212 - val_loss: 5.5689\n",
      "Epoch 2641/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2210 - val_loss: 5.5687\n",
      "Epoch 2642/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2208 - val_loss: 5.5686\n",
      "Epoch 2643/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2206 - val_loss: 5.5684\n",
      "Epoch 2644/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2205 - val_loss: 5.5683\n",
      "Epoch 2645/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2203 - val_loss: 5.5681\n",
      "Epoch 2646/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2201 - val_loss: 5.5680\n",
      "Epoch 2647/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2199 - val_loss: 5.5679\n",
      "Epoch 2648/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2197 - val_loss: 5.5677\n",
      "Epoch 2649/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2195 - val_loss: 5.5676\n",
      "Epoch 2650/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2194 - val_loss: 5.5674\n",
      "Epoch 2651/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2192 - val_loss: 5.5673\n",
      "Epoch 2652/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2190 - val_loss: 5.5671\n",
      "Epoch 2653/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2188 - val_loss: 5.5670\n",
      "Epoch 2654/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2186 - val_loss: 5.5669\n",
      "Epoch 2655/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2184 - val_loss: 5.5667\n",
      "Epoch 2656/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2183 - val_loss: 5.5666\n",
      "Epoch 2657/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2181 - val_loss: 5.5664\n",
      "Epoch 2658/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2179 - val_loss: 5.5663\n",
      "Epoch 2659/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2177 - val_loss: 5.5662\n",
      "Epoch 2660/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2175 - val_loss: 5.5660\n",
      "Epoch 2661/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2173 - val_loss: 5.5659\n",
      "Epoch 2662/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2172 - val_loss: 5.5657\n",
      "Epoch 2663/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2170 - val_loss: 5.5656\n",
      "Epoch 2664/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2168 - val_loss: 5.5654\n",
      "Epoch 2665/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2166 - val_loss: 5.5653\n",
      "Epoch 2666/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2164 - val_loss: 5.5652\n",
      "Epoch 2667/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2162 - val_loss: 5.5650\n",
      "Epoch 2668/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2161 - val_loss: 5.5649\n",
      "Epoch 2669/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2159 - val_loss: 5.5647\n",
      "Epoch 2670/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2157 - val_loss: 5.5646\n",
      "Epoch 2671/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2155 - val_loss: 5.5645\n",
      "Epoch 2672/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2153 - val_loss: 5.5643\n",
      "Epoch 2673/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2151 - val_loss: 5.5642\n",
      "Epoch 2674/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2150 - val_loss: 5.5640\n",
      "Epoch 2675/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2148 - val_loss: 5.5639\n",
      "Epoch 2676/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2146 - val_loss: 5.5637\n",
      "Epoch 2677/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2144 - val_loss: 5.5636\n",
      "Epoch 2678/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2142 - val_loss: 5.5635\n",
      "Epoch 2679/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2140 - val_loss: 5.5633\n",
      "Epoch 2680/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2139 - val_loss: 5.5632\n",
      "Epoch 2681/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2137 - val_loss: 5.5630\n",
      "Epoch 2682/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2135 - val_loss: 5.5629\n",
      "Epoch 2683/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2133 - val_loss: 5.5628\n",
      "Epoch 2684/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2131 - val_loss: 5.5626\n",
      "Epoch 2685/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2130 - val_loss: 5.5625\n",
      "Epoch 2686/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2128 - val_loss: 5.5623\n",
      "Epoch 2687/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2126 - val_loss: 5.5622\n",
      "Epoch 2688/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2124 - val_loss: 5.5621\n",
      "Epoch 2689/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2122 - val_loss: 5.5619\n",
      "Epoch 2690/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2120 - val_loss: 5.5618\n",
      "Epoch 2691/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2119 - val_loss: 5.5616\n",
      "Epoch 2692/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2117 - val_loss: 5.5615\n",
      "Epoch 2693/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2115 - val_loss: 5.5614\n",
      "Epoch 2694/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2113 - val_loss: 5.5612\n",
      "Epoch 2695/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2111 - val_loss: 5.5611\n",
      "Epoch 2696/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2110 - val_loss: 5.5609\n",
      "Epoch 2697/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2108 - val_loss: 5.5608\n",
      "Epoch 2698/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2106 - val_loss: 5.5607\n",
      "Epoch 2699/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2104 - val_loss: 5.5605\n",
      "Epoch 2700/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2102 - val_loss: 5.5604\n",
      "Epoch 2701/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2100 - val_loss: 5.5602\n",
      "Epoch 2702/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2099 - val_loss: 5.5601\n",
      "Epoch 2703/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2097 - val_loss: 5.5600\n",
      "Epoch 2704/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2095 - val_loss: 5.5598\n",
      "Epoch 2705/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2093 - val_loss: 5.5597\n",
      "Epoch 2706/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2091 - val_loss: 5.5595\n",
      "Epoch 2707/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2090 - val_loss: 5.5594\n",
      "Epoch 2708/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2088 - val_loss: 5.5593\n",
      "Epoch 2709/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2086 - val_loss: 5.5591\n",
      "Epoch 2710/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2084 - val_loss: 5.5590\n",
      "Epoch 2711/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2082 - val_loss: 5.5588\n",
      "Epoch 2712/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2081 - val_loss: 5.5587\n",
      "Epoch 2713/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2079 - val_loss: 5.5586\n",
      "Epoch 2714/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2077 - val_loss: 5.5584\n",
      "Epoch 2715/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2075 - val_loss: 5.5583\n",
      "Epoch 2716/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2073 - val_loss: 5.5581\n",
      "Epoch 2717/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2072 - val_loss: 5.5580\n",
      "Epoch 2718/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2070 - val_loss: 5.5579\n",
      "Epoch 2719/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2068 - val_loss: 5.5577\n",
      "Epoch 2720/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2066 - val_loss: 5.5576\n",
      "Epoch 2721/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2064 - val_loss: 5.5574\n",
      "Epoch 2722/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2062 - val_loss: 5.5573\n",
      "Epoch 2723/5000\n",
      "39898/39898 [==============================] - 1s 19us/step - loss: 6.2061 - val_loss: 5.5572\n",
      "Epoch 2724/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2059 - val_loss: 5.5570\n",
      "Epoch 2725/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2057 - val_loss: 5.5569\n",
      "Epoch 2726/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2055 - val_loss: 5.5567\n",
      "Epoch 2727/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2053 - val_loss: 5.5566\n",
      "Epoch 2728/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2052 - val_loss: 5.5565\n",
      "Epoch 2729/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2050 - val_loss: 5.5563\n",
      "Epoch 2730/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2048 - val_loss: 5.5562\n",
      "Epoch 2731/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2046 - val_loss: 5.5560\n",
      "Epoch 2732/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2044 - val_loss: 5.5559\n",
      "Epoch 2733/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2043 - val_loss: 5.5558\n",
      "Epoch 2734/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.2041 - val_loss: 5.5556\n",
      "Epoch 2735/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2039 - val_loss: 5.5555\n",
      "Epoch 2736/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2037 - val_loss: 5.5554\n",
      "Epoch 2737/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2035 - val_loss: 5.5552\n",
      "Epoch 2738/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2034 - val_loss: 5.5551\n",
      "Epoch 2739/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2032 - val_loss: 5.5549\n",
      "Epoch 2740/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2030 - val_loss: 5.5548\n",
      "Epoch 2741/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2028 - val_loss: 5.5547\n",
      "Epoch 2742/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2026 - val_loss: 5.5545\n",
      "Epoch 2743/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2025 - val_loss: 5.5544\n",
      "Epoch 2744/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2023 - val_loss: 5.5542\n",
      "Epoch 2745/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2021 - val_loss: 5.5541\n",
      "Epoch 2746/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2019 - val_loss: 5.5540\n",
      "Epoch 2747/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2017 - val_loss: 5.5538\n",
      "Epoch 2748/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 6.2016 - val_loss: 5.5537\n",
      "Epoch 2749/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2014 - val_loss: 5.5536\n",
      "Epoch 2750/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2012 - val_loss: 5.5534\n",
      "Epoch 2751/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2010 - val_loss: 5.5533\n",
      "Epoch 2752/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2009 - val_loss: 5.5531\n",
      "Epoch 2753/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.2007 - val_loss: 5.5530\n",
      "Epoch 2754/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2005 - val_loss: 5.5529\n",
      "Epoch 2755/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2003 - val_loss: 5.5527\n",
      "Epoch 2756/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2001 - val_loss: 5.5526\n",
      "Epoch 2757/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.2000 - val_loss: 5.5525\n",
      "Epoch 2758/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1998 - val_loss: 5.5523\n",
      "Epoch 2759/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1996 - val_loss: 5.5522\n",
      "Epoch 2760/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1994 - val_loss: 5.5520\n",
      "Epoch 2761/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1992 - val_loss: 5.5519\n",
      "Epoch 2762/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1991 - val_loss: 5.5518\n",
      "Epoch 2763/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1989 - val_loss: 5.5516\n",
      "Epoch 2764/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1987 - val_loss: 5.5515\n",
      "Epoch 2765/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1985 - val_loss: 5.5514\n",
      "Epoch 2766/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1983 - val_loss: 5.5512\n",
      "Epoch 2767/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1982 - val_loss: 5.5511\n",
      "Epoch 2768/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1980 - val_loss: 5.5509\n",
      "Epoch 2769/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1978 - val_loss: 5.5508\n",
      "Epoch 2770/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.1976 - val_loss: 5.5507\n",
      "Epoch 2771/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1975 - val_loss: 5.5505\n",
      "Epoch 2772/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1973 - val_loss: 5.5504\n",
      "Epoch 2773/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1971 - val_loss: 5.5503\n",
      "Epoch 2774/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1969 - val_loss: 5.5501\n",
      "Epoch 2775/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1967 - val_loss: 5.5500\n",
      "Epoch 2776/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1966 - val_loss: 5.5498\n",
      "Epoch 2777/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1964 - val_loss: 5.5497\n",
      "Epoch 2778/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1962 - val_loss: 5.5496\n",
      "Epoch 2779/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1960 - val_loss: 5.5494\n",
      "Epoch 2780/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1959 - val_loss: 5.5493\n",
      "Epoch 2781/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1957 - val_loss: 5.5492\n",
      "Epoch 2782/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1955 - val_loss: 5.5490\n",
      "Epoch 2783/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1953 - val_loss: 5.5489\n",
      "Epoch 2784/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1951 - val_loss: 5.5487\n",
      "Epoch 2785/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1950 - val_loss: 5.5486\n",
      "Epoch 2786/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1948 - val_loss: 5.5485\n",
      "Epoch 2787/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1946 - val_loss: 5.5483\n",
      "Epoch 2788/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1944 - val_loss: 5.5482\n",
      "Epoch 2789/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1943 - val_loss: 5.5481\n",
      "Epoch 2790/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1941 - val_loss: 5.5479\n",
      "Epoch 2791/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1939 - val_loss: 5.5478\n",
      "Epoch 2792/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1937 - val_loss: 5.5477\n",
      "Epoch 2793/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1935 - val_loss: 5.5475\n",
      "Epoch 2794/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1934 - val_loss: 5.5474\n",
      "Epoch 2795/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1932 - val_loss: 5.5472\n",
      "Epoch 2796/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1930 - val_loss: 5.5471\n",
      "Epoch 2797/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1928 - val_loss: 5.5470\n",
      "Epoch 2798/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1927 - val_loss: 5.5468\n",
      "Epoch 2799/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1925 - val_loss: 5.5467\n",
      "Epoch 2800/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1923 - val_loss: 5.5466\n",
      "Epoch 2801/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1921 - val_loss: 5.5464\n",
      "Epoch 2802/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1919 - val_loss: 5.5463\n",
      "Epoch 2803/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1918 - val_loss: 5.5462\n",
      "Epoch 2804/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1916 - val_loss: 5.5460\n",
      "Epoch 2805/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1914 - val_loss: 5.5459\n",
      "Epoch 2806/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1912 - val_loss: 5.5457\n",
      "Epoch 2807/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1911 - val_loss: 5.5456\n",
      "Epoch 2808/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1909 - val_loss: 5.5455\n",
      "Epoch 2809/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1907 - val_loss: 5.5453\n",
      "Epoch 2810/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1905 - val_loss: 5.5452\n",
      "Epoch 2811/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1904 - val_loss: 5.5451\n",
      "Epoch 2812/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1902 - val_loss: 5.5449\n",
      "Epoch 2813/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1900 - val_loss: 5.5448\n",
      "Epoch 2814/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.1898 - val_loss: 5.5447\n",
      "Epoch 2815/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1896 - val_loss: 5.5445\n",
      "Epoch 2816/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1895 - val_loss: 5.5444\n",
      "Epoch 2817/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1893 - val_loss: 5.5443\n",
      "Epoch 2818/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1891 - val_loss: 5.5441\n",
      "Epoch 2819/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1889 - val_loss: 5.5440\n",
      "Epoch 2820/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1888 - val_loss: 5.5439\n",
      "Epoch 2821/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1886 - val_loss: 5.5437\n",
      "Epoch 2822/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1884 - val_loss: 5.5436\n",
      "Epoch 2823/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1882 - val_loss: 5.5434\n",
      "Epoch 2824/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1881 - val_loss: 5.5433\n",
      "Epoch 2825/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1879 - val_loss: 5.5432\n",
      "Epoch 2826/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1877 - val_loss: 5.5430\n",
      "Epoch 2827/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1875 - val_loss: 5.5429\n",
      "Epoch 2828/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1874 - val_loss: 5.5428\n",
      "Epoch 2829/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1872 - val_loss: 5.5426\n",
      "Epoch 2830/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1870 - val_loss: 5.5425\n",
      "Epoch 2831/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1868 - val_loss: 5.5424\n",
      "Epoch 2832/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1867 - val_loss: 5.5422\n",
      "Epoch 2833/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1865 - val_loss: 5.5421\n",
      "Epoch 2834/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1863 - val_loss: 5.5420\n",
      "Epoch 2835/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1861 - val_loss: 5.5418\n",
      "Epoch 2836/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1859 - val_loss: 5.5417\n",
      "Epoch 2837/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1858 - val_loss: 5.5416\n",
      "Epoch 2838/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1856 - val_loss: 5.5414\n",
      "Epoch 2839/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1854 - val_loss: 5.5413\n",
      "Epoch 2840/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1852 - val_loss: 5.5412\n",
      "Epoch 2841/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1851 - val_loss: 5.5410\n",
      "Epoch 2842/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1849 - val_loss: 5.5409\n",
      "Epoch 2843/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1847 - val_loss: 5.5407\n",
      "Epoch 2844/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1845 - val_loss: 5.5406\n",
      "Epoch 2845/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1844 - val_loss: 5.5405\n",
      "Epoch 2846/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1842 - val_loss: 5.5403\n",
      "Epoch 2847/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1840 - val_loss: 5.5402\n",
      "Epoch 2848/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1838 - val_loss: 5.5401\n",
      "Epoch 2849/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1837 - val_loss: 5.5399\n",
      "Epoch 2850/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1835 - val_loss: 5.5398\n",
      "Epoch 2851/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1833 - val_loss: 5.5397\n",
      "Epoch 2852/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1831 - val_loss: 5.5395\n",
      "Epoch 2853/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1830 - val_loss: 5.5394\n",
      "Epoch 2854/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1828 - val_loss: 5.5393\n",
      "Epoch 2855/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.1826 - val_loss: 5.5391\n",
      "Epoch 2856/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 6.1824 - val_loss: 5.5390\n",
      "Epoch 2857/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1823 - val_loss: 5.5389\n",
      "Epoch 2858/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1821 - val_loss: 5.5387\n",
      "Epoch 2859/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1819 - val_loss: 5.5386\n",
      "Epoch 2860/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1817 - val_loss: 5.5385\n",
      "Epoch 2861/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1816 - val_loss: 5.5383\n",
      "Epoch 2862/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1814 - val_loss: 5.5382\n",
      "Epoch 2863/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1812 - val_loss: 5.5381\n",
      "Epoch 2864/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1810 - val_loss: 5.5379\n",
      "Epoch 2865/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1809 - val_loss: 5.5378\n",
      "Epoch 2866/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1807 - val_loss: 5.5377\n",
      "Epoch 2867/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1805 - val_loss: 5.5375\n",
      "Epoch 2868/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.1803 - val_loss: 5.5374\n",
      "Epoch 2869/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1802 - val_loss: 5.5373\n",
      "Epoch 2870/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1800 - val_loss: 5.5371\n",
      "Epoch 2871/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1798 - val_loss: 5.5370\n",
      "Epoch 2872/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1796 - val_loss: 5.5369\n",
      "Epoch 2873/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1795 - val_loss: 5.5367\n",
      "Epoch 2874/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1793 - val_loss: 5.5366\n",
      "Epoch 2875/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1791 - val_loss: 5.5365\n",
      "Epoch 2876/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1790 - val_loss: 5.5363\n",
      "Epoch 2877/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1788 - val_loss: 5.5362\n",
      "Epoch 2878/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1786 - val_loss: 5.5361\n",
      "Epoch 2879/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1784 - val_loss: 5.5359\n",
      "Epoch 2880/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1783 - val_loss: 5.5358\n",
      "Epoch 2881/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1781 - val_loss: 5.5357\n",
      "Epoch 2882/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1779 - val_loss: 5.5355\n",
      "Epoch 2883/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1777 - val_loss: 5.5354\n",
      "Epoch 2884/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1776 - val_loss: 5.5353\n",
      "Epoch 2885/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1774 - val_loss: 5.5351\n",
      "Epoch 2886/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1772 - val_loss: 5.5350\n",
      "Epoch 2887/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1770 - val_loss: 5.5349\n",
      "Epoch 2888/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1769 - val_loss: 5.5347\n",
      "Epoch 2889/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1767 - val_loss: 5.5346\n",
      "Epoch 2890/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1765 - val_loss: 5.5345\n",
      "Epoch 2891/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1763 - val_loss: 5.5343\n",
      "Epoch 2892/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1762 - val_loss: 5.5342\n",
      "Epoch 2893/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1760 - val_loss: 5.5341\n",
      "Epoch 2894/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1758 - val_loss: 5.5339\n",
      "Epoch 2895/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1756 - val_loss: 5.5338\n",
      "Epoch 2896/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1755 - val_loss: 5.5337\n",
      "Epoch 2897/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1753 - val_loss: 5.5335\n",
      "Epoch 2898/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1751 - val_loss: 5.5334\n",
      "Epoch 2899/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1750 - val_loss: 5.5333\n",
      "Epoch 2900/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1748 - val_loss: 5.5331\n",
      "Epoch 2901/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1746 - val_loss: 5.5330\n",
      "Epoch 2902/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1744 - val_loss: 5.5329\n",
      "Epoch 2903/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1743 - val_loss: 5.5327\n",
      "Epoch 2904/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1741 - val_loss: 5.5326\n",
      "Epoch 2905/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1739 - val_loss: 5.5325\n",
      "Epoch 2906/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1737 - val_loss: 5.5324\n",
      "Epoch 2907/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1736 - val_loss: 5.5322\n",
      "Epoch 2908/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1734 - val_loss: 5.5321\n",
      "Epoch 2909/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1732 - val_loss: 5.5320\n",
      "Epoch 2910/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1731 - val_loss: 5.5318\n",
      "Epoch 2911/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1729 - val_loss: 5.5317\n",
      "Epoch 2912/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1727 - val_loss: 5.5316\n",
      "Epoch 2913/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1725 - val_loss: 5.5314\n",
      "Epoch 2914/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1724 - val_loss: 5.5313\n",
      "Epoch 2915/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1722 - val_loss: 5.5312\n",
      "Epoch 2916/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1720 - val_loss: 5.5310\n",
      "Epoch 2917/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1718 - val_loss: 5.5309\n",
      "Epoch 2918/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1717 - val_loss: 5.5308\n",
      "Epoch 2919/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1715 - val_loss: 5.5306\n",
      "Epoch 2920/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1713 - val_loss: 5.5305\n",
      "Epoch 2921/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1712 - val_loss: 5.5304\n",
      "Epoch 2922/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1710 - val_loss: 5.5302\n",
      "Epoch 2923/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1708 - val_loss: 5.5301\n",
      "Epoch 2924/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1706 - val_loss: 5.5300\n",
      "Epoch 2925/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1705 - val_loss: 5.5298\n",
      "Epoch 2926/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1703 - val_loss: 5.5297\n",
      "Epoch 2927/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1701 - val_loss: 5.5296\n",
      "Epoch 2928/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1699 - val_loss: 5.5295\n",
      "Epoch 2929/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1698 - val_loss: 5.5293\n",
      "Epoch 2930/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1696 - val_loss: 5.5292\n",
      "Epoch 2931/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1694 - val_loss: 5.5291\n",
      "Epoch 2932/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1693 - val_loss: 5.5289\n",
      "Epoch 2933/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1691 - val_loss: 5.5288\n",
      "Epoch 2934/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1689 - val_loss: 5.5287\n",
      "Epoch 2935/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1687 - val_loss: 5.5285\n",
      "Epoch 2936/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1686 - val_loss: 5.5284\n",
      "Epoch 2937/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1684 - val_loss: 5.5283\n",
      "Epoch 2938/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1682 - val_loss: 5.5281\n",
      "Epoch 2939/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1681 - val_loss: 5.5280\n",
      "Epoch 2940/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1679 - val_loss: 5.5279\n",
      "Epoch 2941/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1677 - val_loss: 5.5277\n",
      "Epoch 2942/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1675 - val_loss: 5.5276\n",
      "Epoch 2943/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1674 - val_loss: 5.5275\n",
      "Epoch 2944/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1672 - val_loss: 5.5274\n",
      "Epoch 2945/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1670 - val_loss: 5.5272\n",
      "Epoch 2946/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1669 - val_loss: 5.5271\n",
      "Epoch 2947/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1667 - val_loss: 5.5270\n",
      "Epoch 2948/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1665 - val_loss: 5.5268\n",
      "Epoch 2949/5000\n",
      "39898/39898 [==============================] - 1s 19us/step - loss: 6.1663 - val_loss: 5.5267\n",
      "Epoch 2950/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1662 - val_loss: 5.5266\n",
      "Epoch 2951/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1660 - val_loss: 5.5264\n",
      "Epoch 2952/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1658 - val_loss: 5.5263\n",
      "Epoch 2953/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1657 - val_loss: 5.5262\n",
      "Epoch 2954/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1655 - val_loss: 5.5261\n",
      "Epoch 2955/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1653 - val_loss: 5.5259\n",
      "Epoch 2956/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1651 - val_loss: 5.5258\n",
      "Epoch 2957/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1650 - val_loss: 5.5257\n",
      "Epoch 2958/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1648 - val_loss: 5.5255\n",
      "Epoch 2959/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1646 - val_loss: 5.5254\n",
      "Epoch 2960/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1645 - val_loss: 5.5253\n",
      "Epoch 2961/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1643 - val_loss: 5.5251\n",
      "Epoch 2962/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1641 - val_loss: 5.5250\n",
      "Epoch 2963/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1639 - val_loss: 5.5249\n",
      "Epoch 2964/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1638 - val_loss: 5.5247\n",
      "Epoch 2965/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1636 - val_loss: 5.5246\n",
      "Epoch 2966/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1634 - val_loss: 5.5245\n",
      "Epoch 2967/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1633 - val_loss: 5.5244\n",
      "Epoch 2968/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1631 - val_loss: 5.5242\n",
      "Epoch 2969/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1629 - val_loss: 5.5241\n",
      "Epoch 2970/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1627 - val_loss: 5.5240\n",
      "Epoch 2971/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1626 - val_loss: 5.5238\n",
      "Epoch 2972/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1624 - val_loss: 5.5237\n",
      "Epoch 2973/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1622 - val_loss: 5.5236\n",
      "Epoch 2974/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1621 - val_loss: 5.5234\n",
      "Epoch 2975/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1619 - val_loss: 5.5233\n",
      "Epoch 2976/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1617 - val_loss: 5.5232\n",
      "Epoch 2977/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1616 - val_loss: 5.5231\n",
      "Epoch 2978/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1614 - val_loss: 5.5229\n",
      "Epoch 2979/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1612 - val_loss: 5.5228\n",
      "Epoch 2980/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1610 - val_loss: 5.5227\n",
      "Epoch 2981/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1609 - val_loss: 5.5225\n",
      "Epoch 2982/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1607 - val_loss: 5.5224\n",
      "Epoch 2983/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1605 - val_loss: 5.5223\n",
      "Epoch 2984/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1604 - val_loss: 5.5222\n",
      "Epoch 2985/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1602 - val_loss: 5.5220\n",
      "Epoch 2986/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1600 - val_loss: 5.5219\n",
      "Epoch 2987/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1599 - val_loss: 5.5218\n",
      "Epoch 2988/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1597 - val_loss: 5.5216\n",
      "Epoch 2989/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.1595 - val_loss: 5.5215\n",
      "Epoch 2990/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1593 - val_loss: 5.5214\n",
      "Epoch 2991/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1592 - val_loss: 5.5212\n",
      "Epoch 2992/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1590 - val_loss: 5.5211\n",
      "Epoch 2993/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1588 - val_loss: 5.5210\n",
      "Epoch 2994/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1587 - val_loss: 5.5209\n",
      "Epoch 2995/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1585 - val_loss: 5.5207\n",
      "Epoch 2996/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1583 - val_loss: 5.5206\n",
      "Epoch 2997/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1582 - val_loss: 5.5205\n",
      "Epoch 2998/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1580 - val_loss: 5.5203\n",
      "Epoch 2999/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1578 - val_loss: 5.5202\n",
      "Epoch 3000/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.1576 - val_loss: 5.5201\n",
      "Epoch 3001/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1575 - val_loss: 5.5200\n",
      "Epoch 3002/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1573 - val_loss: 5.5198\n",
      "Epoch 3003/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1571 - val_loss: 5.5197\n",
      "Epoch 3004/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1570 - val_loss: 5.5196\n",
      "Epoch 3005/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1568 - val_loss: 5.5194\n",
      "Epoch 3006/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1566 - val_loss: 5.5193\n",
      "Epoch 3007/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1565 - val_loss: 5.5192\n",
      "Epoch 3008/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1563 - val_loss: 5.5191\n",
      "Epoch 3009/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1561 - val_loss: 5.5189\n",
      "Epoch 3010/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1560 - val_loss: 5.5188\n",
      "Epoch 3011/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1558 - val_loss: 5.5187\n",
      "Epoch 3012/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1556 - val_loss: 5.5185\n",
      "Epoch 3013/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1554 - val_loss: 5.5184\n",
      "Epoch 3014/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1553 - val_loss: 5.5183\n",
      "Epoch 3015/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1551 - val_loss: 5.5182\n",
      "Epoch 3016/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1549 - val_loss: 5.5180\n",
      "Epoch 3017/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1548 - val_loss: 5.5179\n",
      "Epoch 3018/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.1546 - val_loss: 5.5178\n",
      "Epoch 3019/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1544 - val_loss: 5.5176\n",
      "Epoch 3020/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1543 - val_loss: 5.5175\n",
      "Epoch 3021/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1541 - val_loss: 5.5174\n",
      "Epoch 3022/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1539 - val_loss: 5.5173\n",
      "Epoch 3023/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1538 - val_loss: 5.5171\n",
      "Epoch 3024/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1536 - val_loss: 5.5170\n",
      "Epoch 3025/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1534 - val_loss: 5.5169\n",
      "Epoch 3026/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1532 - val_loss: 5.5167\n",
      "Epoch 3027/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1531 - val_loss: 5.5166\n",
      "Epoch 3028/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1529 - val_loss: 5.5165\n",
      "Epoch 3029/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1527 - val_loss: 5.5164\n",
      "Epoch 3030/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1526 - val_loss: 5.5162\n",
      "Epoch 3031/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1524 - val_loss: 5.5161\n",
      "Epoch 3032/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1522 - val_loss: 5.5160\n",
      "Epoch 3033/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1521 - val_loss: 5.5159\n",
      "Epoch 3034/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1519 - val_loss: 5.5157\n",
      "Epoch 3035/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1517 - val_loss: 5.5156\n",
      "Epoch 3036/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1516 - val_loss: 5.5155\n",
      "Epoch 3037/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1514 - val_loss: 5.5153\n",
      "Epoch 3038/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1512 - val_loss: 5.5152\n",
      "Epoch 3039/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1511 - val_loss: 5.5151\n",
      "Epoch 3040/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1509 - val_loss: 5.5150\n",
      "Epoch 3041/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1507 - val_loss: 5.5148\n",
      "Epoch 3042/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1506 - val_loss: 5.5147\n",
      "Epoch 3043/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1504 - val_loss: 5.5146\n",
      "Epoch 3044/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1502 - val_loss: 5.5144\n",
      "Epoch 3045/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1501 - val_loss: 5.5143\n",
      "Epoch 3046/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1499 - val_loss: 5.5142\n",
      "Epoch 3047/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1497 - val_loss: 5.5141\n",
      "Epoch 3048/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1495 - val_loss: 5.5139\n",
      "Epoch 3049/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1494 - val_loss: 5.5138\n",
      "Epoch 3050/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1492 - val_loss: 5.5137\n",
      "Epoch 3051/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1490 - val_loss: 5.5136\n",
      "Epoch 3052/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1489 - val_loss: 5.5134\n",
      "Epoch 3053/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1487 - val_loss: 5.5133\n",
      "Epoch 3054/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1485 - val_loss: 5.5132\n",
      "Epoch 3055/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1484 - val_loss: 5.5131\n",
      "Epoch 3056/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1482 - val_loss: 5.5129\n",
      "Epoch 3057/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1480 - val_loss: 5.5128\n",
      "Epoch 3058/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1479 - val_loss: 5.5127\n",
      "Epoch 3059/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1477 - val_loss: 5.5125\n",
      "Epoch 3060/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1475 - val_loss: 5.5124\n",
      "Epoch 3061/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1474 - val_loss: 5.5123\n",
      "Epoch 3062/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1472 - val_loss: 5.5122\n",
      "Epoch 3063/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1470 - val_loss: 5.5120\n",
      "Epoch 3064/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1469 - val_loss: 5.5119\n",
      "Epoch 3065/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1467 - val_loss: 5.5118\n",
      "Epoch 3066/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1465 - val_loss: 5.5117\n",
      "Epoch 3067/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1464 - val_loss: 5.5115\n",
      "Epoch 3068/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1462 - val_loss: 5.5114\n",
      "Epoch 3069/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1460 - val_loss: 5.5113\n",
      "Epoch 3070/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1459 - val_loss: 5.5111\n",
      "Epoch 3071/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1457 - val_loss: 5.5110\n",
      "Epoch 3072/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1455 - val_loss: 5.5109\n",
      "Epoch 3073/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1454 - val_loss: 5.5108\n",
      "Epoch 3074/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1452 - val_loss: 5.5106\n",
      "Epoch 3075/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1450 - val_loss: 5.5105\n",
      "Epoch 3076/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1449 - val_loss: 5.5104\n",
      "Epoch 3077/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1447 - val_loss: 5.5103\n",
      "Epoch 3078/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1445 - val_loss: 5.5101\n",
      "Epoch 3079/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1444 - val_loss: 5.5100\n",
      "Epoch 3080/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1442 - val_loss: 5.5099\n",
      "Epoch 3081/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1440 - val_loss: 5.5098\n",
      "Epoch 3082/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1439 - val_loss: 5.5096\n",
      "Epoch 3083/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1437 - val_loss: 5.5095\n",
      "Epoch 3084/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1435 - val_loss: 5.5094\n",
      "Epoch 3085/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1434 - val_loss: 5.5093\n",
      "Epoch 3086/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1432 - val_loss: 5.5091\n",
      "Epoch 3087/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1430 - val_loss: 5.5090\n",
      "Epoch 3088/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1429 - val_loss: 5.5089\n",
      "Epoch 3089/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1427 - val_loss: 5.5088\n",
      "Epoch 3090/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1425 - val_loss: 5.5086\n",
      "Epoch 3091/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1424 - val_loss: 5.5085\n",
      "Epoch 3092/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1422 - val_loss: 5.5084\n",
      "Epoch 3093/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1420 - val_loss: 5.5082\n",
      "Epoch 3094/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1419 - val_loss: 5.5081\n",
      "Epoch 3095/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1417 - val_loss: 5.5080\n",
      "Epoch 3096/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1415 - val_loss: 5.5079\n",
      "Epoch 3097/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1414 - val_loss: 5.5077\n",
      "Epoch 3098/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1412 - val_loss: 5.5076\n",
      "Epoch 3099/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1410 - val_loss: 5.5075\n",
      "Epoch 3100/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1409 - val_loss: 5.5074\n",
      "Epoch 3101/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1407 - val_loss: 5.5072\n",
      "Epoch 3102/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1405 - val_loss: 5.5071\n",
      "Epoch 3103/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1404 - val_loss: 5.5070\n",
      "Epoch 3104/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1402 - val_loss: 5.5069\n",
      "Epoch 3105/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1400 - val_loss: 5.5067\n",
      "Epoch 3106/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1399 - val_loss: 5.5066\n",
      "Epoch 3107/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1397 - val_loss: 5.5065\n",
      "Epoch 3108/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1395 - val_loss: 5.5064\n",
      "Epoch 3109/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1394 - val_loss: 5.5062\n",
      "Epoch 3110/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1392 - val_loss: 5.5061\n",
      "Epoch 3111/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1390 - val_loss: 5.5060\n",
      "Epoch 3112/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1389 - val_loss: 5.5059\n",
      "Epoch 3113/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1387 - val_loss: 5.5057\n",
      "Epoch 3114/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1385 - val_loss: 5.5056\n",
      "Epoch 3115/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1384 - val_loss: 5.5055\n",
      "Epoch 3116/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1382 - val_loss: 5.5054\n",
      "Epoch 3117/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1380 - val_loss: 5.5052\n",
      "Epoch 3118/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1379 - val_loss: 5.5051\n",
      "Epoch 3119/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1377 - val_loss: 5.5050\n",
      "Epoch 3120/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1376 - val_loss: 5.5049\n",
      "Epoch 3121/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 6.1374 - val_loss: 5.5047\n",
      "Epoch 3122/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1372 - val_loss: 5.5046\n",
      "Epoch 3123/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1371 - val_loss: 5.5045\n",
      "Epoch 3124/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1369 - val_loss: 5.5044\n",
      "Epoch 3125/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1367 - val_loss: 5.5042\n",
      "Epoch 3126/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1366 - val_loss: 5.5041\n",
      "Epoch 3127/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1364 - val_loss: 5.5040\n",
      "Epoch 3128/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.1362 - val_loss: 5.5039\n",
      "Epoch 3129/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1361 - val_loss: 5.5037\n",
      "Epoch 3130/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1359 - val_loss: 5.5036\n",
      "Epoch 3131/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1357 - val_loss: 5.5035\n",
      "Epoch 3132/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1356 - val_loss: 5.5034\n",
      "Epoch 3133/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1354 - val_loss: 5.5032\n",
      "Epoch 3134/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1352 - val_loss: 5.5031\n",
      "Epoch 3135/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1351 - val_loss: 5.5030\n",
      "Epoch 3136/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1349 - val_loss: 5.5029\n",
      "Epoch 3137/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1347 - val_loss: 5.5027\n",
      "Epoch 3138/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1346 - val_loss: 5.5026\n",
      "Epoch 3139/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1344 - val_loss: 5.5025\n",
      "Epoch 3140/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1343 - val_loss: 5.5024\n",
      "Epoch 3141/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1341 - val_loss: 5.5022\n",
      "Epoch 3142/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1339 - val_loss: 5.5021\n",
      "Epoch 3143/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1338 - val_loss: 5.5020\n",
      "Epoch 3144/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1336 - val_loss: 5.5019\n",
      "Epoch 3145/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1334 - val_loss: 5.5018\n",
      "Epoch 3146/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1333 - val_loss: 5.5016\n",
      "Epoch 3147/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1331 - val_loss: 5.5015\n",
      "Epoch 3148/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1329 - val_loss: 5.5014\n",
      "Epoch 3149/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1328 - val_loss: 5.5013\n",
      "Epoch 3150/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1326 - val_loss: 5.5011\n",
      "Epoch 3151/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1324 - val_loss: 5.5010\n",
      "Epoch 3152/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1323 - val_loss: 5.5009\n",
      "Epoch 3153/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1321 - val_loss: 5.5008\n",
      "Epoch 3154/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1319 - val_loss: 5.5006\n",
      "Epoch 3155/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1318 - val_loss: 5.5005\n",
      "Epoch 3156/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1316 - val_loss: 5.5004\n",
      "Epoch 3157/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1315 - val_loss: 5.5003\n",
      "Epoch 3158/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1313 - val_loss: 5.5001\n",
      "Epoch 3159/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1311 - val_loss: 5.5000\n",
      "Epoch 3160/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1310 - val_loss: 5.4999\n",
      "Epoch 3161/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1308 - val_loss: 5.4998\n",
      "Epoch 3162/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1306 - val_loss: 5.4996\n",
      "Epoch 3163/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1305 - val_loss: 5.4995\n",
      "Epoch 3164/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1303 - val_loss: 5.4994\n",
      "Epoch 3165/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1301 - val_loss: 5.4993\n",
      "Epoch 3166/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1300 - val_loss: 5.4992\n",
      "Epoch 3167/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1298 - val_loss: 5.4990\n",
      "Epoch 3168/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1297 - val_loss: 5.4989\n",
      "Epoch 3169/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1295 - val_loss: 5.4988\n",
      "Epoch 3170/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1293 - val_loss: 5.4987\n",
      "Epoch 3171/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1292 - val_loss: 5.4985\n",
      "Epoch 3172/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1290 - val_loss: 5.4984\n",
      "Epoch 3173/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1288 - val_loss: 5.4983\n",
      "Epoch 3174/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1287 - val_loss: 5.4982\n",
      "Epoch 3175/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1285 - val_loss: 5.4980\n",
      "Epoch 3176/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1283 - val_loss: 5.4979\n",
      "Epoch 3177/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1282 - val_loss: 5.4978\n",
      "Epoch 3178/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1280 - val_loss: 5.4977\n",
      "Epoch 3179/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1279 - val_loss: 5.4976\n",
      "Epoch 3180/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1277 - val_loss: 5.4974\n",
      "Epoch 3181/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1275 - val_loss: 5.4973\n",
      "Epoch 3182/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1274 - val_loss: 5.4972\n",
      "Epoch 3183/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1272 - val_loss: 5.4971\n",
      "Epoch 3184/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1270 - val_loss: 5.4969\n",
      "Epoch 3185/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1269 - val_loss: 5.4968\n",
      "Epoch 3186/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1267 - val_loss: 5.4967\n",
      "Epoch 3187/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1265 - val_loss: 5.4966\n",
      "Epoch 3188/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1264 - val_loss: 5.4964\n",
      "Epoch 3189/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1262 - val_loss: 5.4963\n",
      "Epoch 3190/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1261 - val_loss: 5.4962\n",
      "Epoch 3191/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1259 - val_loss: 5.4961\n",
      "Epoch 3192/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1257 - val_loss: 5.4960\n",
      "Epoch 3193/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1256 - val_loss: 5.4958\n",
      "Epoch 3194/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1254 - val_loss: 5.4957\n",
      "Epoch 3195/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1252 - val_loss: 5.4956\n",
      "Epoch 3196/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1251 - val_loss: 5.4955\n",
      "Epoch 3197/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1249 - val_loss: 5.4953\n",
      "Epoch 3198/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1248 - val_loss: 5.4952\n",
      "Epoch 3199/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1246 - val_loss: 5.4951\n",
      "Epoch 3200/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1244 - val_loss: 5.4950\n",
      "Epoch 3201/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1243 - val_loss: 5.4949\n",
      "Epoch 3202/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1241 - val_loss: 5.4947\n",
      "Epoch 3203/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1239 - val_loss: 5.4946\n",
      "Epoch 3204/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1238 - val_loss: 5.4945\n",
      "Epoch 3205/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1236 - val_loss: 5.4944\n",
      "Epoch 3206/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1235 - val_loss: 5.4942\n",
      "Epoch 3207/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1233 - val_loss: 5.4941\n",
      "Epoch 3208/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1231 - val_loss: 5.4940\n",
      "Epoch 3209/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1230 - val_loss: 5.4939\n",
      "Epoch 3210/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1228 - val_loss: 5.4938\n",
      "Epoch 3211/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1226 - val_loss: 5.4936\n",
      "Epoch 3212/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1225 - val_loss: 5.4935\n",
      "Epoch 3213/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1223 - val_loss: 5.4934\n",
      "Epoch 3214/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1222 - val_loss: 5.4933\n",
      "Epoch 3215/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1220 - val_loss: 5.4931\n",
      "Epoch 3216/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1218 - val_loss: 5.4930\n",
      "Epoch 3217/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1217 - val_loss: 5.4929\n",
      "Epoch 3218/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1215 - val_loss: 5.4928\n",
      "Epoch 3219/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1213 - val_loss: 5.4927\n",
      "Epoch 3220/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1212 - val_loss: 5.4925\n",
      "Epoch 3221/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1210 - val_loss: 5.4924\n",
      "Epoch 3222/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1209 - val_loss: 5.4923\n",
      "Epoch 3223/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1207 - val_loss: 5.4922\n",
      "Epoch 3224/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1205 - val_loss: 5.4920\n",
      "Epoch 3225/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1204 - val_loss: 5.4919\n",
      "Epoch 3226/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1202 - val_loss: 5.4918\n",
      "Epoch 3227/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1200 - val_loss: 5.4917\n",
      "Epoch 3228/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1199 - val_loss: 5.4916\n",
      "Epoch 3229/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1197 - val_loss: 5.4914\n",
      "Epoch 3230/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1196 - val_loss: 5.4913\n",
      "Epoch 3231/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1194 - val_loss: 5.4912\n",
      "Epoch 3232/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1192 - val_loss: 5.4911\n",
      "Epoch 3233/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1191 - val_loss: 5.4909\n",
      "Epoch 3234/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1189 - val_loss: 5.4908\n",
      "Epoch 3235/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1187 - val_loss: 5.4907\n",
      "Epoch 3236/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1186 - val_loss: 5.4906\n",
      "Epoch 3237/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1184 - val_loss: 5.4905\n",
      "Epoch 3238/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1183 - val_loss: 5.4903\n",
      "Epoch 3239/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1181 - val_loss: 5.4902\n",
      "Epoch 3240/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1179 - val_loss: 5.4901\n",
      "Epoch 3241/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1178 - val_loss: 5.4900\n",
      "Epoch 3242/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1176 - val_loss: 5.4899\n",
      "Epoch 3243/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1175 - val_loss: 5.4897\n",
      "Epoch 3244/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1173 - val_loss: 5.4896\n",
      "Epoch 3245/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1171 - val_loss: 5.4895\n",
      "Epoch 3246/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1170 - val_loss: 5.4894\n",
      "Epoch 3247/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1168 - val_loss: 5.4893\n",
      "Epoch 3248/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1166 - val_loss: 5.4891\n",
      "Epoch 3249/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1165 - val_loss: 5.4890\n",
      "Epoch 3250/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1163 - val_loss: 5.4889\n",
      "Epoch 3251/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1162 - val_loss: 5.4888\n",
      "Epoch 3252/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1160 - val_loss: 5.4886\n",
      "Epoch 3253/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.1158 - val_loss: 5.4885\n",
      "Epoch 3254/5000\n",
      "39898/39898 [==============================] - 1s 19us/step - loss: 6.1157 - val_loss: 5.4884\n",
      "Epoch 3255/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1155 - val_loss: 5.4883\n",
      "Epoch 3256/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1154 - val_loss: 5.4882\n",
      "Epoch 3257/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.1152 - val_loss: 5.4880\n",
      "Epoch 3258/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.1150 - val_loss: 5.4879\n",
      "Epoch 3259/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1149 - val_loss: 5.4878\n",
      "Epoch 3260/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.1147 - val_loss: 5.4877\n",
      "Epoch 3261/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1146 - val_loss: 5.4876\n",
      "Epoch 3262/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1144 - val_loss: 5.4874\n",
      "Epoch 3263/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1142 - val_loss: 5.4873\n",
      "Epoch 3264/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1141 - val_loss: 5.4872\n",
      "Epoch 3265/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1139 - val_loss: 5.4871\n",
      "Epoch 3266/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1138 - val_loss: 5.4870\n",
      "Epoch 3267/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1136 - val_loss: 5.4868\n",
      "Epoch 3268/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1134 - val_loss: 5.4867\n",
      "Epoch 3269/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1133 - val_loss: 5.4866\n",
      "Epoch 3270/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1131 - val_loss: 5.4865\n",
      "Epoch 3271/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1129 - val_loss: 5.4864\n",
      "Epoch 3272/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1128 - val_loss: 5.4862\n",
      "Epoch 3273/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1126 - val_loss: 5.4861\n",
      "Epoch 3274/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1125 - val_loss: 5.4860\n",
      "Epoch 3275/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1123 - val_loss: 5.4859\n",
      "Epoch 3276/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1121 - val_loss: 5.4858\n",
      "Epoch 3277/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1120 - val_loss: 5.4856\n",
      "Epoch 3278/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1118 - val_loss: 5.4855\n",
      "Epoch 3279/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1117 - val_loss: 5.4854\n",
      "Epoch 3280/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1115 - val_loss: 5.4853\n",
      "Epoch 3281/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1113 - val_loss: 5.4852\n",
      "Epoch 3282/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1112 - val_loss: 5.4850\n",
      "Epoch 3283/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1110 - val_loss: 5.4849\n",
      "Epoch 3284/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1109 - val_loss: 5.4848\n",
      "Epoch 3285/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1107 - val_loss: 5.4847\n",
      "Epoch 3286/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1105 - val_loss: 5.4846\n",
      "Epoch 3287/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1104 - val_loss: 5.4844\n",
      "Epoch 3288/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1102 - val_loss: 5.4843\n",
      "Epoch 3289/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1101 - val_loss: 5.4842\n",
      "Epoch 3290/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1099 - val_loss: 5.4841\n",
      "Epoch 3291/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1097 - val_loss: 5.4840\n",
      "Epoch 3292/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1096 - val_loss: 5.4838\n",
      "Epoch 3293/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1094 - val_loss: 5.4837\n",
      "Epoch 3294/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1093 - val_loss: 5.4836\n",
      "Epoch 3295/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1091 - val_loss: 5.4835\n",
      "Epoch 3296/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1089 - val_loss: 5.4834\n",
      "Epoch 3297/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1088 - val_loss: 5.4832\n",
      "Epoch 3298/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1086 - val_loss: 5.4831\n",
      "Epoch 3299/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1085 - val_loss: 5.4830\n",
      "Epoch 3300/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1083 - val_loss: 5.4829\n",
      "Epoch 3301/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1081 - val_loss: 5.4828\n",
      "Epoch 3302/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1080 - val_loss: 5.4826\n",
      "Epoch 3303/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1078 - val_loss: 5.4825\n",
      "Epoch 3304/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1077 - val_loss: 5.4824\n",
      "Epoch 3305/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1075 - val_loss: 5.4823\n",
      "Epoch 3306/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1073 - val_loss: 5.4822\n",
      "Epoch 3307/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1072 - val_loss: 5.4820\n",
      "Epoch 3308/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1070 - val_loss: 5.4819\n",
      "Epoch 3309/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1069 - val_loss: 5.4818\n",
      "Epoch 3310/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1067 - val_loss: 5.4817\n",
      "Epoch 3311/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1066 - val_loss: 5.4816\n",
      "Epoch 3312/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1064 - val_loss: 5.4814\n",
      "Epoch 3313/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1062 - val_loss: 5.4813\n",
      "Epoch 3314/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1061 - val_loss: 5.4812\n",
      "Epoch 3315/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1059 - val_loss: 5.4811\n",
      "Epoch 3316/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1058 - val_loss: 5.4810\n",
      "Epoch 3317/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1056 - val_loss: 5.4808\n",
      "Epoch 3318/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1054 - val_loss: 5.4807\n",
      "Epoch 3319/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1053 - val_loss: 5.4806\n",
      "Epoch 3320/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1051 - val_loss: 5.4805\n",
      "Epoch 3321/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1050 - val_loss: 5.4804\n",
      "Epoch 3322/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1048 - val_loss: 5.4803\n",
      "Epoch 3323/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1046 - val_loss: 5.4801\n",
      "Epoch 3324/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1045 - val_loss: 5.4800\n",
      "Epoch 3325/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1043 - val_loss: 5.4799\n",
      "Epoch 3326/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1042 - val_loss: 5.4798\n",
      "Epoch 3327/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1040 - val_loss: 5.4797\n",
      "Epoch 3328/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1038 - val_loss: 5.4795\n",
      "Epoch 3329/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1037 - val_loss: 5.4794\n",
      "Epoch 3330/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1035 - val_loss: 5.4793\n",
      "Epoch 3331/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1034 - val_loss: 5.4792\n",
      "Epoch 3332/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1032 - val_loss: 5.4791\n",
      "Epoch 3333/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1031 - val_loss: 5.4789\n",
      "Epoch 3334/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1029 - val_loss: 5.4788\n",
      "Epoch 3335/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1027 - val_loss: 5.4787\n",
      "Epoch 3336/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1026 - val_loss: 5.4786\n",
      "Epoch 3337/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1024 - val_loss: 5.4785\n",
      "Epoch 3338/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1023 - val_loss: 5.4784\n",
      "Epoch 3339/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1021 - val_loss: 5.4782\n",
      "Epoch 3340/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1019 - val_loss: 5.4781\n",
      "Epoch 3341/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1018 - val_loss: 5.4780\n",
      "Epoch 3342/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1016 - val_loss: 5.4779\n",
      "Epoch 3343/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1015 - val_loss: 5.4778\n",
      "Epoch 3344/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1013 - val_loss: 5.4776\n",
      "Epoch 3345/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1011 - val_loss: 5.4775\n",
      "Epoch 3346/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1010 - val_loss: 5.4774\n",
      "Epoch 3347/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.1008 - val_loss: 5.4773\n",
      "Epoch 3348/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1007 - val_loss: 5.4772\n",
      "Epoch 3349/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1005 - val_loss: 5.4771\n",
      "Epoch 3350/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1004 - val_loss: 5.4769\n",
      "Epoch 3351/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1002 - val_loss: 5.4768\n",
      "Epoch 3352/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.1000 - val_loss: 5.4767\n",
      "Epoch 3353/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0999 - val_loss: 5.4766\n",
      "Epoch 3354/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0997 - val_loss: 5.4765\n",
      "Epoch 3355/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0996 - val_loss: 5.4763\n",
      "Epoch 3356/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0994 - val_loss: 5.4762\n",
      "Epoch 3357/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0993 - val_loss: 5.4761\n",
      "Epoch 3358/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0991 - val_loss: 5.4760\n",
      "Epoch 3359/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0989 - val_loss: 5.4759\n",
      "Epoch 3360/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0988 - val_loss: 5.4758\n",
      "Epoch 3361/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0986 - val_loss: 5.4756\n",
      "Epoch 3362/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0985 - val_loss: 5.4755\n",
      "Epoch 3363/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0983 - val_loss: 5.4754\n",
      "Epoch 3364/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0981 - val_loss: 5.4753\n",
      "Epoch 3365/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0980 - val_loss: 5.4752\n",
      "Epoch 3366/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0978 - val_loss: 5.4750\n",
      "Epoch 3367/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.0977 - val_loss: 5.4749\n",
      "Epoch 3368/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0975 - val_loss: 5.4748\n",
      "Epoch 3369/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0974 - val_loss: 5.4747\n",
      "Epoch 3370/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0972 - val_loss: 5.4746\n",
      "Epoch 3371/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0970 - val_loss: 5.4745\n",
      "Epoch 3372/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0969 - val_loss: 5.4743\n",
      "Epoch 3373/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0967 - val_loss: 5.4742\n",
      "Epoch 3374/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0966 - val_loss: 5.4741\n",
      "Epoch 3375/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0964 - val_loss: 5.4740\n",
      "Epoch 3376/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0963 - val_loss: 5.4739\n",
      "Epoch 3377/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0961 - val_loss: 5.4738\n",
      "Epoch 3378/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0959 - val_loss: 5.4736\n",
      "Epoch 3379/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0958 - val_loss: 5.4735\n",
      "Epoch 3380/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0956 - val_loss: 5.4734\n",
      "Epoch 3381/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0955 - val_loss: 5.4733\n",
      "Epoch 3382/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0953 - val_loss: 5.4732\n",
      "Epoch 3383/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0952 - val_loss: 5.4730\n",
      "Epoch 3384/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0950 - val_loss: 5.4729\n",
      "Epoch 3385/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0948 - val_loss: 5.4728\n",
      "Epoch 3386/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.0947 - val_loss: 5.4727\n",
      "Epoch 3387/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.0945 - val_loss: 5.4726\n",
      "Epoch 3388/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0944 - val_loss: 5.4725\n",
      "Epoch 3389/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0942 - val_loss: 5.4723\n",
      "Epoch 3390/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0941 - val_loss: 5.4722\n",
      "Epoch 3391/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0939 - val_loss: 5.4721\n",
      "Epoch 3392/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 6.0937 - val_loss: 5.4720\n",
      "Epoch 3393/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0936 - val_loss: 5.4719\n",
      "Epoch 3394/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0934 - val_loss: 5.4718\n",
      "Epoch 3395/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0933 - val_loss: 5.4716\n",
      "Epoch 3396/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0931 - val_loss: 5.4715\n",
      "Epoch 3397/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0930 - val_loss: 5.4714\n",
      "Epoch 3398/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0928 - val_loss: 5.4713\n",
      "Epoch 3399/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0926 - val_loss: 5.4712\n",
      "Epoch 3400/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0925 - val_loss: 5.4711\n",
      "Epoch 3401/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0923 - val_loss: 5.4709\n",
      "Epoch 3402/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0922 - val_loss: 5.4708\n",
      "Epoch 3403/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0920 - val_loss: 5.4707\n",
      "Epoch 3404/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0919 - val_loss: 5.4706\n",
      "Epoch 3405/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0917 - val_loss: 5.4705\n",
      "Epoch 3406/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0915 - val_loss: 5.4704\n",
      "Epoch 3407/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0914 - val_loss: 5.4702\n",
      "Epoch 3408/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0912 - val_loss: 5.4701\n",
      "Epoch 3409/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0911 - val_loss: 5.4700\n",
      "Epoch 3410/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0909 - val_loss: 5.4699\n",
      "Epoch 3411/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0908 - val_loss: 5.4698\n",
      "Epoch 3412/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.0906 - val_loss: 5.4697\n",
      "Epoch 3413/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0904 - val_loss: 5.4695\n",
      "Epoch 3414/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0903 - val_loss: 5.4694\n",
      "Epoch 3415/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0901 - val_loss: 5.4693\n",
      "Epoch 3416/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0900 - val_loss: 5.4692\n",
      "Epoch 3417/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0898 - val_loss: 5.4691\n",
      "Epoch 3418/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0897 - val_loss: 5.4690\n",
      "Epoch 3419/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0895 - val_loss: 5.4688\n",
      "Epoch 3420/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0894 - val_loss: 5.4687\n",
      "Epoch 3421/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0892 - val_loss: 5.4686\n",
      "Epoch 3422/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0890 - val_loss: 5.4685\n",
      "Epoch 3423/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0889 - val_loss: 5.4684\n",
      "Epoch 3424/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0887 - val_loss: 5.4683\n",
      "Epoch 3425/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0886 - val_loss: 5.4681\n",
      "Epoch 3426/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0884 - val_loss: 5.4680\n",
      "Epoch 3427/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0883 - val_loss: 5.4679\n",
      "Epoch 3428/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0881 - val_loss: 5.4678\n",
      "Epoch 3429/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0880 - val_loss: 5.4677\n",
      "Epoch 3430/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0878 - val_loss: 5.4676\n",
      "Epoch 3431/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0876 - val_loss: 5.4675\n",
      "Epoch 3432/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0875 - val_loss: 5.4673\n",
      "Epoch 3433/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0873 - val_loss: 5.4672\n",
      "Epoch 3434/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0872 - val_loss: 5.4671\n",
      "Epoch 3435/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0870 - val_loss: 5.4670\n",
      "Epoch 3436/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0869 - val_loss: 5.4669\n",
      "Epoch 3437/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0867 - val_loss: 5.4668\n",
      "Epoch 3438/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0865 - val_loss: 5.4666\n",
      "Epoch 3439/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0864 - val_loss: 5.4665\n",
      "Epoch 3440/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0862 - val_loss: 5.4664\n",
      "Epoch 3441/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0861 - val_loss: 5.4663\n",
      "Epoch 3442/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0859 - val_loss: 5.4662\n",
      "Epoch 3443/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0858 - val_loss: 5.4661\n",
      "Epoch 3444/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0856 - val_loss: 5.4659\n",
      "Epoch 3445/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0855 - val_loss: 5.4658\n",
      "Epoch 3446/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0853 - val_loss: 5.4657\n",
      "Epoch 3447/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0851 - val_loss: 5.4656\n",
      "Epoch 3448/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0850 - val_loss: 5.4655\n",
      "Epoch 3449/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0848 - val_loss: 5.4654\n",
      "Epoch 3450/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0847 - val_loss: 5.4653\n",
      "Epoch 3451/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0845 - val_loss: 5.4651\n",
      "Epoch 3452/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0844 - val_loss: 5.4650\n",
      "Epoch 3453/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0842 - val_loss: 5.4649\n",
      "Epoch 3454/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0841 - val_loss: 5.4648\n",
      "Epoch 3455/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0839 - val_loss: 5.4647\n",
      "Epoch 3456/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0838 - val_loss: 5.4646\n",
      "Epoch 3457/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0836 - val_loss: 5.4644\n",
      "Epoch 3458/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0834 - val_loss: 5.4643\n",
      "Epoch 3459/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0833 - val_loss: 5.4642\n",
      "Epoch 3460/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0831 - val_loss: 5.4641\n",
      "Epoch 3461/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0830 - val_loss: 5.4640\n",
      "Epoch 3462/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0828 - val_loss: 5.4639\n",
      "Epoch 3463/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0827 - val_loss: 5.4638\n",
      "Epoch 3464/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.0825 - val_loss: 5.4636\n",
      "Epoch 3465/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0824 - val_loss: 5.4635\n",
      "Epoch 3466/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0822 - val_loss: 5.4634\n",
      "Epoch 3467/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.0820 - val_loss: 5.4633\n",
      "Epoch 3468/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0819 - val_loss: 5.4632\n",
      "Epoch 3469/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0817 - val_loss: 5.4631\n",
      "Epoch 3470/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0816 - val_loss: 5.4630\n",
      "Epoch 3471/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0814 - val_loss: 5.4628\n",
      "Epoch 3472/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0813 - val_loss: 5.4627\n",
      "Epoch 3473/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0811 - val_loss: 5.4626\n",
      "Epoch 3474/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0810 - val_loss: 5.4625\n",
      "Epoch 3475/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0808 - val_loss: 5.4624\n",
      "Epoch 3476/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0807 - val_loss: 5.4623\n",
      "Epoch 3477/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0805 - val_loss: 5.4621\n",
      "Epoch 3478/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0803 - val_loss: 5.4620\n",
      "Epoch 3479/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0802 - val_loss: 5.4619\n",
      "Epoch 3480/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0800 - val_loss: 5.4618\n",
      "Epoch 3481/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0799 - val_loss: 5.4617\n",
      "Epoch 3482/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0797 - val_loss: 5.4616\n",
      "Epoch 3483/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0796 - val_loss: 5.4615\n",
      "Epoch 3484/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0794 - val_loss: 5.4613\n",
      "Epoch 3485/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0793 - val_loss: 5.4612\n",
      "Epoch 3486/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0791 - val_loss: 5.4611\n",
      "Epoch 3487/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0790 - val_loss: 5.4610\n",
      "Epoch 3488/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0788 - val_loss: 5.4609\n",
      "Epoch 3489/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0786 - val_loss: 5.4608\n",
      "Epoch 3490/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0785 - val_loss: 5.4607\n",
      "Epoch 3491/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0783 - val_loss: 5.4605\n",
      "Epoch 3492/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0782 - val_loss: 5.4604\n",
      "Epoch 3493/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0780 - val_loss: 5.4603\n",
      "Epoch 3494/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0779 - val_loss: 5.4602\n",
      "Epoch 3495/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0777 - val_loss: 5.4601\n",
      "Epoch 3496/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0776 - val_loss: 5.4600\n",
      "Epoch 3497/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0774 - val_loss: 5.4599\n",
      "Epoch 3498/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0773 - val_loss: 5.4597\n",
      "Epoch 3499/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0771 - val_loss: 5.4596\n",
      "Epoch 3500/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0770 - val_loss: 5.4595\n",
      "Epoch 3501/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0768 - val_loss: 5.4594\n",
      "Epoch 3502/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0766 - val_loss: 5.4593\n",
      "Epoch 3503/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0765 - val_loss: 5.4592\n",
      "Epoch 3504/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0763 - val_loss: 5.4591\n",
      "Epoch 3505/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0762 - val_loss: 5.4589\n",
      "Epoch 3506/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0760 - val_loss: 5.4588\n",
      "Epoch 3507/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0759 - val_loss: 5.4587\n",
      "Epoch 3508/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0757 - val_loss: 5.4586\n",
      "Epoch 3509/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0756 - val_loss: 5.4585\n",
      "Epoch 3510/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0754 - val_loss: 5.4584\n",
      "Epoch 3511/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0753 - val_loss: 5.4583\n",
      "Epoch 3512/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0751 - val_loss: 5.4581\n",
      "Epoch 3513/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0750 - val_loss: 5.4580\n",
      "Epoch 3514/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0748 - val_loss: 5.4579\n",
      "Epoch 3515/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0746 - val_loss: 5.4578\n",
      "Epoch 3516/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0745 - val_loss: 5.4577\n",
      "Epoch 3517/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0743 - val_loss: 5.4576\n",
      "Epoch 3518/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0742 - val_loss: 5.4575\n",
      "Epoch 3519/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0740 - val_loss: 5.4573\n",
      "Epoch 3520/5000\n",
      "39898/39898 [==============================] - 1s 18us/step - loss: 6.0739 - val_loss: 5.4572\n",
      "Epoch 3521/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0737 - val_loss: 5.4571\n",
      "Epoch 3522/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0736 - val_loss: 5.4570\n",
      "Epoch 3523/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0734 - val_loss: 5.4569\n",
      "Epoch 3524/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0733 - val_loss: 5.4568\n",
      "Epoch 3525/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0731 - val_loss: 5.4567\n",
      "Epoch 3526/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0730 - val_loss: 5.4566\n",
      "Epoch 3527/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0728 - val_loss: 5.4564\n",
      "Epoch 3528/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0727 - val_loss: 5.4563\n",
      "Epoch 3529/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0725 - val_loss: 5.4562\n",
      "Epoch 3530/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0723 - val_loss: 5.4561\n",
      "Epoch 3531/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0722 - val_loss: 5.4560\n",
      "Epoch 3532/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0720 - val_loss: 5.4559\n",
      "Epoch 3533/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0719 - val_loss: 5.4558\n",
      "Epoch 3534/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0717 - val_loss: 5.4556\n",
      "Epoch 3535/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0716 - val_loss: 5.4555\n",
      "Epoch 3536/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0714 - val_loss: 5.4554\n",
      "Epoch 3537/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0713 - val_loss: 5.4553\n",
      "Epoch 3538/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0711 - val_loss: 5.4552\n",
      "Epoch 3539/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0710 - val_loss: 5.4551\n",
      "Epoch 3540/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0708 - val_loss: 5.4550\n",
      "Epoch 3541/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0707 - val_loss: 5.4549\n",
      "Epoch 3542/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0705 - val_loss: 5.4547\n",
      "Epoch 3543/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0704 - val_loss: 5.4546\n",
      "Epoch 3544/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0702 - val_loss: 5.4545\n",
      "Epoch 3545/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0701 - val_loss: 5.4544\n",
      "Epoch 3546/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0699 - val_loss: 5.4543\n",
      "Epoch 3547/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0697 - val_loss: 5.4542\n",
      "Epoch 3548/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0696 - val_loss: 5.4541\n",
      "Epoch 3549/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0694 - val_loss: 5.4539\n",
      "Epoch 3550/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0693 - val_loss: 5.4538\n",
      "Epoch 3551/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0691 - val_loss: 5.4537\n",
      "Epoch 3552/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0690 - val_loss: 5.4536\n",
      "Epoch 3553/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0688 - val_loss: 5.4535\n",
      "Epoch 3554/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0687 - val_loss: 5.4534\n",
      "Epoch 3555/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0685 - val_loss: 5.4533\n",
      "Epoch 3556/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0684 - val_loss: 5.4532\n",
      "Epoch 3557/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.0682 - val_loss: 5.4530\n",
      "Epoch 3558/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0681 - val_loss: 5.4529\n",
      "Epoch 3559/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0679 - val_loss: 5.4528\n",
      "Epoch 3560/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0678 - val_loss: 5.4527\n",
      "Epoch 3561/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0676 - val_loss: 5.4526\n",
      "Epoch 3562/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0675 - val_loss: 5.4525\n",
      "Epoch 3563/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0673 - val_loss: 5.4524\n",
      "Epoch 3564/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0672 - val_loss: 5.4523\n",
      "Epoch 3565/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0670 - val_loss: 5.4521\n",
      "Epoch 3566/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0668 - val_loss: 5.4520\n",
      "Epoch 3567/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.0667 - val_loss: 5.4519\n",
      "Epoch 3568/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0665 - val_loss: 5.4518\n",
      "Epoch 3569/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0664 - val_loss: 5.4517\n",
      "Epoch 3570/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0662 - val_loss: 5.4516\n",
      "Epoch 3571/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.0661 - val_loss: 5.4515\n",
      "Epoch 3572/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0659 - val_loss: 5.4514\n",
      "Epoch 3573/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 6.0658 - val_loss: 5.4512\n",
      "Epoch 3574/5000\n",
      "39898/39898 [==============================] - 1s 19us/step - loss: 6.0656 - val_loss: 5.4511\n",
      "Epoch 3575/5000\n",
      "39898/39898 [==============================] - 1s 16us/step - loss: 6.0655 - val_loss: 5.4510\n",
      "Epoch 3576/5000\n",
      "39898/39898 [==============================] - 1s 18us/step - loss: 6.0653 - val_loss: 5.4509\n",
      "Epoch 3577/5000\n",
      "39898/39898 [==============================] - 1s 16us/step - loss: 6.0652 - val_loss: 5.4508\n",
      "Epoch 3578/5000\n",
      "39898/39898 [==============================] - 1s 17us/step - loss: 6.0650 - val_loss: 5.4507\n",
      "Epoch 3579/5000\n",
      "39898/39898 [==============================] - 1s 18us/step - loss: 6.0649 - val_loss: 5.4506\n",
      "Epoch 3580/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0647 - val_loss: 5.4505\n",
      "Epoch 3581/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0646 - val_loss: 5.4503\n",
      "Epoch 3582/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0644 - val_loss: 5.4502\n",
      "Epoch 3583/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0643 - val_loss: 5.4501\n",
      "Epoch 3584/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0641 - val_loss: 5.4500\n",
      "Epoch 3585/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0640 - val_loss: 5.4499\n",
      "Epoch 3586/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0638 - val_loss: 5.4498\n",
      "Epoch 3587/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0637 - val_loss: 5.4497\n",
      "Epoch 3588/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0635 - val_loss: 5.4496\n",
      "Epoch 3589/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0634 - val_loss: 5.4494\n",
      "Epoch 3590/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0632 - val_loss: 5.4493\n",
      "Epoch 3591/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0631 - val_loss: 5.4492\n",
      "Epoch 3592/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0629 - val_loss: 5.4491\n",
      "Epoch 3593/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0628 - val_loss: 5.4490\n",
      "Epoch 3594/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0626 - val_loss: 5.4489\n",
      "Epoch 3595/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0624 - val_loss: 5.4488\n",
      "Epoch 3596/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0623 - val_loss: 5.4487\n",
      "Epoch 3597/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0621 - val_loss: 5.4486\n",
      "Epoch 3598/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0620 - val_loss: 5.4484\n",
      "Epoch 3599/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0618 - val_loss: 5.4483\n",
      "Epoch 3600/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0617 - val_loss: 5.4482\n",
      "Epoch 3601/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0615 - val_loss: 5.4481\n",
      "Epoch 3602/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0614 - val_loss: 5.4480\n",
      "Epoch 3603/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0612 - val_loss: 5.4479\n",
      "Epoch 3604/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0611 - val_loss: 5.4478\n",
      "Epoch 3605/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0609 - val_loss: 5.4477\n",
      "Epoch 3606/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0608 - val_loss: 5.4475\n",
      "Epoch 3607/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0606 - val_loss: 5.4474\n",
      "Epoch 3608/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0605 - val_loss: 5.4473\n",
      "Epoch 3609/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0603 - val_loss: 5.4472\n",
      "Epoch 3610/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0602 - val_loss: 5.4471\n",
      "Epoch 3611/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0600 - val_loss: 5.4470\n",
      "Epoch 3612/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0599 - val_loss: 5.4469\n",
      "Epoch 3613/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.0597 - val_loss: 5.4468\n",
      "Epoch 3614/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.0596 - val_loss: 5.4467\n",
      "Epoch 3615/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0594 - val_loss: 5.4465\n",
      "Epoch 3616/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0593 - val_loss: 5.4464\n",
      "Epoch 3617/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0591 - val_loss: 5.4463\n",
      "Epoch 3618/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0590 - val_loss: 5.4462\n",
      "Epoch 3619/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0588 - val_loss: 5.4461\n",
      "Epoch 3620/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0587 - val_loss: 5.4460\n",
      "Epoch 3621/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0585 - val_loss: 5.4459\n",
      "Epoch 3622/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0584 - val_loss: 5.4458\n",
      "Epoch 3623/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0582 - val_loss: 5.4457\n",
      "Epoch 3624/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0581 - val_loss: 5.4455\n",
      "Epoch 3625/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0579 - val_loss: 5.4454\n",
      "Epoch 3626/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0578 - val_loss: 5.4453\n",
      "Epoch 3627/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0576 - val_loss: 5.4452\n",
      "Epoch 3628/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0575 - val_loss: 5.4451\n",
      "Epoch 3629/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0573 - val_loss: 5.4450\n",
      "Epoch 3630/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0572 - val_loss: 5.4449\n",
      "Epoch 3631/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0570 - val_loss: 5.4448\n",
      "Epoch 3632/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0569 - val_loss: 5.4447\n",
      "Epoch 3633/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0567 - val_loss: 5.4445\n",
      "Epoch 3634/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0566 - val_loss: 5.4444\n",
      "Epoch 3635/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0564 - val_loss: 5.4443\n",
      "Epoch 3636/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0563 - val_loss: 5.4442\n",
      "Epoch 3637/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0561 - val_loss: 5.4441\n",
      "Epoch 3638/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0560 - val_loss: 5.4440\n",
      "Epoch 3639/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0558 - val_loss: 5.4439\n",
      "Epoch 3640/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0557 - val_loss: 5.4438\n",
      "Epoch 3641/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0555 - val_loss: 5.4437\n",
      "Epoch 3642/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0554 - val_loss: 5.4435\n",
      "Epoch 3643/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0552 - val_loss: 5.4434\n",
      "Epoch 3644/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0551 - val_loss: 5.4433\n",
      "Epoch 3645/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0549 - val_loss: 5.4432\n",
      "Epoch 3646/5000\n",
      "39898/39898 [==============================] - 1s 13us/step - loss: 6.0548 - val_loss: 5.4431\n",
      "Epoch 3647/5000\n",
      "39898/39898 [==============================] - 1s 16us/step - loss: 6.0546 - val_loss: 5.4430\n",
      "Epoch 3648/5000\n",
      "39898/39898 [==============================] - 1s 15us/step - loss: 6.0545 - val_loss: 5.4429\n",
      "Epoch 3649/5000\n",
      "39898/39898 [==============================] - 1s 14us/step - loss: 6.0543 - val_loss: 5.4428\n",
      "Epoch 3650/5000\n",
      "39898/39898 [==============================] - 1s 18us/step - loss: 6.0542 - val_loss: 5.4427\n",
      "Epoch 3651/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0540 - val_loss: 5.4425\n",
      "Epoch 3652/5000\n",
      "39898/39898 [==============================] - 1s 15us/step - loss: 6.0539 - val_loss: 5.4424\n",
      "Epoch 3653/5000\n",
      "39898/39898 [==============================] - 1s 16us/step - loss: 6.0537 - val_loss: 5.4423\n",
      "Epoch 3654/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0536 - val_loss: 5.4422\n",
      "Epoch 3655/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0534 - val_loss: 5.4421\n",
      "Epoch 3656/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.0533 - val_loss: 5.4420\n",
      "Epoch 3657/5000\n",
      "39898/39898 [==============================] - 1s 18us/step - loss: 6.0531 - val_loss: 5.4419\n",
      "Epoch 3658/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0530 - val_loss: 5.4418\n",
      "Epoch 3659/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0528 - val_loss: 5.4417\n",
      "Epoch 3660/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0527 - val_loss: 5.4416\n",
      "Epoch 3661/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0525 - val_loss: 5.4414\n",
      "Epoch 3662/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0524 - val_loss: 5.4413\n",
      "Epoch 3663/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0522 - val_loss: 5.4412\n",
      "Epoch 3664/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0521 - val_loss: 5.4411\n",
      "Epoch 3665/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0519 - val_loss: 5.4410\n",
      "Epoch 3666/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0518 - val_loss: 5.4409\n",
      "Epoch 3667/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0516 - val_loss: 5.4408\n",
      "Epoch 3668/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0515 - val_loss: 5.4407\n",
      "Epoch 3669/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0513 - val_loss: 5.4406\n",
      "Epoch 3670/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0512 - val_loss: 5.4405\n",
      "Epoch 3671/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0510 - val_loss: 5.4403\n",
      "Epoch 3672/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0509 - val_loss: 5.4402\n",
      "Epoch 3673/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0507 - val_loss: 5.4401\n",
      "Epoch 3674/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0506 - val_loss: 5.4400\n",
      "Epoch 3675/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0504 - val_loss: 5.4399\n",
      "Epoch 3676/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0503 - val_loss: 5.4398\n",
      "Epoch 3677/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0501 - val_loss: 5.4397\n",
      "Epoch 3678/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0500 - val_loss: 5.4396\n",
      "Epoch 3679/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0498 - val_loss: 5.4395\n",
      "Epoch 3680/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0497 - val_loss: 5.4394\n",
      "Epoch 3681/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0495 - val_loss: 5.4392\n",
      "Epoch 3682/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0494 - val_loss: 5.4391\n",
      "Epoch 3683/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0492 - val_loss: 5.4390\n",
      "Epoch 3684/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0491 - val_loss: 5.4389\n",
      "Epoch 3685/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0489 - val_loss: 5.4388\n",
      "Epoch 3686/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0488 - val_loss: 5.4387\n",
      "Epoch 3687/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0486 - val_loss: 5.4386\n",
      "Epoch 3688/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0485 - val_loss: 5.4385\n",
      "Epoch 3689/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0483 - val_loss: 5.4384\n",
      "Epoch 3690/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0482 - val_loss: 5.4383\n",
      "Epoch 3691/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0480 - val_loss: 5.4381\n",
      "Epoch 3692/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0479 - val_loss: 5.4380\n",
      "Epoch 3693/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0477 - val_loss: 5.4379\n",
      "Epoch 3694/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0476 - val_loss: 5.4378\n",
      "Epoch 3695/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0474 - val_loss: 5.4377\n",
      "Epoch 3696/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0473 - val_loss: 5.4376\n",
      "Epoch 3697/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0471 - val_loss: 5.4375\n",
      "Epoch 3698/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0470 - val_loss: 5.4374\n",
      "Epoch 3699/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0468 - val_loss: 5.4373\n",
      "Epoch 3700/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0467 - val_loss: 5.4372\n",
      "Epoch 3701/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0465 - val_loss: 5.4371\n",
      "Epoch 3702/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0464 - val_loss: 5.4369\n",
      "Epoch 3703/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0462 - val_loss: 5.4368\n",
      "Epoch 3704/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0461 - val_loss: 5.4367\n",
      "Epoch 3705/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0459 - val_loss: 5.4366\n",
      "Epoch 3706/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0458 - val_loss: 5.4365\n",
      "Epoch 3707/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0456 - val_loss: 5.4364\n",
      "Epoch 3708/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0455 - val_loss: 5.4363\n",
      "Epoch 3709/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0454 - val_loss: 5.4362\n",
      "Epoch 3710/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0452 - val_loss: 5.4361\n",
      "Epoch 3711/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0451 - val_loss: 5.4360\n",
      "Epoch 3712/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0449 - val_loss: 5.4359\n",
      "Epoch 3713/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0448 - val_loss: 5.4357\n",
      "Epoch 3714/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.0446 - val_loss: 5.4356\n",
      "Epoch 3715/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0445 - val_loss: 5.4355\n",
      "Epoch 3716/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0443 - val_loss: 5.4354\n",
      "Epoch 3717/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0442 - val_loss: 5.4353\n",
      "Epoch 3718/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0440 - val_loss: 5.4352\n",
      "Epoch 3719/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0439 - val_loss: 5.4351\n",
      "Epoch 3720/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0437 - val_loss: 5.4350\n",
      "Epoch 3721/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0436 - val_loss: 5.4349\n",
      "Epoch 3722/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0434 - val_loss: 5.4348\n",
      "Epoch 3723/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0433 - val_loss: 5.4347\n",
      "Epoch 3724/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0431 - val_loss: 5.4345\n",
      "Epoch 3725/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0430 - val_loss: 5.4344\n",
      "Epoch 3726/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0428 - val_loss: 5.4343\n",
      "Epoch 3727/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0427 - val_loss: 5.4342\n",
      "Epoch 3728/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0425 - val_loss: 5.4341\n",
      "Epoch 3729/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0424 - val_loss: 5.4340\n",
      "Epoch 3730/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0422 - val_loss: 5.4339\n",
      "Epoch 3731/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0421 - val_loss: 5.4338\n",
      "Epoch 3732/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0419 - val_loss: 5.4337\n",
      "Epoch 3733/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0418 - val_loss: 5.4336\n",
      "Epoch 3734/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0416 - val_loss: 5.4335\n",
      "Epoch 3735/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0415 - val_loss: 5.4333\n",
      "Epoch 3736/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0414 - val_loss: 5.4332\n",
      "Epoch 3737/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0412 - val_loss: 5.4331\n",
      "Epoch 3738/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0411 - val_loss: 5.4330\n",
      "Epoch 3739/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0409 - val_loss: 5.4329\n",
      "Epoch 3740/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0408 - val_loss: 5.4328\n",
      "Epoch 3741/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0406 - val_loss: 5.4327\n",
      "Epoch 3742/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0405 - val_loss: 5.4326\n",
      "Epoch 3743/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0403 - val_loss: 5.4325\n",
      "Epoch 3744/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0402 - val_loss: 5.4324\n",
      "Epoch 3745/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0400 - val_loss: 5.4323\n",
      "Epoch 3746/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0399 - val_loss: 5.4322\n",
      "Epoch 3747/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0397 - val_loss: 5.4320\n",
      "Epoch 3748/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0396 - val_loss: 5.4319\n",
      "Epoch 3749/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0394 - val_loss: 5.4318\n",
      "Epoch 3750/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0393 - val_loss: 5.4317\n",
      "Epoch 3751/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0391 - val_loss: 5.4316\n",
      "Epoch 3752/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0390 - val_loss: 5.4315\n",
      "Epoch 3753/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0388 - val_loss: 5.4314\n",
      "Epoch 3754/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0387 - val_loss: 5.4313\n",
      "Epoch 3755/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0385 - val_loss: 5.4312\n",
      "Epoch 3756/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0384 - val_loss: 5.4311\n",
      "Epoch 3757/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0383 - val_loss: 5.4310\n",
      "Epoch 3758/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0381 - val_loss: 5.4309\n",
      "Epoch 3759/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0380 - val_loss: 5.4308\n",
      "Epoch 3760/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0378 - val_loss: 5.4306\n",
      "Epoch 3761/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0377 - val_loss: 5.4305\n",
      "Epoch 3762/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0375 - val_loss: 5.4304\n",
      "Epoch 3763/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0374 - val_loss: 5.4303\n",
      "Epoch 3764/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0372 - val_loss: 5.4302\n",
      "Epoch 3765/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0371 - val_loss: 5.4301\n",
      "Epoch 3766/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0369 - val_loss: 5.4300\n",
      "Epoch 3767/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0368 - val_loss: 5.4299\n",
      "Epoch 3768/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0366 - val_loss: 5.4298\n",
      "Epoch 3769/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0365 - val_loss: 5.4297\n",
      "Epoch 3770/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0363 - val_loss: 5.4296\n",
      "Epoch 3771/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0362 - val_loss: 5.4295\n",
      "Epoch 3772/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0360 - val_loss: 5.4293\n",
      "Epoch 3773/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0359 - val_loss: 5.4292\n",
      "Epoch 3774/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0357 - val_loss: 5.4291\n",
      "Epoch 3775/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0356 - val_loss: 5.4290\n",
      "Epoch 3776/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0355 - val_loss: 5.4289\n",
      "Epoch 3777/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0353 - val_loss: 5.4288\n",
      "Epoch 3778/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0352 - val_loss: 5.4287\n",
      "Epoch 3779/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0350 - val_loss: 5.4286\n",
      "Epoch 3780/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0349 - val_loss: 5.4285\n",
      "Epoch 3781/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0347 - val_loss: 5.4284\n",
      "Epoch 3782/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0346 - val_loss: 5.4283\n",
      "Epoch 3783/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0344 - val_loss: 5.4282\n",
      "Epoch 3784/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0343 - val_loss: 5.4281\n",
      "Epoch 3785/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0341 - val_loss: 5.4280\n",
      "Epoch 3786/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0340 - val_loss: 5.4278\n",
      "Epoch 3787/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0338 - val_loss: 5.4277\n",
      "Epoch 3788/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0337 - val_loss: 5.4276\n",
      "Epoch 3789/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0335 - val_loss: 5.4275\n",
      "Epoch 3790/5000\n",
      "39898/39898 [==============================] - 1s 19us/step - loss: 6.0334 - val_loss: 5.4274\n",
      "Epoch 3791/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0333 - val_loss: 5.4273\n",
      "Epoch 3792/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.0331 - val_loss: 5.4272\n",
      "Epoch 3793/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0330 - val_loss: 5.4271\n",
      "Epoch 3794/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0328 - val_loss: 5.4270\n",
      "Epoch 3795/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0327 - val_loss: 5.4269\n",
      "Epoch 3796/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0325 - val_loss: 5.4268\n",
      "Epoch 3797/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0324 - val_loss: 5.4267\n",
      "Epoch 3798/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0322 - val_loss: 5.4266\n",
      "Epoch 3799/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0321 - val_loss: 5.4265\n",
      "Epoch 3800/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0319 - val_loss: 5.4263\n",
      "Epoch 3801/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0318 - val_loss: 5.4262\n",
      "Epoch 3802/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0316 - val_loss: 5.4261\n",
      "Epoch 3803/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0315 - val_loss: 5.4260\n",
      "Epoch 3804/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0314 - val_loss: 5.4259\n",
      "Epoch 3805/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0312 - val_loss: 5.4258\n",
      "Epoch 3806/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0311 - val_loss: 5.4257\n",
      "Epoch 3807/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0309 - val_loss: 5.4256\n",
      "Epoch 3808/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0308 - val_loss: 5.4255\n",
      "Epoch 3809/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0306 - val_loss: 5.4254\n",
      "Epoch 3810/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0305 - val_loss: 5.4253\n",
      "Epoch 3811/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0303 - val_loss: 5.4252\n",
      "Epoch 3812/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0302 - val_loss: 5.4251\n",
      "Epoch 3813/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0300 - val_loss: 5.4250\n",
      "Epoch 3814/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0299 - val_loss: 5.4248\n",
      "Epoch 3815/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0297 - val_loss: 5.4247\n",
      "Epoch 3816/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0296 - val_loss: 5.4246\n",
      "Epoch 3817/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0295 - val_loss: 5.4245\n",
      "Epoch 3818/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0293 - val_loss: 5.4244\n",
      "Epoch 3819/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0292 - val_loss: 5.4243\n",
      "Epoch 3820/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0290 - val_loss: 5.4242\n",
      "Epoch 3821/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0289 - val_loss: 5.4241\n",
      "Epoch 3822/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0287 - val_loss: 5.4240\n",
      "Epoch 3823/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0286 - val_loss: 5.4239\n",
      "Epoch 3824/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0284 - val_loss: 5.4238\n",
      "Epoch 3825/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0283 - val_loss: 5.4237\n",
      "Epoch 3826/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0281 - val_loss: 5.4236\n",
      "Epoch 3827/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0280 - val_loss: 5.4235\n",
      "Epoch 3828/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0278 - val_loss: 5.4234\n",
      "Epoch 3829/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0277 - val_loss: 5.4232\n",
      "Epoch 3830/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0276 - val_loss: 5.4231\n",
      "Epoch 3831/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0274 - val_loss: 5.4230\n",
      "Epoch 3832/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0273 - val_loss: 5.4229\n",
      "Epoch 3833/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0271 - val_loss: 5.4228\n",
      "Epoch 3834/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0270 - val_loss: 5.4227\n",
      "Epoch 3835/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0268 - val_loss: 5.4226\n",
      "Epoch 3836/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0267 - val_loss: 5.4225\n",
      "Epoch 3837/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0265 - val_loss: 5.4224\n",
      "Epoch 3838/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0264 - val_loss: 5.4223\n",
      "Epoch 3839/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0262 - val_loss: 5.4222\n",
      "Epoch 3840/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0261 - val_loss: 5.4221\n",
      "Epoch 3841/5000\n",
      "39898/39898 [==============================] - 1s 16us/step - loss: 6.0260 - val_loss: 5.4220\n",
      "Epoch 3842/5000\n",
      "39898/39898 [==============================] - 1s 17us/step - loss: 6.0258 - val_loss: 5.4219\n",
      "Epoch 3843/5000\n",
      "39898/39898 [==============================] - 1s 19us/step - loss: 6.0257 - val_loss: 5.4218\n",
      "Epoch 3844/5000\n",
      "39898/39898 [==============================] - 1s 16us/step - loss: 6.0255 - val_loss: 5.4217\n",
      "Epoch 3845/5000\n",
      "39898/39898 [==============================] - 1s 15us/step - loss: 6.0254 - val_loss: 5.4216\n",
      "Epoch 3846/5000\n",
      "39898/39898 [==============================] - 1s 16us/step - loss: 6.0252 - val_loss: 5.4214\n",
      "Epoch 3847/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0251 - val_loss: 5.4213\n",
      "Epoch 3848/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0249 - val_loss: 5.4212\n",
      "Epoch 3849/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0248 - val_loss: 5.4211\n",
      "Epoch 3850/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0246 - val_loss: 5.4210\n",
      "Epoch 3851/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0245 - val_loss: 5.4209\n",
      "Epoch 3852/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0244 - val_loss: 5.4208\n",
      "Epoch 3853/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0242 - val_loss: 5.4207\n",
      "Epoch 3854/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0241 - val_loss: 5.4206\n",
      "Epoch 3855/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0239 - val_loss: 5.4205\n",
      "Epoch 3856/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0238 - val_loss: 5.4204\n",
      "Epoch 3857/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0236 - val_loss: 5.4203\n",
      "Epoch 3858/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0235 - val_loss: 5.4202\n",
      "Epoch 3859/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0233 - val_loss: 5.4201\n",
      "Epoch 3860/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0232 - val_loss: 5.4200\n",
      "Epoch 3861/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0231 - val_loss: 5.4199\n",
      "Epoch 3862/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0229 - val_loss: 5.4198\n",
      "Epoch 3863/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0228 - val_loss: 5.4196\n",
      "Epoch 3864/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0226 - val_loss: 5.4195\n",
      "Epoch 3865/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0225 - val_loss: 5.4194\n",
      "Epoch 3866/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0223 - val_loss: 5.4193\n",
      "Epoch 3867/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0222 - val_loss: 5.4192\n",
      "Epoch 3868/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0220 - val_loss: 5.4191\n",
      "Epoch 3869/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0219 - val_loss: 5.4190\n",
      "Epoch 3870/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0218 - val_loss: 5.4189\n",
      "Epoch 3871/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0216 - val_loss: 5.4188\n",
      "Epoch 3872/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0215 - val_loss: 5.4187\n",
      "Epoch 3873/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0213 - val_loss: 5.4186\n",
      "Epoch 3874/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0212 - val_loss: 5.4185\n",
      "Epoch 3875/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0210 - val_loss: 5.4184\n",
      "Epoch 3876/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0209 - val_loss: 5.4183\n",
      "Epoch 3877/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0207 - val_loss: 5.4182\n",
      "Epoch 3878/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0206 - val_loss: 5.4181\n",
      "Epoch 3879/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0204 - val_loss: 5.4180\n",
      "Epoch 3880/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0203 - val_loss: 5.4179\n",
      "Epoch 3881/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0202 - val_loss: 5.4177\n",
      "Epoch 3882/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0200 - val_loss: 5.4176\n",
      "Epoch 3883/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0199 - val_loss: 5.4175\n",
      "Epoch 3884/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0197 - val_loss: 5.4174\n",
      "Epoch 3885/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0196 - val_loss: 5.4173\n",
      "Epoch 3886/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0194 - val_loss: 5.4172\n",
      "Epoch 3887/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0193 - val_loss: 5.4171\n",
      "Epoch 3888/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0191 - val_loss: 5.4170\n",
      "Epoch 3889/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0190 - val_loss: 5.4169\n",
      "Epoch 3890/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0189 - val_loss: 5.4168\n",
      "Epoch 3891/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0187 - val_loss: 5.4167\n",
      "Epoch 3892/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0186 - val_loss: 5.4166\n",
      "Epoch 3893/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0184 - val_loss: 5.4165\n",
      "Epoch 3894/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0183 - val_loss: 5.4164\n",
      "Epoch 3895/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0181 - val_loss: 5.4163\n",
      "Epoch 3896/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0180 - val_loss: 5.4162\n",
      "Epoch 3897/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0179 - val_loss: 5.4161\n",
      "Epoch 3898/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0177 - val_loss: 5.4160\n",
      "Epoch 3899/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0176 - val_loss: 5.4159\n",
      "Epoch 3900/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0174 - val_loss: 5.4158\n",
      "Epoch 3901/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0173 - val_loss: 5.4156\n",
      "Epoch 3902/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0171 - val_loss: 5.4155\n",
      "Epoch 3903/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0170 - val_loss: 5.4154\n",
      "Epoch 3904/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0168 - val_loss: 5.4153\n",
      "Epoch 3905/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0167 - val_loss: 5.4152\n",
      "Epoch 3906/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0166 - val_loss: 5.4151\n",
      "Epoch 3907/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0164 - val_loss: 5.4150\n",
      "Epoch 3908/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0163 - val_loss: 5.4149\n",
      "Epoch 3909/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0161 - val_loss: 5.4148\n",
      "Epoch 3910/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0160 - val_loss: 5.4147\n",
      "Epoch 3911/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0158 - val_loss: 5.4146\n",
      "Epoch 3912/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0157 - val_loss: 5.4145\n",
      "Epoch 3913/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0155 - val_loss: 5.4144\n",
      "Epoch 3914/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0154 - val_loss: 5.4143\n",
      "Epoch 3915/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0153 - val_loss: 5.4142\n",
      "Epoch 3916/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0151 - val_loss: 5.4141\n",
      "Epoch 3917/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0150 - val_loss: 5.4140\n",
      "Epoch 3918/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0148 - val_loss: 5.4139\n",
      "Epoch 3919/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 6.0147 - val_loss: 5.4138\n",
      "Epoch 3920/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0145 - val_loss: 5.4137\n",
      "Epoch 3921/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0144 - val_loss: 5.4136\n",
      "Epoch 3922/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0143 - val_loss: 5.4135\n",
      "Epoch 3923/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0141 - val_loss: 5.4133\n",
      "Epoch 3924/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0140 - val_loss: 5.4132\n",
      "Epoch 3925/5000\n",
      "39898/39898 [==============================] - 1s 17us/step - loss: 6.0138 - val_loss: 5.4131\n",
      "Epoch 3926/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0137 - val_loss: 5.4130\n",
      "Epoch 3927/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0135 - val_loss: 5.4129\n",
      "Epoch 3928/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0134 - val_loss: 5.4128\n",
      "Epoch 3929/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0133 - val_loss: 5.4127\n",
      "Epoch 3930/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0131 - val_loss: 5.4126\n",
      "Epoch 3931/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0130 - val_loss: 5.4125\n",
      "Epoch 3932/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0128 - val_loss: 5.4124\n",
      "Epoch 3933/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0127 - val_loss: 5.4123\n",
      "Epoch 3934/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0125 - val_loss: 5.4122\n",
      "Epoch 3935/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0124 - val_loss: 5.4121\n",
      "Epoch 3936/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0122 - val_loss: 5.4120\n",
      "Epoch 3937/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.0121 - val_loss: 5.4119\n",
      "Epoch 3938/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0120 - val_loss: 5.4118\n",
      "Epoch 3939/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0118 - val_loss: 5.4117\n",
      "Epoch 3940/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0117 - val_loss: 5.4116\n",
      "Epoch 3941/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0115 - val_loss: 5.4115\n",
      "Epoch 3942/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.0114 - val_loss: 5.4114\n",
      "Epoch 3943/5000\n",
      "39898/39898 [==============================] - 1s 15us/step - loss: 6.0112 - val_loss: 5.4113\n",
      "Epoch 3944/5000\n",
      "39898/39898 [==============================] - 1s 18us/step - loss: 6.0111 - val_loss: 5.4112\n",
      "Epoch 3945/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0110 - val_loss: 5.4111\n",
      "Epoch 3946/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0108 - val_loss: 5.4110\n",
      "Epoch 3947/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0107 - val_loss: 5.4108\n",
      "Epoch 3948/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0105 - val_loss: 5.4107\n",
      "Epoch 3949/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 6.0104 - val_loss: 5.4106\n",
      "Epoch 3950/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0102 - val_loss: 5.4105\n",
      "Epoch 3951/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0101 - val_loss: 5.4104\n",
      "Epoch 3952/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0100 - val_loss: 5.4103\n",
      "Epoch 3953/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0098 - val_loss: 5.4102\n",
      "Epoch 3954/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0097 - val_loss: 5.4101\n",
      "Epoch 3955/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0095 - val_loss: 5.4100\n",
      "Epoch 3956/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0094 - val_loss: 5.4099\n",
      "Epoch 3957/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0092 - val_loss: 5.4098\n",
      "Epoch 3958/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0091 - val_loss: 5.4097\n",
      "Epoch 3959/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0090 - val_loss: 5.4096\n",
      "Epoch 3960/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0088 - val_loss: 5.4095\n",
      "Epoch 3961/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0087 - val_loss: 5.4094\n",
      "Epoch 3962/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0085 - val_loss: 5.4093\n",
      "Epoch 3963/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0084 - val_loss: 5.4092\n",
      "Epoch 3964/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0082 - val_loss: 5.4091\n",
      "Epoch 3965/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0081 - val_loss: 5.4090\n",
      "Epoch 3966/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0080 - val_loss: 5.4089\n",
      "Epoch 3967/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0078 - val_loss: 5.4088\n",
      "Epoch 3968/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0077 - val_loss: 5.4087\n",
      "Epoch 3969/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0075 - val_loss: 5.4086\n",
      "Epoch 3970/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0074 - val_loss: 5.4085\n",
      "Epoch 3971/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0072 - val_loss: 5.4084\n",
      "Epoch 3972/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0071 - val_loss: 5.4083\n",
      "Epoch 3973/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0070 - val_loss: 5.4082\n",
      "Epoch 3974/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0068 - val_loss: 5.4080\n",
      "Epoch 3975/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0067 - val_loss: 5.4079\n",
      "Epoch 3976/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0065 - val_loss: 5.4078\n",
      "Epoch 3977/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0064 - val_loss: 5.4077\n",
      "Epoch 3978/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0063 - val_loss: 5.4076\n",
      "Epoch 3979/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0061 - val_loss: 5.4075\n",
      "Epoch 3980/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0060 - val_loss: 5.4074\n",
      "Epoch 3981/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0058 - val_loss: 5.4073\n",
      "Epoch 3982/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0057 - val_loss: 5.4072\n",
      "Epoch 3983/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0055 - val_loss: 5.4071\n",
      "Epoch 3984/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0054 - val_loss: 5.4070\n",
      "Epoch 3985/5000\n",
      "39898/39898 [==============================] - 1s 19us/step - loss: 6.0053 - val_loss: 5.4069\n",
      "Epoch 3986/5000\n",
      "39898/39898 [==============================] - 0s 11us/step - loss: 6.0051 - val_loss: 5.4068\n",
      "Epoch 3987/5000\n",
      "39898/39898 [==============================] - 0s 12us/step - loss: 6.0050 - val_loss: 5.4067\n",
      "Epoch 3988/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 6.0048 - val_loss: 5.4066\n",
      "Epoch 3989/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0047 - val_loss: 5.4065\n",
      "Epoch 3990/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0045 - val_loss: 5.4064\n",
      "Epoch 3991/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0044 - val_loss: 5.4063\n",
      "Epoch 3992/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0043 - val_loss: 5.4062\n",
      "Epoch 3993/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0041 - val_loss: 5.4061\n",
      "Epoch 3994/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0040 - val_loss: 5.4060\n",
      "Epoch 3995/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0038 - val_loss: 5.4059\n",
      "Epoch 3996/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0037 - val_loss: 5.4058\n",
      "Epoch 3997/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0036 - val_loss: 5.4057\n",
      "Epoch 3998/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0034 - val_loss: 5.4056\n",
      "Epoch 3999/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0033 - val_loss: 5.4055\n",
      "Epoch 4000/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0031 - val_loss: 5.4054\n",
      "Epoch 4001/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0030 - val_loss: 5.4053\n",
      "Epoch 4002/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0028 - val_loss: 5.4052\n",
      "Epoch 4003/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0027 - val_loss: 5.4051\n",
      "Epoch 4004/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0026 - val_loss: 5.4050\n",
      "Epoch 4005/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0024 - val_loss: 5.4049\n",
      "Epoch 4006/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0023 - val_loss: 5.4048\n",
      "Epoch 4007/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0021 - val_loss: 5.4046\n",
      "Epoch 4008/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0020 - val_loss: 5.4045\n",
      "Epoch 4009/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0019 - val_loss: 5.4044\n",
      "Epoch 4010/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0017 - val_loss: 5.4043\n",
      "Epoch 4011/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0016 - val_loss: 5.4042\n",
      "Epoch 4012/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0014 - val_loss: 5.4041\n",
      "Epoch 4013/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0013 - val_loss: 5.4040\n",
      "Epoch 4014/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0011 - val_loss: 5.4039\n",
      "Epoch 4015/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0010 - val_loss: 5.4038\n",
      "Epoch 4016/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 6.0009 - val_loss: 5.4037\n",
      "Epoch 4017/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 6.0007 - val_loss: 5.4036\n",
      "Epoch 4018/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0006 - val_loss: 5.4035\n",
      "Epoch 4019/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0004 - val_loss: 5.4034\n",
      "Epoch 4020/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0003 - val_loss: 5.4033\n",
      "Epoch 4021/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0002 - val_loss: 5.4032\n",
      "Epoch 4022/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 6.0000 - val_loss: 5.4031\n",
      "Epoch 4023/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9999 - val_loss: 5.4030\n",
      "Epoch 4024/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9997 - val_loss: 5.4029\n",
      "Epoch 4025/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9996 - val_loss: 5.4028\n",
      "Epoch 4026/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9994 - val_loss: 5.4027\n",
      "Epoch 4027/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9993 - val_loss: 5.4026\n",
      "Epoch 4028/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9992 - val_loss: 5.4025\n",
      "Epoch 4029/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9990 - val_loss: 5.4024\n",
      "Epoch 4030/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9989 - val_loss: 5.4023\n",
      "Epoch 4031/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9987 - val_loss: 5.4022\n",
      "Epoch 4032/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9986 - val_loss: 5.4021\n",
      "Epoch 4033/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9985 - val_loss: 5.4020\n",
      "Epoch 4034/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9983 - val_loss: 5.4019\n",
      "Epoch 4035/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9982 - val_loss: 5.4018\n",
      "Epoch 4036/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9980 - val_loss: 5.4017\n",
      "Epoch 4037/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9979 - val_loss: 5.4016\n",
      "Epoch 4038/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9978 - val_loss: 5.4015\n",
      "Epoch 4039/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9976 - val_loss: 5.4014\n",
      "Epoch 4040/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9975 - val_loss: 5.4013\n",
      "Epoch 4041/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9973 - val_loss: 5.4012\n",
      "Epoch 4042/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9972 - val_loss: 5.4011\n",
      "Epoch 4043/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9970 - val_loss: 5.4010\n",
      "Epoch 4044/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9969 - val_loss: 5.4009\n",
      "Epoch 4045/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9968 - val_loss: 5.4008\n",
      "Epoch 4046/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9966 - val_loss: 5.4007\n",
      "Epoch 4047/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9965 - val_loss: 5.4006\n",
      "Epoch 4048/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9963 - val_loss: 5.4005\n",
      "Epoch 4049/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9962 - val_loss: 5.4004\n",
      "Epoch 4050/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9961 - val_loss: 5.4002\n",
      "Epoch 4051/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9959 - val_loss: 5.4001\n",
      "Epoch 4052/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9958 - val_loss: 5.4000\n",
      "Epoch 4053/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9956 - val_loss: 5.3999\n",
      "Epoch 4054/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 5.9955 - val_loss: 5.3998\n",
      "Epoch 4055/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9954 - val_loss: 5.3997\n",
      "Epoch 4056/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9952 - val_loss: 5.3996\n",
      "Epoch 4057/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9951 - val_loss: 5.3995\n",
      "Epoch 4058/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9949 - val_loss: 5.3994\n",
      "Epoch 4059/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9948 - val_loss: 5.3993\n",
      "Epoch 4060/5000\n",
      "39898/39898 [==============================] - 1s 19us/step - loss: 5.9947 - val_loss: 5.3992\n",
      "Epoch 4061/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9945 - val_loss: 5.3991\n",
      "Epoch 4062/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9944 - val_loss: 5.3990\n",
      "Epoch 4063/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9942 - val_loss: 5.3989\n",
      "Epoch 4064/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9941 - val_loss: 5.3988\n",
      "Epoch 4065/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9940 - val_loss: 5.3987\n",
      "Epoch 4066/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9938 - val_loss: 5.3986\n",
      "Epoch 4067/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9937 - val_loss: 5.3985\n",
      "Epoch 4068/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9935 - val_loss: 5.3984\n",
      "Epoch 4069/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9934 - val_loss: 5.3983\n",
      "Epoch 4070/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9933 - val_loss: 5.3982\n",
      "Epoch 4071/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9931 - val_loss: 5.3981\n",
      "Epoch 4072/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9930 - val_loss: 5.3980\n",
      "Epoch 4073/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9928 - val_loss: 5.3979\n",
      "Epoch 4074/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9927 - val_loss: 5.3978\n",
      "Epoch 4075/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9926 - val_loss: 5.3977\n",
      "Epoch 4076/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9924 - val_loss: 5.3976\n",
      "Epoch 4077/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9923 - val_loss: 5.3975\n",
      "Epoch 4078/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9921 - val_loss: 5.3974\n",
      "Epoch 4079/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9920 - val_loss: 5.3973\n",
      "Epoch 4080/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9918 - val_loss: 5.3972\n",
      "Epoch 4081/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9917 - val_loss: 5.3971\n",
      "Epoch 4082/5000\n",
      "39898/39898 [==============================] - 1s 13us/step - loss: 5.9916 - val_loss: 5.3970\n",
      "Epoch 4083/5000\n",
      "39898/39898 [==============================] - 1s 14us/step - loss: 5.9914 - val_loss: 5.3969\n",
      "Epoch 4084/5000\n",
      "39898/39898 [==============================] - 1s 13us/step - loss: 5.9913 - val_loss: 5.3968\n",
      "Epoch 4085/5000\n",
      "39898/39898 [==============================] - 1s 17us/step - loss: 5.9911 - val_loss: 5.3967\n",
      "Epoch 4086/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9910 - val_loss: 5.3966\n",
      "Epoch 4087/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9909 - val_loss: 5.3965\n",
      "Epoch 4088/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9907 - val_loss: 5.3964\n",
      "Epoch 4089/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9906 - val_loss: 5.3963\n",
      "Epoch 4090/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9904 - val_loss: 5.3962\n",
      "Epoch 4091/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9903 - val_loss: 5.3961\n",
      "Epoch 4092/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9902 - val_loss: 5.3960\n",
      "Epoch 4093/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9900 - val_loss: 5.3959\n",
      "Epoch 4094/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9899 - val_loss: 5.3958\n",
      "Epoch 4095/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9898 - val_loss: 5.3957\n",
      "Epoch 4096/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9896 - val_loss: 5.3956\n",
      "Epoch 4097/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9895 - val_loss: 5.3955\n",
      "Epoch 4098/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9893 - val_loss: 5.3954\n",
      "Epoch 4099/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9892 - val_loss: 5.3953\n",
      "Epoch 4100/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9891 - val_loss: 5.3952\n",
      "Epoch 4101/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9889 - val_loss: 5.3951\n",
      "Epoch 4102/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9888 - val_loss: 5.3950\n",
      "Epoch 4103/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9886 - val_loss: 5.3949\n",
      "Epoch 4104/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9885 - val_loss: 5.3948\n",
      "Epoch 4105/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9884 - val_loss: 5.3947\n",
      "Epoch 4106/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9882 - val_loss: 5.3946\n",
      "Epoch 4107/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9881 - val_loss: 5.3945\n",
      "Epoch 4108/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9879 - val_loss: 5.3944\n",
      "Epoch 4109/5000\n",
      "39898/39898 [==============================] - 0s 12us/step - loss: 5.9878 - val_loss: 5.3943\n",
      "Epoch 4110/5000\n",
      "39898/39898 [==============================] - 0s 12us/step - loss: 5.9877 - val_loss: 5.3942\n",
      "Epoch 4111/5000\n",
      "39898/39898 [==============================] - 1s 13us/step - loss: 5.9875 - val_loss: 5.3941\n",
      "Epoch 4112/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 5.9874 - val_loss: 5.3940\n",
      "Epoch 4113/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9872 - val_loss: 5.3939\n",
      "Epoch 4114/5000\n",
      "39898/39898 [==============================] - 1s 13us/step - loss: 5.9871 - val_loss: 5.3938\n",
      "Epoch 4115/5000\n",
      "39898/39898 [==============================] - 1s 16us/step - loss: 5.9870 - val_loss: 5.3937\n",
      "Epoch 4116/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 5.9868 - val_loss: 5.3936\n",
      "Epoch 4117/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9867 - val_loss: 5.3935\n",
      "Epoch 4118/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9865 - val_loss: 5.3934\n",
      "Epoch 4119/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9864 - val_loss: 5.3933\n",
      "Epoch 4120/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9863 - val_loss: 5.3932\n",
      "Epoch 4121/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9861 - val_loss: 5.3931\n",
      "Epoch 4122/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9860 - val_loss: 5.3930\n",
      "Epoch 4123/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9858 - val_loss: 5.3929\n",
      "Epoch 4124/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9857 - val_loss: 5.3928\n",
      "Epoch 4125/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9856 - val_loss: 5.3927\n",
      "Epoch 4126/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9854 - val_loss: 5.3926\n",
      "Epoch 4127/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9853 - val_loss: 5.3925\n",
      "Epoch 4128/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9851 - val_loss: 5.3924\n",
      "Epoch 4129/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9850 - val_loss: 5.3923\n",
      "Epoch 4130/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9849 - val_loss: 5.3922\n",
      "Epoch 4131/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9847 - val_loss: 5.3921\n",
      "Epoch 4132/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9846 - val_loss: 5.3920\n",
      "Epoch 4133/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9845 - val_loss: 5.3919\n",
      "Epoch 4134/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9843 - val_loss: 5.3918\n",
      "Epoch 4135/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9842 - val_loss: 5.3917\n",
      "Epoch 4136/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9840 - val_loss: 5.3916\n",
      "Epoch 4137/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9839 - val_loss: 5.3915\n",
      "Epoch 4138/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9838 - val_loss: 5.3914\n",
      "Epoch 4139/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9836 - val_loss: 5.3913\n",
      "Epoch 4140/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9835 - val_loss: 5.3912\n",
      "Epoch 4141/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9833 - val_loss: 5.3911\n",
      "Epoch 4142/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9832 - val_loss: 5.3910\n",
      "Epoch 4143/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9831 - val_loss: 5.3909\n",
      "Epoch 4144/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9829 - val_loss: 5.3908\n",
      "Epoch 4145/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9828 - val_loss: 5.3907\n",
      "Epoch 4146/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9826 - val_loss: 5.3906\n",
      "Epoch 4147/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9825 - val_loss: 5.3905\n",
      "Epoch 4148/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9824 - val_loss: 5.3904\n",
      "Epoch 4149/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9822 - val_loss: 5.3903\n",
      "Epoch 4150/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9821 - val_loss: 5.3902\n",
      "Epoch 4151/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9820 - val_loss: 5.3901\n",
      "Epoch 4152/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9818 - val_loss: 5.3900\n",
      "Epoch 4153/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9817 - val_loss: 5.3899\n",
      "Epoch 4154/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9815 - val_loss: 5.3898\n",
      "Epoch 4155/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9814 - val_loss: 5.3897\n",
      "Epoch 4156/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9813 - val_loss: 5.3896\n",
      "Epoch 4157/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9811 - val_loss: 5.3895\n",
      "Epoch 4158/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9810 - val_loss: 5.3894\n",
      "Epoch 4159/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9808 - val_loss: 5.3893\n",
      "Epoch 4160/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9807 - val_loss: 5.3892\n",
      "Epoch 4161/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9806 - val_loss: 5.3891\n",
      "Epoch 4162/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9804 - val_loss: 5.3890\n",
      "Epoch 4163/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9803 - val_loss: 5.3889\n",
      "Epoch 4164/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9802 - val_loss: 5.3888\n",
      "Epoch 4165/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9800 - val_loss: 5.3887\n",
      "Epoch 4166/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9799 - val_loss: 5.3886\n",
      "Epoch 4167/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9797 - val_loss: 5.3885\n",
      "Epoch 4168/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9796 - val_loss: 5.3884\n",
      "Epoch 4169/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9795 - val_loss: 5.3883\n",
      "Epoch 4170/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9793 - val_loss: 5.3882\n",
      "Epoch 4171/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9792 - val_loss: 5.3881\n",
      "Epoch 4172/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9790 - val_loss: 5.3880\n",
      "Epoch 4173/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9789 - val_loss: 5.3879\n",
      "Epoch 4174/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9788 - val_loss: 5.3878\n",
      "Epoch 4175/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9786 - val_loss: 5.3877\n",
      "Epoch 4176/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9785 - val_loss: 5.3876\n",
      "Epoch 4177/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9784 - val_loss: 5.3875\n",
      "Epoch 4178/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9782 - val_loss: 5.3874\n",
      "Epoch 4179/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9781 - val_loss: 5.3873\n",
      "Epoch 4180/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9779 - val_loss: 5.3872\n",
      "Epoch 4181/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9778 - val_loss: 5.3871\n",
      "Epoch 4182/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9777 - val_loss: 5.3870\n",
      "Epoch 4183/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9775 - val_loss: 5.3869\n",
      "Epoch 4184/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9774 - val_loss: 5.3868\n",
      "Epoch 4185/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9773 - val_loss: 5.3867\n",
      "Epoch 4186/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9771 - val_loss: 5.3866\n",
      "Epoch 4187/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9770 - val_loss: 5.3865\n",
      "Epoch 4188/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9768 - val_loss: 5.3864\n",
      "Epoch 4189/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9767 - val_loss: 5.3863\n",
      "Epoch 4190/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9766 - val_loss: 5.3862\n",
      "Epoch 4191/5000\n",
      "39898/39898 [==============================] - 1s 19us/step - loss: 5.9764 - val_loss: 5.3861\n",
      "Epoch 4192/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 5.9763 - val_loss: 5.3860\n",
      "Epoch 4193/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 5.9761 - val_loss: 5.3859\n",
      "Epoch 4194/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 5.9760 - val_loss: 5.3858\n",
      "Epoch 4195/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9759 - val_loss: 5.3857\n",
      "Epoch 4196/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9757 - val_loss: 5.3856\n",
      "Epoch 4197/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9756 - val_loss: 5.3855\n",
      "Epoch 4198/5000\n",
      "39898/39898 [==============================] - 1s 19us/step - loss: 5.9755 - val_loss: 5.3854\n",
      "Epoch 4199/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9753 - val_loss: 5.3853\n",
      "Epoch 4200/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9752 - val_loss: 5.3852\n",
      "Epoch 4201/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9750 - val_loss: 5.3851\n",
      "Epoch 4202/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9749 - val_loss: 5.3850\n",
      "Epoch 4203/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9748 - val_loss: 5.3849\n",
      "Epoch 4204/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9746 - val_loss: 5.3848\n",
      "Epoch 4205/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9745 - val_loss: 5.3847\n",
      "Epoch 4206/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9744 - val_loss: 5.3846\n",
      "Epoch 4207/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9742 - val_loss: 5.3845\n",
      "Epoch 4208/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9741 - val_loss: 5.3844\n",
      "Epoch 4209/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9739 - val_loss: 5.3843\n",
      "Epoch 4210/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9738 - val_loss: 5.3842\n",
      "Epoch 4211/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9737 - val_loss: 5.3841\n",
      "Epoch 4212/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9735 - val_loss: 5.3840\n",
      "Epoch 4213/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9734 - val_loss: 5.3839\n",
      "Epoch 4214/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9733 - val_loss: 5.3838\n",
      "Epoch 4215/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9731 - val_loss: 5.3837\n",
      "Epoch 4216/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9730 - val_loss: 5.3836\n",
      "Epoch 4217/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9728 - val_loss: 5.3835\n",
      "Epoch 4218/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9727 - val_loss: 5.3834\n",
      "Epoch 4219/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9726 - val_loss: 5.3833\n",
      "Epoch 4220/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9724 - val_loss: 5.3832\n",
      "Epoch 4221/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9723 - val_loss: 5.3831\n",
      "Epoch 4222/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9722 - val_loss: 5.3830\n",
      "Epoch 4223/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9720 - val_loss: 5.3829\n",
      "Epoch 4224/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9719 - val_loss: 5.3828\n",
      "Epoch 4225/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9717 - val_loss: 5.3827\n",
      "Epoch 4226/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9716 - val_loss: 5.3826\n",
      "Epoch 4227/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9715 - val_loss: 5.3825\n",
      "Epoch 4228/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9713 - val_loss: 5.3824\n",
      "Epoch 4229/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9712 - val_loss: 5.3823\n",
      "Epoch 4230/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9711 - val_loss: 5.3822\n",
      "Epoch 4231/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9709 - val_loss: 5.3821\n",
      "Epoch 4232/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9708 - val_loss: 5.3820\n",
      "Epoch 4233/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9707 - val_loss: 5.3819\n",
      "Epoch 4234/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9705 - val_loss: 5.3818\n",
      "Epoch 4235/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9704 - val_loss: 5.3817\n",
      "Epoch 4236/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9702 - val_loss: 5.3816\n",
      "Epoch 4237/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9701 - val_loss: 5.3815\n",
      "Epoch 4238/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9700 - val_loss: 5.3814\n",
      "Epoch 4239/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9698 - val_loss: 5.3813\n",
      "Epoch 4240/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9697 - val_loss: 5.3812\n",
      "Epoch 4241/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9696 - val_loss: 5.3811\n",
      "Epoch 4242/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9694 - val_loss: 5.3810\n",
      "Epoch 4243/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9693 - val_loss: 5.3809\n",
      "Epoch 4244/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9691 - val_loss: 5.3808\n",
      "Epoch 4245/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9690 - val_loss: 5.3807\n",
      "Epoch 4246/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9689 - val_loss: 5.3806\n",
      "Epoch 4247/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9687 - val_loss: 5.3805\n",
      "Epoch 4248/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9686 - val_loss: 5.3804\n",
      "Epoch 4249/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9685 - val_loss: 5.3803\n",
      "Epoch 4250/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9683 - val_loss: 5.3802\n",
      "Epoch 4251/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9682 - val_loss: 5.3802\n",
      "Epoch 4252/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9681 - val_loss: 5.3801\n",
      "Epoch 4253/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 5.9679 - val_loss: 5.3800\n",
      "Epoch 4254/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9678 - val_loss: 5.3799\n",
      "Epoch 4255/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9676 - val_loss: 5.3798\n",
      "Epoch 4256/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9675 - val_loss: 5.3797\n",
      "Epoch 4257/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9674 - val_loss: 5.3796\n",
      "Epoch 4258/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9672 - val_loss: 5.3795\n",
      "Epoch 4259/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9671 - val_loss: 5.3794\n",
      "Epoch 4260/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9670 - val_loss: 5.3793\n",
      "Epoch 4261/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9668 - val_loss: 5.3792\n",
      "Epoch 4262/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9667 - val_loss: 5.3791\n",
      "Epoch 4263/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9665 - val_loss: 5.3790\n",
      "Epoch 4264/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9664 - val_loss: 5.3789\n",
      "Epoch 4265/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9663 - val_loss: 5.3788\n",
      "Epoch 4266/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9661 - val_loss: 5.3787\n",
      "Epoch 4267/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9660 - val_loss: 5.3786\n",
      "Epoch 4268/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9659 - val_loss: 5.3785\n",
      "Epoch 4269/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9657 - val_loss: 5.3784\n",
      "Epoch 4270/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9656 - val_loss: 5.3783\n",
      "Epoch 4271/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9655 - val_loss: 5.3782\n",
      "Epoch 4272/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 5.9653 - val_loss: 5.3781\n",
      "Epoch 4273/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9652 - val_loss: 5.3780\n",
      "Epoch 4274/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9651 - val_loss: 5.3779\n",
      "Epoch 4275/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9649 - val_loss: 5.3778\n",
      "Epoch 4276/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9648 - val_loss: 5.3777\n",
      "Epoch 4277/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9646 - val_loss: 5.3776\n",
      "Epoch 4278/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9645 - val_loss: 5.3775\n",
      "Epoch 4279/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9644 - val_loss: 5.3774\n",
      "Epoch 4280/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9642 - val_loss: 5.3773\n",
      "Epoch 4281/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9641 - val_loss: 5.3772\n",
      "Epoch 4282/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9640 - val_loss: 5.3771\n",
      "Epoch 4283/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9638 - val_loss: 5.3770\n",
      "Epoch 4284/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9637 - val_loss: 5.3769\n",
      "Epoch 4285/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9636 - val_loss: 5.3768\n",
      "Epoch 4286/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9634 - val_loss: 5.3767\n",
      "Epoch 4287/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 5.9633 - val_loss: 5.3766\n",
      "Epoch 4288/5000\n",
      "39898/39898 [==============================] - 1s 19us/step - loss: 5.9631 - val_loss: 5.3765\n",
      "Epoch 4289/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9630 - val_loss: 5.3764\n",
      "Epoch 4290/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9629 - val_loss: 5.3763\n",
      "Epoch 4291/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9627 - val_loss: 5.3762\n",
      "Epoch 4292/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9626 - val_loss: 5.3761\n",
      "Epoch 4293/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9625 - val_loss: 5.3760\n",
      "Epoch 4294/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9623 - val_loss: 5.3759\n",
      "Epoch 4295/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9622 - val_loss: 5.3758\n",
      "Epoch 4296/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9621 - val_loss: 5.3758\n",
      "Epoch 4297/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9619 - val_loss: 5.3757\n",
      "Epoch 4298/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9618 - val_loss: 5.3756\n",
      "Epoch 4299/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9617 - val_loss: 5.3755\n",
      "Epoch 4300/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9615 - val_loss: 5.3754\n",
      "Epoch 4301/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9614 - val_loss: 5.3753\n",
      "Epoch 4302/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9612 - val_loss: 5.3752\n",
      "Epoch 4303/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9611 - val_loss: 5.3751\n",
      "Epoch 4304/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9610 - val_loss: 5.3750\n",
      "Epoch 4305/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9608 - val_loss: 5.3749\n",
      "Epoch 4306/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9607 - val_loss: 5.3748\n",
      "Epoch 4307/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9606 - val_loss: 5.3747\n",
      "Epoch 4308/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9604 - val_loss: 5.3746\n",
      "Epoch 4309/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 5.9603 - val_loss: 5.3745\n",
      "Epoch 4310/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9602 - val_loss: 5.3744\n",
      "Epoch 4311/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9600 - val_loss: 5.3743\n",
      "Epoch 4312/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9599 - val_loss: 5.3742\n",
      "Epoch 4313/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9598 - val_loss: 5.3741\n",
      "Epoch 4314/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9596 - val_loss: 5.3740\n",
      "Epoch 4315/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9595 - val_loss: 5.3739\n",
      "Epoch 4316/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9593 - val_loss: 5.3738\n",
      "Epoch 4317/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9592 - val_loss: 5.3737\n",
      "Epoch 4318/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9591 - val_loss: 5.3736\n",
      "Epoch 4319/5000\n",
      "39898/39898 [==============================] - ETA: 0s - loss: 5.668 - 1s 22us/step - loss: 5.9589 - val_loss: 5.3735\n",
      "Epoch 4320/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9588 - val_loss: 5.3734\n",
      "Epoch 4321/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9587 - val_loss: 5.3733\n",
      "Epoch 4322/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9585 - val_loss: 5.3732\n",
      "Epoch 4323/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9584 - val_loss: 5.3731\n",
      "Epoch 4324/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9583 - val_loss: 5.3730\n",
      "Epoch 4325/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9581 - val_loss: 5.3729\n",
      "Epoch 4326/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9580 - val_loss: 5.3728\n",
      "Epoch 4327/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9579 - val_loss: 5.3727\n",
      "Epoch 4328/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9577 - val_loss: 5.3726\n",
      "Epoch 4329/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9576 - val_loss: 5.3725\n",
      "Epoch 4330/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9575 - val_loss: 5.3725\n",
      "Epoch 4331/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9573 - val_loss: 5.3724\n",
      "Epoch 4332/5000\n",
      "39898/39898 [==============================] - 1s 16us/step - loss: 5.9572 - val_loss: 5.3723\n",
      "Epoch 4333/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9570 - val_loss: 5.3722\n",
      "Epoch 4334/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9569 - val_loss: 5.3721\n",
      "Epoch 4335/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9568 - val_loss: 5.3720\n",
      "Epoch 4336/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9566 - val_loss: 5.3719\n",
      "Epoch 4337/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9565 - val_loss: 5.3718\n",
      "Epoch 4338/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9564 - val_loss: 5.3717\n",
      "Epoch 4339/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 5.9562 - val_loss: 5.3716\n",
      "Epoch 4340/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9561 - val_loss: 5.3715\n",
      "Epoch 4341/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9560 - val_loss: 5.3714\n",
      "Epoch 4342/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9558 - val_loss: 5.3713\n",
      "Epoch 4343/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9557 - val_loss: 5.3712\n",
      "Epoch 4344/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9556 - val_loss: 5.3711\n",
      "Epoch 4345/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9554 - val_loss: 5.3710\n",
      "Epoch 4346/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9553 - val_loss: 5.3709\n",
      "Epoch 4347/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9552 - val_loss: 5.3708\n",
      "Epoch 4348/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9550 - val_loss: 5.3707\n",
      "Epoch 4349/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9549 - val_loss: 5.3706\n",
      "Epoch 4350/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9548 - val_loss: 5.3705\n",
      "Epoch 4351/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9546 - val_loss: 5.3704\n",
      "Epoch 4352/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9545 - val_loss: 5.3703\n",
      "Epoch 4353/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9543 - val_loss: 5.3702\n",
      "Epoch 4354/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9542 - val_loss: 5.3701\n",
      "Epoch 4355/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9541 - val_loss: 5.3700\n",
      "Epoch 4356/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9539 - val_loss: 5.3699\n",
      "Epoch 4357/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9538 - val_loss: 5.3698\n",
      "Epoch 4358/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9537 - val_loss: 5.3697\n",
      "Epoch 4359/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9535 - val_loss: 5.3697\n",
      "Epoch 4360/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9534 - val_loss: 5.3696\n",
      "Epoch 4361/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9533 - val_loss: 5.3695\n",
      "Epoch 4362/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9531 - val_loss: 5.3694\n",
      "Epoch 4363/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9530 - val_loss: 5.3693\n",
      "Epoch 4364/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9529 - val_loss: 5.3692\n",
      "Epoch 4365/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9527 - val_loss: 5.3691\n",
      "Epoch 4366/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9526 - val_loss: 5.3690\n",
      "Epoch 4367/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9525 - val_loss: 5.3689\n",
      "Epoch 4368/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9523 - val_loss: 5.3688\n",
      "Epoch 4369/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9522 - val_loss: 5.3687\n",
      "Epoch 4370/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9521 - val_loss: 5.3686\n",
      "Epoch 4371/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9519 - val_loss: 5.3685\n",
      "Epoch 4372/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9518 - val_loss: 5.3684\n",
      "Epoch 4373/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9517 - val_loss: 5.3683\n",
      "Epoch 4374/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9515 - val_loss: 5.3682\n",
      "Epoch 4375/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9514 - val_loss: 5.3681\n",
      "Epoch 4376/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9513 - val_loss: 5.3680\n",
      "Epoch 4377/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9511 - val_loss: 5.3679\n",
      "Epoch 4378/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9510 - val_loss: 5.3678\n",
      "Epoch 4379/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9509 - val_loss: 5.3677\n",
      "Epoch 4380/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9507 - val_loss: 5.3676\n",
      "Epoch 4381/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9506 - val_loss: 5.3675\n",
      "Epoch 4382/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9504 - val_loss: 5.3674\n",
      "Epoch 4383/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9503 - val_loss: 5.3673\n",
      "Epoch 4384/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9502 - val_loss: 5.3673\n",
      "Epoch 4385/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9500 - val_loss: 5.3672\n",
      "Epoch 4386/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9499 - val_loss: 5.3671\n",
      "Epoch 4387/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9498 - val_loss: 5.3670\n",
      "Epoch 4388/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9496 - val_loss: 5.3669\n",
      "Epoch 4389/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9495 - val_loss: 5.3668\n",
      "Epoch 4390/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9494 - val_loss: 5.3667\n",
      "Epoch 4391/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9492 - val_loss: 5.3666\n",
      "Epoch 4392/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9491 - val_loss: 5.3665\n",
      "Epoch 4393/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9490 - val_loss: 5.3664\n",
      "Epoch 4394/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9488 - val_loss: 5.3663\n",
      "Epoch 4395/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9487 - val_loss: 5.3662\n",
      "Epoch 4396/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9486 - val_loss: 5.3661\n",
      "Epoch 4397/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9484 - val_loss: 5.3660\n",
      "Epoch 4398/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9483 - val_loss: 5.3659\n",
      "Epoch 4399/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9482 - val_loss: 5.3658\n",
      "Epoch 4400/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9480 - val_loss: 5.3657\n",
      "Epoch 4401/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9479 - val_loss: 5.3656\n",
      "Epoch 4402/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9478 - val_loss: 5.3655\n",
      "Epoch 4403/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9476 - val_loss: 5.3654\n",
      "Epoch 4404/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9475 - val_loss: 5.3653\n",
      "Epoch 4405/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9474 - val_loss: 5.3652\n",
      "Epoch 4406/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9472 - val_loss: 5.3651\n",
      "Epoch 4407/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9471 - val_loss: 5.3651\n",
      "Epoch 4408/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9470 - val_loss: 5.3650\n",
      "Epoch 4409/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9468 - val_loss: 5.3649\n",
      "Epoch 4410/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9467 - val_loss: 5.3648\n",
      "Epoch 4411/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9466 - val_loss: 5.3647\n",
      "Epoch 4412/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9464 - val_loss: 5.3646\n",
      "Epoch 4413/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9463 - val_loss: 5.3645\n",
      "Epoch 4414/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9462 - val_loss: 5.3644\n",
      "Epoch 4415/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9460 - val_loss: 5.3643\n",
      "Epoch 4416/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9459 - val_loss: 5.3642\n",
      "Epoch 4417/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9458 - val_loss: 5.3641\n",
      "Epoch 4418/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9456 - val_loss: 5.3640\n",
      "Epoch 4419/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9455 - val_loss: 5.3639\n",
      "Epoch 4420/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9454 - val_loss: 5.3638\n",
      "Epoch 4421/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9452 - val_loss: 5.3637\n",
      "Epoch 4422/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9451 - val_loss: 5.3636\n",
      "Epoch 4423/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9450 - val_loss: 5.3635\n",
      "Epoch 4424/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9448 - val_loss: 5.3634\n",
      "Epoch 4425/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9447 - val_loss: 5.3633\n",
      "Epoch 4426/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9446 - val_loss: 5.3632\n",
      "Epoch 4427/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9444 - val_loss: 5.3631\n",
      "Epoch 4428/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9443 - val_loss: 5.3630\n",
      "Epoch 4429/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9442 - val_loss: 5.3630\n",
      "Epoch 4430/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9440 - val_loss: 5.3629\n",
      "Epoch 4431/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9439 - val_loss: 5.3628\n",
      "Epoch 4432/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9438 - val_loss: 5.3627\n",
      "Epoch 4433/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9436 - val_loss: 5.3626\n",
      "Epoch 4434/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9435 - val_loss: 5.3625\n",
      "Epoch 4435/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9434 - val_loss: 5.3624\n",
      "Epoch 4436/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9432 - val_loss: 5.3623\n",
      "Epoch 4437/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9431 - val_loss: 5.3622\n",
      "Epoch 4438/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9430 - val_loss: 5.3621\n",
      "Epoch 4439/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9428 - val_loss: 5.3620\n",
      "Epoch 4440/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9427 - val_loss: 5.3619\n",
      "Epoch 4441/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9426 - val_loss: 5.3618\n",
      "Epoch 4442/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9424 - val_loss: 5.3617\n",
      "Epoch 4443/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9423 - val_loss: 5.3616\n",
      "Epoch 4444/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9422 - val_loss: 5.3615\n",
      "Epoch 4445/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9420 - val_loss: 5.3614\n",
      "Epoch 4446/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9419 - val_loss: 5.3613\n",
      "Epoch 4447/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9418 - val_loss: 5.3612\n",
      "Epoch 4448/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9416 - val_loss: 5.3611\n",
      "Epoch 4449/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9415 - val_loss: 5.3611\n",
      "Epoch 4450/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9414 - val_loss: 5.3610\n",
      "Epoch 4451/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9412 - val_loss: 5.3609\n",
      "Epoch 4452/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9411 - val_loss: 5.3608\n",
      "Epoch 4453/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9410 - val_loss: 5.3607\n",
      "Epoch 4454/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9408 - val_loss: 5.3606\n",
      "Epoch 4455/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9407 - val_loss: 5.3605\n",
      "Epoch 4456/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 5.9406 - val_loss: 5.3604\n",
      "Epoch 4457/5000\n",
      "39898/39898 [==============================] - 1s 18us/step - loss: 5.9404 - val_loss: 5.3603\n",
      "Epoch 4458/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9403 - val_loss: 5.3602\n",
      "Epoch 4459/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9402 - val_loss: 5.3601\n",
      "Epoch 4460/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9400 - val_loss: 5.3600\n",
      "Epoch 4461/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9399 - val_loss: 5.3599\n",
      "Epoch 4462/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9398 - val_loss: 5.3598\n",
      "Epoch 4463/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9396 - val_loss: 5.3597\n",
      "Epoch 4464/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9395 - val_loss: 5.3596\n",
      "Epoch 4465/5000\n",
      "39898/39898 [==============================] - 1s 19us/step - loss: 5.9394 - val_loss: 5.3595\n",
      "Epoch 4466/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9392 - val_loss: 5.3594\n",
      "Epoch 4467/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9391 - val_loss: 5.3594\n",
      "Epoch 4468/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9390 - val_loss: 5.3593\n",
      "Epoch 4469/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9388 - val_loss: 5.3592\n",
      "Epoch 4470/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9387 - val_loss: 5.3591\n",
      "Epoch 4471/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9386 - val_loss: 5.3590\n",
      "Epoch 4472/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 5.9384 - val_loss: 5.3589\n",
      "Epoch 4473/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9383 - val_loss: 5.3588\n",
      "Epoch 4474/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9382 - val_loss: 5.3587\n",
      "Epoch 4475/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9381 - val_loss: 5.3586\n",
      "Epoch 4476/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9379 - val_loss: 5.3585\n",
      "Epoch 4477/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9378 - val_loss: 5.3584\n",
      "Epoch 4478/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9377 - val_loss: 5.3583\n",
      "Epoch 4479/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9375 - val_loss: 5.3582\n",
      "Epoch 4480/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9374 - val_loss: 5.3581\n",
      "Epoch 4481/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9373 - val_loss: 5.3580\n",
      "Epoch 4482/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9371 - val_loss: 5.3579\n",
      "Epoch 4483/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9370 - val_loss: 5.3578\n",
      "Epoch 4484/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9369 - val_loss: 5.3577\n",
      "Epoch 4485/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9367 - val_loss: 5.3577\n",
      "Epoch 4486/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9366 - val_loss: 5.3576\n",
      "Epoch 4487/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9365 - val_loss: 5.3575\n",
      "Epoch 4488/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9363 - val_loss: 5.3574\n",
      "Epoch 4489/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9362 - val_loss: 5.3573\n",
      "Epoch 4490/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9361 - val_loss: 5.3572\n",
      "Epoch 4491/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9359 - val_loss: 5.3571\n",
      "Epoch 4492/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9358 - val_loss: 5.3570\n",
      "Epoch 4493/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9357 - val_loss: 5.3569\n",
      "Epoch 4494/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9355 - val_loss: 5.3568\n",
      "Epoch 4495/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9354 - val_loss: 5.3567\n",
      "Epoch 4496/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9353 - val_loss: 5.3566\n",
      "Epoch 4497/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9351 - val_loss: 5.3565\n",
      "Epoch 4498/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9350 - val_loss: 5.3564\n",
      "Epoch 4499/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9349 - val_loss: 5.3563\n",
      "Epoch 4500/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9347 - val_loss: 5.3562\n",
      "Epoch 4501/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9346 - val_loss: 5.3561\n",
      "Epoch 4502/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9345 - val_loss: 5.3561\n",
      "Epoch 4503/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9343 - val_loss: 5.3560\n",
      "Epoch 4504/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9342 - val_loss: 5.3559\n",
      "Epoch 4505/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9341 - val_loss: 5.3558\n",
      "Epoch 4506/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9340 - val_loss: 5.3557\n",
      "Epoch 4507/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9338 - val_loss: 5.3556\n",
      "Epoch 4508/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9337 - val_loss: 5.3555\n",
      "Epoch 4509/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9336 - val_loss: 5.3554\n",
      "Epoch 4510/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9334 - val_loss: 5.3553\n",
      "Epoch 4511/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9333 - val_loss: 5.3552\n",
      "Epoch 4512/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9332 - val_loss: 5.3551\n",
      "Epoch 4513/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9330 - val_loss: 5.3550\n",
      "Epoch 4514/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9329 - val_loss: 5.3549\n",
      "Epoch 4515/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9328 - val_loss: 5.3548\n",
      "Epoch 4516/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9326 - val_loss: 5.3547\n",
      "Epoch 4517/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9325 - val_loss: 5.3546\n",
      "Epoch 4518/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9324 - val_loss: 5.3546\n",
      "Epoch 4519/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9322 - val_loss: 5.3545\n",
      "Epoch 4520/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9321 - val_loss: 5.3544\n",
      "Epoch 4521/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9320 - val_loss: 5.3543\n",
      "Epoch 4522/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9318 - val_loss: 5.3542\n",
      "Epoch 4523/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9317 - val_loss: 5.3541\n",
      "Epoch 4524/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9316 - val_loss: 5.3540\n",
      "Epoch 4525/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9314 - val_loss: 5.3539\n",
      "Epoch 4526/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9313 - val_loss: 5.3538\n",
      "Epoch 4527/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9312 - val_loss: 5.3537\n",
      "Epoch 4528/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9311 - val_loss: 5.3536\n",
      "Epoch 4529/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9309 - val_loss: 5.3535\n",
      "Epoch 4530/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9308 - val_loss: 5.3534\n",
      "Epoch 4531/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9307 - val_loss: 5.3533\n",
      "Epoch 4532/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9305 - val_loss: 5.3532\n",
      "Epoch 4533/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9304 - val_loss: 5.3531\n",
      "Epoch 4534/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9303 - val_loss: 5.3531\n",
      "Epoch 4535/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9301 - val_loss: 5.3530\n",
      "Epoch 4536/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9300 - val_loss: 5.3529\n",
      "Epoch 4537/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9299 - val_loss: 5.3528\n",
      "Epoch 4538/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9297 - val_loss: 5.3527\n",
      "Epoch 4539/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9296 - val_loss: 5.3526\n",
      "Epoch 4540/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9295 - val_loss: 5.3525\n",
      "Epoch 4541/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9293 - val_loss: 5.3524\n",
      "Epoch 4542/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9292 - val_loss: 5.3523\n",
      "Epoch 4543/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9291 - val_loss: 5.3522\n",
      "Epoch 4544/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9290 - val_loss: 5.3521\n",
      "Epoch 4545/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9288 - val_loss: 5.3520\n",
      "Epoch 4546/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9287 - val_loss: 5.3519\n",
      "Epoch 4547/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9286 - val_loss: 5.3518\n",
      "Epoch 4548/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9284 - val_loss: 5.3517\n",
      "Epoch 4549/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9283 - val_loss: 5.3517\n",
      "Epoch 4550/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9282 - val_loss: 5.3516\n",
      "Epoch 4551/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9280 - val_loss: 5.3515\n",
      "Epoch 4552/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9279 - val_loss: 5.3514\n",
      "Epoch 4553/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9278 - val_loss: 5.3513\n",
      "Epoch 4554/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9276 - val_loss: 5.3512\n",
      "Epoch 4555/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9275 - val_loss: 5.3511\n",
      "Epoch 4556/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9274 - val_loss: 5.3510\n",
      "Epoch 4557/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9272 - val_loss: 5.3509\n",
      "Epoch 4558/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9271 - val_loss: 5.3508\n",
      "Epoch 4559/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9270 - val_loss: 5.3507\n",
      "Epoch 4560/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9269 - val_loss: 5.3506\n",
      "Epoch 4561/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9267 - val_loss: 5.3505\n",
      "Epoch 4562/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9266 - val_loss: 5.3504\n",
      "Epoch 4563/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9265 - val_loss: 5.3504\n",
      "Epoch 4564/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9263 - val_loss: 5.3503\n",
      "Epoch 4565/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9262 - val_loss: 5.3502\n",
      "Epoch 4566/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9261 - val_loss: 5.3501\n",
      "Epoch 4567/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9259 - val_loss: 5.3500\n",
      "Epoch 4568/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9258 - val_loss: 5.3499\n",
      "Epoch 4569/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9257 - val_loss: 5.3498\n",
      "Epoch 4570/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9255 - val_loss: 5.3497\n",
      "Epoch 4571/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9254 - val_loss: 5.3496\n",
      "Epoch 4572/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9253 - val_loss: 5.3495\n",
      "Epoch 4573/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9252 - val_loss: 5.3494\n",
      "Epoch 4574/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9250 - val_loss: 5.3493\n",
      "Epoch 4575/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9249 - val_loss: 5.3492\n",
      "Epoch 4576/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9248 - val_loss: 5.3491\n",
      "Epoch 4577/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9246 - val_loss: 5.3491\n",
      "Epoch 4578/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9245 - val_loss: 5.3490\n",
      "Epoch 4579/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9244 - val_loss: 5.3489\n",
      "Epoch 4580/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9242 - val_loss: 5.3488\n",
      "Epoch 4581/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9241 - val_loss: 5.3487\n",
      "Epoch 4582/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9240 - val_loss: 5.3486\n",
      "Epoch 4583/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9238 - val_loss: 5.3485\n",
      "Epoch 4584/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9237 - val_loss: 5.3484\n",
      "Epoch 4585/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9236 - val_loss: 5.3483\n",
      "Epoch 4586/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9235 - val_loss: 5.3482\n",
      "Epoch 4587/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9233 - val_loss: 5.3481\n",
      "Epoch 4588/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9232 - val_loss: 5.3480\n",
      "Epoch 4589/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9231 - val_loss: 5.3479\n",
      "Epoch 4590/5000\n",
      "39898/39898 [==============================] - 1s 18us/step - loss: 5.9229 - val_loss: 5.3478\n",
      "Epoch 4591/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9228 - val_loss: 5.3478\n",
      "Epoch 4592/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9227 - val_loss: 5.3477\n",
      "Epoch 4593/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9225 - val_loss: 5.3476\n",
      "Epoch 4594/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9224 - val_loss: 5.3475\n",
      "Epoch 4595/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9223 - val_loss: 5.3474\n",
      "Epoch 4596/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9221 - val_loss: 5.3473\n",
      "Epoch 4597/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9220 - val_loss: 5.3472\n",
      "Epoch 4598/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 5.9219 - val_loss: 5.3471\n",
      "Epoch 4599/5000\n",
      "39898/39898 [==============================] - 1s 19us/step - loss: 5.9218 - val_loss: 5.3470\n",
      "Epoch 4600/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9216 - val_loss: 5.3469\n",
      "Epoch 4601/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9215 - val_loss: 5.3468\n",
      "Epoch 4602/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9214 - val_loss: 5.3467\n",
      "Epoch 4603/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9212 - val_loss: 5.3466\n",
      "Epoch 4604/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9211 - val_loss: 5.3466\n",
      "Epoch 4605/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9210 - val_loss: 5.3465\n",
      "Epoch 4606/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9208 - val_loss: 5.3464\n",
      "Epoch 4607/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9207 - val_loss: 5.3463\n",
      "Epoch 4608/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9206 - val_loss: 5.3462\n",
      "Epoch 4609/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9205 - val_loss: 5.3461\n",
      "Epoch 4610/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9203 - val_loss: 5.3460\n",
      "Epoch 4611/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9202 - val_loss: 5.3459\n",
      "Epoch 4612/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9201 - val_loss: 5.3458\n",
      "Epoch 4613/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9199 - val_loss: 5.3457\n",
      "Epoch 4614/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9198 - val_loss: 5.3456\n",
      "Epoch 4615/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9197 - val_loss: 5.3455\n",
      "Epoch 4616/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9195 - val_loss: 5.3454\n",
      "Epoch 4617/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9194 - val_loss: 5.3454\n",
      "Epoch 4618/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9193 - val_loss: 5.3453\n",
      "Epoch 4619/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9192 - val_loss: 5.3452\n",
      "Epoch 4620/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9190 - val_loss: 5.3451\n",
      "Epoch 4621/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9189 - val_loss: 5.3450\n",
      "Epoch 4622/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9188 - val_loss: 5.3449\n",
      "Epoch 4623/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9186 - val_loss: 5.3448\n",
      "Epoch 4624/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9185 - val_loss: 5.3447\n",
      "Epoch 4625/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9184 - val_loss: 5.3446\n",
      "Epoch 4626/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9182 - val_loss: 5.3445\n",
      "Epoch 4627/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9181 - val_loss: 5.3444\n",
      "Epoch 4628/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9180 - val_loss: 5.3443\n",
      "Epoch 4629/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9179 - val_loss: 5.3442\n",
      "Epoch 4630/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9177 - val_loss: 5.3442\n",
      "Epoch 4631/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9176 - val_loss: 5.3441\n",
      "Epoch 4632/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9175 - val_loss: 5.3440\n",
      "Epoch 4633/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9173 - val_loss: 5.3439\n",
      "Epoch 4634/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9172 - val_loss: 5.3438\n",
      "Epoch 4635/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9171 - val_loss: 5.3437\n",
      "Epoch 4636/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9169 - val_loss: 5.3436\n",
      "Epoch 4637/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9168 - val_loss: 5.3435\n",
      "Epoch 4638/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9167 - val_loss: 5.3434\n",
      "Epoch 4639/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9166 - val_loss: 5.3433\n",
      "Epoch 4640/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9164 - val_loss: 5.3432\n",
      "Epoch 4641/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9163 - val_loss: 5.3431\n",
      "Epoch 4642/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9162 - val_loss: 5.3431\n",
      "Epoch 4643/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9160 - val_loss: 5.3430\n",
      "Epoch 4644/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9159 - val_loss: 5.3429\n",
      "Epoch 4645/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9158 - val_loss: 5.3428\n",
      "Epoch 4646/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9157 - val_loss: 5.3427\n",
      "Epoch 4647/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9155 - val_loss: 5.3426\n",
      "Epoch 4648/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9154 - val_loss: 5.3425\n",
      "Epoch 4649/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9153 - val_loss: 5.3424\n",
      "Epoch 4650/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9151 - val_loss: 5.3423\n",
      "Epoch 4651/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9150 - val_loss: 5.3422\n",
      "Epoch 4652/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9149 - val_loss: 5.3421\n",
      "Epoch 4653/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9147 - val_loss: 5.3420\n",
      "Epoch 4654/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9146 - val_loss: 5.3420\n",
      "Epoch 4655/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9145 - val_loss: 5.3419\n",
      "Epoch 4656/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9144 - val_loss: 5.3418\n",
      "Epoch 4657/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9142 - val_loss: 5.3417\n",
      "Epoch 4658/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9141 - val_loss: 5.3416\n",
      "Epoch 4659/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9140 - val_loss: 5.3415\n",
      "Epoch 4660/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9138 - val_loss: 5.3414\n",
      "Epoch 4661/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9137 - val_loss: 5.3413\n",
      "Epoch 4662/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9136 - val_loss: 5.3412\n",
      "Epoch 4663/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9135 - val_loss: 5.3411\n",
      "Epoch 4664/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9133 - val_loss: 5.3410\n",
      "Epoch 4665/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9132 - val_loss: 5.3409\n",
      "Epoch 4666/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9131 - val_loss: 5.3409\n",
      "Epoch 4667/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9129 - val_loss: 5.3408\n",
      "Epoch 4668/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9128 - val_loss: 5.3407\n",
      "Epoch 4669/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9127 - val_loss: 5.3406\n",
      "Epoch 4670/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9125 - val_loss: 5.3405\n",
      "Epoch 4671/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9124 - val_loss: 5.3404\n",
      "Epoch 4672/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9123 - val_loss: 5.3403\n",
      "Epoch 4673/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9122 - val_loss: 5.3402\n",
      "Epoch 4674/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9120 - val_loss: 5.3401\n",
      "Epoch 4675/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9119 - val_loss: 5.3400\n",
      "Epoch 4676/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9118 - val_loss: 5.3399\n",
      "Epoch 4677/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9116 - val_loss: 5.3398\n",
      "Epoch 4678/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9115 - val_loss: 5.3398\n",
      "Epoch 4679/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9114 - val_loss: 5.3397\n",
      "Epoch 4680/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9113 - val_loss: 5.3396\n",
      "Epoch 4681/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9111 - val_loss: 5.3395\n",
      "Epoch 4682/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9110 - val_loss: 5.3394\n",
      "Epoch 4683/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9109 - val_loss: 5.3393\n",
      "Epoch 4684/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9107 - val_loss: 5.3392\n",
      "Epoch 4685/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9106 - val_loss: 5.3391\n",
      "Epoch 4686/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9105 - val_loss: 5.3390\n",
      "Epoch 4687/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9104 - val_loss: 5.3389\n",
      "Epoch 4688/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9102 - val_loss: 5.3388\n",
      "Epoch 4689/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9101 - val_loss: 5.3388\n",
      "Epoch 4690/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9100 - val_loss: 5.3387\n",
      "Epoch 4691/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9098 - val_loss: 5.3386\n",
      "Epoch 4692/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9097 - val_loss: 5.3385\n",
      "Epoch 4693/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9096 - val_loss: 5.3384\n",
      "Epoch 4694/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9095 - val_loss: 5.3383\n",
      "Epoch 4695/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9093 - val_loss: 5.3382\n",
      "Epoch 4696/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9092 - val_loss: 5.3381\n",
      "Epoch 4697/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9091 - val_loss: 5.3380\n",
      "Epoch 4698/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9089 - val_loss: 5.3379\n",
      "Epoch 4699/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9088 - val_loss: 5.3378\n",
      "Epoch 4700/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9087 - val_loss: 5.3378\n",
      "Epoch 4701/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9086 - val_loss: 5.3377\n",
      "Epoch 4702/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9084 - val_loss: 5.3376\n",
      "Epoch 4703/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9083 - val_loss: 5.3375\n",
      "Epoch 4704/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9082 - val_loss: 5.3374\n",
      "Epoch 4705/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9080 - val_loss: 5.3373\n",
      "Epoch 4706/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9079 - val_loss: 5.3372\n",
      "Epoch 4707/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9078 - val_loss: 5.3371\n",
      "Epoch 4708/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9077 - val_loss: 5.3370\n",
      "Epoch 4709/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9075 - val_loss: 5.3369\n",
      "Epoch 4710/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9074 - val_loss: 5.3368\n",
      "Epoch 4711/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9073 - val_loss: 5.3368\n",
      "Epoch 4712/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9071 - val_loss: 5.3367\n",
      "Epoch 4713/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9070 - val_loss: 5.3366\n",
      "Epoch 4714/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9069 - val_loss: 5.3365\n",
      "Epoch 4715/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9068 - val_loss: 5.3364\n",
      "Epoch 4716/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9066 - val_loss: 5.3363\n",
      "Epoch 4717/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9065 - val_loss: 5.3362\n",
      "Epoch 4718/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 5.9064 - val_loss: 5.3361\n",
      "Epoch 4719/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9062 - val_loss: 5.3360\n",
      "Epoch 4720/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9061 - val_loss: 5.3359\n",
      "Epoch 4721/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9060 - val_loss: 5.3358\n",
      "Epoch 4722/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9059 - val_loss: 5.3358\n",
      "Epoch 4723/5000\n",
      "39898/39898 [==============================] - 1s 18us/step - loss: 5.9057 - val_loss: 5.3357\n",
      "Epoch 4724/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9056 - val_loss: 5.3356\n",
      "Epoch 4725/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9055 - val_loss: 5.3355\n",
      "Epoch 4726/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 5.9053 - val_loss: 5.3354\n",
      "Epoch 4727/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9052 - val_loss: 5.3353\n",
      "Epoch 4728/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9051 - val_loss: 5.3352\n",
      "Epoch 4729/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9050 - val_loss: 5.3351\n",
      "Epoch 4730/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9048 - val_loss: 5.3350\n",
      "Epoch 4731/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9047 - val_loss: 5.3349\n",
      "Epoch 4732/5000\n",
      "39898/39898 [==============================] - 1s 19us/step - loss: 5.9046 - val_loss: 5.3348\n",
      "Epoch 4733/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9044 - val_loss: 5.3348\n",
      "Epoch 4734/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 5.9043 - val_loss: 5.3347\n",
      "Epoch 4735/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9042 - val_loss: 5.3346\n",
      "Epoch 4736/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9041 - val_loss: 5.3345\n",
      "Epoch 4737/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9039 - val_loss: 5.3344\n",
      "Epoch 4738/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9038 - val_loss: 5.3343\n",
      "Epoch 4739/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9037 - val_loss: 5.3342\n",
      "Epoch 4740/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9035 - val_loss: 5.3341\n",
      "Epoch 4741/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9034 - val_loss: 5.3340\n",
      "Epoch 4742/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9033 - val_loss: 5.3339\n",
      "Epoch 4743/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9032 - val_loss: 5.3339\n",
      "Epoch 4744/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9030 - val_loss: 5.3338\n",
      "Epoch 4745/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9029 - val_loss: 5.3337\n",
      "Epoch 4746/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9028 - val_loss: 5.3336\n",
      "Epoch 4747/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9027 - val_loss: 5.3335\n",
      "Epoch 4748/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9025 - val_loss: 5.3334\n",
      "Epoch 4749/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9024 - val_loss: 5.3333\n",
      "Epoch 4750/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9023 - val_loss: 5.3332\n",
      "Epoch 4751/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9021 - val_loss: 5.3331\n",
      "Epoch 4752/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9020 - val_loss: 5.3330\n",
      "Epoch 4753/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9019 - val_loss: 5.3330\n",
      "Epoch 4754/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9018 - val_loss: 5.3329\n",
      "Epoch 4755/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9016 - val_loss: 5.3328\n",
      "Epoch 4756/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9015 - val_loss: 5.3327\n",
      "Epoch 4757/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9014 - val_loss: 5.3326\n",
      "Epoch 4758/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9012 - val_loss: 5.3325\n",
      "Epoch 4759/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9011 - val_loss: 5.3324\n",
      "Epoch 4760/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9010 - val_loss: 5.3323\n",
      "Epoch 4761/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9009 - val_loss: 5.3322\n",
      "Epoch 4762/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9007 - val_loss: 5.3321\n",
      "Epoch 4763/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9006 - val_loss: 5.3320\n",
      "Epoch 4764/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9005 - val_loss: 5.3320\n",
      "Epoch 4765/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9004 - val_loss: 5.3319\n",
      "Epoch 4766/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.9002 - val_loss: 5.3318\n",
      "Epoch 4767/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9001 - val_loss: 5.3317\n",
      "Epoch 4768/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.9000 - val_loss: 5.3316\n",
      "Epoch 4769/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8998 - val_loss: 5.3315\n",
      "Epoch 4770/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8997 - val_loss: 5.3314\n",
      "Epoch 4771/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8996 - val_loss: 5.3313\n",
      "Epoch 4772/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8995 - val_loss: 5.3312\n",
      "Epoch 4773/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8993 - val_loss: 5.3311\n",
      "Epoch 4774/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8992 - val_loss: 5.3311\n",
      "Epoch 4775/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8991 - val_loss: 5.3310\n",
      "Epoch 4776/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8990 - val_loss: 5.3309\n",
      "Epoch 4777/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8988 - val_loss: 5.3308\n",
      "Epoch 4778/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8987 - val_loss: 5.3307\n",
      "Epoch 4779/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8986 - val_loss: 5.3306\n",
      "Epoch 4780/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8984 - val_loss: 5.3305\n",
      "Epoch 4781/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8983 - val_loss: 5.3304\n",
      "Epoch 4782/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8982 - val_loss: 5.3303\n",
      "Epoch 4783/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8981 - val_loss: 5.3302\n",
      "Epoch 4784/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8979 - val_loss: 5.3302\n",
      "Epoch 4785/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8978 - val_loss: 5.3301\n",
      "Epoch 4786/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8977 - val_loss: 5.3300\n",
      "Epoch 4787/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8976 - val_loss: 5.3299\n",
      "Epoch 4788/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8974 - val_loss: 5.3298\n",
      "Epoch 4789/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8973 - val_loss: 5.3297\n",
      "Epoch 4790/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8972 - val_loss: 5.3296\n",
      "Epoch 4791/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8970 - val_loss: 5.3295\n",
      "Epoch 4792/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8969 - val_loss: 5.3294\n",
      "Epoch 4793/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8968 - val_loss: 5.3294\n",
      "Epoch 4794/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8967 - val_loss: 5.3293\n",
      "Epoch 4795/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8965 - val_loss: 5.3292\n",
      "Epoch 4796/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8964 - val_loss: 5.3291\n",
      "Epoch 4797/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8963 - val_loss: 5.3290\n",
      "Epoch 4798/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8962 - val_loss: 5.3289\n",
      "Epoch 4799/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8960 - val_loss: 5.3288\n",
      "Epoch 4800/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8959 - val_loss: 5.3287\n",
      "Epoch 4801/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8958 - val_loss: 5.3286\n",
      "Epoch 4802/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8956 - val_loss: 5.3285\n",
      "Epoch 4803/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8955 - val_loss: 5.3285\n",
      "Epoch 4804/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8954 - val_loss: 5.3284\n",
      "Epoch 4805/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8953 - val_loss: 5.3283\n",
      "Epoch 4806/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8951 - val_loss: 5.3282\n",
      "Epoch 4807/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8950 - val_loss: 5.3281\n",
      "Epoch 4808/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8949 - val_loss: 5.3280\n",
      "Epoch 4809/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8948 - val_loss: 5.3279\n",
      "Epoch 4810/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8946 - val_loss: 5.3278\n",
      "Epoch 4811/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8945 - val_loss: 5.3277\n",
      "Epoch 4812/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8944 - val_loss: 5.3277\n",
      "Epoch 4813/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8942 - val_loss: 5.3276\n",
      "Epoch 4814/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8941 - val_loss: 5.3275\n",
      "Epoch 4815/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8940 - val_loss: 5.3274\n",
      "Epoch 4816/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8939 - val_loss: 5.3273\n",
      "Epoch 4817/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8937 - val_loss: 5.3272\n",
      "Epoch 4818/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8936 - val_loss: 5.3271\n",
      "Epoch 4819/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8935 - val_loss: 5.3270\n",
      "Epoch 4820/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8934 - val_loss: 5.3269\n",
      "Epoch 4821/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8932 - val_loss: 5.3268\n",
      "Epoch 4822/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8931 - val_loss: 5.3268\n",
      "Epoch 4823/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8930 - val_loss: 5.3267\n",
      "Epoch 4824/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8929 - val_loss: 5.3266\n",
      "Epoch 4825/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8927 - val_loss: 5.3265\n",
      "Epoch 4826/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8926 - val_loss: 5.3264\n",
      "Epoch 4827/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8925 - val_loss: 5.3263\n",
      "Epoch 4828/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8923 - val_loss: 5.3262\n",
      "Epoch 4829/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8922 - val_loss: 5.3261\n",
      "Epoch 4830/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8921 - val_loss: 5.3260\n",
      "Epoch 4831/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8920 - val_loss: 5.3260\n",
      "Epoch 4832/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8918 - val_loss: 5.3259\n",
      "Epoch 4833/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8917 - val_loss: 5.3258\n",
      "Epoch 4834/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8916 - val_loss: 5.3257\n",
      "Epoch 4835/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8915 - val_loss: 5.3256\n",
      "Epoch 4836/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8913 - val_loss: 5.3255\n",
      "Epoch 4837/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8912 - val_loss: 5.3254\n",
      "Epoch 4838/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8911 - val_loss: 5.3253\n",
      "Epoch 4839/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8910 - val_loss: 5.3252\n",
      "Epoch 4840/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8908 - val_loss: 5.3252\n",
      "Epoch 4841/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8907 - val_loss: 5.3251\n",
      "Epoch 4842/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8906 - val_loss: 5.3250\n",
      "Epoch 4843/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8905 - val_loss: 5.3249\n",
      "Epoch 4844/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8903 - val_loss: 5.3248\n",
      "Epoch 4845/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8902 - val_loss: 5.3247\n",
      "Epoch 4846/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8901 - val_loss: 5.3246\n",
      "Epoch 4847/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8899 - val_loss: 5.3245\n",
      "Epoch 4848/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8898 - val_loss: 5.3244\n",
      "Epoch 4849/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8897 - val_loss: 5.3244\n",
      "Epoch 4850/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8896 - val_loss: 5.3243\n",
      "Epoch 4851/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8894 - val_loss: 5.3242\n",
      "Epoch 4852/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8893 - val_loss: 5.3241\n",
      "Epoch 4853/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8892 - val_loss: 5.3240\n",
      "Epoch 4854/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8891 - val_loss: 5.3239\n",
      "Epoch 4855/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8889 - val_loss: 5.3238\n",
      "Epoch 4856/5000\n",
      "39898/39898 [==============================] - 1s 17us/step - loss: 5.8888 - val_loss: 5.3237\n",
      "Epoch 4857/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8887 - val_loss: 5.3236\n",
      "Epoch 4858/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8886 - val_loss: 5.3236\n",
      "Epoch 4859/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8884 - val_loss: 5.3235\n",
      "Epoch 4860/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8883 - val_loss: 5.3234\n",
      "Epoch 4861/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8882 - val_loss: 5.3233\n",
      "Epoch 4862/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8881 - val_loss: 5.3232\n",
      "Epoch 4863/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8879 - val_loss: 5.3231\n",
      "Epoch 4864/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8878 - val_loss: 5.3230\n",
      "Epoch 4865/5000\n",
      "39898/39898 [==============================] - 1s 18us/step - loss: 5.8877 - val_loss: 5.3229\n",
      "Epoch 4866/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8876 - val_loss: 5.3228\n",
      "Epoch 4867/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8874 - val_loss: 5.3228\n",
      "Epoch 4868/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8873 - val_loss: 5.3227\n",
      "Epoch 4869/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8872 - val_loss: 5.3226\n",
      "Epoch 4870/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8870 - val_loss: 5.3225\n",
      "Epoch 4871/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8869 - val_loss: 5.3224\n",
      "Epoch 4872/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8868 - val_loss: 5.3223\n",
      "Epoch 4873/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8867 - val_loss: 5.3222\n",
      "Epoch 4874/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8865 - val_loss: 5.3221\n",
      "Epoch 4875/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8864 - val_loss: 5.3220\n",
      "Epoch 4876/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8863 - val_loss: 5.3220\n",
      "Epoch 4877/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8862 - val_loss: 5.3219\n",
      "Epoch 4878/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8860 - val_loss: 5.3218\n",
      "Epoch 4879/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8859 - val_loss: 5.3217\n",
      "Epoch 4880/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8858 - val_loss: 5.3216\n",
      "Epoch 4881/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8857 - val_loss: 5.3215\n",
      "Epoch 4882/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8855 - val_loss: 5.3214\n",
      "Epoch 4883/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8854 - val_loss: 5.3213\n",
      "Epoch 4884/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8853 - val_loss: 5.3213\n",
      "Epoch 4885/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 5.8852 - val_loss: 5.3212\n",
      "Epoch 4886/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8850 - val_loss: 5.3211\n",
      "Epoch 4887/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8849 - val_loss: 5.3210\n",
      "Epoch 4888/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8848 - val_loss: 5.3209\n",
      "Epoch 4889/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8847 - val_loss: 5.3208\n",
      "Epoch 4890/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8845 - val_loss: 5.3207\n",
      "Epoch 4891/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8844 - val_loss: 5.3206\n",
      "Epoch 4892/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8843 - val_loss: 5.3205\n",
      "Epoch 4893/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8842 - val_loss: 5.3205\n",
      "Epoch 4894/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8840 - val_loss: 5.3204\n",
      "Epoch 4895/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8839 - val_loss: 5.3203\n",
      "Epoch 4896/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8838 - val_loss: 5.3202\n",
      "Epoch 4897/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8837 - val_loss: 5.3201\n",
      "Epoch 4898/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8835 - val_loss: 5.3200\n",
      "Epoch 4899/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8834 - val_loss: 5.3199\n",
      "Epoch 4900/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8833 - val_loss: 5.3198\n",
      "Epoch 4901/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8832 - val_loss: 5.3198\n",
      "Epoch 4902/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8830 - val_loss: 5.3197\n",
      "Epoch 4903/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8829 - val_loss: 5.3196\n",
      "Epoch 4904/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8828 - val_loss: 5.3195\n",
      "Epoch 4905/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8827 - val_loss: 5.3194\n",
      "Epoch 4906/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8825 - val_loss: 5.3193\n",
      "Epoch 4907/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8824 - val_loss: 5.3192\n",
      "Epoch 4908/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8823 - val_loss: 5.3191\n",
      "Epoch 4909/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8821 - val_loss: 5.3190\n",
      "Epoch 4910/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8820 - val_loss: 5.3190\n",
      "Epoch 4911/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8819 - val_loss: 5.3189\n",
      "Epoch 4912/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8818 - val_loss: 5.3188\n",
      "Epoch 4913/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8816 - val_loss: 5.3187\n",
      "Epoch 4914/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8815 - val_loss: 5.3186\n",
      "Epoch 4915/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8814 - val_loss: 5.3185\n",
      "Epoch 4916/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8813 - val_loss: 5.3184\n",
      "Epoch 4917/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8811 - val_loss: 5.3183\n",
      "Epoch 4918/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8810 - val_loss: 5.3183\n",
      "Epoch 4919/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8809 - val_loss: 5.3182\n",
      "Epoch 4920/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8808 - val_loss: 5.3181\n",
      "Epoch 4921/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8806 - val_loss: 5.3180\n",
      "Epoch 4922/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8805 - val_loss: 5.3179\n",
      "Epoch 4923/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8804 - val_loss: 5.3178\n",
      "Epoch 4924/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8803 - val_loss: 5.3177\n",
      "Epoch 4925/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8801 - val_loss: 5.3176\n",
      "Epoch 4926/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8800 - val_loss: 5.3176\n",
      "Epoch 4927/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8799 - val_loss: 5.3175\n",
      "Epoch 4928/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8798 - val_loss: 5.3174\n",
      "Epoch 4929/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8796 - val_loss: 5.3173\n",
      "Epoch 4930/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8795 - val_loss: 5.3172\n",
      "Epoch 4931/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8794 - val_loss: 5.3171\n",
      "Epoch 4932/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8793 - val_loss: 5.3170\n",
      "Epoch 4933/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8791 - val_loss: 5.3169\n",
      "Epoch 4934/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8790 - val_loss: 5.3169\n",
      "Epoch 4935/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8789 - val_loss: 5.3168\n",
      "Epoch 4936/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8788 - val_loss: 5.3167\n",
      "Epoch 4937/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8786 - val_loss: 5.3166\n",
      "Epoch 4938/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8785 - val_loss: 5.3165\n",
      "Epoch 4939/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8784 - val_loss: 5.3164\n",
      "Epoch 4940/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8783 - val_loss: 5.3163\n",
      "Epoch 4941/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8781 - val_loss: 5.3162\n",
      "Epoch 4942/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8780 - val_loss: 5.3161\n",
      "Epoch 4943/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8779 - val_loss: 5.3161\n",
      "Epoch 4944/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8778 - val_loss: 5.3160\n",
      "Epoch 4945/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8776 - val_loss: 5.3159\n",
      "Epoch 4946/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8775 - val_loss: 5.3158\n",
      "Epoch 4947/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8774 - val_loss: 5.3157\n",
      "Epoch 4948/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8773 - val_loss: 5.3156\n",
      "Epoch 4949/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8771 - val_loss: 5.3155\n",
      "Epoch 4950/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8770 - val_loss: 5.3154\n",
      "Epoch 4951/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8769 - val_loss: 5.3154\n",
      "Epoch 4952/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8768 - val_loss: 5.3153\n",
      "Epoch 4953/5000\n",
      "39898/39898 [==============================] - 1s 19us/step - loss: 5.8767 - val_loss: 5.3152\n",
      "Epoch 4954/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8765 - val_loss: 5.3151\n",
      "Epoch 4955/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8764 - val_loss: 5.3150\n",
      "Epoch 4956/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8763 - val_loss: 5.3149\n",
      "Epoch 4957/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8762 - val_loss: 5.3148\n",
      "Epoch 4958/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8760 - val_loss: 5.3147\n",
      "Epoch 4959/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8759 - val_loss: 5.3147\n",
      "Epoch 4960/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8758 - val_loss: 5.3146\n",
      "Epoch 4961/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8757 - val_loss: 5.3145\n",
      "Epoch 4962/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8755 - val_loss: 5.3144\n",
      "Epoch 4963/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8754 - val_loss: 5.3143\n",
      "Epoch 4964/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8753 - val_loss: 5.3142\n",
      "Epoch 4965/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8752 - val_loss: 5.3141\n",
      "Epoch 4966/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8750 - val_loss: 5.3141\n",
      "Epoch 4967/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8749 - val_loss: 5.3140\n",
      "Epoch 4968/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8748 - val_loss: 5.3139\n",
      "Epoch 4969/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8747 - val_loss: 5.3138\n",
      "Epoch 4970/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8745 - val_loss: 5.3137\n",
      "Epoch 4971/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8744 - val_loss: 5.3136\n",
      "Epoch 4972/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8743 - val_loss: 5.3135\n",
      "Epoch 4973/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8742 - val_loss: 5.3134\n",
      "Epoch 4974/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8740 - val_loss: 5.3134\n",
      "Epoch 4975/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8739 - val_loss: 5.3133\n",
      "Epoch 4976/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8738 - val_loss: 5.3132\n",
      "Epoch 4977/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8737 - val_loss: 5.3131\n",
      "Epoch 4978/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8735 - val_loss: 5.3130\n",
      "Epoch 4979/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8734 - val_loss: 5.3129\n",
      "Epoch 4980/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8733 - val_loss: 5.3128\n",
      "Epoch 4981/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8732 - val_loss: 5.3127\n",
      "Epoch 4982/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8730 - val_loss: 5.3127\n",
      "Epoch 4983/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8729 - val_loss: 5.3126\n",
      "Epoch 4984/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8728 - val_loss: 5.3125\n",
      "Epoch 4985/5000\n",
      "39898/39898 [==============================] - 1s 24us/step - loss: 5.8727 - val_loss: 5.3124\n",
      "Epoch 4986/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8725 - val_loss: 5.3123\n",
      "Epoch 4987/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8724 - val_loss: 5.3122\n",
      "Epoch 4988/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8723 - val_loss: 5.3121\n",
      "Epoch 4989/5000\n",
      "39898/39898 [==============================] - 1s 19us/step - loss: 5.8722 - val_loss: 5.3120\n",
      "Epoch 4990/5000\n",
      "39898/39898 [==============================] - 1s 21us/step - loss: 5.8721 - val_loss: 5.3120\n",
      "Epoch 4991/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8719 - val_loss: 5.3119\n",
      "Epoch 4992/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8718 - val_loss: 5.3118\n",
      "Epoch 4993/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8717 - val_loss: 5.3117\n",
      "Epoch 4994/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8716 - val_loss: 5.3116\n",
      "Epoch 4995/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8714 - val_loss: 5.3115\n",
      "Epoch 4996/5000\n",
      "39898/39898 [==============================] - 1s 22us/step - loss: 5.8713 - val_loss: 5.3114\n",
      "Epoch 4997/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8712 - val_loss: 5.3114\n",
      "Epoch 4998/5000\n",
      "39898/39898 [==============================] - 1s 23us/step - loss: 5.8711 - val_loss: 5.3113\n",
      "Epoch 4999/5000\n",
      "39898/39898 [==============================] - 1s 18us/step - loss: 5.8709 - val_loss: 5.3112\n",
      "Epoch 5000/5000\n",
      "39898/39898 [==============================] - 1s 20us/step - loss: 5.8708 - val_loss: 5.3111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbd1417a630>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir=\"/home/rgadea3/EXPERIMENTOS/nuevas_investigaciones_2018/experimentos/logs/{}\".format(time()))\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=5000,\n",
    "                batch_size=500,\n",
    "                shuffle=False,\n",
    "                callbacks=[tensorboard],\n",
    "                validation_data=(x_test, x_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13301/13301 [==============================] - 1s 72us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.311091592590412"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.evaluate(x=x_test,y=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 320)\n",
      "(320,)\n",
      "(320, 640)\n",
      "(640,)\n"
     ]
    }
   ],
   "source": [
    "autoencoder.save_weights('compresor_python')\n",
    "autoencoder.load_weights('compresor_python', by_name=False)\n",
    "vamos=autoencoder.get_weights()\n",
    "print(vamos[0].shape)\n",
    "print(vamos[1].shape)\n",
    "print(vamos[2].shape)\n",
    "print(vamos[3].shape)\n",
    "#autoencoder.evaluate(x=x_test,y=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some images\n",
    "# note that we take them from the *test* set\n",
    "# encoded_imgs = encoder.predict(x_test_min_max)\n",
    "# decoded_imgs_scaled = decoder.predict(encoded_imgs)\n",
    "#decoded_imgs_scaled = autoencoder.predict(x_test_min_max)\n",
    "decoded_imgs = autoencoder.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10845\n"
     ]
    }
   ],
   "source": [
    "n = 6  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    idea=np.random.randint(1,x_test.shape[0])\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[idea].reshape(40, 16).transpose(),vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[idea].reshape(40, 16).transpose(),vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "print(idea)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6320, 3840)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filename = '../datos_octubre_2018/p_OF_5mm_161mm000.h5'\n",
    "conjunto_datos_test=pd.read_hdf(filename,'MC');\n",
    "conjunto_datos_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6320, 3840)\n",
      "(6320, 3840)\n"
     ]
    }
   ],
   "source": [
    "L1A=6;\n",
    "# hay tres L1 con 640 sensores (40*16)\n",
    "L1B=0;\n",
    "# hay dos L1 con 640 sensores (40*16)\n",
    "X_trained=conjunto_datos_test.values;\n",
    "x_trained=X_trained;\n",
    "\n",
    "for i in range (X_trained.shape[0]):\n",
    "    idea1=X_trained[i,:].reshape(img_rows,(L1A*img_cols));\n",
    "    ideat=idea1.transpose();\n",
    "    idea2=ideat.reshape(1,(L1A*img_cols)*img_rows);\n",
    "    x_trained[i,:] =idea2;\n",
    "x_tested = x_trained;\n",
    "print(x_trained.shape)\n",
    "print(x_tested.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vamos a procesar y comprimir con la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora los particionamos y pasamos por las redes de compresin. Hay una red la A que se utiliza 5 veces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(x, derivative=False):\n",
    "  return x*(1-x) if derivative else 1/(1+np.exp(-x))\n",
    "ideaA=np.zeros((L1A,input_output_dim_A))\n",
    "\n",
    "cara_externa=x_tested[:,0: L1A*input_output_dim_A] \n",
    "cara_externa_reconstruida=np.zeros((x_tested.shape[0],L1A*input_output_dim_A))\n",
    "for i in range(x_tested.shape[0]):\n",
    "    for k in range(L1A):\n",
    "        ideaA[k,:]=x_tested[i,k*input_output_dim_A:k*input_output_dim_A+input_output_dim_A]\n",
    "    salida_reconstructed_1 = autoencoder.predict(ideaA)    \n",
    "    \n",
    "    #entrada_imgs_A=(ideaA-min_A.transpose())/(max_A.transpose()-min_A.transpose())\n",
    "    #entrada_imgs_A=(ideaA) #he quitado el escalado\n",
    "    #encoded_imgs_A = sigmoid(np.dot(entrada_imgs_A, Encoder_weights_A) + Encoder_biases_A)\n",
    "    #decoded_imgs_A= (np.dot(encoded_imgs_A, Decoder_weights_A) + Decoder_biases_A)\n",
    "    #print(decoded_imgs_A.shape)\n",
    "    #salida_reconstructed_1 = decoded_imgs_A*(max_A.transpose()-min_A.transpose())+min_A.transpose();\n",
    "    #salida_reconstructed_1 = decoded_imgs_A #quito el escalado inverso    \n",
    " \n",
    "    hola1=np.reshape(salida_reconstructed_1,(L1A*input_output_dim_A))\n",
    "\n",
    "    #print(hola.shape)\n",
    "    salida_total=hola1\n",
    "    #salida_total[salida_total<0]=0\n",
    "    #print(salida_total.shape)\n",
    "    cara_externa_reconstruida[i]=salida_total\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizamos los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos todos los sensores: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 1  # how many digits we will display\n",
    "plt.figure(figsize=(40, 10))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    idea=np.random.randint(1,x_tested.shape[0])\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(cara_externa[idea].reshape(L1A*img_cols, img_rows).transpose(), vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(cara_externa_reconstruida[idea].reshape(L1A*img_cols, img_rows).transpose(), vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos ahora L1 a L1, teniendo en cuenta que hay de dos tipos:\n",
    "L1A (con 36 columnas )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x720 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = L1A  # how many digits we will display\n",
    "plt.figure(figsize=(40, 10))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(cara_externa[idea].reshape(L1A*img_cols, img_rows).transpose()[:,i*img_cols:(i+1)*img_cols] ,vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax = plt.subplot(2, n, i + 1+n)\n",
    "    plt.imshow(cara_externa_reconstruida[idea].reshape(L1A*img_cols, img_rows).transpose()[:,i*img_cols:(i+1)*img_cols] ,vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  1  0  0  0  1  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  0]\n",
      " [ 0  0  0  1  1  0  0  0  2  0  2  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  1  0  1  2  2  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  1  1  1  0  1  1  0  1]\n",
      " [ 0  0  0  0  0  0  2  3  1  2  5  2  2  2  0  1]\n",
      " [ 0  0  0  0  0  2  1  3  6  5  7  3  1  1  1  2]\n",
      " [ 0  0  0  0  0  1  5  4  8 10  6  7  6  2  3  3]\n",
      " [ 0  0  0  1  0  3  4  4 11 12 11 10  7  3  2  1]\n",
      " [ 0  2  0  0  0  0  1  7  7 14 13 19 16  1  8  2]\n",
      " [ 0  0  0  1  1  0  4  4 14 16 12 12  9  2  4  2]\n",
      " [ 0  0  0  0  1  3  2  9  8 14 14 10  8  8  1  3]\n",
      " [ 0  0  0  0  0  0  2  4  4  9  4  6  3  1  2  2]\n",
      " [ 0  0  0  0  0  0  3  1  2  7  4  7  2  3  3  2]\n",
      " [ 0  0  0  0  0  0  1  1  6  5  1  3  2  1  1  0]\n",
      " [ 0  0  0  0  1  0  0  0  3  1  0  1  0  1  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  1  0  0  1  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "566\n"
     ]
    }
   ],
   "source": [
    "i=3\n",
    "print(cara_externa[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:])\n",
    "print(np.sum(cara_externa[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  1  2  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  2  3  3  3  3  2  1  0  0]\n",
      " [ 0  0  0  0  0  0  2  3  4  5  5  5  3  2  1  0]\n",
      " [ 0  0  0  0  0  1  3  5  8  9  8  8  5  3  2  1]\n",
      " [ 0  0  0  0  0  1  3  5  9 11 13  8  7  4  4  2]\n",
      " [ 0  0  0  0  0  1  3  6 10 11 10  8  8  5  3  2]\n",
      " [ 0  0  0  0  0  1  3  6 15 11 14  9  6  5  3  2]\n",
      " [ 0  0  0  0  0  1  3  6  8  9 10  8  7  4  3  2]\n",
      " [ 0  0  0  0  0  1  2  4  7  9  7  6  5  3  2  1]\n",
      " [ 0  0  0  0  0  0  1  2  4  5  5  4  4  2  1  1]\n",
      " [ 0  0  0  0  0  0  1  1  2  4  3  3  2  1  1  0]\n",
      " [ 0  0  0  0  0  0  0  1  1  1  1  0  1  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "584.9281552084722\n"
     ]
    }
   ],
   "source": [
    "print(cara_externa_reconstruida[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:].astype(int))\n",
    "print(np.sum(cara_externa_reconstruida[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "495px",
    "left": "1249px",
    "right": "57px",
    "top": "240px",
    "width": "390px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
