{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple CNN for PETALO\n",
    "\n",
    "Esta red la vamos a utilizar para obtener el radio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/rgadea/anaconda3/envs/tensorflow/lib/python36.zip', '/home/rgadea/anaconda3/envs/tensorflow/lib/python3.6', '/home/rgadea/anaconda3/envs/tensorflow/lib/python3.6/lib-dynload', '/home/rgadea/anaconda3/envs/tensorflow/lib/python3.6/site-packages', '/home/rgadea/anaconda3/envs/tensorflow/lib/python3.6/site-packages/lmfit-0.9.11-py3.6.egg', '/home/rgadea/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/extensions', '/volumedisk0/home/rgadea/.ipython', '/home/rgadea/lmfit-py/', '.']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append(\"/home/rgadea/lmfit-py/\")\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.utils import np_utils\n",
    "from math import floor\n",
    "from lmfit.models import  GaussianModel\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "# (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "def data():\n",
    "    '''\n",
    "    Data providing function:\n",
    "\n",
    "    This function is separated from model() so that hyperopt\n",
    "    won't reload data for each evaluation run.\n",
    "    '''\n",
    "    datos_matlab = sio.loadmat('../datos_mayo_2018/conjunto_entrenamiento_mayo_2018_ring1y2_filtrado9_run200_pho_super+.mat')\n",
    "    conjunto_datos=datos_matlab.get('photodefbox2_todo_fil2')\n",
    "    numero_muestras=conjunto_datos.shape[0]\n",
    "    #print(numero_muestras)\n",
    "    #print('conjunto_datos shape:', conjunto_datos.shape)\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = 16, 30\n",
    "    \n",
    "    tr_size=60\n",
    "    val_size=20\n",
    "    test_size=100-val_size-tr_size\n",
    "\n",
    "    tamanyo_tr=floor(tr_size*numero_muestras/100)\n",
    "    tamanyo_val=floor(val_size*numero_muestras/100)\n",
    "    tamanyo_test=numero_muestras-tamanyo_tr-tamanyo_val\n",
    "    #print(tamanyo_tr)\n",
    "    #print(tamanyo_val)\n",
    "    #print(tamanyo_test)\n",
    "    XY_test=conjunto_datos[tamanyo_tr+tamanyo_val:numero_muestras,:]\n",
    "    XY_test_bin0=XY_test[np.where((XY_test[:,1]>=99.3128) * (XY_test[:,1]<105.3128))]\n",
    "    XY_test_bin1=XY_test[np.where((XY_test[:,1]>=105.3128) * (XY_test[:,1]<111.3128))]\n",
    "    XY_test_bin2=XY_test[np.where((XY_test[:,1]>=111.3128) * (XY_test[:,1]<117.3128))]\n",
    "    XY_test_bin3=XY_test[np.where((XY_test[:,1]>=117.3128) * (XY_test[:,1]<123.3128))]\n",
    "    XY_test_bin4=XY_test[np.where((XY_test[:,1]>=123.3128))]\n",
    "\n",
    "    X_train=conjunto_datos[:tamanyo_tr,3:483]\n",
    "    X_val=conjunto_datos[tamanyo_tr:tamanyo_tr+tamanyo_val,3:483]\n",
    "    X_test=conjunto_datos[tamanyo_tr+tamanyo_val:numero_muestras,3:483]\n",
    "\n",
    "    X_test_bin0=XY_test_bin0[:,3:483]\n",
    "    Y_test_bin0=XY_test_bin0[:,1]\n",
    "    #print(X_test_bin0.shape)\n",
    "    X_test_bin1=XY_test_bin1[:,3:483]\n",
    "    Y_test_bin1=XY_test_bin1[:,1]\n",
    "    #print(X_test_bin1.shape)\n",
    "    X_test_bin2=XY_test_bin2[:,3:483]\n",
    "    Y_test_bin2=XY_test_bin2[:,1]\n",
    "    #print(X_test_bin2.shape)\n",
    "    X_test_bin3=XY_test_bin3[:,3:483]\n",
    "    Y_test_bin3=XY_test_bin3[:,1]\n",
    "    #print(X_test_bin3.shape)\n",
    "    X_test_bin4=XY_test_bin4[:,3:483]\n",
    "    Y_test_bin4=XY_test_bin4[:,1]\n",
    "    #print(X_test_bin4.shape)\n",
    "\n",
    "\n",
    "\n",
    "    Y_train=conjunto_datos[:tamanyo_tr,1] #elijo la coordenada radius\n",
    "    Y_val=conjunto_datos[tamanyo_tr:tamanyo_tr+tamanyo_val,1] #elijo la corrdenada radius\n",
    "    Y_test=conjunto_datos[tamanyo_tr+tamanyo_val:numero_muestras,1] #elijo la corrdenada radius\n",
    "    \n",
    "    X_train = X_train.reshape(X_train.shape[0], img_cols, img_rows,1)\n",
    "    X_val = X_val.reshape(X_val.shape[0], img_cols, img_rows,1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_cols, img_rows,1)\n",
    "\n",
    "    X_test_bin0 = X_test_bin0.reshape(X_test_bin0.shape[0], img_cols, img_rows,1)\n",
    "    X_test_bin1 = X_test_bin1.reshape(X_test_bin1.shape[0], img_cols, img_rows,1)\n",
    "    X_test_bin2 = X_test_bin2.reshape(X_test_bin2.shape[0], img_cols, img_rows,1)\n",
    "    X_test_bin3 = X_test_bin3.reshape(X_test_bin3.shape[0], img_cols, img_rows,1)\n",
    "    X_test_bin4 = X_test_bin4.reshape(X_test_bin4.shape[0], img_cols, img_rows,1)\n",
    "\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_val= X_val.astype('float32')\n",
    "    X_test = X_test.astype('float32')    \n",
    "\n",
    "    #input_shape = (img_cols, img_rows,1)\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test, X_val, Y_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the CNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  model(X_train, Y_train,X_test, Y_test, X_val_Y_val):\n",
    "    '''\n",
    "    Model providing function:\n",
    "\n",
    "    Create Keras model with double curly brackets dropped-in as needed.\n",
    "    Return value has to be a valid python dictionary with two customary keys:\n",
    "        - loss: Specify a numeric evaluation metric to be minimized\n",
    "        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
    "    The last one is optional, though recommended, namely:\n",
    "        - model: specify the model just created so that we can later use it again.\n",
    "    '''\n",
    "    nb_epoch = 150\n",
    "\n",
    "    nb_filters = 32\n",
    "\n",
    "    pool_size = (2, 2)\n",
    "\n",
    "    kernel_size = (4,4)\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(8, kernel_size=kernel_size,\n",
    "                            padding='same',\n",
    "                            input_shape=(30,16,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(16, kernel_size, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dropout({{uniform(0,1)}}))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "\n",
    "\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}},\n",
    "                  metrics=['mae'])\n",
    "    model.fit(X_train, Y_train, \n",
    "              batch_size={{choice([250,500,1000])}},\n",
    "              epochs=100,\n",
    "              verbose=1,\n",
    "              validation_data=(X_val, Y_val))\n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print('Test mse:', score[0])\n",
    "    return {'loss': score[0], 'status': STATUS_OK, 'model': model}           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## optimization of the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import sys\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.datasets import mnist\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense, Dropout, Activation, Flatten\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import rmsprop\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from math import floor\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from lmfit.models import GaussianModel\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import scipy.io as sio\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from numpy import exp, loadtxt, pi, sqrt, log\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from lmfit import Model\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dropout': hp.uniform('Dropout', 0,1),\n",
      "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n",
      "        'batch_size': hp.choice('batch_size', [250,500,1000]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: '''\n",
      "   3: Data providing function:\n",
      "   4: \n",
      "   5: This function is separated from model() so that hyperopt\n",
      "   6: won't reload data for each evaluation run.\n",
      "   7: '''\n",
      "   8: datos_matlab = sio.loadmat('../datos_mayo_2018/conjunto_entrenamiento_mayo_2018_ring1y2_filtrado9_run200_pho_super+.mat')\n",
      "   9: conjunto_datos=datos_matlab.get('photodefbox2_todo_fil2')\n",
      "  10: numero_muestras=conjunto_datos.shape[0]\n",
      "  11: #print(numero_muestras)\n",
      "  12: #print('conjunto_datos shape:', conjunto_datos.shape)\n",
      "  13: # input image dimensions\n",
      "  14: img_rows, img_cols = 16, 30\n",
      "  15: \n",
      "  16: tr_size=60\n",
      "  17: val_size=20\n",
      "  18: test_size=100-val_size-tr_size\n",
      "  19: \n",
      "  20: tamanyo_tr=floor(tr_size*numero_muestras/100)\n",
      "  21: tamanyo_val=floor(val_size*numero_muestras/100)\n",
      "  22: tamanyo_test=numero_muestras-tamanyo_tr-tamanyo_val\n",
      "  23: #print(tamanyo_tr)\n",
      "  24: #print(tamanyo_val)\n",
      "  25: #print(tamanyo_test)\n",
      "  26: XY_test=conjunto_datos[tamanyo_tr+tamanyo_val:numero_muestras,:]\n",
      "  27: XY_test_bin0=XY_test[np.where((XY_test[:,1]>=99.3128) * (XY_test[:,1]<105.3128))]\n",
      "  28: XY_test_bin1=XY_test[np.where((XY_test[:,1]>=105.3128) * (XY_test[:,1]<111.3128))]\n",
      "  29: XY_test_bin2=XY_test[np.where((XY_test[:,1]>=111.3128) * (XY_test[:,1]<117.3128))]\n",
      "  30: XY_test_bin3=XY_test[np.where((XY_test[:,1]>=117.3128) * (XY_test[:,1]<123.3128))]\n",
      "  31: XY_test_bin4=XY_test[np.where((XY_test[:,1]>=123.3128))]\n",
      "  32: \n",
      "  33: X_train=conjunto_datos[:tamanyo_tr,3:483]\n",
      "  34: X_val=conjunto_datos[tamanyo_tr:tamanyo_tr+tamanyo_val,3:483]\n",
      "  35: X_test=conjunto_datos[tamanyo_tr+tamanyo_val:numero_muestras,3:483]\n",
      "  36: \n",
      "  37: X_test_bin0=XY_test_bin0[:,3:483]\n",
      "  38: Y_test_bin0=XY_test_bin0[:,1]\n",
      "  39: #print(X_test_bin0.shape)\n",
      "  40: X_test_bin1=XY_test_bin1[:,3:483]\n",
      "  41: Y_test_bin1=XY_test_bin1[:,1]\n",
      "  42: #print(X_test_bin1.shape)\n",
      "  43: X_test_bin2=XY_test_bin2[:,3:483]\n",
      "  44: Y_test_bin2=XY_test_bin2[:,1]\n",
      "  45: #print(X_test_bin2.shape)\n",
      "  46: X_test_bin3=XY_test_bin3[:,3:483]\n",
      "  47: Y_test_bin3=XY_test_bin3[:,1]\n",
      "  48: #print(X_test_bin3.shape)\n",
      "  49: X_test_bin4=XY_test_bin4[:,3:483]\n",
      "  50: Y_test_bin4=XY_test_bin4[:,1]\n",
      "  51: #print(X_test_bin4.shape)\n",
      "  52: \n",
      "  53: \n",
      "  54: \n",
      "  55: Y_train=conjunto_datos[:tamanyo_tr,1] #elijo la coordenada radius\n",
      "  56: Y_val=conjunto_datos[tamanyo_tr:tamanyo_tr+tamanyo_val,1] #elijo la corrdenada radius\n",
      "  57: Y_test=conjunto_datos[tamanyo_tr+tamanyo_val:numero_muestras,1] #elijo la corrdenada radius\n",
      "  58: \n",
      "  59: X_train = X_train.reshape(X_train.shape[0], img_cols, img_rows,1)\n",
      "  60: X_val = X_val.reshape(X_val.shape[0], img_cols, img_rows,1)\n",
      "  61: X_test = X_test.reshape(X_test.shape[0], img_cols, img_rows,1)\n",
      "  62: \n",
      "  63: X_test_bin0 = X_test_bin0.reshape(X_test_bin0.shape[0], img_cols, img_rows,1)\n",
      "  64: X_test_bin1 = X_test_bin1.reshape(X_test_bin1.shape[0], img_cols, img_rows,1)\n",
      "  65: X_test_bin2 = X_test_bin2.reshape(X_test_bin2.shape[0], img_cols, img_rows,1)\n",
      "  66: X_test_bin3 = X_test_bin3.reshape(X_test_bin3.shape[0], img_cols, img_rows,1)\n",
      "  67: X_test_bin4 = X_test_bin4.reshape(X_test_bin4.shape[0], img_cols, img_rows,1)\n",
      "  68: \n",
      "  69: X_train = X_train.astype('float32')\n",
      "  70: X_val= X_val.astype('float32')\n",
      "  71: X_test = X_test.astype('float32')    \n",
      "  72: \n",
      "  73: #input_shape = (img_cols, img_rows,1)\n",
      "  74: \n",
      "  75: \n",
      "  76: \n",
      "  77: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     '''\n",
      "   4:     Model providing function:\n",
      "   5: \n",
      "   6:     Create Keras model with double curly brackets dropped-in as needed.\n",
      "   7:     Return value has to be a valid python dictionary with two customary keys:\n",
      "   8:         - loss: Specify a numeric evaluation metric to be minimized\n",
      "   9:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
      "  10:     The last one is optional, though recommended, namely:\n",
      "  11:         - model: specify the model just created so that we can later use it again.\n",
      "  12:     '''\n",
      "  13:     nb_epoch = 150\n",
      "  14: \n",
      "  15:     nb_filters = 32\n",
      "  16: \n",
      "  17:     pool_size = (2, 2)\n",
      "  18: \n",
      "  19:     kernel_size = (4,4)\n",
      "  20:     model = Sequential()\n",
      "  21: \n",
      "  22:     model.add(Conv2D(8, kernel_size=kernel_size,\n",
      "  23:                             padding='same',\n",
      "  24:                             input_shape=(30,16,1)))\n",
      "  25:     model.add(BatchNormalization())\n",
      "  26:     model.add(Activation('relu'))\n",
      "  27:     model.add(MaxPooling2D(pool_size=pool_size))\n",
      "  28: \n",
      "  29:     model.add(Conv2D(16, kernel_size, padding='same'))\n",
      "  30:     model.add(BatchNormalization())\n",
      "  31:     model.add(Activation('relu'))\n",
      "  32:     model.add(MaxPooling2D(pool_size=pool_size))\n",
      "  33: \n",
      "  34:     model.add(Conv2D(32, kernel_size, padding='same'))\n",
      "  35:     model.add(BatchNormalization())\n",
      "  36:     model.add(Activation('relu'))\n",
      "  37: \n",
      "  38:     model.add(Conv2D(64, kernel_size, padding='same'))\n",
      "  39:     model.add(BatchNormalization())\n",
      "  40:     model.add(Activation('relu'))\n",
      "  41: \n",
      "  42:     model.add(Dropout(space['Dropout']))\n",
      "  43:     model.add(Flatten())\n",
      "  44:     model.add(Dense(1))\n",
      "  45: \n",
      "  46: \n",
      "  47:     model.compile(loss='mean_squared_error',\n",
      "  48:                   optimizer=space['optimizer'],\n",
      "  49:                   metrics=['mae','acc'])\n",
      "  50:     model.fit(X_train, Y_train, \n",
      "  51:               batch_size=space['batch_size'],\n",
      "  52:               epochs=100,\n",
      "  53:               verbose=0,\n",
      "  54:               validation_data=(X_val, Y_val))\n",
      "  55:     score = model.evaluate(X_test, Y_test, verbose=0)\n",
      "  56:     print('Test mse:', score[0])\n",
      "  57:     return {'loss': score[0], 'status': STATUS_OK, 'model': model}           \n",
      "  58: \n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test, X_val, Y_val = data()\n",
    "best_run, best_model = optim.minimize(model=model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=10,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='CNN_for_PETALO_radius-optimization')\n",
    "print('acabe la optimizacion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score = best_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test mse:', score[0])\n",
    "print('Test mae:', score[1])\n",
    "Y_test_predicted=best_model.predict(X_test)\n",
    "print(Y_test_predicted[:10].flatten())\n",
    "print(Y_test[:10])\n",
    "error_prediction=Y_test-Y_test_predicted.flatten()\n",
    "\n",
    "print(error_prediction[:10])\n",
    "n, bins, patches = plt.hist(error_prediction, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "plt.title(\"Histogram with 400 bins\")\n",
    "plt.show()\n",
    "x=bins[:400]\n",
    "y=n\n",
    "print(n.shape)\n",
    "print(bins.shape)\n",
    "from numpy import exp, loadtxt, pi, sqrt, log\n",
    "\n",
    "from lmfit import Model\n",
    "def gaussian(x, amp, cen, wid):\n",
    "    \"\"\"1-d gaussian: gaussian(x, amp, cen, wid)\"\"\"\n",
    "    return amp * exp(-((x-cen)/wid)**2 )\n",
    "\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "\n",
    "print(result.fit_report())\n",
    "\n",
    "plt.plot(x, y, 'bo')\n",
    "plt.plot(x, result.init_fit, 'k--')\n",
    "plt.plot(x, result.best_fit, 'r-')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWHM=result.params['wid'].value*2*sqrt(log(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FWHM)\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_bin0_predicted=best_model.predict(X_test_bin0)\n",
    "print(Y_test_bin0_predicted)\n",
    "error_prediction_bin0=Y_test_bin0-Y_test_bin0_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin0, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin0=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_bin1_predicted=best_model.predict(X_test_bin1)\n",
    "#print(Y_test_bin1_predicted)\n",
    "error_prediction_bin1=Y_test_bin1-Y_test_bin1_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin1, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin1=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_bin2_predicted=best_model.predict(X_test_bin2)\n",
    "#print(Y_test_bin2_predicted)\n",
    "error_prediction_bin2=Y_test_bin2-Y_test_bin2_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin2, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin2=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_bin3_predicted=best_model.predict(X_test_bin3)\n",
    "#print(Y_test_bin3_predicted)\n",
    "error_prediction_bin3=Y_test_bin3-Y_test_bin3_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin3, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin3=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_bin4_predicted=best_model.predict(X_test_bin4)\n",
    "#print(Y_test_bin4_predicted)\n",
    "error_prediction_bin4=Y_test_bin4-Y_test_bin4_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin4, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin4=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin4)\n",
    "print(FWHM_bin3)\n",
    "print(FWHM_bin2)\n",
    "print(FWHM_bin1)\n",
    "print(FWHM_bin0)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
