{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple AUTOENCODER for PETALO\n",
    "\n",
    "Esta red la vamos a utilizar para obtener el radio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python36.zip', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/lib-dynload', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/extensions', '/home/rgadea3/.ipython']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#np.random.seed(1337)  # for reproducibility\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append(\"/home/rgadea/lmfit-py/\")\n",
    "import seaborn as sns\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from math import floor\n",
    "from lmfit.models import  GaussianModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos introducir los datos de petalo preprocesados en matlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66498, 640)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import hdf5storage\n",
    "datos_matlab = hdf5storage.loadmat('../datos_octubre_2018/conjunto_entrenamiento_octubre_2018_red_pitch5mm_rad161mm_total.mat')\n",
    "conjunto_datos= datos_matlab.get('photodefA')\n",
    "conjunto_datos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6320, 3840)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "dir_name='../datos_octubre_2018'\n",
    "base_filename='p_OF_5mm_161mm'\n",
    "filename_suffix='.h5'\n",
    "file=os.path.join(dir_name, base_filename+ \"{0:03d}\".format(0) + filename_suffix)\n",
    "conjunto_datos_waves=pd.read_hdf(file,'MC')\n",
    "datos_waves=conjunto_datos_waves.values\n",
    "datos_waves.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12641, 3840)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1,2):\n",
    "    file=os.path.join(dir_name, base_filename+ \"{0:03d}\".format(i) + filename_suffix)\n",
    "    #print(file)\n",
    "    veamos=pd.read_hdf(file,'MC')\n",
    "    veamos_array=veamos.values\n",
    "    datos_waves=np.concatenate((datos_waves,veamos_array),axis=0)\n",
    "datos_waves.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12641, 3840)\n"
     ]
    }
   ],
   "source": [
    "L1A=6;\n",
    "# hay tres L1 con 640 sensores (40*16)\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 16, 40\n",
    "\n",
    "X_trained=datos_waves;\n",
    "x_trained=X_trained;\n",
    "\n",
    "for i in range (X_trained.shape[0]):\n",
    "    idea1=X_trained[i,:].reshape(img_rows,(L1A*img_cols));\n",
    "    ideat=idea1.transpose();\n",
    "    idea2=ideat.reshape(1,(L1A*img_cols)*img_rows);\n",
    "    x_trained[i,:] =idea2;\n",
    "\n",
    "print(x_trained.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_output_dim_A=img_rows*img_cols\n",
    "ideaA=np.zeros((L1A,input_output_dim_A))\n",
    "\n",
    "conjunto_datos=np.zeros((x_trained.shape[0]*L1A,input_output_dim_A))\n",
    "for i in range(x_trained.shape[0]):\n",
    "    for k in range(L1A):\n",
    "        ideaA[k,:]=x_trained[i,k*input_output_dim_A:k*input_output_dim_A+input_output_dim_A]\n",
    "    conjunto_datos[(i)*L1A :(i+1)*L1A,:] = ideaA    \n",
    "    \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_regularizer = True\n",
    "my_regularizer = None\n",
    "my_epochs = 50\n",
    "features_path = 'simple_autoe_features.pickle'\n",
    "labels_path = 'simple_autoe_labels.pickle'\n",
    "\n",
    "if use_regularizer:\n",
    "    # add a sparsity constraint on the encoded representations\n",
    "    # note use of 10e-5 leads to blurred results\n",
    "    my_regularizer = regularizers.l2(0.001)\n",
    "    # and a larger number of epochs as the added regularization the model\n",
    "    # is less likely to overfit and can be trained longer\n",
    "    my_epochs = 100\n",
    "    features_path = 'sparse_autoe_features.pickle'\n",
    "    labels_path = 'sparse_autoe_labels.pickle'\n",
    "\n",
    "   \n",
    "    \n",
    "encoding_dim = 200  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "\n",
    "# this is our input placeholder\n",
    "\n",
    "input_img = Input(shape=(img_rows*img_cols,))\n",
    "\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='sigmoid', use_bias=False,bias_initializer='random_uniform')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(img_cols*img_rows, activation='sigmoid',use_bias=True,bias_initializer='random_uniform')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "\n",
    "\n",
    "#autoencoder=Sequential([\n",
    "#    Dense(encoding_dim, kernel_regularizer=regularizers.l2(0.001), use_bias=True,bias_initializer='random_uniform',input_shape=(640,)),\n",
    "#    Activation('sigmoid'),\n",
    "#    Dense(img_cols*img_rows, use_bias=True,bias_initializer='random_uniform'),\n",
    "#    Activation('linear'),\n",
    "#])\n",
    "\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75846\n",
      "conjunto_datos shape: (75846, 640)\n",
      "45507\n",
      "15169\n",
      "15170\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "# (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "numero_muestras=conjunto_datos.shape[0]\n",
    "print(numero_muestras)\n",
    "print('conjunto_datos shape:', conjunto_datos.shape)\n",
    "\n",
    "tr_size=60\n",
    "val_size=20\n",
    "test_size=100-val_size-tr_size\n",
    "\n",
    "tamanyo_tr=floor(tr_size*numero_muestras/100)\n",
    "tamanyo_val=floor(val_size*numero_muestras/100)\n",
    "tamanyo_test=numero_muestras-tamanyo_tr-tamanyo_val\n",
    "print(tamanyo_tr)\n",
    "print(tamanyo_val)\n",
    "print(tamanyo_test)\n",
    "\n",
    "\n",
    "X_train=conjunto_datos[:tamanyo_tr,:]\n",
    "X_val=conjunto_datos[tamanyo_tr:tamanyo_tr+tamanyo_val,:]\n",
    "X_test=conjunto_datos[tamanyo_tr+tamanyo_val:numero_muestras,:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Y_train=conjunto_datos[:tamanyo_tr,1] #elijo la coordenada radius\n",
    "Y_val=conjunto_datos[tamanyo_tr:tamanyo_tr+tamanyo_val,1] #elijo la corrdenada radius\n",
    "Y_test=conjunto_datos[tamanyo_tr+tamanyo_val:numero_muestras,1] #elijo la corrdenada radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], img_cols, img_rows,1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_cols, img_rows,1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_cols, img_rows,1)\n",
    "\n",
    "\n",
    "input_shape = (img_cols, img_rows,1)\n",
    "#input_shape=input_shape.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (45507, 40, 16, 1)\n",
      "45507 train samples\n",
      "15169 validation samples\n",
      "15170 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_val= X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_val.shape[0], 'validation samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display 20 random training images using image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43277\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15304\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20534\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "#Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "#Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "for i in range(1,5):\n",
    "    idea=np.random.randint(1,X_train.shape[0])\n",
    "    plt.imshow(np.reshape(X_train[idea].transpose(), [16, 40]), vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    plt.show()\n",
    "    print(idea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a generar las matrices de datos para la red neuronal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45507, 640)\n",
      "(15170, 640)\n",
      "(15170, 640)\n"
     ]
    }
   ],
   "source": [
    "x_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
    "x_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n",
    "prueba=x_train[0:15170,:]\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(prueba.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.  , 0.  , 0.  , 0.01, 0.01, 0.  , 0.03, 0.  , 0.04, 0.02,\n",
       "       0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02,\n",
       "       0.03, 0.04, 0.01, 0.  , 0.02, 0.01, 0.02, 0.01, 0.02, 0.01, 0.  ,\n",
       "       0.01, 0.01, 0.01, 0.02, 0.  , 0.04, 0.05, 0.04, 0.01, 0.  , 0.  ,\n",
       "       0.01, 0.01, 0.02, 0.01, 0.  , 0.  , 0.01, 0.  , 0.01, 0.02, 0.03,\n",
       "       0.02, 0.01, 0.  , 0.04, 0.04, 0.04, 0.  , 0.01, 0.01, 0.01, 0.  ,\n",
       "       0.01, 0.  , 0.01, 0.03, 0.01, 0.01, 0.02, 0.01, 0.02, 0.03, 0.01,\n",
       "       0.  , 0.01, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.02, 0.02, 0.01,\n",
       "       0.03, 0.04, 0.03, 0.03, 0.01, 0.03, 0.  , 0.02, 0.  , 0.  , 0.01,\n",
       "       0.  , 0.  , 0.02, 0.01, 0.02, 0.01, 0.02, 0.  , 0.03, 0.02, 0.01,\n",
       "       0.02, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.03, 0.02,\n",
       "       0.01, 0.  , 0.01, 0.03, 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.01,\n",
       "       0.02, 0.  , 0.  , 0.01, 0.04, 0.02, 0.  , 0.01, 0.01, 0.  , 0.  ,\n",
       "       0.01, 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.02, 0.01, 0.  ,\n",
       "       0.  , 0.01, 0.01, 0.  , 0.  , 0.  , 0.01, 0.01, 0.  , 0.  , 0.  ,\n",
       "       0.02, 0.  , 0.01, 0.02, 0.  , 0.01, 0.02, 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.01, 0.01, 0.  , 0.  , 0.01, 0.01, 0.  , 0.  ,\n",
       "       0.01, 0.  , 0.  , 0.01, 0.01, 0.  , 0.  , 0.01, 0.  , 0.  , 0.01,\n",
       "       0.01, 0.02, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.01, 0.  , 0.01, 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.01, 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.01, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  ], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min_max_scaler = preprocessing.QuantileTransformer().fit(x_train)\n",
    "# min_max_scaler = preprocessing.MaxAbsScaler().fit(x_train)\n",
    "# min_max_scaler = preprocessing.StandardScaler(with_mean=False).fit(x_train)\n",
    "min_max_scaler = preprocessing.MinMaxScaler().fit(x_train)\n",
    "#min_max_scaler = preprocessing.RobustScaler().fit(x_train)\n",
    "supermax=100\n",
    "factor_aprendizaje=0.0001\n",
    "print(min_max_scaler)\n",
    "#x_train_scaled = min_max_scaler.transform(x_train)\n",
    "#x_test_scaled = min_max_scaler.transform(x_test)\n",
    "x_train_scaled=(x_train/supermax)\n",
    "x_test_scaled=(x_test/supermax)\n",
    "#min_max_scaler.scale_\n",
    "x_train[29413]\n",
    "x_train_scaled[29413]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the autoencoder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our metrics, for example energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as KK\n",
    "import keras.callbacks as KKcall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(KKcall.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self._data = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        X_val, y_val = self.validation_data[0], self.validation_data[1]\n",
    "        y_predict = np.asarray(self.model.predict(X_val))\n",
    "\n",
    "        y_val = np.sum((y_val+1)*supermax/2, axis=1)\n",
    "        y_predict = np.sum((y_predict+1)*supermax/2, axis=1)\n",
    "\n",
    "        self._data.append({\n",
    "            'val_energy': np.mean(y_predict-y_val),\n",
    "        })\n",
    "        return\n",
    "\n",
    "    def get_data(self):\n",
    "        return self._data\n",
    "\n",
    "metrics = Metrics()\n",
    "\n",
    "def energy_error(y_true, y_pred):\n",
    "    veamos_energia=(KK.sum(y_pred, axis=1)-KK.sum(y_true,axis=1))\n",
    "    return KK.mean(veamos_energia,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='RMSprop', loss='mse', metrics=[energy_error])\n",
    "\n",
    "autoencoder.optimizer.lr=(factor_aprendizaje)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a summary of the model parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now train the model and evaluate on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45507 samples, validate on 15170 samples\n",
      "Epoch 1/1000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 0.0847 - energy_error: 167.4982 - val_loss: 0.0123 - val_energy_error: 67.4085\n",
      "Epoch 2/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 0.0036 - energy_error: 31.1548 - val_loss: 6.1210e-04 - val_energy_error: 10.8606\n",
      "Epoch 3/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 4.3758e-04 - energy_error: 5.6384 - val_loss: 3.2117e-04 - val_energy_error: 2.9523\n",
      "Epoch 4/1000\n",
      "45507/45507 [==============================] - 1s 21us/step - loss: 3.5318e-04 - energy_error: 2.1429 - val_loss: 3.0536e-04 - val_energy_error: 1.6180\n",
      "Epoch 5/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4557e-04 - energy_error: 1.3378 - val_loss: 3.0185e-04 - val_energy_error: 1.1303\n",
      "Epoch 6/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4334e-04 - energy_error: 0.9823 - val_loss: 3.0045e-04 - val_energy_error: 0.8703\n",
      "Epoch 7/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4234e-04 - energy_error: 0.7753 - val_loss: 2.9973e-04 - val_energy_error: 0.7052\n",
      "Epoch 8/1000\n",
      "45507/45507 [==============================] - 1s 19us/step - loss: 3.4179e-04 - energy_error: 0.6371 - val_loss: 2.9931e-04 - val_energy_error: 0.5895\n",
      "Epoch 9/1000\n",
      "45507/45507 [==============================] - 1s 19us/step - loss: 3.4145e-04 - energy_error: 0.5371 - val_loss: 2.9904e-04 - val_energy_error: 0.5030\n",
      "Epoch 10/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4123e-04 - energy_error: 0.4607 - val_loss: 2.9885e-04 - val_energy_error: 0.4355\n",
      "Epoch 11/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4107e-04 - energy_error: 0.4001 - val_loss: 2.9871e-04 - val_energy_error: 0.3812\n",
      "Epoch 12/1000\n",
      "45507/45507 [==============================] - 1s 19us/step - loss: 3.4095e-04 - energy_error: 0.3507 - val_loss: 2.9861e-04 - val_energy_error: 0.3363\n",
      "Epoch 13/1000\n",
      "45507/45507 [==============================] - 1s 21us/step - loss: 3.4086e-04 - energy_error: 0.3095 - val_loss: 2.9853e-04 - val_energy_error: 0.2985\n",
      "Epoch 14/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4079e-04 - energy_error: 0.2746 - val_loss: 2.9847e-04 - val_energy_error: 0.2662\n",
      "Epoch 15/1000\n",
      "45507/45507 [==============================] - 1s 21us/step - loss: 3.4074e-04 - energy_error: 0.2445 - val_loss: 2.9842e-04 - val_energy_error: 0.2382\n",
      "Epoch 16/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4070e-04 - energy_error: 0.2183 - val_loss: 2.9838e-04 - val_energy_error: 0.2137\n",
      "Epoch 17/1000\n",
      "45507/45507 [==============================] - 1s 19us/step - loss: 3.4066e-04 - energy_error: 0.1953 - val_loss: 2.9835e-04 - val_energy_error: 0.1921\n",
      "Epoch 18/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4063e-04 - energy_error: 0.1749 - val_loss: 2.9832e-04 - val_energy_error: 0.1728\n",
      "Epoch 19/1000\n",
      "45507/45507 [==============================] - 1s 19us/step - loss: 3.4060e-04 - energy_error: 0.1567 - val_loss: 2.9830e-04 - val_energy_error: 0.1556\n",
      "Epoch 20/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4058e-04 - energy_error: 0.1404 - val_loss: 2.9828e-04 - val_energy_error: 0.1401\n",
      "Epoch 21/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4056e-04 - energy_error: 0.1256 - val_loss: 2.9826e-04 - val_energy_error: 0.1260\n",
      "Epoch 22/1000\n",
      "45507/45507 [==============================] - 1s 21us/step - loss: 3.4055e-04 - energy_error: 0.1122 - val_loss: 2.9824e-04 - val_energy_error: 0.1132\n",
      "Epoch 23/1000\n",
      "45507/45507 [==============================] - 1s 21us/step - loss: 3.4053e-04 - energy_error: 0.0999 - val_loss: 2.9823e-04 - val_energy_error: 0.1015\n",
      "Epoch 24/1000\n",
      "45507/45507 [==============================] - 1s 22us/step - loss: 3.4052e-04 - energy_error: 0.0887 - val_loss: 2.9822e-04 - val_energy_error: 0.0908\n",
      "Epoch 25/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4051e-04 - energy_error: 0.0784 - val_loss: 2.9821e-04 - val_energy_error: 0.0809\n",
      "Epoch 26/1000\n",
      "45507/45507 [==============================] - 1s 19us/step - loss: 3.4050e-04 - energy_error: 0.0690 - val_loss: 2.9820e-04 - val_energy_error: 0.0718\n",
      "Epoch 27/1000\n",
      "45507/45507 [==============================] - 1s 19us/step - loss: 3.4049e-04 - energy_error: 0.0602 - val_loss: 2.9819e-04 - val_energy_error: 0.0634\n",
      "Epoch 28/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4049e-04 - energy_error: 0.0521 - val_loss: 2.9819e-04 - val_energy_error: 0.0556\n",
      "Epoch 29/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4048e-04 - energy_error: 0.0446 - val_loss: 2.9818e-04 - val_energy_error: 0.0483\n",
      "Epoch 30/1000\n",
      "45507/45507 [==============================] - 1s 19us/step - loss: 3.4047e-04 - energy_error: 0.0375 - val_loss: 2.9817e-04 - val_energy_error: 0.0415\n",
      "Epoch 31/1000\n",
      "45507/45507 [==============================] - 1s 21us/step - loss: 3.4047e-04 - energy_error: 0.0310 - val_loss: 2.9817e-04 - val_energy_error: 0.0352\n",
      "Epoch 32/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4046e-04 - energy_error: 0.0249 - val_loss: 2.9816e-04 - val_energy_error: 0.0293\n",
      "Epoch 33/1000\n",
      "45507/45507 [==============================] - 1s 19us/step - loss: 3.4046e-04 - energy_error: 0.0192 - val_loss: 2.9816e-04 - val_energy_error: 0.0238\n",
      "Epoch 34/1000\n",
      "45507/45507 [==============================] - 1s 19us/step - loss: 3.4045e-04 - energy_error: 0.0138 - val_loss: 2.9815e-04 - val_energy_error: 0.0186\n",
      "Epoch 35/1000\n",
      "45507/45507 [==============================] - 1s 18us/step - loss: 3.4045e-04 - energy_error: 0.0088 - val_loss: 2.9815e-04 - val_energy_error: 0.0137\n",
      "Epoch 36/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4045e-04 - energy_error: 0.0041 - val_loss: 2.9815e-04 - val_energy_error: 0.0092\n",
      "Epoch 37/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4044e-04 - energy_error: -3.2463e-04 - val_loss: 2.9814e-04 - val_energy_error: 0.0049\n",
      "Epoch 38/1000\n",
      "45507/45507 [==============================] - 1s 19us/step - loss: 3.4044e-04 - energy_error: -0.0045 - val_loss: 2.9814e-04 - val_energy_error: 8.1404e-04\n",
      "Epoch 39/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4044e-04 - energy_error: -0.0084 - val_loss: 2.9814e-04 - val_energy_error: -0.0030\n",
      "Epoch 40/1000\n",
      "45507/45507 [==============================] - 1s 19us/step - loss: 3.4043e-04 - energy_error: -0.0121 - val_loss: 2.9814e-04 - val_energy_error: -0.0066\n",
      "Epoch 41/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4043e-04 - energy_error: -0.0157 - val_loss: 2.9813e-04 - val_energy_error: -0.0100\n",
      "Epoch 42/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4043e-04 - energy_error: -0.0190 - val_loss: 2.9813e-04 - val_energy_error: -0.0132\n",
      "Epoch 43/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4043e-04 - energy_error: -0.0221 - val_loss: 2.9813e-04 - val_energy_error: -0.0163\n",
      "Epoch 44/1000\n",
      "45507/45507 [==============================] - 1s 19us/step - loss: 3.4043e-04 - energy_error: -0.0251 - val_loss: 2.9813e-04 - val_energy_error: -0.0192\n",
      "Epoch 45/1000\n",
      "45507/45507 [==============================] - 1s 19us/step - loss: 3.4042e-04 - energy_error: -0.0279 - val_loss: 2.9812e-04 - val_energy_error: -0.0219\n",
      "Epoch 46/1000\n",
      "45507/45507 [==============================] - 1s 19us/step - loss: 3.4042e-04 - energy_error: -0.0305 - val_loss: 2.9812e-04 - val_energy_error: -0.0245\n",
      "Epoch 47/1000\n",
      "45507/45507 [==============================] - 1s 19us/step - loss: 3.4042e-04 - energy_error: -0.0330 - val_loss: 2.9812e-04 - val_energy_error: -0.0270\n",
      "Epoch 48/1000\n",
      "45507/45507 [==============================] - 1s 18us/step - loss: 3.4042e-04 - energy_error: -0.0354 - val_loss: 2.9812e-04 - val_energy_error: -0.0293\n",
      "Epoch 49/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4042e-04 - energy_error: -0.0377 - val_loss: 2.9812e-04 - val_energy_error: -0.0315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4041e-04 - energy_error: -0.0399 - val_loss: 2.9812e-04 - val_energy_error: -0.0336\n",
      "Epoch 51/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4041e-04 - energy_error: -0.0419 - val_loss: 2.9811e-04 - val_energy_error: -0.0356\n",
      "Epoch 52/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4041e-04 - energy_error: -0.0438 - val_loss: 2.9811e-04 - val_energy_error: -0.0375\n",
      "Epoch 53/1000\n",
      "45507/45507 [==============================] - 1s 19us/step - loss: 3.4041e-04 - energy_error: -0.0457 - val_loss: 2.9811e-04 - val_energy_error: -0.0393\n",
      "Epoch 54/1000\n",
      "45507/45507 [==============================] - 1s 19us/step - loss: 3.4041e-04 - energy_error: -0.0474 - val_loss: 2.9811e-04 - val_energy_error: -0.0410\n",
      "Epoch 55/1000\n",
      "45507/45507 [==============================] - 1s 21us/step - loss: 3.4041e-04 - energy_error: -0.0491 - val_loss: 2.9811e-04 - val_energy_error: -0.0426\n",
      "Epoch 56/1000\n",
      "45507/45507 [==============================] - 1s 21us/step - loss: 3.4040e-04 - energy_error: -0.0507 - val_loss: 2.9811e-04 - val_energy_error: -0.0442\n",
      "Epoch 57/1000\n",
      "45507/45507 [==============================] - 1s 21us/step - loss: 3.4040e-04 - energy_error: -0.0522 - val_loss: 2.9811e-04 - val_energy_error: -0.0456\n",
      "Epoch 58/1000\n",
      "45507/45507 [==============================] - 1s 20us/step - loss: 3.4040e-04 - energy_error: -0.0536 - val_loss: 2.9810e-04 - val_energy_error: -0.0470\n",
      "Epoch 59/1000\n",
      "  200/45507 [..............................] - ETA: 1s - loss: 2.0246e-04 - energy_error: 0.0466"
     ]
    }
   ],
   "source": [
    "algoritmo='RMSprop'\n",
    "experimento=\"scaled_{}_encoder_without_bias_sig_sig_lr_{}\".format(supermax,factor_aprendizaje)\n",
    "tensorboard=TensorBoard(log_dir=\"/home/rgadea3/EXPERIMENTOS/nuevas_investigaciones_2018/experimentos/logs/defs/{}{}{}{}\".format(encoding_dim,algoritmo,experimento,datetime.now()))\n",
    "#modelCheckpoint=ModelCheckpoint(\"/home/rgadea3/EXPERIMENTOS/nuevas_investigaciones_2018/experimentos/logs/\", monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "early_stop=EarlyStopping(monitor='val_loss', min_delta=0, patience=500, verbose=2, mode='auto', baseline=None)\n",
    "autoencoder.fit(x_train_scaled, x_train_scaled,\n",
    "                epochs=10000,\n",
    "                batch_size=200,\n",
    "                shuffle=False,\n",
    "                callbacks=[tensorboard, early_stop, metrics],\n",
    "                validation_data=(x_test_scaled, x_test_scaled))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.evaluate(x=x_test_scaled,y=x_test_scaled)\n",
    "D=metrics.get_data()\n",
    "\n",
    "\n",
    "energies=pd.DataFrame(D).values.reshape(len(D))\n",
    "valores=len(energies)\n",
    "plt.plot(range(valores),energies) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save_weights('../redes_compresoras/defs/compresor_python_{}{}{}{}'.format(encoding_dim,algoritmo,experimento,datetime.now()))\n",
    "#np.savez('../redes_compresoras/maxmin_python_ver_rms_prop_scaled_min_max_ver2', min_max_scaler.data_max_, min_max_scaler.data_min_)\n",
    "#autoencoder.load_weights('../redes_compresoras/defs/compresor_python_320RMSpropscaled_100_encoder_without_bias_sig_sig_lr_0.00012018-11-03 09:43:55.047213')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scores = encoder.predict(x_test_scaled).ravel()\n",
    "#regularized_scores = encoded_regularized.predict(x_test).ravel()\n",
    "sns.distplot(standard_scores, hist=True, label='standard model')\n",
    "#sns.distplot(regularized_scores, hist=False, label='regularized model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some images\n",
    "# note that we take them from the *test* set\n",
    "# encoded_imgs = encoder.predict(x_test_min_max)\n",
    "# decoded_imgs_scaled = decoder.predict(encoded_imgs)\n",
    "#decoded_imgs_scaled = autoencoder.predict(x_test_min_max)\n",
    "decoded_imgs_scaled = autoencoder.predict(x_test_scaled)\n",
    "decoded_imgs = supermax*(decoded_imgs_scaled)\n",
    "#decoded_imgs = min_max_scaler.inverse_transform(decoded_imgs_scaled)\n",
    "#decoded_imgs = autoencoder.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    idea=np.random.randint(1,x_test.shape[0])\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[idea].reshape(40, 16).transpose(),vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[idea].reshape(40, 16).transpose(),vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "print(idea)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "filename = '../datos_octubre_2018/p_OF_5mm_161mm003.h5'\n",
    "conjunto_datos_test=pd.read_hdf(filename,'MC');\n",
    "conjunto_datos_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1A=6;\n",
    "# hay tres L1 con 640 sensores (40*16)\n",
    "L1B=0;\n",
    "# hay dos L1 con 640 sensores (40*16)\n",
    "X_trained=conjunto_datos_test.values;\n",
    "x_trained=X_trained;\n",
    "\n",
    "for i in range (X_trained.shape[0]):\n",
    "    idea1=X_trained[i,:].reshape(img_rows,(L1A*img_cols));\n",
    "    ideat=idea1.transpose();\n",
    "    idea2=ideat.reshape(1,(L1A*img_cols)*img_rows);\n",
    "    x_trained[i,:] =idea2;\n",
    "x_tested = x_trained;\n",
    "print(x_trained.shape)\n",
    "print(x_tested.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vamos a procesar y comprimir con la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora los particionamos y pasamos por las redes de compresin. Hay una red la A que se utiliza 5 veces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(x, derivative=False):\n",
    "  return x*(1-x) if derivative else 1/(1+np.exp(-x))\n",
    "ideaA=np.zeros((L1A,input_output_dim_A))\n",
    "\n",
    "cara_externa=x_tested[:,0: L1A*input_output_dim_A] \n",
    "cara_externa_reconstruida=np.zeros((x_tested.shape[0],L1A*input_output_dim_A))\n",
    "for i in range(x_tested.shape[0]):\n",
    "    for k in range(L1A):\n",
    "        ideaA[k,:]=x_tested[i,k*input_output_dim_A:k*input_output_dim_A+input_output_dim_A]\n",
    "    #ideaA_scaled=min_max_scaler.transform(ideaA)\n",
    "    ideaA_scaled=(ideaA/(supermax))\n",
    "    salida_reconstructed_1_scaled = autoencoder.predict(ideaA_scaled)    \n",
    "    salida_reconstructed_1 = supermax*(salida_reconstructed_1_scaled)\n",
    "    #salida_reconstructed_1 = min_max_scaler.inverse_transform(salida_reconstructed_1_scaled)     \n",
    "    #salida_reconstructed_1 = ideaA\n",
    "    \n",
    "    #entrada_imgs_A=(ideaA-min_A.transpose())/(max_A.transpose()-min_A.transpose())\n",
    "    #entrada_imgs_A=(ideaA) #he quitado el escalado\n",
    "    #encoded_imgs_A = sigmoid(np.dot(entrada_imgs_A, Encoder_weights_A) + Encoder_biases_A)\n",
    "    #decoded_imgs_A= (np.dot(encoded_imgs_A, Decoder_weights_A) + Decoder_biases_A)\n",
    "    #print(decoded_imgs_A.shape)\n",
    "    #salida_reconstructed_1 = decoded_imgs_A*(max_A.transpose()-min_A.transpose())+min_A.transpose();\n",
    "    #salida_reconstructed_1 = decoded_imgs_A #quito el escalado inverso    \n",
    " \n",
    "    hola1=np.reshape(salida_reconstructed_1,(L1A*input_output_dim_A))\n",
    "\n",
    "    #print(hola.shape)\n",
    "    salida_total=hola1\n",
    "    #salida_total[salida_total<0]=0\n",
    "    #print(salida_total.shape)\n",
    "    cara_externa_reconstruida[i]=salida_total\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizamos los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos todos los sensores: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 1  # how many digits we will display\n",
    "plt.figure(figsize=(40, 10))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    idea=np.random.randint(1,x_tested.shape[0])\n",
    "    idea=1890\n",
    "    idea= 4299\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(cara_externa[idea].reshape(L1A*img_cols, img_rows).transpose(), vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(cara_externa_reconstruida[idea].reshape(L1A*img_cols, img_rows).transpose(), vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos ahora L1 a L1, teniendo en cuenta que hay de dos tipos:\n",
    "L1A (con 36 columnas )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = L1A  # how many digits we will display\n",
    "plt.figure(figsize=(40, 10))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(cara_externa[idea].reshape(L1A*img_cols, img_rows).transpose()[:,i*img_cols:(i+1)*img_cols] ,vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax = plt.subplot(2, n, i + 1+n)\n",
    "    plt.imshow(cara_externa_reconstruida[idea].reshape(L1A*img_cols, img_rows).transpose()[:,i*img_cols:(i+1)*img_cols] ,vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=2\n",
    "print(cara_externa[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:])\n",
    "print(np.sum(cara_externa[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(cara_externa_reconstruida[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:].astype(int))\n",
    "print(np.sum(cara_externa_reconstruida[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(idea)\n",
    "np.sum(cara_externa_reconstruida,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veamos_energia=(np.sum(cara_externa_reconstruida, axis=1))-(np.sum(cara_externa, axis=1))\n",
    "n, bins, patches = plt.hist(veamos_energia, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "plt.title(\"Histogram with 400 bins\")\n",
    "plt.show()\n",
    "x=bins[:400]\n",
    "y=n\n",
    "print(n.shape)\n",
    "print(bins.shape)\n",
    "from numpy import exp, loadtxt, pi, sqrt, log\n",
    "\n",
    "from lmfit import Model\n",
    "def gaussian(x, amp, cen, wid):\n",
    "    \"\"\"1-d gaussian: gaussian(x, amp, cen, wid)\"\"\"\n",
    "    return amp * exp(-((x-cen)/wid)**2 )\n",
    "\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=200, cen=100, wid=100)\n",
    "\n",
    "print(result.fit_report())\n",
    "\n",
    "plt.plot(x, y, 'bo')\n",
    "plt.plot(x, result.init_fit, 'k--')\n",
    "plt.plot(x, result.best_fit, 'r-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "495px",
    "left": "1249px",
    "right": "57px",
    "top": "240px",
    "width": "390px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
