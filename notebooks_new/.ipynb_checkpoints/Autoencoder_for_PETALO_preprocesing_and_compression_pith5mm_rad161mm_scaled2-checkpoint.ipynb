{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple AUTOENCODER for PETALO\n",
    "\n",
    "Esta red la vamos a utilizar para obtener el radio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python36.zip', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/lib-dynload', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/extensions', '/home/rgadea3/.ipython', '/home/rgadea/lmfit-py/', '/home/rgadea/lmfit-py/', '/home/rgadea/lmfit-py/']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#np.random.seed(1337)  # for reproducibility\n",
    "from time import time\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append(\"/home/rgadea/lmfit-py/\")\n",
    "import seaborn as sns\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from math import floor\n",
    "#from lmfit.models import  GaussianModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos introducir los datos de petalo preprocesados en matlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66498, 640)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import hdf5storage\n",
    "datos_matlab = hdf5storage.loadmat('../datos_octubre_2018/conjunto_entrenamiento_octubre_2018_red_pitch5mm_rad161mm_total.mat')\n",
    "conjunto_datos= datos_matlab.get('photodefA')\n",
    "conjunto_datos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6320, 3840)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "dir_name='../datos_octubre_2018'\n",
    "base_filename='p_OF_5mm_161mm'\n",
    "filename_suffix='.h5'\n",
    "file=os.path.join(dir_name, base_filename+ \"{0:03d}\".format(0) + filename_suffix)\n",
    "conjunto_datos_waves=pd.read_hdf(file,'MC')\n",
    "datos_waves=conjunto_datos_waves.values\n",
    "datos_waves.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12641, 3840)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1,2):\n",
    "    file=os.path.join(dir_name, base_filename+ \"{0:03d}\".format(i) + filename_suffix)\n",
    "    #print(file)\n",
    "    veamos=pd.read_hdf(file,'MC')\n",
    "    veamos_array=veamos.values\n",
    "    datos_waves=np.concatenate((datos_waves,veamos_array),axis=0)\n",
    "datos_waves.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12641, 3840)\n"
     ]
    }
   ],
   "source": [
    "L1A=6;\n",
    "# hay tres L1 con 640 sensores (40*16)\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 16, 40\n",
    "\n",
    "X_trained=datos_waves;\n",
    "x_trained=X_trained;\n",
    "\n",
    "for i in range (X_trained.shape[0]):\n",
    "    idea1=X_trained[i,:].reshape(img_rows,(L1A*img_cols));\n",
    "    ideat=idea1.transpose();\n",
    "    idea2=ideat.reshape(1,(L1A*img_cols)*img_rows);\n",
    "    x_trained[i,:] =idea2;\n",
    "\n",
    "print(x_trained.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_output_dim_A=img_rows*img_cols\n",
    "ideaA=np.zeros((L1A,input_output_dim_A))\n",
    "\n",
    "conjunto_datos=np.zeros((x_trained.shape[0]*L1A,input_output_dim_A))\n",
    "for i in range(x_trained.shape[0]):\n",
    "    for k in range(L1A):\n",
    "        ideaA[k,:]=x_trained[i,k*input_output_dim_A:k*input_output_dim_A+input_output_dim_A]\n",
    "    conjunto_datos[(i)*L1A :(i+1)*L1A,:] = ideaA    \n",
    "    \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_regularizer = True\n",
    "my_regularizer = None\n",
    "my_epochs = 50\n",
    "features_path = 'simple_autoe_features.pickle'\n",
    "labels_path = 'simple_autoe_labels.pickle'\n",
    "\n",
    "if use_regularizer:\n",
    "    # add a sparsity constraint on the encoded representations\n",
    "    # note use of 10e-5 leads to blurred results\n",
    "    my_regularizer = regularizers.l2(0.001)\n",
    "    # and a larger number of epochs as the added regularization the model\n",
    "    # is less likely to overfit and can be trained longer\n",
    "    my_epochs = 100\n",
    "    features_path = 'sparse_autoe_features.pickle'\n",
    "    labels_path = 'sparse_autoe_labels.pickle'\n",
    "\n",
    "   \n",
    "    \n",
    "encoding_dim = 320  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "\n",
    "# this is our input placeholder\n",
    "\n",
    "input_img = Input(shape=(img_rows*img_cols,))\n",
    "\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='sigmoid', use_bias=False,bias_initializer='random_uniform')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(img_cols*img_rows, activation='sigmoid',use_bias=True,bias_initializer='random_uniform')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "\n",
    "\n",
    "#autoencoder=Sequential([\n",
    "#    Dense(encoding_dim, kernel_regularizer=regularizers.l2(0.001), use_bias=True,bias_initializer='random_uniform',input_shape=(640,)),\n",
    "#    Activation('sigmoid'),\n",
    "#    Dense(img_cols*img_rows, use_bias=True,bias_initializer='random_uniform'),\n",
    "#    Activation('linear'),\n",
    "#])\n",
    "\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75846\n",
      "conjunto_datos shape: (75846, 640)\n",
      "45507\n",
      "15169\n",
      "15170\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "# (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "numero_muestras=conjunto_datos.shape[0]\n",
    "print(numero_muestras)\n",
    "print('conjunto_datos shape:', conjunto_datos.shape)\n",
    "\n",
    "tr_size=60\n",
    "val_size=20\n",
    "test_size=100-val_size-tr_size\n",
    "\n",
    "tamanyo_tr=floor(tr_size*numero_muestras/100)\n",
    "tamanyo_val=floor(val_size*numero_muestras/100)\n",
    "tamanyo_test=numero_muestras-tamanyo_tr-tamanyo_val\n",
    "print(tamanyo_tr)\n",
    "print(tamanyo_val)\n",
    "print(tamanyo_test)\n",
    "\n",
    "\n",
    "X_train=conjunto_datos[:tamanyo_tr,:]\n",
    "X_val=conjunto_datos[tamanyo_tr:tamanyo_tr+tamanyo_val,:]\n",
    "X_test=conjunto_datos[tamanyo_tr+tamanyo_val:numero_muestras,:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Y_train=conjunto_datos[:tamanyo_tr,1] #elijo la coordenada radius\n",
    "Y_val=conjunto_datos[tamanyo_tr:tamanyo_tr+tamanyo_val,1] #elijo la corrdenada radius\n",
    "Y_test=conjunto_datos[tamanyo_tr+tamanyo_val:numero_muestras,1] #elijo la corrdenada radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], img_cols, img_rows,1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_cols, img_rows,1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_cols, img_rows,1)\n",
    "\n",
    "\n",
    "input_shape = (img_cols, img_rows,1)\n",
    "#input_shape=input_shape.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (45507, 40, 16, 1)\n",
      "45507 train samples\n",
      "15169 validation samples\n",
      "15170 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_val= X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_val.shape[0], 'validation samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display 20 random training images using image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23822\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24382\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35467\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "#Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "#Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "for i in range(1,5):\n",
    "    idea=np.random.randint(1,X_train.shape[0])\n",
    "    plt.imshow(np.reshape(X_train[idea].transpose(), [16, 40]), vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    plt.show()\n",
    "    print(idea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a generar las matrices de datos para la red neuronal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45507, 640)\n",
      "(15170, 640)\n",
      "(15170, 640)\n"
     ]
    }
   ],
   "source": [
    "x_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
    "x_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n",
    "prueba=x_train[0:15170,:]\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(prueba.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.  , 0.  , 0.  , 0.01, 0.01, 0.  , 0.03, 0.  , 0.04, 0.02,\n",
       "       0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02,\n",
       "       0.03, 0.04, 0.01, 0.  , 0.02, 0.01, 0.02, 0.01, 0.02, 0.01, 0.  ,\n",
       "       0.01, 0.01, 0.01, 0.02, 0.  , 0.04, 0.05, 0.04, 0.01, 0.  , 0.  ,\n",
       "       0.01, 0.01, 0.02, 0.01, 0.  , 0.  , 0.01, 0.  , 0.01, 0.02, 0.03,\n",
       "       0.02, 0.01, 0.  , 0.04, 0.04, 0.04, 0.  , 0.01, 0.01, 0.01, 0.  ,\n",
       "       0.01, 0.  , 0.01, 0.03, 0.01, 0.01, 0.02, 0.01, 0.02, 0.03, 0.01,\n",
       "       0.  , 0.01, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.02, 0.02, 0.01,\n",
       "       0.03, 0.04, 0.03, 0.03, 0.01, 0.03, 0.  , 0.02, 0.  , 0.  , 0.01,\n",
       "       0.  , 0.  , 0.02, 0.01, 0.02, 0.01, 0.02, 0.  , 0.03, 0.02, 0.01,\n",
       "       0.02, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.03, 0.02,\n",
       "       0.01, 0.  , 0.01, 0.03, 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.01,\n",
       "       0.02, 0.  , 0.  , 0.01, 0.04, 0.02, 0.  , 0.01, 0.01, 0.  , 0.  ,\n",
       "       0.01, 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.02, 0.01, 0.  ,\n",
       "       0.  , 0.01, 0.01, 0.  , 0.  , 0.  , 0.01, 0.01, 0.  , 0.  , 0.  ,\n",
       "       0.02, 0.  , 0.01, 0.02, 0.  , 0.01, 0.02, 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.01, 0.01, 0.  , 0.  , 0.01, 0.01, 0.  , 0.  ,\n",
       "       0.01, 0.  , 0.  , 0.01, 0.01, 0.  , 0.  , 0.01, 0.  , 0.  , 0.01,\n",
       "       0.01, 0.02, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.01, 0.  , 0.01, 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.01, 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.01, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  ], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min_max_scaler = preprocessing.QuantileTransformer().fit(x_train)\n",
    "# min_max_scaler = preprocessing.MaxAbsScaler().fit(x_train)\n",
    "# min_max_scaler = preprocessing.StandardScaler(with_mean=False).fit(x_train)\n",
    "min_max_scaler = preprocessing.MinMaxScaler().fit(x_train)\n",
    "#min_max_scaler = preprocessing.RobustScaler().fit(x_train)\n",
    "supermax=100\n",
    "print(min_max_scaler)\n",
    "#x_train_scaled = min_max_scaler.transform(x_train)\n",
    "#x_test_scaled = min_max_scaler.transform(x_test)\n",
    "x_train_scaled=x_train/supermax\n",
    "x_test_scaled=x_test/supermax\n",
    "#min_max_scaler.scale_\n",
    "x_train[29413]\n",
    "x_train_scaled[29413]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the autoencoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='RMSprop', loss='mse')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a summary of the model parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now train the model and evaluate on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'%Y-%m-%d %H'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-248a00c86622>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0malgoritmo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mexperimento\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"scaled_100_without_encoder_bias\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtensorboard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/home/rgadea3/EXPERIMENTOS/nuevas_investigaciones_2018/experimentos/logs/{}{}{%Y-%m-%d %H:%M}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgoritmo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexperimento\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#modelCheckpoint=ModelCheckpoint(\"/home/rgadea3/EXPERIMENTOS/nuevas_investigaciones_2018/experimentos/logs/\", monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '%Y-%m-%d %H'"
     ]
    }
   ],
   "source": [
    "algoritmo='rmsprop'\n",
    "experimento=\"scaled_100_without_encoder_bias\"\n",
    "tensorboard=TensorBoard(log_dir=\"/home/rgadea3/EXPERIMENTOS/nuevas_investigaciones_2018/experimentos/logs/{}{}{}\".format(algoritmo,experimento,time()))\n",
    "#modelCheckpoint=ModelCheckpoint(\"/home/rgadea3/EXPERIMENTOS/nuevas_investigaciones_2018/experimentos/logs/\", monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "early_stop=EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=2, mode='auto', baseline=None)\n",
    "autoencoder.fit(x_train_scaled, x_train_scaled,\n",
    "                epochs=5000,\n",
    "                batch_size=200,\n",
    "                shuffle=False,\n",
    "                callbacks=[tensorboard, early_stop],\n",
    "                validation_data=(x_test_scaled, x_test_scaled))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.evaluate(x=x_test_scaled,y=x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save_weights('../redes_compresoras/compresor_python_{}{}{}'.format(algoritmo,experimento,time()))\n",
    "#np.savez('../redes_compresoras/maxmin_python_ver_rms_prop_scaled_min_max_ver2', min_max_scaler.data_max_, min_max_scaler.data_min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scores = encoder.predict(x_test_scaled).ravel()\n",
    "#regularized_scores = encoded_regularized.predict(x_test).ravel()\n",
    "sns.distplot(standard_scores, hist=False, label='standard model')\n",
    "#sns.distplot(regularized_scores, hist=False, label='regularized model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some images\n",
    "# note that we take them from the *test* set\n",
    "# encoded_imgs = encoder.predict(x_test_min_max)\n",
    "# decoded_imgs_scaled = decoder.predict(encoded_imgs)\n",
    "#decoded_imgs_scaled = autoencoder.predict(x_test_min_max)\n",
    "decoded_imgs_scaled = autoencoder.predict(x_test_scaled)\n",
    "decoded_imgs = supermax*decoded_imgs_scaled\n",
    "#decoded_imgs = min_max_scaler.inverse_transform(decoded_imgs_scaled)\n",
    "#decoded_imgs = autoencoder.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    idea=np.random.randint(1,x_test.shape[0])\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[idea].reshape(40, 16).transpose(),vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[idea].reshape(40, 16).transpose(),vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "print(idea)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "filename = '../datos_octubre_2018/p_OF_5mm_161mm003.h5'\n",
    "conjunto_datos_test=pd.read_hdf(filename,'MC');\n",
    "conjunto_datos_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1A=6;\n",
    "# hay tres L1 con 640 sensores (40*16)\n",
    "L1B=0;\n",
    "# hay dos L1 con 640 sensores (40*16)\n",
    "X_trained=conjunto_datos_test.values;\n",
    "x_trained=X_trained;\n",
    "\n",
    "for i in range (X_trained.shape[0]):\n",
    "    idea1=X_trained[i,:].reshape(img_rows,(L1A*img_cols));\n",
    "    ideat=idea1.transpose();\n",
    "    idea2=ideat.reshape(1,(L1A*img_cols)*img_rows);\n",
    "    x_trained[i,:] =idea2;\n",
    "x_tested = x_trained;\n",
    "print(x_trained.shape)\n",
    "print(x_tested.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vamos a procesar y comprimir con la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora los particionamos y pasamos por las redes de compresi√≥n. Hay una red la A que se utiliza 5 veces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(x, derivative=False):\n",
    "  return x*(1-x) if derivative else 1/(1+np.exp(-x))\n",
    "ideaA=np.zeros((L1A,input_output_dim_A))\n",
    "\n",
    "cara_externa=x_tested[:,0: L1A*input_output_dim_A] \n",
    "cara_externa_reconstruida=np.zeros((x_tested.shape[0],L1A*input_output_dim_A))\n",
    "for i in range(x_tested.shape[0]):\n",
    "    for k in range(L1A):\n",
    "        ideaA[k,:]=x_tested[i,k*input_output_dim_A:k*input_output_dim_A+input_output_dim_A]\n",
    "    #ideaA_scaled=min_max_scaler.transform(ideaA)\n",
    "    ideaA_scaled=ideaA/(supermax)\n",
    "    salida_reconstructed_1_scaled = autoencoder.predict(ideaA_scaled)    \n",
    "    salida_reconstructed_1 = supermax*salida_reconstructed_1_scaled\n",
    "    #salida_reconstructed_1 = min_max_scaler.inverse_transform(salida_reconstructed_1_scaled)     \n",
    "    #salida_reconstructed_1 = ideaA\n",
    "    \n",
    "    #entrada_imgs_A=(ideaA-min_A.transpose())/(max_A.transpose()-min_A.transpose())\n",
    "    #entrada_imgs_A=(ideaA) #he quitado el escalado\n",
    "    #encoded_imgs_A = sigmoid(np.dot(entrada_imgs_A, Encoder_weights_A) + Encoder_biases_A)\n",
    "    #decoded_imgs_A= (np.dot(encoded_imgs_A, Decoder_weights_A) + Decoder_biases_A)\n",
    "    #print(decoded_imgs_A.shape)\n",
    "    #salida_reconstructed_1 = decoded_imgs_A*(max_A.transpose()-min_A.transpose())+min_A.transpose();\n",
    "    #salida_reconstructed_1 = decoded_imgs_A #quito el escalado inverso    \n",
    " \n",
    "    hola1=np.reshape(salida_reconstructed_1,(L1A*input_output_dim_A))\n",
    "\n",
    "    #print(hola.shape)\n",
    "    salida_total=hola1\n",
    "    #salida_total[salida_total<0]=0\n",
    "    #print(salida_total.shape)\n",
    "    cara_externa_reconstruida[i]=salida_total\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizamos los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos todos los sensores: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 1  # how many digits we will display\n",
    "plt.figure(figsize=(40, 10))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    idea=np.random.randint(1,x_tested.shape[0])\n",
    "    idea=1890\n",
    "    idea= 4299\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(cara_externa[idea].reshape(L1A*img_cols, img_rows).transpose(), vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(cara_externa_reconstruida[idea].reshape(L1A*img_cols, img_rows).transpose(), vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos ahora L1 a L1, teniendo en cuenta que hay de dos tipos:\n",
    "L1A (con 36 columnas )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = L1A  # how many digits we will display\n",
    "plt.figure(figsize=(40, 10))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(cara_externa[idea].reshape(L1A*img_cols, img_rows).transpose()[:,i*img_cols:(i+1)*img_cols] ,vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax = plt.subplot(2, n, i + 1+n)\n",
    "    plt.imshow(cara_externa_reconstruida[idea].reshape(L1A*img_cols, img_rows).transpose()[:,i*img_cols:(i+1)*img_cols] ,vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=2\n",
    "print(cara_externa[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:])\n",
    "print(np.sum(cara_externa[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(cara_externa_reconstruida[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:].astype(int))\n",
    "print(np.sum(cara_externa_reconstruida[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(idea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "495px",
    "left": "1249px",
    "right": "57px",
    "top": "240px",
    "width": "390px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
