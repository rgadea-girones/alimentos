{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple AUTOENCODER for PETALO\n",
    "\n",
    "Esta red la vamos a utilizar para obtener el radio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python36.zip', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/lib-dynload', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/extensions', '/home/rgadea3/.ipython']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#np.random.seed(1337)  # for reproducibility\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append(\"/home/rgadea/lmfit-py/\")\n",
    "import seaborn as sns\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from math import floor\n",
    "from lmfit.models import  GaussianModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos introducir los datos de petalo preprocesados en matlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66498, 640)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import hdf5storage\n",
    "datos_matlab = hdf5storage.loadmat('../datos_octubre_2018/conjunto_entrenamiento_octubre_2018_red_pitch5mm_rad161mm_total.mat')\n",
    "conjunto_datos= datos_matlab.get('photodefA')\n",
    "conjunto_datos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6320, 3840)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "dir_name='../datos_octubre_2018'\n",
    "base_filename='p_OF_5mm_161mm'\n",
    "filename_suffix='.h5'\n",
    "file=os.path.join(dir_name, base_filename+ \"{0:03d}\".format(0) + filename_suffix)\n",
    "conjunto_datos_waves=pd.read_hdf(file,'MC')\n",
    "datos_waves=conjunto_datos_waves.values\n",
    "datos_waves.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12641, 3840)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1,2):\n",
    "    file=os.path.join(dir_name, base_filename+ \"{0:03d}\".format(i) + filename_suffix)\n",
    "    #print(file)\n",
    "    veamos=pd.read_hdf(file,'MC')\n",
    "    veamos_array=veamos.values\n",
    "    datos_waves=np.concatenate((datos_waves,veamos_array),axis=0)\n",
    "datos_waves.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12641, 3840)\n"
     ]
    }
   ],
   "source": [
    "L1A=6;\n",
    "# hay tres L1 con 640 sensores (40*16)\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 16, 40\n",
    "\n",
    "X_trained=datos_waves;\n",
    "x_trained=X_trained;\n",
    "\n",
    "for i in range (X_trained.shape[0]):\n",
    "    idea1=X_trained[i,:].reshape(img_rows,(L1A*img_cols));\n",
    "    ideat=idea1.transpose();\n",
    "    idea2=ideat.reshape(1,(L1A*img_cols)*img_rows);\n",
    "    x_trained[i,:] =idea2;\n",
    "\n",
    "print(x_trained.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_output_dim_A=img_rows*img_cols\n",
    "ideaA=np.zeros((L1A,input_output_dim_A))\n",
    "\n",
    "conjunto_datos=np.zeros((x_trained.shape[0]*L1A,input_output_dim_A))\n",
    "for i in range(x_trained.shape[0]):\n",
    "    for k in range(L1A):\n",
    "        ideaA[k,:]=x_trained[i,k*input_output_dim_A:k*input_output_dim_A+input_output_dim_A]\n",
    "    conjunto_datos[(i)*L1A :(i+1)*L1A,:] = ideaA    \n",
    "    \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_regularizer = True\n",
    "my_regularizer = None\n",
    "my_epochs = 50\n",
    "features_path = 'simple_autoe_features.pickle'\n",
    "labels_path = 'simple_autoe_labels.pickle'\n",
    "\n",
    "if use_regularizer:\n",
    "    # add a sparsity constraint on the encoded representations\n",
    "    # note use of 10e-5 leads to blurred results\n",
    "    my_regularizer = regularizers.l2(0.001)\n",
    "    # and a larger number of epochs as the added regularization the model\n",
    "    # is less likely to overfit and can be trained longer\n",
    "    my_epochs = 100\n",
    "    features_path = 'sparse_autoe_features.pickle'\n",
    "    labels_path = 'sparse_autoe_labels.pickle'\n",
    "\n",
    "   \n",
    "    \n",
    "encoding_dim = 400  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "\n",
    "# this is our input placeholder\n",
    "\n",
    "input_img = Input(shape=(img_rows*img_cols,))\n",
    "\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh', use_bias=False,bias_initializer='random_uniform')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(img_cols*img_rows, activation='tanh',use_bias=True,bias_initializer='random_uniform')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "\n",
    "\n",
    "#autoencoder=Sequential([\n",
    "#    Dense(encoding_dim, kernel_regularizer=regularizers.l2(0.001), use_bias=True,bias_initializer='random_uniform',input_shape=(640,)),\n",
    "#    Activation('sigmoid'),\n",
    "#    Dense(img_cols*img_rows, use_bias=True,bias_initializer='random_uniform'),\n",
    "#    Activation('linear'),\n",
    "#])\n",
    "\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75846\n",
      "conjunto_datos shape: (75846, 640)\n",
      "45507\n",
      "15169\n",
      "15170\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "# (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "numero_muestras=conjunto_datos.shape[0]\n",
    "print(numero_muestras)\n",
    "print('conjunto_datos shape:', conjunto_datos.shape)\n",
    "\n",
    "tr_size=60\n",
    "val_size=20\n",
    "test_size=100-val_size-tr_size\n",
    "\n",
    "tamanyo_tr=floor(tr_size*numero_muestras/100)\n",
    "tamanyo_val=floor(val_size*numero_muestras/100)\n",
    "tamanyo_test=numero_muestras-tamanyo_tr-tamanyo_val\n",
    "print(tamanyo_tr)\n",
    "print(tamanyo_val)\n",
    "print(tamanyo_test)\n",
    "\n",
    "\n",
    "X_train=conjunto_datos[:tamanyo_tr,:]\n",
    "X_val=conjunto_datos[tamanyo_tr:tamanyo_tr+tamanyo_val,:]\n",
    "X_test=conjunto_datos[tamanyo_tr+tamanyo_val:numero_muestras,:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Y_train=conjunto_datos[:tamanyo_tr,1] #elijo la coordenada radius\n",
    "Y_val=conjunto_datos[tamanyo_tr:tamanyo_tr+tamanyo_val,1] #elijo la corrdenada radius\n",
    "Y_test=conjunto_datos[tamanyo_tr+tamanyo_val:numero_muestras,1] #elijo la corrdenada radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], img_cols, img_rows,1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_cols, img_rows,1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_cols, img_rows,1)\n",
    "\n",
    "\n",
    "input_shape = (img_cols, img_rows,1)\n",
    "#input_shape=input_shape.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (45507, 40, 16, 1)\n",
      "45507 train samples\n",
      "15169 validation samples\n",
      "15170 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_val= X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_val.shape[0], 'validation samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display 20 random training images using image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43816\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14381\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35306\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21983\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "#Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "#Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "for i in range(1,5):\n",
    "    idea=np.random.randint(1,X_train.shape[0])\n",
    "    plt.imshow(np.reshape(X_train[idea].transpose(), [16, 40]), vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    plt.show()\n",
    "    print(idea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a generar las matrices de datos para la red neuronal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45507, 640)\n",
      "(15170, 640)\n",
      "(15170, 640)\n"
     ]
    }
   ],
   "source": [
    "x_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
    "x_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n",
    "prueba=x_train[0:15170,:]\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(prueba.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.98, -1.  , -1.  , -1.  , -0.98, -0.98, -1.  , -0.94, -1.  ,\n",
       "       -0.92, -0.96, -0.98, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -0.96, -0.94, -0.92, -0.98, -1.  , -0.96,\n",
       "       -0.98, -0.96, -0.98, -0.96, -0.98, -1.  , -0.98, -0.98, -0.98,\n",
       "       -0.96, -1.  , -0.92, -0.9 , -0.92, -0.98, -1.  , -1.  , -0.98,\n",
       "       -0.98, -0.96, -0.98, -1.  , -1.  , -0.98, -1.  , -0.98, -0.96,\n",
       "       -0.94, -0.96, -0.98, -1.  , -0.92, -0.92, -0.92, -1.  , -0.98,\n",
       "       -0.98, -0.98, -1.  , -0.98, -1.  , -0.98, -0.94, -0.98, -0.98,\n",
       "       -0.96, -0.98, -0.96, -0.94, -0.98, -1.  , -0.98, -0.98, -1.  ,\n",
       "       -1.  , -1.  , -1.  , -0.98, -0.96, -0.96, -0.98, -0.94, -0.92,\n",
       "       -0.94, -0.94, -0.98, -0.94, -1.  , -0.96, -1.  , -1.  , -0.98,\n",
       "       -1.  , -1.  , -0.96, -0.98, -0.96, -0.98, -0.96, -1.  , -0.94,\n",
       "       -0.96, -0.98, -0.96, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -0.96, -0.94, -0.96, -0.98, -1.  , -0.98, -0.94, -1.  ,\n",
       "       -1.  , -0.98, -1.  , -1.  , -1.  , -0.98, -0.96, -1.  , -1.  ,\n",
       "       -0.98, -0.92, -0.96, -1.  , -0.98, -0.98, -1.  , -1.  , -0.98,\n",
       "       -1.  , -1.  , -1.  , -0.98, -1.  , -1.  , -1.  , -0.96, -0.98,\n",
       "       -1.  , -1.  , -0.98, -0.98, -1.  , -1.  , -1.  , -0.98, -0.98,\n",
       "       -1.  , -1.  , -1.  , -0.96, -1.  , -0.98, -0.96, -1.  , -0.98,\n",
       "       -0.96, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -0.98,\n",
       "       -0.98, -1.  , -1.  , -0.98, -0.98, -1.  , -1.  , -0.98, -1.  ,\n",
       "       -1.  , -0.98, -0.98, -1.  , -1.  , -0.98, -1.  , -1.  , -0.98,\n",
       "       -0.98, -0.96, -1.  , -1.  , -1.  , -1.  , -0.98, -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -0.98, -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -0.98, -1.  , -0.98, -1.  , -0.98,\n",
       "       -1.  , -1.  , -1.  , -1.  , -0.98, -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -0.98, -0.98, -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -0.98, -0.98, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -0.98, -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -0.98,\n",
       "       -1.  , -0.98, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -0.98, -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -0.96, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -0.98, -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -0.98, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -0.98, -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -0.98, -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -0.98, -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -0.98, -1.  , -1.  , -1.  ,\n",
       "       -1.  , -0.98, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  ], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min_max_scaler = preprocessing.QuantileTransformer().fit(x_train)\n",
    "# min_max_scaler = preprocessing.MaxAbsScaler().fit(x_train)\n",
    "# min_max_scaler = preprocessing.StandardScaler(with_mean=False).fit(x_train)\n",
    "min_max_scaler = preprocessing.MinMaxScaler().fit(x_train)\n",
    "#min_max_scaler = preprocessing.RobustScaler().fit(x_train)\n",
    "supermax=100\n",
    "factor_aprendizaje=0.0001\n",
    "print(min_max_scaler)\n",
    "#x_train_scaled = min_max_scaler.transform(x_train)\n",
    "#x_test_scaled = min_max_scaler.transform(x_test)\n",
    "x_train_scaled=(2*x_train/supermax)-1\n",
    "x_test_scaled=(2*x_test/supermax)-1\n",
    "#min_max_scaler.scale_\n",
    "x_train[29413]\n",
    "x_train_scaled[29413]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the autoencoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='RMSprop', loss='mse')\n",
    "\n",
    "autoencoder.optimizer.lr=(factor_aprendizaje)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a summary of the model parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now train the model and evaluate on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45507 samples, validate on 15170 samples\n",
      "Epoch 1/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 0.0650 - val_loss: 0.0012\n",
      "Epoch 2/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 3/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 4/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 5/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 6/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 7/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 8/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 9/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 10/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 11/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 12/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 13/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 14/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 15/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 16/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 17/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 18/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 19/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 20/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 21/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 22/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 23/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 24/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 25/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 26/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 27/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 28/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 29/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 30/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 31/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 32/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 33/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 34/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 35/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 36/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 37/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 38/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 39/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 40/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 41/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 42/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 43/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 44/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 45/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 46/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 47/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 48/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 49/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 50/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 51/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 52/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 53/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 54/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 55/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 56/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 57/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 58/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 59/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 60/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 61/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 62/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 63/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 64/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 65/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 66/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 67/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 68/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 69/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 70/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 71/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 72/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 73/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 74/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 75/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 76/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 77/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 78/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 79/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 80/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 81/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 82/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 83/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 84/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 85/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 86/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 87/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 88/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 89/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 90/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 91/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 92/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 93/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 94/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 95/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 96/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 97/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 98/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 99/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 100/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 101/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 102/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0010 - val_loss: 9.9594e-04\n",
      "Epoch 103/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0010 - val_loss: 9.9072e-04\n",
      "Epoch 104/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 9.9383e-04 - val_loss: 9.8352e-04\n",
      "Epoch 105/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 9.8725e-04 - val_loss: 9.7506e-04\n",
      "Epoch 106/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 9.8061e-04 - val_loss: 9.6801e-04\n",
      "Epoch 107/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 9.7545e-04 - val_loss: 9.5992e-04\n",
      "Epoch 108/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 9.6854e-04 - val_loss: 9.5252e-04\n",
      "Epoch 109/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 9.5961e-04 - val_loss: 9.4622e-04\n",
      "Epoch 110/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 9.5230e-04 - val_loss: 9.3940e-04\n",
      "Epoch 111/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 9.4532e-04 - val_loss: 9.3151e-04\n",
      "Epoch 112/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 9.3815e-04 - val_loss: 9.2472e-04\n",
      "Epoch 113/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 9.3094e-04 - val_loss: 9.1784e-04\n",
      "Epoch 114/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 9.2363e-04 - val_loss: 9.1108e-04\n",
      "Epoch 115/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 9.1684e-04 - val_loss: 9.0468e-04\n",
      "Epoch 116/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 9.0896e-04 - val_loss: 8.9727e-04\n",
      "Epoch 117/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 9.0424e-04 - val_loss: 8.9190e-04\n",
      "Epoch 118/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 8.9823e-04 - val_loss: 8.8573e-04\n",
      "Epoch 119/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 8.9064e-04 - val_loss: 8.7968e-04\n",
      "Epoch 120/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 8.8466e-04 - val_loss: 8.7490e-04\n",
      "Epoch 121/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 8.8004e-04 - val_loss: 8.6956e-04\n",
      "Epoch 122/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 8.7476e-04 - val_loss: 8.6420e-04\n",
      "Epoch 123/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 8.6892e-04 - val_loss: 8.5921e-04\n",
      "Epoch 124/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 8.6399e-04 - val_loss: 8.5461e-04\n",
      "Epoch 125/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 8.5914e-04 - val_loss: 8.5030e-04\n",
      "Epoch 126/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 8.5465e-04 - val_loss: 8.4637e-04\n",
      "Epoch 127/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.5012e-04 - val_loss: 8.4264e-04\n",
      "Epoch 128/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.4530e-04 - val_loss: 8.3944e-04\n",
      "Epoch 129/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 8.4108e-04 - val_loss: 8.3705e-04\n",
      "Epoch 130/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.3712e-04 - val_loss: 8.3347e-04\n",
      "Epoch 131/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.3306e-04 - val_loss: 8.2991e-04\n",
      "Epoch 132/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 8.2904e-04 - val_loss: 8.2671e-04\n",
      "Epoch 133/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.2513e-04 - val_loss: 8.2380e-04\n",
      "Epoch 134/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 8.2153e-04 - val_loss: 8.2172e-04\n",
      "Epoch 135/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 8.1816e-04 - val_loss: 8.2014e-04\n",
      "Epoch 136/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 8.1494e-04 - val_loss: 8.1730e-04\n",
      "Epoch 137/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 8.1187e-04 - val_loss: 8.1366e-04\n",
      "Epoch 138/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 8.0896e-04 - val_loss: 8.1068e-04\n",
      "Epoch 139/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.0615e-04 - val_loss: 8.0829e-04\n",
      "Epoch 140/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.0337e-04 - val_loss: 8.0588e-04\n",
      "Epoch 141/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.0037e-04 - val_loss: 8.0302e-04\n",
      "Epoch 142/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.9766e-04 - val_loss: 8.0019e-04\n",
      "Epoch 143/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.9506e-04 - val_loss: 7.9748e-04\n",
      "Epoch 144/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 7.9256e-04 - val_loss: 7.9496e-04\n",
      "Epoch 145/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 7.9014e-04 - val_loss: 7.9265e-04\n",
      "Epoch 146/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.8778e-04 - val_loss: 7.9049e-04\n",
      "Epoch 147/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.8549e-04 - val_loss: 7.8843e-04\n",
      "Epoch 148/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.8325e-04 - val_loss: 7.8642e-04\n",
      "Epoch 149/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.8107e-04 - val_loss: 7.8443e-04\n",
      "Epoch 150/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.7894e-04 - val_loss: 7.8247e-04\n",
      "Epoch 151/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.7683e-04 - val_loss: 7.8053e-04\n",
      "Epoch 152/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.7473e-04 - val_loss: 7.7860e-04\n",
      "Epoch 153/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.7265e-04 - val_loss: 7.7671e-04\n",
      "Epoch 154/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 7.7061e-04 - val_loss: 7.7485e-04\n",
      "Epoch 155/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 7.6860e-04 - val_loss: 7.7302e-04\n",
      "Epoch 156/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 7.6662e-04 - val_loss: 7.7122e-04\n",
      "Epoch 157/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 7.6466e-04 - val_loss: 7.6944e-04\n",
      "Epoch 158/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.6274e-04 - val_loss: 7.6768e-04\n",
      "Epoch 159/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.6087e-04 - val_loss: 7.6592e-04\n",
      "Epoch 160/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 7.5908e-04 - val_loss: 7.6415e-04\n",
      "Epoch 161/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 7.5737e-04 - val_loss: 7.6234e-04\n",
      "Epoch 162/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.5572e-04 - val_loss: 7.6047e-04\n",
      "Epoch 163/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.5412e-04 - val_loss: 7.5852e-04\n",
      "Epoch 164/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 7.5253e-04 - val_loss: 7.5653e-04\n",
      "Epoch 165/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.5098e-04 - val_loss: 7.5462e-04\n",
      "Epoch 166/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.4942e-04 - val_loss: 7.5289e-04\n",
      "Epoch 167/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 7.4785e-04 - val_loss: 7.5134e-04\n",
      "Epoch 168/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.4628e-04 - val_loss: 7.4996e-04\n",
      "Epoch 169/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.4475e-04 - val_loss: 7.4868e-04\n",
      "Epoch 170/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 7.4330e-04 - val_loss: 7.4743e-04\n",
      "Epoch 171/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.4191e-04 - val_loss: 7.4618e-04\n",
      "Epoch 172/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.4057e-04 - val_loss: 7.4493e-04\n",
      "Epoch 173/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 7.3925e-04 - val_loss: 7.4369e-04\n",
      "Epoch 174/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 7.3797e-04 - val_loss: 7.4248e-04\n",
      "Epoch 175/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 7.3670e-04 - val_loss: 7.4130e-04\n",
      "Epoch 176/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 7.3546e-04 - val_loss: 7.4015e-04\n",
      "Epoch 177/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 7.3426e-04 - val_loss: 7.3903e-04\n",
      "Epoch 178/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.3309e-04 - val_loss: 7.3793e-04\n",
      "Epoch 179/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.3194e-04 - val_loss: 7.3685e-04\n",
      "Epoch 180/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 7.3080e-04 - val_loss: 7.3589e-04\n",
      "Epoch 181/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.2963e-04 - val_loss: 7.3533e-04\n",
      "Epoch 182/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.2845e-04 - val_loss: 7.3566e-04\n",
      "Epoch 183/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 7.2731e-04 - val_loss: 7.3651e-04\n",
      "Epoch 184/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.2626e-04 - val_loss: 7.3717e-04\n",
      "Epoch 185/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.2529e-04 - val_loss: 7.3737e-04\n",
      "Epoch 186/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.2434e-04 - val_loss: 7.3574e-04\n",
      "Epoch 187/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.2338e-04 - val_loss: 7.3339e-04\n",
      "Epoch 188/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.2244e-04 - val_loss: 7.3112e-04\n",
      "Epoch 189/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 7.2150e-04 - val_loss: 7.2906e-04\n",
      "Epoch 190/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.2059e-04 - val_loss: 7.2717e-04\n",
      "Epoch 191/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.1969e-04 - val_loss: 7.2544e-04\n",
      "Epoch 192/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 7.1879e-04 - val_loss: 7.2382e-04\n",
      "Epoch 193/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 7.1791e-04 - val_loss: 7.2232e-04\n",
      "Epoch 194/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 7.1704e-04 - val_loss: 7.2090e-04\n",
      "Epoch 195/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 7.1619e-04 - val_loss: 7.1958e-04\n",
      "Epoch 196/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 7.1534e-04 - val_loss: 7.1834e-04\n",
      "Epoch 197/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.1450e-04 - val_loss: 7.1720e-04\n",
      "Epoch 198/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.1368e-04 - val_loss: 7.1617e-04\n",
      "Epoch 199/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 7.1286e-04 - val_loss: 7.1523e-04\n",
      "Epoch 200/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.1206e-04 - val_loss: 7.1439e-04\n",
      "Epoch 201/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.1126e-04 - val_loss: 7.1365e-04\n",
      "Epoch 202/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 7.1048e-04 - val_loss: 7.1301e-04\n",
      "Epoch 203/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.0970e-04 - val_loss: 7.1245e-04\n",
      "Epoch 204/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.0894e-04 - val_loss: 7.1198e-04\n",
      "Epoch 205/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.0820e-04 - val_loss: 7.1159e-04\n",
      "Epoch 206/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.0746e-04 - val_loss: 7.1127e-04\n",
      "Epoch 207/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.0674e-04 - val_loss: 7.1102e-04\n",
      "Epoch 208/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.0603e-04 - val_loss: 7.1083e-04\n",
      "Epoch 209/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.0534e-04 - val_loss: 7.1069e-04\n",
      "Epoch 210/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 7.0466e-04 - val_loss: 7.1060e-04\n",
      "Epoch 211/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.0400e-04 - val_loss: 7.1056e-04\n",
      "Epoch 212/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.0334e-04 - val_loss: 7.1055e-04\n",
      "Epoch 213/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 7.0270e-04 - val_loss: 7.1058e-04\n",
      "Epoch 214/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.0207e-04 - val_loss: 7.1062e-04\n",
      "Epoch 215/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 7.0145e-04 - val_loss: 7.1069e-04\n",
      "Epoch 216/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.0084e-04 - val_loss: 7.1076e-04\n",
      "Epoch 217/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.0023e-04 - val_loss: 7.1084e-04\n",
      "Epoch 218/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.9964e-04 - val_loss: 7.1092e-04\n",
      "Epoch 219/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.9905e-04 - val_loss: 7.1099e-04\n",
      "Epoch 220/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.9847e-04 - val_loss: 7.1107e-04\n",
      "Epoch 221/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.9790e-04 - val_loss: 7.1114e-04\n",
      "Epoch 222/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.9735e-04 - val_loss: 7.1121e-04\n",
      "Epoch 223/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.9681e-04 - val_loss: 7.1130e-04\n",
      "Epoch 224/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.9629e-04 - val_loss: 7.1140e-04\n",
      "Epoch 225/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.9580e-04 - val_loss: 7.1152e-04\n",
      "Epoch 226/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.9532e-04 - val_loss: 7.1166e-04\n",
      "Epoch 227/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.9485e-04 - val_loss: 7.1182e-04\n",
      "Epoch 228/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.9439e-04 - val_loss: 7.1198e-04\n",
      "Epoch 229/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.9393e-04 - val_loss: 7.1213e-04\n",
      "Epoch 230/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.9348e-04 - val_loss: 7.1228e-04\n",
      "Epoch 231/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.9302e-04 - val_loss: 7.1244e-04\n",
      "Epoch 232/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.9257e-04 - val_loss: 7.1259e-04\n",
      "Epoch 233/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.9213e-04 - val_loss: 7.1275e-04\n",
      "Epoch 234/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.9169e-04 - val_loss: 7.1290e-04\n",
      "Epoch 235/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.9126e-04 - val_loss: 7.1305e-04\n",
      "Epoch 236/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.9084e-04 - val_loss: 7.1320e-04\n",
      "Epoch 237/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.9042e-04 - val_loss: 7.1335e-04\n",
      "Epoch 238/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.9001e-04 - val_loss: 7.1349e-04\n",
      "Epoch 239/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.8960e-04 - val_loss: 7.1364e-04\n",
      "Epoch 240/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.8920e-04 - val_loss: 7.1378e-04\n",
      "Epoch 241/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8880e-04 - val_loss: 7.1392e-04\n",
      "Epoch 242/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8840e-04 - val_loss: 7.1406e-04\n",
      "Epoch 243/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.8800e-04 - val_loss: 7.1420e-04\n",
      "Epoch 244/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8761e-04 - val_loss: 7.1431e-04\n",
      "Epoch 245/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.8722e-04 - val_loss: 7.1439e-04\n",
      "Epoch 246/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8684e-04 - val_loss: 7.1443e-04\n",
      "Epoch 247/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.8647e-04 - val_loss: 7.1444e-04\n",
      "Epoch 248/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.8612e-04 - val_loss: 7.1443e-04\n",
      "Epoch 249/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.8577e-04 - val_loss: 7.1439e-04\n",
      "Epoch 250/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.8544e-04 - val_loss: 7.1432e-04\n",
      "Epoch 251/10000\n",
      "45507/45507 [==============================] - 1s 22us/step - loss: 6.8511e-04 - val_loss: 7.1424e-04\n",
      "Epoch 252/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.8480e-04 - val_loss: 7.1413e-04\n",
      "Epoch 253/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.8450e-04 - val_loss: 7.1399e-04\n",
      "Epoch 254/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8422e-04 - val_loss: 7.1384e-04\n",
      "Epoch 255/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.8396e-04 - val_loss: 7.1369e-04\n",
      "Epoch 256/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8370e-04 - val_loss: 7.1354e-04\n",
      "Epoch 257/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8341e-04 - val_loss: 7.1336e-04\n",
      "Epoch 258/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8310e-04 - val_loss: 7.1310e-04\n",
      "Epoch 259/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8278e-04 - val_loss: 7.1280e-04\n",
      "Epoch 260/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.8247e-04 - val_loss: 7.1254e-04\n",
      "Epoch 261/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.8217e-04 - val_loss: 7.1236e-04\n",
      "Epoch 262/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8187e-04 - val_loss: 7.1210e-04\n",
      "Epoch 263/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.8169e-04 - val_loss: 7.1279e-04\n",
      "Epoch 264/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8147e-04 - val_loss: 7.1276e-04\n",
      "Epoch 265/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.8119e-04 - val_loss: 7.1247e-04\n",
      "Epoch 266/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.8071e-04 - val_loss: 7.1250e-04\n",
      "Epoch 267/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.8040e-04 - val_loss: 7.1245e-04\n",
      "Epoch 268/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.8009e-04 - val_loss: 7.1299e-04\n",
      "Epoch 269/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.7981e-04 - val_loss: 7.1284e-04\n",
      "Epoch 270/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.7932e-04 - val_loss: 7.1262e-04\n",
      "Epoch 271/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.7882e-04 - val_loss: 7.1237e-04\n",
      "Epoch 272/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.7871e-04 - val_loss: 7.1211e-04\n",
      "Epoch 273/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7827e-04 - val_loss: 7.1221e-04\n",
      "Epoch 274/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.7797e-04 - val_loss: 7.1222e-04\n",
      "Epoch 275/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7768e-04 - val_loss: 7.1224e-04\n",
      "Epoch 276/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7738e-04 - val_loss: 7.1231e-04\n",
      "Epoch 277/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7708e-04 - val_loss: 7.1243e-04\n",
      "Epoch 278/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7677e-04 - val_loss: 7.1256e-04\n",
      "Epoch 279/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7643e-04 - val_loss: 7.1270e-04\n",
      "Epoch 280/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7614e-04 - val_loss: 7.1263e-04\n",
      "Epoch 281/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7570e-04 - val_loss: 7.1259e-04\n",
      "Epoch 282/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.7560e-04 - val_loss: 7.1281e-04\n",
      "Epoch 283/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7508e-04 - val_loss: 7.1290e-04\n",
      "Epoch 284/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7486e-04 - val_loss: 7.1277e-04\n",
      "Epoch 285/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.7460e-04 - val_loss: 7.1272e-04\n",
      "Epoch 286/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7431e-04 - val_loss: 7.1272e-04\n",
      "Epoch 287/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.7402e-04 - val_loss: 7.1274e-04\n",
      "Epoch 288/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.7374e-04 - val_loss: 7.1276e-04\n",
      "Epoch 289/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.7349e-04 - val_loss: 7.1268e-04\n",
      "Epoch 290/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7327e-04 - val_loss: 7.1241e-04\n",
      "Epoch 291/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7304e-04 - val_loss: 7.1195e-04\n",
      "Epoch 292/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7281e-04 - val_loss: 7.1147e-04\n",
      "Epoch 293/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7260e-04 - val_loss: 7.1116e-04\n",
      "Epoch 294/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.7243e-04 - val_loss: 7.1119e-04\n",
      "Epoch 295/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.7231e-04 - val_loss: 7.1129e-04\n",
      "Epoch 296/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7215e-04 - val_loss: 7.1123e-04\n",
      "Epoch 297/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7191e-04 - val_loss: 7.1110e-04\n",
      "Epoch 298/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7162e-04 - val_loss: 7.1076e-04\n",
      "Epoch 299/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7126e-04 - val_loss: 7.1015e-04\n",
      "Epoch 300/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.7073e-04 - val_loss: 7.0907e-04\n",
      "Epoch 301/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.7041e-04 - val_loss: 7.0746e-04\n",
      "Epoch 302/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7003e-04 - val_loss: 7.0663e-04\n",
      "Epoch 303/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6992e-04 - val_loss: 7.0488e-04\n",
      "Epoch 304/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.7028e-04 - val_loss: 7.0643e-04\n",
      "Epoch 305/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.7020e-04 - val_loss: 7.0807e-04\n",
      "Epoch 306/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7015e-04 - val_loss: 7.0929e-04\n",
      "Epoch 307/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.6959e-04 - val_loss: 7.0857e-04\n",
      "Epoch 308/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6936e-04 - val_loss: 7.0839e-04\n",
      "Epoch 309/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6913e-04 - val_loss: 7.0827e-04\n",
      "Epoch 310/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6897e-04 - val_loss: 7.0836e-04\n",
      "Epoch 311/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.6882e-04 - val_loss: 7.0865e-04\n",
      "Epoch 312/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6865e-04 - val_loss: 7.0904e-04\n",
      "Epoch 313/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6842e-04 - val_loss: 7.0932e-04\n",
      "Epoch 314/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.6815e-04 - val_loss: 7.0937e-04\n",
      "Epoch 315/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6796e-04 - val_loss: 7.0945e-04\n",
      "Epoch 316/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6785e-04 - val_loss: 7.0991e-04\n",
      "Epoch 317/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.6748e-04 - val_loss: 7.0968e-04\n",
      "Epoch 318/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6742e-04 - val_loss: 7.1022e-04\n",
      "Epoch 319/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6725e-04 - val_loss: 7.0985e-04\n",
      "Epoch 320/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6727e-04 - val_loss: 7.0974e-04\n",
      "Epoch 321/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6705e-04 - val_loss: 7.0953e-04\n",
      "Epoch 322/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6681e-04 - val_loss: 7.0951e-04\n",
      "Epoch 323/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6655e-04 - val_loss: 7.0900e-04\n",
      "Epoch 324/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.6637e-04 - val_loss: 7.0832e-04\n",
      "Epoch 325/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6618e-04 - val_loss: 7.0741e-04\n",
      "Epoch 326/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.6596e-04 - val_loss: 7.0671e-04\n",
      "Epoch 327/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.6571e-04 - val_loss: 7.0642e-04\n",
      "Epoch 328/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6546e-04 - val_loss: 7.0618e-04\n",
      "Epoch 329/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6526e-04 - val_loss: 7.0544e-04\n",
      "Epoch 330/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6506e-04 - val_loss: 7.0466e-04\n",
      "Epoch 331/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6487e-04 - val_loss: 7.0419e-04\n",
      "Epoch 332/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6468e-04 - val_loss: 7.0378e-04\n",
      "Epoch 333/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6449e-04 - val_loss: 7.0330e-04\n",
      "Epoch 334/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6428e-04 - val_loss: 7.0256e-04\n",
      "Epoch 335/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6425e-04 - val_loss: 7.0094e-04\n",
      "Epoch 336/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6433e-04 - val_loss: 6.9899e-04\n",
      "Epoch 337/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6404e-04 - val_loss: 6.9752e-04\n",
      "Epoch 338/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6381e-04 - val_loss: 6.9636e-04\n",
      "Epoch 339/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6368e-04 - val_loss: 6.9609e-04\n",
      "Epoch 340/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6334e-04 - val_loss: 6.9629e-04\n",
      "Epoch 341/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6303e-04 - val_loss: 6.9681e-04\n",
      "Epoch 342/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6279e-04 - val_loss: 6.9881e-04\n",
      "Epoch 343/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6272e-04 - val_loss: 7.0019e-04\n",
      "Epoch 344/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.6266e-04 - val_loss: 7.0022e-04\n",
      "Epoch 345/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.6253e-04 - val_loss: 7.0141e-04\n",
      "Epoch 346/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.6232e-04 - val_loss: 7.0244e-04\n",
      "Epoch 347/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6207e-04 - val_loss: 7.0294e-04\n",
      "Epoch 348/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6187e-04 - val_loss: 7.0263e-04\n",
      "Epoch 349/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.6156e-04 - val_loss: 7.0116e-04\n",
      "Epoch 350/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6138e-04 - val_loss: 6.9959e-04\n",
      "Epoch 351/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6117e-04 - val_loss: 6.9774e-04\n",
      "Epoch 352/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6111e-04 - val_loss: 6.9253e-04\n",
      "Epoch 353/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6061e-04 - val_loss: 6.9423e-04\n",
      "Epoch 354/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6056e-04 - val_loss: 6.9513e-04\n",
      "Epoch 355/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.6048e-04 - val_loss: 6.9674e-04\n",
      "Epoch 356/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6048e-04 - val_loss: 6.9889e-04\n",
      "Epoch 357/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6036e-04 - val_loss: 7.0015e-04\n",
      "Epoch 358/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6015e-04 - val_loss: 7.0056e-04\n",
      "Epoch 359/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5987e-04 - val_loss: 7.0051e-04\n",
      "Epoch 360/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5979e-04 - val_loss: 7.0063e-04\n",
      "Epoch 361/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6005e-04 - val_loss: 6.9991e-04\n",
      "Epoch 362/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6009e-04 - val_loss: 6.9923e-04\n",
      "Epoch 363/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.5995e-04 - val_loss: 6.9918e-04\n",
      "Epoch 364/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.5998e-04 - val_loss: 6.9983e-04\n",
      "Epoch 365/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6010e-04 - val_loss: 6.9916e-04\n",
      "Epoch 366/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6013e-04 - val_loss: 6.9876e-04\n",
      "Epoch 367/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5990e-04 - val_loss: 6.9779e-04\n",
      "Epoch 368/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5968e-04 - val_loss: 6.9709e-04\n",
      "Epoch 369/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5935e-04 - val_loss: 6.9588e-04\n",
      "Epoch 370/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.5947e-04 - val_loss: 6.9512e-04\n",
      "Epoch 371/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.5925e-04 - val_loss: 6.9478e-04\n",
      "Epoch 372/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5906e-04 - val_loss: 6.9446e-04\n",
      "Epoch 373/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5884e-04 - val_loss: 6.9407e-04\n",
      "Epoch 374/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5859e-04 - val_loss: 6.9351e-04\n",
      "Epoch 375/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5849e-04 - val_loss: 6.9256e-04\n",
      "Epoch 376/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5845e-04 - val_loss: 6.9092e-04\n",
      "Epoch 377/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5834e-04 - val_loss: 6.8967e-04\n",
      "Epoch 378/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5811e-04 - val_loss: 6.8928e-04\n",
      "Epoch 379/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.5817e-04 - val_loss: 6.8956e-04\n",
      "Epoch 380/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5797e-04 - val_loss: 6.8965e-04\n",
      "Epoch 381/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.5785e-04 - val_loss: 6.8982e-04\n",
      "Epoch 382/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.5772e-04 - val_loss: 6.8985e-04\n",
      "Epoch 383/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5758e-04 - val_loss: 6.8959e-04\n",
      "Epoch 384/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.5746e-04 - val_loss: 6.8938e-04\n",
      "Epoch 385/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5731e-04 - val_loss: 6.8922e-04\n",
      "Epoch 386/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5713e-04 - val_loss: 6.8882e-04\n",
      "Epoch 387/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5693e-04 - val_loss: 6.8822e-04\n",
      "Epoch 388/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5674e-04 - val_loss: 6.8772e-04\n",
      "Epoch 389/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5655e-04 - val_loss: 6.8743e-04\n",
      "Epoch 390/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.5639e-04 - val_loss: 6.8705e-04\n",
      "Epoch 391/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5628e-04 - val_loss: 6.8722e-04\n",
      "Epoch 392/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5695e-04 - val_loss: 6.8544e-04\n",
      "Epoch 393/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.5600e-04 - val_loss: 6.8696e-04\n",
      "Epoch 394/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5615e-04 - val_loss: 6.9024e-04\n",
      "Epoch 395/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5582e-04 - val_loss: 7.0017e-04\n",
      "Epoch 396/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5632e-04 - val_loss: 6.9259e-04\n",
      "Epoch 397/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5566e-04 - val_loss: 6.9041e-04\n",
      "Epoch 398/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5514e-04 - val_loss: 7.0860e-04\n",
      "Epoch 399/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5607e-04 - val_loss: 7.0810e-04\n",
      "Epoch 400/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5592e-04 - val_loss: 7.0751e-04\n",
      "Epoch 401/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.5573e-04 - val_loss: 7.0767e-04\n",
      "Epoch 402/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5552e-04 - val_loss: 7.0851e-04\n",
      "Epoch 403/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.5509e-04 - val_loss: 6.9256e-04\n",
      "Epoch 404/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5471e-04 - val_loss: 6.8890e-04\n",
      "Epoch 405/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5474e-04 - val_loss: 6.8760e-04\n",
      "Epoch 406/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5538e-04 - val_loss: 6.9187e-04\n",
      "Epoch 407/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5402e-04 - val_loss: 7.1933e-04\n",
      "Epoch 408/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5509e-04 - val_loss: 6.8950e-04\n",
      "Epoch 409/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5416e-04 - val_loss: 6.8710e-04\n",
      "Epoch 410/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5437e-04 - val_loss: 6.9224e-04\n",
      "Epoch 411/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5437e-04 - val_loss: 6.8818e-04\n",
      "Epoch 412/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5452e-04 - val_loss: 6.8630e-04\n",
      "Epoch 413/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5400e-04 - val_loss: 6.9443e-04\n",
      "Epoch 414/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5517e-04 - val_loss: 6.9288e-04\n",
      "Epoch 415/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5472e-04 - val_loss: 6.8202e-04\n",
      "Epoch 416/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5311e-04 - val_loss: 6.8964e-04\n",
      "Epoch 417/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5311e-04 - val_loss: 6.8539e-04\n",
      "Epoch 418/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.5325e-04 - val_loss: 6.9288e-04\n",
      "Epoch 419/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.5421e-04 - val_loss: 6.8716e-04\n",
      "Epoch 420/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5273e-04 - val_loss: 6.8784e-04\n",
      "Epoch 421/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5299e-04 - val_loss: 6.8750e-04\n",
      "Epoch 422/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5299e-04 - val_loss: 6.9433e-04\n",
      "Epoch 423/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5369e-04 - val_loss: 6.9037e-04\n",
      "Epoch 424/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.5352e-04 - val_loss: 6.9433e-04\n",
      "Epoch 425/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5353e-04 - val_loss: 6.9056e-04\n",
      "Epoch 426/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5300e-04 - val_loss: 6.8623e-04\n",
      "Epoch 427/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.5275e-04 - val_loss: 6.8646e-04\n",
      "Epoch 428/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5397e-04 - val_loss: 6.8864e-04\n",
      "Epoch 429/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5271e-04 - val_loss: 6.9801e-04\n",
      "Epoch 430/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5276e-04 - val_loss: 7.1610e-04\n",
      "Epoch 431/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.5323e-04 - val_loss: 7.2911e-04\n",
      "Epoch 432/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5309e-04 - val_loss: 7.2583e-04\n",
      "Epoch 433/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5286e-04 - val_loss: 7.2440e-04\n",
      "Epoch 434/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.5198e-04 - val_loss: 6.9214e-04\n",
      "Epoch 435/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5332e-04 - val_loss: 7.1722e-04\n",
      "Epoch 436/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5165e-04 - val_loss: 7.1001e-04\n",
      "Epoch 437/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.5201e-04 - val_loss: 6.8788e-04\n",
      "Epoch 438/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.5200e-04 - val_loss: 7.2353e-04\n",
      "Epoch 439/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.5246e-04 - val_loss: 6.9384e-04\n",
      "Epoch 440/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5171e-04 - val_loss: 6.9303e-04\n",
      "Epoch 441/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.5234e-04 - val_loss: 7.0873e-04\n",
      "Epoch 442/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5143e-04 - val_loss: 6.9445e-04\n",
      "Epoch 443/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5254e-04 - val_loss: 7.3336e-04\n",
      "Epoch 444/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5192e-04 - val_loss: 7.1546e-04\n",
      "Epoch 445/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.5154e-04 - val_loss: 6.9073e-04\n",
      "Epoch 446/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5197e-04 - val_loss: 6.9001e-04\n",
      "Epoch 447/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5143e-04 - val_loss: 6.9434e-04\n",
      "Epoch 448/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5080e-04 - val_loss: 7.1163e-04\n",
      "Epoch 449/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5135e-04 - val_loss: 6.8796e-04\n",
      "Epoch 450/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.5086e-04 - val_loss: 6.8987e-04\n",
      "Epoch 451/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5073e-04 - val_loss: 6.9206e-04\n",
      "Epoch 452/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5129e-04 - val_loss: 6.9275e-04\n",
      "Epoch 453/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5009e-04 - val_loss: 6.9764e-04\n",
      "Epoch 454/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5018e-04 - val_loss: 7.0048e-04\n",
      "Epoch 455/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5002e-04 - val_loss: 6.9117e-04\n",
      "Epoch 456/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.5009e-04 - val_loss: 6.9227e-04\n",
      "Epoch 457/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.4985e-04 - val_loss: 6.8938e-04\n",
      "Epoch 458/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.4963e-04 - val_loss: 6.9468e-04\n",
      "Epoch 459/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4968e-04 - val_loss: 6.8925e-04\n",
      "Epoch 460/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.4952e-04 - val_loss: 6.8915e-04\n",
      "Epoch 461/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4951e-04 - val_loss: 6.9005e-04\n",
      "Epoch 462/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4933e-04 - val_loss: 6.8510e-04\n",
      "Epoch 463/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4927e-04 - val_loss: 6.8534e-04\n",
      "Epoch 464/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4956e-04 - val_loss: 7.0107e-04\n",
      "Epoch 465/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4976e-04 - val_loss: 7.0559e-04\n",
      "Epoch 466/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4926e-04 - val_loss: 7.0053e-04\n",
      "Epoch 467/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4992e-04 - val_loss: 6.9243e-04\n",
      "Epoch 468/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4944e-04 - val_loss: 6.8653e-04\n",
      "Epoch 469/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5013e-04 - val_loss: 6.9565e-04\n",
      "Epoch 470/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4898e-04 - val_loss: 7.0123e-04\n",
      "Epoch 471/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4967e-04 - val_loss: 7.0666e-04\n",
      "Epoch 472/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4955e-04 - val_loss: 6.9593e-04\n",
      "Epoch 473/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4960e-04 - val_loss: 6.9178e-04\n",
      "Epoch 474/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.4916e-04 - val_loss: 6.9798e-04\n",
      "Epoch 475/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4920e-04 - val_loss: 6.9214e-04\n",
      "Epoch 476/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.4915e-04 - val_loss: 6.9637e-04\n",
      "Epoch 477/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4875e-04 - val_loss: 6.9752e-04\n",
      "Epoch 478/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4870e-04 - val_loss: 7.1240e-04\n",
      "Epoch 479/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4910e-04 - val_loss: 7.0194e-04\n",
      "Epoch 480/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4849e-04 - val_loss: 6.9939e-04\n",
      "Epoch 481/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4869e-04 - val_loss: 7.0665e-04\n",
      "Epoch 482/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4900e-04 - val_loss: 7.0849e-04\n",
      "Epoch 483/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4871e-04 - val_loss: 6.9670e-04\n",
      "Epoch 484/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4815e-04 - val_loss: 6.9927e-04\n",
      "Epoch 485/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4829e-04 - val_loss: 6.9159e-04\n",
      "Epoch 486/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4852e-04 - val_loss: 6.9287e-04\n",
      "Epoch 487/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4807e-04 - val_loss: 6.9325e-04\n",
      "Epoch 488/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4797e-04 - val_loss: 6.9303e-04\n",
      "Epoch 489/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4752e-04 - val_loss: 6.9649e-04\n",
      "Epoch 490/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4757e-04 - val_loss: 6.9490e-04\n",
      "Epoch 491/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4760e-04 - val_loss: 6.9453e-04\n",
      "Epoch 492/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4755e-04 - val_loss: 7.1525e-04\n",
      "Epoch 493/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.4840e-04 - val_loss: 6.9836e-04\n",
      "Epoch 494/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.4748e-04 - val_loss: 6.8548e-04\n",
      "Epoch 495/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.4768e-04 - val_loss: 6.9467e-04\n",
      "Epoch 496/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.4823e-04 - val_loss: 6.9700e-04\n",
      "Epoch 497/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4715e-04 - val_loss: 6.8778e-04\n",
      "Epoch 498/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4736e-04 - val_loss: 7.1177e-04\n",
      "Epoch 499/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.4783e-04 - val_loss: 7.0132e-04\n",
      "Epoch 500/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4719e-04 - val_loss: 6.8784e-04\n",
      "Epoch 501/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4683e-04 - val_loss: 7.0281e-04\n",
      "Epoch 502/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4728e-04 - val_loss: 6.9688e-04\n",
      "Epoch 503/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4749e-04 - val_loss: 7.0235e-04\n",
      "Epoch 504/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4645e-04 - val_loss: 7.0044e-04\n",
      "Epoch 505/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4673e-04 - val_loss: 6.9598e-04\n",
      "Epoch 506/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4660e-04 - val_loss: 7.0523e-04\n",
      "Epoch 507/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4650e-04 - val_loss: 6.9107e-04\n",
      "Epoch 508/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4661e-04 - val_loss: 6.9387e-04\n",
      "Epoch 509/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4609e-04 - val_loss: 7.0627e-04\n",
      "Epoch 510/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4612e-04 - val_loss: 7.0063e-04\n",
      "Epoch 511/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4664e-04 - val_loss: 7.0091e-04\n",
      "Epoch 512/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.4676e-04 - val_loss: 6.9860e-04\n",
      "Epoch 513/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.4671e-04 - val_loss: 6.9554e-04\n",
      "Epoch 514/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.4637e-04 - val_loss: 6.9360e-04\n",
      "Epoch 515/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.4648e-04 - val_loss: 6.9807e-04\n",
      "Epoch 516/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4578e-04 - val_loss: 7.3338e-04\n",
      "Epoch 517/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4658e-04 - val_loss: 6.8651e-04\n",
      "Epoch 518/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4642e-04 - val_loss: 6.9586e-04\n",
      "Epoch 519/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4594e-04 - val_loss: 6.8940e-04\n",
      "Epoch 520/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.4604e-04 - val_loss: 6.9483e-04\n",
      "Epoch 521/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4502e-04 - val_loss: 6.9396e-04\n",
      "Epoch 522/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4573e-04 - val_loss: 6.9568e-04\n",
      "Epoch 523/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4555e-04 - val_loss: 6.9785e-04\n",
      "Epoch 524/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.4576e-04 - val_loss: 6.8518e-04\n",
      "Epoch 525/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4527e-04 - val_loss: 6.8305e-04\n",
      "Epoch 526/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4449e-04 - val_loss: 7.3386e-04\n",
      "Epoch 527/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.4556e-04 - val_loss: 7.0749e-04\n",
      "Epoch 528/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4494e-04 - val_loss: 6.9608e-04\n",
      "Epoch 529/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4422e-04 - val_loss: 6.9361e-04\n",
      "Epoch 530/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.4426e-04 - val_loss: 6.9117e-04\n",
      "Epoch 531/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4418e-04 - val_loss: 6.8389e-04\n",
      "Epoch 532/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.4430e-04 - val_loss: 6.9742e-04\n",
      "Epoch 533/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.4533e-04 - val_loss: 6.9410e-04\n",
      "Epoch 534/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.4441e-04 - val_loss: 6.9971e-04\n",
      "Epoch 535/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4449e-04 - val_loss: 6.8383e-04\n",
      "Epoch 536/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4401e-04 - val_loss: 6.9227e-04\n",
      "Epoch 537/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.4483e-04 - val_loss: 6.9431e-04\n",
      "Epoch 538/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4372e-04 - val_loss: 7.1866e-04\n",
      "Epoch 539/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4424e-04 - val_loss: 6.9623e-04\n",
      "Epoch 540/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.4450e-04 - val_loss: 6.9503e-04\n",
      "Epoch 541/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4381e-04 - val_loss: 7.0375e-04\n",
      "Epoch 542/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4458e-04 - val_loss: 6.9289e-04\n",
      "Epoch 543/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4430e-04 - val_loss: 6.8514e-04\n",
      "Epoch 544/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4336e-04 - val_loss: 6.9149e-04\n",
      "Epoch 545/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4356e-04 - val_loss: 6.9498e-04\n",
      "Epoch 546/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.4354e-04 - val_loss: 6.9499e-04\n",
      "Epoch 547/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4399e-04 - val_loss: 6.8219e-04\n",
      "Epoch 548/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4314e-04 - val_loss: 6.9549e-04\n",
      "Epoch 549/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.4397e-04 - val_loss: 6.9313e-04\n",
      "Epoch 550/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4347e-04 - val_loss: 7.1816e-04\n",
      "Epoch 551/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.4390e-04 - val_loss: 7.0021e-04\n",
      "Epoch 552/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4364e-04 - val_loss: 6.9781e-04\n",
      "Epoch 553/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4374e-04 - val_loss: 6.9532e-04\n",
      "Epoch 554/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4320e-04 - val_loss: 6.9558e-04\n",
      "Epoch 555/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4338e-04 - val_loss: 6.9775e-04\n",
      "Epoch 556/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4265e-04 - val_loss: 6.9427e-04\n",
      "Epoch 557/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4323e-04 - val_loss: 6.9248e-04\n",
      "Epoch 558/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4234e-04 - val_loss: 6.9548e-04\n",
      "Epoch 559/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.4270e-04 - val_loss: 6.8979e-04\n",
      "Epoch 560/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4246e-04 - val_loss: 6.9690e-04\n",
      "Epoch 561/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4219e-04 - val_loss: 6.9533e-04\n",
      "Epoch 562/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4180e-04 - val_loss: 6.9564e-04\n",
      "Epoch 563/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4173e-04 - val_loss: 6.9653e-04\n",
      "Epoch 564/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4149e-04 - val_loss: 6.9128e-04\n",
      "Epoch 565/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.4157e-04 - val_loss: 6.9352e-04\n",
      "Epoch 566/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4138e-04 - val_loss: 6.9284e-04\n",
      "Epoch 567/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4146e-04 - val_loss: 6.9177e-04\n",
      "Epoch 568/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.4125e-04 - val_loss: 6.9161e-04\n",
      "Epoch 569/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4105e-04 - val_loss: 6.9154e-04\n",
      "Epoch 570/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.4086e-04 - val_loss: 6.9360e-04\n",
      "Epoch 571/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4064e-04 - val_loss: 6.8997e-04\n",
      "Epoch 572/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4074e-04 - val_loss: 6.8992e-04\n",
      "Epoch 573/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4126e-04 - val_loss: 6.7368e-04\n",
      "Epoch 574/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.4062e-04 - val_loss: 6.8992e-04\n",
      "Epoch 575/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.4019e-04 - val_loss: 6.8850e-04\n",
      "Epoch 576/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4067e-04 - val_loss: 6.8884e-04\n",
      "Epoch 577/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4008e-04 - val_loss: 6.8422e-04\n",
      "Epoch 578/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.4036e-04 - val_loss: 6.7765e-04\n",
      "Epoch 579/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4041e-04 - val_loss: 6.8249e-04\n",
      "Epoch 580/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4031e-04 - val_loss: 6.8373e-04\n",
      "Epoch 581/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.3985e-04 - val_loss: 6.7979e-04\n",
      "Epoch 582/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4035e-04 - val_loss: 6.8409e-04\n",
      "Epoch 583/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3944e-04 - val_loss: 6.7718e-04\n",
      "Epoch 584/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.3933e-04 - val_loss: 6.8355e-04\n",
      "Epoch 585/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3992e-04 - val_loss: 6.8447e-04\n",
      "Epoch 586/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3968e-04 - val_loss: 6.8317e-04\n",
      "Epoch 587/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.3969e-04 - val_loss: 6.7396e-04\n",
      "Epoch 588/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3921e-04 - val_loss: 6.7637e-04\n",
      "Epoch 589/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.3897e-04 - val_loss: 6.8167e-04\n",
      "Epoch 590/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.3886e-04 - val_loss: 6.7407e-04\n",
      "Epoch 591/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3921e-04 - val_loss: 6.7706e-04\n",
      "Epoch 592/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3937e-04 - val_loss: 6.7767e-04\n",
      "Epoch 593/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3955e-04 - val_loss: 6.7992e-04\n",
      "Epoch 594/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.3926e-04 - val_loss: 6.7879e-04\n",
      "Epoch 595/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3917e-04 - val_loss: 6.7929e-04\n",
      "Epoch 596/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.3858e-04 - val_loss: 6.7609e-04\n",
      "Epoch 597/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.3815e-04 - val_loss: 6.7258e-04\n",
      "Epoch 598/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3907e-04 - val_loss: 6.8004e-04\n",
      "Epoch 599/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3862e-04 - val_loss: 6.8100e-04\n",
      "Epoch 600/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3842e-04 - val_loss: 6.8170e-04\n",
      "Epoch 601/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3873e-04 - val_loss: 6.8265e-04\n",
      "Epoch 602/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3838e-04 - val_loss: 6.8024e-04\n",
      "Epoch 603/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3805e-04 - val_loss: 6.7510e-04\n",
      "Epoch 604/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.3866e-04 - val_loss: 6.8119e-04\n",
      "Epoch 605/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3809e-04 - val_loss: 6.7381e-04\n",
      "Epoch 606/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.3802e-04 - val_loss: 6.7014e-04\n",
      "Epoch 607/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3819e-04 - val_loss: 6.6898e-04\n",
      "Epoch 608/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.3807e-04 - val_loss: 6.7026e-04\n",
      "Epoch 609/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3781e-04 - val_loss: 6.6919e-04\n",
      "Epoch 610/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3792e-04 - val_loss: 6.7147e-04\n",
      "Epoch 611/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3772e-04 - val_loss: 6.7157e-04\n",
      "Epoch 612/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.3763e-04 - val_loss: 6.7125e-04\n",
      "Epoch 613/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3745e-04 - val_loss: 6.7700e-04\n",
      "Epoch 614/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3799e-04 - val_loss: 6.8250e-04\n",
      "Epoch 615/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3768e-04 - val_loss: 6.7812e-04\n",
      "Epoch 616/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3701e-04 - val_loss: 6.7978e-04\n",
      "Epoch 617/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3673e-04 - val_loss: 6.7811e-04\n",
      "Epoch 618/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3784e-04 - val_loss: 6.8382e-04\n",
      "Epoch 619/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3693e-04 - val_loss: 6.7641e-04\n",
      "Epoch 620/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3800e-04 - val_loss: 6.8553e-04\n",
      "Epoch 621/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3749e-04 - val_loss: 6.8537e-04\n",
      "Epoch 622/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3662e-04 - val_loss: 6.7705e-04\n",
      "Epoch 623/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3703e-04 - val_loss: 6.8587e-04\n",
      "Epoch 624/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3664e-04 - val_loss: 6.8260e-04\n",
      "Epoch 625/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.3699e-04 - val_loss: 6.8590e-04\n",
      "Epoch 626/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.3632e-04 - val_loss: 6.7723e-04\n",
      "Epoch 627/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.3645e-04 - val_loss: 6.8377e-04\n",
      "Epoch 628/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.3688e-04 - val_loss: 6.8678e-04\n",
      "Epoch 629/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3619e-04 - val_loss: 6.8311e-04\n",
      "Epoch 630/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3655e-04 - val_loss: 6.8681e-04\n",
      "Epoch 631/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3567e-04 - val_loss: 6.8437e-04\n",
      "Epoch 632/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3634e-04 - val_loss: 6.8792e-04\n",
      "Epoch 633/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3595e-04 - val_loss: 6.8475e-04\n",
      "Epoch 634/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3533e-04 - val_loss: 6.8406e-04\n",
      "Epoch 635/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3632e-04 - val_loss: 6.8738e-04\n",
      "Epoch 636/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3571e-04 - val_loss: 6.8484e-04\n",
      "Epoch 637/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3567e-04 - val_loss: 6.8543e-04\n",
      "Epoch 638/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3648e-04 - val_loss: 6.8637e-04\n",
      "Epoch 639/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3558e-04 - val_loss: 6.8368e-04\n",
      "Epoch 640/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3588e-04 - val_loss: 6.8843e-04\n",
      "Epoch 641/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3575e-04 - val_loss: 6.8753e-04\n",
      "Epoch 642/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.3543e-04 - val_loss: 6.8281e-04\n",
      "Epoch 643/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3575e-04 - val_loss: 6.8840e-04\n",
      "Epoch 644/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.3517e-04 - val_loss: 6.8446e-04\n",
      "Epoch 645/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.3548e-04 - val_loss: 6.8594e-04\n",
      "Epoch 646/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.3481e-04 - val_loss: 6.8522e-04\n",
      "Epoch 647/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3553e-04 - val_loss: 6.8715e-04\n",
      "Epoch 648/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3430e-04 - val_loss: 6.8497e-04\n",
      "Epoch 649/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3469e-04 - val_loss: 6.8397e-04\n",
      "Epoch 650/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3536e-04 - val_loss: 6.8635e-04\n",
      "Epoch 651/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3442e-04 - val_loss: 6.8502e-04\n",
      "Epoch 652/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3483e-04 - val_loss: 6.8833e-04\n",
      "Epoch 653/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3411e-04 - val_loss: 6.8575e-04\n",
      "Epoch 654/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3438e-04 - val_loss: 6.8611e-04\n",
      "Epoch 655/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3459e-04 - val_loss: 6.8837e-04\n",
      "Epoch 656/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3430e-04 - val_loss: 6.8581e-04\n",
      "Epoch 657/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3343e-04 - val_loss: 6.8636e-04\n",
      "Epoch 658/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3357e-04 - val_loss: 6.8551e-04\n",
      "Epoch 659/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3418e-04 - val_loss: 6.8787e-04\n",
      "Epoch 660/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3384e-04 - val_loss: 6.8975e-04\n",
      "Epoch 661/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.3409e-04 - val_loss: 6.8941e-04\n",
      "Epoch 662/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3446e-04 - val_loss: 6.9050e-04\n",
      "Epoch 663/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3374e-04 - val_loss: 6.9299e-04\n",
      "Epoch 664/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.3353e-04 - val_loss: 6.9072e-04\n",
      "Epoch 665/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.3303e-04 - val_loss: 6.9015e-04\n",
      "Epoch 666/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.3367e-04 - val_loss: 6.9015e-04\n",
      "Epoch 667/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3381e-04 - val_loss: 6.9158e-04\n",
      "Epoch 668/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3351e-04 - val_loss: 6.8864e-04\n",
      "Epoch 669/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3356e-04 - val_loss: 6.9124e-04\n",
      "Epoch 670/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3318e-04 - val_loss: 6.8917e-04\n",
      "Epoch 671/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3323e-04 - val_loss: 6.8798e-04\n",
      "Epoch 672/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.3301e-04 - val_loss: 6.8709e-04\n",
      "Epoch 673/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3275e-04 - val_loss: 6.8666e-04\n",
      "Epoch 674/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.3294e-04 - val_loss: 6.8666e-04\n",
      "Epoch 675/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3221e-04 - val_loss: 6.8669e-04\n",
      "Epoch 676/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3283e-04 - val_loss: 6.8699e-04\n",
      "Epoch 677/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3274e-04 - val_loss: 6.8664e-04\n",
      "Epoch 678/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3229e-04 - val_loss: 6.8608e-04\n",
      "Epoch 679/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3264e-04 - val_loss: 6.8813e-04\n",
      "Epoch 680/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3245e-04 - val_loss: 6.8529e-04\n",
      "Epoch 681/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3209e-04 - val_loss: 6.8711e-04\n",
      "Epoch 682/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3202e-04 - val_loss: 6.8563e-04\n",
      "Epoch 683/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.3231e-04 - val_loss: 6.8730e-04\n",
      "Epoch 684/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.3169e-04 - val_loss: 6.8512e-04\n",
      "Epoch 685/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3204e-04 - val_loss: 6.8890e-04\n",
      "Epoch 686/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3157e-04 - val_loss: 6.8465e-04\n",
      "Epoch 687/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.3191e-04 - val_loss: 6.8705e-04\n",
      "Epoch 688/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3152e-04 - val_loss: 6.8346e-04\n",
      "Epoch 689/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3176e-04 - val_loss: 6.8474e-04\n",
      "Epoch 690/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.3186e-04 - val_loss: 6.8731e-04\n",
      "Epoch 691/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3156e-04 - val_loss: 6.8292e-04\n",
      "Epoch 692/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3120e-04 - val_loss: 6.8530e-04\n",
      "Epoch 693/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3084e-04 - val_loss: 6.8496e-04\n",
      "Epoch 694/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3153e-04 - val_loss: 6.8656e-04\n",
      "Epoch 695/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3124e-04 - val_loss: 6.8749e-04\n",
      "Epoch 696/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3085e-04 - val_loss: 6.8533e-04\n",
      "Epoch 697/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3135e-04 - val_loss: 6.8257e-04\n",
      "Epoch 698/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3097e-04 - val_loss: 6.7990e-04\n",
      "Epoch 699/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3076e-04 - val_loss: 6.8134e-04\n",
      "Epoch 700/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.3113e-04 - val_loss: 6.8032e-04\n",
      "Epoch 701/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3074e-04 - val_loss: 6.8046e-04\n",
      "Epoch 702/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.3085e-04 - val_loss: 6.8223e-04\n",
      "Epoch 703/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.3076e-04 - val_loss: 6.7946e-04\n",
      "Epoch 704/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3050e-04 - val_loss: 6.8087e-04\n",
      "Epoch 705/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3012e-04 - val_loss: 6.7898e-04\n",
      "Epoch 706/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3043e-04 - val_loss: 6.8053e-04\n",
      "Epoch 707/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3011e-04 - val_loss: 6.7934e-04\n",
      "Epoch 708/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3022e-04 - val_loss: 6.7925e-04\n",
      "Epoch 709/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.3005e-04 - val_loss: 6.7676e-04\n",
      "Epoch 710/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2946e-04 - val_loss: 6.7590e-04\n",
      "Epoch 711/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3071e-04 - val_loss: 6.7729e-04\n",
      "Epoch 712/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.3004e-04 - val_loss: 6.7820e-04\n",
      "Epoch 713/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2926e-04 - val_loss: 6.7761e-04\n",
      "Epoch 714/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2979e-04 - val_loss: 6.7783e-04\n",
      "Epoch 715/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2945e-04 - val_loss: 6.7682e-04\n",
      "Epoch 716/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2947e-04 - val_loss: 6.7944e-04\n",
      "Epoch 717/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2960e-04 - val_loss: 6.8022e-04\n",
      "Epoch 718/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2953e-04 - val_loss: 6.7740e-04\n",
      "Epoch 719/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2927e-04 - val_loss: 6.7713e-04\n",
      "Epoch 720/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.2897e-04 - val_loss: 6.7744e-04\n",
      "Epoch 721/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.2889e-04 - val_loss: 6.7624e-04\n",
      "Epoch 722/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 6.2899e-04 - val_loss: 6.7645e-04\n",
      "Epoch 723/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.2970e-04 - val_loss: 6.8072e-04\n",
      "Epoch 724/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2941e-04 - val_loss: 6.7681e-04\n",
      "Epoch 725/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2918e-04 - val_loss: 6.7705e-04\n",
      "Epoch 726/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2882e-04 - val_loss: 6.7712e-04\n",
      "Epoch 727/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2917e-04 - val_loss: 6.7685e-04\n",
      "Epoch 728/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2841e-04 - val_loss: 6.7541e-04\n",
      "Epoch 729/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2833e-04 - val_loss: 6.7610e-04\n",
      "Epoch 730/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2835e-04 - val_loss: 6.7602e-04\n",
      "Epoch 731/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2844e-04 - val_loss: 6.7582e-04\n",
      "Epoch 732/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2811e-04 - val_loss: 6.7519e-04\n",
      "Epoch 733/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2798e-04 - val_loss: 6.7454e-04\n",
      "Epoch 734/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2842e-04 - val_loss: 6.7468e-04\n",
      "Epoch 735/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.2833e-04 - val_loss: 6.7574e-04\n",
      "Epoch 736/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2862e-04 - val_loss: 6.7447e-04\n",
      "Epoch 737/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2860e-04 - val_loss: 6.7610e-04\n",
      "Epoch 738/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.2795e-04 - val_loss: 6.7407e-04\n",
      "Epoch 739/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2780e-04 - val_loss: 6.7522e-04\n",
      "Epoch 740/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.2735e-04 - val_loss: 6.7477e-04\n",
      "Epoch 741/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2764e-04 - val_loss: 6.7561e-04\n",
      "Epoch 742/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2745e-04 - val_loss: 6.7635e-04\n",
      "Epoch 743/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2727e-04 - val_loss: 6.7374e-04\n",
      "Epoch 744/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2727e-04 - val_loss: 6.7172e-04\n",
      "Epoch 745/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2698e-04 - val_loss: 6.7094e-04\n",
      "Epoch 746/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2686e-04 - val_loss: 6.7131e-04\n",
      "Epoch 747/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2664e-04 - val_loss: 6.7033e-04\n",
      "Epoch 748/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2657e-04 - val_loss: 6.6800e-04\n",
      "Epoch 749/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2687e-04 - val_loss: 6.6867e-04\n",
      "Epoch 750/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2652e-04 - val_loss: 6.6919e-04\n",
      "Epoch 751/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2663e-04 - val_loss: 6.6782e-04\n",
      "Epoch 752/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2637e-04 - val_loss: 6.6801e-04\n",
      "Epoch 753/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2651e-04 - val_loss: 6.6786e-04\n",
      "Epoch 754/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2651e-04 - val_loss: 6.6580e-04\n",
      "Epoch 755/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2590e-04 - val_loss: 6.6566e-04\n",
      "Epoch 756/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2644e-04 - val_loss: 6.6519e-04\n",
      "Epoch 757/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2613e-04 - val_loss: 6.6353e-04\n",
      "Epoch 758/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.2628e-04 - val_loss: 6.6393e-04\n",
      "Epoch 759/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 6.2613e-04 - val_loss: 6.6363e-04\n",
      "Epoch 760/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.2571e-04 - val_loss: 6.6304e-04\n",
      "Epoch 761/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2569e-04 - val_loss: 6.6437e-04\n",
      "Epoch 762/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2548e-04 - val_loss: 6.6272e-04\n",
      "Epoch 763/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.2571e-04 - val_loss: 6.6329e-04\n",
      "Epoch 764/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2550e-04 - val_loss: 6.6120e-04\n",
      "Epoch 765/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2536e-04 - val_loss: 6.6306e-04\n",
      "Epoch 766/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2512e-04 - val_loss: 6.6195e-04\n",
      "Epoch 767/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2498e-04 - val_loss: 6.6160e-04\n",
      "Epoch 768/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2499e-04 - val_loss: 6.6156e-04\n",
      "Epoch 769/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2525e-04 - val_loss: 6.6127e-04\n",
      "Epoch 770/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2503e-04 - val_loss: 6.6069e-04\n",
      "Epoch 771/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2465e-04 - val_loss: 6.6050e-04\n",
      "Epoch 772/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2457e-04 - val_loss: 6.6093e-04\n",
      "Epoch 773/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.2518e-04 - val_loss: 6.5938e-04\n",
      "Epoch 774/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2470e-04 - val_loss: 6.5891e-04\n",
      "Epoch 775/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2462e-04 - val_loss: 6.6109e-04\n",
      "Epoch 776/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.2456e-04 - val_loss: 6.5873e-04\n",
      "Epoch 777/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2452e-04 - val_loss: 6.6004e-04\n",
      "Epoch 778/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.2444e-04 - val_loss: 6.5926e-04\n",
      "Epoch 779/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2451e-04 - val_loss: 6.5851e-04\n",
      "Epoch 780/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.2434e-04 - val_loss: 6.5869e-04\n",
      "Epoch 781/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2424e-04 - val_loss: 6.5870e-04\n",
      "Epoch 782/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.2419e-04 - val_loss: 6.6003e-04\n",
      "Epoch 783/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.2433e-04 - val_loss: 6.5700e-04\n",
      "Epoch 784/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2383e-04 - val_loss: 6.5812e-04\n",
      "Epoch 785/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2405e-04 - val_loss: 6.5868e-04\n",
      "Epoch 786/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2388e-04 - val_loss: 6.5667e-04\n",
      "Epoch 787/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2380e-04 - val_loss: 6.5786e-04\n",
      "Epoch 788/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2373e-04 - val_loss: 6.5656e-04\n",
      "Epoch 789/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2369e-04 - val_loss: 6.5663e-04\n",
      "Epoch 790/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2352e-04 - val_loss: 6.5643e-04\n",
      "Epoch 791/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2368e-04 - val_loss: 6.5696e-04\n",
      "Epoch 792/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.2363e-04 - val_loss: 6.5718e-04\n",
      "Epoch 793/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2341e-04 - val_loss: 6.5605e-04\n",
      "Epoch 794/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2342e-04 - val_loss: 6.5515e-04\n",
      "Epoch 795/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.2368e-04 - val_loss: 6.5422e-04\n",
      "Epoch 796/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2351e-04 - val_loss: 6.5494e-04\n",
      "Epoch 797/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.2304e-04 - val_loss: 6.5584e-04\n",
      "Epoch 798/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2304e-04 - val_loss: 6.5592e-04\n",
      "Epoch 799/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2324e-04 - val_loss: 6.5669e-04\n",
      "Epoch 800/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2289e-04 - val_loss: 6.5510e-04\n",
      "Epoch 801/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2279e-04 - val_loss: 6.5540e-04\n",
      "Epoch 802/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2271e-04 - val_loss: 6.5393e-04\n",
      "Epoch 803/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2272e-04 - val_loss: 6.5496e-04\n",
      "Epoch 804/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2240e-04 - val_loss: 6.5307e-04\n",
      "Epoch 805/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2254e-04 - val_loss: 6.5447e-04\n",
      "Epoch 806/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2229e-04 - val_loss: 6.5301e-04\n",
      "Epoch 807/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2233e-04 - val_loss: 6.5401e-04\n",
      "Epoch 808/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2228e-04 - val_loss: 6.5422e-04\n",
      "Epoch 809/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2249e-04 - val_loss: 6.5212e-04\n",
      "Epoch 810/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2185e-04 - val_loss: 6.5276e-04\n",
      "Epoch 811/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2192e-04 - val_loss: 6.5096e-04\n",
      "Epoch 812/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2214e-04 - val_loss: 6.5174e-04\n",
      "Epoch 813/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2195e-04 - val_loss: 6.5179e-04\n",
      "Epoch 814/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2193e-04 - val_loss: 6.5177e-04\n",
      "Epoch 815/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.2168e-04 - val_loss: 6.5100e-04\n",
      "Epoch 816/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.2172e-04 - val_loss: 6.5072e-04\n",
      "Epoch 817/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2125e-04 - val_loss: 6.4802e-04\n",
      "Epoch 818/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2126e-04 - val_loss: 6.4961e-04\n",
      "Epoch 819/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2090e-04 - val_loss: 6.4826e-04\n",
      "Epoch 820/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2119e-04 - val_loss: 6.4882e-04\n",
      "Epoch 821/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2142e-04 - val_loss: 6.4786e-04\n",
      "Epoch 822/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2092e-04 - val_loss: 6.4634e-04\n",
      "Epoch 823/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2076e-04 - val_loss: 6.4667e-04\n",
      "Epoch 824/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.2081e-04 - val_loss: 6.4851e-04\n",
      "Epoch 825/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2087e-04 - val_loss: 6.4867e-04\n",
      "Epoch 826/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2089e-04 - val_loss: 6.4882e-04\n",
      "Epoch 827/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2050e-04 - val_loss: 6.4702e-04\n",
      "Epoch 828/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2067e-04 - val_loss: 6.4735e-04\n",
      "Epoch 829/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2056e-04 - val_loss: 6.4803e-04\n",
      "Epoch 830/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2047e-04 - val_loss: 6.4806e-04\n",
      "Epoch 831/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2030e-04 - val_loss: 6.4767e-04\n",
      "Epoch 832/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2017e-04 - val_loss: 6.4747e-04\n",
      "Epoch 833/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2023e-04 - val_loss: 6.4688e-04\n",
      "Epoch 834/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.2006e-04 - val_loss: 6.4689e-04\n",
      "Epoch 835/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.2006e-04 - val_loss: 6.4453e-04\n",
      "Epoch 836/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2022e-04 - val_loss: 6.4422e-04\n",
      "Epoch 837/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.1996e-04 - val_loss: 6.4412e-04\n",
      "Epoch 838/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.2023e-04 - val_loss: 6.4714e-04\n",
      "Epoch 839/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1998e-04 - val_loss: 6.4477e-04\n",
      "Epoch 840/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1987e-04 - val_loss: 6.4596e-04\n",
      "Epoch 841/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1984e-04 - val_loss: 6.4556e-04\n",
      "Epoch 842/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1975e-04 - val_loss: 6.4529e-04\n",
      "Epoch 843/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1964e-04 - val_loss: 6.4300e-04\n",
      "Epoch 844/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1955e-04 - val_loss: 6.4488e-04\n",
      "Epoch 845/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1943e-04 - val_loss: 6.4361e-04\n",
      "Epoch 846/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1948e-04 - val_loss: 6.4440e-04\n",
      "Epoch 847/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1938e-04 - val_loss: 6.4421e-04\n",
      "Epoch 848/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1930e-04 - val_loss: 6.4360e-04\n",
      "Epoch 849/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1923e-04 - val_loss: 6.4372e-04\n",
      "Epoch 850/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1916e-04 - val_loss: 6.4372e-04\n",
      "Epoch 851/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.1900e-04 - val_loss: 6.4311e-04\n",
      "Epoch 852/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1889e-04 - val_loss: 6.4319e-04\n",
      "Epoch 853/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.1870e-04 - val_loss: 6.4278e-04\n",
      "Epoch 854/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1865e-04 - val_loss: 6.4271e-04\n",
      "Epoch 855/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1853e-04 - val_loss: 6.4277e-04\n",
      "Epoch 856/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.1857e-04 - val_loss: 6.4259e-04\n",
      "Epoch 857/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1839e-04 - val_loss: 6.4252e-04\n",
      "Epoch 858/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1833e-04 - val_loss: 6.4210e-04\n",
      "Epoch 859/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1878e-04 - val_loss: 6.4192e-04\n",
      "Epoch 860/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1852e-04 - val_loss: 6.4258e-04\n",
      "Epoch 861/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1812e-04 - val_loss: 6.4169e-04\n",
      "Epoch 862/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1833e-04 - val_loss: 6.4092e-04\n",
      "Epoch 863/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1840e-04 - val_loss: 6.4185e-04\n",
      "Epoch 864/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1803e-04 - val_loss: 6.4264e-04\n",
      "Epoch 865/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1770e-04 - val_loss: 6.4101e-04\n",
      "Epoch 866/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1808e-04 - val_loss: 6.4102e-04\n",
      "Epoch 867/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1784e-04 - val_loss: 6.4159e-04\n",
      "Epoch 868/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1789e-04 - val_loss: 6.4104e-04\n",
      "Epoch 869/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1773e-04 - val_loss: 6.4178e-04\n",
      "Epoch 870/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.1780e-04 - val_loss: 6.4074e-04\n",
      "Epoch 871/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1772e-04 - val_loss: 6.4130e-04\n",
      "Epoch 872/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 6.1773e-04 - val_loss: 6.4189e-04\n",
      "Epoch 873/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.1761e-04 - val_loss: 6.4060e-04\n",
      "Epoch 874/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1743e-04 - val_loss: 6.4048e-04\n",
      "Epoch 875/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1733e-04 - val_loss: 6.4160e-04\n",
      "Epoch 876/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.1735e-04 - val_loss: 6.4090e-04\n",
      "Epoch 877/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1716e-04 - val_loss: 6.4108e-04\n",
      "Epoch 878/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1724e-04 - val_loss: 6.3952e-04\n",
      "Epoch 879/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1696e-04 - val_loss: 6.4033e-04\n",
      "Epoch 880/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1676e-04 - val_loss: 6.4033e-04\n",
      "Epoch 881/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1680e-04 - val_loss: 6.3916e-04\n",
      "Epoch 882/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1688e-04 - val_loss: 6.3952e-04\n",
      "Epoch 883/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1683e-04 - val_loss: 6.4000e-04\n",
      "Epoch 884/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1670e-04 - val_loss: 6.3983e-04\n",
      "Epoch 885/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1641e-04 - val_loss: 6.3998e-04\n",
      "Epoch 886/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1675e-04 - val_loss: 6.3895e-04\n",
      "Epoch 887/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1643e-04 - val_loss: 6.3945e-04\n",
      "Epoch 888/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1625e-04 - val_loss: 6.3979e-04\n",
      "Epoch 889/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1647e-04 - val_loss: 6.3864e-04\n",
      "Epoch 890/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.1636e-04 - val_loss: 6.3911e-04\n",
      "Epoch 891/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.1620e-04 - val_loss: 6.3931e-04\n",
      "Epoch 892/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1622e-04 - val_loss: 6.3812e-04\n",
      "Epoch 893/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1621e-04 - val_loss: 6.3725e-04\n",
      "Epoch 894/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1566e-04 - val_loss: 6.3657e-04\n",
      "Epoch 895/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1581e-04 - val_loss: 6.3659e-04\n",
      "Epoch 896/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1586e-04 - val_loss: 6.3807e-04\n",
      "Epoch 897/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1575e-04 - val_loss: 6.3633e-04\n",
      "Epoch 898/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1565e-04 - val_loss: 6.3550e-04\n",
      "Epoch 899/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1562e-04 - val_loss: 6.3747e-04\n",
      "Epoch 900/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1532e-04 - val_loss: 6.3724e-04\n",
      "Epoch 901/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1550e-04 - val_loss: 6.3463e-04\n",
      "Epoch 902/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1552e-04 - val_loss: 6.3582e-04\n",
      "Epoch 903/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1532e-04 - val_loss: 6.3587e-04\n",
      "Epoch 904/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.1516e-04 - val_loss: 6.3384e-04\n",
      "Epoch 905/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1535e-04 - val_loss: 6.3743e-04\n",
      "Epoch 906/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1516e-04 - val_loss: 6.3613e-04\n",
      "Epoch 907/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.1497e-04 - val_loss: 6.3629e-04\n",
      "Epoch 908/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1489e-04 - val_loss: 6.3450e-04\n",
      "Epoch 909/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.1491e-04 - val_loss: 6.3721e-04\n",
      "Epoch 910/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1456e-04 - val_loss: 6.3410e-04\n",
      "Epoch 911/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1456e-04 - val_loss: 6.3622e-04\n",
      "Epoch 912/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1445e-04 - val_loss: 6.3521e-04\n",
      "Epoch 913/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1446e-04 - val_loss: 6.3628e-04\n",
      "Epoch 914/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1441e-04 - val_loss: 6.3825e-04\n",
      "Epoch 915/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1435e-04 - val_loss: 6.3293e-04\n",
      "Epoch 916/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1426e-04 - val_loss: 6.3497e-04\n",
      "Epoch 917/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1411e-04 - val_loss: 6.3536e-04\n",
      "Epoch 918/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1411e-04 - val_loss: 6.3833e-04\n",
      "Epoch 919/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1392e-04 - val_loss: 6.3534e-04\n",
      "Epoch 920/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1390e-04 - val_loss: 6.3479e-04\n",
      "Epoch 921/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1384e-04 - val_loss: 6.3360e-04\n",
      "Epoch 922/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1396e-04 - val_loss: 6.3392e-04\n",
      "Epoch 923/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1376e-04 - val_loss: 6.3347e-04\n",
      "Epoch 924/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1368e-04 - val_loss: 6.3460e-04\n",
      "Epoch 925/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1370e-04 - val_loss: 6.3214e-04\n",
      "Epoch 926/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.1386e-04 - val_loss: 6.3425e-04\n",
      "Epoch 927/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.1338e-04 - val_loss: 6.3364e-04\n",
      "Epoch 928/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 6.1338e-04 - val_loss: 6.3302e-04\n",
      "Epoch 929/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.1358e-04 - val_loss: 6.3480e-04\n",
      "Epoch 930/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1333e-04 - val_loss: 6.3438e-04\n",
      "Epoch 931/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1366e-04 - val_loss: 6.3400e-04\n",
      "Epoch 932/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1314e-04 - val_loss: 6.3394e-04\n",
      "Epoch 933/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1294e-04 - val_loss: 6.3256e-04\n",
      "Epoch 934/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1321e-04 - val_loss: 6.3309e-04\n",
      "Epoch 935/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1295e-04 - val_loss: 6.3312e-04\n",
      "Epoch 936/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1303e-04 - val_loss: 6.3228e-04\n",
      "Epoch 937/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1291e-04 - val_loss: 6.3338e-04\n",
      "Epoch 938/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1286e-04 - val_loss: 6.3261e-04\n",
      "Epoch 939/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1282e-04 - val_loss: 6.2971e-04\n",
      "Epoch 940/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1270e-04 - val_loss: 6.3188e-04\n",
      "Epoch 941/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1260e-04 - val_loss: 6.3171e-04\n",
      "Epoch 942/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1284e-04 - val_loss: 6.3165e-04\n",
      "Epoch 943/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1262e-04 - val_loss: 6.3118e-04\n",
      "Epoch 944/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1223e-04 - val_loss: 6.3055e-04\n",
      "Epoch 945/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1231e-04 - val_loss: 6.3134e-04\n",
      "Epoch 946/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.1227e-04 - val_loss: 6.3057e-04\n",
      "Epoch 947/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.1213e-04 - val_loss: 6.3032e-04\n",
      "Epoch 948/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.1216e-04 - val_loss: 6.3119e-04\n",
      "Epoch 949/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1194e-04 - val_loss: 6.3009e-04\n",
      "Epoch 950/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1178e-04 - val_loss: 6.2943e-04\n",
      "Epoch 951/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1224e-04 - val_loss: 6.3147e-04\n",
      "Epoch 952/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1190e-04 - val_loss: 6.2960e-04\n",
      "Epoch 953/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1155e-04 - val_loss: 6.3088e-04\n",
      "Epoch 954/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1156e-04 - val_loss: 6.2991e-04\n",
      "Epoch 955/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1149e-04 - val_loss: 6.2935e-04\n",
      "Epoch 956/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1156e-04 - val_loss: 6.2990e-04\n",
      "Epoch 957/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1131e-04 - val_loss: 6.2952e-04\n",
      "Epoch 958/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1141e-04 - val_loss: 6.3030e-04\n",
      "Epoch 959/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.1144e-04 - val_loss: 6.3015e-04\n",
      "Epoch 960/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1119e-04 - val_loss: 6.2900e-04\n",
      "Epoch 961/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1115e-04 - val_loss: 6.2911e-04\n",
      "Epoch 962/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1093e-04 - val_loss: 6.2786e-04\n",
      "Epoch 963/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1140e-04 - val_loss: 6.2977e-04\n",
      "Epoch 964/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1095e-04 - val_loss: 6.2806e-04\n",
      "Epoch 965/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.1074e-04 - val_loss: 6.2909e-04\n",
      "Epoch 966/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.1082e-04 - val_loss: 6.2934e-04\n",
      "Epoch 967/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1069e-04 - val_loss: 6.2669e-04\n",
      "Epoch 968/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1122e-04 - val_loss: 6.2776e-04\n",
      "Epoch 969/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1085e-04 - val_loss: 6.2995e-04\n",
      "Epoch 970/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1055e-04 - val_loss: 6.2786e-04\n",
      "Epoch 971/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1035e-04 - val_loss: 6.2734e-04\n",
      "Epoch 972/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1068e-04 - val_loss: 6.2604e-04\n",
      "Epoch 973/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1065e-04 - val_loss: 6.2912e-04\n",
      "Epoch 974/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.1032e-04 - val_loss: 6.2780e-04\n",
      "Epoch 975/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1025e-04 - val_loss: 6.2611e-04\n",
      "Epoch 976/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1012e-04 - val_loss: 6.2518e-04\n",
      "Epoch 977/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0996e-04 - val_loss: 6.2408e-04\n",
      "Epoch 978/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0989e-04 - val_loss: 6.2747e-04\n",
      "Epoch 979/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1034e-04 - val_loss: 6.2653e-04\n",
      "Epoch 980/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1016e-04 - val_loss: 6.2452e-04\n",
      "Epoch 981/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1024e-04 - val_loss: 6.3192e-04\n",
      "Epoch 982/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1002e-04 - val_loss: 6.2506e-04\n",
      "Epoch 983/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0992e-04 - val_loss: 6.2410e-04\n",
      "Epoch 984/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.0964e-04 - val_loss: 6.2779e-04\n",
      "Epoch 985/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.0963e-04 - val_loss: 6.2458e-04\n",
      "Epoch 986/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0949e-04 - val_loss: 6.2720e-04\n",
      "Epoch 987/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0958e-04 - val_loss: 6.2469e-04\n",
      "Epoch 988/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0974e-04 - val_loss: 6.2300e-04\n",
      "Epoch 989/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0947e-04 - val_loss: 6.2348e-04\n",
      "Epoch 990/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0935e-04 - val_loss: 6.2380e-04\n",
      "Epoch 991/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0924e-04 - val_loss: 6.2537e-04\n",
      "Epoch 992/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0931e-04 - val_loss: 6.2431e-04\n",
      "Epoch 993/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0908e-04 - val_loss: 6.2499e-04\n",
      "Epoch 994/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0937e-04 - val_loss: 6.2236e-04\n",
      "Epoch 995/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0913e-04 - val_loss: 6.2246e-04\n",
      "Epoch 996/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0945e-04 - val_loss: 6.2852e-04\n",
      "Epoch 997/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0895e-04 - val_loss: 6.2559e-04\n",
      "Epoch 998/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0890e-04 - val_loss: 6.2480e-04\n",
      "Epoch 999/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0880e-04 - val_loss: 6.2693e-04\n",
      "Epoch 1000/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0841e-04 - val_loss: 6.2363e-04\n",
      "Epoch 1001/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0893e-04 - val_loss: 6.2323e-04\n",
      "Epoch 1002/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0860e-04 - val_loss: 6.2393e-04\n",
      "Epoch 1003/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.0838e-04 - val_loss: 6.2094e-04\n",
      "Epoch 1004/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.0836e-04 - val_loss: 6.2527e-04\n",
      "Epoch 1005/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0862e-04 - val_loss: 6.1956e-04\n",
      "Epoch 1006/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0849e-04 - val_loss: 6.2510e-04\n",
      "Epoch 1007/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0865e-04 - val_loss: 6.2073e-04\n",
      "Epoch 1008/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0816e-04 - val_loss: 6.2139e-04\n",
      "Epoch 1009/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.0807e-04 - val_loss: 6.2062e-04\n",
      "Epoch 1010/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0801e-04 - val_loss: 6.2657e-04\n",
      "Epoch 1011/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0787e-04 - val_loss: 6.2428e-04\n",
      "Epoch 1012/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0785e-04 - val_loss: 6.2272e-04\n",
      "Epoch 1013/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0800e-04 - val_loss: 6.2755e-04\n",
      "Epoch 1014/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0827e-04 - val_loss: 6.2163e-04\n",
      "Epoch 1015/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0775e-04 - val_loss: 6.2111e-04\n",
      "Epoch 1016/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0764e-04 - val_loss: 6.2027e-04\n",
      "Epoch 1017/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0763e-04 - val_loss: 6.2766e-04\n",
      "Epoch 1018/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0785e-04 - val_loss: 6.2034e-04\n",
      "Epoch 1019/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0752e-04 - val_loss: 6.2122e-04\n",
      "Epoch 1020/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.0735e-04 - val_loss: 6.1961e-04\n",
      "Epoch 1021/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0726e-04 - val_loss: 6.2263e-04\n",
      "Epoch 1022/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.0726e-04 - val_loss: 6.2309e-04\n",
      "Epoch 1023/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0725e-04 - val_loss: 6.2078e-04\n",
      "Epoch 1024/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0715e-04 - val_loss: 6.2543e-04\n",
      "Epoch 1025/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0741e-04 - val_loss: 6.2320e-04\n",
      "Epoch 1026/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.0736e-04 - val_loss: 6.2876e-04\n",
      "Epoch 1027/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0707e-04 - val_loss: 6.1990e-04\n",
      "Epoch 1028/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.0693e-04 - val_loss: 6.2661e-04\n",
      "Epoch 1029/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0699e-04 - val_loss: 6.1865e-04\n",
      "Epoch 1030/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0715e-04 - val_loss: 6.2731e-04\n",
      "Epoch 1031/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0671e-04 - val_loss: 6.2537e-04\n",
      "Epoch 1032/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0718e-04 - val_loss: 6.2456e-04\n",
      "Epoch 1033/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0695e-04 - val_loss: 6.2281e-04\n",
      "Epoch 1034/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0686e-04 - val_loss: 6.2241e-04\n",
      "Epoch 1035/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0661e-04 - val_loss: 6.1985e-04\n",
      "Epoch 1036/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0650e-04 - val_loss: 6.2137e-04\n",
      "Epoch 1037/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0661e-04 - val_loss: 6.2138e-04\n",
      "Epoch 1038/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0625e-04 - val_loss: 6.1808e-04\n",
      "Epoch 1039/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.0642e-04 - val_loss: 6.1926e-04\n",
      "Epoch 1040/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0638e-04 - val_loss: 6.1927e-04\n",
      "Epoch 1041/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 6.0618e-04 - val_loss: 6.1844e-04\n",
      "Epoch 1042/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.0594e-04 - val_loss: 6.1476e-04\n",
      "Epoch 1043/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0589e-04 - val_loss: 6.1451e-04\n",
      "Epoch 1044/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0578e-04 - val_loss: 6.1714e-04\n",
      "Epoch 1045/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0604e-04 - val_loss: 6.1811e-04\n",
      "Epoch 1046/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0593e-04 - val_loss: 6.1690e-04\n",
      "Epoch 1047/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0617e-04 - val_loss: 6.1733e-04\n",
      "Epoch 1048/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0602e-04 - val_loss: 6.1675e-04\n",
      "Epoch 1049/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0550e-04 - val_loss: 6.1708e-04\n",
      "Epoch 1050/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.0544e-04 - val_loss: 6.1476e-04\n",
      "Epoch 1051/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.0578e-04 - val_loss: 6.1679e-04\n",
      "Epoch 1052/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0535e-04 - val_loss: 6.1640e-04\n",
      "Epoch 1053/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0551e-04 - val_loss: 6.1529e-04\n",
      "Epoch 1054/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0553e-04 - val_loss: 6.1552e-04\n",
      "Epoch 1055/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0537e-04 - val_loss: 6.1567e-04\n",
      "Epoch 1056/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0525e-04 - val_loss: 6.1489e-04\n",
      "Epoch 1057/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0563e-04 - val_loss: 6.1351e-04\n",
      "Epoch 1058/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0505e-04 - val_loss: 6.1525e-04\n",
      "Epoch 1059/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0511e-04 - val_loss: 6.1386e-04\n",
      "Epoch 1060/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.0487e-04 - val_loss: 6.1402e-04\n",
      "Epoch 1061/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.0508e-04 - val_loss: 6.1272e-04\n",
      "Epoch 1062/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0527e-04 - val_loss: 6.1441e-04\n",
      "Epoch 1063/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0507e-04 - val_loss: 6.1481e-04\n",
      "Epoch 1064/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.0502e-04 - val_loss: 6.1457e-04\n",
      "Epoch 1065/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0497e-04 - val_loss: 6.1427e-04\n",
      "Epoch 1066/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0480e-04 - val_loss: 6.1379e-04\n",
      "Epoch 1067/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.0461e-04 - val_loss: 6.1315e-04\n",
      "Epoch 1068/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0464e-04 - val_loss: 6.1366e-04\n",
      "Epoch 1069/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0430e-04 - val_loss: 6.1277e-04\n",
      "Epoch 1070/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0466e-04 - val_loss: 6.1152e-04\n",
      "Epoch 1071/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0446e-04 - val_loss: 6.1259e-04\n",
      "Epoch 1072/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0442e-04 - val_loss: 6.1331e-04\n",
      "Epoch 1073/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.0438e-04 - val_loss: 6.1021e-04\n",
      "Epoch 1074/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0428e-04 - val_loss: 6.1150e-04\n",
      "Epoch 1075/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0429e-04 - val_loss: 6.1175e-04\n",
      "Epoch 1076/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0435e-04 - val_loss: 6.1218e-04\n",
      "Epoch 1077/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0424e-04 - val_loss: 6.1124e-04\n",
      "Epoch 1078/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0385e-04 - val_loss: 6.1134e-04\n",
      "Epoch 1079/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.0408e-04 - val_loss: 6.1038e-04\n",
      "Epoch 1080/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.0388e-04 - val_loss: 6.1028e-04\n",
      "Epoch 1081/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0381e-04 - val_loss: 6.1262e-04\n",
      "Epoch 1082/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0393e-04 - val_loss: 6.1033e-04\n",
      "Epoch 1083/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0365e-04 - val_loss: 6.0939e-04\n",
      "Epoch 1084/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0366e-04 - val_loss: 6.0954e-04\n",
      "Epoch 1085/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0360e-04 - val_loss: 6.0979e-04\n",
      "Epoch 1086/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0341e-04 - val_loss: 6.1188e-04\n",
      "Epoch 1087/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0361e-04 - val_loss: 6.0958e-04\n",
      "Epoch 1088/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0332e-04 - val_loss: 6.1140e-04\n",
      "Epoch 1089/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0323e-04 - val_loss: 6.0925e-04\n",
      "Epoch 1090/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0344e-04 - val_loss: 6.0901e-04\n",
      "Epoch 1091/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0313e-04 - val_loss: 6.1072e-04\n",
      "Epoch 1092/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0331e-04 - val_loss: 6.0864e-04\n",
      "Epoch 1093/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0316e-04 - val_loss: 6.0804e-04\n",
      "Epoch 1094/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0309e-04 - val_loss: 6.0773e-04\n",
      "Epoch 1095/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0306e-04 - val_loss: 6.0934e-04\n",
      "Epoch 1096/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0282e-04 - val_loss: 6.1143e-04\n",
      "Epoch 1097/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.0290e-04 - val_loss: 6.0774e-04\n",
      "Epoch 1098/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 6.0285e-04 - val_loss: 6.1038e-04\n",
      "Epoch 1099/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.0277e-04 - val_loss: 6.0968e-04\n",
      "Epoch 1100/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0269e-04 - val_loss: 6.0705e-04\n",
      "Epoch 1101/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0263e-04 - val_loss: 6.0621e-04\n",
      "Epoch 1102/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.0255e-04 - val_loss: 6.0931e-04\n",
      "Epoch 1103/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0244e-04 - val_loss: 6.0593e-04\n",
      "Epoch 1104/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0226e-04 - val_loss: 6.0582e-04\n",
      "Epoch 1105/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0230e-04 - val_loss: 6.0786e-04\n",
      "Epoch 1106/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0225e-04 - val_loss: 6.0443e-04\n",
      "Epoch 1107/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0217e-04 - val_loss: 6.0436e-04\n",
      "Epoch 1108/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0213e-04 - val_loss: 6.0397e-04\n",
      "Epoch 1109/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0205e-04 - val_loss: 6.0596e-04\n",
      "Epoch 1110/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0202e-04 - val_loss: 6.0299e-04\n",
      "Epoch 1111/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0196e-04 - val_loss: 6.0254e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1112/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0171e-04 - val_loss: 6.0339e-04\n",
      "Epoch 1113/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0183e-04 - val_loss: 6.0181e-04\n",
      "Epoch 1114/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0169e-04 - val_loss: 6.0170e-04\n",
      "Epoch 1115/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0167e-04 - val_loss: 6.0197e-04\n",
      "Epoch 1116/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.0181e-04 - val_loss: 6.0508e-04\n",
      "Epoch 1117/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0161e-04 - val_loss: 6.0246e-04\n",
      "Epoch 1118/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0139e-04 - val_loss: 6.0011e-04\n",
      "Epoch 1119/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0128e-04 - val_loss: 6.0021e-04\n",
      "Epoch 1120/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0162e-04 - val_loss: 5.9988e-04\n",
      "Epoch 1121/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0126e-04 - val_loss: 6.0189e-04\n",
      "Epoch 1122/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0121e-04 - val_loss: 6.0184e-04\n",
      "Epoch 1123/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0109e-04 - val_loss: 5.9956e-04\n",
      "Epoch 1124/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0103e-04 - val_loss: 5.9878e-04\n",
      "Epoch 1125/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0101e-04 - val_loss: 5.9871e-04\n",
      "Epoch 1126/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.0086e-04 - val_loss: 5.9919e-04\n",
      "Epoch 1127/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0121e-04 - val_loss: 5.9905e-04\n",
      "Epoch 1128/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0125e-04 - val_loss: 5.9983e-04\n",
      "Epoch 1129/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0094e-04 - val_loss: 5.9980e-04\n",
      "Epoch 1130/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0110e-04 - val_loss: 5.9878e-04\n",
      "Epoch 1131/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0078e-04 - val_loss: 5.9878e-04\n",
      "Epoch 1132/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0066e-04 - val_loss: 5.9777e-04\n",
      "Epoch 1133/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.0069e-04 - val_loss: 5.9812e-04\n",
      "Epoch 1134/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0099e-04 - val_loss: 5.9872e-04\n",
      "Epoch 1135/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.0076e-04 - val_loss: 5.9885e-04\n",
      "Epoch 1136/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.0078e-04 - val_loss: 5.9778e-04\n",
      "Epoch 1137/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0038e-04 - val_loss: 5.9703e-04\n",
      "Epoch 1138/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0069e-04 - val_loss: 5.9753e-04\n",
      "Epoch 1139/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0051e-04 - val_loss: 5.9805e-04\n",
      "Epoch 1140/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0046e-04 - val_loss: 5.9784e-04\n",
      "Epoch 1141/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0036e-04 - val_loss: 5.9781e-04\n",
      "Epoch 1142/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0025e-04 - val_loss: 5.9777e-04\n",
      "Epoch 1143/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0022e-04 - val_loss: 5.9748e-04\n",
      "Epoch 1144/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0001e-04 - val_loss: 6.0497e-04\n",
      "Epoch 1145/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0046e-04 - val_loss: 5.9683e-04\n",
      "Epoch 1146/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0002e-04 - val_loss: 5.9607e-04\n",
      "Epoch 1147/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9992e-04 - val_loss: 5.9614e-04\n",
      "Epoch 1148/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9976e-04 - val_loss: 5.9643e-04\n",
      "Epoch 1149/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0021e-04 - val_loss: 5.9700e-04\n",
      "Epoch 1150/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.9970e-04 - val_loss: 5.9661e-04\n",
      "Epoch 1151/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9975e-04 - val_loss: 5.9656e-04\n",
      "Epoch 1152/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.0012e-04 - val_loss: 5.9649e-04\n",
      "Epoch 1153/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.9950e-04 - val_loss: 5.9652e-04\n",
      "Epoch 1154/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.9988e-04 - val_loss: 5.9491e-04\n",
      "Epoch 1155/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9932e-04 - val_loss: 5.9520e-04\n",
      "Epoch 1156/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9965e-04 - val_loss: 5.9501e-04\n",
      "Epoch 1157/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9941e-04 - val_loss: 5.9800e-04\n",
      "Epoch 1158/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9972e-04 - val_loss: 5.9460e-04\n",
      "Epoch 1159/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9958e-04 - val_loss: 5.9445e-04\n",
      "Epoch 1160/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9932e-04 - val_loss: 5.9875e-04\n",
      "Epoch 1161/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9926e-04 - val_loss: 5.9500e-04\n",
      "Epoch 1162/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9920e-04 - val_loss: 5.9469e-04\n",
      "Epoch 1163/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9911e-04 - val_loss: 5.9479e-04\n",
      "Epoch 1164/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9906e-04 - val_loss: 5.9460e-04\n",
      "Epoch 1165/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9897e-04 - val_loss: 5.9483e-04\n",
      "Epoch 1166/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9890e-04 - val_loss: 5.9475e-04\n",
      "Epoch 1167/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9882e-04 - val_loss: 5.9477e-04\n",
      "Epoch 1168/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9875e-04 - val_loss: 5.9471e-04\n",
      "Epoch 1169/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9866e-04 - val_loss: 5.9478e-04\n",
      "Epoch 1170/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9851e-04 - val_loss: 5.9393e-04\n",
      "Epoch 1171/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9851e-04 - val_loss: 5.9386e-04\n",
      "Epoch 1172/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.9859e-04 - val_loss: 5.9488e-04\n",
      "Epoch 1173/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.9864e-04 - val_loss: 5.9556e-04\n",
      "Epoch 1174/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9835e-04 - val_loss: 5.9485e-04\n",
      "Epoch 1175/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9870e-04 - val_loss: 5.9521e-04\n",
      "Epoch 1176/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9815e-04 - val_loss: 5.9482e-04\n",
      "Epoch 1177/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9850e-04 - val_loss: 5.9325e-04\n",
      "Epoch 1178/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9835e-04 - val_loss: 5.9488e-04\n",
      "Epoch 1179/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9843e-04 - val_loss: 5.9523e-04\n",
      "Epoch 1180/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9830e-04 - val_loss: 5.9308e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1181/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9823e-04 - val_loss: 5.9530e-04\n",
      "Epoch 1182/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9812e-04 - val_loss: 5.9298e-04\n",
      "Epoch 1183/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9807e-04 - val_loss: 5.9529e-04\n",
      "Epoch 1184/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9806e-04 - val_loss: 5.9276e-04\n",
      "Epoch 1185/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9792e-04 - val_loss: 5.9523e-04\n",
      "Epoch 1186/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9796e-04 - val_loss: 5.9262e-04\n",
      "Epoch 1187/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9792e-04 - val_loss: 5.9391e-04\n",
      "Epoch 1188/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.9784e-04 - val_loss: 5.9248e-04\n",
      "Epoch 1189/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9777e-04 - val_loss: 5.9496e-04\n",
      "Epoch 1190/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9777e-04 - val_loss: 5.9235e-04\n",
      "Epoch 1191/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.9770e-04 - val_loss: 5.9606e-04\n",
      "Epoch 1192/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.9769e-04 - val_loss: 5.9255e-04\n",
      "Epoch 1193/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9746e-04 - val_loss: 5.9344e-04\n",
      "Epoch 1194/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9740e-04 - val_loss: 5.9161e-04\n",
      "Epoch 1195/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9723e-04 - val_loss: 5.9229e-04\n",
      "Epoch 1196/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9711e-04 - val_loss: 5.9246e-04\n",
      "Epoch 1197/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9738e-04 - val_loss: 5.9465e-04\n",
      "Epoch 1198/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9724e-04 - val_loss: 5.9352e-04\n",
      "Epoch 1199/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9731e-04 - val_loss: 5.9137e-04\n",
      "Epoch 1200/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9709e-04 - val_loss: 5.9089e-04\n",
      "Epoch 1201/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9696e-04 - val_loss: 5.9166e-04\n",
      "Epoch 1202/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9685e-04 - val_loss: 5.9200e-04\n",
      "Epoch 1203/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9682e-04 - val_loss: 5.9067e-04\n",
      "Epoch 1204/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9665e-04 - val_loss: 5.9249e-04\n",
      "Epoch 1205/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9683e-04 - val_loss: 5.9016e-04\n",
      "Epoch 1206/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9682e-04 - val_loss: 5.9307e-04\n",
      "Epoch 1207/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9692e-04 - val_loss: 5.9009e-04\n",
      "Epoch 1208/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9671e-04 - val_loss: 5.9156e-04\n",
      "Epoch 1209/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9669e-04 - val_loss: 5.8966e-04\n",
      "Epoch 1210/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.9655e-04 - val_loss: 5.9216e-04\n",
      "Epoch 1211/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.9654e-04 - val_loss: 5.8935e-04\n",
      "Epoch 1212/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9638e-04 - val_loss: 5.9035e-04\n",
      "Epoch 1213/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9642e-04 - val_loss: 5.8909e-04\n",
      "Epoch 1214/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9631e-04 - val_loss: 5.8933e-04\n",
      "Epoch 1215/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9618e-04 - val_loss: 5.9414e-04\n",
      "Epoch 1216/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9636e-04 - val_loss: 5.8882e-04\n",
      "Epoch 1217/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.9623e-04 - val_loss: 5.9066e-04\n",
      "Epoch 1218/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9611e-04 - val_loss: 5.9340e-04\n",
      "Epoch 1219/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9627e-04 - val_loss: 5.8843e-04\n",
      "Epoch 1220/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9606e-04 - val_loss: 5.9031e-04\n",
      "Epoch 1221/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9590e-04 - val_loss: 5.8987e-04\n",
      "Epoch 1222/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9607e-04 - val_loss: 5.8750e-04\n",
      "Epoch 1223/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9588e-04 - val_loss: 5.8865e-04\n",
      "Epoch 1224/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9606e-04 - val_loss: 5.8738e-04\n",
      "Epoch 1225/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9575e-04 - val_loss: 5.8939e-04\n",
      "Epoch 1226/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9572e-04 - val_loss: 5.8793e-04\n",
      "Epoch 1227/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9583e-04 - val_loss: 5.8838e-04\n",
      "Epoch 1228/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9582e-04 - val_loss: 5.8674e-04\n",
      "Epoch 1229/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.9590e-04 - val_loss: 5.9029e-04\n",
      "Epoch 1230/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.9561e-04 - val_loss: 5.8836e-04\n",
      "Epoch 1231/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9540e-04 - val_loss: 5.8976e-04\n",
      "Epoch 1232/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9568e-04 - val_loss: 5.8611e-04\n",
      "Epoch 1233/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9542e-04 - val_loss: 5.8736e-04\n",
      "Epoch 1234/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9542e-04 - val_loss: 5.8848e-04\n",
      "Epoch 1235/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9543e-04 - val_loss: 5.8621e-04\n",
      "Epoch 1236/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9550e-04 - val_loss: 5.8599e-04\n",
      "Epoch 1237/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9517e-04 - val_loss: 5.8703e-04\n",
      "Epoch 1238/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9517e-04 - val_loss: 5.8691e-04\n",
      "Epoch 1239/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9523e-04 - val_loss: 5.8760e-04\n",
      "Epoch 1240/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9509e-04 - val_loss: 5.8704e-04\n",
      "Epoch 1241/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9504e-04 - val_loss: 5.8791e-04\n",
      "Epoch 1242/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9515e-04 - val_loss: 5.8692e-04\n",
      "Epoch 1243/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9488e-04 - val_loss: 5.8699e-04\n",
      "Epoch 1244/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9504e-04 - val_loss: 5.8777e-04\n",
      "Epoch 1245/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9520e-04 - val_loss: 5.8681e-04\n",
      "Epoch 1246/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9488e-04 - val_loss: 5.8751e-04\n",
      "Epoch 1247/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9488e-04 - val_loss: 5.8535e-04\n",
      "Epoch 1248/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.9465e-04 - val_loss: 5.8709e-04\n",
      "Epoch 1249/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9464e-04 - val_loss: 5.8645e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1250/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9472e-04 - val_loss: 5.8627e-04\n",
      "Epoch 1251/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9453e-04 - val_loss: 5.8621e-04\n",
      "Epoch 1252/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9445e-04 - val_loss: 5.8570e-04\n",
      "Epoch 1253/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9455e-04 - val_loss: 5.8562e-04\n",
      "Epoch 1254/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9444e-04 - val_loss: 5.8630e-04\n",
      "Epoch 1255/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9455e-04 - val_loss: 5.8420e-04\n",
      "Epoch 1256/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9459e-04 - val_loss: 5.8404e-04\n",
      "Epoch 1257/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9431e-04 - val_loss: 5.8584e-04\n",
      "Epoch 1258/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.9441e-04 - val_loss: 5.8395e-04\n",
      "Epoch 1259/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9434e-04 - val_loss: 5.8373e-04\n",
      "Epoch 1260/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9429e-04 - val_loss: 5.8378e-04\n",
      "Epoch 1261/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9420e-04 - val_loss: 5.8383e-04\n",
      "Epoch 1262/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9397e-04 - val_loss: 5.8590e-04\n",
      "Epoch 1263/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9440e-04 - val_loss: 5.8430e-04\n",
      "Epoch 1264/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9408e-04 - val_loss: 5.8508e-04\n",
      "Epoch 1265/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.9401e-04 - val_loss: 5.8550e-04\n",
      "Epoch 1266/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9380e-04 - val_loss: 5.8653e-04\n",
      "Epoch 1267/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.9421e-04 - val_loss: 5.8358e-04\n",
      "Epoch 1268/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9396e-04 - val_loss: 5.8286e-04\n",
      "Epoch 1269/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9388e-04 - val_loss: 5.8275e-04\n",
      "Epoch 1270/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9394e-04 - val_loss: 5.8333e-04\n",
      "Epoch 1271/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9380e-04 - val_loss: 5.8276e-04\n",
      "Epoch 1272/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9373e-04 - val_loss: 5.8252e-04\n",
      "Epoch 1273/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9361e-04 - val_loss: 5.8311e-04\n",
      "Epoch 1274/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9375e-04 - val_loss: 5.8227e-04\n",
      "Epoch 1275/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9350e-04 - val_loss: 5.8284e-04\n",
      "Epoch 1276/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9348e-04 - val_loss: 5.8239e-04\n",
      "Epoch 1277/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9363e-04 - val_loss: 5.8174e-04\n",
      "Epoch 1278/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9344e-04 - val_loss: 5.8518e-04\n",
      "Epoch 1279/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9342e-04 - val_loss: 5.8152e-04\n",
      "Epoch 1280/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9346e-04 - val_loss: 5.8195e-04\n",
      "Epoch 1281/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9319e-04 - val_loss: 5.8395e-04\n",
      "Epoch 1282/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9337e-04 - val_loss: 5.8119e-04\n",
      "Epoch 1283/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9324e-04 - val_loss: 5.8114e-04\n",
      "Epoch 1284/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9336e-04 - val_loss: 5.8240e-04\n",
      "Epoch 1285/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.9322e-04 - val_loss: 5.8095e-04\n",
      "Epoch 1286/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9319e-04 - val_loss: 5.8348e-04\n",
      "Epoch 1287/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9312e-04 - val_loss: 5.8085e-04\n",
      "Epoch 1288/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9318e-04 - val_loss: 5.8211e-04\n",
      "Epoch 1289/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.9312e-04 - val_loss: 5.8060e-04\n",
      "Epoch 1290/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9296e-04 - val_loss: 5.8080e-04\n",
      "Epoch 1291/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9278e-04 - val_loss: 5.8250e-04\n",
      "Epoch 1292/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9293e-04 - val_loss: 5.8027e-04\n",
      "Epoch 1293/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9283e-04 - val_loss: 5.8029e-04\n",
      "Epoch 1294/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.9284e-04 - val_loss: 5.8076e-04\n",
      "Epoch 1295/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9278e-04 - val_loss: 5.8005e-04\n",
      "Epoch 1296/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9305e-04 - val_loss: 5.7979e-04\n",
      "Epoch 1297/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9269e-04 - val_loss: 5.8031e-04\n",
      "Epoch 1298/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9261e-04 - val_loss: 5.8013e-04\n",
      "Epoch 1299/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9264e-04 - val_loss: 5.8004e-04\n",
      "Epoch 1300/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9267e-04 - val_loss: 5.7995e-04\n",
      "Epoch 1301/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9275e-04 - val_loss: 5.7944e-04\n",
      "Epoch 1302/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.9257e-04 - val_loss: 5.7964e-04\n",
      "Epoch 1303/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9247e-04 - val_loss: 5.7982e-04\n",
      "Epoch 1304/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.9257e-04 - val_loss: 5.8060e-04\n",
      "Epoch 1305/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9247e-04 - val_loss: 5.8045e-04\n",
      "Epoch 1306/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9233e-04 - val_loss: 5.8025e-04\n",
      "Epoch 1307/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9229e-04 - val_loss: 5.7918e-04\n",
      "Epoch 1308/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9215e-04 - val_loss: 5.7910e-04\n",
      "Epoch 1309/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9214e-04 - val_loss: 5.7929e-04\n",
      "Epoch 1310/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9207e-04 - val_loss: 5.7962e-04\n",
      "Epoch 1311/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9205e-04 - val_loss: 5.8038e-04\n",
      "Epoch 1312/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.9220e-04 - val_loss: 5.7838e-04\n",
      "Epoch 1313/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.9224e-04 - val_loss: 5.7883e-04\n",
      "Epoch 1314/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.9202e-04 - val_loss: 5.7821e-04\n",
      "Epoch 1315/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9197e-04 - val_loss: 5.7891e-04\n",
      "Epoch 1316/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9198e-04 - val_loss: 5.7800e-04\n",
      "Epoch 1317/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9187e-04 - val_loss: 5.7850e-04\n",
      "Epoch 1318/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9189e-04 - val_loss: 5.7811e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1319/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9175e-04 - val_loss: 5.7789e-04\n",
      "Epoch 1320/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9180e-04 - val_loss: 5.7810e-04\n",
      "Epoch 1321/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9170e-04 - val_loss: 5.7831e-04\n",
      "Epoch 1322/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9177e-04 - val_loss: 5.7965e-04\n",
      "Epoch 1323/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.9168e-04 - val_loss: 5.7938e-04\n",
      "Epoch 1324/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.9196e-04 - val_loss: 5.7707e-04\n",
      "Epoch 1325/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9157e-04 - val_loss: 5.7985e-04\n",
      "Epoch 1326/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9167e-04 - val_loss: 5.7811e-04\n",
      "Epoch 1327/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9162e-04 - val_loss: 5.7776e-04\n",
      "Epoch 1328/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9141e-04 - val_loss: 5.7885e-04\n",
      "Epoch 1329/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9149e-04 - val_loss: 5.7725e-04\n",
      "Epoch 1330/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9144e-04 - val_loss: 5.7744e-04\n",
      "Epoch 1331/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9139e-04 - val_loss: 5.7731e-04\n",
      "Epoch 1332/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9135e-04 - val_loss: 5.7723e-04\n",
      "Epoch 1333/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9129e-04 - val_loss: 5.7723e-04\n",
      "Epoch 1334/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9125e-04 - val_loss: 5.7725e-04\n",
      "Epoch 1335/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9121e-04 - val_loss: 5.7710e-04\n",
      "Epoch 1336/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9107e-04 - val_loss: 5.7840e-04\n",
      "Epoch 1337/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9105e-04 - val_loss: 5.8058e-04\n",
      "Epoch 1338/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.9137e-04 - val_loss: 5.8003e-04\n",
      "Epoch 1339/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9114e-04 - val_loss: 5.7909e-04\n",
      "Epoch 1340/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.9104e-04 - val_loss: 5.8001e-04\n",
      "Epoch 1341/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9108e-04 - val_loss: 5.7644e-04\n",
      "Epoch 1342/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.9120e-04 - val_loss: 5.7588e-04\n",
      "Epoch 1343/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9122e-04 - val_loss: 5.7611e-04\n",
      "Epoch 1344/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9083e-04 - val_loss: 5.7882e-04\n",
      "Epoch 1345/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9072e-04 - val_loss: 5.7674e-04\n",
      "Epoch 1346/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9069e-04 - val_loss: 5.7976e-04\n",
      "Epoch 1347/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9082e-04 - val_loss: 5.7623e-04\n",
      "Epoch 1348/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9080e-04 - val_loss: 5.7605e-04\n",
      "Epoch 1349/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9057e-04 - val_loss: 5.8112e-04\n",
      "Epoch 1350/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9052e-04 - val_loss: 5.7614e-04\n",
      "Epoch 1351/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9090e-04 - val_loss: 5.7926e-04\n",
      "Epoch 1352/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9072e-04 - val_loss: 5.7644e-04\n",
      "Epoch 1353/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.9054e-04 - val_loss: 5.7613e-04\n",
      "Epoch 1354/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9052e-04 - val_loss: 5.7566e-04\n",
      "Epoch 1355/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9051e-04 - val_loss: 5.7943e-04\n",
      "Epoch 1356/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9030e-04 - val_loss: 5.7591e-04\n",
      "Epoch 1357/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9042e-04 - val_loss: 5.7795e-04\n",
      "Epoch 1358/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9036e-04 - val_loss: 5.8054e-04\n",
      "Epoch 1359/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9064e-04 - val_loss: 5.7412e-04\n",
      "Epoch 1360/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9023e-04 - val_loss: 5.7534e-04\n",
      "Epoch 1361/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.9028e-04 - val_loss: 5.7520e-04\n",
      "Epoch 1362/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 5.9040e-04 - val_loss: 5.7633e-04\n",
      "Epoch 1363/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.9040e-04 - val_loss: 5.7627e-04\n",
      "Epoch 1364/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9013e-04 - val_loss: 5.7855e-04\n",
      "Epoch 1365/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9015e-04 - val_loss: 5.7865e-04\n",
      "Epoch 1366/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9033e-04 - val_loss: 5.7371e-04\n",
      "Epoch 1367/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8992e-04 - val_loss: 5.7452e-04\n",
      "Epoch 1368/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9006e-04 - val_loss: 5.7542e-04\n",
      "Epoch 1369/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9006e-04 - val_loss: 5.7379e-04\n",
      "Epoch 1370/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9003e-04 - val_loss: 5.7446e-04\n",
      "Epoch 1371/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8975e-04 - val_loss: 5.7457e-04\n",
      "Epoch 1372/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8989e-04 - val_loss: 5.7511e-04\n",
      "Epoch 1373/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8998e-04 - val_loss: 5.7436e-04\n",
      "Epoch 1374/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8984e-04 - val_loss: 5.7443e-04\n",
      "Epoch 1375/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8974e-04 - val_loss: 5.7362e-04\n",
      "Epoch 1376/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8986e-04 - val_loss: 5.7520e-04\n",
      "Epoch 1377/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9010e-04 - val_loss: 5.7495e-04\n",
      "Epoch 1378/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8971e-04 - val_loss: 5.7338e-04\n",
      "Epoch 1379/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8995e-04 - val_loss: 5.7528e-04\n",
      "Epoch 1380/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.8964e-04 - val_loss: 5.7351e-04\n",
      "Epoch 1381/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8962e-04 - val_loss: 5.7319e-04\n",
      "Epoch 1382/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8936e-04 - val_loss: 5.7383e-04\n",
      "Epoch 1383/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8955e-04 - val_loss: 5.7650e-04\n",
      "Epoch 1384/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8961e-04 - val_loss: 5.7585e-04\n",
      "Epoch 1385/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8945e-04 - val_loss: 5.7633e-04\n",
      "Epoch 1386/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8938e-04 - val_loss: 5.7367e-04\n",
      "Epoch 1387/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8941e-04 - val_loss: 5.7501e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1388/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8969e-04 - val_loss: 5.7413e-04\n",
      "Epoch 1389/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8939e-04 - val_loss: 5.7406e-04\n",
      "Epoch 1390/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.8925e-04 - val_loss: 5.7327e-04\n",
      "Epoch 1391/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8952e-04 - val_loss: 5.7365e-04\n",
      "Epoch 1392/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8924e-04 - val_loss: 5.7327e-04\n",
      "Epoch 1393/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8903e-04 - val_loss: 5.7321e-04\n",
      "Epoch 1394/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8918e-04 - val_loss: 5.7210e-04\n",
      "Epoch 1395/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8951e-04 - val_loss: 5.7585e-04\n",
      "Epoch 1396/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8950e-04 - val_loss: 5.7438e-04\n",
      "Epoch 1397/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8929e-04 - val_loss: 5.7509e-04\n",
      "Epoch 1398/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8944e-04 - val_loss: 5.7221e-04\n",
      "Epoch 1399/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.8933e-04 - val_loss: 5.7260e-04\n",
      "Epoch 1400/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8911e-04 - val_loss: 5.7127e-04\n",
      "Epoch 1401/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8904e-04 - val_loss: 5.7484e-04\n",
      "Epoch 1402/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8919e-04 - val_loss: 5.7300e-04\n",
      "Epoch 1403/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8904e-04 - val_loss: 5.7201e-04\n",
      "Epoch 1404/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8886e-04 - val_loss: 5.7267e-04\n",
      "Epoch 1405/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8880e-04 - val_loss: 5.7119e-04\n",
      "Epoch 1406/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8892e-04 - val_loss: 5.7280e-04\n",
      "Epoch 1407/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8890e-04 - val_loss: 5.7101e-04\n",
      "Epoch 1408/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8880e-04 - val_loss: 5.7234e-04\n",
      "Epoch 1409/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.8881e-04 - val_loss: 5.7344e-04\n",
      "Epoch 1410/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8861e-04 - val_loss: 5.7133e-04\n",
      "Epoch 1411/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8897e-04 - val_loss: 5.7318e-04\n",
      "Epoch 1412/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8865e-04 - val_loss: 5.7372e-04\n",
      "Epoch 1413/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8867e-04 - val_loss: 5.7055e-04\n",
      "Epoch 1414/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8886e-04 - val_loss: 5.7407e-04\n",
      "Epoch 1415/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.8894e-04 - val_loss: 5.7309e-04\n",
      "Epoch 1416/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8852e-04 - val_loss: 5.7229e-04\n",
      "Epoch 1417/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.8880e-04 - val_loss: 5.7133e-04\n",
      "Epoch 1418/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8855e-04 - val_loss: 5.7008e-04\n",
      "Epoch 1419/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8846e-04 - val_loss: 5.7054e-04\n",
      "Epoch 1420/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8860e-04 - val_loss: 5.7316e-04\n",
      "Epoch 1421/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8862e-04 - val_loss: 5.7125e-04\n",
      "Epoch 1422/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8844e-04 - val_loss: 5.6968e-04\n",
      "Epoch 1423/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8845e-04 - val_loss: 5.7062e-04\n",
      "Epoch 1424/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8845e-04 - val_loss: 5.7361e-04\n",
      "Epoch 1425/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8851e-04 - val_loss: 5.7163e-04\n",
      "Epoch 1426/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8836e-04 - val_loss: 5.6976e-04\n",
      "Epoch 1427/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8851e-04 - val_loss: 5.7305e-04\n",
      "Epoch 1428/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8810e-04 - val_loss: 5.7130e-04\n",
      "Epoch 1429/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8818e-04 - val_loss: 5.7007e-04\n",
      "Epoch 1430/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8801e-04 - val_loss: 5.7344e-04\n",
      "Epoch 1431/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8839e-04 - val_loss: 5.7183e-04\n",
      "Epoch 1432/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8803e-04 - val_loss: 5.7261e-04\n",
      "Epoch 1433/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8786e-04 - val_loss: 5.7193e-04\n",
      "Epoch 1434/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.8804e-04 - val_loss: 5.7017e-04\n",
      "Epoch 1435/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8792e-04 - val_loss: 5.6967e-04\n",
      "Epoch 1436/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.8787e-04 - val_loss: 5.6966e-04\n",
      "Epoch 1437/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.8808e-04 - val_loss: 5.7100e-04\n",
      "Epoch 1438/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8768e-04 - val_loss: 5.6981e-04\n",
      "Epoch 1439/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8797e-04 - val_loss: 5.7084e-04\n",
      "Epoch 1440/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8782e-04 - val_loss: 5.6905e-04\n",
      "Epoch 1441/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8799e-04 - val_loss: 5.6997e-04\n",
      "Epoch 1442/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8780e-04 - val_loss: 5.6919e-04\n",
      "Epoch 1443/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8751e-04 - val_loss: 5.7114e-04\n",
      "Epoch 1444/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.8770e-04 - val_loss: 5.6849e-04\n",
      "Epoch 1445/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8764e-04 - val_loss: 5.6876e-04\n",
      "Epoch 1446/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8735e-04 - val_loss: 5.6956e-04\n",
      "Epoch 1447/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8761e-04 - val_loss: 5.6870e-04\n",
      "Epoch 1448/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8731e-04 - val_loss: 5.6952e-04\n",
      "Epoch 1449/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8777e-04 - val_loss: 5.6898e-04\n",
      "Epoch 1450/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8745e-04 - val_loss: 5.6770e-04\n",
      "Epoch 1451/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8733e-04 - val_loss: 5.6875e-04\n",
      "Epoch 1452/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8705e-04 - val_loss: 5.6895e-04\n",
      "Epoch 1453/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8730e-04 - val_loss: 5.6844e-04\n",
      "Epoch 1454/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8731e-04 - val_loss: 5.6865e-04\n",
      "Epoch 1455/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.8723e-04 - val_loss: 5.6860e-04\n",
      "Epoch 1456/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8734e-04 - val_loss: 5.6788e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1457/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8700e-04 - val_loss: 5.6794e-04\n",
      "Epoch 1458/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8707e-04 - val_loss: 5.6717e-04\n",
      "Epoch 1459/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8693e-04 - val_loss: 5.6764e-04\n",
      "Epoch 1460/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8697e-04 - val_loss: 5.6683e-04\n",
      "Epoch 1461/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8702e-04 - val_loss: 5.6674e-04\n",
      "Epoch 1462/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8694e-04 - val_loss: 5.6675e-04\n",
      "Epoch 1463/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8692e-04 - val_loss: 5.6637e-04\n",
      "Epoch 1464/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.8684e-04 - val_loss: 5.6652e-04\n",
      "Epoch 1465/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8678e-04 - val_loss: 5.6668e-04\n",
      "Epoch 1466/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8671e-04 - val_loss: 5.6647e-04\n",
      "Epoch 1467/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8681e-04 - val_loss: 5.6649e-04\n",
      "Epoch 1468/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8650e-04 - val_loss: 5.6708e-04\n",
      "Epoch 1469/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8681e-04 - val_loss: 5.6608e-04\n",
      "Epoch 1470/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8672e-04 - val_loss: 5.6607e-04\n",
      "Epoch 1471/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8650e-04 - val_loss: 5.6643e-04\n",
      "Epoch 1472/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.8668e-04 - val_loss: 5.6656e-04\n",
      "Epoch 1473/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8642e-04 - val_loss: 5.6641e-04\n",
      "Epoch 1474/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.8652e-04 - val_loss: 5.6609e-04\n",
      "Epoch 1475/10000\n",
      "45507/45507 [==============================] - 1s 23us/step - loss: 5.8646e-04 - val_loss: 5.6567e-04\n",
      "Epoch 1476/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.8652e-04 - val_loss: 5.6579e-04\n",
      "Epoch 1477/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8640e-04 - val_loss: 5.6558e-04\n",
      "Epoch 1478/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8634e-04 - val_loss: 5.6532e-04\n",
      "Epoch 1479/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8630e-04 - val_loss: 5.6533e-04\n",
      "Epoch 1480/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8624e-04 - val_loss: 5.6508e-04\n",
      "Epoch 1481/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8613e-04 - val_loss: 5.6544e-04\n",
      "Epoch 1482/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8616e-04 - val_loss: 5.6506e-04\n",
      "Epoch 1483/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8604e-04 - val_loss: 5.6526e-04\n",
      "Epoch 1484/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8601e-04 - val_loss: 5.6530e-04\n",
      "Epoch 1485/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8617e-04 - val_loss: 5.6487e-04\n",
      "Epoch 1486/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8620e-04 - val_loss: 5.6546e-04\n",
      "Epoch 1487/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8596e-04 - val_loss: 5.6529e-04\n",
      "Epoch 1488/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8584e-04 - val_loss: 5.6529e-04\n",
      "Epoch 1489/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8596e-04 - val_loss: 5.6497e-04\n",
      "Epoch 1490/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8594e-04 - val_loss: 5.6513e-04\n",
      "Epoch 1491/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8593e-04 - val_loss: 5.6471e-04\n",
      "Epoch 1492/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8582e-04 - val_loss: 5.6516e-04\n",
      "Epoch 1493/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.8585e-04 - val_loss: 5.6473e-04\n",
      "Epoch 1494/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.8558e-04 - val_loss: 5.6522e-04\n",
      "Epoch 1495/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8572e-04 - val_loss: 5.6473e-04\n",
      "Epoch 1496/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8565e-04 - val_loss: 5.6482e-04\n",
      "Epoch 1497/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8558e-04 - val_loss: 5.6483e-04\n",
      "Epoch 1498/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8556e-04 - val_loss: 5.6461e-04\n",
      "Epoch 1499/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8574e-04 - val_loss: 5.6396e-04\n",
      "Epoch 1500/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8547e-04 - val_loss: 5.6442e-04\n",
      "Epoch 1501/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8541e-04 - val_loss: 5.6429e-04\n",
      "Epoch 1502/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8534e-04 - val_loss: 5.6436e-04\n",
      "Epoch 1503/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8537e-04 - val_loss: 5.6418e-04\n",
      "Epoch 1504/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8525e-04 - val_loss: 5.6475e-04\n",
      "Epoch 1505/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.8557e-04 - val_loss: 5.6382e-04\n",
      "Epoch 1506/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8537e-04 - val_loss: 5.6421e-04\n",
      "Epoch 1507/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8525e-04 - val_loss: 5.6456e-04\n",
      "Epoch 1508/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8525e-04 - val_loss: 5.6395e-04\n",
      "Epoch 1509/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8514e-04 - val_loss: 5.6402e-04\n",
      "Epoch 1510/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8516e-04 - val_loss: 5.6403e-04\n",
      "Epoch 1511/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8539e-04 - val_loss: 5.6311e-04\n",
      "Epoch 1512/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.8518e-04 - val_loss: 5.6398e-04\n",
      "Epoch 1513/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.8507e-04 - val_loss: 5.6398e-04\n",
      "Epoch 1514/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8507e-04 - val_loss: 5.6364e-04\n",
      "Epoch 1515/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8490e-04 - val_loss: 5.6351e-04\n",
      "Epoch 1516/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8500e-04 - val_loss: 5.6381e-04\n",
      "Epoch 1517/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8489e-04 - val_loss: 5.6331e-04\n",
      "Epoch 1518/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8488e-04 - val_loss: 5.6304e-04\n",
      "Epoch 1519/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8489e-04 - val_loss: 5.6347e-04\n",
      "Epoch 1520/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8495e-04 - val_loss: 5.6292e-04\n",
      "Epoch 1521/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8472e-04 - val_loss: 5.6313e-04\n",
      "Epoch 1522/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8485e-04 - val_loss: 5.6247e-04\n",
      "Epoch 1523/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8482e-04 - val_loss: 5.6257e-04\n",
      "Epoch 1524/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8503e-04 - val_loss: 5.6171e-04\n",
      "Epoch 1525/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8490e-04 - val_loss: 5.6187e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1526/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8478e-04 - val_loss: 5.6261e-04\n",
      "Epoch 1527/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8471e-04 - val_loss: 5.6379e-04\n",
      "Epoch 1528/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8469e-04 - val_loss: 5.6288e-04\n",
      "Epoch 1529/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8460e-04 - val_loss: 5.6284e-04\n",
      "Epoch 1530/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8457e-04 - val_loss: 5.6228e-04\n",
      "Epoch 1531/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.8450e-04 - val_loss: 5.6272e-04\n",
      "Epoch 1532/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8446e-04 - val_loss: 5.6279e-04\n",
      "Epoch 1533/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8465e-04 - val_loss: 5.6271e-04\n",
      "Epoch 1534/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8441e-04 - val_loss: 5.6274e-04\n",
      "Epoch 1535/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8445e-04 - val_loss: 5.6285e-04\n",
      "Epoch 1536/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8428e-04 - val_loss: 5.6255e-04\n",
      "Epoch 1537/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8430e-04 - val_loss: 5.6279e-04\n",
      "Epoch 1538/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8441e-04 - val_loss: 5.6286e-04\n",
      "Epoch 1539/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8432e-04 - val_loss: 5.6289e-04\n",
      "Epoch 1540/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8425e-04 - val_loss: 5.6222e-04\n",
      "Epoch 1541/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8425e-04 - val_loss: 5.6198e-04\n",
      "Epoch 1542/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8423e-04 - val_loss: 5.6160e-04\n",
      "Epoch 1543/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8417e-04 - val_loss: 5.6091e-04\n",
      "Epoch 1544/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8421e-04 - val_loss: 5.6050e-04\n",
      "Epoch 1545/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8422e-04 - val_loss: 5.6056e-04\n",
      "Epoch 1546/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8405e-04 - val_loss: 5.6097e-04\n",
      "Epoch 1547/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8403e-04 - val_loss: 5.6088e-04\n",
      "Epoch 1548/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8397e-04 - val_loss: 5.6066e-04\n",
      "Epoch 1549/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8392e-04 - val_loss: 5.6038e-04\n",
      "Epoch 1550/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.8388e-04 - val_loss: 5.6049e-04\n",
      "Epoch 1551/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8377e-04 - val_loss: 5.6040e-04\n",
      "Epoch 1552/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8385e-04 - val_loss: 5.6067e-04\n",
      "Epoch 1553/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8409e-04 - val_loss: 5.5953e-04\n",
      "Epoch 1554/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8382e-04 - val_loss: 5.6046e-04\n",
      "Epoch 1555/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8375e-04 - val_loss: 5.6002e-04\n",
      "Epoch 1556/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8363e-04 - val_loss: 5.6007e-04\n",
      "Epoch 1557/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8381e-04 - val_loss: 5.5922e-04\n",
      "Epoch 1558/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8370e-04 - val_loss: 5.6023e-04\n",
      "Epoch 1559/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8363e-04 - val_loss: 5.5972e-04\n",
      "Epoch 1560/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8357e-04 - val_loss: 5.6004e-04\n",
      "Epoch 1561/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8359e-04 - val_loss: 5.5996e-04\n",
      "Epoch 1562/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8345e-04 - val_loss: 5.6006e-04\n",
      "Epoch 1563/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.8349e-04 - val_loss: 5.6009e-04\n",
      "Epoch 1564/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8355e-04 - val_loss: 5.5870e-04\n",
      "Epoch 1565/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8355e-04 - val_loss: 5.5927e-04\n",
      "Epoch 1566/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8335e-04 - val_loss: 5.6007e-04\n",
      "Epoch 1567/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8332e-04 - val_loss: 5.5974e-04\n",
      "Epoch 1568/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.8328e-04 - val_loss: 5.5947e-04\n",
      "Epoch 1569/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.8326e-04 - val_loss: 5.5998e-04\n",
      "Epoch 1570/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8329e-04 - val_loss: 5.5856e-04\n",
      "Epoch 1571/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8327e-04 - val_loss: 5.5969e-04\n",
      "Epoch 1572/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8317e-04 - val_loss: 5.5860e-04\n",
      "Epoch 1573/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8308e-04 - val_loss: 5.5931e-04\n",
      "Epoch 1574/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8306e-04 - val_loss: 5.5887e-04\n",
      "Epoch 1575/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8327e-04 - val_loss: 5.5860e-04\n",
      "Epoch 1576/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8305e-04 - val_loss: 5.5856e-04\n",
      "Epoch 1577/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8315e-04 - val_loss: 5.5755e-04\n",
      "Epoch 1578/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8304e-04 - val_loss: 5.5887e-04\n",
      "Epoch 1579/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8299e-04 - val_loss: 5.5823e-04\n",
      "Epoch 1580/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8322e-04 - val_loss: 5.5758e-04\n",
      "Epoch 1581/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8313e-04 - val_loss: 5.5735e-04\n",
      "Epoch 1582/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8303e-04 - val_loss: 5.5857e-04\n",
      "Epoch 1583/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8289e-04 - val_loss: 5.5791e-04\n",
      "Epoch 1584/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8303e-04 - val_loss: 5.5731e-04\n",
      "Epoch 1585/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8292e-04 - val_loss: 5.5778e-04\n",
      "Epoch 1586/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8281e-04 - val_loss: 5.5854e-04\n",
      "Epoch 1587/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.8276e-04 - val_loss: 5.5796e-04\n",
      "Epoch 1588/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8290e-04 - val_loss: 5.5764e-04\n",
      "Epoch 1589/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8266e-04 - val_loss: 5.5736e-04\n",
      "Epoch 1590/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8258e-04 - val_loss: 5.5798e-04\n",
      "Epoch 1591/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.8275e-04 - val_loss: 5.5688e-04\n",
      "Epoch 1592/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8259e-04 - val_loss: 5.5769e-04\n",
      "Epoch 1593/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8265e-04 - val_loss: 5.5701e-04\n",
      "Epoch 1594/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8250e-04 - val_loss: 5.5796e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1595/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8247e-04 - val_loss: 5.5792e-04\n",
      "Epoch 1596/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8242e-04 - val_loss: 5.5748e-04\n",
      "Epoch 1597/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8245e-04 - val_loss: 5.5678e-04\n",
      "Epoch 1598/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8237e-04 - val_loss: 5.5706e-04\n",
      "Epoch 1599/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8231e-04 - val_loss: 5.5667e-04\n",
      "Epoch 1600/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8245e-04 - val_loss: 5.5606e-04\n",
      "Epoch 1601/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8231e-04 - val_loss: 5.5748e-04\n",
      "Epoch 1602/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8230e-04 - val_loss: 5.5669e-04\n",
      "Epoch 1603/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8222e-04 - val_loss: 5.5696e-04\n",
      "Epoch 1604/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8226e-04 - val_loss: 5.5602e-04\n",
      "Epoch 1605/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.8247e-04 - val_loss: 5.5611e-04\n",
      "Epoch 1606/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.8220e-04 - val_loss: 5.5693e-04\n",
      "Epoch 1607/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8219e-04 - val_loss: 5.5595e-04\n",
      "Epoch 1608/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8210e-04 - val_loss: 5.5706e-04\n",
      "Epoch 1609/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8204e-04 - val_loss: 5.5647e-04\n",
      "Epoch 1610/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8203e-04 - val_loss: 5.5691e-04\n",
      "Epoch 1611/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8197e-04 - val_loss: 5.5647e-04\n",
      "Epoch 1612/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8203e-04 - val_loss: 5.5638e-04\n",
      "Epoch 1613/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8199e-04 - val_loss: 5.5635e-04\n",
      "Epoch 1614/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8196e-04 - val_loss: 5.5589e-04\n",
      "Epoch 1615/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8189e-04 - val_loss: 5.5591e-04\n",
      "Epoch 1616/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8187e-04 - val_loss: 5.5584e-04\n",
      "Epoch 1617/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8186e-04 - val_loss: 5.5509e-04\n",
      "Epoch 1618/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8182e-04 - val_loss: 5.5555e-04\n",
      "Epoch 1619/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8180e-04 - val_loss: 5.5491e-04\n",
      "Epoch 1620/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8176e-04 - val_loss: 5.5565e-04\n",
      "Epoch 1621/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8187e-04 - val_loss: 5.5576e-04\n",
      "Epoch 1622/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8193e-04 - val_loss: 5.5454e-04\n",
      "Epoch 1623/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8172e-04 - val_loss: 5.5548e-04\n",
      "Epoch 1624/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.8178e-04 - val_loss: 5.5537e-04\n",
      "Epoch 1625/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.8183e-04 - val_loss: 5.5478e-04\n",
      "Epoch 1626/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8175e-04 - val_loss: 5.5467e-04\n",
      "Epoch 1627/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8161e-04 - val_loss: 5.5521e-04\n",
      "Epoch 1628/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8165e-04 - val_loss: 5.5490e-04\n",
      "Epoch 1629/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8155e-04 - val_loss: 5.5489e-04\n",
      "Epoch 1630/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8157e-04 - val_loss: 5.5459e-04\n",
      "Epoch 1631/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8155e-04 - val_loss: 5.5465e-04\n",
      "Epoch 1632/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8148e-04 - val_loss: 5.5515e-04\n",
      "Epoch 1633/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8154e-04 - val_loss: 5.5512e-04\n",
      "Epoch 1634/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8137e-04 - val_loss: 5.5426e-04\n",
      "Epoch 1635/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8147e-04 - val_loss: 5.5464e-04\n",
      "Epoch 1636/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8136e-04 - val_loss: 5.5429e-04\n",
      "Epoch 1637/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8128e-04 - val_loss: 5.5472e-04\n",
      "Epoch 1638/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8125e-04 - val_loss: 5.5467e-04\n",
      "Epoch 1639/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8130e-04 - val_loss: 5.5454e-04\n",
      "Epoch 1640/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8122e-04 - val_loss: 5.5439e-04\n",
      "Epoch 1641/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8130e-04 - val_loss: 5.5502e-04\n",
      "Epoch 1642/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8108e-04 - val_loss: 5.5439e-04\n",
      "Epoch 1643/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.8106e-04 - val_loss: 5.5522e-04\n",
      "Epoch 1644/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8119e-04 - val_loss: 5.5435e-04\n",
      "Epoch 1645/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8106e-04 - val_loss: 5.5429e-04\n",
      "Epoch 1646/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8105e-04 - val_loss: 5.5358e-04\n",
      "Epoch 1647/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8099e-04 - val_loss: 5.5412e-04\n",
      "Epoch 1648/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.8087e-04 - val_loss: 5.5437e-04\n",
      "Epoch 1649/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8086e-04 - val_loss: 5.5380e-04\n",
      "Epoch 1650/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8083e-04 - val_loss: 5.5396e-04\n",
      "Epoch 1651/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8080e-04 - val_loss: 5.5368e-04\n",
      "Epoch 1652/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8076e-04 - val_loss: 5.5396e-04\n",
      "Epoch 1653/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8095e-04 - val_loss: 5.5421e-04\n",
      "Epoch 1654/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8080e-04 - val_loss: 5.5438e-04\n",
      "Epoch 1655/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8094e-04 - val_loss: 5.5350e-04\n",
      "Epoch 1656/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8090e-04 - val_loss: 5.5384e-04\n",
      "Epoch 1657/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8098e-04 - val_loss: 5.5361e-04\n",
      "Epoch 1658/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8079e-04 - val_loss: 5.5315e-04\n",
      "Epoch 1659/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8081e-04 - val_loss: 5.5345e-04\n",
      "Epoch 1660/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8070e-04 - val_loss: 5.5349e-04\n",
      "Epoch 1661/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8082e-04 - val_loss: 5.5320e-04\n",
      "Epoch 1662/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8066e-04 - val_loss: 5.5316e-04\n",
      "Epoch 1663/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8061e-04 - val_loss: 5.5352e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1664/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.8070e-04 - val_loss: 5.5333e-04\n",
      "Epoch 1665/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8051e-04 - val_loss: 5.5294e-04\n",
      "Epoch 1666/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8047e-04 - val_loss: 5.5311e-04\n",
      "Epoch 1667/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.8052e-04 - val_loss: 5.5347e-04\n",
      "Epoch 1668/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8055e-04 - val_loss: 5.5390e-04\n",
      "Epoch 1669/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8037e-04 - val_loss: 5.5327e-04\n",
      "Epoch 1670/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8048e-04 - val_loss: 5.5410e-04\n",
      "Epoch 1671/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8032e-04 - val_loss: 5.5279e-04\n",
      "Epoch 1672/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8054e-04 - val_loss: 5.5420e-04\n",
      "Epoch 1673/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8048e-04 - val_loss: 5.5258e-04\n",
      "Epoch 1674/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8033e-04 - val_loss: 5.5307e-04\n",
      "Epoch 1675/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8030e-04 - val_loss: 5.5360e-04\n",
      "Epoch 1676/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8023e-04 - val_loss: 5.5253e-04\n",
      "Epoch 1677/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8013e-04 - val_loss: 5.5392e-04\n",
      "Epoch 1678/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8011e-04 - val_loss: 5.5297e-04\n",
      "Epoch 1679/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8013e-04 - val_loss: 5.5267e-04\n",
      "Epoch 1680/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8006e-04 - val_loss: 5.5450e-04\n",
      "Epoch 1681/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.8023e-04 - val_loss: 5.5234e-04\n",
      "Epoch 1682/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8001e-04 - val_loss: 5.5242e-04\n",
      "Epoch 1683/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8023e-04 - val_loss: 5.5379e-04\n",
      "Epoch 1684/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8002e-04 - val_loss: 5.5291e-04\n",
      "Epoch 1685/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8005e-04 - val_loss: 5.5381e-04\n",
      "Epoch 1686/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7991e-04 - val_loss: 5.5257e-04\n",
      "Epoch 1687/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7992e-04 - val_loss: 5.5189e-04\n",
      "Epoch 1688/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7983e-04 - val_loss: 5.5226e-04\n",
      "Epoch 1689/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8001e-04 - val_loss: 5.5375e-04\n",
      "Epoch 1690/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7985e-04 - val_loss: 5.5252e-04\n",
      "Epoch 1691/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7989e-04 - val_loss: 5.5325e-04\n",
      "Epoch 1692/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7992e-04 - val_loss: 5.5263e-04\n",
      "Epoch 1693/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7988e-04 - val_loss: 5.5276e-04\n",
      "Epoch 1694/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7986e-04 - val_loss: 5.5217e-04\n",
      "Epoch 1695/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7978e-04 - val_loss: 5.5227e-04\n",
      "Epoch 1696/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7984e-04 - val_loss: 5.5233e-04\n",
      "Epoch 1697/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7967e-04 - val_loss: 5.5241e-04\n",
      "Epoch 1698/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7993e-04 - val_loss: 5.5282e-04\n",
      "Epoch 1699/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7987e-04 - val_loss: 5.5217e-04\n",
      "Epoch 1700/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7970e-04 - val_loss: 5.5280e-04\n",
      "Epoch 1701/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7969e-04 - val_loss: 5.5289e-04\n",
      "Epoch 1702/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7968e-04 - val_loss: 5.5155e-04\n",
      "Epoch 1703/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7970e-04 - val_loss: 5.5287e-04\n",
      "Epoch 1704/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7960e-04 - val_loss: 5.5294e-04\n",
      "Epoch 1705/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7966e-04 - val_loss: 5.5321e-04\n",
      "Epoch 1706/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7958e-04 - val_loss: 5.5267e-04\n",
      "Epoch 1707/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7949e-04 - val_loss: 5.5162e-04\n",
      "Epoch 1708/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7974e-04 - val_loss: 5.5309e-04\n",
      "Epoch 1709/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7959e-04 - val_loss: 5.5247e-04\n",
      "Epoch 1710/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7950e-04 - val_loss: 5.5274e-04\n",
      "Epoch 1711/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7948e-04 - val_loss: 5.5264e-04\n",
      "Epoch 1712/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7952e-04 - val_loss: 5.5330e-04\n",
      "Epoch 1713/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7940e-04 - val_loss: 5.5239e-04\n",
      "Epoch 1714/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7943e-04 - val_loss: 5.5337e-04\n",
      "Epoch 1715/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7935e-04 - val_loss: 5.5245e-04\n",
      "Epoch 1716/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7935e-04 - val_loss: 5.5256e-04\n",
      "Epoch 1717/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7927e-04 - val_loss: 5.5218e-04\n",
      "Epoch 1718/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7938e-04 - val_loss: 5.5232e-04\n",
      "Epoch 1719/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7930e-04 - val_loss: 5.5302e-04\n",
      "Epoch 1720/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7919e-04 - val_loss: 5.5263e-04\n",
      "Epoch 1721/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7923e-04 - val_loss: 5.5346e-04\n",
      "Epoch 1722/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7917e-04 - val_loss: 5.5212e-04\n",
      "Epoch 1723/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7911e-04 - val_loss: 5.5211e-04\n",
      "Epoch 1724/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7927e-04 - val_loss: 5.5233e-04\n",
      "Epoch 1725/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7924e-04 - val_loss: 5.5239e-04\n",
      "Epoch 1726/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7916e-04 - val_loss: 5.5199e-04\n",
      "Epoch 1727/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7900e-04 - val_loss: 5.5162e-04\n",
      "Epoch 1728/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7926e-04 - val_loss: 5.5198e-04\n",
      "Epoch 1729/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7910e-04 - val_loss: 5.5194e-04\n",
      "Epoch 1730/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7907e-04 - val_loss: 5.5272e-04\n",
      "Epoch 1731/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7908e-04 - val_loss: 5.5249e-04\n",
      "Epoch 1732/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7891e-04 - val_loss: 5.5125e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1733/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7899e-04 - val_loss: 5.5152e-04\n",
      "Epoch 1734/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7885e-04 - val_loss: 5.5149e-04\n",
      "Epoch 1735/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7892e-04 - val_loss: 5.5202e-04\n",
      "Epoch 1736/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7879e-04 - val_loss: 5.5156e-04\n",
      "Epoch 1737/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7877e-04 - val_loss: 5.5168e-04\n",
      "Epoch 1738/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7876e-04 - val_loss: 5.5205e-04\n",
      "Epoch 1739/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7873e-04 - val_loss: 5.5232e-04\n",
      "Epoch 1740/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7875e-04 - val_loss: 5.5297e-04\n",
      "Epoch 1741/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7891e-04 - val_loss: 5.5185e-04\n",
      "Epoch 1742/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7864e-04 - val_loss: 5.5169e-04\n",
      "Epoch 1743/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7863e-04 - val_loss: 5.5259e-04\n",
      "Epoch 1744/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7855e-04 - val_loss: 5.5296e-04\n",
      "Epoch 1745/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7867e-04 - val_loss: 5.5354e-04\n",
      "Epoch 1746/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7880e-04 - val_loss: 5.5145e-04\n",
      "Epoch 1747/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7858e-04 - val_loss: 5.5176e-04\n",
      "Epoch 1748/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7867e-04 - val_loss: 5.5217e-04\n",
      "Epoch 1749/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7864e-04 - val_loss: 5.5239e-04\n",
      "Epoch 1750/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7856e-04 - val_loss: 5.5191e-04\n",
      "Epoch 1751/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7847e-04 - val_loss: 5.5255e-04\n",
      "Epoch 1752/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7841e-04 - val_loss: 5.5241e-04\n",
      "Epoch 1753/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7860e-04 - val_loss: 5.5213e-04\n",
      "Epoch 1754/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7857e-04 - val_loss: 5.5207e-04\n",
      "Epoch 1755/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7847e-04 - val_loss: 5.5229e-04\n",
      "Epoch 1756/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7840e-04 - val_loss: 5.5183e-04\n",
      "Epoch 1757/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7842e-04 - val_loss: 5.5192e-04\n",
      "Epoch 1758/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7839e-04 - val_loss: 5.5263e-04\n",
      "Epoch 1759/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7845e-04 - val_loss: 5.5195e-04\n",
      "Epoch 1760/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7840e-04 - val_loss: 5.5099e-04\n",
      "Epoch 1761/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7819e-04 - val_loss: 5.5168e-04\n",
      "Epoch 1762/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7834e-04 - val_loss: 5.5190e-04\n",
      "Epoch 1763/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7837e-04 - val_loss: 5.5219e-04\n",
      "Epoch 1764/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7814e-04 - val_loss: 5.5132e-04\n",
      "Epoch 1765/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7830e-04 - val_loss: 5.5175e-04\n",
      "Epoch 1766/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7822e-04 - val_loss: 5.5156e-04\n",
      "Epoch 1767/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7823e-04 - val_loss: 5.5192e-04\n",
      "Epoch 1768/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7825e-04 - val_loss: 5.5188e-04\n",
      "Epoch 1769/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7809e-04 - val_loss: 5.5244e-04\n",
      "Epoch 1770/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7820e-04 - val_loss: 5.5241e-04\n",
      "Epoch 1771/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7795e-04 - val_loss: 5.5186e-04\n",
      "Epoch 1772/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7824e-04 - val_loss: 5.5172e-04\n",
      "Epoch 1773/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7817e-04 - val_loss: 5.5125e-04\n",
      "Epoch 1774/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7808e-04 - val_loss: 5.5218e-04\n",
      "Epoch 1775/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7807e-04 - val_loss: 5.5108e-04\n",
      "Epoch 1776/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7803e-04 - val_loss: 5.5204e-04\n",
      "Epoch 1777/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7795e-04 - val_loss: 5.5149e-04\n",
      "Epoch 1778/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7791e-04 - val_loss: 5.5165e-04\n",
      "Epoch 1779/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7784e-04 - val_loss: 5.5170e-04\n",
      "Epoch 1780/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.7782e-04 - val_loss: 5.5255e-04\n",
      "Epoch 1781/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7779e-04 - val_loss: 5.5109e-04\n",
      "Epoch 1782/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7803e-04 - val_loss: 5.5110e-04\n",
      "Epoch 1783/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7771e-04 - val_loss: 5.5229e-04\n",
      "Epoch 1784/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7777e-04 - val_loss: 5.5170e-04\n",
      "Epoch 1785/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7782e-04 - val_loss: 5.5122e-04\n",
      "Epoch 1786/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7788e-04 - val_loss: 5.5125e-04\n",
      "Epoch 1787/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7777e-04 - val_loss: 5.5175e-04\n",
      "Epoch 1788/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7779e-04 - val_loss: 5.5115e-04\n",
      "Epoch 1789/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7773e-04 - val_loss: 5.5167e-04\n",
      "Epoch 1790/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7774e-04 - val_loss: 5.5180e-04\n",
      "Epoch 1791/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7773e-04 - val_loss: 5.5188e-04\n",
      "Epoch 1792/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7759e-04 - val_loss: 5.5194e-04\n",
      "Epoch 1793/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7766e-04 - val_loss: 5.5124e-04\n",
      "Epoch 1794/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7765e-04 - val_loss: 5.5212e-04\n",
      "Epoch 1795/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7745e-04 - val_loss: 5.5262e-04\n",
      "Epoch 1796/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7758e-04 - val_loss: 5.5187e-04\n",
      "Epoch 1797/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7749e-04 - val_loss: 5.5124e-04\n",
      "Epoch 1798/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7755e-04 - val_loss: 5.5139e-04\n",
      "Epoch 1799/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7763e-04 - val_loss: 5.5094e-04\n",
      "Epoch 1800/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7740e-04 - val_loss: 5.5240e-04\n",
      "Epoch 1801/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7747e-04 - val_loss: 5.5134e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1802/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7750e-04 - val_loss: 5.5106e-04\n",
      "Epoch 1803/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7749e-04 - val_loss: 5.5133e-04\n",
      "Epoch 1804/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7732e-04 - val_loss: 5.5131e-04\n",
      "Epoch 1805/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7736e-04 - val_loss: 5.5224e-04\n",
      "Epoch 1806/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7749e-04 - val_loss: 5.5132e-04\n",
      "Epoch 1807/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7733e-04 - val_loss: 5.5136e-04\n",
      "Epoch 1808/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7748e-04 - val_loss: 5.5113e-04\n",
      "Epoch 1809/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7753e-04 - val_loss: 5.5098e-04\n",
      "Epoch 1810/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7736e-04 - val_loss: 5.5129e-04\n",
      "Epoch 1811/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7736e-04 - val_loss: 5.5150e-04\n",
      "Epoch 1812/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7736e-04 - val_loss: 5.5184e-04\n",
      "Epoch 1813/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7727e-04 - val_loss: 5.5058e-04\n",
      "Epoch 1814/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7715e-04 - val_loss: 5.5251e-04\n",
      "Epoch 1815/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7723e-04 - val_loss: 5.5161e-04\n",
      "Epoch 1816/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7737e-04 - val_loss: 5.5157e-04\n",
      "Epoch 1817/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7721e-04 - val_loss: 5.5151e-04\n",
      "Epoch 1818/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7714e-04 - val_loss: 5.5163e-04\n",
      "Epoch 1819/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7712e-04 - val_loss: 5.5201e-04\n",
      "Epoch 1820/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7710e-04 - val_loss: 5.5394e-04\n",
      "Epoch 1821/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7729e-04 - val_loss: 5.5108e-04\n",
      "Epoch 1822/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7700e-04 - val_loss: 5.5062e-04\n",
      "Epoch 1823/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7722e-04 - val_loss: 5.5089e-04\n",
      "Epoch 1824/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7699e-04 - val_loss: 5.5126e-04\n",
      "Epoch 1825/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7699e-04 - val_loss: 5.5315e-04\n",
      "Epoch 1826/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7706e-04 - val_loss: 5.5040e-04\n",
      "Epoch 1827/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7712e-04 - val_loss: 5.5118e-04\n",
      "Epoch 1828/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7694e-04 - val_loss: 5.5203e-04\n",
      "Epoch 1829/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7692e-04 - val_loss: 5.5047e-04\n",
      "Epoch 1830/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7707e-04 - val_loss: 5.5071e-04\n",
      "Epoch 1831/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7689e-04 - val_loss: 5.5107e-04\n",
      "Epoch 1832/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7694e-04 - val_loss: 5.5091e-04\n",
      "Epoch 1833/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7683e-04 - val_loss: 5.5073e-04\n",
      "Epoch 1834/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7674e-04 - val_loss: 5.5356e-04\n",
      "Epoch 1835/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7689e-04 - val_loss: 5.5168e-04\n",
      "Epoch 1836/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7687e-04 - val_loss: 5.5070e-04\n",
      "Epoch 1837/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7681e-04 - val_loss: 5.5168e-04\n",
      "Epoch 1838/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7678e-04 - val_loss: 5.5170e-04\n",
      "Epoch 1839/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7678e-04 - val_loss: 5.5070e-04\n",
      "Epoch 1840/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7677e-04 - val_loss: 5.5205e-04\n",
      "Epoch 1841/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7691e-04 - val_loss: 5.5069e-04\n",
      "Epoch 1842/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7669e-04 - val_loss: 5.5164e-04\n",
      "Epoch 1843/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7661e-04 - val_loss: 5.5235e-04\n",
      "Epoch 1844/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7676e-04 - val_loss: 5.5079e-04\n",
      "Epoch 1845/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7652e-04 - val_loss: 5.5433e-04\n",
      "Epoch 1846/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7668e-04 - val_loss: 5.5085e-04\n",
      "Epoch 1847/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7658e-04 - val_loss: 5.5139e-04\n",
      "Epoch 1848/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7658e-04 - val_loss: 5.4975e-04\n",
      "Epoch 1849/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7656e-04 - val_loss: 5.5049e-04\n",
      "Epoch 1850/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7646e-04 - val_loss: 5.5073e-04\n",
      "Epoch 1851/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7682e-04 - val_loss: 5.5225e-04\n",
      "Epoch 1852/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7666e-04 - val_loss: 5.5087e-04\n",
      "Epoch 1853/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7652e-04 - val_loss: 5.5098e-04\n",
      "Epoch 1854/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7652e-04 - val_loss: 5.5259e-04\n",
      "Epoch 1855/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7668e-04 - val_loss: 5.5021e-04\n",
      "Epoch 1856/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7637e-04 - val_loss: 5.5065e-04\n",
      "Epoch 1857/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7653e-04 - val_loss: 5.4989e-04\n",
      "Epoch 1858/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7636e-04 - val_loss: 5.5016e-04\n",
      "Epoch 1859/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7637e-04 - val_loss: 5.5169e-04\n",
      "Epoch 1860/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7658e-04 - val_loss: 5.5266e-04\n",
      "Epoch 1861/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7636e-04 - val_loss: 5.5278e-04\n",
      "Epoch 1862/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7635e-04 - val_loss: 5.5085e-04\n",
      "Epoch 1863/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7633e-04 - val_loss: 5.5402e-04\n",
      "Epoch 1864/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7640e-04 - val_loss: 5.5136e-04\n",
      "Epoch 1865/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7637e-04 - val_loss: 5.4996e-04\n",
      "Epoch 1866/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7619e-04 - val_loss: 5.5046e-04\n",
      "Epoch 1867/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7615e-04 - val_loss: 5.5127e-04\n",
      "Epoch 1868/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7643e-04 - val_loss: 5.4954e-04\n",
      "Epoch 1869/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7624e-04 - val_loss: 5.4996e-04\n",
      "Epoch 1870/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7619e-04 - val_loss: 5.5336e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1871/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7636e-04 - val_loss: 5.5068e-04\n",
      "Epoch 1872/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7618e-04 - val_loss: 5.5126e-04\n",
      "Epoch 1873/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7638e-04 - val_loss: 5.5238e-04\n",
      "Epoch 1874/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7637e-04 - val_loss: 5.4920e-04\n",
      "Epoch 1875/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7613e-04 - val_loss: 5.5112e-04\n",
      "Epoch 1876/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7605e-04 - val_loss: 5.5061e-04\n",
      "Epoch 1877/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.7604e-04 - val_loss: 5.5078e-04\n",
      "Epoch 1878/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7600e-04 - val_loss: 5.5093e-04\n",
      "Epoch 1879/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7606e-04 - val_loss: 5.5164e-04\n",
      "Epoch 1880/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7622e-04 - val_loss: 5.4977e-04\n",
      "Epoch 1881/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7606e-04 - val_loss: 5.5033e-04\n",
      "Epoch 1882/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7602e-04 - val_loss: 5.5019e-04\n",
      "Epoch 1883/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7597e-04 - val_loss: 5.5206e-04\n",
      "Epoch 1884/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7621e-04 - val_loss: 5.5183e-04\n",
      "Epoch 1885/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7615e-04 - val_loss: 5.5129e-04\n",
      "Epoch 1886/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7591e-04 - val_loss: 5.5178e-04\n",
      "Epoch 1887/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7600e-04 - val_loss: 5.5005e-04\n",
      "Epoch 1888/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7585e-04 - val_loss: 5.4999e-04\n",
      "Epoch 1889/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7594e-04 - val_loss: 5.5094e-04\n",
      "Epoch 1890/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7588e-04 - val_loss: 5.5086e-04\n",
      "Epoch 1891/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7586e-04 - val_loss: 5.4981e-04\n",
      "Epoch 1892/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7581e-04 - val_loss: 5.5302e-04\n",
      "Epoch 1893/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7582e-04 - val_loss: 5.5121e-04\n",
      "Epoch 1894/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7590e-04 - val_loss: 5.5240e-04\n",
      "Epoch 1895/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7586e-04 - val_loss: 5.4949e-04\n",
      "Epoch 1896/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7575e-04 - val_loss: 5.5152e-04\n",
      "Epoch 1897/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7575e-04 - val_loss: 5.5179e-04\n",
      "Epoch 1898/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7568e-04 - val_loss: 5.5094e-04\n",
      "Epoch 1899/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7585e-04 - val_loss: 5.5317e-04\n",
      "Epoch 1900/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7577e-04 - val_loss: 5.5076e-04\n",
      "Epoch 1901/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7586e-04 - val_loss: 5.5113e-04\n",
      "Epoch 1902/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7579e-04 - val_loss: 5.5036e-04\n",
      "Epoch 1903/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7563e-04 - val_loss: 5.5022e-04\n",
      "Epoch 1904/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7577e-04 - val_loss: 5.5160e-04\n",
      "Epoch 1905/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7563e-04 - val_loss: 5.5310e-04\n",
      "Epoch 1906/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7569e-04 - val_loss: 5.5061e-04\n",
      "Epoch 1907/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7564e-04 - val_loss: 5.4956e-04\n",
      "Epoch 1908/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7548e-04 - val_loss: 5.5091e-04\n",
      "Epoch 1909/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7548e-04 - val_loss: 5.5189e-04\n",
      "Epoch 1910/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7554e-04 - val_loss: 5.5186e-04\n",
      "Epoch 1911/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7580e-04 - val_loss: 5.4960e-04\n",
      "Epoch 1912/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7559e-04 - val_loss: 5.4927e-04\n",
      "Epoch 1913/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7552e-04 - val_loss: 5.5088e-04\n",
      "Epoch 1914/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7552e-04 - val_loss: 5.5015e-04\n",
      "Epoch 1915/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7563e-04 - val_loss: 5.4828e-04\n",
      "Epoch 1916/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7544e-04 - val_loss: 5.4873e-04\n",
      "Epoch 1917/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7533e-04 - val_loss: 5.5017e-04\n",
      "Epoch 1918/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7547e-04 - val_loss: 5.4971e-04\n",
      "Epoch 1919/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7531e-04 - val_loss: 5.4950e-04\n",
      "Epoch 1920/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7548e-04 - val_loss: 5.5127e-04\n",
      "Epoch 1921/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7539e-04 - val_loss: 5.5021e-04\n",
      "Epoch 1922/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7537e-04 - val_loss: 5.4924e-04\n",
      "Epoch 1923/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7531e-04 - val_loss: 5.5134e-04\n",
      "Epoch 1924/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7549e-04 - val_loss: 5.5226e-04\n",
      "Epoch 1925/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7538e-04 - val_loss: 5.5061e-04\n",
      "Epoch 1926/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7534e-04 - val_loss: 5.4956e-04\n",
      "Epoch 1927/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7532e-04 - val_loss: 5.5075e-04\n",
      "Epoch 1928/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7521e-04 - val_loss: 5.5110e-04\n",
      "Epoch 1929/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7540e-04 - val_loss: 5.4852e-04\n",
      "Epoch 1930/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7534e-04 - val_loss: 5.4873e-04\n",
      "Epoch 1931/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7514e-04 - val_loss: 5.5281e-04\n",
      "Epoch 1932/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7524e-04 - val_loss: 5.5013e-04\n",
      "Epoch 1933/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7523e-04 - val_loss: 5.5030e-04\n",
      "Epoch 1934/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7535e-04 - val_loss: 5.5162e-04\n",
      "Epoch 1935/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7510e-04 - val_loss: 5.5188e-04\n",
      "Epoch 1936/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7521e-04 - val_loss: 5.5368e-04\n",
      "Epoch 1937/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7517e-04 - val_loss: 5.5104e-04\n",
      "Epoch 1938/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7510e-04 - val_loss: 5.5052e-04\n",
      "Epoch 1939/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7542e-04 - val_loss: 5.4827e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1940/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7515e-04 - val_loss: 5.5207e-04\n",
      "Epoch 1941/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7513e-04 - val_loss: 5.4853e-04\n",
      "Epoch 1942/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7505e-04 - val_loss: 5.4873e-04\n",
      "Epoch 1943/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7500e-04 - val_loss: 5.4871e-04\n",
      "Epoch 1944/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7501e-04 - val_loss: 5.5252e-04\n",
      "Epoch 1945/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7509e-04 - val_loss: 5.4840e-04\n",
      "Epoch 1946/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7516e-04 - val_loss: 5.4855e-04\n",
      "Epoch 1947/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7487e-04 - val_loss: 5.4824e-04\n",
      "Epoch 1948/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7510e-04 - val_loss: 5.4877e-04\n",
      "Epoch 1949/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7502e-04 - val_loss: 5.4966e-04\n",
      "Epoch 1950/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7493e-04 - val_loss: 5.4938e-04\n",
      "Epoch 1951/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7488e-04 - val_loss: 5.4833e-04\n",
      "Epoch 1952/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7484e-04 - val_loss: 5.5049e-04\n",
      "Epoch 1953/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7502e-04 - val_loss: 5.5181e-04\n",
      "Epoch 1954/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7493e-04 - val_loss: 5.4796e-04\n",
      "Epoch 1955/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7496e-04 - val_loss: 5.5181e-04\n",
      "Epoch 1956/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7489e-04 - val_loss: 5.4873e-04\n",
      "Epoch 1957/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7480e-04 - val_loss: 5.4884e-04\n",
      "Epoch 1958/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7482e-04 - val_loss: 5.4913e-04\n",
      "Epoch 1959/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7479e-04 - val_loss: 5.4877e-04\n",
      "Epoch 1960/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7477e-04 - val_loss: 5.4819e-04\n",
      "Epoch 1961/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7476e-04 - val_loss: 5.5196e-04\n",
      "Epoch 1962/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7474e-04 - val_loss: 5.4960e-04\n",
      "Epoch 1963/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7468e-04 - val_loss: 5.4938e-04\n",
      "Epoch 1964/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7486e-04 - val_loss: 5.4801e-04\n",
      "Epoch 1965/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7471e-04 - val_loss: 5.4724e-04\n",
      "Epoch 1966/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7469e-04 - val_loss: 5.5093e-04\n",
      "Epoch 1967/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7476e-04 - val_loss: 5.4794e-04\n",
      "Epoch 1968/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7464e-04 - val_loss: 5.5107e-04\n",
      "Epoch 1969/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7468e-04 - val_loss: 5.4758e-04\n",
      "Epoch 1970/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7462e-04 - val_loss: 5.4949e-04\n",
      "Epoch 1971/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7466e-04 - val_loss: 5.4900e-04\n",
      "Epoch 1972/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7462e-04 - val_loss: 5.4998e-04\n",
      "Epoch 1973/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7454e-04 - val_loss: 5.5065e-04\n",
      "Epoch 1974/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7480e-04 - val_loss: 5.4886e-04\n",
      "Epoch 1975/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7454e-04 - val_loss: 5.4972e-04\n",
      "Epoch 1976/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7457e-04 - val_loss: 5.4851e-04\n",
      "Epoch 1977/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7449e-04 - val_loss: 5.4749e-04\n",
      "Epoch 1978/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7457e-04 - val_loss: 5.4787e-04\n",
      "Epoch 1979/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7452e-04 - val_loss: 5.5350e-04\n",
      "Epoch 1980/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7454e-04 - val_loss: 5.4984e-04\n",
      "Epoch 1981/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7450e-04 - val_loss: 5.4862e-04\n",
      "Epoch 1982/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7437e-04 - val_loss: 5.4778e-04\n",
      "Epoch 1983/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7451e-04 - val_loss: 5.5230e-04\n",
      "Epoch 1984/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7450e-04 - val_loss: 5.4796e-04\n",
      "Epoch 1985/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7444e-04 - val_loss: 5.5112e-04\n",
      "Epoch 1986/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7453e-04 - val_loss: 5.4811e-04\n",
      "Epoch 1987/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7436e-04 - val_loss: 5.4979e-04\n",
      "Epoch 1988/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7439e-04 - val_loss: 5.4915e-04\n",
      "Epoch 1989/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7445e-04 - val_loss: 5.4835e-04\n",
      "Epoch 1990/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7429e-04 - val_loss: 5.4971e-04\n",
      "Epoch 1991/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7431e-04 - val_loss: 5.5138e-04\n",
      "Epoch 1992/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7439e-04 - val_loss: 5.4841e-04\n",
      "Epoch 1993/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7440e-04 - val_loss: 5.4848e-04\n",
      "Epoch 1994/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7433e-04 - val_loss: 5.4626e-04\n",
      "Epoch 1995/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7419e-04 - val_loss: 5.4655e-04\n",
      "Epoch 1996/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7416e-04 - val_loss: 5.4750e-04\n",
      "Epoch 1997/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7426e-04 - val_loss: 5.5051e-04\n",
      "Epoch 1998/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7425e-04 - val_loss: 5.5390e-04\n",
      "Epoch 1999/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7420e-04 - val_loss: 5.4889e-04\n",
      "Epoch 2000/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7425e-04 - val_loss: 5.4815e-04\n",
      "Epoch 2001/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7422e-04 - val_loss: 5.5085e-04\n",
      "Epoch 2002/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7417e-04 - val_loss: 5.4904e-04\n",
      "Epoch 2003/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7408e-04 - val_loss: 5.4864e-04\n",
      "Epoch 2004/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7409e-04 - val_loss: 5.4952e-04\n",
      "Epoch 2005/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7420e-04 - val_loss: 5.4857e-04\n",
      "Epoch 2006/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7409e-04 - val_loss: 5.4979e-04\n",
      "Epoch 2007/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7413e-04 - val_loss: 5.5156e-04\n",
      "Epoch 2008/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7409e-04 - val_loss: 5.4903e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2009/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7401e-04 - val_loss: 5.4845e-04\n",
      "Epoch 2010/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7413e-04 - val_loss: 5.4752e-04\n",
      "Epoch 2011/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7404e-04 - val_loss: 5.4615e-04\n",
      "Epoch 2012/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7405e-04 - val_loss: 5.5017e-04\n",
      "Epoch 2013/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7405e-04 - val_loss: 5.4772e-04\n",
      "Epoch 2014/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7402e-04 - val_loss: 5.4737e-04\n",
      "Epoch 2015/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7390e-04 - val_loss: 5.4554e-04\n",
      "Epoch 2016/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7390e-04 - val_loss: 5.4978e-04\n",
      "Epoch 2017/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7397e-04 - val_loss: 5.4936e-04\n",
      "Epoch 2018/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7394e-04 - val_loss: 5.5084e-04\n",
      "Epoch 2019/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7392e-04 - val_loss: 5.4871e-04\n",
      "Epoch 2020/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7395e-04 - val_loss: 5.4799e-04\n",
      "Epoch 2021/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7391e-04 - val_loss: 5.4627e-04\n",
      "Epoch 2022/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7384e-04 - val_loss: 5.4956e-04\n",
      "Epoch 2023/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7392e-04 - val_loss: 5.5196e-04\n",
      "Epoch 2024/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7390e-04 - val_loss: 5.4796e-04\n",
      "Epoch 2025/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7376e-04 - val_loss: 5.4805e-04\n",
      "Epoch 2026/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7377e-04 - val_loss: 5.4752e-04\n",
      "Epoch 2027/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7379e-04 - val_loss: 5.4715e-04\n",
      "Epoch 2028/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7378e-04 - val_loss: 5.5171e-04\n",
      "Epoch 2029/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7385e-04 - val_loss: 5.5054e-04\n",
      "Epoch 2030/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7371e-04 - val_loss: 5.5084e-04\n",
      "Epoch 2031/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7378e-04 - val_loss: 5.4753e-04\n",
      "Epoch 2032/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7375e-04 - val_loss: 5.4776e-04\n",
      "Epoch 2033/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7378e-04 - val_loss: 5.4702e-04\n",
      "Epoch 2034/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7369e-04 - val_loss: 5.4652e-04\n",
      "Epoch 2035/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7369e-04 - val_loss: 5.4769e-04\n",
      "Epoch 2036/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7363e-04 - val_loss: 5.4969e-04\n",
      "Epoch 2037/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7372e-04 - val_loss: 5.5039e-04\n",
      "Epoch 2038/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7365e-04 - val_loss: 5.4900e-04\n",
      "Epoch 2039/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7360e-04 - val_loss: 5.4884e-04\n",
      "Epoch 2040/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7355e-04 - val_loss: 5.4934e-04\n",
      "Epoch 2041/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7363e-04 - val_loss: 5.5208e-04\n",
      "Epoch 2042/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7365e-04 - val_loss: 5.4819e-04\n",
      "Epoch 2043/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7358e-04 - val_loss: 5.5311e-04\n",
      "Epoch 2044/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7370e-04 - val_loss: 5.4836e-04\n",
      "Epoch 2045/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7363e-04 - val_loss: 5.4791e-04\n",
      "Epoch 2046/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7356e-04 - val_loss: 5.4894e-04\n",
      "Epoch 2047/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7359e-04 - val_loss: 5.4725e-04\n",
      "Epoch 2048/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7350e-04 - val_loss: 5.4874e-04\n",
      "Epoch 2049/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7343e-04 - val_loss: 5.4960e-04\n",
      "Epoch 2050/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7351e-04 - val_loss: 5.4707e-04\n",
      "Epoch 2051/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7349e-04 - val_loss: 5.4965e-04\n",
      "Epoch 2052/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7345e-04 - val_loss: 5.4931e-04\n",
      "Epoch 2053/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7348e-04 - val_loss: 5.4827e-04\n",
      "Epoch 2054/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7350e-04 - val_loss: 5.4631e-04\n",
      "Epoch 2055/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7349e-04 - val_loss: 5.4671e-04\n",
      "Epoch 2056/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7346e-04 - val_loss: 5.4719e-04\n",
      "Epoch 2057/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7332e-04 - val_loss: 5.4745e-04\n",
      "Epoch 2058/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7336e-04 - val_loss: 5.4883e-04\n",
      "Epoch 2059/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7337e-04 - val_loss: 5.4951e-04\n",
      "Epoch 2060/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7333e-04 - val_loss: 5.4889e-04\n",
      "Epoch 2061/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7339e-04 - val_loss: 5.4744e-04\n",
      "Epoch 2062/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7334e-04 - val_loss: 5.4980e-04\n",
      "Epoch 2063/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7333e-04 - val_loss: 5.4996e-04\n",
      "Epoch 2064/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7323e-04 - val_loss: 5.4849e-04\n",
      "Epoch 2065/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7321e-04 - val_loss: 5.4879e-04\n",
      "Epoch 2066/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7325e-04 - val_loss: 5.4878e-04\n",
      "Epoch 2067/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7327e-04 - val_loss: 5.4978e-04\n",
      "Epoch 2068/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7328e-04 - val_loss: 5.4775e-04\n",
      "Epoch 2069/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7323e-04 - val_loss: 5.5033e-04\n",
      "Epoch 2070/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7320e-04 - val_loss: 5.4966e-04\n",
      "Epoch 2071/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7320e-04 - val_loss: 5.4835e-04\n",
      "Epoch 2072/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7314e-04 - val_loss: 5.4961e-04\n",
      "Epoch 2073/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7318e-04 - val_loss: 5.4773e-04\n",
      "Epoch 2074/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7317e-04 - val_loss: 5.4946e-04\n",
      "Epoch 2075/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7308e-04 - val_loss: 5.4646e-04\n",
      "Epoch 2076/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7317e-04 - val_loss: 5.5049e-04\n",
      "Epoch 2077/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7320e-04 - val_loss: 5.4631e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2078/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7312e-04 - val_loss: 5.4817e-04\n",
      "Epoch 2079/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7306e-04 - val_loss: 5.4664e-04\n",
      "Epoch 2080/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7306e-04 - val_loss: 5.4762e-04\n",
      "Epoch 2081/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7308e-04 - val_loss: 5.5036e-04\n",
      "Epoch 2082/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7309e-04 - val_loss: 5.4789e-04\n",
      "Epoch 2083/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7303e-04 - val_loss: 5.5022e-04\n",
      "Epoch 2084/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7297e-04 - val_loss: 5.5023e-04\n",
      "Epoch 2085/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7306e-04 - val_loss: 5.4733e-04\n",
      "Epoch 2086/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7304e-04 - val_loss: 5.4859e-04\n",
      "Epoch 2087/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7302e-04 - val_loss: 5.4635e-04\n",
      "Epoch 2088/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7299e-04 - val_loss: 5.4923e-04\n",
      "Epoch 2089/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7290e-04 - val_loss: 5.4862e-04\n",
      "Epoch 2090/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7297e-04 - val_loss: 5.4557e-04\n",
      "Epoch 2091/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7300e-04 - val_loss: 5.4826e-04\n",
      "Epoch 2092/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7287e-04 - val_loss: 5.5047e-04\n",
      "Epoch 2093/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7294e-04 - val_loss: 5.5074e-04\n",
      "Epoch 2094/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7299e-04 - val_loss: 5.4720e-04\n",
      "Epoch 2095/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7286e-04 - val_loss: 5.4875e-04\n",
      "Epoch 2096/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7284e-04 - val_loss: 5.4509e-04\n",
      "Epoch 2097/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7287e-04 - val_loss: 5.4941e-04\n",
      "Epoch 2098/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7282e-04 - val_loss: 5.4936e-04\n",
      "Epoch 2099/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7274e-04 - val_loss: 5.4855e-04\n",
      "Epoch 2100/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7287e-04 - val_loss: 5.4757e-04\n",
      "Epoch 2101/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7269e-04 - val_loss: 5.4948e-04\n",
      "Epoch 2102/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7274e-04 - val_loss: 5.4882e-04\n",
      "Epoch 2103/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7286e-04 - val_loss: 5.4898e-04\n",
      "Epoch 2104/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7279e-04 - val_loss: 5.4564e-04\n",
      "Epoch 2105/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7284e-04 - val_loss: 5.4650e-04\n",
      "Epoch 2106/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7280e-04 - val_loss: 5.4719e-04\n",
      "Epoch 2107/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7275e-04 - val_loss: 5.4942e-04\n",
      "Epoch 2108/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7283e-04 - val_loss: 5.4666e-04\n",
      "Epoch 2109/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7272e-04 - val_loss: 5.4830e-04\n",
      "Epoch 2110/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7273e-04 - val_loss: 5.4911e-04\n",
      "Epoch 2111/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7268e-04 - val_loss: 5.4715e-04\n",
      "Epoch 2112/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7277e-04 - val_loss: 5.5000e-04\n",
      "Epoch 2113/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.7266e-04 - val_loss: 5.4901e-04\n",
      "Epoch 2114/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7273e-04 - val_loss: 5.4788e-04\n",
      "Epoch 2115/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7265e-04 - val_loss: 5.4931e-04\n",
      "Epoch 2116/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7274e-04 - val_loss: 5.4702e-04\n",
      "Epoch 2117/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7258e-04 - val_loss: 5.4663e-04\n",
      "Epoch 2118/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7269e-04 - val_loss: 5.4636e-04\n",
      "Epoch 2119/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7263e-04 - val_loss: 5.4897e-04\n",
      "Epoch 2120/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7255e-04 - val_loss: 5.4824e-04\n",
      "Epoch 2121/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7254e-04 - val_loss: 5.4857e-04\n",
      "Epoch 2122/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7260e-04 - val_loss: 5.4633e-04\n",
      "Epoch 2123/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7264e-04 - val_loss: 5.4637e-04\n",
      "Epoch 2124/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7250e-04 - val_loss: 5.4844e-04\n",
      "Epoch 2125/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7256e-04 - val_loss: 5.4794e-04\n",
      "Epoch 2126/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7253e-04 - val_loss: 5.4965e-04\n",
      "Epoch 2127/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7245e-04 - val_loss: 5.4677e-04\n",
      "Epoch 2128/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7253e-04 - val_loss: 5.4881e-04\n",
      "Epoch 2129/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7246e-04 - val_loss: 5.4930e-04\n",
      "Epoch 2130/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7249e-04 - val_loss: 5.4746e-04\n",
      "Epoch 2131/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7246e-04 - val_loss: 5.4839e-04\n",
      "Epoch 2132/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7245e-04 - val_loss: 5.4740e-04\n",
      "Epoch 2133/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7245e-04 - val_loss: 5.4630e-04\n",
      "Epoch 2134/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7243e-04 - val_loss: 5.4759e-04\n",
      "Epoch 2135/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7241e-04 - val_loss: 5.4624e-04\n",
      "Epoch 2136/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7238e-04 - val_loss: 5.4817e-04\n",
      "Epoch 2137/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7232e-04 - val_loss: 5.4713e-04\n",
      "Epoch 2138/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7224e-04 - val_loss: 5.4867e-04\n",
      "Epoch 2139/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7242e-04 - val_loss: 5.4832e-04\n",
      "Epoch 2140/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7234e-04 - val_loss: 5.4775e-04\n",
      "Epoch 2141/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7224e-04 - val_loss: 5.4698e-04\n",
      "Epoch 2142/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7242e-04 - val_loss: 5.4629e-04\n",
      "Epoch 2143/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7244e-04 - val_loss: 5.4750e-04\n",
      "Epoch 2144/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7235e-04 - val_loss: 5.4554e-04\n",
      "Epoch 2145/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7226e-04 - val_loss: 5.4757e-04\n",
      "Epoch 2146/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7223e-04 - val_loss: 5.4774e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2147/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7223e-04 - val_loss: 5.4809e-04\n",
      "Epoch 2148/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7214e-04 - val_loss: 5.4802e-04\n",
      "Epoch 2149/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7213e-04 - val_loss: 5.4975e-04\n",
      "Epoch 2150/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7218e-04 - val_loss: 5.4828e-04\n",
      "Epoch 2151/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7215e-04 - val_loss: 5.5008e-04\n",
      "Epoch 2152/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7217e-04 - val_loss: 5.4791e-04\n",
      "Epoch 2153/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7225e-04 - val_loss: 5.4589e-04\n",
      "Epoch 2154/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7227e-04 - val_loss: 5.4639e-04\n",
      "Epoch 2155/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7218e-04 - val_loss: 5.4570e-04\n",
      "Epoch 2156/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7229e-04 - val_loss: 5.4670e-04\n",
      "Epoch 2157/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7217e-04 - val_loss: 5.4636e-04\n",
      "Epoch 2158/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7212e-04 - val_loss: 5.4757e-04\n",
      "Epoch 2159/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7210e-04 - val_loss: 5.4788e-04\n",
      "Epoch 2160/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7210e-04 - val_loss: 5.4642e-04\n",
      "Epoch 2161/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7205e-04 - val_loss: 5.4758e-04\n",
      "Epoch 2162/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7203e-04 - val_loss: 5.4649e-04\n",
      "Epoch 2163/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7209e-04 - val_loss: 5.4907e-04\n",
      "Epoch 2164/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7201e-04 - val_loss: 5.4840e-04\n",
      "Epoch 2165/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7196e-04 - val_loss: 5.4771e-04\n",
      "Epoch 2166/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7199e-04 - val_loss: 5.4684e-04\n",
      "Epoch 2167/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7196e-04 - val_loss: 5.4538e-04\n",
      "Epoch 2168/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7210e-04 - val_loss: 5.4699e-04\n",
      "Epoch 2169/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.7194e-04 - val_loss: 5.4867e-04\n",
      "Epoch 2170/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7199e-04 - val_loss: 5.4712e-04\n",
      "Epoch 2171/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7194e-04 - val_loss: 5.4762e-04\n",
      "Epoch 2172/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7196e-04 - val_loss: 5.4800e-04\n",
      "Epoch 2173/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7183e-04 - val_loss: 5.4759e-04\n",
      "Epoch 2174/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7196e-04 - val_loss: 5.4536e-04\n",
      "Epoch 2175/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7192e-04 - val_loss: 5.4687e-04\n",
      "Epoch 2176/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7190e-04 - val_loss: 5.4807e-04\n",
      "Epoch 2177/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7190e-04 - val_loss: 5.4585e-04\n",
      "Epoch 2178/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7181e-04 - val_loss: 5.4752e-04\n",
      "Epoch 2179/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7179e-04 - val_loss: 5.4859e-04\n",
      "Epoch 2180/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7194e-04 - val_loss: 5.4601e-04\n",
      "Epoch 2181/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7199e-04 - val_loss: 5.4629e-04\n",
      "Epoch 2182/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7184e-04 - val_loss: 5.4763e-04\n",
      "Epoch 2183/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7195e-04 - val_loss: 5.4767e-04\n",
      "Epoch 2184/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7185e-04 - val_loss: 5.4631e-04\n",
      "Epoch 2185/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7185e-04 - val_loss: 5.4665e-04\n",
      "Epoch 2186/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7172e-04 - val_loss: 5.4739e-04\n",
      "Epoch 2187/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7176e-04 - val_loss: 5.4658e-04\n",
      "Epoch 2188/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7185e-04 - val_loss: 5.4519e-04\n",
      "Epoch 2189/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7177e-04 - val_loss: 5.4555e-04\n",
      "Epoch 2190/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7185e-04 - val_loss: 5.4542e-04\n",
      "Epoch 2191/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7169e-04 - val_loss: 5.4912e-04\n",
      "Epoch 2192/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7168e-04 - val_loss: 5.4932e-04\n",
      "Epoch 2193/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7167e-04 - val_loss: 5.4862e-04\n",
      "Epoch 2194/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7173e-04 - val_loss: 5.4689e-04\n",
      "Epoch 2195/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7172e-04 - val_loss: 5.4526e-04\n",
      "Epoch 2196/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7159e-04 - val_loss: 5.4696e-04\n",
      "Epoch 2197/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7177e-04 - val_loss: 5.4535e-04\n",
      "Epoch 2198/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7173e-04 - val_loss: 5.4552e-04\n",
      "Epoch 2199/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7163e-04 - val_loss: 5.4791e-04\n",
      "Epoch 2200/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7168e-04 - val_loss: 5.4676e-04\n",
      "Epoch 2201/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7158e-04 - val_loss: 5.4701e-04\n",
      "Epoch 2202/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7158e-04 - val_loss: 5.4711e-04\n",
      "Epoch 2203/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7161e-04 - val_loss: 5.4595e-04\n",
      "Epoch 2204/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7174e-04 - val_loss: 5.4448e-04\n",
      "Epoch 2205/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7158e-04 - val_loss: 5.4722e-04\n",
      "Epoch 2206/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7153e-04 - val_loss: 5.4797e-04\n",
      "Epoch 2207/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7161e-04 - val_loss: 5.4582e-04\n",
      "Epoch 2208/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7160e-04 - val_loss: 5.4571e-04\n",
      "Epoch 2209/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7160e-04 - val_loss: 5.4547e-04\n",
      "Epoch 2210/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7153e-04 - val_loss: 5.4963e-04\n",
      "Epoch 2211/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7156e-04 - val_loss: 5.4720e-04\n",
      "Epoch 2212/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7158e-04 - val_loss: 5.4831e-04\n",
      "Epoch 2213/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7145e-04 - val_loss: 5.4583e-04\n",
      "Epoch 2214/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7149e-04 - val_loss: 5.4862e-04\n",
      "Epoch 2215/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7154e-04 - val_loss: 5.4594e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2216/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7144e-04 - val_loss: 5.4524e-04\n",
      "Epoch 2217/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7146e-04 - val_loss: 5.4721e-04\n",
      "Epoch 2218/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7147e-04 - val_loss: 5.4657e-04\n",
      "Epoch 2219/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7144e-04 - val_loss: 5.4672e-04\n",
      "Epoch 2220/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7147e-04 - val_loss: 5.4636e-04\n",
      "Epoch 2221/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7149e-04 - val_loss: 5.4574e-04\n",
      "Epoch 2222/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7145e-04 - val_loss: 5.4528e-04\n",
      "Epoch 2223/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7141e-04 - val_loss: 5.4600e-04\n",
      "Epoch 2224/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7135e-04 - val_loss: 5.4609e-04\n",
      "Epoch 2225/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7123e-04 - val_loss: 5.4684e-04\n",
      "Epoch 2226/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7141e-04 - val_loss: 5.4549e-04\n",
      "Epoch 2227/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7139e-04 - val_loss: 5.4678e-04\n",
      "Epoch 2228/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7141e-04 - val_loss: 5.4770e-04\n",
      "Epoch 2229/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7139e-04 - val_loss: 5.4681e-04\n",
      "Epoch 2230/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7145e-04 - val_loss: 5.4530e-04\n",
      "Epoch 2231/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7128e-04 - val_loss: 5.4698e-04\n",
      "Epoch 2232/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7121e-04 - val_loss: 5.4789e-04\n",
      "Epoch 2233/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7128e-04 - val_loss: 5.4760e-04\n",
      "Epoch 2234/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7130e-04 - val_loss: 5.4559e-04\n",
      "Epoch 2235/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7143e-04 - val_loss: 5.4495e-04\n",
      "Epoch 2236/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7122e-04 - val_loss: 5.4785e-04\n",
      "Epoch 2237/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7124e-04 - val_loss: 5.4646e-04\n",
      "Epoch 2238/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7132e-04 - val_loss: 5.4537e-04\n",
      "Epoch 2239/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7130e-04 - val_loss: 5.4630e-04\n",
      "Epoch 2240/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7116e-04 - val_loss: 5.4647e-04\n",
      "Epoch 2241/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7121e-04 - val_loss: 5.4621e-04\n",
      "Epoch 2242/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7118e-04 - val_loss: 5.4652e-04\n",
      "Epoch 2243/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7123e-04 - val_loss: 5.4485e-04\n",
      "Epoch 2244/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7117e-04 - val_loss: 5.4658e-04\n",
      "Epoch 2245/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7110e-04 - val_loss: 5.4637e-04\n",
      "Epoch 2246/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7122e-04 - val_loss: 5.4466e-04\n",
      "Epoch 2247/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7113e-04 - val_loss: 5.4644e-04\n",
      "Epoch 2248/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7116e-04 - val_loss: 5.4502e-04\n",
      "Epoch 2249/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7114e-04 - val_loss: 5.4675e-04\n",
      "Epoch 2250/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7110e-04 - val_loss: 5.4631e-04\n",
      "Epoch 2251/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7103e-04 - val_loss: 5.4628e-04\n",
      "Epoch 2252/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7098e-04 - val_loss: 5.4664e-04\n",
      "Epoch 2253/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7114e-04 - val_loss: 5.4677e-04\n",
      "Epoch 2254/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7112e-04 - val_loss: 5.4727e-04\n",
      "Epoch 2255/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7109e-04 - val_loss: 5.4425e-04\n",
      "Epoch 2256/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7111e-04 - val_loss: 5.4599e-04\n",
      "Epoch 2257/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7104e-04 - val_loss: 5.4522e-04\n",
      "Epoch 2258/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7108e-04 - val_loss: 5.4776e-04\n",
      "Epoch 2259/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7106e-04 - val_loss: 5.4623e-04\n",
      "Epoch 2260/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7095e-04 - val_loss: 5.4714e-04\n",
      "Epoch 2261/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7103e-04 - val_loss: 5.4480e-04\n",
      "Epoch 2262/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7092e-04 - val_loss: 5.4757e-04\n",
      "Epoch 2263/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7096e-04 - val_loss: 5.4599e-04\n",
      "Epoch 2264/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7101e-04 - val_loss: 5.4561e-04\n",
      "Epoch 2265/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7088e-04 - val_loss: 5.4602e-04\n",
      "Epoch 2266/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7094e-04 - val_loss: 5.4650e-04\n",
      "Epoch 2267/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7093e-04 - val_loss: 5.4627e-04\n",
      "Epoch 2268/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7092e-04 - val_loss: 5.4631e-04\n",
      "Epoch 2269/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7090e-04 - val_loss: 5.4647e-04\n",
      "Epoch 2270/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7096e-04 - val_loss: 5.4508e-04\n",
      "Epoch 2271/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7090e-04 - val_loss: 5.4677e-04\n",
      "Epoch 2272/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7079e-04 - val_loss: 5.4799e-04\n",
      "Epoch 2273/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7103e-04 - val_loss: 5.4464e-04\n",
      "Epoch 2274/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7085e-04 - val_loss: 5.4674e-04\n",
      "Epoch 2275/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7092e-04 - val_loss: 5.4540e-04\n",
      "Epoch 2276/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7089e-04 - val_loss: 5.4698e-04\n",
      "Epoch 2277/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7075e-04 - val_loss: 5.4672e-04\n",
      "Epoch 2278/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7094e-04 - val_loss: 5.4521e-04\n",
      "Epoch 2279/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7074e-04 - val_loss: 5.4673e-04\n",
      "Epoch 2280/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7085e-04 - val_loss: 5.4516e-04\n",
      "Epoch 2281/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7080e-04 - val_loss: 5.4639e-04\n",
      "Epoch 2282/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.7086e-04 - val_loss: 5.4531e-04\n",
      "Epoch 2283/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7080e-04 - val_loss: 5.4760e-04\n",
      "Epoch 2284/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7088e-04 - val_loss: 5.4593e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2285/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7078e-04 - val_loss: 5.4522e-04\n",
      "Epoch 2286/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7083e-04 - val_loss: 5.4693e-04\n",
      "Epoch 2287/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7071e-04 - val_loss: 5.4541e-04\n",
      "Epoch 2288/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7066e-04 - val_loss: 5.4774e-04\n",
      "Epoch 2289/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7081e-04 - val_loss: 5.4505e-04\n",
      "Epoch 2290/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7071e-04 - val_loss: 5.4519e-04\n",
      "Epoch 2291/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7066e-04 - val_loss: 5.4661e-04\n",
      "Epoch 2292/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7072e-04 - val_loss: 5.4459e-04\n",
      "Epoch 2293/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7069e-04 - val_loss: 5.4611e-04\n",
      "Epoch 2294/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7066e-04 - val_loss: 5.4702e-04\n",
      "Epoch 2295/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7064e-04 - val_loss: 5.4680e-04\n",
      "Epoch 2296/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7076e-04 - val_loss: 5.4465e-04\n",
      "Epoch 2297/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7063e-04 - val_loss: 5.4704e-04\n",
      "Epoch 2298/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7064e-04 - val_loss: 5.4541e-04\n",
      "Epoch 2299/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7067e-04 - val_loss: 5.4684e-04\n",
      "Epoch 2300/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7055e-04 - val_loss: 5.4575e-04\n",
      "Epoch 2301/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7071e-04 - val_loss: 5.4433e-04\n",
      "Epoch 2302/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7060e-04 - val_loss: 5.4715e-04\n",
      "Epoch 2303/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7052e-04 - val_loss: 5.4540e-04\n",
      "Epoch 2304/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7056e-04 - val_loss: 5.4609e-04\n",
      "Epoch 2305/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7067e-04 - val_loss: 5.4426e-04\n",
      "Epoch 2306/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7051e-04 - val_loss: 5.4458e-04\n",
      "Epoch 2307/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7049e-04 - val_loss: 5.4707e-04\n",
      "Epoch 2308/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7051e-04 - val_loss: 5.4576e-04\n",
      "Epoch 2309/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7058e-04 - val_loss: 5.4496e-04\n",
      "Epoch 2310/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7050e-04 - val_loss: 5.4783e-04\n",
      "Epoch 2311/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7041e-04 - val_loss: 5.4707e-04\n",
      "Epoch 2312/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7058e-04 - val_loss: 5.4645e-04\n",
      "Epoch 2313/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7051e-04 - val_loss: 5.4593e-04\n",
      "Epoch 2314/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7048e-04 - val_loss: 5.4581e-04\n",
      "Epoch 2315/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7058e-04 - val_loss: 5.4428e-04\n",
      "Epoch 2316/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7054e-04 - val_loss: 5.4455e-04\n",
      "Epoch 2317/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7047e-04 - val_loss: 5.4562e-04\n",
      "Epoch 2318/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7042e-04 - val_loss: 5.4559e-04\n",
      "Epoch 2319/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7044e-04 - val_loss: 5.4580e-04\n",
      "Epoch 2320/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7042e-04 - val_loss: 5.4545e-04\n",
      "Epoch 2321/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7031e-04 - val_loss: 5.4743e-04\n",
      "Epoch 2322/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7044e-04 - val_loss: 5.4638e-04\n",
      "Epoch 2323/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7050e-04 - val_loss: 5.4445e-04\n",
      "Epoch 2324/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7030e-04 - val_loss: 5.4650e-04\n",
      "Epoch 2325/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7043e-04 - val_loss: 5.4476e-04\n",
      "Epoch 2326/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7036e-04 - val_loss: 5.4449e-04\n",
      "Epoch 2327/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7039e-04 - val_loss: 5.4529e-04\n",
      "Epoch 2328/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7036e-04 - val_loss: 5.4639e-04\n",
      "Epoch 2329/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7038e-04 - val_loss: 5.4623e-04\n",
      "Epoch 2330/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7046e-04 - val_loss: 5.4499e-04\n",
      "Epoch 2331/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7041e-04 - val_loss: 5.4684e-04\n",
      "Epoch 2332/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7042e-04 - val_loss: 5.4510e-04\n",
      "Epoch 2333/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7029e-04 - val_loss: 5.4473e-04\n",
      "Epoch 2334/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7043e-04 - val_loss: 5.4520e-04\n",
      "Epoch 2335/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7022e-04 - val_loss: 5.4594e-04\n",
      "Epoch 2336/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7030e-04 - val_loss: 5.4603e-04\n",
      "Epoch 2337/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7031e-04 - val_loss: 5.4585e-04\n",
      "Epoch 2338/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7019e-04 - val_loss: 5.4672e-04\n",
      "Epoch 2339/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7037e-04 - val_loss: 5.4430e-04\n",
      "Epoch 2340/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7021e-04 - val_loss: 5.4814e-04\n",
      "Epoch 2341/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7024e-04 - val_loss: 5.4467e-04\n",
      "Epoch 2342/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7032e-04 - val_loss: 5.4683e-04\n",
      "Epoch 2343/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7024e-04 - val_loss: 5.4466e-04\n",
      "Epoch 2344/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7025e-04 - val_loss: 5.4655e-04\n",
      "Epoch 2345/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7010e-04 - val_loss: 5.4595e-04\n",
      "Epoch 2346/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7011e-04 - val_loss: 5.4458e-04\n",
      "Epoch 2347/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7042e-04 - val_loss: 5.4560e-04\n",
      "Epoch 2348/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7013e-04 - val_loss: 5.4557e-04\n",
      "Epoch 2349/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7020e-04 - val_loss: 5.4509e-04\n",
      "Epoch 2350/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7028e-04 - val_loss: 5.4459e-04\n",
      "Epoch 2351/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7016e-04 - val_loss: 5.4587e-04\n",
      "Epoch 2352/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7019e-04 - val_loss: 5.4720e-04\n",
      "Epoch 2353/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7017e-04 - val_loss: 5.4525e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2354/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7031e-04 - val_loss: 5.4470e-04\n",
      "Epoch 2355/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7014e-04 - val_loss: 5.4569e-04\n",
      "Epoch 2356/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7012e-04 - val_loss: 5.4506e-04\n",
      "Epoch 2357/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7018e-04 - val_loss: 5.4485e-04\n",
      "Epoch 2358/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7011e-04 - val_loss: 5.4742e-04\n",
      "Epoch 2359/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7005e-04 - val_loss: 5.4627e-04\n",
      "Epoch 2360/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7014e-04 - val_loss: 5.4558e-04\n",
      "Epoch 2361/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7014e-04 - val_loss: 5.4782e-04\n",
      "Epoch 2362/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7001e-04 - val_loss: 5.4594e-04\n",
      "Epoch 2363/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7007e-04 - val_loss: 5.4461e-04\n",
      "Epoch 2364/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7013e-04 - val_loss: 5.4724e-04\n",
      "Epoch 2365/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7017e-04 - val_loss: 5.4467e-04\n",
      "Epoch 2366/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7007e-04 - val_loss: 5.4627e-04\n",
      "Epoch 2367/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6997e-04 - val_loss: 5.4515e-04\n",
      "Epoch 2368/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7010e-04 - val_loss: 5.4520e-04\n",
      "Epoch 2369/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7004e-04 - val_loss: 5.4601e-04\n",
      "Epoch 2370/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7004e-04 - val_loss: 5.4528e-04\n",
      "Epoch 2371/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7008e-04 - val_loss: 5.4609e-04\n",
      "Epoch 2372/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7005e-04 - val_loss: 5.4413e-04\n",
      "Epoch 2373/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6992e-04 - val_loss: 5.4506e-04\n",
      "Epoch 2374/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7004e-04 - val_loss: 5.4491e-04\n",
      "Epoch 2375/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6998e-04 - val_loss: 5.4622e-04\n",
      "Epoch 2376/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6992e-04 - val_loss: 5.4548e-04\n",
      "Epoch 2377/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6992e-04 - val_loss: 5.4595e-04\n",
      "Epoch 2378/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6988e-04 - val_loss: 5.4491e-04\n",
      "Epoch 2379/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6989e-04 - val_loss: 5.4543e-04\n",
      "Epoch 2380/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6984e-04 - val_loss: 5.4621e-04\n",
      "Epoch 2381/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6995e-04 - val_loss: 5.4416e-04\n",
      "Epoch 2382/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6987e-04 - val_loss: 5.4721e-04\n",
      "Epoch 2383/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6983e-04 - val_loss: 5.4543e-04\n",
      "Epoch 2384/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6999e-04 - val_loss: 5.4405e-04\n",
      "Epoch 2385/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6981e-04 - val_loss: 5.4538e-04\n",
      "Epoch 2386/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6985e-04 - val_loss: 5.4502e-04\n",
      "Epoch 2387/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6983e-04 - val_loss: 5.4494e-04\n",
      "Epoch 2388/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6989e-04 - val_loss: 5.4438e-04\n",
      "Epoch 2389/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6977e-04 - val_loss: 5.4763e-04\n",
      "Epoch 2390/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6979e-04 - val_loss: 5.4566e-04\n",
      "Epoch 2391/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6983e-04 - val_loss: 5.4583e-04\n",
      "Epoch 2392/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6978e-04 - val_loss: 5.4600e-04\n",
      "Epoch 2393/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6983e-04 - val_loss: 5.4735e-04\n",
      "Epoch 2394/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6991e-04 - val_loss: 5.4439e-04\n",
      "Epoch 2395/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 5.6985e-04 - val_loss: 5.4515e-04\n",
      "Epoch 2396/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6968e-04 - val_loss: 5.4616e-04\n",
      "Epoch 2397/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6977e-04 - val_loss: 5.4546e-04\n",
      "Epoch 2398/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6975e-04 - val_loss: 5.4476e-04\n",
      "Epoch 2399/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6976e-04 - val_loss: 5.4568e-04\n",
      "Epoch 2400/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6991e-04 - val_loss: 5.4481e-04\n",
      "Epoch 2401/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6970e-04 - val_loss: 5.4581e-04\n",
      "Epoch 2402/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6964e-04 - val_loss: 5.4420e-04\n",
      "Epoch 2403/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6967e-04 - val_loss: 5.4437e-04\n",
      "Epoch 2404/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6967e-04 - val_loss: 5.4619e-04\n",
      "Epoch 2405/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6965e-04 - val_loss: 5.4409e-04\n",
      "Epoch 2406/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6980e-04 - val_loss: 5.4369e-04\n",
      "Epoch 2407/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6971e-04 - val_loss: 5.4580e-04\n",
      "Epoch 2408/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6978e-04 - val_loss: 5.4466e-04\n",
      "Epoch 2409/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6968e-04 - val_loss: 5.4649e-04\n",
      "Epoch 2410/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6979e-04 - val_loss: 5.4501e-04\n",
      "Epoch 2411/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6961e-04 - val_loss: 5.4663e-04\n",
      "Epoch 2412/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6962e-04 - val_loss: 5.4372e-04\n",
      "Epoch 2413/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6957e-04 - val_loss: 5.4509e-04\n",
      "Epoch 2414/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6954e-04 - val_loss: 5.4530e-04\n",
      "Epoch 2415/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6975e-04 - val_loss: 5.4651e-04\n",
      "Epoch 2416/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6955e-04 - val_loss: 5.4606e-04\n",
      "Epoch 2417/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6958e-04 - val_loss: 5.4554e-04\n",
      "Epoch 2418/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6958e-04 - val_loss: 5.4350e-04\n",
      "Epoch 2419/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6955e-04 - val_loss: 5.4485e-04\n",
      "Epoch 2420/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6948e-04 - val_loss: 5.4672e-04\n",
      "Epoch 2421/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6963e-04 - val_loss: 5.4373e-04\n",
      "Epoch 2422/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6972e-04 - val_loss: 5.4481e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2423/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6949e-04 - val_loss: 5.4542e-04\n",
      "Epoch 2424/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6974e-04 - val_loss: 5.4470e-04\n",
      "Epoch 2425/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6952e-04 - val_loss: 5.4405e-04\n",
      "Epoch 2426/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6948e-04 - val_loss: 5.4523e-04\n",
      "Epoch 2427/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6951e-04 - val_loss: 5.4519e-04\n",
      "Epoch 2428/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6952e-04 - val_loss: 5.4753e-04\n",
      "Epoch 2429/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6950e-04 - val_loss: 5.4653e-04\n",
      "Epoch 2430/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6943e-04 - val_loss: 5.4526e-04\n",
      "Epoch 2431/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6941e-04 - val_loss: 5.4556e-04\n",
      "Epoch 2432/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6954e-04 - val_loss: 5.4368e-04\n",
      "Epoch 2433/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.6951e-04 - val_loss: 5.4446e-04\n",
      "Epoch 2434/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6942e-04 - val_loss: 5.4387e-04\n",
      "Epoch 2435/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6944e-04 - val_loss: 5.4448e-04\n",
      "Epoch 2436/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6943e-04 - val_loss: 5.4523e-04\n",
      "Epoch 2437/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6956e-04 - val_loss: 5.4504e-04\n",
      "Epoch 2438/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6942e-04 - val_loss: 5.4394e-04\n",
      "Epoch 2439/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6945e-04 - val_loss: 5.4363e-04\n",
      "Epoch 2440/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6964e-04 - val_loss: 5.4533e-04\n",
      "Epoch 2441/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6935e-04 - val_loss: 5.4626e-04\n",
      "Epoch 2442/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6936e-04 - val_loss: 5.4520e-04\n",
      "Epoch 2443/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6931e-04 - val_loss: 5.4565e-04\n",
      "Epoch 2444/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6930e-04 - val_loss: 5.4661e-04\n",
      "Epoch 2445/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6943e-04 - val_loss: 5.4534e-04\n",
      "Epoch 2446/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6943e-04 - val_loss: 5.4463e-04\n",
      "Epoch 2447/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6943e-04 - val_loss: 5.4487e-04\n",
      "Epoch 2448/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6933e-04 - val_loss: 5.4507e-04\n",
      "Epoch 2449/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6935e-04 - val_loss: 5.4616e-04\n",
      "Epoch 2450/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6923e-04 - val_loss: 5.4478e-04\n",
      "Epoch 2451/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6935e-04 - val_loss: 5.4531e-04\n",
      "Epoch 2452/10000\n",
      "45507/45507 [==============================] - 1s 21us/step - loss: 5.6927e-04 - val_loss: 5.4452e-04\n",
      "Epoch 2453/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6937e-04 - val_loss: 5.4357e-04\n",
      "Epoch 2454/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6928e-04 - val_loss: 5.4630e-04\n",
      "Epoch 2455/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6926e-04 - val_loss: 5.4602e-04\n",
      "Epoch 2456/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6921e-04 - val_loss: 5.4391e-04\n",
      "Epoch 2457/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6938e-04 - val_loss: 5.4500e-04\n",
      "Epoch 2458/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6920e-04 - val_loss: 5.4446e-04\n",
      "Epoch 2459/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6927e-04 - val_loss: 5.4517e-04\n",
      "Epoch 2460/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6936e-04 - val_loss: 5.4476e-04\n",
      "Epoch 2461/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6919e-04 - val_loss: 5.4494e-04\n",
      "Epoch 2462/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6921e-04 - val_loss: 5.4404e-04\n",
      "Epoch 2463/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6927e-04 - val_loss: 5.4353e-04\n",
      "Epoch 2464/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6919e-04 - val_loss: 5.4522e-04\n",
      "Epoch 2465/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6939e-04 - val_loss: 5.4457e-04\n",
      "Epoch 2466/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.6919e-04 - val_loss: 5.4543e-04\n",
      "Epoch 2467/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6912e-04 - val_loss: 5.4628e-04\n",
      "Epoch 2468/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6921e-04 - val_loss: 5.4400e-04\n",
      "Epoch 2469/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6919e-04 - val_loss: 5.4443e-04\n",
      "Epoch 2470/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6917e-04 - val_loss: 5.4555e-04\n",
      "Epoch 2471/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6905e-04 - val_loss: 5.4624e-04\n",
      "Epoch 2472/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6914e-04 - val_loss: 5.4365e-04\n",
      "Epoch 2473/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6918e-04 - val_loss: 5.4479e-04\n",
      "Epoch 2474/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6913e-04 - val_loss: 5.4473e-04\n",
      "Epoch 2475/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6917e-04 - val_loss: 5.4356e-04\n",
      "Epoch 2476/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6909e-04 - val_loss: 5.4424e-04\n",
      "Epoch 2477/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6914e-04 - val_loss: 5.4553e-04\n",
      "Epoch 2478/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6908e-04 - val_loss: 5.4480e-04\n",
      "Epoch 2479/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6921e-04 - val_loss: 5.4376e-04\n",
      "Epoch 2480/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6904e-04 - val_loss: 5.4492e-04\n",
      "Epoch 2481/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6916e-04 - val_loss: 5.4303e-04\n",
      "Epoch 2482/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6906e-04 - val_loss: 5.4364e-04\n",
      "Epoch 2483/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6900e-04 - val_loss: 5.4381e-04\n",
      "Epoch 2484/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6908e-04 - val_loss: 5.4418e-04\n",
      "Epoch 2485/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6911e-04 - val_loss: 5.4385e-04\n",
      "Epoch 2486/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6917e-04 - val_loss: 5.4465e-04\n",
      "Epoch 2487/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6916e-04 - val_loss: 5.4475e-04\n",
      "Epoch 2488/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6903e-04 - val_loss: 5.4419e-04\n",
      "Epoch 2489/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6908e-04 - val_loss: 5.4417e-04\n",
      "Epoch 2490/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6910e-04 - val_loss: 5.4419e-04\n",
      "Epoch 2491/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6899e-04 - val_loss: 5.4529e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2492/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6891e-04 - val_loss: 5.4474e-04\n",
      "Epoch 2493/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6890e-04 - val_loss: 5.4463e-04\n",
      "Epoch 2494/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6898e-04 - val_loss: 5.4669e-04\n",
      "Epoch 2495/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6896e-04 - val_loss: 5.4571e-04\n",
      "Epoch 2496/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6896e-04 - val_loss: 5.4418e-04\n",
      "Epoch 2497/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6909e-04 - val_loss: 5.4348e-04\n",
      "Epoch 2498/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6893e-04 - val_loss: 5.4485e-04\n",
      "Epoch 2499/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6898e-04 - val_loss: 5.4306e-04\n",
      "Epoch 2500/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6909e-04 - val_loss: 5.4554e-04\n",
      "Epoch 2501/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6894e-04 - val_loss: 5.4571e-04\n",
      "Epoch 2502/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6893e-04 - val_loss: 5.4360e-04\n",
      "Epoch 2503/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6893e-04 - val_loss: 5.4524e-04\n",
      "Epoch 2504/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6906e-04 - val_loss: 5.4404e-04\n",
      "Epoch 2505/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6895e-04 - val_loss: 5.4582e-04\n",
      "Epoch 2506/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6884e-04 - val_loss: 5.4439e-04\n",
      "Epoch 2507/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6884e-04 - val_loss: 5.4591e-04\n",
      "Epoch 2508/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6884e-04 - val_loss: 5.4491e-04\n",
      "Epoch 2509/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6884e-04 - val_loss: 5.4648e-04\n",
      "Epoch 2510/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6889e-04 - val_loss: 5.4483e-04\n",
      "Epoch 2511/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6890e-04 - val_loss: 5.4398e-04\n",
      "Epoch 2512/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6879e-04 - val_loss: 5.4333e-04\n",
      "Epoch 2513/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6897e-04 - val_loss: 5.4408e-04\n",
      "Epoch 2514/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6891e-04 - val_loss: 5.4490e-04\n",
      "Epoch 2515/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6891e-04 - val_loss: 5.4379e-04\n",
      "Epoch 2516/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6882e-04 - val_loss: 5.4351e-04\n",
      "Epoch 2517/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6880e-04 - val_loss: 5.4327e-04\n",
      "Epoch 2518/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6885e-04 - val_loss: 5.4488e-04\n",
      "Epoch 2519/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6881e-04 - val_loss: 5.4529e-04\n",
      "Epoch 2520/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6880e-04 - val_loss: 5.4524e-04\n",
      "Epoch 2521/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6892e-04 - val_loss: 5.4442e-04\n",
      "Epoch 2522/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6883e-04 - val_loss: 5.4485e-04\n",
      "Epoch 2523/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6883e-04 - val_loss: 5.4373e-04\n",
      "Epoch 2524/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6875e-04 - val_loss: 5.4454e-04\n",
      "Epoch 2525/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6873e-04 - val_loss: 5.4337e-04\n",
      "Epoch 2526/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6877e-04 - val_loss: 5.4215e-04\n",
      "Epoch 2527/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6862e-04 - val_loss: 5.4389e-04\n",
      "Epoch 2528/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6866e-04 - val_loss: 5.4623e-04\n",
      "Epoch 2529/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6882e-04 - val_loss: 5.4447e-04\n",
      "Epoch 2530/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6868e-04 - val_loss: 5.4523e-04\n",
      "Epoch 2531/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6867e-04 - val_loss: 5.4464e-04\n",
      "Epoch 2532/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6877e-04 - val_loss: 5.4184e-04\n",
      "Epoch 2533/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6862e-04 - val_loss: 5.4454e-04\n",
      "Epoch 2534/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6869e-04 - val_loss: 5.4321e-04\n",
      "Epoch 2535/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6873e-04 - val_loss: 5.4384e-04\n",
      "Epoch 2536/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6877e-04 - val_loss: 5.4395e-04\n",
      "Epoch 2537/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6862e-04 - val_loss: 5.4505e-04\n",
      "Epoch 2538/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6872e-04 - val_loss: 5.4464e-04\n",
      "Epoch 2539/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6854e-04 - val_loss: 5.4523e-04\n",
      "Epoch 2540/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6874e-04 - val_loss: 5.4525e-04\n",
      "Epoch 2541/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6870e-04 - val_loss: 5.4379e-04\n",
      "Epoch 2542/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6867e-04 - val_loss: 5.4384e-04\n",
      "Epoch 2543/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6868e-04 - val_loss: 5.4372e-04\n",
      "Epoch 2544/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6860e-04 - val_loss: 5.4369e-04\n",
      "Epoch 2545/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6866e-04 - val_loss: 5.4380e-04\n",
      "Epoch 2546/10000\n",
      "45507/45507 [==============================] - 1s 23us/step - loss: 5.6851e-04 - val_loss: 5.4283e-04\n",
      "Epoch 2547/10000\n",
      "45507/45507 [==============================] - ETA: 0s - loss: 5.7222e-0 - 1s 25us/step - loss: 5.6860e-04 - val_loss: 5.4359e-04\n",
      "Epoch 2548/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6869e-04 - val_loss: 5.4408e-04\n",
      "Epoch 2549/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6869e-04 - val_loss: 5.4489e-04\n",
      "Epoch 2550/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6868e-04 - val_loss: 5.4480e-04\n",
      "Epoch 2551/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6863e-04 - val_loss: 5.4431e-04\n",
      "Epoch 2552/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6854e-04 - val_loss: 5.4322e-04\n",
      "Epoch 2553/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6853e-04 - val_loss: 5.4214e-04\n",
      "Epoch 2554/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6865e-04 - val_loss: 5.4346e-04\n",
      "Epoch 2555/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6860e-04 - val_loss: 5.4359e-04\n",
      "Epoch 2556/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6859e-04 - val_loss: 5.4350e-04\n",
      "Epoch 2557/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6845e-04 - val_loss: 5.4320e-04\n",
      "Epoch 2558/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6859e-04 - val_loss: 5.4514e-04\n",
      "Epoch 2559/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6851e-04 - val_loss: 5.4593e-04\n",
      "Epoch 2560/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6856e-04 - val_loss: 5.4503e-04\n",
      "Epoch 2561/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6856e-04 - val_loss: 5.4469e-04\n",
      "Epoch 2562/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6852e-04 - val_loss: 5.4371e-04\n",
      "Epoch 2563/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6857e-04 - val_loss: 5.4361e-04\n",
      "Epoch 2564/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6850e-04 - val_loss: 5.4410e-04\n",
      "Epoch 2565/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6848e-04 - val_loss: 5.4388e-04\n",
      "Epoch 2566/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6845e-04 - val_loss: 5.4242e-04\n",
      "Epoch 2567/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6845e-04 - val_loss: 5.4270e-04\n",
      "Epoch 2568/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6847e-04 - val_loss: 5.4283e-04\n",
      "Epoch 2569/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6848e-04 - val_loss: 5.4378e-04\n",
      "Epoch 2570/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6838e-04 - val_loss: 5.4479e-04\n",
      "Epoch 2571/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6848e-04 - val_loss: 5.4413e-04\n",
      "Epoch 2572/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6848e-04 - val_loss: 5.4363e-04\n",
      "Epoch 2573/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6837e-04 - val_loss: 5.4485e-04\n",
      "Epoch 2574/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6836e-04 - val_loss: 5.4294e-04\n",
      "Epoch 2575/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6841e-04 - val_loss: 5.4270e-04\n",
      "Epoch 2576/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6836e-04 - val_loss: 5.4382e-04\n",
      "Epoch 2577/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6843e-04 - val_loss: 5.4232e-04\n",
      "Epoch 2578/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6839e-04 - val_loss: 5.4160e-04\n",
      "Epoch 2579/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6846e-04 - val_loss: 5.4430e-04\n",
      "Epoch 2580/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6841e-04 - val_loss: 5.4474e-04\n",
      "Epoch 2581/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6835e-04 - val_loss: 5.4434e-04\n",
      "Epoch 2582/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6835e-04 - val_loss: 5.4296e-04\n",
      "Epoch 2583/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6836e-04 - val_loss: 5.4320e-04\n",
      "Epoch 2584/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6827e-04 - val_loss: 5.4352e-04\n",
      "Epoch 2585/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6824e-04 - val_loss: 5.4280e-04\n",
      "Epoch 2586/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6837e-04 - val_loss: 5.4485e-04\n",
      "Epoch 2587/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6838e-04 - val_loss: 5.4448e-04\n",
      "Epoch 2588/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6832e-04 - val_loss: 5.4492e-04\n",
      "Epoch 2589/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6827e-04 - val_loss: 5.4432e-04\n",
      "Epoch 2590/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6833e-04 - val_loss: 5.4337e-04\n",
      "Epoch 2591/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6834e-04 - val_loss: 5.4327e-04\n",
      "Epoch 2592/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6822e-04 - val_loss: 5.4363e-04\n",
      "Epoch 2593/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6844e-04 - val_loss: 5.4360e-04\n",
      "Epoch 2594/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6831e-04 - val_loss: 5.4282e-04\n",
      "Epoch 2595/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6828e-04 - val_loss: 5.4386e-04\n",
      "Epoch 2596/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6817e-04 - val_loss: 5.4460e-04\n",
      "Epoch 2597/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6827e-04 - val_loss: 5.4257e-04\n",
      "Epoch 2598/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6831e-04 - val_loss: 5.4428e-04\n",
      "Epoch 2599/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6822e-04 - val_loss: 5.4404e-04\n",
      "Epoch 2600/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6825e-04 - val_loss: 5.4347e-04\n",
      "Epoch 2601/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6821e-04 - val_loss: 5.4451e-04\n",
      "Epoch 2602/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6824e-04 - val_loss: 5.4468e-04\n",
      "Epoch 2603/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6826e-04 - val_loss: 5.4450e-04\n",
      "Epoch 2604/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6823e-04 - val_loss: 5.4460e-04\n",
      "Epoch 2605/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6824e-04 - val_loss: 5.4344e-04\n",
      "Epoch 2606/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6827e-04 - val_loss: 5.4264e-04\n",
      "Epoch 2607/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6823e-04 - val_loss: 5.4397e-04\n",
      "Epoch 2608/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6822e-04 - val_loss: 5.4383e-04\n",
      "Epoch 2609/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6807e-04 - val_loss: 5.4480e-04\n",
      "Epoch 2610/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6818e-04 - val_loss: 5.4348e-04\n",
      "Epoch 2611/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6819e-04 - val_loss: 5.4602e-04\n",
      "Epoch 2612/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6813e-04 - val_loss: 5.4444e-04\n",
      "Epoch 2613/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6817e-04 - val_loss: 5.4307e-04\n",
      "Epoch 2614/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6818e-04 - val_loss: 5.4396e-04\n",
      "Epoch 2615/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6821e-04 - val_loss: 5.4462e-04\n",
      "Epoch 2616/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6803e-04 - val_loss: 5.4373e-04\n",
      "Epoch 2617/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6811e-04 - val_loss: 5.4315e-04\n",
      "Epoch 2618/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6807e-04 - val_loss: 5.4437e-04\n",
      "Epoch 2619/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6804e-04 - val_loss: 5.4707e-04\n",
      "Epoch 2620/10000\n",
      "45507/45507 [==============================] - ETA: 0s - loss: 5.4205e-0 - 1s 32us/step - loss: 5.6814e-04 - val_loss: 5.4424e-04\n",
      "Epoch 2621/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 5.6824e-04 - val_loss: 5.4338e-04\n",
      "Epoch 2622/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6809e-04 - val_loss: 5.4390e-04\n",
      "Epoch 2623/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6825e-04 - val_loss: 5.4449e-04\n",
      "Epoch 2624/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6812e-04 - val_loss: 5.4516e-04\n",
      "Epoch 2625/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6809e-04 - val_loss: 5.4184e-04\n",
      "Epoch 2626/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6801e-04 - val_loss: 5.4215e-04\n",
      "Epoch 2627/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6797e-04 - val_loss: 5.4381e-04\n",
      "Epoch 2628/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6809e-04 - val_loss: 5.4402e-04\n",
      "Epoch 2629/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6809e-04 - val_loss: 5.4300e-04\n",
      "Epoch 2630/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6801e-04 - val_loss: 5.4325e-04\n",
      "Epoch 2631/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6801e-04 - val_loss: 5.4286e-04\n",
      "Epoch 2632/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6808e-04 - val_loss: 5.4438e-04\n",
      "Epoch 2633/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6804e-04 - val_loss: 5.4294e-04\n",
      "Epoch 2634/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6803e-04 - val_loss: 5.4487e-04\n",
      "Epoch 2635/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6810e-04 - val_loss: 5.4342e-04\n",
      "Epoch 2636/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6798e-04 - val_loss: 5.4482e-04\n",
      "Epoch 2637/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6798e-04 - val_loss: 5.4236e-04\n",
      "Epoch 2638/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.6795e-04 - val_loss: 5.4255e-04\n",
      "Epoch 2639/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6799e-04 - val_loss: 5.4299e-04\n",
      "Epoch 2640/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6791e-04 - val_loss: 5.4336e-04\n",
      "Epoch 2641/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6784e-04 - val_loss: 5.4202e-04\n",
      "Epoch 2642/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6796e-04 - val_loss: 5.4325e-04\n",
      "Epoch 2643/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6789e-04 - val_loss: 5.4198e-04\n",
      "Epoch 2644/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6805e-04 - val_loss: 5.4498e-04\n",
      "Epoch 2645/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6787e-04 - val_loss: 5.4376e-04\n",
      "Epoch 2646/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6793e-04 - val_loss: 5.4313e-04\n",
      "Epoch 2647/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6795e-04 - val_loss: 5.4357e-04\n",
      "Epoch 2648/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6792e-04 - val_loss: 5.4321e-04\n",
      "Epoch 2649/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6794e-04 - val_loss: 5.4324e-04\n",
      "Epoch 2650/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6797e-04 - val_loss: 5.4366e-04\n",
      "Epoch 2651/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6791e-04 - val_loss: 5.4461e-04\n",
      "Epoch 2652/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6787e-04 - val_loss: 5.4315e-04\n",
      "Epoch 2653/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6794e-04 - val_loss: 5.4295e-04\n",
      "Epoch 2654/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6783e-04 - val_loss: 5.4247e-04\n",
      "Epoch 2655/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6792e-04 - val_loss: 5.4257e-04\n",
      "Epoch 2656/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6787e-04 - val_loss: 5.4421e-04\n",
      "Epoch 2657/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6781e-04 - val_loss: 5.4396e-04\n",
      "Epoch 2658/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6784e-04 - val_loss: 5.4511e-04\n",
      "Epoch 2659/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6782e-04 - val_loss: 5.4294e-04\n",
      "Epoch 2660/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6785e-04 - val_loss: 5.4194e-04\n",
      "Epoch 2661/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6799e-04 - val_loss: 5.4373e-04\n",
      "Epoch 2662/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6787e-04 - val_loss: 5.4292e-04\n",
      "Epoch 2663/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6781e-04 - val_loss: 5.4357e-04\n",
      "Epoch 2664/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6789e-04 - val_loss: 5.4243e-04\n",
      "Epoch 2665/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6786e-04 - val_loss: 5.4464e-04\n",
      "Epoch 2666/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6784e-04 - val_loss: 5.4332e-04\n",
      "Epoch 2667/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6782e-04 - val_loss: 5.4343e-04\n",
      "Epoch 2668/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6779e-04 - val_loss: 5.4298e-04\n",
      "Epoch 2669/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6776e-04 - val_loss: 5.4359e-04\n",
      "Epoch 2670/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6778e-04 - val_loss: 5.4402e-04\n",
      "Epoch 2671/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6776e-04 - val_loss: 5.4322e-04\n",
      "Epoch 2672/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6778e-04 - val_loss: 5.4345e-04\n",
      "Epoch 2673/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6774e-04 - val_loss: 5.4283e-04\n",
      "Epoch 2674/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6773e-04 - val_loss: 5.4339e-04\n",
      "Epoch 2675/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6770e-04 - val_loss: 5.4260e-04\n",
      "Epoch 2676/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6773e-04 - val_loss: 5.4300e-04\n",
      "Epoch 2677/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6773e-04 - val_loss: 5.4302e-04\n",
      "Epoch 2678/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6771e-04 - val_loss: 5.4391e-04\n",
      "Epoch 2679/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6770e-04 - val_loss: 5.4322e-04\n",
      "Epoch 2680/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6767e-04 - val_loss: 5.4147e-04\n",
      "Epoch 2681/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6768e-04 - val_loss: 5.4325e-04\n",
      "Epoch 2682/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6778e-04 - val_loss: 5.4347e-04\n",
      "Epoch 2683/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6769e-04 - val_loss: 5.4099e-04\n",
      "Epoch 2684/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6769e-04 - val_loss: 5.4260e-04\n",
      "Epoch 2685/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6764e-04 - val_loss: 5.4284e-04\n",
      "Epoch 2686/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6758e-04 - val_loss: 5.4409e-04\n",
      "Epoch 2687/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6764e-04 - val_loss: 5.4283e-04\n",
      "Epoch 2688/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6777e-04 - val_loss: 5.4517e-04\n",
      "Epoch 2689/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6767e-04 - val_loss: 5.4346e-04\n",
      "Epoch 2690/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6770e-04 - val_loss: 5.4408e-04\n",
      "Epoch 2691/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6761e-04 - val_loss: 5.4453e-04\n",
      "Epoch 2692/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6758e-04 - val_loss: 5.4360e-04\n",
      "Epoch 2693/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6767e-04 - val_loss: 5.4287e-04\n",
      "Epoch 2694/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6772e-04 - val_loss: 5.4236e-04\n",
      "Epoch 2695/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6759e-04 - val_loss: 5.4341e-04\n",
      "Epoch 2696/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6755e-04 - val_loss: 5.4486e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2697/10000\n",
      "45507/45507 [==============================] - 1s 22us/step - loss: 5.6750e-04 - val_loss: 5.4286e-04\n",
      "Epoch 2698/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 5.6752e-04 - val_loss: 5.4308e-04\n",
      "Epoch 2699/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6757e-04 - val_loss: 5.4363e-04\n",
      "Epoch 2700/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6761e-04 - val_loss: 5.4287e-04\n",
      "Epoch 2701/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6759e-04 - val_loss: 5.4262e-04\n",
      "Epoch 2702/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6753e-04 - val_loss: 5.4165e-04\n",
      "Epoch 2703/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6770e-04 - val_loss: 5.4230e-04\n",
      "Epoch 2704/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6753e-04 - val_loss: 5.4219e-04\n",
      "Epoch 2705/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6761e-04 - val_loss: 5.4174e-04\n",
      "Epoch 2706/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6753e-04 - val_loss: 5.4279e-04\n",
      "Epoch 2707/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6745e-04 - val_loss: 5.4111e-04\n",
      "Epoch 2708/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6760e-04 - val_loss: 5.4298e-04\n",
      "Epoch 2709/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6743e-04 - val_loss: 5.4287e-04\n",
      "Epoch 2710/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6752e-04 - val_loss: 5.4352e-04\n",
      "Epoch 2711/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6755e-04 - val_loss: 5.4306e-04\n",
      "Epoch 2712/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6751e-04 - val_loss: 5.4516e-04\n",
      "Epoch 2713/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6750e-04 - val_loss: 5.4257e-04\n",
      "Epoch 2714/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6752e-04 - val_loss: 5.4448e-04\n",
      "Epoch 2715/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6758e-04 - val_loss: 5.4230e-04\n",
      "Epoch 2716/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6741e-04 - val_loss: 5.4308e-04\n",
      "Epoch 2717/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6756e-04 - val_loss: 5.4330e-04\n",
      "Epoch 2718/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6749e-04 - val_loss: 5.4271e-04\n",
      "Epoch 2719/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6743e-04 - val_loss: 5.4256e-04\n",
      "Epoch 2720/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6747e-04 - val_loss: 5.4521e-04\n",
      "Epoch 2721/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6743e-04 - val_loss: 5.4395e-04\n",
      "Epoch 2722/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6749e-04 - val_loss: 5.4173e-04\n",
      "Epoch 2723/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6741e-04 - val_loss: 5.4362e-04\n",
      "Epoch 2724/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6741e-04 - val_loss: 5.4332e-04\n",
      "Epoch 2725/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6742e-04 - val_loss: 5.4117e-04\n",
      "Epoch 2726/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6742e-04 - val_loss: 5.4352e-04\n",
      "Epoch 2727/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6747e-04 - val_loss: 5.4452e-04\n",
      "Epoch 2728/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6738e-04 - val_loss: 5.4150e-04\n",
      "Epoch 2729/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6738e-04 - val_loss: 5.4265e-04\n",
      "Epoch 2730/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6741e-04 - val_loss: 5.4168e-04\n",
      "Epoch 2731/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6746e-04 - val_loss: 5.4324e-04\n",
      "Epoch 2732/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6735e-04 - val_loss: 5.4185e-04\n",
      "Epoch 2733/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6729e-04 - val_loss: 5.4408e-04\n",
      "Epoch 2734/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6747e-04 - val_loss: 5.4250e-04\n",
      "Epoch 2735/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6736e-04 - val_loss: 5.4490e-04\n",
      "Epoch 2736/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6742e-04 - val_loss: 5.4385e-04\n",
      "Epoch 2737/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6736e-04 - val_loss: 5.4157e-04\n",
      "Epoch 2738/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6735e-04 - val_loss: 5.4277e-04\n",
      "Epoch 2739/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6741e-04 - val_loss: 5.4189e-04\n",
      "Epoch 2740/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6736e-04 - val_loss: 5.4366e-04\n",
      "Epoch 2741/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6737e-04 - val_loss: 5.4311e-04\n",
      "Epoch 2742/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6734e-04 - val_loss: 5.4301e-04\n",
      "Epoch 2743/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6729e-04 - val_loss: 5.4386e-04\n",
      "Epoch 2744/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6732e-04 - val_loss: 5.4189e-04\n",
      "Epoch 2745/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6741e-04 - val_loss: 5.4252e-04\n",
      "Epoch 2746/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6729e-04 - val_loss: 5.4253e-04\n",
      "Epoch 2747/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6719e-04 - val_loss: 5.4389e-04\n",
      "Epoch 2748/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6719e-04 - val_loss: 5.4330e-04\n",
      "Epoch 2749/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6730e-04 - val_loss: 5.4360e-04\n",
      "Epoch 2750/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6721e-04 - val_loss: 5.4342e-04\n",
      "Epoch 2751/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6732e-04 - val_loss: 5.4510e-04\n",
      "Epoch 2752/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6730e-04 - val_loss: 5.4364e-04\n",
      "Epoch 2753/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6719e-04 - val_loss: 5.4516e-04\n",
      "Epoch 2754/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6719e-04 - val_loss: 5.4349e-04\n",
      "Epoch 2755/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6729e-04 - val_loss: 5.4311e-04\n",
      "Epoch 2756/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6726e-04 - val_loss: 5.4304e-04\n",
      "Epoch 2757/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6729e-04 - val_loss: 5.4503e-04\n",
      "Epoch 2758/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6728e-04 - val_loss: 5.4410e-04\n",
      "Epoch 2759/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6724e-04 - val_loss: 5.4233e-04\n",
      "Epoch 2760/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6717e-04 - val_loss: 5.4254e-04\n",
      "Epoch 2761/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6722e-04 - val_loss: 5.4311e-04\n",
      "Epoch 2762/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6722e-04 - val_loss: 5.4348e-04\n",
      "Epoch 2763/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6722e-04 - val_loss: 5.4173e-04\n",
      "Epoch 2764/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6711e-04 - val_loss: 5.4341e-04\n",
      "Epoch 2765/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6709e-04 - val_loss: 5.4214e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2766/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6723e-04 - val_loss: 5.4240e-04\n",
      "Epoch 2767/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6716e-04 - val_loss: 5.4279e-04\n",
      "Epoch 2768/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6720e-04 - val_loss: 5.4186e-04\n",
      "Epoch 2769/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6720e-04 - val_loss: 5.4369e-04\n",
      "Epoch 2770/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6713e-04 - val_loss: 5.4326e-04\n",
      "Epoch 2771/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6718e-04 - val_loss: 5.4050e-04\n",
      "Epoch 2772/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6720e-04 - val_loss: 5.4443e-04\n",
      "Epoch 2773/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6719e-04 - val_loss: 5.4095e-04\n",
      "Epoch 2774/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6706e-04 - val_loss: 5.4048e-04\n",
      "Epoch 2775/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6707e-04 - val_loss: 5.4305e-04\n",
      "Epoch 2776/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6713e-04 - val_loss: 5.4206e-04\n",
      "Epoch 2777/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6702e-04 - val_loss: 5.4101e-04\n",
      "Epoch 2778/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6706e-04 - val_loss: 5.4142e-04\n",
      "Epoch 2779/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6716e-04 - val_loss: 5.4323e-04\n",
      "Epoch 2780/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6706e-04 - val_loss: 5.4122e-04\n",
      "Epoch 2781/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6705e-04 - val_loss: 5.4426e-04\n",
      "Epoch 2782/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6704e-04 - val_loss: 5.4325e-04\n",
      "Epoch 2783/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6704e-04 - val_loss: 5.4326e-04\n",
      "Epoch 2784/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6702e-04 - val_loss: 5.4305e-04\n",
      "Epoch 2785/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6695e-04 - val_loss: 5.4371e-04\n",
      "Epoch 2786/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6698e-04 - val_loss: 5.4364e-04\n",
      "Epoch 2787/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6716e-04 - val_loss: 5.4107e-04\n",
      "Epoch 2788/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6703e-04 - val_loss: 5.4216e-04\n",
      "Epoch 2789/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6693e-04 - val_loss: 5.4212e-04\n",
      "Epoch 2790/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6700e-04 - val_loss: 5.4182e-04\n",
      "Epoch 2791/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6711e-04 - val_loss: 5.4249e-04\n",
      "Epoch 2792/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6696e-04 - val_loss: 5.4158e-04\n",
      "Epoch 2793/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6703e-04 - val_loss: 5.4318e-04\n",
      "Epoch 2794/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6700e-04 - val_loss: 5.4278e-04\n",
      "Epoch 2795/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6697e-04 - val_loss: 5.4299e-04\n",
      "Epoch 2796/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6696e-04 - val_loss: 5.4216e-04\n",
      "Epoch 2797/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6696e-04 - val_loss: 5.4388e-04\n",
      "Epoch 2798/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6701e-04 - val_loss: 5.4253e-04\n",
      "Epoch 2799/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6691e-04 - val_loss: 5.4361e-04\n",
      "Epoch 2800/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6690e-04 - val_loss: 5.4349e-04\n",
      "Epoch 2801/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6699e-04 - val_loss: 5.4210e-04\n",
      "Epoch 2802/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6713e-04 - val_loss: 5.4160e-04\n",
      "Epoch 2803/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6693e-04 - val_loss: 5.4367e-04\n",
      "Epoch 2804/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6692e-04 - val_loss: 5.4173e-04\n",
      "Epoch 2805/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6701e-04 - val_loss: 5.4066e-04\n",
      "Epoch 2806/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6688e-04 - val_loss: 5.4397e-04\n",
      "Epoch 2807/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6691e-04 - val_loss: 5.4301e-04\n",
      "Epoch 2808/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6687e-04 - val_loss: 5.4240e-04\n",
      "Epoch 2809/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6691e-04 - val_loss: 5.4131e-04\n",
      "Epoch 2810/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6699e-04 - val_loss: 5.4537e-04\n",
      "Epoch 2811/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6694e-04 - val_loss: 5.4134e-04\n",
      "Epoch 2812/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6688e-04 - val_loss: 5.4238e-04\n",
      "Epoch 2813/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6686e-04 - val_loss: 5.4488e-04\n",
      "Epoch 2814/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6688e-04 - val_loss: 5.4224e-04\n",
      "Epoch 2815/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6691e-04 - val_loss: 5.4118e-04\n",
      "Epoch 2816/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6690e-04 - val_loss: 5.4436e-04\n",
      "Epoch 2817/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6685e-04 - val_loss: 5.4494e-04\n",
      "Epoch 2818/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6694e-04 - val_loss: 5.4179e-04\n",
      "Epoch 2819/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6680e-04 - val_loss: 5.4222e-04\n",
      "Epoch 2820/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6681e-04 - val_loss: 5.4224e-04\n",
      "Epoch 2821/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6683e-04 - val_loss: 5.4165e-04\n",
      "Epoch 2822/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6680e-04 - val_loss: 5.4200e-04\n",
      "Epoch 2823/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6687e-04 - val_loss: 5.4249e-04\n",
      "Epoch 2824/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6687e-04 - val_loss: 5.4214e-04\n",
      "Epoch 2825/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6675e-04 - val_loss: 5.4363e-04\n",
      "Epoch 2826/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6683e-04 - val_loss: 5.4404e-04\n",
      "Epoch 2827/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6682e-04 - val_loss: 5.4164e-04\n",
      "Epoch 2828/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6679e-04 - val_loss: 5.4169e-04\n",
      "Epoch 2829/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6680e-04 - val_loss: 5.4198e-04\n",
      "Epoch 2830/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6689e-04 - val_loss: 5.4473e-04\n",
      "Epoch 2831/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6677e-04 - val_loss: 5.4410e-04\n",
      "Epoch 2832/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6692e-04 - val_loss: 5.4217e-04\n",
      "Epoch 2833/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6674e-04 - val_loss: 5.4352e-04\n",
      "Epoch 2834/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6675e-04 - val_loss: 5.4336e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2835/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6665e-04 - val_loss: 5.4357e-04\n",
      "Epoch 2836/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6686e-04 - val_loss: 5.4204e-04\n",
      "Epoch 2837/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6670e-04 - val_loss: 5.4422e-04\n",
      "Epoch 2838/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6675e-04 - val_loss: 5.4360e-04\n",
      "Epoch 2839/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6682e-04 - val_loss: 5.4425e-04\n",
      "Epoch 2840/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6677e-04 - val_loss: 5.4087e-04\n",
      "Epoch 2841/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6674e-04 - val_loss: 5.4296e-04\n",
      "Epoch 2842/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6679e-04 - val_loss: 5.4348e-04\n",
      "Epoch 2843/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6661e-04 - val_loss: 5.4542e-04\n",
      "Epoch 2844/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6666e-04 - val_loss: 5.4127e-04\n",
      "Epoch 2845/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6677e-04 - val_loss: 5.4420e-04\n",
      "Epoch 2846/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6680e-04 - val_loss: 5.4385e-04\n",
      "Epoch 2847/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6676e-04 - val_loss: 5.4206e-04\n",
      "Epoch 2848/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6670e-04 - val_loss: 5.4367e-04\n",
      "Epoch 2849/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6671e-04 - val_loss: 5.4324e-04\n",
      "Epoch 2850/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6668e-04 - val_loss: 5.4159e-04\n",
      "Epoch 2851/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6664e-04 - val_loss: 5.4261e-04\n",
      "Epoch 2852/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6675e-04 - val_loss: 5.4349e-04\n",
      "Epoch 2853/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6673e-04 - val_loss: 5.4084e-04\n",
      "Epoch 2854/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6670e-04 - val_loss: 5.4452e-04\n",
      "Epoch 2855/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6663e-04 - val_loss: 5.4453e-04\n",
      "Epoch 2856/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6663e-04 - val_loss: 5.4432e-04\n",
      "Epoch 2857/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6669e-04 - val_loss: 5.4313e-04\n",
      "Epoch 2858/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6670e-04 - val_loss: 5.4094e-04\n",
      "Epoch 2859/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6665e-04 - val_loss: 5.4283e-04\n",
      "Epoch 2860/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6661e-04 - val_loss: 5.4236e-04\n",
      "Epoch 2861/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6659e-04 - val_loss: 5.4217e-04\n",
      "Epoch 2862/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6664e-04 - val_loss: 5.4233e-04\n",
      "Epoch 2863/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6663e-04 - val_loss: 5.4140e-04\n",
      "Epoch 2864/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6666e-04 - val_loss: 5.4119e-04\n",
      "Epoch 2865/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6661e-04 - val_loss: 5.4327e-04\n",
      "Epoch 2866/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6658e-04 - val_loss: 5.4140e-04\n",
      "Epoch 2867/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6663e-04 - val_loss: 5.4135e-04\n",
      "Epoch 2868/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6658e-04 - val_loss: 5.4310e-04\n",
      "Epoch 2869/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6652e-04 - val_loss: 5.4234e-04\n",
      "Epoch 2870/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6664e-04 - val_loss: 5.4190e-04\n",
      "Epoch 2871/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6662e-04 - val_loss: 5.4316e-04\n",
      "Epoch 2872/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6649e-04 - val_loss: 5.4308e-04\n",
      "Epoch 2873/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6654e-04 - val_loss: 5.4122e-04\n",
      "Epoch 2874/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6654e-04 - val_loss: 5.4326e-04\n",
      "Epoch 2875/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6654e-04 - val_loss: 5.3991e-04\n",
      "Epoch 2876/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6653e-04 - val_loss: 5.4492e-04\n",
      "Epoch 2877/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6656e-04 - val_loss: 5.4226e-04\n",
      "Epoch 2878/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6655e-04 - val_loss: 5.4292e-04\n",
      "Epoch 2879/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6655e-04 - val_loss: 5.4164e-04\n",
      "Epoch 2880/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6656e-04 - val_loss: 5.4176e-04\n",
      "Epoch 2881/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6654e-04 - val_loss: 5.4254e-04\n",
      "Epoch 2882/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6648e-04 - val_loss: 5.4185e-04\n",
      "Epoch 2883/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6646e-04 - val_loss: 5.4434e-04\n",
      "Epoch 2884/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6652e-04 - val_loss: 5.4341e-04\n",
      "Epoch 2885/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6648e-04 - val_loss: 5.4127e-04\n",
      "Epoch 2886/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6656e-04 - val_loss: 5.4159e-04\n",
      "Epoch 2887/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6647e-04 - val_loss: 5.4455e-04\n",
      "Epoch 2888/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6655e-04 - val_loss: 5.4204e-04\n",
      "Epoch 2889/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6645e-04 - val_loss: 5.4183e-04\n",
      "Epoch 2890/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6645e-04 - val_loss: 5.4378e-04\n",
      "Epoch 2891/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6643e-04 - val_loss: 5.4223e-04\n",
      "Epoch 2892/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6641e-04 - val_loss: 5.4117e-04\n",
      "Epoch 2893/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6642e-04 - val_loss: 5.4260e-04\n",
      "Epoch 2894/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6642e-04 - val_loss: 5.4244e-04\n",
      "Epoch 2895/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6642e-04 - val_loss: 5.4161e-04\n",
      "Epoch 2896/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6648e-04 - val_loss: 5.4185e-04\n",
      "Epoch 2897/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6652e-04 - val_loss: 5.4463e-04\n",
      "Epoch 2898/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6642e-04 - val_loss: 5.4249e-04\n",
      "Epoch 2899/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6640e-04 - val_loss: 5.4138e-04\n",
      "Epoch 2900/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6641e-04 - val_loss: 5.4483e-04\n",
      "Epoch 2901/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6646e-04 - val_loss: 5.4189e-04\n",
      "Epoch 2902/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6640e-04 - val_loss: 5.4252e-04\n",
      "Epoch 2903/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6637e-04 - val_loss: 5.4211e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2904/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6637e-04 - val_loss: 5.4504e-04\n",
      "Epoch 2905/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6639e-04 - val_loss: 5.4074e-04\n",
      "Epoch 2906/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6637e-04 - val_loss: 5.4264e-04\n",
      "Epoch 2907/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6642e-04 - val_loss: 5.4201e-04\n",
      "Epoch 2908/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6633e-04 - val_loss: 5.4132e-04\n",
      "Epoch 2909/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6628e-04 - val_loss: 5.4140e-04\n",
      "Epoch 2910/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6629e-04 - val_loss: 5.4234e-04\n",
      "Epoch 2911/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6644e-04 - val_loss: 5.4233e-04\n",
      "Epoch 2912/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6635e-04 - val_loss: 5.4354e-04\n",
      "Epoch 2913/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6644e-04 - val_loss: 5.4279e-04\n",
      "Epoch 2914/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6637e-04 - val_loss: 5.4434e-04\n",
      "Epoch 2915/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6638e-04 - val_loss: 5.4181e-04\n",
      "Epoch 2916/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6629e-04 - val_loss: 5.4657e-04\n",
      "Epoch 2917/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6634e-04 - val_loss: 5.4307e-04\n",
      "Epoch 2918/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6642e-04 - val_loss: 5.4370e-04\n",
      "Epoch 2919/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6636e-04 - val_loss: 5.4330e-04\n",
      "Epoch 2920/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6629e-04 - val_loss: 5.4064e-04\n",
      "Epoch 2921/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6629e-04 - val_loss: 5.4297e-04\n",
      "Epoch 2922/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6621e-04 - val_loss: 5.4415e-04\n",
      "Epoch 2923/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6631e-04 - val_loss: 5.4175e-04\n",
      "Epoch 2924/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6630e-04 - val_loss: 5.4395e-04\n",
      "Epoch 2925/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6627e-04 - val_loss: 5.4301e-04\n",
      "Epoch 2926/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6625e-04 - val_loss: 5.4233e-04\n",
      "Epoch 2927/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6625e-04 - val_loss: 5.4295e-04\n",
      "Epoch 2928/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6632e-04 - val_loss: 5.4188e-04\n",
      "Epoch 2929/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6622e-04 - val_loss: 5.4437e-04\n",
      "Epoch 2930/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6628e-04 - val_loss: 5.4315e-04\n",
      "Epoch 2931/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6621e-04 - val_loss: 5.4498e-04\n",
      "Epoch 2932/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6618e-04 - val_loss: 5.4298e-04\n",
      "Epoch 2933/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6635e-04 - val_loss: 5.4261e-04\n",
      "Epoch 2934/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6617e-04 - val_loss: 5.4486e-04\n",
      "Epoch 2935/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6622e-04 - val_loss: 5.4304e-04\n",
      "Epoch 2936/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6620e-04 - val_loss: 5.4112e-04\n",
      "Epoch 2937/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6619e-04 - val_loss: 5.4271e-04\n",
      "Epoch 2938/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6623e-04 - val_loss: 5.4128e-04\n",
      "Epoch 2939/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6614e-04 - val_loss: 5.4242e-04\n",
      "Epoch 2940/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6620e-04 - val_loss: 5.4318e-04\n",
      "Epoch 2941/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 5.6613e-04 - val_loss: 5.4197e-04\n",
      "Epoch 2942/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6624e-04 - val_loss: 5.4092e-04\n",
      "Epoch 2943/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6621e-04 - val_loss: 5.4242e-04\n",
      "Epoch 2944/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6616e-04 - val_loss: 5.4260e-04\n",
      "Epoch 2945/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6621e-04 - val_loss: 5.4091e-04\n",
      "Epoch 2946/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6612e-04 - val_loss: 5.4406e-04\n",
      "Epoch 2947/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6616e-04 - val_loss: 5.4535e-04\n",
      "Epoch 2948/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6611e-04 - val_loss: 5.4351e-04\n",
      "Epoch 2949/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6612e-04 - val_loss: 5.4282e-04\n",
      "Epoch 2950/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6613e-04 - val_loss: 5.4183e-04\n",
      "Epoch 2951/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6617e-04 - val_loss: 5.4450e-04\n",
      "Epoch 2952/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6607e-04 - val_loss: 5.4247e-04\n",
      "Epoch 2953/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6624e-04 - val_loss: 5.4285e-04\n",
      "Epoch 2954/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6610e-04 - val_loss: 5.4144e-04\n",
      "Epoch 2955/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6611e-04 - val_loss: 5.4155e-04\n",
      "Epoch 2956/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6622e-04 - val_loss: 5.4283e-04\n",
      "Epoch 2957/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6603e-04 - val_loss: 5.4226e-04\n",
      "Epoch 2958/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6611e-04 - val_loss: 5.4268e-04\n",
      "Epoch 2959/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6613e-04 - val_loss: 5.4280e-04\n",
      "Epoch 2960/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6601e-04 - val_loss: 5.4316e-04\n",
      "Epoch 2961/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6604e-04 - val_loss: 5.4221e-04\n",
      "Epoch 2962/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6613e-04 - val_loss: 5.4173e-04\n",
      "Epoch 2963/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6607e-04 - val_loss: 5.4363e-04\n",
      "Epoch 2964/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6606e-04 - val_loss: 5.4138e-04\n",
      "Epoch 2965/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6608e-04 - val_loss: 5.4261e-04\n",
      "Epoch 2966/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6600e-04 - val_loss: 5.4223e-04\n",
      "Epoch 2967/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6600e-04 - val_loss: 5.4286e-04\n",
      "Epoch 2968/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6612e-04 - val_loss: 5.4113e-04\n",
      "Epoch 2969/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6603e-04 - val_loss: 5.4172e-04\n",
      "Epoch 2970/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6604e-04 - val_loss: 5.4375e-04\n",
      "Epoch 2971/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6595e-04 - val_loss: 5.4422e-04\n",
      "Epoch 2972/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6602e-04 - val_loss: 5.4427e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2973/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6597e-04 - val_loss: 5.4200e-04\n",
      "Epoch 2974/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6606e-04 - val_loss: 5.4195e-04\n",
      "Epoch 2975/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6605e-04 - val_loss: 5.4296e-04\n",
      "Epoch 2976/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6600e-04 - val_loss: 5.4203e-04\n",
      "Epoch 2977/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6598e-04 - val_loss: 5.4484e-04\n",
      "Epoch 2978/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6599e-04 - val_loss: 5.4211e-04\n",
      "Epoch 2979/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.6600e-04 - val_loss: 5.4278e-04\n",
      "Epoch 2980/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6594e-04 - val_loss: 5.4379e-04\n",
      "Epoch 2981/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6585e-04 - val_loss: 5.4325e-04\n",
      "Epoch 2982/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6602e-04 - val_loss: 5.4034e-04\n",
      "Epoch 2983/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6598e-04 - val_loss: 5.4289e-04\n",
      "Epoch 2984/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6591e-04 - val_loss: 5.4203e-04\n",
      "Epoch 2985/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6600e-04 - val_loss: 5.4200e-04\n",
      "Epoch 2986/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6601e-04 - val_loss: 5.4391e-04\n",
      "Epoch 2987/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6596e-04 - val_loss: 5.4271e-04\n",
      "Epoch 2988/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6593e-04 - val_loss: 5.4360e-04\n",
      "Epoch 2989/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6594e-04 - val_loss: 5.4333e-04\n",
      "Epoch 2990/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6592e-04 - val_loss: 5.4205e-04\n",
      "Epoch 2991/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6592e-04 - val_loss: 5.4197e-04\n",
      "Epoch 2992/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6592e-04 - val_loss: 5.4168e-04\n",
      "Epoch 2993/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6591e-04 - val_loss: 5.4241e-04\n",
      "Epoch 2994/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6584e-04 - val_loss: 5.4279e-04\n",
      "Epoch 2995/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6590e-04 - val_loss: 5.4242e-04\n",
      "Epoch 2996/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6596e-04 - val_loss: 5.4132e-04\n",
      "Epoch 2997/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6598e-04 - val_loss: 5.4226e-04\n",
      "Epoch 2998/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.6594e-04 - val_loss: 5.4166e-04\n",
      "Epoch 2999/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6579e-04 - val_loss: 5.4406e-04\n",
      "Epoch 3000/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6584e-04 - val_loss: 5.4427e-04\n",
      "Epoch 3001/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6592e-04 - val_loss: 5.4184e-04\n",
      "Epoch 3002/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6580e-04 - val_loss: 5.4250e-04\n",
      "Epoch 3003/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6589e-04 - val_loss: 5.4304e-04\n",
      "Epoch 3004/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6581e-04 - val_loss: 5.4443e-04\n",
      "Epoch 3005/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6586e-04 - val_loss: 5.4072e-04\n",
      "Epoch 3006/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6595e-04 - val_loss: 5.4219e-04\n",
      "Epoch 3007/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6595e-04 - val_loss: 5.4250e-04\n",
      "Epoch 3008/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6578e-04 - val_loss: 5.4424e-04\n",
      "Epoch 3009/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6583e-04 - val_loss: 5.4294e-04\n",
      "Epoch 3010/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6590e-04 - val_loss: 5.4342e-04\n",
      "Epoch 3011/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6583e-04 - val_loss: 5.4149e-04\n",
      "Epoch 3012/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6586e-04 - val_loss: 5.4140e-04\n",
      "Epoch 3013/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6577e-04 - val_loss: 5.4236e-04\n",
      "Epoch 3014/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6583e-04 - val_loss: 5.4276e-04\n",
      "Epoch 3015/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6583e-04 - val_loss: 5.4484e-04\n",
      "Epoch 3016/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6583e-04 - val_loss: 5.4144e-04\n",
      "Epoch 3017/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.6584e-04 - val_loss: 5.4075e-04\n",
      "Epoch 3018/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6578e-04 - val_loss: 5.4396e-04\n",
      "Epoch 3019/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6583e-04 - val_loss: 5.4261e-04\n",
      "Epoch 3020/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6581e-04 - val_loss: 5.4541e-04\n",
      "Epoch 3021/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6579e-04 - val_loss: 5.4186e-04\n",
      "Epoch 3022/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6575e-04 - val_loss: 5.4257e-04\n",
      "Epoch 3023/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6572e-04 - val_loss: 5.4429e-04\n",
      "Epoch 3024/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6575e-04 - val_loss: 5.4107e-04\n",
      "Epoch 3025/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6587e-04 - val_loss: 5.3979e-04\n",
      "Epoch 3026/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6573e-04 - val_loss: 5.4195e-04\n",
      "Epoch 3027/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6575e-04 - val_loss: 5.4042e-04\n",
      "Epoch 3028/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6584e-04 - val_loss: 5.4262e-04\n",
      "Epoch 3029/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6565e-04 - val_loss: 5.4116e-04\n",
      "Epoch 3030/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6582e-04 - val_loss: 5.4230e-04\n",
      "Epoch 3031/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6572e-04 - val_loss: 5.4313e-04\n",
      "Epoch 3032/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6575e-04 - val_loss: 5.4245e-04\n",
      "Epoch 3033/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6574e-04 - val_loss: 5.4163e-04\n",
      "Epoch 3034/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6565e-04 - val_loss: 5.4214e-04\n",
      "Epoch 3035/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6567e-04 - val_loss: 5.4138e-04\n",
      "Epoch 3036/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6568e-04 - val_loss: 5.4160e-04\n",
      "Epoch 3037/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6571e-04 - val_loss: 5.4293e-04\n",
      "Epoch 3038/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6567e-04 - val_loss: 5.4085e-04\n",
      "Epoch 3039/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6576e-04 - val_loss: 5.4122e-04\n",
      "Epoch 3040/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6563e-04 - val_loss: 5.4258e-04\n",
      "Epoch 3041/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6568e-04 - val_loss: 5.4078e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3042/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6573e-04 - val_loss: 5.4205e-04\n",
      "Epoch 3043/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6567e-04 - val_loss: 5.4203e-04\n",
      "Epoch 3044/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6575e-04 - val_loss: 5.4218e-04\n",
      "Epoch 3045/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6564e-04 - val_loss: 5.4157e-04\n",
      "Epoch 3046/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6565e-04 - val_loss: 5.4170e-04\n",
      "Epoch 3047/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6562e-04 - val_loss: 5.4342e-04\n",
      "Epoch 3048/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6568e-04 - val_loss: 5.4418e-04\n",
      "Epoch 3049/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6559e-04 - val_loss: 5.4498e-04\n",
      "Epoch 3050/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6567e-04 - val_loss: 5.4157e-04\n",
      "Epoch 3051/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6567e-04 - val_loss: 5.4303e-04\n",
      "Epoch 3052/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6557e-04 - val_loss: 5.4340e-04\n",
      "Epoch 3053/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6564e-04 - val_loss: 5.4145e-04\n",
      "Epoch 3054/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6562e-04 - val_loss: 5.4307e-04\n",
      "Epoch 3055/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6565e-04 - val_loss: 5.4141e-04\n",
      "Epoch 3056/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6558e-04 - val_loss: 5.4277e-04\n",
      "Epoch 3057/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6558e-04 - val_loss: 5.4338e-04\n",
      "Epoch 3058/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6557e-04 - val_loss: 5.4226e-04\n",
      "Epoch 3059/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6558e-04 - val_loss: 5.4119e-04\n",
      "Epoch 3060/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6561e-04 - val_loss: 5.4205e-04\n",
      "Epoch 3061/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6556e-04 - val_loss: 5.4225e-04\n",
      "Epoch 3062/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6563e-04 - val_loss: 5.4211e-04\n",
      "Epoch 3063/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6553e-04 - val_loss: 5.4387e-04\n",
      "Epoch 3064/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6559e-04 - val_loss: 5.4077e-04\n",
      "Epoch 3065/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6556e-04 - val_loss: 5.4349e-04\n",
      "Epoch 3066/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6552e-04 - val_loss: 5.4280e-04\n",
      "Epoch 3067/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6549e-04 - val_loss: 5.4535e-04\n",
      "Epoch 3068/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6563e-04 - val_loss: 5.4145e-04\n",
      "Epoch 3069/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6562e-04 - val_loss: 5.4166e-04\n",
      "Epoch 3070/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6555e-04 - val_loss: 5.4213e-04\n",
      "Epoch 3071/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6553e-04 - val_loss: 5.4579e-04\n",
      "Epoch 3072/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6549e-04 - val_loss: 5.4280e-04\n",
      "Epoch 3073/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6550e-04 - val_loss: 5.4333e-04\n",
      "Epoch 3074/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6546e-04 - val_loss: 5.4340e-04\n",
      "Epoch 3075/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6551e-04 - val_loss: 5.4259e-04\n",
      "Epoch 3076/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6553e-04 - val_loss: 5.4135e-04\n",
      "Epoch 3077/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6541e-04 - val_loss: 5.4338e-04\n",
      "Epoch 3078/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6552e-04 - val_loss: 5.4138e-04\n",
      "Epoch 3079/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6547e-04 - val_loss: 5.4334e-04\n",
      "Epoch 3080/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6547e-04 - val_loss: 5.4217e-04\n",
      "Epoch 3081/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6554e-04 - val_loss: 5.4177e-04\n",
      "Epoch 3082/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6546e-04 - val_loss: 5.4403e-04\n",
      "Epoch 3083/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6549e-04 - val_loss: 5.4176e-04\n",
      "Epoch 3084/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6549e-04 - val_loss: 5.4119e-04\n",
      "Epoch 3085/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6544e-04 - val_loss: 5.4184e-04\n",
      "Epoch 3086/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6544e-04 - val_loss: 5.4254e-04\n",
      "Epoch 3087/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6545e-04 - val_loss: 5.4415e-04\n",
      "Epoch 3088/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6543e-04 - val_loss: 5.4513e-04\n",
      "Epoch 3089/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6544e-04 - val_loss: 5.4187e-04\n",
      "Epoch 3090/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6542e-04 - val_loss: 5.4171e-04\n",
      "Epoch 3091/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6545e-04 - val_loss: 5.4297e-04\n",
      "Epoch 3092/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 5.6547e-04 - val_loss: 5.4266e-04\n",
      "Epoch 3093/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6538e-04 - val_loss: 5.4237e-04\n",
      "Epoch 3094/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6539e-04 - val_loss: 5.4370e-04\n",
      "Epoch 3095/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6555e-04 - val_loss: 5.4032e-04\n",
      "Epoch 3096/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6536e-04 - val_loss: 5.4444e-04\n",
      "Epoch 3097/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6544e-04 - val_loss: 5.4255e-04\n",
      "Epoch 3098/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6540e-04 - val_loss: 5.4173e-04\n",
      "Epoch 3099/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6541e-04 - val_loss: 5.4226e-04\n",
      "Epoch 3100/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6540e-04 - val_loss: 5.4075e-04\n",
      "Epoch 3101/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6543e-04 - val_loss: 5.4039e-04\n",
      "Epoch 3102/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6553e-04 - val_loss: 5.4165e-04\n",
      "Epoch 3103/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6537e-04 - val_loss: 5.4107e-04\n",
      "Epoch 3104/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6540e-04 - val_loss: 5.4396e-04\n",
      "Epoch 3105/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6527e-04 - val_loss: 5.4083e-04\n",
      "Epoch 3106/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6538e-04 - val_loss: 5.4240e-04\n",
      "Epoch 3107/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6529e-04 - val_loss: 5.4240e-04\n",
      "Epoch 3108/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6536e-04 - val_loss: 5.4244e-04\n",
      "Epoch 3109/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6536e-04 - val_loss: 5.4387e-04\n",
      "Epoch 3110/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6525e-04 - val_loss: 5.4091e-04\n",
      "Epoch 3111/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6530e-04 - val_loss: 5.4355e-04\n",
      "Epoch 3112/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6532e-04 - val_loss: 5.4261e-04\n",
      "Epoch 3113/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6538e-04 - val_loss: 5.4552e-04\n",
      "Epoch 3114/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6533e-04 - val_loss: 5.4233e-04\n",
      "Epoch 3115/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6529e-04 - val_loss: 5.4324e-04\n",
      "Epoch 3116/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6543e-04 - val_loss: 5.4287e-04\n",
      "Epoch 3117/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6541e-04 - val_loss: 5.4246e-04\n",
      "Epoch 3118/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6531e-04 - val_loss: 5.4361e-04\n",
      "Epoch 3119/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6541e-04 - val_loss: 5.4468e-04\n",
      "Epoch 3120/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6525e-04 - val_loss: 5.4318e-04\n",
      "Epoch 3121/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6539e-04 - val_loss: 5.4245e-04\n",
      "Epoch 3122/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6535e-04 - val_loss: 5.4205e-04\n",
      "Epoch 3123/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6527e-04 - val_loss: 5.4378e-04\n",
      "Epoch 3124/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6529e-04 - val_loss: 5.4112e-04\n",
      "Epoch 3125/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6526e-04 - val_loss: 5.4188e-04\n",
      "Epoch 3126/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6537e-04 - val_loss: 5.4101e-04\n",
      "Epoch 3127/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6522e-04 - val_loss: 5.4226e-04\n",
      "Epoch 3128/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6530e-04 - val_loss: 5.4072e-04\n",
      "Epoch 3129/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6531e-04 - val_loss: 5.4195e-04\n",
      "Epoch 3130/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6522e-04 - val_loss: 5.4405e-04\n",
      "Epoch 3131/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6515e-04 - val_loss: 5.4431e-04\n",
      "Epoch 3132/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6534e-04 - val_loss: 5.4330e-04\n",
      "Epoch 3133/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6530e-04 - val_loss: 5.4248e-04\n",
      "Epoch 3134/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6526e-04 - val_loss: 5.4304e-04\n",
      "Epoch 3135/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6527e-04 - val_loss: 5.4174e-04\n",
      "Epoch 3136/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6528e-04 - val_loss: 5.4110e-04\n",
      "Epoch 3137/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6520e-04 - val_loss: 5.4058e-04\n",
      "Epoch 3138/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6526e-04 - val_loss: 5.4484e-04\n",
      "Epoch 3139/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6525e-04 - val_loss: 5.4120e-04\n",
      "Epoch 3140/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6525e-04 - val_loss: 5.4107e-04\n",
      "Epoch 3141/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6513e-04 - val_loss: 5.4237e-04\n",
      "Epoch 3142/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6519e-04 - val_loss: 5.4299e-04\n",
      "Epoch 3143/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6526e-04 - val_loss: 5.4256e-04\n",
      "Epoch 3144/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6520e-04 - val_loss: 5.4328e-04\n",
      "Epoch 3145/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6522e-04 - val_loss: 5.4098e-04\n",
      "Epoch 3146/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6511e-04 - val_loss: 5.4227e-04\n",
      "Epoch 3147/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6520e-04 - val_loss: 5.4303e-04\n",
      "Epoch 3148/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6516e-04 - val_loss: 5.4137e-04\n",
      "Epoch 3149/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6513e-04 - val_loss: 5.4286e-04\n",
      "Epoch 3150/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6513e-04 - val_loss: 5.4027e-04\n",
      "Epoch 3151/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6515e-04 - val_loss: 5.4244e-04\n",
      "Epoch 3152/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6520e-04 - val_loss: 5.4410e-04\n",
      "Epoch 3153/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6507e-04 - val_loss: 5.4150e-04\n",
      "Epoch 3154/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6517e-04 - val_loss: 5.4105e-04\n",
      "Epoch 3155/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6507e-04 - val_loss: 5.4323e-04\n",
      "Epoch 3156/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6514e-04 - val_loss: 5.4384e-04\n",
      "Epoch 3157/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6519e-04 - val_loss: 5.4495e-04\n",
      "Epoch 3158/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6519e-04 - val_loss: 5.4178e-04\n",
      "Epoch 3159/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6509e-04 - val_loss: 5.4431e-04\n",
      "Epoch 3160/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6505e-04 - val_loss: 5.4288e-04\n",
      "Epoch 3161/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6514e-04 - val_loss: 5.4136e-04\n",
      "Epoch 3162/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6513e-04 - val_loss: 5.4432e-04\n",
      "Epoch 3163/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6506e-04 - val_loss: 5.4436e-04\n",
      "Epoch 3164/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6512e-04 - val_loss: 5.4250e-04\n",
      "Epoch 3165/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6511e-04 - val_loss: 5.4217e-04\n",
      "Epoch 3166/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6521e-04 - val_loss: 5.4183e-04\n",
      "Epoch 3167/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.6504e-04 - val_loss: 5.4319e-04\n",
      "Epoch 3168/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6511e-04 - val_loss: 5.4182e-04\n",
      "Epoch 3169/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6500e-04 - val_loss: 5.4399e-04\n",
      "Epoch 3170/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6512e-04 - val_loss: 5.4316e-04\n",
      "Epoch 3171/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6512e-04 - val_loss: 5.4168e-04\n",
      "Epoch 3172/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6514e-04 - val_loss: 5.4269e-04\n",
      "Epoch 3173/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6506e-04 - val_loss: 5.4407e-04\n",
      "Epoch 3174/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6503e-04 - val_loss: 5.4448e-04\n",
      "Epoch 3175/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6510e-04 - val_loss: 5.4146e-04\n",
      "Epoch 3176/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6514e-04 - val_loss: 5.4413e-04\n",
      "Epoch 3177/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6505e-04 - val_loss: 5.4646e-04\n",
      "Epoch 3178/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6495e-04 - val_loss: 5.4543e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3179/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6508e-04 - val_loss: 5.4106e-04\n",
      "Epoch 3180/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6493e-04 - val_loss: 5.4158e-04\n",
      "Epoch 3181/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6501e-04 - val_loss: 5.4161e-04\n",
      "Epoch 3182/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6494e-04 - val_loss: 5.4581e-04\n",
      "Epoch 3183/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6511e-04 - val_loss: 5.3903e-04\n",
      "Epoch 3184/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6503e-04 - val_loss: 5.4129e-04\n",
      "Epoch 3185/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6508e-04 - val_loss: 5.4313e-04\n",
      "Epoch 3186/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6503e-04 - val_loss: 5.4204e-04\n",
      "Epoch 3187/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6515e-04 - val_loss: 5.4394e-04\n",
      "Epoch 3188/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6507e-04 - val_loss: 5.4172e-04\n",
      "Epoch 3189/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6497e-04 - val_loss: 5.4292e-04\n",
      "Epoch 3190/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6503e-04 - val_loss: 5.4135e-04\n",
      "Epoch 3191/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6493e-04 - val_loss: 5.4235e-04\n",
      "Epoch 3192/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6493e-04 - val_loss: 5.4287e-04\n",
      "Epoch 3193/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6497e-04 - val_loss: 5.4181e-04\n",
      "Epoch 3194/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6506e-04 - val_loss: 5.4028e-04\n",
      "Epoch 3195/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6493e-04 - val_loss: 5.4249e-04\n",
      "Epoch 3196/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6494e-04 - val_loss: 5.4428e-04\n",
      "Epoch 3197/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6496e-04 - val_loss: 5.4146e-04\n",
      "Epoch 3198/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6504e-04 - val_loss: 5.4522e-04\n",
      "Epoch 3199/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6496e-04 - val_loss: 5.4522e-04\n",
      "Epoch 3200/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6501e-04 - val_loss: 5.4274e-04\n",
      "Epoch 3201/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6485e-04 - val_loss: 5.4311e-04\n",
      "Epoch 3202/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6493e-04 - val_loss: 5.4353e-04\n",
      "Epoch 3203/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6498e-04 - val_loss: 5.4098e-04\n",
      "Epoch 3204/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6484e-04 - val_loss: 5.4269e-04\n",
      "Epoch 3205/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6496e-04 - val_loss: 5.4251e-04\n",
      "Epoch 3206/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6487e-04 - val_loss: 5.4504e-04\n",
      "Epoch 3207/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6491e-04 - val_loss: 5.4251e-04\n",
      "Epoch 3208/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6493e-04 - val_loss: 5.4212e-04\n",
      "Epoch 3209/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6494e-04 - val_loss: 5.4460e-04\n",
      "Epoch 3210/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6493e-04 - val_loss: 5.4038e-04\n",
      "Epoch 3211/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.6488e-04 - val_loss: 5.3943e-04\n",
      "Epoch 3212/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6489e-04 - val_loss: 5.4227e-04\n",
      "Epoch 3213/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6491e-04 - val_loss: 5.4180e-04\n",
      "Epoch 3214/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6496e-04 - val_loss: 5.4403e-04\n",
      "Epoch 3215/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6487e-04 - val_loss: 5.4730e-04\n",
      "Epoch 3216/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6485e-04 - val_loss: 5.4167e-04\n",
      "Epoch 3217/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6486e-04 - val_loss: 5.4600e-04\n",
      "Epoch 3218/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6489e-04 - val_loss: 5.4310e-04\n",
      "Epoch 3219/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6483e-04 - val_loss: 5.4474e-04\n",
      "Epoch 3220/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6488e-04 - val_loss: 5.4497e-04\n",
      "Epoch 3221/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6483e-04 - val_loss: 5.4209e-04\n",
      "Epoch 3222/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6477e-04 - val_loss: 5.4415e-04\n",
      "Epoch 3223/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6490e-04 - val_loss: 5.4070e-04\n",
      "Epoch 3224/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6482e-04 - val_loss: 5.4273e-04\n",
      "Epoch 3225/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6481e-04 - val_loss: 5.4174e-04\n",
      "Epoch 3226/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6488e-04 - val_loss: 5.4094e-04\n",
      "Epoch 3227/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6480e-04 - val_loss: 5.4345e-04\n",
      "Epoch 3228/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6485e-04 - val_loss: 5.4199e-04\n",
      "Epoch 3229/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6481e-04 - val_loss: 5.4392e-04\n",
      "Epoch 3230/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6478e-04 - val_loss: 5.4252e-04\n",
      "Epoch 3231/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6481e-04 - val_loss: 5.4280e-04\n",
      "Epoch 3232/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6484e-04 - val_loss: 5.4234e-04\n",
      "Epoch 3233/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6477e-04 - val_loss: 5.4482e-04\n",
      "Epoch 3234/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6476e-04 - val_loss: 5.4271e-04\n",
      "Epoch 3235/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6477e-04 - val_loss: 5.4169e-04\n",
      "Epoch 3236/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6479e-04 - val_loss: 5.4140e-04\n",
      "Epoch 3237/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6495e-04 - val_loss: 5.4077e-04\n",
      "Epoch 3238/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6476e-04 - val_loss: 5.4245e-04\n",
      "Epoch 3239/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6475e-04 - val_loss: 5.4140e-04\n",
      "Epoch 3240/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6468e-04 - val_loss: 5.4222e-04\n",
      "Epoch 3241/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6481e-04 - val_loss: 5.4075e-04\n",
      "Epoch 3242/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.6476e-04 - val_loss: 5.4145e-04\n",
      "Epoch 3243/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6468e-04 - val_loss: 5.4172e-04\n",
      "Epoch 3244/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6471e-04 - val_loss: 5.4250e-04\n",
      "Epoch 3245/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6485e-04 - val_loss: 5.4165e-04\n",
      "Epoch 3246/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6477e-04 - val_loss: 5.4124e-04\n",
      "Epoch 3247/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6480e-04 - val_loss: 5.4172e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3248/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6477e-04 - val_loss: 5.4513e-04\n",
      "Epoch 3249/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6477e-04 - val_loss: 5.4158e-04\n",
      "Epoch 3250/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6467e-04 - val_loss: 5.4385e-04\n",
      "Epoch 3251/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6479e-04 - val_loss: 5.4054e-04\n",
      "Epoch 3252/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6470e-04 - val_loss: 5.4276e-04\n",
      "Epoch 3253/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6468e-04 - val_loss: 5.4182e-04\n",
      "Epoch 3254/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6463e-04 - val_loss: 5.4111e-04\n",
      "Epoch 3255/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6469e-04 - val_loss: 5.4313e-04\n",
      "Epoch 3256/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6468e-04 - val_loss: 5.4432e-04\n",
      "Epoch 3257/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6462e-04 - val_loss: 5.4005e-04\n",
      "Epoch 3258/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6464e-04 - val_loss: 5.4343e-04\n",
      "Epoch 3259/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6466e-04 - val_loss: 5.4517e-04\n",
      "Epoch 3260/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6476e-04 - val_loss: 5.4046e-04\n",
      "Epoch 3261/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6473e-04 - val_loss: 5.4608e-04\n",
      "Epoch 3262/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6467e-04 - val_loss: 5.4121e-04\n",
      "Epoch 3263/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6469e-04 - val_loss: 5.4281e-04\n",
      "Epoch 3264/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6456e-04 - val_loss: 5.4440e-04\n",
      "Epoch 3265/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6468e-04 - val_loss: 5.4222e-04\n",
      "Epoch 3266/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6465e-04 - val_loss: 5.4176e-04\n",
      "Epoch 3267/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6466e-04 - val_loss: 5.4305e-04\n",
      "Epoch 3268/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6462e-04 - val_loss: 5.4516e-04\n",
      "Epoch 3269/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6465e-04 - val_loss: 5.4469e-04\n",
      "Epoch 3270/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6468e-04 - val_loss: 5.4225e-04\n",
      "Epoch 3271/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6465e-04 - val_loss: 5.4351e-04\n",
      "Epoch 3272/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6459e-04 - val_loss: 5.4604e-04\n",
      "Epoch 3273/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6466e-04 - val_loss: 5.4094e-04\n",
      "Epoch 3274/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6465e-04 - val_loss: 5.4342e-04\n",
      "Epoch 3275/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6464e-04 - val_loss: 5.4327e-04\n",
      "Epoch 3276/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6463e-04 - val_loss: 5.4095e-04\n",
      "Epoch 3277/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6462e-04 - val_loss: 5.4251e-04\n",
      "Epoch 3278/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6459e-04 - val_loss: 5.4357e-04\n",
      "Epoch 3279/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6448e-04 - val_loss: 5.4263e-04\n",
      "Epoch 3280/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 5.6468e-04 - val_loss: 5.4109e-04\n",
      "Epoch 3281/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6465e-04 - val_loss: 5.4229e-04\n",
      "Epoch 3282/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6459e-04 - val_loss: 5.4106e-04\n",
      "Epoch 3283/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6464e-04 - val_loss: 5.4075e-04\n",
      "Epoch 3284/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6461e-04 - val_loss: 5.4258e-04\n",
      "Epoch 3285/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6452e-04 - val_loss: 5.4238e-04\n",
      "Epoch 3286/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6458e-04 - val_loss: 5.4053e-04\n",
      "Epoch 3287/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6452e-04 - val_loss: 5.4227e-04\n",
      "Epoch 3288/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6456e-04 - val_loss: 5.4287e-04\n",
      "Epoch 3289/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6455e-04 - val_loss: 5.4194e-04\n",
      "Epoch 3290/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6460e-04 - val_loss: 5.4157e-04\n",
      "Epoch 3291/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6453e-04 - val_loss: 5.4418e-04\n",
      "Epoch 3292/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6449e-04 - val_loss: 5.4203e-04\n",
      "Epoch 3293/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6452e-04 - val_loss: 5.4172e-04\n",
      "Epoch 3294/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6457e-04 - val_loss: 5.4164e-04\n",
      "Epoch 3295/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6452e-04 - val_loss: 5.4297e-04\n",
      "Epoch 3296/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6451e-04 - val_loss: 5.4401e-04\n",
      "Epoch 3297/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6456e-04 - val_loss: 5.4150e-04\n",
      "Epoch 3298/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6449e-04 - val_loss: 5.4095e-04\n",
      "Epoch 3299/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.6453e-04 - val_loss: 5.4346e-04\n",
      "Epoch 3300/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.6457e-04 - val_loss: 5.4062e-04\n",
      "Epoch 3301/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6446e-04 - val_loss: 5.4125e-04\n",
      "Epoch 3302/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6449e-04 - val_loss: 5.4261e-04\n",
      "Epoch 3303/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6453e-04 - val_loss: 5.4275e-04\n",
      "Epoch 3304/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6449e-04 - val_loss: 5.4331e-04\n",
      "Epoch 3305/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6452e-04 - val_loss: 5.4414e-04\n",
      "Epoch 3306/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6454e-04 - val_loss: 5.4149e-04\n",
      "Epoch 3307/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6447e-04 - val_loss: 5.4523e-04\n",
      "Epoch 3308/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6444e-04 - val_loss: 5.4448e-04\n",
      "Epoch 3309/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6446e-04 - val_loss: 5.3993e-04\n",
      "Epoch 3310/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6446e-04 - val_loss: 5.4224e-04\n",
      "Epoch 3311/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6450e-04 - val_loss: 5.4252e-04\n",
      "Epoch 3312/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6445e-04 - val_loss: 5.4167e-04\n",
      "Epoch 3313/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6444e-04 - val_loss: 5.4223e-04\n",
      "Epoch 3314/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6441e-04 - val_loss: 5.4335e-04\n",
      "Epoch 3315/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6448e-04 - val_loss: 5.4522e-04\n",
      "Epoch 3316/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6449e-04 - val_loss: 5.4044e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3317/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6437e-04 - val_loss: 5.4160e-04\n",
      "Epoch 3318/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6448e-04 - val_loss: 5.4430e-04\n",
      "Epoch 3319/10000\n",
      "45507/45507 [==============================] - 1s 23us/step - loss: 5.6446e-04 - val_loss: 5.4404e-04\n",
      "Epoch 3320/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6443e-04 - val_loss: 5.4359e-04\n",
      "Epoch 3321/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6437e-04 - val_loss: 5.4664e-04\n",
      "Epoch 3322/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6439e-04 - val_loss: 5.4076e-04\n",
      "Epoch 3323/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6442e-04 - val_loss: 5.4194e-04\n",
      "Epoch 3324/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6439e-04 - val_loss: 5.4368e-04\n",
      "Epoch 3325/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6443e-04 - val_loss: 5.4199e-04\n",
      "Epoch 3326/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6436e-04 - val_loss: 5.4349e-04\n",
      "Epoch 3327/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6447e-04 - val_loss: 5.4327e-04\n",
      "Epoch 3328/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6436e-04 - val_loss: 5.4300e-04\n",
      "Epoch 3329/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6437e-04 - val_loss: 5.4078e-04\n",
      "Epoch 3330/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6444e-04 - val_loss: 5.4335e-04\n",
      "Epoch 3331/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6441e-04 - val_loss: 5.4150e-04\n",
      "Epoch 3332/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6445e-04 - val_loss: 5.4627e-04\n",
      "Epoch 3333/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6442e-04 - val_loss: 5.4160e-04\n",
      "Epoch 3334/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6438e-04 - val_loss: 5.4225e-04\n",
      "Epoch 3335/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6442e-04 - val_loss: 5.4435e-04\n",
      "Epoch 3336/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6436e-04 - val_loss: 5.4167e-04\n",
      "Epoch 3337/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6439e-04 - val_loss: 5.4091e-04\n",
      "Epoch 3338/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6429e-04 - val_loss: 5.4315e-04\n",
      "Epoch 3339/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6435e-04 - val_loss: 5.4325e-04\n",
      "Epoch 3340/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6437e-04 - val_loss: 5.4096e-04\n",
      "Epoch 3341/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6443e-04 - val_loss: 5.4365e-04\n",
      "Epoch 3342/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6442e-04 - val_loss: 5.4232e-04\n",
      "Epoch 3343/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6427e-04 - val_loss: 5.4357e-04\n",
      "Epoch 3344/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6436e-04 - val_loss: 5.4348e-04\n",
      "Epoch 3345/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6434e-04 - val_loss: 5.4097e-04\n",
      "Epoch 3346/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6432e-04 - val_loss: 5.4367e-04\n",
      "Epoch 3347/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6435e-04 - val_loss: 5.4169e-04\n",
      "Epoch 3348/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6428e-04 - val_loss: 5.4321e-04\n",
      "Epoch 3349/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6435e-04 - val_loss: 5.4079e-04\n",
      "Epoch 3350/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6423e-04 - val_loss: 5.4271e-04\n",
      "Epoch 3351/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6434e-04 - val_loss: 5.4151e-04\n",
      "Epoch 3352/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6435e-04 - val_loss: 5.4163e-04\n",
      "Epoch 3353/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6422e-04 - val_loss: 5.4362e-04\n",
      "Epoch 3354/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6427e-04 - val_loss: 5.4562e-04\n",
      "Epoch 3355/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6424e-04 - val_loss: 5.4201e-04\n",
      "Epoch 3356/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 5.6430e-04 - val_loss: 5.4276e-04\n",
      "Epoch 3357/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6425e-04 - val_loss: 5.4300e-04\n",
      "Epoch 3358/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6438e-04 - val_loss: 5.4296e-04\n",
      "Epoch 3359/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6422e-04 - val_loss: 5.4315e-04\n",
      "Epoch 3360/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6426e-04 - val_loss: 5.4139e-04\n",
      "Epoch 3361/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6433e-04 - val_loss: 5.4253e-04\n",
      "Epoch 3362/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6417e-04 - val_loss: 5.4059e-04\n",
      "Epoch 3363/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6423e-04 - val_loss: 5.4383e-04\n",
      "Epoch 3364/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6426e-04 - val_loss: 5.4316e-04\n",
      "Epoch 3365/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6431e-04 - val_loss: 5.4173e-04\n",
      "Epoch 3366/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6423e-04 - val_loss: 5.4382e-04\n",
      "Epoch 3367/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6421e-04 - val_loss: 5.4002e-04\n",
      "Epoch 3368/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6419e-04 - val_loss: 5.4326e-04\n",
      "Epoch 3369/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6428e-04 - val_loss: 5.4336e-04\n",
      "Epoch 3370/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6428e-04 - val_loss: 5.4194e-04\n",
      "Epoch 3371/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6427e-04 - val_loss: 5.4199e-04\n",
      "Epoch 3372/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6415e-04 - val_loss: 5.3954e-04\n",
      "Epoch 3373/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6417e-04 - val_loss: 5.4237e-04\n",
      "Epoch 3374/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6426e-04 - val_loss: 5.4445e-04\n",
      "Epoch 3375/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6422e-04 - val_loss: 5.4174e-04\n",
      "Epoch 3376/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6413e-04 - val_loss: 5.4329e-04\n",
      "Epoch 3377/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6424e-04 - val_loss: 5.4240e-04\n",
      "Epoch 3378/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6421e-04 - val_loss: 5.4091e-04\n",
      "Epoch 3379/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6417e-04 - val_loss: 5.4155e-04\n",
      "Epoch 3380/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6421e-04 - val_loss: 5.4380e-04\n",
      "Epoch 3381/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6418e-04 - val_loss: 5.4280e-04\n",
      "Epoch 3382/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6419e-04 - val_loss: 5.4393e-04\n",
      "Epoch 3383/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6423e-04 - val_loss: 5.4310e-04\n",
      "Epoch 3384/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6411e-04 - val_loss: 5.4341e-04\n",
      "Epoch 3385/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6417e-04 - val_loss: 5.4158e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3386/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6411e-04 - val_loss: 5.4069e-04\n",
      "Epoch 3387/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6414e-04 - val_loss: 5.4104e-04\n",
      "Epoch 3388/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6413e-04 - val_loss: 5.4261e-04\n",
      "Epoch 3389/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6422e-04 - val_loss: 5.4158e-04\n",
      "Epoch 3390/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6420e-04 - val_loss: 5.4062e-04\n",
      "Epoch 3391/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6408e-04 - val_loss: 5.4188e-04\n",
      "Epoch 3392/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6414e-04 - val_loss: 5.4205e-04\n",
      "Epoch 3393/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6410e-04 - val_loss: 5.4321e-04\n",
      "Epoch 3394/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6414e-04 - val_loss: 5.4448e-04\n",
      "Epoch 3395/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6410e-04 - val_loss: 5.4288e-04\n",
      "Epoch 3396/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6406e-04 - val_loss: 5.4518e-04\n",
      "Epoch 3397/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6412e-04 - val_loss: 5.4273e-04\n",
      "Epoch 3398/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6420e-04 - val_loss: 5.4023e-04\n",
      "Epoch 3399/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6408e-04 - val_loss: 5.4140e-04\n",
      "Epoch 3400/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6414e-04 - val_loss: 5.4489e-04\n",
      "Epoch 3401/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6412e-04 - val_loss: 5.4529e-04\n",
      "Epoch 3402/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6408e-04 - val_loss: 5.4141e-04\n",
      "Epoch 3403/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6412e-04 - val_loss: 5.4258e-04\n",
      "Epoch 3404/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6403e-04 - val_loss: 5.4295e-04\n",
      "Epoch 3405/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6412e-04 - val_loss: 5.4331e-04\n",
      "Epoch 3406/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6413e-04 - val_loss: 5.4245e-04\n",
      "Epoch 3407/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6407e-04 - val_loss: 5.4290e-04\n",
      "Epoch 3408/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6402e-04 - val_loss: 5.4410e-04\n",
      "Epoch 3409/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6417e-04 - val_loss: 5.4268e-04\n",
      "Epoch 3410/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6405e-04 - val_loss: 5.4036e-04\n",
      "Epoch 3411/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6406e-04 - val_loss: 5.4379e-04\n",
      "Epoch 3412/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6408e-04 - val_loss: 5.4246e-04\n",
      "Epoch 3413/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6408e-04 - val_loss: 5.4066e-04\n",
      "Epoch 3414/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6398e-04 - val_loss: 5.4364e-04\n",
      "Epoch 3415/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6403e-04 - val_loss: 5.4271e-04\n",
      "Epoch 3416/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6413e-04 - val_loss: 5.4123e-04\n",
      "Epoch 3417/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6399e-04 - val_loss: 5.4242e-04\n",
      "Epoch 3418/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6404e-04 - val_loss: 5.4193e-04\n",
      "Epoch 3419/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6406e-04 - val_loss: 5.4038e-04\n",
      "Epoch 3420/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6410e-04 - val_loss: 5.4309e-04\n",
      "Epoch 3421/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6404e-04 - val_loss: 5.4180e-04\n",
      "Epoch 3422/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6399e-04 - val_loss: 5.4354e-04\n",
      "Epoch 3423/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6411e-04 - val_loss: 5.4344e-04\n",
      "Epoch 3424/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6394e-04 - val_loss: 5.4187e-04\n",
      "Epoch 3425/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6399e-04 - val_loss: 5.4341e-04\n",
      "Epoch 3426/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6397e-04 - val_loss: 5.4356e-04\n",
      "Epoch 3427/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6406e-04 - val_loss: 5.4276e-04\n",
      "Epoch 3428/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6402e-04 - val_loss: 5.4362e-04\n",
      "Epoch 3429/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6396e-04 - val_loss: 5.4088e-04\n",
      "Epoch 3430/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6399e-04 - val_loss: 5.4283e-04\n",
      "Epoch 3431/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6402e-04 - val_loss: 5.4009e-04\n",
      "Epoch 3432/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6393e-04 - val_loss: 5.4179e-04\n",
      "Epoch 3433/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6403e-04 - val_loss: 5.4398e-04\n",
      "Epoch 3434/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6396e-04 - val_loss: 5.4408e-04\n",
      "Epoch 3435/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6395e-04 - val_loss: 5.4405e-04\n",
      "Epoch 3436/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6397e-04 - val_loss: 5.4131e-04\n",
      "Epoch 3437/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6393e-04 - val_loss: 5.4375e-04\n",
      "Epoch 3438/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6402e-04 - val_loss: 5.4371e-04\n",
      "Epoch 3439/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6408e-04 - val_loss: 5.4254e-04\n",
      "Epoch 3440/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6393e-04 - val_loss: 5.4280e-04\n",
      "Epoch 3441/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6401e-04 - val_loss: 5.4270e-04\n",
      "Epoch 3442/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6397e-04 - val_loss: 5.4287e-04\n",
      "Epoch 3443/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6389e-04 - val_loss: 5.4874e-04\n",
      "Epoch 3444/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6402e-04 - val_loss: 5.4188e-04\n",
      "Epoch 3445/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6394e-04 - val_loss: 5.4076e-04\n",
      "Epoch 3446/10000\n",
      "45507/45507 [==============================] - 2s 38us/step - loss: 5.6395e-04 - val_loss: 5.4295e-04\n",
      "Epoch 3447/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6392e-04 - val_loss: 5.4057e-04\n",
      "Epoch 3448/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6391e-04 - val_loss: 5.4181e-04\n",
      "Epoch 3449/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6388e-04 - val_loss: 5.4395e-04\n",
      "Epoch 3450/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6398e-04 - val_loss: 5.4116e-04\n",
      "Epoch 3451/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6393e-04 - val_loss: 5.4256e-04\n",
      "Epoch 3452/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6398e-04 - val_loss: 5.4164e-04\n",
      "Epoch 3453/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6391e-04 - val_loss: 5.4113e-04\n",
      "Epoch 3454/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6391e-04 - val_loss: 5.4268e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3455/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6388e-04 - val_loss: 5.4176e-04\n",
      "Epoch 3456/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6384e-04 - val_loss: 5.4282e-04\n",
      "Epoch 3457/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6386e-04 - val_loss: 5.4433e-04\n",
      "Epoch 3458/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6387e-04 - val_loss: 5.4287e-04\n",
      "Epoch 3459/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6390e-04 - val_loss: 5.4165e-04\n",
      "Epoch 3460/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6389e-04 - val_loss: 5.4365e-04\n",
      "Epoch 3461/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6390e-04 - val_loss: 5.4048e-04\n",
      "Epoch 3462/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6394e-04 - val_loss: 5.4361e-04\n",
      "Epoch 3463/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6390e-04 - val_loss: 5.4179e-04\n",
      "Epoch 3464/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6389e-04 - val_loss: 5.4082e-04\n",
      "Epoch 3465/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6382e-04 - val_loss: 5.4566e-04\n",
      "Epoch 3466/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6392e-04 - val_loss: 5.4261e-04\n",
      "Epoch 3467/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6381e-04 - val_loss: 5.4157e-04\n",
      "Epoch 3468/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6392e-04 - val_loss: 5.4331e-04\n",
      "Epoch 3469/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6384e-04 - val_loss: 5.4137e-04\n",
      "Epoch 3470/10000\n",
      "45507/45507 [==============================] - 1s 23us/step - loss: 5.6376e-04 - val_loss: 5.4182e-04\n",
      "Epoch 3471/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6386e-04 - val_loss: 5.4354e-04\n",
      "Epoch 3472/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6385e-04 - val_loss: 5.4399e-04\n",
      "Epoch 3473/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6387e-04 - val_loss: 5.4480e-04\n",
      "Epoch 3474/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6388e-04 - val_loss: 5.4057e-04\n",
      "Epoch 3475/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6383e-04 - val_loss: 5.4373e-04\n",
      "Epoch 3476/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6382e-04 - val_loss: 5.4483e-04\n",
      "Epoch 3477/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6384e-04 - val_loss: 5.4298e-04\n",
      "Epoch 3478/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6389e-04 - val_loss: 5.4133e-04\n",
      "Epoch 3479/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6378e-04 - val_loss: 5.4384e-04\n",
      "Epoch 3480/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6386e-04 - val_loss: 5.4298e-04\n",
      "Epoch 3481/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6376e-04 - val_loss: 5.4412e-04\n",
      "Epoch 3482/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6376e-04 - val_loss: 5.4202e-04\n",
      "Epoch 3483/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6383e-04 - val_loss: 5.4257e-04\n",
      "Epoch 3484/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6377e-04 - val_loss: 5.4356e-04\n",
      "Epoch 3485/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6380e-04 - val_loss: 5.4277e-04\n",
      "Epoch 3486/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6376e-04 - val_loss: 5.4099e-04\n",
      "Epoch 3487/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6377e-04 - val_loss: 5.4334e-04\n",
      "Epoch 3488/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6378e-04 - val_loss: 5.4312e-04\n",
      "Epoch 3489/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6378e-04 - val_loss: 5.4153e-04\n",
      "Epoch 3490/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6375e-04 - val_loss: 5.4255e-04\n",
      "Epoch 3491/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6376e-04 - val_loss: 5.4185e-04\n",
      "Epoch 3492/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6378e-04 - val_loss: 5.4257e-04\n",
      "Epoch 3493/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6367e-04 - val_loss: 5.4253e-04\n",
      "Epoch 3494/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6383e-04 - val_loss: 5.4200e-04\n",
      "Epoch 3495/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6369e-04 - val_loss: 5.4134e-04\n",
      "Epoch 3496/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6378e-04 - val_loss: 5.4308e-04\n",
      "Epoch 3497/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6371e-04 - val_loss: 5.4514e-04\n",
      "Epoch 3498/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6378e-04 - val_loss: 5.4171e-04\n",
      "Epoch 3499/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6368e-04 - val_loss: 5.4222e-04\n",
      "Epoch 3500/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6376e-04 - val_loss: 5.4237e-04\n",
      "Epoch 3501/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6371e-04 - val_loss: 5.4143e-04\n",
      "Epoch 3502/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6374e-04 - val_loss: 5.4216e-04\n",
      "Epoch 3503/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6368e-04 - val_loss: 5.4183e-04\n",
      "Epoch 3504/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6369e-04 - val_loss: 5.4165e-04\n",
      "Epoch 3505/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6374e-04 - val_loss: 5.4297e-04\n",
      "Epoch 3506/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6368e-04 - val_loss: 5.4306e-04\n",
      "Epoch 3507/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6372e-04 - val_loss: 5.4252e-04\n",
      "Epoch 3508/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6368e-04 - val_loss: 5.4078e-04\n",
      "Epoch 3509/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6365e-04 - val_loss: 5.4144e-04\n",
      "Epoch 3510/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6371e-04 - val_loss: 5.4045e-04\n",
      "Epoch 3511/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6364e-04 - val_loss: 5.4339e-04\n",
      "Epoch 3512/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6370e-04 - val_loss: 5.4239e-04\n",
      "Epoch 3513/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6367e-04 - val_loss: 5.4309e-04\n",
      "Epoch 3514/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6367e-04 - val_loss: 5.4400e-04\n",
      "Epoch 3515/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6369e-04 - val_loss: 5.4191e-04\n",
      "Epoch 3516/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6367e-04 - val_loss: 5.4220e-04\n",
      "Epoch 3517/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6364e-04 - val_loss: 5.4370e-04\n",
      "Epoch 3518/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6361e-04 - val_loss: 5.4314e-04\n",
      "Epoch 3519/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6362e-04 - val_loss: 5.4127e-04\n",
      "Epoch 3520/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6367e-04 - val_loss: 5.4251e-04\n",
      "Epoch 3521/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6366e-04 - val_loss: 5.4447e-04\n",
      "Epoch 3522/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6359e-04 - val_loss: 5.4187e-04\n",
      "Epoch 3523/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6370e-04 - val_loss: 5.4365e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3524/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6362e-04 - val_loss: 5.4084e-04\n",
      "Epoch 3525/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6368e-04 - val_loss: 5.4213e-04\n",
      "Epoch 3526/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6360e-04 - val_loss: 5.4282e-04\n",
      "Epoch 3527/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6359e-04 - val_loss: 5.4193e-04\n",
      "Epoch 3528/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6359e-04 - val_loss: 5.4149e-04\n",
      "Epoch 3529/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6368e-04 - val_loss: 5.4197e-04\n",
      "Epoch 3530/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6361e-04 - val_loss: 5.4245e-04\n",
      "Epoch 3531/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6352e-04 - val_loss: 5.4096e-04\n",
      "Epoch 3532/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6364e-04 - val_loss: 5.4292e-04\n",
      "Epoch 3533/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6353e-04 - val_loss: 5.4329e-04\n",
      "Epoch 3534/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6367e-04 - val_loss: 5.4083e-04\n",
      "Epoch 3535/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6352e-04 - val_loss: 5.4039e-04\n",
      "Epoch 3536/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6352e-04 - val_loss: 5.4056e-04\n",
      "Epoch 3537/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6363e-04 - val_loss: 5.4196e-04\n",
      "Epoch 3538/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6363e-04 - val_loss: 5.4205e-04\n",
      "Epoch 3539/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6353e-04 - val_loss: 5.4010e-04\n",
      "Epoch 3540/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6357e-04 - val_loss: 5.4357e-04\n",
      "Epoch 3541/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6361e-04 - val_loss: 5.4371e-04\n",
      "Epoch 3542/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6355e-04 - val_loss: 5.4182e-04\n",
      "Epoch 3543/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6357e-04 - val_loss: 5.4351e-04\n",
      "Epoch 3544/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 5.6358e-04 - val_loss: 5.4260e-04\n",
      "Epoch 3545/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6356e-04 - val_loss: 5.4147e-04\n",
      "Epoch 3546/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6359e-04 - val_loss: 5.4131e-04\n",
      "Epoch 3547/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6349e-04 - val_loss: 5.4192e-04\n",
      "Epoch 3548/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6359e-04 - val_loss: 5.4256e-04\n",
      "Epoch 3549/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6356e-04 - val_loss: 5.4213e-04\n",
      "Epoch 3550/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6352e-04 - val_loss: 5.4130e-04\n",
      "Epoch 3551/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6356e-04 - val_loss: 5.4210e-04\n",
      "Epoch 3552/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6356e-04 - val_loss: 5.4325e-04\n",
      "Epoch 3553/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6360e-04 - val_loss: 5.4174e-04\n",
      "Epoch 3554/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6356e-04 - val_loss: 5.4157e-04\n",
      "Epoch 3555/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6349e-04 - val_loss: 5.4278e-04\n",
      "Epoch 3556/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6347e-04 - val_loss: 5.4141e-04\n",
      "Epoch 3557/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6352e-04 - val_loss: 5.4647e-04\n",
      "Epoch 3558/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6344e-04 - val_loss: 5.4219e-04\n",
      "Epoch 3559/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6346e-04 - val_loss: 5.4213e-04\n",
      "Epoch 3560/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6350e-04 - val_loss: 5.4142e-04\n",
      "Epoch 3561/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6351e-04 - val_loss: 5.4259e-04\n",
      "Epoch 3562/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6352e-04 - val_loss: 5.4216e-04\n",
      "Epoch 3563/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6349e-04 - val_loss: 5.4314e-04\n",
      "Epoch 3564/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6343e-04 - val_loss: 5.4191e-04\n",
      "Epoch 3565/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6350e-04 - val_loss: 5.4224e-04\n",
      "Epoch 3566/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6353e-04 - val_loss: 5.4022e-04\n",
      "Epoch 3567/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6340e-04 - val_loss: 5.4342e-04\n",
      "Epoch 3568/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6341e-04 - val_loss: 5.4136e-04\n",
      "Epoch 3569/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6351e-04 - val_loss: 5.4183e-04\n",
      "Epoch 3570/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6345e-04 - val_loss: 5.4066e-04\n",
      "Epoch 3571/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6344e-04 - val_loss: 5.4203e-04\n",
      "Epoch 3572/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6348e-04 - val_loss: 5.4300e-04\n",
      "Epoch 3573/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6353e-04 - val_loss: 5.4375e-04\n",
      "Epoch 3574/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6346e-04 - val_loss: 5.4356e-04\n",
      "Epoch 3575/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6343e-04 - val_loss: 5.4181e-04\n",
      "Epoch 3576/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6341e-04 - val_loss: 5.4454e-04\n",
      "Epoch 3577/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6348e-04 - val_loss: 5.4370e-04\n",
      "Epoch 3578/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6342e-04 - val_loss: 5.4276e-04\n",
      "Epoch 3579/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6346e-04 - val_loss: 5.4227e-04\n",
      "Epoch 3580/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6340e-04 - val_loss: 5.4102e-04\n",
      "Epoch 3581/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6345e-04 - val_loss: 5.4136e-04\n",
      "Epoch 3582/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6345e-04 - val_loss: 5.4102e-04\n",
      "Epoch 3583/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6341e-04 - val_loss: 5.4236e-04\n",
      "Epoch 3584/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6330e-04 - val_loss: 5.4292e-04\n",
      "Epoch 3585/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6333e-04 - val_loss: 5.4241e-04\n",
      "Epoch 3586/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6332e-04 - val_loss: 5.4125e-04\n",
      "Epoch 3587/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6341e-04 - val_loss: 5.4318e-04\n",
      "Epoch 3588/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6344e-04 - val_loss: 5.4272e-04\n",
      "Epoch 3589/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6340e-04 - val_loss: 5.4245e-04\n",
      "Epoch 3590/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6341e-04 - val_loss: 5.4260e-04\n",
      "Epoch 3591/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6333e-04 - val_loss: 5.4307e-04\n",
      "Epoch 3592/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6340e-04 - val_loss: 5.4363e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3593/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6340e-04 - val_loss: 5.4224e-04\n",
      "Epoch 3594/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6344e-04 - val_loss: 5.4195e-04\n",
      "Epoch 3595/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6339e-04 - val_loss: 5.4191e-04\n",
      "Epoch 3596/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6342e-04 - val_loss: 5.4230e-04\n",
      "Epoch 3597/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6332e-04 - val_loss: 5.4282e-04\n",
      "Epoch 3598/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6333e-04 - val_loss: 5.4138e-04\n",
      "Epoch 3599/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6338e-04 - val_loss: 5.4177e-04\n",
      "Epoch 3600/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6337e-04 - val_loss: 5.4248e-04\n",
      "Epoch 3601/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6341e-04 - val_loss: 5.4278e-04\n",
      "Epoch 3602/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6331e-04 - val_loss: 5.4212e-04\n",
      "Epoch 3603/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6335e-04 - val_loss: 5.4273e-04\n",
      "Epoch 3604/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6334e-04 - val_loss: 5.4136e-04\n",
      "Epoch 3605/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6330e-04 - val_loss: 5.3939e-04\n",
      "Epoch 3606/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6336e-04 - val_loss: 5.4453e-04\n",
      "Epoch 3607/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6332e-04 - val_loss: 5.4174e-04\n",
      "Epoch 3608/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6339e-04 - val_loss: 5.4117e-04\n",
      "Epoch 3609/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6328e-04 - val_loss: 5.4321e-04\n",
      "Epoch 3610/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6329e-04 - val_loss: 5.4288e-04\n",
      "Epoch 3611/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6325e-04 - val_loss: 5.4393e-04\n",
      "Epoch 3612/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6334e-04 - val_loss: 5.4100e-04\n",
      "Epoch 3613/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6325e-04 - val_loss: 5.4138e-04\n",
      "Epoch 3614/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6332e-04 - val_loss: 5.4159e-04\n",
      "Epoch 3615/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6329e-04 - val_loss: 5.4265e-04\n",
      "Epoch 3616/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6324e-04 - val_loss: 5.4297e-04\n",
      "Epoch 3617/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6330e-04 - val_loss: 5.4310e-04\n",
      "Epoch 3618/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6331e-04 - val_loss: 5.4154e-04\n",
      "Epoch 3619/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6325e-04 - val_loss: 5.4139e-04\n",
      "Epoch 3620/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6341e-04 - val_loss: 5.4252e-04\n",
      "Epoch 3621/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6329e-04 - val_loss: 5.4197e-04\n",
      "Epoch 3622/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6331e-04 - val_loss: 5.4305e-04\n",
      "Epoch 3623/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6327e-04 - val_loss: 5.4048e-04\n",
      "Epoch 3624/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6323e-04 - val_loss: 5.4279e-04\n",
      "Epoch 3625/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6326e-04 - val_loss: 5.4199e-04\n",
      "Epoch 3626/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6320e-04 - val_loss: 5.4191e-04\n",
      "Epoch 3627/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6335e-04 - val_loss: 5.4233e-04\n",
      "Epoch 3628/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6329e-04 - val_loss: 5.4190e-04\n",
      "Epoch 3629/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6319e-04 - val_loss: 5.4265e-04\n",
      "Epoch 3630/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6323e-04 - val_loss: 5.4220e-04\n",
      "Epoch 3631/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6325e-04 - val_loss: 5.4049e-04\n",
      "Epoch 3632/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6324e-04 - val_loss: 5.4273e-04\n",
      "Epoch 3633/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6326e-04 - val_loss: 5.4256e-04\n",
      "Epoch 3634/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6323e-04 - val_loss: 5.4243e-04\n",
      "Epoch 3635/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6322e-04 - val_loss: 5.4110e-04\n",
      "Epoch 3636/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6330e-04 - val_loss: 5.4002e-04\n",
      "Epoch 3637/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6324e-04 - val_loss: 5.4111e-04\n",
      "Epoch 3638/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6322e-04 - val_loss: 5.4233e-04\n",
      "Epoch 3639/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6321e-04 - val_loss: 5.4135e-04\n",
      "Epoch 3640/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6322e-04 - val_loss: 5.4310e-04\n",
      "Epoch 3641/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6323e-04 - val_loss: 5.4274e-04\n",
      "Epoch 3642/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6320e-04 - val_loss: 5.4258e-04\n",
      "Epoch 3643/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6317e-04 - val_loss: 5.4333e-04\n",
      "Epoch 3644/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6320e-04 - val_loss: 5.4149e-04\n",
      "Epoch 3645/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6319e-04 - val_loss: 5.4355e-04\n",
      "Epoch 3646/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6324e-04 - val_loss: 5.4301e-04\n",
      "Epoch 3647/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6322e-04 - val_loss: 5.4368e-04\n",
      "Epoch 3648/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6319e-04 - val_loss: 5.4081e-04\n",
      "Epoch 3649/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6316e-04 - val_loss: 5.4199e-04\n",
      "Epoch 3650/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6319e-04 - val_loss: 5.4244e-04\n",
      "Epoch 3651/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6319e-04 - val_loss: 5.4226e-04\n",
      "Epoch 3652/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6315e-04 - val_loss: 5.4121e-04\n",
      "Epoch 3653/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6323e-04 - val_loss: 5.4294e-04\n",
      "Epoch 3654/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6316e-04 - val_loss: 5.4111e-04\n",
      "Epoch 3655/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6315e-04 - val_loss: 5.4375e-04\n",
      "Epoch 3656/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6315e-04 - val_loss: 5.4138e-04\n",
      "Epoch 3657/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6308e-04 - val_loss: 5.4047e-04\n",
      "Epoch 3658/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6316e-04 - val_loss: 5.4190e-04\n",
      "Epoch 3659/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6318e-04 - val_loss: 5.4208e-04\n",
      "Epoch 3660/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6314e-04 - val_loss: 5.4140e-04\n",
      "Epoch 3661/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6313e-04 - val_loss: 5.4222e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3662/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6309e-04 - val_loss: 5.4131e-04\n",
      "Epoch 3663/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6324e-04 - val_loss: 5.4309e-04\n",
      "Epoch 3664/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6310e-04 - val_loss: 5.4331e-04\n",
      "Epoch 3665/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6314e-04 - val_loss: 5.4230e-04\n",
      "Epoch 3666/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6308e-04 - val_loss: 5.4263e-04\n",
      "Epoch 3667/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6305e-04 - val_loss: 5.4206e-04\n",
      "Epoch 3668/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6314e-04 - val_loss: 5.4237e-04\n",
      "Epoch 3669/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6308e-04 - val_loss: 5.4247e-04\n",
      "Epoch 3670/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6316e-04 - val_loss: 5.4432e-04\n",
      "Epoch 3671/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6307e-04 - val_loss: 5.4457e-04\n",
      "Epoch 3672/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6318e-04 - val_loss: 5.4172e-04\n",
      "Epoch 3673/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6311e-04 - val_loss: 5.4130e-04\n",
      "Epoch 3674/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6304e-04 - val_loss: 5.4129e-04\n",
      "Epoch 3675/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6309e-04 - val_loss: 5.4126e-04\n",
      "Epoch 3676/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6307e-04 - val_loss: 5.4267e-04\n",
      "Epoch 3677/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6307e-04 - val_loss: 5.4488e-04\n",
      "Epoch 3678/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6310e-04 - val_loss: 5.4152e-04\n",
      "Epoch 3679/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6308e-04 - val_loss: 5.4180e-04\n",
      "Epoch 3680/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6308e-04 - val_loss: 5.4365e-04\n",
      "Epoch 3681/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6306e-04 - val_loss: 5.4139e-04\n",
      "Epoch 3682/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6299e-04 - val_loss: 5.4459e-04\n",
      "Epoch 3683/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6311e-04 - val_loss: 5.4169e-04\n",
      "Epoch 03683: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8818b956a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algoritmo='RMSprop'\n",
    "experimento=\"scaled_{}_encoder_without_bias_tanh_tanh_lr_{}\".format(supermax,factor_aprendizaje)\n",
    "tensorboard=TensorBoard(log_dir=\"/home/rgadea3/EXPERIMENTOS/nuevas_investigaciones_2018/experimentos/logs/{}{}{}{}\".format(encoding_dim,algoritmo,experimento,datetime.now()))\n",
    "#modelCheckpoint=ModelCheckpoint(\"/home/rgadea3/EXPERIMENTOS/nuevas_investigaciones_2018/experimentos/logs/\", monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "early_stop=EarlyStopping(monitor='val_loss', min_delta=0, patience=500, verbose=2, mode='auto', baseline=None)\n",
    "autoencoder.fit(x_train_scaled, x_train_scaled,\n",
    "                epochs=10000,\n",
    "                batch_size=200,\n",
    "                shuffle=False,\n",
    "                callbacks=[tensorboard, early_stop],\n",
    "                validation_data=(x_test_scaled, x_test_scaled))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15170/15170 [==============================] - 1s 72us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0005416890020614518"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.evaluate(x=x_test_scaled,y=x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save_weights('../redes_compresoras/compresor_python_{}{}{}{}'.format(encoding_dim,algoritmo,experimento,datetime.now()))\n",
    "#np.savez('../redes_compresoras/maxmin_python_ver_rms_prop_scaled_min_max_ver2', min_max_scaler.data_max_, min_max_scaler.data_min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8818b95518>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "standard_scores = encoder.predict(x_test_scaled).ravel()\n",
    "#regularized_scores = encoded_regularized.predict(x_test).ravel()\n",
    "sns.distplot(standard_scores, hist=True, label='standard model')\n",
    "#sns.distplot(regularized_scores, hist=False, label='regularized model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some images\n",
    "# note that we take them from the *test* set\n",
    "# encoded_imgs = encoder.predict(x_test_min_max)\n",
    "# decoded_imgs_scaled = decoder.predict(encoded_imgs)\n",
    "#decoded_imgs_scaled = autoencoder.predict(x_test_min_max)\n",
    "decoded_imgs_scaled = autoencoder.predict(x_test_scaled)\n",
    "decoded_imgs = supermax*(decoded_imgs_scaled+1)/2\n",
    "#decoded_imgs = min_max_scaler.inverse_transform(decoded_imgs_scaled)\n",
    "#decoded_imgs = autoencoder.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2805\n"
     ]
    }
   ],
   "source": [
    "n = 6  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    idea=np.random.randint(1,x_test.shape[0])\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[idea].reshape(40, 16).transpose(),vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[idea].reshape(40, 16).transpose(),vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "print(idea)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6296, 3840)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filename = '../datos_octubre_2018/p_OF_5mm_161mm003.h5'\n",
    "conjunto_datos_test=pd.read_hdf(filename,'MC');\n",
    "conjunto_datos_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6296, 3840)\n",
      "(6296, 3840)\n"
     ]
    }
   ],
   "source": [
    "L1A=6;\n",
    "# hay tres L1 con 640 sensores (40*16)\n",
    "L1B=0;\n",
    "# hay dos L1 con 640 sensores (40*16)\n",
    "X_trained=conjunto_datos_test.values;\n",
    "x_trained=X_trained;\n",
    "\n",
    "for i in range (X_trained.shape[0]):\n",
    "    idea1=X_trained[i,:].reshape(img_rows,(L1A*img_cols));\n",
    "    ideat=idea1.transpose();\n",
    "    idea2=ideat.reshape(1,(L1A*img_cols)*img_rows);\n",
    "    x_trained[i,:] =idea2;\n",
    "x_tested = x_trained;\n",
    "print(x_trained.shape)\n",
    "print(x_tested.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vamos a procesar y comprimir con la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora los particionamos y pasamos por las redes de compresión. Hay una red la A que se utiliza 5 veces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(x, derivative=False):\n",
    "  return x*(1-x) if derivative else 1/(1+np.exp(-x))\n",
    "ideaA=np.zeros((L1A,input_output_dim_A))\n",
    "\n",
    "cara_externa=x_tested[:,0: L1A*input_output_dim_A] \n",
    "cara_externa_reconstruida=np.zeros((x_tested.shape[0],L1A*input_output_dim_A))\n",
    "for i in range(x_tested.shape[0]):\n",
    "    for k in range(L1A):\n",
    "        ideaA[k,:]=x_tested[i,k*input_output_dim_A:k*input_output_dim_A+input_output_dim_A]\n",
    "    #ideaA_scaled=min_max_scaler.transform(ideaA)\n",
    "    ideaA_scaled=(2*ideaA/(supermax)) -1\n",
    "    salida_reconstructed_1_scaled = autoencoder.predict(ideaA_scaled)    \n",
    "    salida_reconstructed_1 = supermax*(salida_reconstructed_1_scaled+1)/2\n",
    "    #salida_reconstructed_1 = min_max_scaler.inverse_transform(salida_reconstructed_1_scaled)     \n",
    "    #salida_reconstructed_1 = ideaA\n",
    "    \n",
    "    #entrada_imgs_A=(ideaA-min_A.transpose())/(max_A.transpose()-min_A.transpose())\n",
    "    #entrada_imgs_A=(ideaA) #he quitado el escalado\n",
    "    #encoded_imgs_A = sigmoid(np.dot(entrada_imgs_A, Encoder_weights_A) + Encoder_biases_A)\n",
    "    #decoded_imgs_A= (np.dot(encoded_imgs_A, Decoder_weights_A) + Decoder_biases_A)\n",
    "    #print(decoded_imgs_A.shape)\n",
    "    #salida_reconstructed_1 = decoded_imgs_A*(max_A.transpose()-min_A.transpose())+min_A.transpose();\n",
    "    #salida_reconstructed_1 = decoded_imgs_A #quito el escalado inverso    \n",
    " \n",
    "    hola1=np.reshape(salida_reconstructed_1,(L1A*input_output_dim_A))\n",
    "\n",
    "    #print(hola.shape)\n",
    "    salida_total=hola1\n",
    "    #salida_total[salida_total<0]=0\n",
    "    #print(salida_total.shape)\n",
    "    cara_externa_reconstruida[i]=salida_total\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizamos los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos todos los sensores: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACM0AAAHSCAYAAAD1iK7WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3c2PJddZB+BTdau7p/v24Mw4k56QRLGCBAlCoAhBJEQkUBAIIRYsWbHPMv8GGzYIlvkDsmCPFyCUBWyIAgJLyKNxrCTdHsd20nOn5+N2FQvLcSLbfd47U133432e7bx9znvr3lt9ztGva5phGAoAAAAAAAAAAGTSrrsBAAAAAAAAAACYmtAMAAAAAAAAAADpCM0AAAAAAAAAAJCO0AwAAAAAAAAAAOkIzQAAAAAAAAAAkI7QDAAAAAAAAAAA6QjNAAAAAAAAAACQjtAMAAAAAAAAAADpCM0AAAAAAAAAAJBOt0rxfnMw3Cjz6+oF+ARNW8+3DX0/QScAAACxPUopsX1KaKy9wPHFpu6JLut9jbmfs38EAAAAKOW8vPv2MAx3anUrhWZulHn5WvON5+8KeC7tUT2s1i8WE3QCAAAQ26OUEtunRMZqT6rnG6U8uoi0NLn+/GG9ZsT9nP0jAAAAQCmvDt95I1Lnv2cCAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACCdbt0NAHX9YrHuFgCADdTO59WabV5H7Prr21bd3ZNqzfL0bIJOeB5jfa/am8ex+SJ1R4f1mkcX1ZL3vv5KfZxSyvJG/e+Hjn/4tFpz4/5PQvP1r9S/M91bP6vWLO/dD80XEfkcRLgHw/aL3g983wEAgCmMdWZRSinlYXDO8WYEAAAAAAAAAIDtIDQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKTTrbsBAACAj9MvFutugY+xPD1bdwu8gMj3qrt7Mt6ER4ejDPPG3/xatebibh8aa/a4XtM9jhyXvByaL6I9e1Cvmc9DY23rvTPy+sZ8bVPPt62m/tzt+uc8YuprsMvXEgAArrKJ+9CoKfdgU+8Z1rFH8aQZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACCdbt0NAAAAz6dfLNbdAvCC2vl8lHHGvB8sT8+qNd3dk9Hm649vVGs+96c/qNa8dHARmu/TB/Vr9fbX6+/L9/7t10PzfeGfn1Zr2pvHobHGsom/P6buaROvwSbyvkxvU69B5PfVpvYOAAAfx35n+p42dV/hSTMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDrduhtgs7TzebWmXywm6ORDm9gTAMDziqxtSrG+AT60ifeD5elZqO7JX/xetebiduBo4tu3qiX3/vwi0lL5pz/4h2rN3z/442rN8MXYfN2jvlqzfOWkWtP+1+uh+cZiLw78orG+793d+v0u+jtmau6LAADrt+tnq7v++ja1b0+aAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACCdbt0NcLV2Pq/W9IvFBJ2sz66/PgAgF2sb1iGyryjF53MdNvGad196pVrTnz0IjXX45nm15uL2rWrN8rA+1//90bcDHZXyLxf178Orr361WtOEZiullPp7vDzaq9Z0wc9K9PsO28x52fZanp6tu4Xn5jM1Pd91AMhl6t/9m7jWmPr1jWmb12WeNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApNOtu4FN0s7n1Zp+sZigkzzzAQAA1886f1ybuHeM9FRKrK/lvfujzVdef7Na8qmj/WrN2e8fV2u+8o/fDLX09FZfrdm/aKo1t//3MjRf99bPqjXt2YP6QCO+x93dk2rN8vQsNN+22sTv8Tab+np6byAH33UA2A5j7QfG/N1vz1dKe7N+lrKJou9L6GzqYWxOT5oBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANLpVilu9rrSffrkyprl6VlorHY+X2XqT9QvFqOMAwAAABGbuA/dxJ5KifXV3a+fI3wuUPP4Nz8f6uknv3VQrfnU68+qNYdvnofmG8uY73H07GaXbep3Zlu5njGR81DXEgCAFzX1unPKNWw0Y9DePK7WTL32HvN96e5endnYVO3JnXpR8MhizPfPk2YAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHS6laov+9KfP7x6wLsnoaFq45RSSr9YhMYay9TzAQAAwJTa+bxaE9kbT75fD5wh7P/7a6GxPvv2F160nfe9/mas7uZxtWTM6znWewysZte/e7v++gAAdskur8u2ef886liBc5KxtIFzjVJKaU/u1IseXbxgN78wX+D9K8HL5EkzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKTTrVI89H3pF4sra2r//oF2Pl9l6q0SfW3RawUAwHYYc41rrQisYpv3of35w2nn+/5r084XuOaR9y/63k35Hm/z5w7G5nMOALA9xtyDbeJ8TH89x3qPo/vs9uZxvejosFrSnz0YZZzoWJG+Q6+tlLI8PQvVRXjSDAAAAAAAAAAA6QjNAAAAAAAAAACQjtAMAAAAAAAAAADpCM0AAAAAAAAAAJCO0AwAAAAAAAAAAOkIzQAAAAAAAAAAkI7QDAAAAAAAAAAA6QjNAAAAAAAAAACQTrdKcdO2pT2aX1nTLxahsSJ13d2Tas3y9Kxa086v7nmVniJjRa8BAAC7Zcx1oHUnsIpNvR9MeS+L7v2ntsv3823tG1jdlPdq9xYA4LpNvd7Y9fXNtq7xxux7rJxBe/M4NF85OqyW9GcP6vOd3KnWLO/dj3QUu57nD+vjBK9B6ByoPt37Y8XKAAAAAAAAAABgdwjNAAAAAAAAAACQjtAMAAAAAAAAAADpCM0AAAAAAAAAAJCO0AwAAAAAAAAAAOkIzQAAAAAAAAAAkI7QDAAAAAAAAAAA6QjNAAAAAAAAAACQTrdK8dD3pV8srquXj1ieno0yzpg9jzlWO59POh8x3hcAYBNE1hvbum6J9F3KeL1PPR+U4nO+jvmic01973RvidnW32nAanyPAQB2z5RnG9u8Xw+d957ciQ326GKc+R4dV2u6uyehlvrP3KrXfP+1es2I5ztRnjQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDrdKsVN25b2aD7KxP1iMco43d2Tas3y9GyUucY21jVgXN4XAGBbbOu6Zeq+t/U6sd18zqfXzsc5r2A9pv4MRz4v0Z7GHAsAAMhp1/cV2/r6omcNkd4jYy3v3Q/NFxkr1PvRYb3m0UWgo1L6779WrYlkO/rzh7H5Rvy8eNIMAAAAAAAAAADpCM0AAAAAAAAAAJCO0AwAAAAAAAAAAOkIzQAAAAAAAAAAkI7QDAAAAAAAAAAA6QjNAAAAAAAAAACQjtAMAAAAAAAAAADpCM0AAAAAAAAAAJBOt+4GrtLO59Wa/vzhBJ2sJtJ3KaX0i8U1dwIAwKaJrhUjrCdhPUJ7Vd/PyUWv+Zj34U3k8xkz5jVwPQHg+Vi3AHxo1+932/r6pt47dndPQmMtT8/qY33plfo49+6H5otof/vL1Zr+9TfrNcFrHrpWPw4N5UkzAAAAAAAAAADkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA63bobeFH9YrHuFj5iE3sCAGAzWCvC9vM93m6b+P6183m1Jtr3Jr4+AICPY90C8KEx94Vsr+XpWagu8nlZ3rv/gt2spn3r3XrRzeNqSfRzHr1WEZ40AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA63SrFQ9+XfrG4sqadz0NjRepqc63DtvZNnPcYAACYiv1HzK5fp23uHQAAgBe3zfvCXd+zj8V1KmV5ejbaWKFcysPgWC/WCgAAAAAAAAAAbB+hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0mmGYYgXN82DUsob19cOAAAAAAAAAAC8kC8Ow3CnVrRSaAYAAAAAAAAAAHaB/54JAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEinW6V4vzkYbpT5dfUCAAAA7JCmaao1Q2Sctj5OaYN/FxToqSwvA/MFximlDJd9qK4+UORKAQAAAFBKKefl3beHYbhTq1spNHOjzMvXmm88f1cAAADA+rSzaafb36vWDIEwSHtwUK1p5kehnkqgp/6d9+rzHeyHput/eh6qqxmWz0YZZy0EfoAsIsFM90QAAPhkkTV1KaF19avDd96IDOW/ZwIAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANLpVv6Jprn634fhOVsBAAB+rrbuLsXaG7KI3A+ihj4wX/3va5q94HHC3l61ZHY8r49zeKNacnn7ONJRefbSQbXm4Ef1+Yb92DWYdfW6/r2f1gcaZqH5hj7wuyHyOQAAgF3kvAVgN4Tu57GhPGkGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHS6lX9iGK7+96YZZxwAAMjMehn4QOR+ENyLN7NZoKj+9zXN/n5svhs36kVd/Wji6RduVWt+8CeBuUop+z+tX6vjz7xcrbl5/yI0XxN4/4bLvj5Q5L0rpZR+Gasbg99VAL9sxN/Z7rEA18T9FWA1Y65fo2ONNV+QJ80AAAAAAAAAAJCO0AwAAAAAAAAAAOkIzQAAAAAAAAAAkI7QDAAAAAAAAAAA6QjNAAAAAAAAAACQjtAMAAAAAAAAAADpCM0AAAAAAAAAAJCO0AwAAAAAAAAAAOl0o484DKMPCQAAAGk1TaAm+DcxgbrmxkG95ugwNt/NebWkD8z3wz+sz7d85SLU0p995b+rNf/xd79brXn3y0eh+T69uF0veue9es3lZWi+kMjnZejHmw+ADzk/BwDgk0TOgKKmXndGeo/0FL0GofliQ3nSDAAAAAAAAAAA6QjNAAAAAAAAAACQjtAMAAAAAAAAAADpCM0AAAAAAAAAAJCO0AwAAAAAAAAAAOkIzQAAAAAAAAAAkI7QDAAAAAAAAAAA6QjNAAAAAAAAAACQTre2mZumXjMM198HAABEWL8C1yFwb2lms2rNcHkZm262Vy969qxec7kfmq+/dVyteXL7oFrz8v/UX99f/fW/hnr61u171Zrf+MuvVGv2/rP+2koppVn21ZphCNT0sd8xTVv/TEXHAgCAa+e8BdgFm3gvi/QUGif2HJbQeUTk/Co4XwmcpUR50gwAAAAAAAAAAOkIzQAAAAAAAAAAkI7QDAAAAAAAAAAA6QjNAAAAAAAAAACQjtAMAAAAAAAAAADpCM0AAAAAAAAAAJCO0AwAAAAAAAAAAOkIzQAAAAAAAAAAkI7QDAAAAAAAAAAA6XQr/0TTXP3vwxAbJ1oHAACbYOr1a23dXYo1NeyCwPd46APf9Sb2NzHDZV+taeeH9YGWy9B8sx+/U625/NXPVWsefLX++r51+16opx8sH1Zruu8dV2s++92L0Hz94V69aDarljTlMjRf6PMytcjvtAi/9wAAdo81HrDJxtrPjj1WaL76WUrT1nsa9Zwhcn411M+uSimlCZyllNhQnjQDAAAAAAAAAEA+QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKTTjT5i08TqhmH0qQEAYGdYLwMfGPp6TRP8m5jIWH3g/rO/F5vu5lG1Zv7Gw2rNzZdfqtb8zt9+M9TT4YP6NdivT1f2frIIzdc8flqtuQxc8yHyvrxfGKsbgzMgAAAACGlms2pNdO8fGSs2Tv08KbjzL8NyGZgv0PcQnDF6FhbgSTMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDrdyj/RVHI2Qx8cp6nXDENsLAAAANhGkb1xZJh2nHFKKWVYLuvzHd4IjdW8d16v6epHE3e++7Rac3nrKNTT4vOH1Zr5j55Ua5rzR6H5hkeBuuhZSkTt3Gbs+SKcAQEAALBp2tm6O/iIMc93JjcLXM9+xL3/iGcbnjQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKTTjT5iM2YOpx9nmGEYZxwAPqpp6jXuwwAAH2+kddJweTnKOKWUUp4t6zXnD2NjdYFjh4ODes3jJ9WS2dmDQEOlvPTWrXrRk6fVkuHx49B8w0W9bui3dL0c/fxG9gwA/DLnLQAA16sPnKW0s/Hmi+QohmA+IlI3q/c+XI6UxyilNLP66xtKff0aPSNpAq8vypNmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEinW/knhv7qf292PIfTNPWaYbj+PgA2hXseAMD1GnMfGhkrYHi2jNVdXlZrmmV9rPalX6nW9I8r5xUfePudes1sVi0ZAn2XErsGsYGCry801sRreHsGgNW5dwIAXK/QeUtwLx7ISITOSPZi8Y0m0ntb76k5OqjW9I8eRVoqQ2T92tb7boZxzq5WseMJFwAAAAAAAAAA+CihGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0ulW/ommkrMZ+udsZYc0TaxuGMYZKzIOAADbxToQ+MBYe8foWGPu6/v63+oM/bJac/n2O2N0875ZoKdlvacym43QzAcTOkuZ/Pee37MAAAC7K3pOUh1nvGeQNO1IPZVShsB+tenrZw3Dkyf1cYLXcrgc6WxjzPOWIE+aAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADS6dbdwEZpmnHGGYZxxhl7LIAPRO537j8AANtjxLXbsFzWi8L758sX6uXnIq8v2NNwOc7fD7X7s9h8T5+OMl/Ytq7jp+57W68TsNmctwAA8AmGvr4ObLvg2Ubg7GZo6ucfkdmG4Pq12atHT4ZngTOnoGasbEfxpBkAAAAAAAAAABISmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgHg/9u7Y+S2YSAKoESkK6TO/Y+VOgdwEZHrKl0mXDmQKPG/1xrCLqQZmJD/wAAAAAAAAABxhGYAAAAAAAAAAIhzvfsV2/rvn4/xxVb+omp/zDvXAzhKZ78D4Fj2auAROmfazv7T3aNe8QxdW2PM/vq2j49mvSfv57M+YwDuZ38FADiXzncIy7IsY85dJXW7Pbfeur++cenVqt+N3jvv504c5Y9tm/cOAI8RAAACzUlEQVTs7aYZAAAAAAAAAADiCM0AAAAAAAAAABBHaAYAAAAAAAAAgDhCMwAAAAAAAAAAxBGaAQAAAAAAAAAgjtAMAAAAAAAAAABxhGYAAAAAAAAAAIgjNAMAAAAAAAAAQJzr0Q2c0hi9cVVz5urMAwAAAM8+Pz6z3sxa73wWf9W+AAAA4Flm/R2+XW9r1Nu/z6TWtVdv7K9vXC5z6nXW1jXzPZjYl5tmAAAAAAAAAACIIzQDAAAAAAAAAEAcoRkAAAAAAAAAAOIIzQAAAAAAAAAAEEdoBgAAAAAAAACAOEIzAAAAAAAAAADEEZoBAAAAAAAAACCO0AwAAAAAAAAAAHGud79ijAe08QK1uvWq5swDAAAAr2jW2fidnX19AHAWnlsAgDMZzTtPatsfctsf06lX27xnqfGt0dMB3DQDAAAAAAAAAEAcoRkAAAAAAAAAAOIIzQAAAAAAAAAAEEdoBgAAAAAAAACAOEIzAAAAAAAAAADEEZoBAAAAAAAAACCO0AwAAAAAAAAAAHGEZgAAAAAAAAAAiCM0AwAAAAAAAABAnOv0GUczh1PbnHpVc+Y5whj7Y955fQAAALwf59DX1PkOYVl8fgBk8XsPAPiqznNE9yw+y6wMxUwTe6p12lRTuWkGAAAAAAAAAIA4QjMAAAAAAAAAAMQRmgEAAAAAAAAAII7QDAAAAAAAAAAAcYRmAAAAAAAAAACIIzQDAAAAAAAAAEAcoRkAAAAAAAAAAOIIzQAAAAAAAAAAEGdUVX/wGL+WZfn5uHYAAAAAAAAAAOC//Kiq73uD7grNAAAAAAAAAADAGfj3TAAAAAAAAAAAxBGaAQAAAAAAAAAgjtAMAAAAAAAAAABxhGYAAAAAAAAAAIgjNAMAAAAAAAAAQByhGQAAAAAAAAAA4gjNAAAAAAAAAAAQR2gGAAAAAAAAAIA4QjMAAAAAAAAAAMT5BJ0ZmMmjKfzHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 2880x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 1  # how many digits we will display\n",
    "plt.figure(figsize=(40, 10))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    idea=np.random.randint(1,x_tested.shape[0])\n",
    "    idea=1890\n",
    "    idea= 4299\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(cara_externa[idea].reshape(L1A*img_cols, img_rows).transpose(), vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(cara_externa_reconstruida[idea].reshape(L1A*img_cols, img_rows).transpose(), vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos ahora L1 a L1, teniendo en cuenta que hay de dos tipos:\n",
    "L1A (con 36 columnas )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACM0AAAG9CAYAAAAMKhNZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3c2PJMlZB+DIrOruma4e1jPrcY+xLVZGAhshkIXACGEJZIsPIQ4cOXH30f8GFy4IjubCyQfOeC2BkIWWC5ZBsBLa0axXtrs9u+uPmZqej+pMDrYRkrfe6J7s7Kyq93mub0VkVE52dETsr3Obvu8LAAAAAAAAAABk0k49AAAAAAAAAAAAuG5CMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOvPLfHi/OehvlMVYY4GN1bRxvqzvumsaCVN4VL7/bt/3d6cexxTM+0BGmef9Usz9sKuG7mlq7cte5Xhh6j3TeXz9H3XvmfsHzP32zMC2eVqW5Xn/rJl6HFOx5gcyct5j7gfyuejcf6nQzI2yKJ9tPv/yo4It1R7GC4luubymkTCF1/uvvD31GKZi3gcyyjzvl2Luh101dE9Ta98eV84fnpzF9ZF1jx6H9X98/Hfm/gFzvz0zsG3e6L829RAmZc0PZOS8x9wP5HPRud//ngkAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhnPvUAYBt0y+XUQwAAuBZN25b2cLG2vunronaxfuylbP74N9383nFYX52cXtNI8hn6bLe3jgbVy+HNuP7kLCz/4HOvhfXVjfhveo6+/Tys33jwXljvXouf3fKvcXnXNQf7Zf7x19bWV/cfDOq/9vzWmLvh5VgXAQAA22zoeUJ5fMHrDLsKAAAAAAAAAABsH6EZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgnfnUAwAAALgq3XI59RB22urkdOohpFV7tuf3jodd4PDmoOZv/8UvhvWze11Ynz2N+58/rR1fvFqpE3qxKt3pw7XldrEIm2/63Dv2+Lf9/gw15vff9Xs79vfb9vsDAACbbur9Zs2273eva0/jTTMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQzn3oAAADA5ui7rnTL5dTDgK3TLhaD2g/9uVudnIb1+b3jQf13RzfC+sf+4Fth/ZWDs7D+4YP4+7/7ufj+fuNffimsf+Krz8N6erO2tLeORut+6t8rY19/6u83tTG//67f26m/X+1319TjAwCATbfr+82xr78pexJvmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIJ351APg6rSLRVjvlsudvj4AQCnWJMBmmnruWZ2chvVnf/KbYf3sTuX44Mu3w/L9Pz4L6//wO38T1v/64e+H9f4X4v7nT7qwnl2/v1dWrx2vrbf/8dao1/e7G6Yx9Gdrfm/9vFFK/XfP2KK5pXnib0kBANj+/ei2j39Txmd3AAAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOvOpB5BJu1iE9W65vKaRjGPbxw8A7AZrElhv1/ckU5r63s0/+VpY704fhvWb7zwK62d3bof11c2wXP7n974c1v/pLH42X3/9M2G9iS9fSvFsR/q2KavDvbX1eeX5rs0tMBa/16a1Ojmdegih6N+/77trHAnbxtwCALtj7N/rU68bxh7/UNuybvKmGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0plPPYDr1C4WYb1bLke9/rb3DwAAbDd7hvWm3i8Ovf7q/oNB/Ze33gnLHzrcD+unv3UU1j/9t18M689vd2F9/6wJ63f++zysz7/3o7CeXbt8WvbfeHP9BwY+n/N7x2F9dXIa1jfd1PPHpovuz9B7k/3eAuMwtwDA5hi63xr6e33X93vtrfg8Z2q1+1s973p8set40wwAAAAAAAAAAOkIzQAAAAAAAAAAkI7QDAAAAAAAAAAA6QjNAAAAAAAAAACQjtAMAAAAAAAAAADpCM0AAAAAAAAAAJCO0AwAAAAAAAAAAOnML/PhZm9e5h8+XltfnZyG7dvF4jKX+xndcjmoPQAAAHyQqfebm379+YN4v/+xSv3pr3w8rL/3qwdh/UNvvQjrN995FNYZZujzWTsv2nZT//xuusz3p3YWmvneAACwO6J179A179hr5tqavb11FNanHl/1POfe+mzHJmiP78YfqBwnXNX996YZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSmV/q0+dd6R49Xt/ZveOwedS2lFK65fJSw7mssfsHAACAMbSLRViv7XdH329X9vv7b7wZ1j/67ieGDeCtd+L6raNh/e+4vusGPSNDn0/YVtv+7G/7+AEA2AzbvG4cOvax19SD21fOa4ZqK+ct7fHduIMnZ8OuX7n/5YJf35tmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIZ36ZD/ddV7rlcm09qpVSSrtYXOZyG6c2/tr3BwBguKFrSms2YBNt+n6ze/R43P6/+ea4/Zv7Q03blvZw/TNYu39j399N//kgL88eAABXYew9jz3Vy9v0/W6tfXvrKB7A4c34+qcPR21fG1+tvjo5DesX5U0zAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkM7/Mh5u2Le3hYm29Wy7D9rX6/N5xWF+dnIb1drF+bBe5/tD2AACMb+iarLbmK48HdQ/wUqbeb469H67OvSMz98f6rpv8GYxs8thgm409t/vZBQC4mLHXTdu8Ltv0NefQ8Q3NL7S3jsJ6ObwZX//0Ydz/8d2wvrr/IG5fuz+P4gOZ2ve7qvMeb5oBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACCd+WU+3Hdd6ZbLscZSVieng9oPHdvQ9u1iMWr/mbm3AMBVsW6INW1b2sP1a6+p79/Y60LrTtbZ9Wdv6v7H/v5+dnOb+ucLdpWfHQAAxrbp5y2Tn6cc3407eHI2rP8nR2F9fu847v8jt+P6N9+M6wPPky7Km2YAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhnfpkPN21b2sPFS1+sWy5fum0ppczvHYf11cnpoP6HGvr9WM+9BQC4Hn3XbfTaa+yxbfJ3Z1qevWHaxcufJcBQY/981Z7v2vWHtgcAABhim/ckmz72sfeLq/sPBrWvntcc3ozrT87CcvfNN8N6Lf/RPXoc16/o39ebZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASGc+9QD+v3axCOvdo8fXNJIPVh3fcnlNIwEAYJ3amq1q2iUnMBH7vXHV7t/guZtJZf/5Gfr9dv3+AMBVyb7mABjLNs+fmz72sfeL83vHYX11chq3/+Rrcfv7D8J6Tftrnwrr3VvvxPWB3798Ny7/lDfNAAAAAAAAAACQjtAMAAAAAAAAAADpCM0AAAAAAAAAAJCO0AwAAAAAAAAAAOkIzQAAAAAAAAAAkI7QDAAAAAAAAAAA6QjNAAAAAAAAAACQznzqAVxGt1ymvj4AAHXWbMDLMHdMy/2fVtO2pT1crK3X/n38+wEA18GaA2Ac7WL9frAU8+8mW52chvXav+3q/oMrHM0HXP97348/cOsoLNeevdr3vyhvmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIJ35ZT7cd13plsu19XaxCNvX6lHf12HTx5eZfxsAAGCTZd+zZP/+26523gMAAMDu2uT9YPbzhl3//quT00Hta/enPL5gP4NGAQAAAAAAAAAAW0hoBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASKfp+/7iH26ah6WUt8cbDsBG+oW+7+9OPYgpmPeBpNLO+6WY+4G0zP3mfiAX8755H8jH3G/uB/K50Nx/qdAMAAAAAAAAAADsAv97JgAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANKZX+bD+81Bf6MsxhoLwEZ6VL7/bt/3d6cexxTM+0BGmef9Usz9kFXTNGG9r7Vv4/alrfzNTuX6ZXVe6b8y/vMurD/q308+99/obzTB3N/XngCA7fK0LMvz/lnll8/usuYHMnLeY+4H8rno3H+p0MyNsiifbT7/8qMC2EKv9195e+oxTMW8D2SUed4vxdwPG6udjdv9/l5Y7yuhifbgIKw3i8N4AJXrd+//IO7/YD9u/8NHYf2rz/8+99zfLMpv7/3R2nq/enGNo3kJQj3AJb3Rf23qIUzqRlmUz7ZfWP8B8yqwg5z3OO8BtlDtj6wq69aLzv3+90wAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkM790i6ZZX+v7AUMBAIBrEK1nSynFkhYYQ23uqem7Sv/x38Q0e5Xt/95eWJ4dLeL2N2+E5fM7R2H9xSsHYf3gO3H//X78/Wbzyvf/blzedU0ppZkFz1A/C9v3XeWXZ+35BQCAoZz3AORzRXO/N80AAAAAAAAAAJCO0AwAAAAAAAAAAOkIzQAAAAAAAAAAkI7QDAAAAAAAAAAA6QjNAAAAAAAAAACQjtAMAAAAAAAAAADpCM0AAAAAAAAAAJDO/NIt+n59rWlevi0AAFwHa1JgCrW5p7KfbmazSvv4b2Ka/f24fuNG3P88Pj54/onbYf1bX4j73/9h/P2PPvJqWL/14CysN+b+UF9K6c+79R+oPX/d6krH8zP8+wFcPef8wK4xNwFcv6Hrxlr7miua+71pBgAAAAAAAACAdIRmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdOZX2lvfX2l3AAAAsBOaplKv/E1Lpd7cOIjrhzfj/m8twnJX6f/bvxv3v3rtLKz/4af/M6z/21/9Rlj//qcOw/qHl3fCejmJy+mdnw9rX3u++25Y/wBcLef8AADboXbeVDP2uq82vtr1q+dptf7j8k950wwAAAAAAAAAAOkIzQAAAAAAAAAAkI7QDAAAAAAAAAAA6QjNAAAAAAAAAACQjtAMAAAAAAAAAADpCM0AAAAAAAAAAJCO0AwAAAAAAAAAAOnMr/VqTRPX+/56xgEAwOayZgS2UWXuamazsN6fn1fa78XXf/Eirp/vh+Xu9lFYf3bnIKy/+l/x+P/sz/85rH/pzv2w/st/+umwvvfv8fibVRfW6Uvp19+jvot/9zZt/PzX2gMAkIDzHoCfNfXcWLt+tX38jpbqeUHlPKzWf3SWcRneNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDrzS7domvW1vo/b1uoAADD2mjFaz5ZSiiUr8DIqc1ffVSaXJv6blv68C+vt4mbc/2oVlmfffT+sn//8x8L6w8/E4//Snfth/Vurx2F9/o2jsP7Rr5+F9e7mXlinKWU2C6rnYevq8z222u/2GudVAADjs+YCMhq6Xx3avtp/fJ7TtPH1B58HVK5f+vg8rAnOMkoppcTN/483zQAAAAAAAAAAkI7QDAAAAAAAAAAA6QjNAAAAAAAAAACQjtAMAAAAAAAAAADpCM0AAAAAAAAAAJCO0AwAAAAAAAAAAOkIzQAAAAAAAAAAkM78Sntrmrje91d6OQAAuDRrUmAKfRfXm8rftNTad5W5bX8v7v7WYVhfvP04rN969ZWw/ut/+cWwfvNh/P324+7L3nvLsN48fR53QPgM9bXnq/Z8DuW8CQAAgISa2Sys1/brtfb168fnVZXdeulXq0r/lfH1lSvUztMuyJtmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIZ37pFk2Qs+m7Stsmrvf9pYcDAAAAk6vtd2vN22Ht+9Uq7v/mjbj+g0dxfR4fH9z9+vOwfn77MKwvP34zrC++8yysN4+ehPX+SVynr5/pRKKzolKG9X2h6ztvAgAAYALtbNLLDz1PGt2scn+6gfv1Kzpv8KYZAAAAAAAAAADSEZoBAAAAAAAAACAdoRkAAAAAAAAAANIRmgEAAAAAAAAAIB2hGQAAAAAAAAAA0hGaAQAAAAAAAAAgHaEZAAAAAAAAAADSmV9pb83QDE43rHnfD7w+AFeqaeK6eRsA2BUD1zX9+fmw679YxfVHj+P6vHI8cHAQ158+C8uz04dh/ZXv3Y77f/Y8LPdPn8b1s7ieXl9K323w2rz281XbdwBwtZz3AAD8WFc5z2lnw/qv5S/6Sr6iVp/F4+vPh+U3mlk8/r7E68baWUVTGf9FedMMAAAAAAAAAADpCM0AAAAAAAAAAJCO0AwAAAAAAAAAAOkIzQAAAAAAAAAAkI7QDAAAAAAAAAAA6QjNAAAAAAAAAACQjtAMAAAAAAAAAADpzC/dou/W15otz+A0TVzv++sZB8CuMG8CAPzY0P1mrX1F/2IV18/P48uv4vbtKz8X1runwVlCKaW8+35cn83Ccl8ZX+37URGdBV2o/cj7AvsOgOtl3gUA+LHqeU9lP13JV1TPa/biuEdTG18bX785PAjr3ZMnYb2vrRvbeHxNP+w87KK2POUCAAAAAAAAAACXJzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkM790iybI2fTdgKFsgaaJ630/bnsAAIarrsmuZxhAMmPvF4fux7v4b2r6bhXWz999f9j1Z5Xrr+Lrl9ls2PXZ7TOdsc9jnPcAAADsptp+r9p+2DtMmnbY9fvKfrTp4rOA/tmzuH3l/vTnA88arum8x5tmAAAAAAAAAABIR2gGAAAAAAAAAIB0hGYAAAAAAAAAAEhHaAYAAAAAAAAAgHSEZgAAAAAAAAAASEdoBgAAAAAAAACAdIRmAAAAAAAAAABIZz71AK5V0wxr3/fTtgeYQjR3mtcAAK7GwHVVv1rFH6juh88HXb86/sr1+/Nhf9PT7s/i/p8/H9Q/FZu+Lxh7fJv+/QE+iPMeAICN13fxuqydV85bKudFfROfx9ROk/rKurHZi+Mo/YvKeVZFMzT/8RPeNAMAAAAAAAAAQDpCMwAAAAAAAAAApCM0AwAAAAAAAABAOkIzAAAAAAAAAACkIzQDAAAAAAAAAEA6QjMAAAAAAAAAAKQjNAMAAAAAAAAAQDrzS7foztfXmmbAUEopfR/XN71/gF1UmzsBto15DdhGtf1qbW7b9P1w31Xq8fi7s7NB7SnD7tHQ5xOA62duBgAYX+28oxn2jpN+tRq3//N4/M0s7r9/URlf7f4E0ZRSSum6q1nTetMMAAAAAAAAAADpCM0AAAAAAAAAAJCO0AwAAAAAAAAAAOkIzQAAAAAAAAAAkI7QDAAAAAAAAAAA6QjNAAAAAAAAAACQjtAMAAAAAAAAAADpzKcewFZpmrje9+O2BwCQxvuCAAACbklEQVQAIKex94ub3r/99GZz/wEAANhFQ//7f7X/rtJ//A6U/vy80j4efzObDeu/Nv6aod9v6PV/wptmAAAAAAAAAABIR2iG/23v7pEbhKEojKKMt+A6+19W6mwh5qXKpEN4ZMzPPafFCFXP4PkGAwAAAAAAAADEEc0AAAAAAAAAABBHNAMAAAAAAAAAQBzRDAAAAAAAAAAAcUQzAAAAAAAAAADEEc0AAAAAAAAAABDn9vQZrW2wjTesvWb9qrHzAQAAYA+jz7tHd/b9AwDXcfX7LgDgPFrnHSk1Lx/+WT7eW7/msfue9tG5/pt40wwAAAAAAAAAAHFEMwAAAAAAAAAAxBHNAAAAAAAAAAAQRzQDAAAAAAAAAEAc0QwAAAAAAAAAAHFEMwAAAAAAAAAAxBHNAAAAAAAAAAAQ5/bS1Vqnwal5bP2qsfO31try8aPvHwAAgHPyvMmW/N4BAP987wEAf3r3Bb3n6eHrD/YXO1+/Hi/axyBvmgEAAAAAAAAAII5oBgAAAAAAAACAOKIZAAAAAAAAAADiiGYAAAAAAAAAAIgjmgEAAAAAAAAAII5oBgAAAAAAAACAOKIZAAAAAAAAAADitKpa/+HWvqdp+tpuOwCH9FlV9703sQdzHwgVO/enyewHYpn9Zj+Qxdw394E8Zr/ZD+RZNfufimYAAAAAAAAAAOAK/D0TAAAAAAAAAABxRDMAAAAAAAAAAMQRzQAAAAAAAAAAEEc0AwAAAAAAAABAHNEMAAAAAAAAAABxRDMAAAAAAAAAAMQRzQAAAAAAAAAAEEc0AwAAAAAAAABAHNEMAAAAAAAAAABxfgGxGT+oB5ps+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 2880x720 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = L1A  # how many digits we will display\n",
    "plt.figure(figsize=(40, 10))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(cara_externa[idea].reshape(L1A*img_cols, img_rows).transpose()[:,i*img_cols:(i+1)*img_cols] ,vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax = plt.subplot(2, n, i + 1+n)\n",
    "    plt.imshow(cara_externa_reconstruida[idea].reshape(L1A*img_cols, img_rows).transpose()[:,i*img_cols:(i+1)*img_cols] ,vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  1  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  1  0  1  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  0  3  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  2  2  2  0  1  1  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  3  3  7  4  1  0  0  0  1  0  0  0  0  0]\n",
      " [ 1  3  3  4  9  9  5  2  2  1  0  0  0  0  0  0]\n",
      " [ 3  2 12 21  9 10 11  2  1  1  0  0  0  0  0  1]\n",
      " [ 2  8 15 22 18 31 13  6  1  1  1  0  1  0  0  0]\n",
      " [ 2  9 14 23 28 27 15 11  4  0  0  1  1  1  0  0]\n",
      " [ 2  6  8 22 23 14 13  7  4  0  0  0  0  0  0  0]\n",
      " [ 2  3  6 14 18 14  8  4  1  0  0  0  0  0  0  0]\n",
      " [ 1  5  6  6  5  5  3  3  2  0  1  0  0  0  0  0]]\n",
      "630\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "print(cara_externa[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:])\n",
    "print(np.sum(cara_externa[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  1  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  1  1  1  1  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  1  3  4  2  3  2  1  0  0  0  0  0  0  0]\n",
      " [ 0  2  2  3  6  7  4  2  1  0  0  0  0  0  0  0]\n",
      " [ 1  3  5 12  7 13  9  3  1  2  0  0  0  0  0  0]\n",
      " [ 2  4 13 17 24 30 11  4  1  1  0  0  0  0  0  0]\n",
      " [ 2  6 11 23 35 28  8  7  2  1  0  0  0  0  0  0]\n",
      " [ 1  3  8  8 18 12 10  6  2  1  0  0  0  0  0  0]\n",
      " [ 1  4  5  9 12  5  3  2  1  1  0  0  0  0  0  0]\n",
      " [ 0  2  1  4  3  4  2  1  0  0  0  0  0  0  0  0]]\n",
      "540.9373786449432\n"
     ]
    }
   ],
   "source": [
    "print(cara_externa_reconstruida[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:].astype(int))\n",
    "print(np.sum(cara_externa_reconstruida[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1074.89031088, 1331.38326943, 1139.2623142 , ...,  558.72033215,\n",
       "        934.67915535,  830.96297133])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(idea)\n",
    "np.sum(cara_externa_reconstruida,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,)\n",
      "(401,)\n",
      "[[Model]]\n",
      "    Model(gaussian)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 38\n",
      "    # data points      = 400\n",
      "    # variables        = 3\n",
      "    chi-square         = 32104.1892\n",
      "    reduced chi-square = 80.8669754\n",
      "    Akaike info crit   = 1760.11090\n",
      "    Bayesian info crit = 1772.08530\n",
      "[[Variables]]\n",
      "    amp:  548.305732 +/- 3.99239471 (0.73%) (init = 200)\n",
      "    cen:  100.238518 +/- 0.63384574 (0.63%) (init = 0)\n",
      "    wid:  106.613828 +/- 0.89639325 (0.84%) (init = 100)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(amp, wid) = -0.577\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "veamos_energia=(np.sum(cara_externa_reconstruida, axis=1))-(np.sum(cara_externa, axis=1))\n",
    "n, bins, patches = plt.hist(veamos_energia, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "plt.title(\"Histogram with 400 bins\")\n",
    "plt.show()\n",
    "x=bins[:400]\n",
    "y=n\n",
    "print(n.shape)\n",
    "print(bins.shape)\n",
    "from numpy import exp, loadtxt, pi, sqrt, log\n",
    "\n",
    "from lmfit import Model\n",
    "def gaussian(x, amp, cen, wid):\n",
    "    \"\"\"1-d gaussian: gaussian(x, amp, cen, wid)\"\"\"\n",
    "    return amp * exp(-((x-cen)/wid)**2 )\n",
    "\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=200, cen=0, wid=100)\n",
    "\n",
    "print(result.fit_report())\n",
    "\n",
    "plt.plot(x, y, 'bo')\n",
    "plt.plot(x, result.init_fit, 'k--')\n",
    "plt.plot(x, result.best_fit, 'r-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "495px",
    "left": "1249px",
    "right": "57px",
    "top": "240px",
    "width": "390px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
