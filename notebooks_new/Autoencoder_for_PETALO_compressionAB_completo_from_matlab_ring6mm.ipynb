{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder for PETALO\n",
    "\n",
    "Esta red la vamos a utilizar para comprimir los datos del anillo de 6mm de pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python36.zip', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/lib-dynload', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/extensions', '/home/rgadea3/.ipython']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#np.random.seed(1337)  # for reproducibility\n",
    "from time import time\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append(\"/home/rgadea/lmfit-py/\")\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from math import floor\n",
    "#from lmfit.models import  GaussianModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos introducir los datos de petalo preprocesados en matlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bb0a6a9ccb08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdatos_matlab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhdf5storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../datos_octubre_2018/conjunto_entrenamiento_octubre_2018_ring5mm_total.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconjunto_datos\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdatos_matlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'photodefbox2_todo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mconjunto_datos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import hdf5storage\n",
    "datos_matlab = hdf5storage.loadmat('../datos_octubre_2018/conjunto_entrenamiento_octubre_2018_ring5mm_total.mat')\n",
    "conjunto_datos= datos_matlab.get('photodefbox2_todo')\n",
    "conjunto_datos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empezamos con el autoencoder A de dimensión 576-250-576 (36 columnas x 16 filas de sensores )\n",
    "datos_matlab= hdf5storage.loadmat('../datos_octubre_2018/compresores_ring5mm_def_1_medio_export.mat')\n",
    "encoder_weights_A= datos_matlab.get('encoder_weights_A')\n",
    "encoder_biases_A= datos_matlab.get('encoder_biases_A')\n",
    "decoder_weights_A= datos_matlab.get('decoder_weights_A')\n",
    "decoder_biases_A= datos_matlab.get('decoder_biases_A')\n",
    "min_A=datos_matlab.get('minA')\n",
    "max_A=datos_matlab.get('maxA')\n",
    "Encoder_weights_A=encoder_weights_A.transpose()\n",
    "Encoder_biases_A=encoder_biases_A.transpose()[0]\n",
    "Decoder_weights_A=decoder_weights_A.transpose()\n",
    "Decoder_biases_A=decoder_biases_A.transpose()[0]\n",
    "\n",
    "# empezamos con el autoencoder B de dimensión 736-300-736 (46 columnas x 16 filas de sensores )\n",
    "encoder_weights_B= datos_matlab.get('encoder_weights_B')\n",
    "encoder_biases_B= datos_matlab.get('encoder_biases_B')\n",
    "decoder_weights_B= datos_matlab.get('decoder_weights_B')\n",
    "decoder_biases_B= datos_matlab.get('decoder_biases_B')\n",
    "min_B=datos_matlab.get('minB')\n",
    "max_B=datos_matlab.get('maxB')\n",
    "Encoder_weights_B=encoder_weights_B.transpose()\n",
    "Encoder_biases_B=encoder_biases_B.transpose()[0]\n",
    "Decoder_weights_B=decoder_weights_B.transpose()\n",
    "Decoder_biases_B=decoder_biases_B.transpose()[0]\n",
    "\n",
    "#Encoder_biases[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear lod dos autoencoders compresores como modelos Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "encoding_dimA = 250  # floats -> compression of factor 2, assuming the input is 480 floats\n",
    "\n",
    "# input image dimensions = sensor dimensions\n",
    "img_rows, img_colsA = 16, 36\n",
    "input_output_dim_A=img_rows*img_colsA\n",
    "# this is our input placeholder\n",
    "input_img_A = Input(shape=(input_output_dim_A,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded_A = Dense(encoding_dimA, activation='sigmoid',use_bias=True, weights=[Encoder_weights_A,Encoder_biases_A] )(input_img_A)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded_A = Dense(input_output_dim_A, activation='sigmoid',use_bias=True, weights=[Decoder_weights_A,Decoder_biases_A] )(encoded_A)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder_matlab_A = Model(input_img_A, decoded_A)\n",
    "# autoencoder_matlab.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "encoding_dimB = 300 \n",
    "# input image dimensions = sensor dimensions\n",
    "img_rows, img_colsB = 16, 40\n",
    "input_output_dim_B=img_rows*img_colsB\n",
    "# this is our input placeholder\n",
    "input_img_B = Input(shape=(input_output_dim_B,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded_B = Dense(encoding_dimB, activation='sigmoid',use_bias=True, weights=[Encoder_weights_B,Encoder_biases_B] )(input_img_B)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded_B = Dense(input_output_dim_B, activation='sigmoid',use_bias=True, weights=[Decoder_weights_B,Decoder_biases_B] )(encoded_B)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "\n",
    "\n",
    "autoencoder_matlab_B = Model(input_img_B, decoded_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "# (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "numero_muestras=conjunto_datos.shape[0]\n",
    "print(numero_muestras)\n",
    "print('conjunto_datos shape:', conjunto_datos.shape)\n",
    "\n",
    "tr_size=5\n",
    "val_size=90\n",
    "test_size=100-val_size-tr_size\n",
    "\n",
    "tamanyo_tr=floor(tr_size*numero_muestras/100)\n",
    "tamanyo_val=floor(val_size*numero_muestras/100)\n",
    "tamanyo_test=numero_muestras-tamanyo_tr-tamanyo_val\n",
    "print(tamanyo_tr)\n",
    "print(tamanyo_val)\n",
    "print(tamanyo_test)\n",
    "\n",
    "\n",
    "X_train=conjunto_datos[:tamanyo_tr,:]\n",
    "X_val=conjunto_datos[tamanyo_tr:tamanyo_tr+tamanyo_val,:]\n",
    "X_test=conjunto_datos[tamanyo_tr+tamanyo_val:numero_muestras,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a generar las matrices de datos para la red neuronal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train\n",
    "x_test = X_test\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vamos a procesar y comprimir con las dos redes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero escalamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max_scaler = preprocessing.QuantileTransformer().fit(x_train)\n",
    "# min_max_scaler = preprocessing.MaxAbsScaler().fit(x_train)\n",
    "# min_max_scaler = preprocessing.StandardScaler(with_mean=False).fit(x_train)\n",
    "# min_max_scaler = preprocessing.RobustScaler().fit(x_train)\n",
    "min_max_scaler = preprocessing.MinMaxScaler().fit(x_train)\n",
    "\n",
    "min_max_scaler_A = preprocessing.MinMaxScaler().fit(x_train[:,6:6+4*input_output_dim_A])\n",
    "min_max_scaler_B = preprocessing.MinMaxScaler().fit(x_train[:,6+4*input_output_dim_A:6+4*input_output_dim_A+3*input_output_dim_B])\n",
    "x_test_scaled = min_max_scaler.transform(x_test)\n",
    "\n",
    "\n",
    "min_max_scaler_A.data_max_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora los particionamos y pasamos por las redes de compresión. Hay una red la A que se utiliza 4 veces\n",
    "y otra red la B que se utiliza 3 veces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1A=3;\n",
    "L1B=2;\n",
    "def sigmoid(x, derivative=False):\n",
    "  return x*(1-x) if derivative else 1/(1+np.exp(-x))\n",
    "ideaA=np.zeros((L1A,input_output_dim_A))\n",
    "ideaB=np.zeros((L1B,input_output_dim_B)) \n",
    "cara_externa=x_test[:,6:6+L1A*input_output_dim_A+L1B*input_output_dim_B] \n",
    "cara_externa_reconstruida=np.zeros((x_test.shape[0],L1A*input_output_dim_A+L1B*input_output_dim_B))\n",
    "for i in range(x_test.shape[0]):\n",
    "    for k in range(L1A):\n",
    "        ideaA[k,:]=x_test[i,6+k*input_output_dim_A:6+k*input_output_dim_A+input_output_dim_A]\n",
    "    entrada_imgs_A=(ideaA-min_A.transpose())/(max_A.transpose()-min_A.transpose())\n",
    "    encoded_imgs_A = sigmoid(np.dot(entrada_imgs_A, Encoder_weights_A) + Encoder_biases_A)\n",
    "    decoded_imgs_A= sigmoid(np.dot(encoded_imgs_A, Decoder_weights_A) + Decoder_biases_A)\n",
    "    #print(decoded_imgs_A.shape)\n",
    "    salida_reconstructed_1 = decoded_imgs_A*(max_A.transpose()-min_A.transpose())+min_A.transpose();\n",
    "    for k in range(L1B):\n",
    "        ideaB[k,:input_output_dim_B]=x_test[i,6+L1A*input_output_dim_A+k*input_output_dim_B:6+L1A*input_output_dim_A+k*input_output_dim_B+input_output_dim_B]\n",
    "    entrada_imgs_B=(ideaB-min_B.transpose())/(max_B.transpose()-min_B.transpose())\n",
    "    encoded_imgs_B = sigmoid(np.dot(entrada_imgs_B, Encoder_weights_B) + Encoder_biases_B)\n",
    "    decoded_imgs_B= sigmoid(np.dot(encoded_imgs_B, Decoder_weights_B) + Decoder_biases_B)\n",
    "    salida_reconstructed_2 = decoded_imgs_B*(max_B.transpose()-min_B.transpose())+min_B.transpose(); \n",
    "    hola1=np.reshape(salida_reconstructed_1,(L1A*input_output_dim_A))\n",
    "    hola2=np.reshape(salida_reconstructed_2,(L1B*input_output_dim_B))\n",
    "    #print(hola.shape)\n",
    "    salida_total=np.concatenate((hola1,hola2))\n",
    "    \n",
    "    #print(salida_total.shape)\n",
    "    cara_externa_reconstruida[i]=salida_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1  # how many digits we will display\n",
    "plt.figure(figsize=(40, 10))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    idea=np.random.randint(1,x_test.shape[0])\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(cara_externa[idea].reshape(L1A*img_colsA+L1B*img_colsB, img_rows).transpose(),vmin=0, vmax=10)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(cara_externa_reconstruida[idea].reshape(L1A*img_colsA+L1B*img_colsB, img_rows).transpose(), vmin=0, vmax=10)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = L1A  # how many digits we will display\n",
    "plt.figure(figsize=(40, 10))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(cara_externa[idea].reshape(L1A*img_colsA+L1B*img_colsB, img_rows).transpose()[:,i*img_colsA:(i+1)*img_colsA] ,vmin=0, vmax=10)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax = plt.subplot(2, n, i + 1+n)\n",
    "    plt.imshow(cara_externa_reconstruida[idea].reshape(L1A*img_colsA+L1B*img_colsB, img_rows).transpose()[:,i*img_colsA:(i+1)*img_colsA] ,vmin=0, vmax=10)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = L1B  # how many digits we will display\n",
    "plt.figure(figsize=(40, 10))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(cara_externa[idea].reshape(L1A*img_colsA+L1B*img_colsB, img_rows).transpose()[:,L1A*img_colsA+i*img_colsB:L1A*img_colsA+(i+1)*img_colsB],vmin=0, vmax=10)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax = plt.subplot(2, n, i + 1+n)\n",
    "    plt.imshow(cara_externa_reconstruida[idea].reshape(L1A*img_colsA+L1B*img_colsB, img_rows).transpose()[:,L1A*img_colsA+i*img_colsB:L1A*img_colsA+(i+1)*img_colsB],vmin=0, vmax=10)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "print(idea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.amax(cara_externa[idea].reshape(204,16),axis=1)[120:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.amax(cara_externa_reconstruida[idea].reshape(204,16),axis=1)[120:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "479px",
    "left": "1851px",
    "right": "72px",
    "top": "112px",
    "width": "637px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
