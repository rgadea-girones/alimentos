{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple AUTOENCODER for PETALO\n",
    "\n",
    "Esta red la vamos a utilizar para obtener el radio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python36.zip', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/lib-dynload', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages', '/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/extensions', '/home/rgadea3/.ipython']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#np.random.seed(1337)  # for reproducibility\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append(\"/home/rgadea/lmfit-py/\")\n",
    "import seaborn as sns\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from math import floor\n",
    "from lmfit.models import  GaussianModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos introducir los datos de petalo preprocesados en matlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66498, 640)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import hdf5storage\n",
    "datos_matlab = hdf5storage.loadmat('../datos_octubre_2018/conjunto_entrenamiento_octubre_2018_red_pitch5mm_rad161mm_total.mat')\n",
    "conjunto_datos= datos_matlab.get('photodefA')\n",
    "conjunto_datos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6320, 3840)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "dir_name='../datos_octubre_2018'\n",
    "base_filename='p_OF_5mm_161mm'\n",
    "filename_suffix='.h5'\n",
    "file=os.path.join(dir_name, base_filename+ \"{0:03d}\".format(0) + filename_suffix)\n",
    "conjunto_datos_waves=pd.read_hdf(file,'MC')\n",
    "datos_waves=conjunto_datos_waves.values\n",
    "datos_waves.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12641, 3840)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1,2):\n",
    "    file=os.path.join(dir_name, base_filename+ \"{0:03d}\".format(i) + filename_suffix)\n",
    "    #print(file)\n",
    "    veamos=pd.read_hdf(file,'MC')\n",
    "    veamos_array=veamos.values\n",
    "    datos_waves=np.concatenate((datos_waves,veamos_array),axis=0)\n",
    "datos_waves.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12641, 3840)\n"
     ]
    }
   ],
   "source": [
    "L1A=6;\n",
    "# hay tres L1 con 640 sensores (40*16)\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 16, 40\n",
    "\n",
    "X_trained=datos_waves;\n",
    "x_trained=X_trained;\n",
    "\n",
    "for i in range (X_trained.shape[0]):\n",
    "    idea1=X_trained[i,:].reshape(img_rows,(L1A*img_cols));\n",
    "    ideat=idea1.transpose();\n",
    "    idea2=ideat.reshape(1,(L1A*img_cols)*img_rows);\n",
    "    x_trained[i,:] =idea2;\n",
    "\n",
    "print(x_trained.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_output_dim_A=img_rows*img_cols\n",
    "ideaA=np.zeros((L1A,input_output_dim_A))\n",
    "\n",
    "conjunto_datos=np.zeros((x_trained.shape[0]*L1A,input_output_dim_A))\n",
    "for i in range(x_trained.shape[0]):\n",
    "    for k in range(L1A):\n",
    "        ideaA[k,:]=x_trained[i,k*input_output_dim_A:k*input_output_dim_A+input_output_dim_A]\n",
    "    conjunto_datos[(i)*L1A :(i+1)*L1A,:] = ideaA    \n",
    "    \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_regularizer = True\n",
    "my_regularizer = None\n",
    "my_epochs = 50\n",
    "features_path = 'simple_autoe_features.pickle'\n",
    "labels_path = 'simple_autoe_labels.pickle'\n",
    "\n",
    "if use_regularizer:\n",
    "    # add a sparsity constraint on the encoded representations\n",
    "    # note use of 10e-5 leads to blurred results\n",
    "    my_regularizer = regularizers.l2(0.001)\n",
    "    # and a larger number of epochs as the added regularization the model\n",
    "    # is less likely to overfit and can be trained longer\n",
    "    my_epochs = 100\n",
    "    features_path = 'sparse_autoe_features.pickle'\n",
    "    labels_path = 'sparse_autoe_labels.pickle'\n",
    "\n",
    "   \n",
    "    \n",
    "encoding_dim = 250  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "\n",
    "# this is our input placeholder\n",
    "\n",
    "input_img = Input(shape=(img_rows*img_cols,))\n",
    "\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh', use_bias=False,bias_initializer='random_uniform')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(img_cols*img_rows, activation='tanh',use_bias=True,bias_initializer='random_uniform')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "\n",
    "\n",
    "#autoencoder=Sequential([\n",
    "#    Dense(encoding_dim, kernel_regularizer=regularizers.l2(0.001), use_bias=True,bias_initializer='random_uniform',input_shape=(640,)),\n",
    "#    Activation('sigmoid'),\n",
    "#    Dense(img_cols*img_rows, use_bias=True,bias_initializer='random_uniform'),\n",
    "#    Activation('linear'),\n",
    "#])\n",
    "\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75846\n",
      "conjunto_datos shape: (75846, 640)\n",
      "45507\n",
      "15169\n",
      "15170\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "# (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "numero_muestras=conjunto_datos.shape[0]\n",
    "print(numero_muestras)\n",
    "print('conjunto_datos shape:', conjunto_datos.shape)\n",
    "\n",
    "tr_size=60\n",
    "val_size=20\n",
    "test_size=100-val_size-tr_size\n",
    "\n",
    "tamanyo_tr=floor(tr_size*numero_muestras/100)\n",
    "tamanyo_val=floor(val_size*numero_muestras/100)\n",
    "tamanyo_test=numero_muestras-tamanyo_tr-tamanyo_val\n",
    "print(tamanyo_tr)\n",
    "print(tamanyo_val)\n",
    "print(tamanyo_test)\n",
    "\n",
    "\n",
    "X_train=conjunto_datos[:tamanyo_tr,:]\n",
    "X_val=conjunto_datos[tamanyo_tr:tamanyo_tr+tamanyo_val,:]\n",
    "X_test=conjunto_datos[tamanyo_tr+tamanyo_val:numero_muestras,:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Y_train=conjunto_datos[:tamanyo_tr,1] #elijo la coordenada radius\n",
    "Y_val=conjunto_datos[tamanyo_tr:tamanyo_tr+tamanyo_val,1] #elijo la corrdenada radius\n",
    "Y_test=conjunto_datos[tamanyo_tr+tamanyo_val:numero_muestras,1] #elijo la corrdenada radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], img_cols, img_rows,1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_cols, img_rows,1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_cols, img_rows,1)\n",
    "\n",
    "\n",
    "input_shape = (img_cols, img_rows,1)\n",
    "#input_shape=input_shape.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (45507, 40, 16, 1)\n",
      "45507 train samples\n",
      "15169 validation samples\n",
      "15170 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_val= X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_val.shape[0], 'validation samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display 20 random training images using image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42685\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20489\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19624\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30003\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "#Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "#Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "for i in range(1,5):\n",
    "    idea=np.random.randint(1,X_train.shape[0])\n",
    "    plt.imshow(np.reshape(X_train[idea].transpose(), [16, 40]), vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    plt.show()\n",
    "    print(idea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a generar las matrices de datos para la red neuronal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45507, 640)\n",
      "(15170, 640)\n",
      "(15170, 640)\n"
     ]
    }
   ],
   "source": [
    "x_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
    "x_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n",
    "prueba=x_train[0:15170,:]\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(prueba.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.98, -1.  , -1.  , -1.  , -0.98, -0.98, -1.  , -0.94, -1.  ,\n",
       "       -0.92, -0.96, -0.98, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -0.96, -0.94, -0.92, -0.98, -1.  , -0.96,\n",
       "       -0.98, -0.96, -0.98, -0.96, -0.98, -1.  , -0.98, -0.98, -0.98,\n",
       "       -0.96, -1.  , -0.92, -0.9 , -0.92, -0.98, -1.  , -1.  , -0.98,\n",
       "       -0.98, -0.96, -0.98, -1.  , -1.  , -0.98, -1.  , -0.98, -0.96,\n",
       "       -0.94, -0.96, -0.98, -1.  , -0.92, -0.92, -0.92, -1.  , -0.98,\n",
       "       -0.98, -0.98, -1.  , -0.98, -1.  , -0.98, -0.94, -0.98, -0.98,\n",
       "       -0.96, -0.98, -0.96, -0.94, -0.98, -1.  , -0.98, -0.98, -1.  ,\n",
       "       -1.  , -1.  , -1.  , -0.98, -0.96, -0.96, -0.98, -0.94, -0.92,\n",
       "       -0.94, -0.94, -0.98, -0.94, -1.  , -0.96, -1.  , -1.  , -0.98,\n",
       "       -1.  , -1.  , -0.96, -0.98, -0.96, -0.98, -0.96, -1.  , -0.94,\n",
       "       -0.96, -0.98, -0.96, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -0.96, -0.94, -0.96, -0.98, -1.  , -0.98, -0.94, -1.  ,\n",
       "       -1.  , -0.98, -1.  , -1.  , -1.  , -0.98, -0.96, -1.  , -1.  ,\n",
       "       -0.98, -0.92, -0.96, -1.  , -0.98, -0.98, -1.  , -1.  , -0.98,\n",
       "       -1.  , -1.  , -1.  , -0.98, -1.  , -1.  , -1.  , -0.96, -0.98,\n",
       "       -1.  , -1.  , -0.98, -0.98, -1.  , -1.  , -1.  , -0.98, -0.98,\n",
       "       -1.  , -1.  , -1.  , -0.96, -1.  , -0.98, -0.96, -1.  , -0.98,\n",
       "       -0.96, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -0.98,\n",
       "       -0.98, -1.  , -1.  , -0.98, -0.98, -1.  , -1.  , -0.98, -1.  ,\n",
       "       -1.  , -0.98, -0.98, -1.  , -1.  , -0.98, -1.  , -1.  , -0.98,\n",
       "       -0.98, -0.96, -1.  , -1.  , -1.  , -1.  , -0.98, -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -0.98, -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -0.98, -1.  , -0.98, -1.  , -0.98,\n",
       "       -1.  , -1.  , -1.  , -1.  , -0.98, -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -0.98, -0.98, -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -0.98, -0.98, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -0.98, -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -0.98,\n",
       "       -1.  , -0.98, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -0.98, -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -0.96, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -0.98, -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -0.98, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -0.98, -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -0.98, -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -0.98, -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -0.98, -1.  , -1.  , -1.  ,\n",
       "       -1.  , -0.98, -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  , -1.  ,\n",
       "       -1.  ], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min_max_scaler = preprocessing.QuantileTransformer().fit(x_train)\n",
    "# min_max_scaler = preprocessing.MaxAbsScaler().fit(x_train)\n",
    "# min_max_scaler = preprocessing.StandardScaler(with_mean=False).fit(x_train)\n",
    "min_max_scaler = preprocessing.MinMaxScaler().fit(x_train)\n",
    "#min_max_scaler = preprocessing.RobustScaler().fit(x_train)\n",
    "supermax=100\n",
    "factor_aprendizaje=0.0001\n",
    "print(min_max_scaler)\n",
    "#x_train_scaled = min_max_scaler.transform(x_train)\n",
    "#x_test_scaled = min_max_scaler.transform(x_test)\n",
    "x_train_scaled=(2*x_train/supermax)-1\n",
    "x_test_scaled=(2*x_test/supermax)-1\n",
    "#min_max_scaler.scale_\n",
    "x_train[29413]\n",
    "x_train_scaled[29413]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the autoencoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='RMSprop', loss='mse')\n",
    "\n",
    "autoencoder.optimizer.lr=(factor_aprendizaje)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a summary of the model parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now train the model and evaluate on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45507 samples, validate on 15170 samples\n",
      "Epoch 1/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 0.0799 - val_loss: 0.0012\n",
      "Epoch 2/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 3/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 4/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 5/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 6/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 7/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 8/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 9/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 10/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 11/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 12/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 13/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 14/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 15/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 16/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 17/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 18/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 19/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 20/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 21/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 22/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 23/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 24/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 25/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 26/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 27/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 28/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 29/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 30/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 31/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 32/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 33/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 34/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 35/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 36/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 37/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 38/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 39/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 40/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 41/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 42/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 43/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 44/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 45/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 46/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 47/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 48/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 49/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 50/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 51/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 52/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 53/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 54/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 55/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 56/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 57/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 58/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 59/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 60/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 61/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 62/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 63/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 64/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 65/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 66/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 67/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 68/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 69/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 70/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 71/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 72/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 73/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 74/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 75/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 76/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 77/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 78/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 79/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 80/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 81/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 82/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 83/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 84/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 85/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 86/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 87/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 88/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 89/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 90/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 91/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 92/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 93/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 94/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 95/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 96/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 97/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 98/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 99/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 100/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 101/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 102/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 103/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 104/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 105/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 106/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 107/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 108/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 109/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 110/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 111/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 112/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 113/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 114/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 115/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 116/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 117/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 118/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 119/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 120/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 121/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 122/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 9.9997e-04 - val_loss: 9.9942e-04\n",
      "Epoch 123/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 9.9531e-04 - val_loss: 9.9188e-04\n",
      "Epoch 124/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 9.8868e-04 - val_loss: 9.8469e-04\n",
      "Epoch 125/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 9.8264e-04 - val_loss: 9.7825e-04\n",
      "Epoch 126/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 9.7696e-04 - val_loss: 9.7320e-04\n",
      "Epoch 127/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 9.7032e-04 - val_loss: 9.6639e-04\n",
      "Epoch 128/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 9.6404e-04 - val_loss: 9.6079e-04\n",
      "Epoch 129/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 9.5823e-04 - val_loss: 9.5460e-04\n",
      "Epoch 130/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 9.5303e-04 - val_loss: 9.4829e-04\n",
      "Epoch 131/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 9.4700e-04 - val_loss: 9.4193e-04\n",
      "Epoch 132/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 9.4078e-04 - val_loss: 9.3664e-04\n",
      "Epoch 133/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 9.3428e-04 - val_loss: 9.3100e-04\n",
      "Epoch 134/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 9.2942e-04 - val_loss: 9.2513e-04\n",
      "Epoch 135/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 9.2283e-04 - val_loss: 9.1983e-04\n",
      "Epoch 136/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 9.1806e-04 - val_loss: 9.1473e-04\n",
      "Epoch 137/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 9.1234e-04 - val_loss: 9.0971e-04\n",
      "Epoch 138/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 9.0715e-04 - val_loss: 9.0491e-04\n",
      "Epoch 139/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 9.0217e-04 - val_loss: 9.0007e-04\n",
      "Epoch 140/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 8.9680e-04 - val_loss: 8.9546e-04\n",
      "Epoch 141/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 8.9168e-04 - val_loss: 8.9103e-04\n",
      "Epoch 142/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 8.8720e-04 - val_loss: 8.8685e-04\n",
      "Epoch 143/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 8.8277e-04 - val_loss: 8.8279e-04\n",
      "Epoch 144/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 8.7807e-04 - val_loss: 8.7887e-04\n",
      "Epoch 145/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.7356e-04 - val_loss: 8.7508e-04\n",
      "Epoch 146/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 8.6914e-04 - val_loss: 8.7129e-04\n",
      "Epoch 147/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 8.6475e-04 - val_loss: 8.6751e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 8.6045e-04 - val_loss: 8.6374e-04\n",
      "Epoch 149/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.5629e-04 - val_loss: 8.5998e-04\n",
      "Epoch 150/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.5213e-04 - val_loss: 8.5618e-04\n",
      "Epoch 151/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 8.4805e-04 - val_loss: 8.5238e-04\n",
      "Epoch 152/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 8.4405e-04 - val_loss: 8.4862e-04\n",
      "Epoch 153/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.4015e-04 - val_loss: 8.4491e-04\n",
      "Epoch 154/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.3637e-04 - val_loss: 8.4123e-04\n",
      "Epoch 155/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 8.3273e-04 - val_loss: 8.3755e-04\n",
      "Epoch 156/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.2922e-04 - val_loss: 8.3388e-04\n",
      "Epoch 157/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 8.2581e-04 - val_loss: 8.3022e-04\n",
      "Epoch 158/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 8.2249e-04 - val_loss: 8.2661e-04\n",
      "Epoch 159/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 8.1924e-04 - val_loss: 8.2310e-04\n",
      "Epoch 160/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.1605e-04 - val_loss: 8.1972e-04\n",
      "Epoch 161/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 8.1293e-04 - val_loss: 8.1651e-04\n",
      "Epoch 162/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 8.0987e-04 - val_loss: 8.1348e-04\n",
      "Epoch 163/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.0688e-04 - val_loss: 8.1061e-04\n",
      "Epoch 164/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.0396e-04 - val_loss: 8.0787e-04\n",
      "Epoch 165/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 8.0113e-04 - val_loss: 8.0520e-04\n",
      "Epoch 166/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.9838e-04 - val_loss: 8.0252e-04\n",
      "Epoch 167/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.9573e-04 - val_loss: 7.9980e-04\n",
      "Epoch 168/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 7.9318e-04 - val_loss: 7.9705e-04\n",
      "Epoch 169/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.9071e-04 - val_loss: 7.9433e-04\n",
      "Epoch 170/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.8833e-04 - val_loss: 7.9171e-04\n",
      "Epoch 171/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 7.8602e-04 - val_loss: 7.8925e-04\n",
      "Epoch 172/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 7.8379e-04 - val_loss: 7.8694e-04\n",
      "Epoch 173/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.8162e-04 - val_loss: 7.8479e-04\n",
      "Epoch 174/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 7.7953e-04 - val_loss: 7.8278e-04\n",
      "Epoch 175/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 7.7749e-04 - val_loss: 7.8088e-04\n",
      "Epoch 176/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.7551e-04 - val_loss: 7.7910e-04\n",
      "Epoch 177/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 7.7357e-04 - val_loss: 7.7741e-04\n",
      "Epoch 178/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 7.7168e-04 - val_loss: 7.7582e-04\n",
      "Epoch 179/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.6982e-04 - val_loss: 7.7431e-04\n",
      "Epoch 180/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 7.6799e-04 - val_loss: 7.7288e-04\n",
      "Epoch 181/10000\n",
      "45507/45507 [==============================] - 1s 22us/step - loss: 7.6620e-04 - val_loss: 7.7154e-04\n",
      "Epoch 182/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 7.6444e-04 - val_loss: 7.7029e-04\n",
      "Epoch 183/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 7.6271e-04 - val_loss: 7.6912e-04\n",
      "Epoch 184/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.6102e-04 - val_loss: 7.6800e-04\n",
      "Epoch 185/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 7.5935e-04 - val_loss: 7.6689e-04\n",
      "Epoch 186/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.5771e-04 - val_loss: 7.6570e-04\n",
      "Epoch 187/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.5608e-04 - val_loss: 7.6430e-04\n",
      "Epoch 188/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 7.5449e-04 - val_loss: 7.6260e-04\n",
      "Epoch 189/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.5290e-04 - val_loss: 7.6071e-04\n",
      "Epoch 190/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.5128e-04 - val_loss: 7.5900e-04\n",
      "Epoch 191/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 7.4967e-04 - val_loss: 7.5762e-04\n",
      "Epoch 192/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.4814e-04 - val_loss: 7.5640e-04\n",
      "Epoch 193/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.4668e-04 - val_loss: 7.5516e-04\n",
      "Epoch 194/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 7.4527e-04 - val_loss: 7.5385e-04\n",
      "Epoch 195/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 7.4389e-04 - val_loss: 7.5246e-04\n",
      "Epoch 196/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.4255e-04 - val_loss: 7.5102e-04\n",
      "Epoch 197/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 7.4124e-04 - val_loss: 7.4952e-04\n",
      "Epoch 198/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.3997e-04 - val_loss: 7.4797e-04\n",
      "Epoch 199/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.3873e-04 - val_loss: 7.4637e-04\n",
      "Epoch 200/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 7.3752e-04 - val_loss: 7.4472e-04\n",
      "Epoch 201/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 7.3635e-04 - val_loss: 7.4305e-04\n",
      "Epoch 202/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.3520e-04 - val_loss: 7.4136e-04\n",
      "Epoch 203/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.3408e-04 - val_loss: 7.3966e-04\n",
      "Epoch 204/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 7.3299e-04 - val_loss: 7.3797e-04\n",
      "Epoch 205/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.3192e-04 - val_loss: 7.3629e-04\n",
      "Epoch 206/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.3087e-04 - val_loss: 7.3464e-04\n",
      "Epoch 207/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 7.2984e-04 - val_loss: 7.3302e-04\n",
      "Epoch 208/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.2883e-04 - val_loss: 7.3144e-04\n",
      "Epoch 209/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.2783e-04 - val_loss: 7.2991e-04\n",
      "Epoch 210/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 7.2686e-04 - val_loss: 7.2843e-04\n",
      "Epoch 211/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.2590e-04 - val_loss: 7.2701e-04\n",
      "Epoch 212/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.2495e-04 - val_loss: 7.2564e-04\n",
      "Epoch 213/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 7.2403e-04 - val_loss: 7.2434e-04\n",
      "Epoch 214/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 7.2312e-04 - val_loss: 7.2309e-04\n",
      "Epoch 215/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.2222e-04 - val_loss: 7.2190e-04\n",
      "Epoch 216/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.2134e-04 - val_loss: 7.2076e-04\n",
      "Epoch 217/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 35us/step - loss: 7.2047e-04 - val_loss: 7.1967e-04\n",
      "Epoch 218/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 7.1961e-04 - val_loss: 7.1864e-04\n",
      "Epoch 219/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 7.1877e-04 - val_loss: 7.1764e-04\n",
      "Epoch 220/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 7.1794e-04 - val_loss: 7.1670e-04\n",
      "Epoch 221/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.1712e-04 - val_loss: 7.1579e-04\n",
      "Epoch 222/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.1631e-04 - val_loss: 7.1492e-04\n",
      "Epoch 223/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 7.1551e-04 - val_loss: 7.1409e-04\n",
      "Epoch 224/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.1473e-04 - val_loss: 7.1330e-04\n",
      "Epoch 225/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.1395e-04 - val_loss: 7.1253e-04\n",
      "Epoch 226/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.1318e-04 - val_loss: 7.1180e-04\n",
      "Epoch 227/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.1242e-04 - val_loss: 7.1111e-04\n",
      "Epoch 228/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.1167e-04 - val_loss: 7.1044e-04\n",
      "Epoch 229/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.1092e-04 - val_loss: 7.0980e-04\n",
      "Epoch 230/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.1018e-04 - val_loss: 7.0920e-04\n",
      "Epoch 231/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.0945e-04 - val_loss: 7.0862e-04\n",
      "Epoch 232/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 7.0873e-04 - val_loss: 7.0807e-04\n",
      "Epoch 233/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.0802e-04 - val_loss: 7.0756e-04\n",
      "Epoch 234/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.0732e-04 - val_loss: 7.0707e-04\n",
      "Epoch 235/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.0662e-04 - val_loss: 7.0660e-04\n",
      "Epoch 236/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.0594e-04 - val_loss: 7.0617e-04\n",
      "Epoch 237/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 7.0526e-04 - val_loss: 7.0576e-04\n",
      "Epoch 238/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 7.0459e-04 - val_loss: 7.0538e-04\n",
      "Epoch 239/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 7.0392e-04 - val_loss: 7.0502e-04\n",
      "Epoch 240/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.0327e-04 - val_loss: 7.0468e-04\n",
      "Epoch 241/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 7.0262e-04 - val_loss: 7.0437e-04\n",
      "Epoch 242/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.0198e-04 - val_loss: 7.0409e-04\n",
      "Epoch 243/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 7.0134e-04 - val_loss: 7.0382e-04\n",
      "Epoch 244/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.0072e-04 - val_loss: 7.0357e-04\n",
      "Epoch 245/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 7.0009e-04 - val_loss: 7.0334e-04\n",
      "Epoch 246/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.9948e-04 - val_loss: 7.0313e-04\n",
      "Epoch 247/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.9887e-04 - val_loss: 7.0293e-04\n",
      "Epoch 248/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.9827e-04 - val_loss: 7.0275e-04\n",
      "Epoch 249/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.9767e-04 - val_loss: 7.0258e-04\n",
      "Epoch 250/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.9709e-04 - val_loss: 7.0242e-04\n",
      "Epoch 251/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.9651e-04 - val_loss: 7.0228e-04\n",
      "Epoch 252/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.9594e-04 - val_loss: 7.0214e-04\n",
      "Epoch 253/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.9538e-04 - val_loss: 7.0202e-04\n",
      "Epoch 254/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.9484e-04 - val_loss: 7.0190e-04\n",
      "Epoch 255/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.9430e-04 - val_loss: 7.0180e-04\n",
      "Epoch 256/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.9378e-04 - val_loss: 7.0169e-04\n",
      "Epoch 257/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.9326e-04 - val_loss: 7.0159e-04\n",
      "Epoch 258/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.9275e-04 - val_loss: 7.0150e-04\n",
      "Epoch 259/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.9224e-04 - val_loss: 7.0140e-04\n",
      "Epoch 260/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.9175e-04 - val_loss: 7.0132e-04\n",
      "Epoch 261/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.9126e-04 - val_loss: 7.0123e-04\n",
      "Epoch 262/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.9078e-04 - val_loss: 7.0115e-04\n",
      "Epoch 263/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.9031e-04 - val_loss: 7.0107e-04\n",
      "Epoch 264/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8984e-04 - val_loss: 7.0100e-04\n",
      "Epoch 265/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.8938e-04 - val_loss: 7.0093e-04\n",
      "Epoch 266/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.8893e-04 - val_loss: 7.0087e-04\n",
      "Epoch 267/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.8848e-04 - val_loss: 7.0081e-04\n",
      "Epoch 268/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.8804e-04 - val_loss: 7.0075e-04\n",
      "Epoch 269/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.8760e-04 - val_loss: 7.0070e-04\n",
      "Epoch 270/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.8717e-04 - val_loss: 7.0065e-04\n",
      "Epoch 271/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.8674e-04 - val_loss: 7.0060e-04\n",
      "Epoch 272/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.8632e-04 - val_loss: 7.0056e-04\n",
      "Epoch 273/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.8591e-04 - val_loss: 7.0052e-04\n",
      "Epoch 274/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.8550e-04 - val_loss: 7.0048e-04\n",
      "Epoch 275/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8509e-04 - val_loss: 7.0043e-04\n",
      "Epoch 276/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 6.8469e-04 - val_loss: 7.0038e-04\n",
      "Epoch 277/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.8429e-04 - val_loss: 7.0031e-04\n",
      "Epoch 278/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.8390e-04 - val_loss: 7.0024e-04\n",
      "Epoch 279/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8351e-04 - val_loss: 7.0015e-04\n",
      "Epoch 280/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8313e-04 - val_loss: 7.0004e-04\n",
      "Epoch 281/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8275e-04 - val_loss: 6.9991e-04\n",
      "Epoch 282/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.8238e-04 - val_loss: 6.9976e-04\n",
      "Epoch 283/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.8201e-04 - val_loss: 6.9960e-04\n",
      "Epoch 284/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.8164e-04 - val_loss: 6.9944e-04\n",
      "Epoch 285/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.8128e-04 - val_loss: 6.9927e-04\n",
      "Epoch 286/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.8093e-04 - val_loss: 6.9910e-04\n",
      "Epoch 287/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.8058e-04 - val_loss: 6.9895e-04\n",
      "Epoch 288/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.8023e-04 - val_loss: 6.9881e-04\n",
      "Epoch 289/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.7988e-04 - val_loss: 6.9868e-04\n",
      "Epoch 290/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7954e-04 - val_loss: 6.9857e-04\n",
      "Epoch 291/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.7920e-04 - val_loss: 6.9848e-04\n",
      "Epoch 292/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7886e-04 - val_loss: 6.9840e-04\n",
      "Epoch 293/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7852e-04 - val_loss: 6.9833e-04\n",
      "Epoch 294/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.7818e-04 - val_loss: 6.9829e-04\n",
      "Epoch 295/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.7785e-04 - val_loss: 6.9826e-04\n",
      "Epoch 296/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.7752e-04 - val_loss: 6.9825e-04\n",
      "Epoch 297/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7720e-04 - val_loss: 6.9826e-04\n",
      "Epoch 298/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7687e-04 - val_loss: 6.9828e-04\n",
      "Epoch 299/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7656e-04 - val_loss: 6.9832e-04\n",
      "Epoch 300/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7624e-04 - val_loss: 6.9838e-04\n",
      "Epoch 301/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.7593e-04 - val_loss: 6.9844e-04\n",
      "Epoch 302/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7562e-04 - val_loss: 6.9852e-04\n",
      "Epoch 303/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7532e-04 - val_loss: 6.9860e-04\n",
      "Epoch 304/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.7503e-04 - val_loss: 6.9868e-04\n",
      "Epoch 305/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7473e-04 - val_loss: 6.9877e-04\n",
      "Epoch 306/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7445e-04 - val_loss: 6.9885e-04\n",
      "Epoch 307/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.7417e-04 - val_loss: 6.9893e-04\n",
      "Epoch 308/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.7389e-04 - val_loss: 6.9902e-04\n",
      "Epoch 309/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7363e-04 - val_loss: 6.9912e-04\n",
      "Epoch 310/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.7337e-04 - val_loss: 6.9923e-04\n",
      "Epoch 311/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.7312e-04 - val_loss: 6.9937e-04\n",
      "Epoch 312/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7288e-04 - val_loss: 6.9952e-04\n",
      "Epoch 313/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.7265e-04 - val_loss: 6.9971e-04\n",
      "Epoch 314/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 6.7243e-04 - val_loss: 6.9994e-04\n",
      "Epoch 315/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.7221e-04 - val_loss: 7.0018e-04\n",
      "Epoch 316/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7199e-04 - val_loss: 7.0043e-04\n",
      "Epoch 317/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7177e-04 - val_loss: 7.0069e-04\n",
      "Epoch 318/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.7155e-04 - val_loss: 7.0094e-04\n",
      "Epoch 319/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7132e-04 - val_loss: 7.0119e-04\n",
      "Epoch 320/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.7110e-04 - val_loss: 7.0141e-04\n",
      "Epoch 321/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7087e-04 - val_loss: 7.0160e-04\n",
      "Epoch 322/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.7064e-04 - val_loss: 7.0174e-04\n",
      "Epoch 323/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.7041e-04 - val_loss: 7.0181e-04\n",
      "Epoch 324/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.7017e-04 - val_loss: 7.0173e-04\n",
      "Epoch 325/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6991e-04 - val_loss: 7.0135e-04\n",
      "Epoch 326/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6966e-04 - val_loss: 7.0050e-04\n",
      "Epoch 327/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.6943e-04 - val_loss: 6.9903e-04\n",
      "Epoch 328/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6934e-04 - val_loss: 6.9714e-04\n",
      "Epoch 329/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6899e-04 - val_loss: 6.9549e-04\n",
      "Epoch 330/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6862e-04 - val_loss: 6.9441e-04\n",
      "Epoch 331/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6830e-04 - val_loss: 6.9375e-04\n",
      "Epoch 332/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6810e-04 - val_loss: 6.9346e-04\n",
      "Epoch 333/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 6.6782e-04 - val_loss: 6.9344e-04\n",
      "Epoch 334/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.6742e-04 - val_loss: 6.9359e-04\n",
      "Epoch 335/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6709e-04 - val_loss: 6.9378e-04\n",
      "Epoch 336/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.6681e-04 - val_loss: 6.9409e-04\n",
      "Epoch 337/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6681e-04 - val_loss: 6.9436e-04\n",
      "Epoch 338/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6645e-04 - val_loss: 6.9453e-04\n",
      "Epoch 339/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.6649e-04 - val_loss: 6.9480e-04\n",
      "Epoch 340/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6614e-04 - val_loss: 6.9535e-04\n",
      "Epoch 341/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6593e-04 - val_loss: 6.9551e-04\n",
      "Epoch 342/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6599e-04 - val_loss: 6.9579e-04\n",
      "Epoch 343/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6551e-04 - val_loss: 6.9618e-04\n",
      "Epoch 344/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6530e-04 - val_loss: 6.9670e-04\n",
      "Epoch 345/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.6511e-04 - val_loss: 6.9716e-04\n",
      "Epoch 346/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.6486e-04 - val_loss: 6.9743e-04\n",
      "Epoch 347/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6517e-04 - val_loss: 6.9758e-04\n",
      "Epoch 348/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6485e-04 - val_loss: 6.9811e-04\n",
      "Epoch 349/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6465e-04 - val_loss: 6.9774e-04\n",
      "Epoch 350/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.6428e-04 - val_loss: 6.9634e-04\n",
      "Epoch 351/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6440e-04 - val_loss: 6.9473e-04\n",
      "Epoch 352/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.6407e-04 - val_loss: 6.9348e-04\n",
      "Epoch 353/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6374e-04 - val_loss: 6.9224e-04\n",
      "Epoch 354/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6347e-04 - val_loss: 6.9171e-04\n",
      "Epoch 355/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6337e-04 - val_loss: 6.9168e-04\n",
      "Epoch 356/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6318e-04 - val_loss: 6.9193e-04\n",
      "Epoch 357/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6296e-04 - val_loss: 6.9220e-04\n",
      "Epoch 358/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6276e-04 - val_loss: 6.9248e-04\n",
      "Epoch 359/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6256e-04 - val_loss: 6.9306e-04\n",
      "Epoch 360/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6236e-04 - val_loss: 6.9395e-04\n",
      "Epoch 361/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6216e-04 - val_loss: 6.9465e-04\n",
      "Epoch 362/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6198e-04 - val_loss: 6.9475e-04\n",
      "Epoch 363/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6178e-04 - val_loss: 6.9428e-04\n",
      "Epoch 364/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6159e-04 - val_loss: 6.9349e-04\n",
      "Epoch 365/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.6139e-04 - val_loss: 6.9258e-04\n",
      "Epoch 366/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.6120e-04 - val_loss: 6.9170e-04\n",
      "Epoch 367/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.6100e-04 - val_loss: 6.9095e-04\n",
      "Epoch 368/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.6080e-04 - val_loss: 6.9041e-04\n",
      "Epoch 369/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.6059e-04 - val_loss: 6.9006e-04\n",
      "Epoch 370/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.6037e-04 - val_loss: 6.8977e-04\n",
      "Epoch 371/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 6.6013e-04 - val_loss: 6.8919e-04\n",
      "Epoch 372/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.5988e-04 - val_loss: 6.8834e-04\n",
      "Epoch 373/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.5951e-04 - val_loss: 6.8786e-04\n",
      "Epoch 374/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5924e-04 - val_loss: 6.8553e-04\n",
      "Epoch 375/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5915e-04 - val_loss: 6.8328e-04\n",
      "Epoch 376/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5883e-04 - val_loss: 6.8165e-04\n",
      "Epoch 377/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5874e-04 - val_loss: 6.8056e-04\n",
      "Epoch 378/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5858e-04 - val_loss: 6.7975e-04\n",
      "Epoch 379/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5842e-04 - val_loss: 6.7939e-04\n",
      "Epoch 380/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5826e-04 - val_loss: 6.7945e-04\n",
      "Epoch 381/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5814e-04 - val_loss: 6.7967e-04\n",
      "Epoch 382/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5801e-04 - val_loss: 6.7990e-04\n",
      "Epoch 383/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5794e-04 - val_loss: 6.7986e-04\n",
      "Epoch 384/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.5785e-04 - val_loss: 6.7978e-04\n",
      "Epoch 385/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5772e-04 - val_loss: 6.7943e-04\n",
      "Epoch 386/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5761e-04 - val_loss: 6.7949e-04\n",
      "Epoch 387/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.5733e-04 - val_loss: 6.7804e-04\n",
      "Epoch 388/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5706e-04 - val_loss: 6.7883e-04\n",
      "Epoch 389/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.5694e-04 - val_loss: 6.7967e-04\n",
      "Epoch 390/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 6.5689e-04 - val_loss: 6.7818e-04\n",
      "Epoch 391/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.5663e-04 - val_loss: 6.8130e-04\n",
      "Epoch 392/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5650e-04 - val_loss: 6.8332e-04\n",
      "Epoch 393/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5619e-04 - val_loss: 6.8512e-04\n",
      "Epoch 394/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.5594e-04 - val_loss: 6.8631e-04\n",
      "Epoch 395/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5574e-04 - val_loss: 6.8715e-04\n",
      "Epoch 396/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5554e-04 - val_loss: 6.8720e-04\n",
      "Epoch 397/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.5534e-04 - val_loss: 6.8613e-04\n",
      "Epoch 398/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5517e-04 - val_loss: 6.8488e-04\n",
      "Epoch 399/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5494e-04 - val_loss: 6.8384e-04\n",
      "Epoch 400/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.5471e-04 - val_loss: 6.8261e-04\n",
      "Epoch 401/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5450e-04 - val_loss: 6.8170e-04\n",
      "Epoch 402/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5435e-04 - val_loss: 6.8137e-04\n",
      "Epoch 403/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5425e-04 - val_loss: 6.8119e-04\n",
      "Epoch 404/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5411e-04 - val_loss: 6.8127e-04\n",
      "Epoch 405/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5392e-04 - val_loss: 6.8131e-04\n",
      "Epoch 406/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5374e-04 - val_loss: 6.8135e-04\n",
      "Epoch 407/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5356e-04 - val_loss: 6.8121e-04\n",
      "Epoch 408/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.5346e-04 - val_loss: 6.7951e-04\n",
      "Epoch 409/10000\n",
      "45507/45507 [==============================] - 1s 23us/step - loss: 6.5406e-04 - val_loss: 6.7935e-04\n",
      "Epoch 410/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.5346e-04 - val_loss: 6.8251e-04\n",
      "Epoch 411/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.5334e-04 - val_loss: 6.8044e-04\n",
      "Epoch 412/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5314e-04 - val_loss: 6.8126e-04\n",
      "Epoch 413/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5314e-04 - val_loss: 6.8088e-04\n",
      "Epoch 414/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5308e-04 - val_loss: 6.8128e-04\n",
      "Epoch 415/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5292e-04 - val_loss: 6.8154e-04\n",
      "Epoch 416/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5273e-04 - val_loss: 6.8169e-04\n",
      "Epoch 417/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5250e-04 - val_loss: 6.8164e-04\n",
      "Epoch 418/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5231e-04 - val_loss: 6.8099e-04\n",
      "Epoch 419/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5214e-04 - val_loss: 6.7865e-04\n",
      "Epoch 420/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5200e-04 - val_loss: 6.7451e-04\n",
      "Epoch 421/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5193e-04 - val_loss: 6.7672e-04\n",
      "Epoch 422/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.5183e-04 - val_loss: 6.7470e-04\n",
      "Epoch 423/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5175e-04 - val_loss: 6.7507e-04\n",
      "Epoch 424/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5160e-04 - val_loss: 6.7562e-04\n",
      "Epoch 425/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5146e-04 - val_loss: 6.7660e-04\n",
      "Epoch 426/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.5132e-04 - val_loss: 6.7765e-04\n",
      "Epoch 427/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.5119e-04 - val_loss: 6.7900e-04\n",
      "Epoch 428/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.5106e-04 - val_loss: 6.8033e-04\n",
      "Epoch 429/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.5096e-04 - val_loss: 6.8155e-04\n",
      "Epoch 430/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.5097e-04 - val_loss: 6.8172e-04\n",
      "Epoch 431/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5087e-04 - val_loss: 6.8508e-04\n",
      "Epoch 432/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5074e-04 - val_loss: 6.8043e-04\n",
      "Epoch 433/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.5074e-04 - val_loss: 6.8848e-04\n",
      "Epoch 434/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5056e-04 - val_loss: 6.8047e-04\n",
      "Epoch 435/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5046e-04 - val_loss: 6.8730e-04\n",
      "Epoch 436/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.5032e-04 - val_loss: 6.8005e-04\n",
      "Epoch 437/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5013e-04 - val_loss: 6.7730e-04\n",
      "Epoch 438/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.5033e-04 - val_loss: 6.7628e-04\n",
      "Epoch 439/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.5007e-04 - val_loss: 6.9054e-04\n",
      "Epoch 440/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5012e-04 - val_loss: 6.8414e-04\n",
      "Epoch 441/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.5007e-04 - val_loss: 6.8999e-04\n",
      "Epoch 442/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.5063e-04 - val_loss: 6.7461e-04\n",
      "Epoch 443/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5002e-04 - val_loss: 6.8092e-04\n",
      "Epoch 444/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.5011e-04 - val_loss: 6.9526e-04\n",
      "Epoch 445/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4949e-04 - val_loss: 6.7452e-04\n",
      "Epoch 446/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4947e-04 - val_loss: 6.9031e-04\n",
      "Epoch 447/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.4935e-04 - val_loss: 6.8276e-04\n",
      "Epoch 448/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4916e-04 - val_loss: 6.7586e-04\n",
      "Epoch 449/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.4900e-04 - val_loss: 6.8762e-04\n",
      "Epoch 450/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4936e-04 - val_loss: 6.8187e-04\n",
      "Epoch 451/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4904e-04 - val_loss: 6.9634e-04\n",
      "Epoch 452/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.4867e-04 - val_loss: 6.7314e-04\n",
      "Epoch 453/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4836e-04 - val_loss: 6.8479e-04\n",
      "Epoch 454/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4914e-04 - val_loss: 6.7048e-04\n",
      "Epoch 455/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.4914e-04 - val_loss: 6.8008e-04\n",
      "Epoch 456/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4821e-04 - val_loss: 6.7410e-04\n",
      "Epoch 457/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4814e-04 - val_loss: 6.7284e-04\n",
      "Epoch 458/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4800e-04 - val_loss: 6.9300e-04\n",
      "Epoch 459/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4880e-04 - val_loss: 6.8411e-04\n",
      "Epoch 460/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.4768e-04 - val_loss: 6.8111e-04\n",
      "Epoch 461/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4799e-04 - val_loss: 6.7175e-04\n",
      "Epoch 462/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4855e-04 - val_loss: 6.7013e-04\n",
      "Epoch 463/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4752e-04 - val_loss: 6.7529e-04\n",
      "Epoch 464/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4723e-04 - val_loss: 6.7192e-04\n",
      "Epoch 465/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.4715e-04 - val_loss: 6.7231e-04\n",
      "Epoch 466/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.4862e-04 - val_loss: 6.7855e-04\n",
      "Epoch 467/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.4736e-04 - val_loss: 6.9286e-04\n",
      "Epoch 468/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4735e-04 - val_loss: 6.7639e-04\n",
      "Epoch 469/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4773e-04 - val_loss: 6.7311e-04\n",
      "Epoch 470/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4723e-04 - val_loss: 6.8769e-04\n",
      "Epoch 471/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4795e-04 - val_loss: 6.7544e-04\n",
      "Epoch 472/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.4653e-04 - val_loss: 6.8915e-04\n",
      "Epoch 473/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4694e-04 - val_loss: 6.9485e-04\n",
      "Epoch 474/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4639e-04 - val_loss: 6.9870e-04\n",
      "Epoch 475/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4656e-04 - val_loss: 6.9653e-04\n",
      "Epoch 476/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4660e-04 - val_loss: 6.7111e-04\n",
      "Epoch 477/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4654e-04 - val_loss: 6.7230e-04\n",
      "Epoch 478/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4645e-04 - val_loss: 6.7329e-04\n",
      "Epoch 479/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.4630e-04 - val_loss: 6.7311e-04\n",
      "Epoch 480/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.4626e-04 - val_loss: 6.6997e-04\n",
      "Epoch 481/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4760e-04 - val_loss: 6.7743e-04\n",
      "Epoch 482/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4628e-04 - val_loss: 6.7122e-04\n",
      "Epoch 483/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4561e-04 - val_loss: 6.7176e-04\n",
      "Epoch 484/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.4589e-04 - val_loss: 6.8169e-04\n",
      "Epoch 485/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.4567e-04 - val_loss: 6.7542e-04\n",
      "Epoch 486/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.4651e-04 - val_loss: 6.7023e-04\n",
      "Epoch 487/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.4631e-04 - val_loss: 6.7976e-04\n",
      "Epoch 488/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4617e-04 - val_loss: 6.8264e-04\n",
      "Epoch 489/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4639e-04 - val_loss: 6.8733e-04\n",
      "Epoch 490/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4593e-04 - val_loss: 6.7214e-04\n",
      "Epoch 491/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4534e-04 - val_loss: 6.7346e-04\n",
      "Epoch 492/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4564e-04 - val_loss: 6.8218e-04\n",
      "Epoch 493/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4606e-04 - val_loss: 6.7964e-04\n",
      "Epoch 494/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4510e-04 - val_loss: 6.7194e-04\n",
      "Epoch 495/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4498e-04 - val_loss: 6.7423e-04\n",
      "Epoch 496/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4553e-04 - val_loss: 6.8056e-04\n",
      "Epoch 497/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.4521e-04 - val_loss: 6.7860e-04\n",
      "Epoch 498/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.4536e-04 - val_loss: 6.7472e-04\n",
      "Epoch 499/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4450e-04 - val_loss: 6.9648e-04\n",
      "Epoch 500/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4544e-04 - val_loss: 6.8159e-04\n",
      "Epoch 501/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4455e-04 - val_loss: 6.8127e-04\n",
      "Epoch 502/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.4468e-04 - val_loss: 6.8609e-04\n",
      "Epoch 503/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4477e-04 - val_loss: 6.8685e-04\n",
      "Epoch 504/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.4436e-04 - val_loss: 7.0642e-04\n",
      "Epoch 505/10000\n",
      "45507/45507 [==============================] - 1s 23us/step - loss: 6.4459e-04 - val_loss: 6.8494e-04\n",
      "Epoch 506/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.4382e-04 - val_loss: 6.9605e-04\n",
      "Epoch 507/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4361e-04 - val_loss: 6.9095e-04\n",
      "Epoch 508/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4348e-04 - val_loss: 6.9051e-04\n",
      "Epoch 509/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4443e-04 - val_loss: 6.7928e-04\n",
      "Epoch 510/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4332e-04 - val_loss: 6.9195e-04\n",
      "Epoch 511/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4364e-04 - val_loss: 6.8474e-04\n",
      "Epoch 512/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4363e-04 - val_loss: 6.6807e-04\n",
      "Epoch 513/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4318e-04 - val_loss: 6.9801e-04\n",
      "Epoch 514/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4426e-04 - val_loss: 6.7423e-04\n",
      "Epoch 515/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4310e-04 - val_loss: 6.7452e-04\n",
      "Epoch 516/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4332e-04 - val_loss: 6.7570e-04\n",
      "Epoch 517/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4279e-04 - val_loss: 6.8053e-04\n",
      "Epoch 518/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4261e-04 - val_loss: 6.9011e-04\n",
      "Epoch 519/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4294e-04 - val_loss: 6.7498e-04\n",
      "Epoch 520/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4223e-04 - val_loss: 6.9126e-04\n",
      "Epoch 521/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4240e-04 - val_loss: 6.7720e-04\n",
      "Epoch 522/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4216e-04 - val_loss: 6.8902e-04\n",
      "Epoch 523/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.4239e-04 - val_loss: 6.9248e-04\n",
      "Epoch 524/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.4293e-04 - val_loss: 6.7236e-04\n",
      "Epoch 525/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4235e-04 - val_loss: 6.8036e-04\n",
      "Epoch 526/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4131e-04 - val_loss: 6.9465e-04\n",
      "Epoch 527/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4208e-04 - val_loss: 6.8845e-04\n",
      "Epoch 528/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4185e-04 - val_loss: 6.9233e-04\n",
      "Epoch 529/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4199e-04 - val_loss: 6.7535e-04\n",
      "Epoch 530/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4170e-04 - val_loss: 6.7592e-04\n",
      "Epoch 531/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4167e-04 - val_loss: 6.7662e-04\n",
      "Epoch 532/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4171e-04 - val_loss: 6.8871e-04\n",
      "Epoch 533/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4164e-04 - val_loss: 6.7456e-04\n",
      "Epoch 534/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4126e-04 - val_loss: 6.7780e-04\n",
      "Epoch 535/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4111e-04 - val_loss: 6.7590e-04\n",
      "Epoch 536/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.4071e-04 - val_loss: 6.9057e-04\n",
      "Epoch 537/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.4112e-04 - val_loss: 6.6882e-04\n",
      "Epoch 538/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4061e-04 - val_loss: 6.9432e-04\n",
      "Epoch 539/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4151e-04 - val_loss: 6.7502e-04\n",
      "Epoch 540/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4041e-04 - val_loss: 6.8601e-04\n",
      "Epoch 541/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4063e-04 - val_loss: 6.7493e-04\n",
      "Epoch 542/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.4122e-04 - val_loss: 6.8051e-04\n",
      "Epoch 543/10000\n",
      "45507/45507 [==============================] - 1s 22us/step - loss: 6.4078e-04 - val_loss: 6.8479e-04\n",
      "Epoch 544/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.4035e-04 - val_loss: 6.7834e-04\n",
      "Epoch 545/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.4034e-04 - val_loss: 6.7924e-04\n",
      "Epoch 546/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.4064e-04 - val_loss: 6.7725e-04\n",
      "Epoch 547/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4055e-04 - val_loss: 6.8390e-04\n",
      "Epoch 548/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4053e-04 - val_loss: 6.7782e-04\n",
      "Epoch 549/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4025e-04 - val_loss: 6.7050e-04\n",
      "Epoch 550/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3954e-04 - val_loss: 6.7769e-04\n",
      "Epoch 551/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3998e-04 - val_loss: 6.7835e-04\n",
      "Epoch 552/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3979e-04 - val_loss: 6.8663e-04\n",
      "Epoch 553/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.4000e-04 - val_loss: 6.7058e-04\n",
      "Epoch 554/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3942e-04 - val_loss: 6.8433e-04\n",
      "Epoch 555/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.4000e-04 - val_loss: 6.7232e-04\n",
      "Epoch 556/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.3920e-04 - val_loss: 6.8067e-04\n",
      "Epoch 557/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3923e-04 - val_loss: 6.7238e-04\n",
      "Epoch 558/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.3922e-04 - val_loss: 6.6861e-04\n",
      "Epoch 559/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.3859e-04 - val_loss: 6.8035e-04\n",
      "Epoch 560/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3859e-04 - val_loss: 6.8060e-04\n",
      "Epoch 561/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.3830e-04 - val_loss: 6.8032e-04\n",
      "Epoch 562/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 1s 24us/step - loss: 6.3861e-04 - val_loss: 6.7832e-04\n",
      "Epoch 563/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.3844e-04 - val_loss: 6.7985e-04\n",
      "Epoch 564/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3881e-04 - val_loss: 6.7929e-04\n",
      "Epoch 565/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3878e-04 - val_loss: 6.7581e-04\n",
      "Epoch 566/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.3851e-04 - val_loss: 6.7288e-04\n",
      "Epoch 567/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3764e-04 - val_loss: 6.7880e-04\n",
      "Epoch 568/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3813e-04 - val_loss: 6.5705e-04\n",
      "Epoch 569/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3856e-04 - val_loss: 6.6424e-04\n",
      "Epoch 570/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3803e-04 - val_loss: 6.7342e-04\n",
      "Epoch 571/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3824e-04 - val_loss: 6.5937e-04\n",
      "Epoch 572/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3802e-04 - val_loss: 6.6856e-04\n",
      "Epoch 573/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3822e-04 - val_loss: 6.7806e-04\n",
      "Epoch 574/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3834e-04 - val_loss: 6.6619e-04\n",
      "Epoch 575/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.3801e-04 - val_loss: 6.7144e-04\n",
      "Epoch 576/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3774e-04 - val_loss: 6.6733e-04\n",
      "Epoch 577/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3780e-04 - val_loss: 6.8170e-04\n",
      "Epoch 578/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3796e-04 - val_loss: 6.6754e-04\n",
      "Epoch 579/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.3774e-04 - val_loss: 6.7050e-04\n",
      "Epoch 580/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3823e-04 - val_loss: 6.7540e-04\n",
      "Epoch 581/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.3752e-04 - val_loss: 6.7701e-04\n",
      "Epoch 582/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.3708e-04 - val_loss: 6.7874e-04\n",
      "Epoch 583/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3693e-04 - val_loss: 6.7446e-04\n",
      "Epoch 584/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3726e-04 - val_loss: 6.6627e-04\n",
      "Epoch 585/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3738e-04 - val_loss: 6.8013e-04\n",
      "Epoch 586/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3720e-04 - val_loss: 6.6918e-04\n",
      "Epoch 587/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3712e-04 - val_loss: 6.6493e-04\n",
      "Epoch 588/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.3646e-04 - val_loss: 6.6275e-04\n",
      "Epoch 589/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3668e-04 - val_loss: 6.7445e-04\n",
      "Epoch 590/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3683e-04 - val_loss: 6.6869e-04\n",
      "Epoch 591/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3708e-04 - val_loss: 6.7942e-04\n",
      "Epoch 592/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3697e-04 - val_loss: 6.6514e-04\n",
      "Epoch 593/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3649e-04 - val_loss: 6.6784e-04\n",
      "Epoch 594/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.3636e-04 - val_loss: 6.7384e-04\n",
      "Epoch 595/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3660e-04 - val_loss: 6.6936e-04\n",
      "Epoch 596/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3646e-04 - val_loss: 6.6544e-04\n",
      "Epoch 597/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3648e-04 - val_loss: 6.6700e-04\n",
      "Epoch 598/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3635e-04 - val_loss: 6.6815e-04\n",
      "Epoch 599/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.3650e-04 - val_loss: 6.6260e-04\n",
      "Epoch 600/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.3611e-04 - val_loss: 6.7265e-04\n",
      "Epoch 601/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3607e-04 - val_loss: 6.6589e-04\n",
      "Epoch 602/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3620e-04 - val_loss: 6.6272e-04\n",
      "Epoch 603/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3615e-04 - val_loss: 6.6982e-04\n",
      "Epoch 604/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3679e-04 - val_loss: 6.6879e-04\n",
      "Epoch 605/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3591e-04 - val_loss: 6.7108e-04\n",
      "Epoch 606/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3596e-04 - val_loss: 6.6508e-04\n",
      "Epoch 607/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3612e-04 - val_loss: 6.6966e-04\n",
      "Epoch 608/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3606e-04 - val_loss: 6.6484e-04\n",
      "Epoch 609/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3540e-04 - val_loss: 6.6820e-04\n",
      "Epoch 610/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3556e-04 - val_loss: 6.6886e-04\n",
      "Epoch 611/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3584e-04 - val_loss: 6.6475e-04\n",
      "Epoch 612/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3553e-04 - val_loss: 6.6260e-04\n",
      "Epoch 613/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3525e-04 - val_loss: 6.6773e-04\n",
      "Epoch 614/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.3517e-04 - val_loss: 6.6082e-04\n",
      "Epoch 615/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3480e-04 - val_loss: 6.6686e-04\n",
      "Epoch 616/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3523e-04 - val_loss: 6.7019e-04\n",
      "Epoch 617/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.3540e-04 - val_loss: 6.6874e-04\n",
      "Epoch 618/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.3558e-04 - val_loss: 6.6119e-04\n",
      "Epoch 619/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 6.3484e-04 - val_loss: 6.6695e-04\n",
      "Epoch 620/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 6.3526e-04 - val_loss: 6.6065e-04\n",
      "Epoch 621/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.3438e-04 - val_loss: 6.5964e-04\n",
      "Epoch 622/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.3455e-04 - val_loss: 6.6109e-04\n",
      "Epoch 623/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3453e-04 - val_loss: 6.7185e-04\n",
      "Epoch 624/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.3480e-04 - val_loss: 6.7136e-04\n",
      "Epoch 625/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3503e-04 - val_loss: 6.5735e-04\n",
      "Epoch 626/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3392e-04 - val_loss: 6.6434e-04\n",
      "Epoch 627/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3446e-04 - val_loss: 6.5561e-04\n",
      "Epoch 628/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3390e-04 - val_loss: 6.5761e-04\n",
      "Epoch 629/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3391e-04 - val_loss: 6.6883e-04\n",
      "Epoch 630/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3432e-04 - val_loss: 6.5407e-04\n",
      "Epoch 631/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3396e-04 - val_loss: 6.6208e-04\n",
      "Epoch 632/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.3340e-04 - val_loss: 6.6204e-04\n",
      "Epoch 633/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3369e-04 - val_loss: 6.5313e-04\n",
      "Epoch 634/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3404e-04 - val_loss: 6.5353e-04\n",
      "Epoch 635/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3318e-04 - val_loss: 6.6898e-04\n",
      "Epoch 636/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3366e-04 - val_loss: 6.5412e-04\n",
      "Epoch 637/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3293e-04 - val_loss: 6.5869e-04\n",
      "Epoch 638/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 6.3305e-04 - val_loss: 6.5451e-04\n",
      "Epoch 639/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.3276e-04 - val_loss: 6.5598e-04\n",
      "Epoch 640/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3343e-04 - val_loss: 6.5427e-04\n",
      "Epoch 641/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3293e-04 - val_loss: 6.5407e-04\n",
      "Epoch 642/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3255e-04 - val_loss: 6.5475e-04\n",
      "Epoch 643/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3243e-04 - val_loss: 6.5507e-04\n",
      "Epoch 644/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3224e-04 - val_loss: 6.5782e-04\n",
      "Epoch 645/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3272e-04 - val_loss: 6.5543e-04\n",
      "Epoch 646/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3214e-04 - val_loss: 6.6697e-04\n",
      "Epoch 647/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3254e-04 - val_loss: 6.6520e-04\n",
      "Epoch 648/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3244e-04 - val_loss: 6.6361e-04\n",
      "Epoch 649/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3225e-04 - val_loss: 6.6115e-04\n",
      "Epoch 650/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3214e-04 - val_loss: 6.6035e-04\n",
      "Epoch 651/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3185e-04 - val_loss: 6.5554e-04\n",
      "Epoch 652/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3290e-04 - val_loss: 6.5582e-04\n",
      "Epoch 653/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.3210e-04 - val_loss: 6.5567e-04\n",
      "Epoch 654/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3135e-04 - val_loss: 6.5438e-04\n",
      "Epoch 655/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3142e-04 - val_loss: 6.5569e-04\n",
      "Epoch 656/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.3178e-04 - val_loss: 6.5492e-04\n",
      "Epoch 657/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.3193e-04 - val_loss: 6.5419e-04\n",
      "Epoch 658/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.3076e-04 - val_loss: 6.5285e-04\n",
      "Epoch 659/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.3093e-04 - val_loss: 6.5675e-04\n",
      "Epoch 660/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3087e-04 - val_loss: 6.5378e-04\n",
      "Epoch 661/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3070e-04 - val_loss: 6.5364e-04\n",
      "Epoch 662/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3077e-04 - val_loss: 6.5599e-04\n",
      "Epoch 663/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3100e-04 - val_loss: 6.5280e-04\n",
      "Epoch 664/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3045e-04 - val_loss: 6.5534e-04\n",
      "Epoch 665/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3069e-04 - val_loss: 6.5221e-04\n",
      "Epoch 666/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.3042e-04 - val_loss: 6.5398e-04\n",
      "Epoch 667/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3001e-04 - val_loss: 6.5276e-04\n",
      "Epoch 668/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3054e-04 - val_loss: 6.5357e-04\n",
      "Epoch 669/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2988e-04 - val_loss: 6.5265e-04\n",
      "Epoch 670/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.2982e-04 - val_loss: 6.5333e-04\n",
      "Epoch 671/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2966e-04 - val_loss: 6.5389e-04\n",
      "Epoch 672/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.3016e-04 - val_loss: 6.5636e-04\n",
      "Epoch 673/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.3024e-04 - val_loss: 6.5321e-04\n",
      "Epoch 674/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.3011e-04 - val_loss: 6.5319e-04\n",
      "Epoch 675/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2980e-04 - val_loss: 6.5405e-04\n",
      "Epoch 676/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.2947e-04 - val_loss: 6.6333e-04\n",
      "Epoch 677/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2999e-04 - val_loss: 6.5365e-04\n",
      "Epoch 678/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2930e-04 - val_loss: 6.5694e-04\n",
      "Epoch 679/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2980e-04 - val_loss: 6.5282e-04\n",
      "Epoch 680/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2919e-04 - val_loss: 6.5199e-04\n",
      "Epoch 681/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2917e-04 - val_loss: 6.5281e-04\n",
      "Epoch 682/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.2917e-04 - val_loss: 6.5265e-04\n",
      "Epoch 683/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2904e-04 - val_loss: 6.5470e-04\n",
      "Epoch 684/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2956e-04 - val_loss: 6.5343e-04\n",
      "Epoch 685/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2929e-04 - val_loss: 6.5383e-04\n",
      "Epoch 686/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2888e-04 - val_loss: 6.5401e-04\n",
      "Epoch 687/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2916e-04 - val_loss: 6.5297e-04\n",
      "Epoch 688/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2894e-04 - val_loss: 6.5365e-04\n",
      "Epoch 689/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.2911e-04 - val_loss: 6.5376e-04\n",
      "Epoch 690/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2853e-04 - val_loss: 6.5354e-04\n",
      "Epoch 691/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2927e-04 - val_loss: 6.5359e-04\n",
      "Epoch 692/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2883e-04 - val_loss: 6.5344e-04\n",
      "Epoch 693/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2870e-04 - val_loss: 6.5303e-04\n",
      "Epoch 694/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2828e-04 - val_loss: 6.6403e-04\n",
      "Epoch 695/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 6.2844e-04 - val_loss: 6.5627e-04\n",
      "Epoch 696/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.2814e-04 - val_loss: 6.5248e-04\n",
      "Epoch 697/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2857e-04 - val_loss: 6.5356e-04\n",
      "Epoch 698/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.2860e-04 - val_loss: 6.5355e-04\n",
      "Epoch 699/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2796e-04 - val_loss: 6.6299e-04\n",
      "Epoch 700/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2828e-04 - val_loss: 6.5169e-04\n",
      "Epoch 701/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2817e-04 - val_loss: 6.5415e-04\n",
      "Epoch 702/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2791e-04 - val_loss: 6.5285e-04\n",
      "Epoch 703/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2778e-04 - val_loss: 6.5259e-04\n",
      "Epoch 704/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2788e-04 - val_loss: 6.5330e-04\n",
      "Epoch 705/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2740e-04 - val_loss: 6.5356e-04\n",
      "Epoch 706/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2770e-04 - val_loss: 6.5310e-04\n",
      "Epoch 707/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2795e-04 - val_loss: 6.5268e-04\n",
      "Epoch 708/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2710e-04 - val_loss: 6.5435e-04\n",
      "Epoch 709/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2722e-04 - val_loss: 6.5332e-04\n",
      "Epoch 710/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2729e-04 - val_loss: 6.5275e-04\n",
      "Epoch 711/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2758e-04 - val_loss: 6.5272e-04\n",
      "Epoch 712/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2717e-04 - val_loss: 6.5177e-04\n",
      "Epoch 713/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.2686e-04 - val_loss: 6.5389e-04\n",
      "Epoch 714/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 6.2701e-04 - val_loss: 6.5272e-04\n",
      "Epoch 715/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.2679e-04 - val_loss: 6.5136e-04\n",
      "Epoch 716/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2719e-04 - val_loss: 6.5140e-04\n",
      "Epoch 717/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2650e-04 - val_loss: 6.5291e-04\n",
      "Epoch 718/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2645e-04 - val_loss: 6.5098e-04\n",
      "Epoch 719/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2679e-04 - val_loss: 6.5097e-04\n",
      "Epoch 720/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2690e-04 - val_loss: 6.5103e-04\n",
      "Epoch 721/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2653e-04 - val_loss: 6.5116e-04\n",
      "Epoch 722/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2634e-04 - val_loss: 6.5121e-04\n",
      "Epoch 723/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2590e-04 - val_loss: 6.5258e-04\n",
      "Epoch 724/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.2655e-04 - val_loss: 6.5003e-04\n",
      "Epoch 725/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2624e-04 - val_loss: 6.5051e-04\n",
      "Epoch 726/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2612e-04 - val_loss: 6.5146e-04\n",
      "Epoch 727/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.2644e-04 - val_loss: 6.4884e-04\n",
      "Epoch 728/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2613e-04 - val_loss: 6.4945e-04\n",
      "Epoch 729/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2592e-04 - val_loss: 6.4824e-04\n",
      "Epoch 730/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2568e-04 - val_loss: 6.4994e-04\n",
      "Epoch 731/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2578e-04 - val_loss: 6.4866e-04\n",
      "Epoch 732/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2584e-04 - val_loss: 6.5086e-04\n",
      "Epoch 733/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.2557e-04 - val_loss: 6.5068e-04\n",
      "Epoch 734/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2564e-04 - val_loss: 6.5017e-04\n",
      "Epoch 735/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2511e-04 - val_loss: 6.4931e-04\n",
      "Epoch 736/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2564e-04 - val_loss: 6.4939e-04\n",
      "Epoch 737/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2543e-04 - val_loss: 6.4931e-04\n",
      "Epoch 738/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2522e-04 - val_loss: 6.4998e-04\n",
      "Epoch 739/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2513e-04 - val_loss: 6.4956e-04\n",
      "Epoch 740/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2499e-04 - val_loss: 6.5049e-04\n",
      "Epoch 741/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2475e-04 - val_loss: 6.4958e-04\n",
      "Epoch 742/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2457e-04 - val_loss: 6.4990e-04\n",
      "Epoch 743/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2489e-04 - val_loss: 6.4983e-04\n",
      "Epoch 744/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2457e-04 - val_loss: 6.4801e-04\n",
      "Epoch 745/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2480e-04 - val_loss: 6.4910e-04\n",
      "Epoch 746/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.2460e-04 - val_loss: 6.4911e-04\n",
      "Epoch 747/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2461e-04 - val_loss: 6.4747e-04\n",
      "Epoch 748/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2437e-04 - val_loss: 6.4888e-04\n",
      "Epoch 749/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2411e-04 - val_loss: 6.4947e-04\n",
      "Epoch 750/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2444e-04 - val_loss: 6.4889e-04\n",
      "Epoch 751/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.2439e-04 - val_loss: 6.4879e-04\n",
      "Epoch 752/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 6.2395e-04 - val_loss: 6.4911e-04\n",
      "Epoch 753/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2383e-04 - val_loss: 6.4825e-04\n",
      "Epoch 754/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2379e-04 - val_loss: 6.4870e-04\n",
      "Epoch 755/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2359e-04 - val_loss: 6.4904e-04\n",
      "Epoch 756/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.2366e-04 - val_loss: 6.4897e-04\n",
      "Epoch 757/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2342e-04 - val_loss: 6.4899e-04\n",
      "Epoch 758/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2343e-04 - val_loss: 6.4840e-04\n",
      "Epoch 759/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2347e-04 - val_loss: 6.4832e-04\n",
      "Epoch 760/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2330e-04 - val_loss: 6.4823e-04\n",
      "Epoch 761/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2289e-04 - val_loss: 6.4915e-04\n",
      "Epoch 762/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.2315e-04 - val_loss: 6.4851e-04\n",
      "Epoch 763/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2285e-04 - val_loss: 6.4766e-04\n",
      "Epoch 764/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2284e-04 - val_loss: 6.4819e-04\n",
      "Epoch 765/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2258e-04 - val_loss: 6.4764e-04\n",
      "Epoch 766/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2266e-04 - val_loss: 6.4699e-04\n",
      "Epoch 767/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2274e-04 - val_loss: 6.4771e-04\n",
      "Epoch 768/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2259e-04 - val_loss: 6.4709e-04\n",
      "Epoch 769/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2283e-04 - val_loss: 6.4578e-04\n",
      "Epoch 770/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.2248e-04 - val_loss: 6.4590e-04\n",
      "Epoch 771/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.2231e-04 - val_loss: 6.4725e-04\n",
      "Epoch 772/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2245e-04 - val_loss: 6.4554e-04\n",
      "Epoch 773/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2200e-04 - val_loss: 6.4598e-04\n",
      "Epoch 774/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2252e-04 - val_loss: 6.4558e-04\n",
      "Epoch 775/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2201e-04 - val_loss: 6.4591e-04\n",
      "Epoch 776/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2216e-04 - val_loss: 6.4624e-04\n",
      "Epoch 777/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2207e-04 - val_loss: 6.4502e-04\n",
      "Epoch 778/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2217e-04 - val_loss: 6.4578e-04\n",
      "Epoch 779/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2191e-04 - val_loss: 6.4510e-04\n",
      "Epoch 780/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2152e-04 - val_loss: 6.4505e-04\n",
      "Epoch 781/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2166e-04 - val_loss: 6.4462e-04\n",
      "Epoch 782/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2166e-04 - val_loss: 6.4479e-04\n",
      "Epoch 783/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.2165e-04 - val_loss: 6.4619e-04\n",
      "Epoch 784/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2144e-04 - val_loss: 6.4422e-04\n",
      "Epoch 785/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2126e-04 - val_loss: 6.4545e-04\n",
      "Epoch 786/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2153e-04 - val_loss: 6.4585e-04\n",
      "Epoch 787/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2119e-04 - val_loss: 6.4591e-04\n",
      "Epoch 788/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2157e-04 - val_loss: 6.4407e-04\n",
      "Epoch 789/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.2143e-04 - val_loss: 6.4394e-04\n",
      "Epoch 790/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 6.2082e-04 - val_loss: 6.4453e-04\n",
      "Epoch 791/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.2130e-04 - val_loss: 6.4378e-04\n",
      "Epoch 792/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2117e-04 - val_loss: 6.4361e-04\n",
      "Epoch 793/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2084e-04 - val_loss: 6.4401e-04\n",
      "Epoch 794/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2075e-04 - val_loss: 6.4477e-04\n",
      "Epoch 795/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2080e-04 - val_loss: 6.4457e-04\n",
      "Epoch 796/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2136e-04 - val_loss: 6.4394e-04\n",
      "Epoch 797/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2075e-04 - val_loss: 6.4382e-04\n",
      "Epoch 798/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.2068e-04 - val_loss: 6.4461e-04\n",
      "Epoch 799/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2054e-04 - val_loss: 6.4324e-04\n",
      "Epoch 800/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2115e-04 - val_loss: 6.4346e-04\n",
      "Epoch 801/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2087e-04 - val_loss: 6.4340e-04\n",
      "Epoch 802/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.2024e-04 - val_loss: 6.4391e-04\n",
      "Epoch 803/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2010e-04 - val_loss: 6.4376e-04\n",
      "Epoch 804/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.2019e-04 - val_loss: 6.4444e-04\n",
      "Epoch 805/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.2015e-04 - val_loss: 6.4384e-04\n",
      "Epoch 806/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1973e-04 - val_loss: 6.4411e-04\n",
      "Epoch 807/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2014e-04 - val_loss: 6.4331e-04\n",
      "Epoch 808/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.1994e-04 - val_loss: 6.4353e-04\n",
      "Epoch 809/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.1998e-04 - val_loss: 6.4292e-04\n",
      "Epoch 810/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1965e-04 - val_loss: 6.4410e-04\n",
      "Epoch 811/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1960e-04 - val_loss: 6.4316e-04\n",
      "Epoch 812/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1903e-04 - val_loss: 6.4302e-04\n",
      "Epoch 813/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.2027e-04 - val_loss: 6.4334e-04\n",
      "Epoch 814/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1928e-04 - val_loss: 6.4362e-04\n",
      "Epoch 815/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1966e-04 - val_loss: 6.4361e-04\n",
      "Epoch 816/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1946e-04 - val_loss: 6.4330e-04\n",
      "Epoch 817/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.1931e-04 - val_loss: 6.4325e-04\n",
      "Epoch 818/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1896e-04 - val_loss: 6.4341e-04\n",
      "Epoch 819/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1914e-04 - val_loss: 6.4339e-04\n",
      "Epoch 820/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1889e-04 - val_loss: 6.4323e-04\n",
      "Epoch 821/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1885e-04 - val_loss: 6.4288e-04\n",
      "Epoch 822/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1864e-04 - val_loss: 6.4252e-04\n",
      "Epoch 823/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.1833e-04 - val_loss: 6.4294e-04\n",
      "Epoch 824/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1879e-04 - val_loss: 6.4219e-04\n",
      "Epoch 825/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1815e-04 - val_loss: 6.4025e-04\n",
      "Epoch 826/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1807e-04 - val_loss: 6.4026e-04\n",
      "Epoch 827/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.1817e-04 - val_loss: 6.4050e-04\n",
      "Epoch 828/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.1796e-04 - val_loss: 6.4020e-04\n",
      "Epoch 829/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1794e-04 - val_loss: 6.3952e-04\n",
      "Epoch 830/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.1787e-04 - val_loss: 6.3921e-04\n",
      "Epoch 831/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1739e-04 - val_loss: 6.3892e-04\n",
      "Epoch 832/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1785e-04 - val_loss: 6.3906e-04\n",
      "Epoch 833/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1744e-04 - val_loss: 6.3939e-04\n",
      "Epoch 834/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1767e-04 - val_loss: 6.3892e-04\n",
      "Epoch 835/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1781e-04 - val_loss: 6.3927e-04\n",
      "Epoch 836/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1765e-04 - val_loss: 6.3856e-04\n",
      "Epoch 837/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1742e-04 - val_loss: 6.3895e-04\n",
      "Epoch 838/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1721e-04 - val_loss: 6.3862e-04\n",
      "Epoch 839/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1716e-04 - val_loss: 6.3863e-04\n",
      "Epoch 840/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1715e-04 - val_loss: 6.3849e-04\n",
      "Epoch 841/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1704e-04 - val_loss: 6.3914e-04\n",
      "Epoch 842/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.1690e-04 - val_loss: 6.3881e-04\n",
      "Epoch 843/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1684e-04 - val_loss: 6.3837e-04\n",
      "Epoch 844/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1678e-04 - val_loss: 6.3877e-04\n",
      "Epoch 845/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1672e-04 - val_loss: 6.3873e-04\n",
      "Epoch 846/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.1660e-04 - val_loss: 6.3796e-04\n",
      "Epoch 847/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.1649e-04 - val_loss: 6.3790e-04\n",
      "Epoch 848/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1639e-04 - val_loss: 6.3794e-04\n",
      "Epoch 849/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.1630e-04 - val_loss: 6.3802e-04\n",
      "Epoch 850/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1623e-04 - val_loss: 6.3798e-04\n",
      "Epoch 851/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1621e-04 - val_loss: 6.3768e-04\n",
      "Epoch 852/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.1603e-04 - val_loss: 6.3744e-04\n",
      "Epoch 853/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1601e-04 - val_loss: 6.3706e-04\n",
      "Epoch 854/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1589e-04 - val_loss: 6.3720e-04\n",
      "Epoch 855/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1627e-04 - val_loss: 6.3691e-04\n",
      "Epoch 856/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1626e-04 - val_loss: 6.3730e-04\n",
      "Epoch 857/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1657e-04 - val_loss: 6.3681e-04\n",
      "Epoch 858/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1609e-04 - val_loss: 6.3619e-04\n",
      "Epoch 859/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.1637e-04 - val_loss: 6.3688e-04\n",
      "Epoch 860/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1628e-04 - val_loss: 6.3512e-04\n",
      "Epoch 861/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1580e-04 - val_loss: 6.3510e-04\n",
      "Epoch 862/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1571e-04 - val_loss: 6.3640e-04\n",
      "Epoch 863/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1575e-04 - val_loss: 6.3612e-04\n",
      "Epoch 864/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1548e-04 - val_loss: 6.3629e-04\n",
      "Epoch 865/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.1542e-04 - val_loss: 6.3596e-04\n",
      "Epoch 866/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.1533e-04 - val_loss: 6.3465e-04\n",
      "Epoch 867/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1520e-04 - val_loss: 6.3451e-04\n",
      "Epoch 868/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1505e-04 - val_loss: 6.3466e-04\n",
      "Epoch 869/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1550e-04 - val_loss: 6.3461e-04\n",
      "Epoch 870/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1485e-04 - val_loss: 6.3482e-04\n",
      "Epoch 871/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1493e-04 - val_loss: 6.3455e-04\n",
      "Epoch 872/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1534e-04 - val_loss: 6.3378e-04\n",
      "Epoch 873/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1487e-04 - val_loss: 6.3351e-04\n",
      "Epoch 874/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1480e-04 - val_loss: 6.3418e-04\n",
      "Epoch 875/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1497e-04 - val_loss: 6.3329e-04\n",
      "Epoch 876/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1439e-04 - val_loss: 6.3365e-04\n",
      "Epoch 877/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1481e-04 - val_loss: 6.3392e-04\n",
      "Epoch 878/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1472e-04 - val_loss: 6.3281e-04\n",
      "Epoch 879/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1482e-04 - val_loss: 6.3307e-04\n",
      "Epoch 880/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1437e-04 - val_loss: 6.3332e-04\n",
      "Epoch 881/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1426e-04 - val_loss: 6.3340e-04\n",
      "Epoch 882/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1431e-04 - val_loss: 6.3297e-04\n",
      "Epoch 883/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1419e-04 - val_loss: 6.3314e-04\n",
      "Epoch 884/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.1429e-04 - val_loss: 6.3279e-04\n",
      "Epoch 885/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1429e-04 - val_loss: 6.3239e-04\n",
      "Epoch 886/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1395e-04 - val_loss: 6.3332e-04\n",
      "Epoch 887/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.1435e-04 - val_loss: 6.3316e-04\n",
      "Epoch 888/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1382e-04 - val_loss: 6.3240e-04\n",
      "Epoch 889/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1387e-04 - val_loss: 6.3221e-04\n",
      "Epoch 890/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1363e-04 - val_loss: 6.3293e-04\n",
      "Epoch 891/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1363e-04 - val_loss: 6.3245e-04\n",
      "Epoch 892/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1340e-04 - val_loss: 6.3298e-04\n",
      "Epoch 893/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1355e-04 - val_loss: 6.3269e-04\n",
      "Epoch 894/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1321e-04 - val_loss: 6.3225e-04\n",
      "Epoch 895/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1359e-04 - val_loss: 6.3336e-04\n",
      "Epoch 896/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1355e-04 - val_loss: 6.3336e-04\n",
      "Epoch 897/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1318e-04 - val_loss: 6.3291e-04\n",
      "Epoch 898/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1306e-04 - val_loss: 6.3219e-04\n",
      "Epoch 899/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1296e-04 - val_loss: 6.3245e-04\n",
      "Epoch 900/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1307e-04 - val_loss: 6.3034e-04\n",
      "Epoch 901/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1295e-04 - val_loss: 6.3293e-04\n",
      "Epoch 902/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.1287e-04 - val_loss: 6.3377e-04\n",
      "Epoch 903/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 6.1304e-04 - val_loss: 6.3277e-04\n",
      "Epoch 904/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.1286e-04 - val_loss: 6.3102e-04\n",
      "Epoch 905/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1279e-04 - val_loss: 6.3253e-04\n",
      "Epoch 906/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1249e-04 - val_loss: 6.3290e-04\n",
      "Epoch 907/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1241e-04 - val_loss: 6.3286e-04\n",
      "Epoch 908/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1250e-04 - val_loss: 6.3142e-04\n",
      "Epoch 909/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1250e-04 - val_loss: 6.3198e-04\n",
      "Epoch 910/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1233e-04 - val_loss: 6.3212e-04\n",
      "Epoch 911/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1231e-04 - val_loss: 6.3278e-04\n",
      "Epoch 912/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1206e-04 - val_loss: 6.3258e-04\n",
      "Epoch 913/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1245e-04 - val_loss: 6.3155e-04\n",
      "Epoch 914/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1222e-04 - val_loss: 6.3192e-04\n",
      "Epoch 915/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1226e-04 - val_loss: 6.3023e-04\n",
      "Epoch 916/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1204e-04 - val_loss: 6.3158e-04\n",
      "Epoch 917/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1175e-04 - val_loss: 6.3260e-04\n",
      "Epoch 918/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1191e-04 - val_loss: 6.3069e-04\n",
      "Epoch 919/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1171e-04 - val_loss: 6.3118e-04\n",
      "Epoch 920/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1183e-04 - val_loss: 6.2996e-04\n",
      "Epoch 921/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.1183e-04 - val_loss: 6.3107e-04\n",
      "Epoch 922/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 6.1166e-04 - val_loss: 6.3003e-04\n",
      "Epoch 923/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.1129e-04 - val_loss: 6.3126e-04\n",
      "Epoch 924/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1156e-04 - val_loss: 6.2936e-04\n",
      "Epoch 925/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1153e-04 - val_loss: 6.3115e-04\n",
      "Epoch 926/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1173e-04 - val_loss: 6.3012e-04\n",
      "Epoch 927/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.1165e-04 - val_loss: 6.3010e-04\n",
      "Epoch 928/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1126e-04 - val_loss: 6.2956e-04\n",
      "Epoch 929/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.1114e-04 - val_loss: 6.3040e-04\n",
      "Epoch 930/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1123e-04 - val_loss: 6.3192e-04\n",
      "Epoch 931/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1112e-04 - val_loss: 6.2867e-04\n",
      "Epoch 932/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1086e-04 - val_loss: 6.3163e-04\n",
      "Epoch 933/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1080e-04 - val_loss: 6.3047e-04\n",
      "Epoch 934/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1087e-04 - val_loss: 6.3127e-04\n",
      "Epoch 935/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.1073e-04 - val_loss: 6.3075e-04\n",
      "Epoch 936/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1079e-04 - val_loss: 6.3089e-04\n",
      "Epoch 937/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.1075e-04 - val_loss: 6.3186e-04\n",
      "Epoch 938/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1040e-04 - val_loss: 6.3285e-04\n",
      "Epoch 939/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1061e-04 - val_loss: 6.3213e-04\n",
      "Epoch 940/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.1035e-04 - val_loss: 6.3108e-04\n",
      "Epoch 941/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 6.1041e-04 - val_loss: 6.3013e-04\n",
      "Epoch 942/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.1047e-04 - val_loss: 6.3185e-04\n",
      "Epoch 943/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1014e-04 - val_loss: 6.3156e-04\n",
      "Epoch 944/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.1015e-04 - val_loss: 6.3032e-04\n",
      "Epoch 945/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0990e-04 - val_loss: 6.3221e-04\n",
      "Epoch 946/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1003e-04 - val_loss: 6.2840e-04\n",
      "Epoch 947/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1026e-04 - val_loss: 6.2900e-04\n",
      "Epoch 948/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.1012e-04 - val_loss: 6.3018e-04\n",
      "Epoch 949/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.1000e-04 - val_loss: 6.2996e-04\n",
      "Epoch 950/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0987e-04 - val_loss: 6.2945e-04\n",
      "Epoch 951/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.1005e-04 - val_loss: 6.3072e-04\n",
      "Epoch 952/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0990e-04 - val_loss: 6.3016e-04\n",
      "Epoch 953/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0967e-04 - val_loss: 6.3037e-04\n",
      "Epoch 954/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.0960e-04 - val_loss: 6.2873e-04\n",
      "Epoch 955/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.0943e-04 - val_loss: 6.3240e-04\n",
      "Epoch 956/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0923e-04 - val_loss: 6.3077e-04\n",
      "Epoch 957/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0950e-04 - val_loss: 6.2960e-04\n",
      "Epoch 958/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.0955e-04 - val_loss: 6.3055e-04\n",
      "Epoch 959/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0952e-04 - val_loss: 6.3037e-04\n",
      "Epoch 960/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 6.0931e-04 - val_loss: 6.3024e-04\n",
      "Epoch 961/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.0913e-04 - val_loss: 6.3117e-04\n",
      "Epoch 962/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0916e-04 - val_loss: 6.2998e-04\n",
      "Epoch 963/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0904e-04 - val_loss: 6.3233e-04\n",
      "Epoch 964/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0900e-04 - val_loss: 6.3181e-04\n",
      "Epoch 965/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0889e-04 - val_loss: 6.3436e-04\n",
      "Epoch 966/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0900e-04 - val_loss: 6.2812e-04\n",
      "Epoch 967/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0879e-04 - val_loss: 6.2935e-04\n",
      "Epoch 968/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0869e-04 - val_loss: 6.3010e-04\n",
      "Epoch 969/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0870e-04 - val_loss: 6.3023e-04\n",
      "Epoch 970/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0844e-04 - val_loss: 6.3475e-04\n",
      "Epoch 971/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0863e-04 - val_loss: 6.2649e-04\n",
      "Epoch 972/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0851e-04 - val_loss: 6.3059e-04\n",
      "Epoch 973/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.0851e-04 - val_loss: 6.3113e-04\n",
      "Epoch 974/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0830e-04 - val_loss: 6.3104e-04\n",
      "Epoch 975/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0817e-04 - val_loss: 6.3043e-04\n",
      "Epoch 976/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0814e-04 - val_loss: 6.2959e-04\n",
      "Epoch 977/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0813e-04 - val_loss: 6.3048e-04\n",
      "Epoch 978/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0822e-04 - val_loss: 6.3033e-04\n",
      "Epoch 979/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 6.0817e-04 - val_loss: 6.3049e-04\n",
      "Epoch 980/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 6.0815e-04 - val_loss: 6.3107e-04\n",
      "Epoch 981/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.0799e-04 - val_loss: 6.3017e-04\n",
      "Epoch 982/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0805e-04 - val_loss: 6.3102e-04\n",
      "Epoch 983/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0793e-04 - val_loss: 6.3025e-04\n",
      "Epoch 984/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0776e-04 - val_loss: 6.3046e-04\n",
      "Epoch 985/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0785e-04 - val_loss: 6.2472e-04\n",
      "Epoch 986/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0763e-04 - val_loss: 6.2999e-04\n",
      "Epoch 987/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.0759e-04 - val_loss: 6.2917e-04\n",
      "Epoch 988/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0748e-04 - val_loss: 6.3027e-04\n",
      "Epoch 989/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0746e-04 - val_loss: 6.3094e-04\n",
      "Epoch 990/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0747e-04 - val_loss: 6.2521e-04\n",
      "Epoch 991/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0744e-04 - val_loss: 6.2834e-04\n",
      "Epoch 992/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0736e-04 - val_loss: 6.2413e-04\n",
      "Epoch 993/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0726e-04 - val_loss: 6.2766e-04\n",
      "Epoch 994/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0718e-04 - val_loss: 6.3106e-04\n",
      "Epoch 995/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0685e-04 - val_loss: 6.2822e-04\n",
      "Epoch 996/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0667e-04 - val_loss: 6.2724e-04\n",
      "Epoch 997/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0711e-04 - val_loss: 6.2319e-04\n",
      "Epoch 998/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.0659e-04 - val_loss: 6.2732e-04\n",
      "Epoch 999/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.0670e-04 - val_loss: 6.2900e-04\n",
      "Epoch 1000/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.0674e-04 - val_loss: 6.2338e-04\n",
      "Epoch 1001/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0675e-04 - val_loss: 6.2647e-04\n",
      "Epoch 1002/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0643e-04 - val_loss: 6.2670e-04\n",
      "Epoch 1003/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0674e-04 - val_loss: 6.2564e-04\n",
      "Epoch 1004/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0659e-04 - val_loss: 6.2656e-04\n",
      "Epoch 1005/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0633e-04 - val_loss: 6.2539e-04\n",
      "Epoch 1006/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0628e-04 - val_loss: 6.2463e-04\n",
      "Epoch 1007/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0641e-04 - val_loss: 6.2178e-04\n",
      "Epoch 1008/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0635e-04 - val_loss: 6.2515e-04\n",
      "Epoch 1009/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0626e-04 - val_loss: 6.2279e-04\n",
      "Epoch 1010/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0589e-04 - val_loss: 6.2415e-04\n",
      "Epoch 1011/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 6.0590e-04 - val_loss: 6.2329e-04\n",
      "Epoch 1012/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0585e-04 - val_loss: 6.2471e-04\n",
      "Epoch 1013/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0577e-04 - val_loss: 6.2191e-04\n",
      "Epoch 1014/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0557e-04 - val_loss: 6.2448e-04\n",
      "Epoch 1015/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0564e-04 - val_loss: 6.2638e-04\n",
      "Epoch 1016/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0566e-04 - val_loss: 6.2530e-04\n",
      "Epoch 1017/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 6.0557e-04 - val_loss: 6.1995e-04\n",
      "Epoch 1018/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 6.0530e-04 - val_loss: 6.2340e-04\n",
      "Epoch 1019/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0535e-04 - val_loss: 6.2139e-04\n",
      "Epoch 1020/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0542e-04 - val_loss: 6.2655e-04\n",
      "Epoch 1021/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0530e-04 - val_loss: 6.2459e-04\n",
      "Epoch 1022/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0533e-04 - val_loss: 6.2206e-04\n",
      "Epoch 1023/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0505e-04 - val_loss: 6.2392e-04\n",
      "Epoch 1024/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0521e-04 - val_loss: 6.2087e-04\n",
      "Epoch 1025/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0516e-04 - val_loss: 6.2227e-04\n",
      "Epoch 1026/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0509e-04 - val_loss: 6.2247e-04\n",
      "Epoch 1027/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0470e-04 - val_loss: 6.1858e-04\n",
      "Epoch 1028/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0518e-04 - val_loss: 6.2009e-04\n",
      "Epoch 1029/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.0486e-04 - val_loss: 6.2044e-04\n",
      "Epoch 1030/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0470e-04 - val_loss: 6.1163e-04\n",
      "Epoch 1031/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0491e-04 - val_loss: 6.1869e-04\n",
      "Epoch 1032/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.0451e-04 - val_loss: 6.1759e-04\n",
      "Epoch 1033/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0457e-04 - val_loss: 6.1791e-04\n",
      "Epoch 1034/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0445e-04 - val_loss: 6.1770e-04\n",
      "Epoch 1035/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0453e-04 - val_loss: 6.1926e-04\n",
      "Epoch 1036/10000\n",
      "45507/45507 [==============================] - 1s 23us/step - loss: 6.0451e-04 - val_loss: 6.1344e-04\n",
      "Epoch 1037/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 6.0434e-04 - val_loss: 6.1749e-04\n",
      "Epoch 1038/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0398e-04 - val_loss: 6.1475e-04\n",
      "Epoch 1039/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0410e-04 - val_loss: 6.1766e-04\n",
      "Epoch 1040/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0403e-04 - val_loss: 6.1176e-04\n",
      "Epoch 1041/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0404e-04 - val_loss: 6.1347e-04\n",
      "Epoch 1042/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0422e-04 - val_loss: 6.1368e-04\n",
      "Epoch 1043/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0392e-04 - val_loss: 6.0794e-04\n",
      "Epoch 1044/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0382e-04 - val_loss: 6.0844e-04\n",
      "Epoch 1045/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.0376e-04 - val_loss: 6.0853e-04\n",
      "Epoch 1046/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0363e-04 - val_loss: 6.1137e-04\n",
      "Epoch 1047/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0409e-04 - val_loss: 6.1657e-04\n",
      "Epoch 1048/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0354e-04 - val_loss: 6.1264e-04\n",
      "Epoch 1049/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.0367e-04 - val_loss: 6.0758e-04\n",
      "Epoch 1050/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0347e-04 - val_loss: 6.0944e-04\n",
      "Epoch 1051/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0345e-04 - val_loss: 6.0898e-04\n",
      "Epoch 1052/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0379e-04 - val_loss: 6.1476e-04\n",
      "Epoch 1053/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0349e-04 - val_loss: 6.1142e-04\n",
      "Epoch 1054/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0347e-04 - val_loss: 6.0704e-04\n",
      "Epoch 1055/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 6.0319e-04 - val_loss: 6.1231e-04\n",
      "Epoch 1056/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.0311e-04 - val_loss: 6.1511e-04\n",
      "Epoch 1057/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0310e-04 - val_loss: 6.1314e-04\n",
      "Epoch 1058/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0278e-04 - val_loss: 6.1794e-04\n",
      "Epoch 1059/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0300e-04 - val_loss: 6.1343e-04\n",
      "Epoch 1060/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0312e-04 - val_loss: 6.0522e-04\n",
      "Epoch 1061/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.0278e-04 - val_loss: 6.0481e-04\n",
      "Epoch 1062/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0285e-04 - val_loss: 6.0729e-04\n",
      "Epoch 1063/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0284e-04 - val_loss: 6.1142e-04\n",
      "Epoch 1064/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0279e-04 - val_loss: 6.1338e-04\n",
      "Epoch 1065/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0271e-04 - val_loss: 6.0511e-04\n",
      "Epoch 1066/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0256e-04 - val_loss: 6.0981e-04\n",
      "Epoch 1067/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0252e-04 - val_loss: 6.1866e-04\n",
      "Epoch 1068/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.0237e-04 - val_loss: 6.0514e-04\n",
      "Epoch 1069/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0258e-04 - val_loss: 6.0668e-04\n",
      "Epoch 1070/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0239e-04 - val_loss: 6.1308e-04\n",
      "Epoch 1071/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0243e-04 - val_loss: 6.0564e-04\n",
      "Epoch 1072/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0221e-04 - val_loss: 6.1456e-04\n",
      "Epoch 1073/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0207e-04 - val_loss: 6.0777e-04\n",
      "Epoch 1074/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 6.0238e-04 - val_loss: 6.1075e-04\n",
      "Epoch 1075/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.0213e-04 - val_loss: 6.1555e-04\n",
      "Epoch 1076/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0194e-04 - val_loss: 6.0814e-04\n",
      "Epoch 1077/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0205e-04 - val_loss: 6.1031e-04\n",
      "Epoch 1078/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0174e-04 - val_loss: 6.0607e-04\n",
      "Epoch 1079/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0203e-04 - val_loss: 6.0633e-04\n",
      "Epoch 1080/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0170e-04 - val_loss: 6.1109e-04\n",
      "Epoch 1081/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 6.0165e-04 - val_loss: 6.0988e-04\n",
      "Epoch 1082/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0143e-04 - val_loss: 6.0781e-04\n",
      "Epoch 1083/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0173e-04 - val_loss: 6.1275e-04\n",
      "Epoch 1084/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0142e-04 - val_loss: 6.0671e-04\n",
      "Epoch 1085/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0139e-04 - val_loss: 6.0571e-04\n",
      "Epoch 1086/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0158e-04 - val_loss: 6.0618e-04\n",
      "Epoch 1087/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 6.0114e-04 - val_loss: 6.0677e-04\n",
      "Epoch 1088/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0124e-04 - val_loss: 6.0604e-04\n",
      "Epoch 1089/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0132e-04 - val_loss: 6.0804e-04\n",
      "Epoch 1090/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0085e-04 - val_loss: 6.0734e-04\n",
      "Epoch 1091/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0114e-04 - val_loss: 6.0331e-04\n",
      "Epoch 1092/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0113e-04 - val_loss: 6.0523e-04\n",
      "Epoch 1093/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 6.0087e-04 - val_loss: 6.0337e-04\n",
      "Epoch 1094/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 6.0089e-04 - val_loss: 6.0331e-04\n",
      "Epoch 1095/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0085e-04 - val_loss: 6.0214e-04\n",
      "Epoch 1096/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0091e-04 - val_loss: 6.0630e-04\n",
      "Epoch 1097/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0088e-04 - val_loss: 6.0215e-04\n",
      "Epoch 1098/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0086e-04 - val_loss: 6.1247e-04\n",
      "Epoch 1099/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0069e-04 - val_loss: 6.0057e-04\n",
      "Epoch 1100/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0069e-04 - val_loss: 6.0521e-04\n",
      "Epoch 1101/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0068e-04 - val_loss: 6.0832e-04\n",
      "Epoch 1102/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 6.0052e-04 - val_loss: 6.0130e-04\n",
      "Epoch 1103/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0058e-04 - val_loss: 5.9991e-04\n",
      "Epoch 1104/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0028e-04 - val_loss: 6.0038e-04\n",
      "Epoch 1105/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 6.0028e-04 - val_loss: 6.0955e-04\n",
      "Epoch 1106/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 6.0038e-04 - val_loss: 6.0734e-04\n",
      "Epoch 1107/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0044e-04 - val_loss: 6.0142e-04\n",
      "Epoch 1108/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0030e-04 - val_loss: 5.9878e-04\n",
      "Epoch 1109/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9997e-04 - val_loss: 5.9900e-04\n",
      "Epoch 1110/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 6.0029e-04 - val_loss: 5.9893e-04\n",
      "Epoch 1111/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 6.0010e-04 - val_loss: 5.9912e-04\n",
      "Epoch 1112/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.9981e-04 - val_loss: 5.9885e-04\n",
      "Epoch 1113/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9988e-04 - val_loss: 5.9884e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1114/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9976e-04 - val_loss: 6.0161e-04\n",
      "Epoch 1115/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9979e-04 - val_loss: 6.0388e-04\n",
      "Epoch 1116/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9989e-04 - val_loss: 6.0682e-04\n",
      "Epoch 1117/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9983e-04 - val_loss: 6.0006e-04\n",
      "Epoch 1118/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9975e-04 - val_loss: 6.0314e-04\n",
      "Epoch 1119/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9944e-04 - val_loss: 6.0137e-04\n",
      "Epoch 1120/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9961e-04 - val_loss: 5.9800e-04\n",
      "Epoch 1121/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9948e-04 - val_loss: 5.9780e-04\n",
      "Epoch 1122/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9968e-04 - val_loss: 5.9740e-04\n",
      "Epoch 1123/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9940e-04 - val_loss: 6.0272e-04\n",
      "Epoch 1124/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9927e-04 - val_loss: 6.0347e-04\n",
      "Epoch 1125/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.9928e-04 - val_loss: 6.0192e-04\n",
      "Epoch 1126/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9916e-04 - val_loss: 5.9797e-04\n",
      "Epoch 1127/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9930e-04 - val_loss: 5.9886e-04\n",
      "Epoch 1128/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9923e-04 - val_loss: 5.9621e-04\n",
      "Epoch 1129/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9913e-04 - val_loss: 5.9873e-04\n",
      "Epoch 1130/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9890e-04 - val_loss: 5.9575e-04\n",
      "Epoch 1131/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.9883e-04 - val_loss: 5.9619e-04\n",
      "Epoch 1132/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.9876e-04 - val_loss: 5.9706e-04\n",
      "Epoch 1133/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9872e-04 - val_loss: 5.9570e-04\n",
      "Epoch 1134/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9894e-04 - val_loss: 6.0089e-04\n",
      "Epoch 1135/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9882e-04 - val_loss: 5.9713e-04\n",
      "Epoch 1136/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.9871e-04 - val_loss: 5.9736e-04\n",
      "Epoch 1137/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9880e-04 - val_loss: 5.9457e-04\n",
      "Epoch 1138/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9859e-04 - val_loss: 6.0025e-04\n",
      "Epoch 1139/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9873e-04 - val_loss: 5.9823e-04\n",
      "Epoch 1140/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9852e-04 - val_loss: 5.9504e-04\n",
      "Epoch 1141/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9838e-04 - val_loss: 5.9623e-04\n",
      "Epoch 1142/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9852e-04 - val_loss: 5.9770e-04\n",
      "Epoch 1143/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9858e-04 - val_loss: 5.9358e-04\n",
      "Epoch 1144/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9844e-04 - val_loss: 5.9641e-04\n",
      "Epoch 1145/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9832e-04 - val_loss: 5.9716e-04\n",
      "Epoch 1146/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9820e-04 - val_loss: 5.9297e-04\n",
      "Epoch 1147/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9821e-04 - val_loss: 5.9418e-04\n",
      "Epoch 1148/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9812e-04 - val_loss: 5.9296e-04\n",
      "Epoch 1149/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9801e-04 - val_loss: 5.9685e-04\n",
      "Epoch 1150/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.9798e-04 - val_loss: 5.9288e-04\n",
      "Epoch 1151/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.9787e-04 - val_loss: 5.9512e-04\n",
      "Epoch 1152/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.9788e-04 - val_loss: 5.9285e-04\n",
      "Epoch 1153/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9776e-04 - val_loss: 5.9602e-04\n",
      "Epoch 1154/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9794e-04 - val_loss: 5.9337e-04\n",
      "Epoch 1155/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.9769e-04 - val_loss: 5.9200e-04\n",
      "Epoch 1156/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9785e-04 - val_loss: 5.9496e-04\n",
      "Epoch 1157/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9771e-04 - val_loss: 5.9617e-04\n",
      "Epoch 1158/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9757e-04 - val_loss: 5.9351e-04\n",
      "Epoch 1159/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9773e-04 - val_loss: 5.9403e-04\n",
      "Epoch 1160/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9777e-04 - val_loss: 5.9239e-04\n",
      "Epoch 1161/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9746e-04 - val_loss: 5.9424e-04\n",
      "Epoch 1162/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9745e-04 - val_loss: 5.9151e-04\n",
      "Epoch 1163/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.9735e-04 - val_loss: 5.9358e-04\n",
      "Epoch 1164/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9738e-04 - val_loss: 5.9718e-04\n",
      "Epoch 1165/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9742e-04 - val_loss: 5.9257e-04\n",
      "Epoch 1166/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9736e-04 - val_loss: 5.9078e-04\n",
      "Epoch 1167/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9735e-04 - val_loss: 5.9397e-04\n",
      "Epoch 1168/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9718e-04 - val_loss: 5.9166e-04\n",
      "Epoch 1169/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.9724e-04 - val_loss: 5.9127e-04\n",
      "Epoch 1170/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.9710e-04 - val_loss: 5.9291e-04\n",
      "Epoch 1171/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9719e-04 - val_loss: 5.9035e-04\n",
      "Epoch 1172/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9714e-04 - val_loss: 5.8994e-04\n",
      "Epoch 1173/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9686e-04 - val_loss: 5.9104e-04\n",
      "Epoch 1174/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9687e-04 - val_loss: 5.9142e-04\n",
      "Epoch 1175/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9696e-04 - val_loss: 5.9168e-04\n",
      "Epoch 1176/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9686e-04 - val_loss: 5.9103e-04\n",
      "Epoch 1177/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9703e-04 - val_loss: 5.8911e-04\n",
      "Epoch 1178/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9686e-04 - val_loss: 5.9017e-04\n",
      "Epoch 1179/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9657e-04 - val_loss: 5.9134e-04\n",
      "Epoch 1180/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9669e-04 - val_loss: 5.9113e-04\n",
      "Epoch 1181/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9678e-04 - val_loss: 5.9123e-04\n",
      "Epoch 1182/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.9671e-04 - val_loss: 5.9075e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1183/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.9652e-04 - val_loss: 5.8954e-04\n",
      "Epoch 1184/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9731e-04 - val_loss: 5.8868e-04\n",
      "Epoch 1185/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9659e-04 - val_loss: 5.8861e-04\n",
      "Epoch 1186/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9622e-04 - val_loss: 5.8875e-04\n",
      "Epoch 1187/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9654e-04 - val_loss: 5.8825e-04\n",
      "Epoch 1188/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.9656e-04 - val_loss: 5.8935e-04\n",
      "Epoch 1189/10000\n",
      "45507/45507 [==============================] - 1s 23us/step - loss: 5.9629e-04 - val_loss: 5.8808e-04\n",
      "Epoch 1190/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.9615e-04 - val_loss: 5.8819e-04\n",
      "Epoch 1191/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9658e-04 - val_loss: 5.9250e-04\n",
      "Epoch 1192/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9648e-04 - val_loss: 5.9072e-04\n",
      "Epoch 1193/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9630e-04 - val_loss: 5.8823e-04\n",
      "Epoch 1194/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.9598e-04 - val_loss: 5.8950e-04\n",
      "Epoch 1195/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9604e-04 - val_loss: 5.8764e-04\n",
      "Epoch 1196/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9603e-04 - val_loss: 5.8885e-04\n",
      "Epoch 1197/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9595e-04 - val_loss: 5.8840e-04\n",
      "Epoch 1198/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9599e-04 - val_loss: 5.8758e-04\n",
      "Epoch 1199/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9596e-04 - val_loss: 5.9008e-04\n",
      "Epoch 1200/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9591e-04 - val_loss: 5.8871e-04\n",
      "Epoch 1201/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9596e-04 - val_loss: 5.8716e-04\n",
      "Epoch 1202/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9597e-04 - val_loss: 5.8639e-04\n",
      "Epoch 1203/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9554e-04 - val_loss: 5.8927e-04\n",
      "Epoch 1204/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9591e-04 - val_loss: 5.8798e-04\n",
      "Epoch 1205/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9561e-04 - val_loss: 5.8744e-04\n",
      "Epoch 1206/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9552e-04 - val_loss: 5.8792e-04\n",
      "Epoch 1207/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.9596e-04 - val_loss: 5.8725e-04\n",
      "Epoch 1208/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.9531e-04 - val_loss: 5.8691e-04\n",
      "Epoch 1209/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.9540e-04 - val_loss: 5.8595e-04\n",
      "Epoch 1210/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.9523e-04 - val_loss: 5.8674e-04\n",
      "Epoch 1211/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9555e-04 - val_loss: 5.8558e-04\n",
      "Epoch 1212/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9563e-04 - val_loss: 5.8723e-04\n",
      "Epoch 1213/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9540e-04 - val_loss: 5.8563e-04\n",
      "Epoch 1214/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.9570e-04 - val_loss: 5.8830e-04\n",
      "Epoch 1215/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9524e-04 - val_loss: 5.8614e-04\n",
      "Epoch 1216/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9504e-04 - val_loss: 5.8530e-04\n",
      "Epoch 1217/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9488e-04 - val_loss: 5.8588e-04\n",
      "Epoch 1218/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9498e-04 - val_loss: 5.8527e-04\n",
      "Epoch 1219/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9560e-04 - val_loss: 5.8531e-04\n",
      "Epoch 1220/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9509e-04 - val_loss: 5.8563e-04\n",
      "Epoch 1221/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9524e-04 - val_loss: 5.8506e-04\n",
      "Epoch 1222/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9553e-04 - val_loss: 5.8526e-04\n",
      "Epoch 1223/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9506e-04 - val_loss: 5.8484e-04\n",
      "Epoch 1224/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9496e-04 - val_loss: 5.8461e-04\n",
      "Epoch 1225/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9493e-04 - val_loss: 5.8467e-04\n",
      "Epoch 1226/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.9468e-04 - val_loss: 5.8513e-04\n",
      "Epoch 1227/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.9548e-04 - val_loss: 5.8465e-04\n",
      "Epoch 1228/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9473e-04 - val_loss: 5.8490e-04\n",
      "Epoch 1229/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9450e-04 - val_loss: 5.8431e-04\n",
      "Epoch 1230/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9486e-04 - val_loss: 5.8729e-04\n",
      "Epoch 1231/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9465e-04 - val_loss: 5.8574e-04\n",
      "Epoch 1232/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9458e-04 - val_loss: 5.8433e-04\n",
      "Epoch 1233/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9464e-04 - val_loss: 5.8356e-04\n",
      "Epoch 1234/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9464e-04 - val_loss: 5.8422e-04\n",
      "Epoch 1235/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9447e-04 - val_loss: 5.8346e-04\n",
      "Epoch 1236/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9495e-04 - val_loss: 5.8416e-04\n",
      "Epoch 1237/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9449e-04 - val_loss: 5.8372e-04\n",
      "Epoch 1238/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9410e-04 - val_loss: 5.8443e-04\n",
      "Epoch 1239/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9433e-04 - val_loss: 5.8333e-04\n",
      "Epoch 1240/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9421e-04 - val_loss: 5.8278e-04\n",
      "Epoch 1241/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9476e-04 - val_loss: 5.8325e-04\n",
      "Epoch 1242/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9417e-04 - val_loss: 5.8686e-04\n",
      "Epoch 1243/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9424e-04 - val_loss: 5.8318e-04\n",
      "Epoch 1244/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9421e-04 - val_loss: 5.8244e-04\n",
      "Epoch 1245/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.9435e-04 - val_loss: 5.8325e-04\n",
      "Epoch 1246/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.9426e-04 - val_loss: 5.8582e-04\n",
      "Epoch 1247/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9411e-04 - val_loss: 5.8546e-04\n",
      "Epoch 1248/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9387e-04 - val_loss: 5.8611e-04\n",
      "Epoch 1249/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.9428e-04 - val_loss: 5.8197e-04\n",
      "Epoch 1250/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9393e-04 - val_loss: 5.8205e-04\n",
      "Epoch 1251/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9378e-04 - val_loss: 5.8199e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1252/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.9373e-04 - val_loss: 5.8176e-04\n",
      "Epoch 1253/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9427e-04 - val_loss: 5.8268e-04\n",
      "Epoch 1254/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9390e-04 - val_loss: 5.8182e-04\n",
      "Epoch 1255/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9396e-04 - val_loss: 5.8222e-04\n",
      "Epoch 1256/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9382e-04 - val_loss: 5.8253e-04\n",
      "Epoch 1257/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9364e-04 - val_loss: 5.8205e-04\n",
      "Epoch 1258/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9369e-04 - val_loss: 5.8211e-04\n",
      "Epoch 1259/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9360e-04 - val_loss: 5.8469e-04\n",
      "Epoch 1260/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9377e-04 - val_loss: 5.8208e-04\n",
      "Epoch 1261/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9347e-04 - val_loss: 5.8204e-04\n",
      "Epoch 1262/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9353e-04 - val_loss: 5.8025e-04\n",
      "Epoch 1263/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9355e-04 - val_loss: 5.8178e-04\n",
      "Epoch 1264/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.9324e-04 - val_loss: 5.8149e-04\n",
      "Epoch 1265/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 5.9347e-04 - val_loss: 5.8082e-04\n",
      "Epoch 1266/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.9358e-04 - val_loss: 5.8187e-04\n",
      "Epoch 1267/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9325e-04 - val_loss: 5.8058e-04\n",
      "Epoch 1268/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9343e-04 - val_loss: 5.8193e-04\n",
      "Epoch 1269/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9318e-04 - val_loss: 5.8132e-04\n",
      "Epoch 1270/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9301e-04 - val_loss: 5.8178e-04\n",
      "Epoch 1271/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9339e-04 - val_loss: 5.8213e-04\n",
      "Epoch 1272/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9317e-04 - val_loss: 5.7937e-04\n",
      "Epoch 1273/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9324e-04 - val_loss: 5.8049e-04\n",
      "Epoch 1274/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9307e-04 - val_loss: 5.8013e-04\n",
      "Epoch 1275/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9287e-04 - val_loss: 5.8132e-04\n",
      "Epoch 1276/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9304e-04 - val_loss: 5.8036e-04\n",
      "Epoch 1277/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9271e-04 - val_loss: 5.8120e-04\n",
      "Epoch 1278/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9288e-04 - val_loss: 5.8075e-04\n",
      "Epoch 1279/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9274e-04 - val_loss: 5.8024e-04\n",
      "Epoch 1280/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9276e-04 - val_loss: 5.7947e-04\n",
      "Epoch 1281/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9254e-04 - val_loss: 5.8021e-04\n",
      "Epoch 1282/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9262e-04 - val_loss: 5.7891e-04\n",
      "Epoch 1283/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.9288e-04 - val_loss: 5.8040e-04\n",
      "Epoch 1284/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 5.9270e-04 - val_loss: 5.7927e-04\n",
      "Epoch 1285/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.9261e-04 - val_loss: 5.7994e-04\n",
      "Epoch 1286/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9246e-04 - val_loss: 5.7866e-04\n",
      "Epoch 1287/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9248e-04 - val_loss: 5.8452e-04\n",
      "Epoch 1288/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.9231e-04 - val_loss: 5.7886e-04\n",
      "Epoch 1289/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9233e-04 - val_loss: 5.8028e-04\n",
      "Epoch 1290/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9255e-04 - val_loss: 5.8087e-04\n",
      "Epoch 1291/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9238e-04 - val_loss: 5.7950e-04\n",
      "Epoch 1292/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9246e-04 - val_loss: 5.7857e-04\n",
      "Epoch 1293/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9236e-04 - val_loss: 5.7936e-04\n",
      "Epoch 1294/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9226e-04 - val_loss: 5.8055e-04\n",
      "Epoch 1295/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9215e-04 - val_loss: 5.7878e-04\n",
      "Epoch 1296/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9213e-04 - val_loss: 5.7843e-04\n",
      "Epoch 1297/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9241e-04 - val_loss: 5.7850e-04\n",
      "Epoch 1298/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9233e-04 - val_loss: 5.7973e-04\n",
      "Epoch 1299/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9209e-04 - val_loss: 5.7889e-04\n",
      "Epoch 1300/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9200e-04 - val_loss: 5.7845e-04\n",
      "Epoch 1301/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9234e-04 - val_loss: 5.8023e-04\n",
      "Epoch 1302/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9215e-04 - val_loss: 5.7810e-04\n",
      "Epoch 1303/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.9185e-04 - val_loss: 5.8105e-04\n",
      "Epoch 1304/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.9173e-04 - val_loss: 5.7737e-04\n",
      "Epoch 1305/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9192e-04 - val_loss: 5.7781e-04\n",
      "Epoch 1306/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9192e-04 - val_loss: 5.7775e-04\n",
      "Epoch 1307/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.9200e-04 - val_loss: 5.7903e-04\n",
      "Epoch 1308/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9184e-04 - val_loss: 5.7958e-04\n",
      "Epoch 1309/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9172e-04 - val_loss: 5.7748e-04\n",
      "Epoch 1310/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9156e-04 - val_loss: 5.7639e-04\n",
      "Epoch 1311/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9161e-04 - val_loss: 5.7903e-04\n",
      "Epoch 1312/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9148e-04 - val_loss: 5.7822e-04\n",
      "Epoch 1313/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9142e-04 - val_loss: 5.7882e-04\n",
      "Epoch 1314/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.9190e-04 - val_loss: 5.7758e-04\n",
      "Epoch 1315/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9144e-04 - val_loss: 5.7799e-04\n",
      "Epoch 1316/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9142e-04 - val_loss: 5.7760e-04\n",
      "Epoch 1317/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9131e-04 - val_loss: 5.7715e-04\n",
      "Epoch 1318/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.9164e-04 - val_loss: 5.7871e-04\n",
      "Epoch 1319/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9158e-04 - val_loss: 5.7791e-04\n",
      "Epoch 1320/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.9131e-04 - val_loss: 5.7679e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1321/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9132e-04 - val_loss: 5.7763e-04\n",
      "Epoch 1322/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.9133e-04 - val_loss: 5.7596e-04\n",
      "Epoch 1323/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9124e-04 - val_loss: 5.7720e-04\n",
      "Epoch 1324/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9125e-04 - val_loss: 5.7633e-04\n",
      "Epoch 1325/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9098e-04 - val_loss: 5.7631e-04\n",
      "Epoch 1326/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9119e-04 - val_loss: 5.7693e-04\n",
      "Epoch 1327/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9109e-04 - val_loss: 5.7502e-04\n",
      "Epoch 1328/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9116e-04 - val_loss: 5.7823e-04\n",
      "Epoch 1329/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9137e-04 - val_loss: 5.7604e-04\n",
      "Epoch 1330/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9091e-04 - val_loss: 5.7698e-04\n",
      "Epoch 1331/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9098e-04 - val_loss: 5.7586e-04\n",
      "Epoch 1332/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9103e-04 - val_loss: 5.7537e-04\n",
      "Epoch 1333/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9096e-04 - val_loss: 5.7551e-04\n",
      "Epoch 1334/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9076e-04 - val_loss: 5.7565e-04\n",
      "Epoch 1335/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9101e-04 - val_loss: 5.7676e-04\n",
      "Epoch 1336/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9078e-04 - val_loss: 5.7638e-04\n",
      "Epoch 1337/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9094e-04 - val_loss: 5.7462e-04\n",
      "Epoch 1338/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9086e-04 - val_loss: 5.7649e-04\n",
      "Epoch 1339/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9079e-04 - val_loss: 5.7462e-04\n",
      "Epoch 1340/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.9077e-04 - val_loss: 5.7447e-04\n",
      "Epoch 1341/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.9075e-04 - val_loss: 5.7476e-04\n",
      "Epoch 1342/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.9066e-04 - val_loss: 5.7686e-04\n",
      "Epoch 1343/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.9056e-04 - val_loss: 5.7533e-04\n",
      "Epoch 1344/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9051e-04 - val_loss: 5.7916e-04\n",
      "Epoch 1345/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9061e-04 - val_loss: 5.7514e-04\n",
      "Epoch 1346/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9033e-04 - val_loss: 5.7333e-04\n",
      "Epoch 1347/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9056e-04 - val_loss: 5.7511e-04\n",
      "Epoch 1348/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9043e-04 - val_loss: 5.7781e-04\n",
      "Epoch 1349/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9036e-04 - val_loss: 5.7475e-04\n",
      "Epoch 1350/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9011e-04 - val_loss: 5.7305e-04\n",
      "Epoch 1351/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.9028e-04 - val_loss: 5.7677e-04\n",
      "Epoch 1352/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9027e-04 - val_loss: 5.7656e-04\n",
      "Epoch 1353/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9022e-04 - val_loss: 5.7436e-04\n",
      "Epoch 1354/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9020e-04 - val_loss: 5.7487e-04\n",
      "Epoch 1355/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9024e-04 - val_loss: 5.7332e-04\n",
      "Epoch 1356/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.9010e-04 - val_loss: 5.7531e-04\n",
      "Epoch 1357/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.9008e-04 - val_loss: 5.7383e-04\n",
      "Epoch 1358/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9028e-04 - val_loss: 5.7343e-04\n",
      "Epoch 1359/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.9030e-04 - val_loss: 5.7897e-04\n",
      "Epoch 1360/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.9009e-04 - val_loss: 5.7276e-04\n",
      "Epoch 1361/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8994e-04 - val_loss: 5.7226e-04\n",
      "Epoch 1362/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9008e-04 - val_loss: 5.7525e-04\n",
      "Epoch 1363/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8998e-04 - val_loss: 5.7272e-04\n",
      "Epoch 1364/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8989e-04 - val_loss: 5.7218e-04\n",
      "Epoch 1365/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8977e-04 - val_loss: 5.7284e-04\n",
      "Epoch 1366/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8990e-04 - val_loss: 5.7448e-04\n",
      "Epoch 1367/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8968e-04 - val_loss: 5.7299e-04\n",
      "Epoch 1368/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8980e-04 - val_loss: 5.7250e-04\n",
      "Epoch 1369/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8964e-04 - val_loss: 5.7304e-04\n",
      "Epoch 1370/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8972e-04 - val_loss: 5.7856e-04\n",
      "Epoch 1371/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.9003e-04 - val_loss: 5.7396e-04\n",
      "Epoch 1372/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8953e-04 - val_loss: 5.7114e-04\n",
      "Epoch 1373/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8947e-04 - val_loss: 5.7203e-04\n",
      "Epoch 1374/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8949e-04 - val_loss: 5.7678e-04\n",
      "Epoch 1375/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8931e-04 - val_loss: 5.7009e-04\n",
      "Epoch 1376/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8942e-04 - val_loss: 5.7108e-04\n",
      "Epoch 1377/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8964e-04 - val_loss: 5.7417e-04\n",
      "Epoch 1378/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.8955e-04 - val_loss: 5.7346e-04\n",
      "Epoch 1379/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.8933e-04 - val_loss: 5.7675e-04\n",
      "Epoch 1380/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8936e-04 - val_loss: 5.7509e-04\n",
      "Epoch 1381/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.8924e-04 - val_loss: 5.7514e-04\n",
      "Epoch 1382/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8922e-04 - val_loss: 5.7111e-04\n",
      "Epoch 1383/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8926e-04 - val_loss: 5.7259e-04\n",
      "Epoch 1384/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.8909e-04 - val_loss: 5.7014e-04\n",
      "Epoch 1385/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8924e-04 - val_loss: 5.7144e-04\n",
      "Epoch 1386/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8909e-04 - val_loss: 5.7163e-04\n",
      "Epoch 1387/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8886e-04 - val_loss: 5.6873e-04\n",
      "Epoch 1388/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8917e-04 - val_loss: 5.7105e-04\n",
      "Epoch 1389/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8898e-04 - val_loss: 5.7434e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1390/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8889e-04 - val_loss: 5.7166e-04\n",
      "Epoch 1391/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8903e-04 - val_loss: 5.7513e-04\n",
      "Epoch 1392/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8890e-04 - val_loss: 5.7260e-04\n",
      "Epoch 1393/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8868e-04 - val_loss: 5.7005e-04\n",
      "Epoch 1394/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8860e-04 - val_loss: 5.7247e-04\n",
      "Epoch 1395/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8904e-04 - val_loss: 5.7147e-04\n",
      "Epoch 1396/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8860e-04 - val_loss: 5.7202e-04\n",
      "Epoch 1397/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.8862e-04 - val_loss: 5.7155e-04\n",
      "Epoch 1398/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.8838e-04 - val_loss: 5.7110e-04\n",
      "Epoch 1399/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8874e-04 - val_loss: 5.7167e-04\n",
      "Epoch 1400/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8851e-04 - val_loss: 5.7306e-04\n",
      "Epoch 1401/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8872e-04 - val_loss: 5.7086e-04\n",
      "Epoch 1402/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8865e-04 - val_loss: 5.7447e-04\n",
      "Epoch 1403/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8854e-04 - val_loss: 5.7211e-04\n",
      "Epoch 1404/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8876e-04 - val_loss: 5.7424e-04\n",
      "Epoch 1405/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8845e-04 - val_loss: 5.6898e-04\n",
      "Epoch 1406/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8879e-04 - val_loss: 5.7369e-04\n",
      "Epoch 1407/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8837e-04 - val_loss: 5.7022e-04\n",
      "Epoch 1408/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8863e-04 - val_loss: 5.6975e-04\n",
      "Epoch 1409/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8836e-04 - val_loss: 5.7040e-04\n",
      "Epoch 1410/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8812e-04 - val_loss: 5.7196e-04\n",
      "Epoch 1411/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8820e-04 - val_loss: 5.7076e-04\n",
      "Epoch 1412/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8823e-04 - val_loss: 5.7072e-04\n",
      "Epoch 1413/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8801e-04 - val_loss: 5.6931e-04\n",
      "Epoch 1414/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8827e-04 - val_loss: 5.7082e-04\n",
      "Epoch 1415/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8825e-04 - val_loss: 5.7077e-04\n",
      "Epoch 1416/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.8825e-04 - val_loss: 5.7101e-04\n",
      "Epoch 1417/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8803e-04 - val_loss: 5.7267e-04\n",
      "Epoch 1418/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8812e-04 - val_loss: 5.6936e-04\n",
      "Epoch 1419/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8791e-04 - val_loss: 5.7021e-04\n",
      "Epoch 1420/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8811e-04 - val_loss: 5.6944e-04\n",
      "Epoch 1421/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8817e-04 - val_loss: 5.7142e-04\n",
      "Epoch 1422/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8816e-04 - val_loss: 5.7111e-04\n",
      "Epoch 1423/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8769e-04 - val_loss: 5.6954e-04\n",
      "Epoch 1424/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8793e-04 - val_loss: 5.6896e-04\n",
      "Epoch 1425/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8792e-04 - val_loss: 5.7034e-04\n",
      "Epoch 1426/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8793e-04 - val_loss: 5.6725e-04\n",
      "Epoch 1427/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8787e-04 - val_loss: 5.6908e-04\n",
      "Epoch 1428/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8792e-04 - val_loss: 5.6983e-04\n",
      "Epoch 1429/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8767e-04 - val_loss: 5.6760e-04\n",
      "Epoch 1430/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8751e-04 - val_loss: 5.6810e-04\n",
      "Epoch 1431/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8775e-04 - val_loss: 5.6936e-04\n",
      "Epoch 1432/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8758e-04 - val_loss: 5.7018e-04\n",
      "Epoch 1433/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8741e-04 - val_loss: 5.6652e-04\n",
      "Epoch 1434/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8756e-04 - val_loss: 5.6879e-04\n",
      "Epoch 1435/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.8759e-04 - val_loss: 5.6816e-04\n",
      "Epoch 1436/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8767e-04 - val_loss: 5.6979e-04\n",
      "Epoch 1437/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8747e-04 - val_loss: 5.6907e-04\n",
      "Epoch 1438/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8735e-04 - val_loss: 5.6600e-04\n",
      "Epoch 1439/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8756e-04 - val_loss: 5.6782e-04\n",
      "Epoch 1440/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8723e-04 - val_loss: 5.6956e-04\n",
      "Epoch 1441/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8728e-04 - val_loss: 5.7419e-04\n",
      "Epoch 1442/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8722e-04 - val_loss: 5.6990e-04\n",
      "Epoch 1443/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8724e-04 - val_loss: 5.6791e-04\n",
      "Epoch 1444/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8708e-04 - val_loss: 5.6700e-04\n",
      "Epoch 1445/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8724e-04 - val_loss: 5.6883e-04\n",
      "Epoch 1446/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8737e-04 - val_loss: 5.6759e-04\n",
      "Epoch 1447/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8715e-04 - val_loss: 5.6831e-04\n",
      "Epoch 1448/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8697e-04 - val_loss: 5.6705e-04\n",
      "Epoch 1449/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8736e-04 - val_loss: 5.6624e-04\n",
      "Epoch 1450/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8704e-04 - val_loss: 5.7121e-04\n",
      "Epoch 1451/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8692e-04 - val_loss: 5.6946e-04\n",
      "Epoch 1452/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8684e-04 - val_loss: 5.6641e-04\n",
      "Epoch 1453/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8696e-04 - val_loss: 5.6865e-04\n",
      "Epoch 1454/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8689e-04 - val_loss: 5.6746e-04\n",
      "Epoch 1455/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8680e-04 - val_loss: 5.7064e-04\n",
      "Epoch 1456/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8677e-04 - val_loss: 5.6660e-04\n",
      "Epoch 1457/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8690e-04 - val_loss: 5.6466e-04\n",
      "Epoch 1458/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8670e-04 - val_loss: 5.6640e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1459/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8669e-04 - val_loss: 5.6766e-04\n",
      "Epoch 1460/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8674e-04 - val_loss: 5.7007e-04\n",
      "Epoch 1461/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8679e-04 - val_loss: 5.6568e-04\n",
      "Epoch 1462/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8664e-04 - val_loss: 5.6960e-04\n",
      "Epoch 1463/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8662e-04 - val_loss: 5.6637e-04\n",
      "Epoch 1464/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8687e-04 - val_loss: 5.6476e-04\n",
      "Epoch 1465/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8671e-04 - val_loss: 5.6717e-04\n",
      "Epoch 1466/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.8663e-04 - val_loss: 5.6587e-04\n",
      "Epoch 1467/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8647e-04 - val_loss: 5.6470e-04\n",
      "Epoch 1468/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8675e-04 - val_loss: 5.6655e-04\n",
      "Epoch 1469/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8644e-04 - val_loss: 5.6573e-04\n",
      "Epoch 1470/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8633e-04 - val_loss: 5.6655e-04\n",
      "Epoch 1471/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8618e-04 - val_loss: 5.6503e-04\n",
      "Epoch 1472/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.8659e-04 - val_loss: 5.6643e-04\n",
      "Epoch 1473/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.8636e-04 - val_loss: 5.6536e-04\n",
      "Epoch 1474/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8651e-04 - val_loss: 5.6355e-04\n",
      "Epoch 1475/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8623e-04 - val_loss: 5.6414e-04\n",
      "Epoch 1476/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8626e-04 - val_loss: 5.6648e-04\n",
      "Epoch 1477/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8625e-04 - val_loss: 5.6500e-04\n",
      "Epoch 1478/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8629e-04 - val_loss: 5.6471e-04\n",
      "Epoch 1479/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8609e-04 - val_loss: 5.6388e-04\n",
      "Epoch 1480/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8607e-04 - val_loss: 5.6368e-04\n",
      "Epoch 1481/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8611e-04 - val_loss: 5.6379e-04\n",
      "Epoch 1482/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8606e-04 - val_loss: 5.6324e-04\n",
      "Epoch 1483/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8590e-04 - val_loss: 5.6751e-04\n",
      "Epoch 1484/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8602e-04 - val_loss: 5.6428e-04\n",
      "Epoch 1485/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8583e-04 - val_loss: 5.6322e-04\n",
      "Epoch 1486/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.8584e-04 - val_loss: 5.6443e-04\n",
      "Epoch 1487/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8566e-04 - val_loss: 5.6561e-04\n",
      "Epoch 1488/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8587e-04 - val_loss: 5.6331e-04\n",
      "Epoch 1489/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8555e-04 - val_loss: 5.6312e-04\n",
      "Epoch 1490/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8556e-04 - val_loss: 5.6302e-04\n",
      "Epoch 1491/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.8588e-04 - val_loss: 5.6437e-04\n",
      "Epoch 1492/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.8566e-04 - val_loss: 5.6364e-04\n",
      "Epoch 1493/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8562e-04 - val_loss: 5.6573e-04\n",
      "Epoch 1494/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.8549e-04 - val_loss: 5.6470e-04\n",
      "Epoch 1495/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8537e-04 - val_loss: 5.6273e-04\n",
      "Epoch 1496/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.8539e-04 - val_loss: 5.6430e-04\n",
      "Epoch 1497/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8572e-04 - val_loss: 5.6460e-04\n",
      "Epoch 1498/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8544e-04 - val_loss: 5.6528e-04\n",
      "Epoch 1499/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8525e-04 - val_loss: 5.6388e-04\n",
      "Epoch 1500/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8558e-04 - val_loss: 5.6313e-04\n",
      "Epoch 1501/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8532e-04 - val_loss: 5.6261e-04\n",
      "Epoch 1502/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8542e-04 - val_loss: 5.6421e-04\n",
      "Epoch 1503/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8512e-04 - val_loss: 5.6615e-04\n",
      "Epoch 1504/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8531e-04 - val_loss: 5.6260e-04\n",
      "Epoch 1505/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8524e-04 - val_loss: 5.6375e-04\n",
      "Epoch 1506/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8519e-04 - val_loss: 5.6441e-04\n",
      "Epoch 1507/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8499e-04 - val_loss: 5.6331e-04\n",
      "Epoch 1508/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8498e-04 - val_loss: 5.6363e-04\n",
      "Epoch 1509/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8509e-04 - val_loss: 5.6216e-04\n",
      "Epoch 1510/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.8507e-04 - val_loss: 5.6300e-04\n",
      "Epoch 1511/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.8509e-04 - val_loss: 5.6343e-04\n",
      "Epoch 1512/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8513e-04 - val_loss: 5.6159e-04\n",
      "Epoch 1513/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8489e-04 - val_loss: 5.6360e-04\n",
      "Epoch 1514/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8479e-04 - val_loss: 5.6484e-04\n",
      "Epoch 1515/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8500e-04 - val_loss: 5.6344e-04\n",
      "Epoch 1516/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8484e-04 - val_loss: 5.6433e-04\n",
      "Epoch 1517/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8474e-04 - val_loss: 5.6460e-04\n",
      "Epoch 1518/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8498e-04 - val_loss: 5.6386e-04\n",
      "Epoch 1519/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8467e-04 - val_loss: 5.6469e-04\n",
      "Epoch 1520/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8462e-04 - val_loss: 5.6395e-04\n",
      "Epoch 1521/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8457e-04 - val_loss: 5.6458e-04\n",
      "Epoch 1522/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8446e-04 - val_loss: 5.6348e-04\n",
      "Epoch 1523/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.8490e-04 - val_loss: 5.6174e-04\n",
      "Epoch 1524/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8471e-04 - val_loss: 5.6321e-04\n",
      "Epoch 1525/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8458e-04 - val_loss: 5.6398e-04\n",
      "Epoch 1526/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8441e-04 - val_loss: 5.6406e-04\n",
      "Epoch 1527/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8435e-04 - val_loss: 5.6322e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1528/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8458e-04 - val_loss: 5.6398e-04\n",
      "Epoch 1529/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.8465e-04 - val_loss: 5.6194e-04\n",
      "Epoch 1530/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8432e-04 - val_loss: 5.6293e-04\n",
      "Epoch 1531/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8426e-04 - val_loss: 5.6353e-04\n",
      "Epoch 1532/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8424e-04 - val_loss: 5.6386e-04\n",
      "Epoch 1533/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8410e-04 - val_loss: 5.6360e-04\n",
      "Epoch 1534/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8449e-04 - val_loss: 5.6198e-04\n",
      "Epoch 1535/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8447e-04 - val_loss: 5.6232e-04\n",
      "Epoch 1536/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8417e-04 - val_loss: 5.6249e-04\n",
      "Epoch 1537/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8411e-04 - val_loss: 5.6154e-04\n",
      "Epoch 1538/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8419e-04 - val_loss: 5.6342e-04\n",
      "Epoch 1539/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8399e-04 - val_loss: 5.6173e-04\n",
      "Epoch 1540/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8407e-04 - val_loss: 5.6202e-04\n",
      "Epoch 1541/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8396e-04 - val_loss: 5.6168e-04\n",
      "Epoch 1542/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8389e-04 - val_loss: 5.6163e-04\n",
      "Epoch 1543/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8414e-04 - val_loss: 5.6085e-04\n",
      "Epoch 1544/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8411e-04 - val_loss: 5.6154e-04\n",
      "Epoch 1545/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8390e-04 - val_loss: 5.6116e-04\n",
      "Epoch 1546/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8392e-04 - val_loss: 5.6173e-04\n",
      "Epoch 1547/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.8422e-04 - val_loss: 5.6224e-04\n",
      "Epoch 1548/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 5.8371e-04 - val_loss: 5.5980e-04\n",
      "Epoch 1549/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8394e-04 - val_loss: 5.6057e-04\n",
      "Epoch 1550/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8391e-04 - val_loss: 5.6066e-04\n",
      "Epoch 1551/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8354e-04 - val_loss: 5.5958e-04\n",
      "Epoch 1552/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8375e-04 - val_loss: 5.6143e-04\n",
      "Epoch 1553/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8385e-04 - val_loss: 5.6030e-04\n",
      "Epoch 1554/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8353e-04 - val_loss: 5.5992e-04\n",
      "Epoch 1555/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8381e-04 - val_loss: 5.5853e-04\n",
      "Epoch 1556/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8359e-04 - val_loss: 5.6055e-04\n",
      "Epoch 1557/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8348e-04 - val_loss: 5.6025e-04\n",
      "Epoch 1558/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8347e-04 - val_loss: 5.6108e-04\n",
      "Epoch 1559/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8343e-04 - val_loss: 5.6058e-04\n",
      "Epoch 1560/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8338e-04 - val_loss: 5.6083e-04\n",
      "Epoch 1561/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8326e-04 - val_loss: 5.6046e-04\n",
      "Epoch 1562/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8374e-04 - val_loss: 5.6070e-04\n",
      "Epoch 1563/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.8365e-04 - val_loss: 5.6107e-04\n",
      "Epoch 1564/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8339e-04 - val_loss: 5.5944e-04\n",
      "Epoch 1565/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8346e-04 - val_loss: 5.5984e-04\n",
      "Epoch 1566/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.8323e-04 - val_loss: 5.6013e-04\n",
      "Epoch 1567/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 5.8315e-04 - val_loss: 5.5967e-04\n",
      "Epoch 1568/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.8314e-04 - val_loss: 5.6066e-04\n",
      "Epoch 1569/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.8313e-04 - val_loss: 5.5997e-04\n",
      "Epoch 1570/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.8354e-04 - val_loss: 5.5990e-04\n",
      "Epoch 1571/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8311e-04 - val_loss: 5.6010e-04\n",
      "Epoch 1572/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8321e-04 - val_loss: 5.5841e-04\n",
      "Epoch 1573/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8339e-04 - val_loss: 5.5847e-04\n",
      "Epoch 1574/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8320e-04 - val_loss: 5.5875e-04\n",
      "Epoch 1575/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8318e-04 - val_loss: 5.5901e-04\n",
      "Epoch 1576/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8305e-04 - val_loss: 5.5803e-04\n",
      "Epoch 1577/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8329e-04 - val_loss: 5.6000e-04\n",
      "Epoch 1578/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8302e-04 - val_loss: 5.5910e-04\n",
      "Epoch 1579/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8310e-04 - val_loss: 5.5802e-04\n",
      "Epoch 1580/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.8313e-04 - val_loss: 5.5992e-04\n",
      "Epoch 1581/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8286e-04 - val_loss: 5.5822e-04\n",
      "Epoch 1582/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8319e-04 - val_loss: 5.5912e-04\n",
      "Epoch 1583/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8282e-04 - val_loss: 5.5943e-04\n",
      "Epoch 1584/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8283e-04 - val_loss: 5.5969e-04\n",
      "Epoch 1585/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8265e-04 - val_loss: 5.5979e-04\n",
      "Epoch 1586/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.8268e-04 - val_loss: 5.5964e-04\n",
      "Epoch 1587/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.8260e-04 - val_loss: 5.5995e-04\n",
      "Epoch 1588/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8288e-04 - val_loss: 5.5916e-04\n",
      "Epoch 1589/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8272e-04 - val_loss: 5.5851e-04\n",
      "Epoch 1590/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8249e-04 - val_loss: 5.5869e-04\n",
      "Epoch 1591/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8279e-04 - val_loss: 5.5826e-04\n",
      "Epoch 1592/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8284e-04 - val_loss: 5.5837e-04\n",
      "Epoch 1593/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8264e-04 - val_loss: 5.5711e-04\n",
      "Epoch 1594/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8253e-04 - val_loss: 5.5831e-04\n",
      "Epoch 1595/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8242e-04 - val_loss: 5.5880e-04\n",
      "Epoch 1596/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8247e-04 - val_loss: 5.5970e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1597/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8283e-04 - val_loss: 5.5680e-04\n",
      "Epoch 1598/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8242e-04 - val_loss: 5.5811e-04\n",
      "Epoch 1599/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.8245e-04 - val_loss: 5.5834e-04\n",
      "Epoch 1600/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.8238e-04 - val_loss: 5.5847e-04\n",
      "Epoch 1601/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8223e-04 - val_loss: 5.5822e-04\n",
      "Epoch 1602/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8222e-04 - val_loss: 5.5881e-04\n",
      "Epoch 1603/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8253e-04 - val_loss: 5.5778e-04\n",
      "Epoch 1604/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8226e-04 - val_loss: 5.5822e-04\n",
      "Epoch 1605/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8224e-04 - val_loss: 5.5770e-04\n",
      "Epoch 1606/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.8215e-04 - val_loss: 5.5894e-04\n",
      "Epoch 1607/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8216e-04 - val_loss: 5.5820e-04\n",
      "Epoch 1608/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8220e-04 - val_loss: 5.5809e-04\n",
      "Epoch 1609/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8199e-04 - val_loss: 5.5818e-04\n",
      "Epoch 1610/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8209e-04 - val_loss: 5.5831e-04\n",
      "Epoch 1611/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8194e-04 - val_loss: 5.5828e-04\n",
      "Epoch 1612/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8229e-04 - val_loss: 5.5786e-04\n",
      "Epoch 1613/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8186e-04 - val_loss: 5.5721e-04\n",
      "Epoch 1614/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8248e-04 - val_loss: 5.5817e-04\n",
      "Epoch 1615/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8203e-04 - val_loss: 5.5709e-04\n",
      "Epoch 1616/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8193e-04 - val_loss: 5.5768e-04\n",
      "Epoch 1617/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8174e-04 - val_loss: 5.5724e-04\n",
      "Epoch 1618/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8236e-04 - val_loss: 5.5659e-04\n",
      "Epoch 1619/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.8184e-04 - val_loss: 5.5720e-04\n",
      "Epoch 1620/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8180e-04 - val_loss: 5.5767e-04\n",
      "Epoch 1621/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8186e-04 - val_loss: 5.5621e-04\n",
      "Epoch 1622/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.8190e-04 - val_loss: 5.5609e-04\n",
      "Epoch 1623/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8170e-04 - val_loss: 5.5662e-04\n",
      "Epoch 1624/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.8168e-04 - val_loss: 5.5619e-04\n",
      "Epoch 1625/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.8191e-04 - val_loss: 5.5711e-04\n",
      "Epoch 1626/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8169e-04 - val_loss: 5.5709e-04\n",
      "Epoch 1627/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8169e-04 - val_loss: 5.5705e-04\n",
      "Epoch 1628/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8161e-04 - val_loss: 5.5634e-04\n",
      "Epoch 1629/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8159e-04 - val_loss: 5.5607e-04\n",
      "Epoch 1630/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8164e-04 - val_loss: 5.5692e-04\n",
      "Epoch 1631/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8147e-04 - val_loss: 5.5685e-04\n",
      "Epoch 1632/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8178e-04 - val_loss: 5.5586e-04\n",
      "Epoch 1633/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8155e-04 - val_loss: 5.5591e-04\n",
      "Epoch 1634/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8154e-04 - val_loss: 5.5645e-04\n",
      "Epoch 1635/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8131e-04 - val_loss: 5.5595e-04\n",
      "Epoch 1636/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8133e-04 - val_loss: 5.5558e-04\n",
      "Epoch 1637/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.8140e-04 - val_loss: 5.5500e-04\n",
      "Epoch 1638/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8135e-04 - val_loss: 5.5647e-04\n",
      "Epoch 1639/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8133e-04 - val_loss: 5.5633e-04\n",
      "Epoch 1640/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8117e-04 - val_loss: 5.5561e-04\n",
      "Epoch 1641/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8127e-04 - val_loss: 5.5596e-04\n",
      "Epoch 1642/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.8105e-04 - val_loss: 5.5604e-04\n",
      "Epoch 1643/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.8120e-04 - val_loss: 5.5508e-04\n",
      "Epoch 1644/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.8119e-04 - val_loss: 5.5570e-04\n",
      "Epoch 1645/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.8106e-04 - val_loss: 5.5549e-04\n",
      "Epoch 1646/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8141e-04 - val_loss: 5.5461e-04\n",
      "Epoch 1647/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8118e-04 - val_loss: 5.5470e-04\n",
      "Epoch 1648/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8109e-04 - val_loss: 5.5419e-04\n",
      "Epoch 1649/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8104e-04 - val_loss: 5.5535e-04\n",
      "Epoch 1650/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8112e-04 - val_loss: 5.5577e-04\n",
      "Epoch 1651/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8095e-04 - val_loss: 5.5461e-04\n",
      "Epoch 1652/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8124e-04 - val_loss: 5.5483e-04\n",
      "Epoch 1653/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8094e-04 - val_loss: 5.5483e-04\n",
      "Epoch 1654/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8098e-04 - val_loss: 5.5411e-04\n",
      "Epoch 1655/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8092e-04 - val_loss: 5.5461e-04\n",
      "Epoch 1656/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8091e-04 - val_loss: 5.5338e-04\n",
      "Epoch 1657/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8094e-04 - val_loss: 5.5318e-04\n",
      "Epoch 1658/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8084e-04 - val_loss: 5.5534e-04\n",
      "Epoch 1659/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8079e-04 - val_loss: 5.5461e-04\n",
      "Epoch 1660/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8076e-04 - val_loss: 5.5498e-04\n",
      "Epoch 1661/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8065e-04 - val_loss: 5.5383e-04\n",
      "Epoch 1662/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.8075e-04 - val_loss: 5.5341e-04\n",
      "Epoch 1663/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.8067e-04 - val_loss: 5.5473e-04\n",
      "Epoch 1664/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.8092e-04 - val_loss: 5.5382e-04\n",
      "Epoch 1665/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8065e-04 - val_loss: 5.5474e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1666/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8079e-04 - val_loss: 5.5336e-04\n",
      "Epoch 1667/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8067e-04 - val_loss: 5.5448e-04\n",
      "Epoch 1668/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8060e-04 - val_loss: 5.5291e-04\n",
      "Epoch 1669/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8055e-04 - val_loss: 5.5398e-04\n",
      "Epoch 1670/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8061e-04 - val_loss: 5.5442e-04\n",
      "Epoch 1671/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8063e-04 - val_loss: 5.5351e-04\n",
      "Epoch 1672/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8053e-04 - val_loss: 5.5343e-04\n",
      "Epoch 1673/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8066e-04 - val_loss: 5.5189e-04\n",
      "Epoch 1674/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8043e-04 - val_loss: 5.5413e-04\n",
      "Epoch 1675/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8034e-04 - val_loss: 5.5382e-04\n",
      "Epoch 1676/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8037e-04 - val_loss: 5.5352e-04\n",
      "Epoch 1677/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8037e-04 - val_loss: 5.5284e-04\n",
      "Epoch 1678/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8035e-04 - val_loss: 5.5210e-04\n",
      "Epoch 1679/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8040e-04 - val_loss: 5.5232e-04\n",
      "Epoch 1680/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.8024e-04 - val_loss: 5.5198e-04\n",
      "Epoch 1681/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8022e-04 - val_loss: 5.5331e-04\n",
      "Epoch 1682/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.8028e-04 - val_loss: 5.5241e-04\n",
      "Epoch 1683/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8011e-04 - val_loss: 5.5210e-04\n",
      "Epoch 1684/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.8015e-04 - val_loss: 5.5236e-04\n",
      "Epoch 1685/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8017e-04 - val_loss: 5.5311e-04\n",
      "Epoch 1686/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.8038e-04 - val_loss: 5.5257e-04\n",
      "Epoch 1687/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8017e-04 - val_loss: 5.5297e-04\n",
      "Epoch 1688/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8016e-04 - val_loss: 5.5326e-04\n",
      "Epoch 1689/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8024e-04 - val_loss: 5.5167e-04\n",
      "Epoch 1690/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.8003e-04 - val_loss: 5.5151e-04\n",
      "Epoch 1691/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.8005e-04 - val_loss: 5.5128e-04\n",
      "Epoch 1692/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7992e-04 - val_loss: 5.5193e-04\n",
      "Epoch 1693/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7982e-04 - val_loss: 5.5176e-04\n",
      "Epoch 1694/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7996e-04 - val_loss: 5.5161e-04\n",
      "Epoch 1695/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7986e-04 - val_loss: 5.5121e-04\n",
      "Epoch 1696/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7990e-04 - val_loss: 5.5316e-04\n",
      "Epoch 1697/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7991e-04 - val_loss: 5.5168e-04\n",
      "Epoch 1698/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.8016e-04 - val_loss: 5.5154e-04\n",
      "Epoch 1699/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7982e-04 - val_loss: 5.5107e-04\n",
      "Epoch 1700/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7994e-04 - val_loss: 5.5120e-04\n",
      "Epoch 1701/10000\n",
      "45507/45507 [==============================] - 1s 23us/step - loss: 5.7972e-04 - val_loss: 5.5166e-04\n",
      "Epoch 1702/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7986e-04 - val_loss: 5.5102e-04\n",
      "Epoch 1703/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7984e-04 - val_loss: 5.5084e-04\n",
      "Epoch 1704/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7970e-04 - val_loss: 5.5109e-04\n",
      "Epoch 1705/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7968e-04 - val_loss: 5.5155e-04\n",
      "Epoch 1706/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7959e-04 - val_loss: 5.5037e-04\n",
      "Epoch 1707/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7949e-04 - val_loss: 5.5130e-04\n",
      "Epoch 1708/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7963e-04 - val_loss: 5.5056e-04\n",
      "Epoch 1709/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7956e-04 - val_loss: 5.5094e-04\n",
      "Epoch 1710/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7943e-04 - val_loss: 5.5079e-04\n",
      "Epoch 1711/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7952e-04 - val_loss: 5.5124e-04\n",
      "Epoch 1712/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7952e-04 - val_loss: 5.5040e-04\n",
      "Epoch 1713/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7951e-04 - val_loss: 5.5042e-04\n",
      "Epoch 1714/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7948e-04 - val_loss: 5.5115e-04\n",
      "Epoch 1715/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7954e-04 - val_loss: 5.5035e-04\n",
      "Epoch 1716/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7945e-04 - val_loss: 5.5006e-04\n",
      "Epoch 1717/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7939e-04 - val_loss: 5.5047e-04\n",
      "Epoch 1718/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7931e-04 - val_loss: 5.5048e-04\n",
      "Epoch 1719/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7931e-04 - val_loss: 5.5031e-04\n",
      "Epoch 1720/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7926e-04 - val_loss: 5.4963e-04\n",
      "Epoch 1721/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7923e-04 - val_loss: 5.4985e-04\n",
      "Epoch 1722/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7929e-04 - val_loss: 5.4990e-04\n",
      "Epoch 1723/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7933e-04 - val_loss: 5.4934e-04\n",
      "Epoch 1724/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7929e-04 - val_loss: 5.5036e-04\n",
      "Epoch 1725/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7923e-04 - val_loss: 5.4958e-04\n",
      "Epoch 1726/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7920e-04 - val_loss: 5.4970e-04\n",
      "Epoch 1727/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7912e-04 - val_loss: 5.5006e-04\n",
      "Epoch 1728/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7931e-04 - val_loss: 5.5115e-04\n",
      "Epoch 1729/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7920e-04 - val_loss: 5.5009e-04\n",
      "Epoch 1730/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7922e-04 - val_loss: 5.4980e-04\n",
      "Epoch 1731/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7905e-04 - val_loss: 5.4959e-04\n",
      "Epoch 1732/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7902e-04 - val_loss: 5.4980e-04\n",
      "Epoch 1733/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7903e-04 - val_loss: 5.4955e-04\n",
      "Epoch 1734/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7896e-04 - val_loss: 5.4960e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1735/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7895e-04 - val_loss: 5.5025e-04\n",
      "Epoch 1736/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7892e-04 - val_loss: 5.5034e-04\n",
      "Epoch 1737/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7889e-04 - val_loss: 5.5071e-04\n",
      "Epoch 1738/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7893e-04 - val_loss: 5.5017e-04\n",
      "Epoch 1739/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7910e-04 - val_loss: 5.5081e-04\n",
      "Epoch 1740/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7890e-04 - val_loss: 5.4999e-04\n",
      "Epoch 1741/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7896e-04 - val_loss: 5.5033e-04\n",
      "Epoch 1742/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7885e-04 - val_loss: 5.4956e-04\n",
      "Epoch 1743/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7880e-04 - val_loss: 5.4938e-04\n",
      "Epoch 1744/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7872e-04 - val_loss: 5.4934e-04\n",
      "Epoch 1745/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7874e-04 - val_loss: 5.4910e-04\n",
      "Epoch 1746/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7881e-04 - val_loss: 5.4895e-04\n",
      "Epoch 1747/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7863e-04 - val_loss: 5.4888e-04\n",
      "Epoch 1748/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7875e-04 - val_loss: 5.4905e-04\n",
      "Epoch 1749/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7873e-04 - val_loss: 5.4914e-04\n",
      "Epoch 1750/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7869e-04 - val_loss: 5.4848e-04\n",
      "Epoch 1751/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7861e-04 - val_loss: 5.4874e-04\n",
      "Epoch 1752/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7862e-04 - val_loss: 5.4865e-04\n",
      "Epoch 1753/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7856e-04 - val_loss: 5.4864e-04\n",
      "Epoch 1754/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7874e-04 - val_loss: 5.4824e-04\n",
      "Epoch 1755/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7863e-04 - val_loss: 5.4840e-04\n",
      "Epoch 1756/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7862e-04 - val_loss: 5.4862e-04\n",
      "Epoch 1757/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7847e-04 - val_loss: 5.4874e-04\n",
      "Epoch 1758/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7846e-04 - val_loss: 5.4875e-04\n",
      "Epoch 1759/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7849e-04 - val_loss: 5.4887e-04\n",
      "Epoch 1760/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7840e-04 - val_loss: 5.4925e-04\n",
      "Epoch 1761/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7837e-04 - val_loss: 5.4875e-04\n",
      "Epoch 1762/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7832e-04 - val_loss: 5.4936e-04\n",
      "Epoch 1763/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7833e-04 - val_loss: 5.4906e-04\n",
      "Epoch 1764/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7833e-04 - val_loss: 5.4948e-04\n",
      "Epoch 1765/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7850e-04 - val_loss: 5.4916e-04\n",
      "Epoch 1766/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7849e-04 - val_loss: 5.4800e-04\n",
      "Epoch 1767/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7840e-04 - val_loss: 5.4873e-04\n",
      "Epoch 1768/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7834e-04 - val_loss: 5.4784e-04\n",
      "Epoch 1769/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7829e-04 - val_loss: 5.4784e-04\n",
      "Epoch 1770/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7824e-04 - val_loss: 5.4790e-04\n",
      "Epoch 1771/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7818e-04 - val_loss: 5.4822e-04\n",
      "Epoch 1772/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7827e-04 - val_loss: 5.4815e-04\n",
      "Epoch 1773/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7827e-04 - val_loss: 5.4785e-04\n",
      "Epoch 1774/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7823e-04 - val_loss: 5.4789e-04\n",
      "Epoch 1775/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7819e-04 - val_loss: 5.4779e-04\n",
      "Epoch 1776/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7809e-04 - val_loss: 5.4801e-04\n",
      "Epoch 1777/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7814e-04 - val_loss: 5.4860e-04\n",
      "Epoch 1778/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7808e-04 - val_loss: 5.4877e-04\n",
      "Epoch 1779/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7803e-04 - val_loss: 5.4883e-04\n",
      "Epoch 1780/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7808e-04 - val_loss: 5.4719e-04\n",
      "Epoch 1781/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7802e-04 - val_loss: 5.4844e-04\n",
      "Epoch 1782/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7805e-04 - val_loss: 5.4741e-04\n",
      "Epoch 1783/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7794e-04 - val_loss: 5.4773e-04\n",
      "Epoch 1784/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7799e-04 - val_loss: 5.4779e-04\n",
      "Epoch 1785/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7786e-04 - val_loss: 5.4855e-04\n",
      "Epoch 1786/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7784e-04 - val_loss: 5.4762e-04\n",
      "Epoch 1787/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7791e-04 - val_loss: 5.4820e-04\n",
      "Epoch 1788/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7794e-04 - val_loss: 5.4863e-04\n",
      "Epoch 1789/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7789e-04 - val_loss: 5.4889e-04\n",
      "Epoch 1790/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7789e-04 - val_loss: 5.4761e-04\n",
      "Epoch 1791/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7785e-04 - val_loss: 5.4708e-04\n",
      "Epoch 1792/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7777e-04 - val_loss: 5.4755e-04\n",
      "Epoch 1793/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7770e-04 - val_loss: 5.4784e-04\n",
      "Epoch 1794/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7766e-04 - val_loss: 5.4737e-04\n",
      "Epoch 1795/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7775e-04 - val_loss: 5.4834e-04\n",
      "Epoch 1796/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7769e-04 - val_loss: 5.4787e-04\n",
      "Epoch 1797/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7770e-04 - val_loss: 5.4792e-04\n",
      "Epoch 1798/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7769e-04 - val_loss: 5.4807e-04\n",
      "Epoch 1799/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7772e-04 - val_loss: 5.4828e-04\n",
      "Epoch 1800/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7776e-04 - val_loss: 5.4819e-04\n",
      "Epoch 1801/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7772e-04 - val_loss: 5.4759e-04\n",
      "Epoch 1802/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7755e-04 - val_loss: 5.4757e-04\n",
      "Epoch 1803/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7770e-04 - val_loss: 5.4752e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1804/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7758e-04 - val_loss: 5.4730e-04\n",
      "Epoch 1805/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7747e-04 - val_loss: 5.4779e-04\n",
      "Epoch 1806/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7749e-04 - val_loss: 5.4685e-04\n",
      "Epoch 1807/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7749e-04 - val_loss: 5.4665e-04\n",
      "Epoch 1808/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7745e-04 - val_loss: 5.4662e-04\n",
      "Epoch 1809/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7740e-04 - val_loss: 5.4673e-04\n",
      "Epoch 1810/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7736e-04 - val_loss: 5.4721e-04\n",
      "Epoch 1811/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7732e-04 - val_loss: 5.4706e-04\n",
      "Epoch 1812/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7732e-04 - val_loss: 5.4720e-04\n",
      "Epoch 1813/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7733e-04 - val_loss: 5.4727e-04\n",
      "Epoch 1814/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7746e-04 - val_loss: 5.4711e-04\n",
      "Epoch 1815/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7750e-04 - val_loss: 5.4739e-04\n",
      "Epoch 1816/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7755e-04 - val_loss: 5.4832e-04\n",
      "Epoch 1817/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7748e-04 - val_loss: 5.4810e-04\n",
      "Epoch 1818/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7741e-04 - val_loss: 5.4820e-04\n",
      "Epoch 1819/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7732e-04 - val_loss: 5.4781e-04\n",
      "Epoch 1820/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7728e-04 - val_loss: 5.4758e-04\n",
      "Epoch 1821/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7721e-04 - val_loss: 5.4672e-04\n",
      "Epoch 1822/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7715e-04 - val_loss: 5.4694e-04\n",
      "Epoch 1823/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7708e-04 - val_loss: 5.4696e-04\n",
      "Epoch 1824/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7714e-04 - val_loss: 5.4713e-04\n",
      "Epoch 1825/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7707e-04 - val_loss: 5.4690e-04\n",
      "Epoch 1826/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7705e-04 - val_loss: 5.4679e-04\n",
      "Epoch 1827/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7699e-04 - val_loss: 5.4666e-04\n",
      "Epoch 1828/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7694e-04 - val_loss: 5.4679e-04\n",
      "Epoch 1829/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7697e-04 - val_loss: 5.4713e-04\n",
      "Epoch 1830/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7694e-04 - val_loss: 5.4696e-04\n",
      "Epoch 1831/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7711e-04 - val_loss: 5.4685e-04\n",
      "Epoch 1832/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7721e-04 - val_loss: 5.4682e-04\n",
      "Epoch 1833/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7723e-04 - val_loss: 5.4705e-04\n",
      "Epoch 1834/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 5.7717e-04 - val_loss: 5.4762e-04\n",
      "Epoch 1835/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7713e-04 - val_loss: 5.4741e-04\n",
      "Epoch 1836/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7716e-04 - val_loss: 5.4683e-04\n",
      "Epoch 1837/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7686e-04 - val_loss: 5.4764e-04\n",
      "Epoch 1838/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7699e-04 - val_loss: 5.4796e-04\n",
      "Epoch 1839/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7687e-04 - val_loss: 5.4644e-04\n",
      "Epoch 1840/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7681e-04 - val_loss: 5.4610e-04\n",
      "Epoch 1841/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7679e-04 - val_loss: 5.4635e-04\n",
      "Epoch 1842/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7675e-04 - val_loss: 5.4631e-04\n",
      "Epoch 1843/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7674e-04 - val_loss: 5.4709e-04\n",
      "Epoch 1844/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7673e-04 - val_loss: 5.4733e-04\n",
      "Epoch 1845/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7671e-04 - val_loss: 5.4736e-04\n",
      "Epoch 1846/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7680e-04 - val_loss: 5.4680e-04\n",
      "Epoch 1847/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7682e-04 - val_loss: 5.4691e-04\n",
      "Epoch 1848/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7667e-04 - val_loss: 5.4622e-04\n",
      "Epoch 1849/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7675e-04 - val_loss: 5.4769e-04\n",
      "Epoch 1850/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7683e-04 - val_loss: 5.4651e-04\n",
      "Epoch 1851/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7662e-04 - val_loss: 5.4656e-04\n",
      "Epoch 1852/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7666e-04 - val_loss: 5.4743e-04\n",
      "Epoch 1853/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7679e-04 - val_loss: 5.4722e-04\n",
      "Epoch 1854/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7672e-04 - val_loss: 5.4692e-04\n",
      "Epoch 1855/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7669e-04 - val_loss: 5.4759e-04\n",
      "Epoch 1856/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7667e-04 - val_loss: 5.4704e-04\n",
      "Epoch 1857/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7660e-04 - val_loss: 5.4737e-04\n",
      "Epoch 1858/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7658e-04 - val_loss: 5.4582e-04\n",
      "Epoch 1859/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7653e-04 - val_loss: 5.4573e-04\n",
      "Epoch 1860/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7649e-04 - val_loss: 5.4783e-04\n",
      "Epoch 1861/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7648e-04 - val_loss: 5.4708e-04\n",
      "Epoch 1862/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7644e-04 - val_loss: 5.4629e-04\n",
      "Epoch 1863/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7634e-04 - val_loss: 5.4634e-04\n",
      "Epoch 1864/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7633e-04 - val_loss: 5.4734e-04\n",
      "Epoch 1865/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7627e-04 - val_loss: 5.4720e-04\n",
      "Epoch 1866/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7645e-04 - val_loss: 5.4691e-04\n",
      "Epoch 1867/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7648e-04 - val_loss: 5.4674e-04\n",
      "Epoch 1868/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7648e-04 - val_loss: 5.4693e-04\n",
      "Epoch 1869/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7648e-04 - val_loss: 5.4665e-04\n",
      "Epoch 1870/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7637e-04 - val_loss: 5.4700e-04\n",
      "Epoch 1871/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7637e-04 - val_loss: 5.4687e-04\n",
      "Epoch 1872/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7644e-04 - val_loss: 5.4624e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1873/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7630e-04 - val_loss: 5.4659e-04\n",
      "Epoch 1874/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7626e-04 - val_loss: 5.4594e-04\n",
      "Epoch 1875/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7616e-04 - val_loss: 5.4658e-04\n",
      "Epoch 1876/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7616e-04 - val_loss: 5.4618e-04\n",
      "Epoch 1877/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7611e-04 - val_loss: 5.4628e-04\n",
      "Epoch 1878/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7624e-04 - val_loss: 5.4715e-04\n",
      "Epoch 1879/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7628e-04 - val_loss: 5.4735e-04\n",
      "Epoch 1880/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7616e-04 - val_loss: 5.4578e-04\n",
      "Epoch 1881/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7617e-04 - val_loss: 5.4672e-04\n",
      "Epoch 1882/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7616e-04 - val_loss: 5.4664e-04\n",
      "Epoch 1883/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7603e-04 - val_loss: 5.4696e-04\n",
      "Epoch 1884/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7611e-04 - val_loss: 5.4670e-04\n",
      "Epoch 1885/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7621e-04 - val_loss: 5.4635e-04\n",
      "Epoch 1886/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7615e-04 - val_loss: 5.4603e-04\n",
      "Epoch 1887/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7602e-04 - val_loss: 5.4573e-04\n",
      "Epoch 1888/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7603e-04 - val_loss: 5.4560e-04\n",
      "Epoch 1889/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7597e-04 - val_loss: 5.4679e-04\n",
      "Epoch 1890/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7601e-04 - val_loss: 5.4636e-04\n",
      "Epoch 1891/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 5.7610e-04 - val_loss: 5.4660e-04\n",
      "Epoch 1892/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7595e-04 - val_loss: 5.4527e-04\n",
      "Epoch 1893/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7588e-04 - val_loss: 5.4597e-04\n",
      "Epoch 1894/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7586e-04 - val_loss: 5.4571e-04\n",
      "Epoch 1895/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7597e-04 - val_loss: 5.4690e-04\n",
      "Epoch 1896/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7588e-04 - val_loss: 5.4617e-04\n",
      "Epoch 1897/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7596e-04 - val_loss: 5.4631e-04\n",
      "Epoch 1898/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7591e-04 - val_loss: 5.4632e-04\n",
      "Epoch 1899/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7583e-04 - val_loss: 5.4574e-04\n",
      "Epoch 1900/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7587e-04 - val_loss: 5.4566e-04\n",
      "Epoch 1901/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7592e-04 - val_loss: 5.4617e-04\n",
      "Epoch 1902/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7593e-04 - val_loss: 5.4625e-04\n",
      "Epoch 1903/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7580e-04 - val_loss: 5.4639e-04\n",
      "Epoch 1904/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7576e-04 - val_loss: 5.4565e-04\n",
      "Epoch 1905/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7573e-04 - val_loss: 5.4544e-04\n",
      "Epoch 1906/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7572e-04 - val_loss: 5.4538e-04\n",
      "Epoch 1907/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7577e-04 - val_loss: 5.4622e-04\n",
      "Epoch 1908/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7562e-04 - val_loss: 5.4590e-04\n",
      "Epoch 1909/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7569e-04 - val_loss: 5.4595e-04\n",
      "Epoch 1910/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7561e-04 - val_loss: 5.4528e-04\n",
      "Epoch 1911/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7570e-04 - val_loss: 5.4602e-04\n",
      "Epoch 1912/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7562e-04 - val_loss: 5.4605e-04\n",
      "Epoch 1913/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7554e-04 - val_loss: 5.4597e-04\n",
      "Epoch 1914/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7564e-04 - val_loss: 5.4563e-04\n",
      "Epoch 1915/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7555e-04 - val_loss: 5.4574e-04\n",
      "Epoch 1916/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7564e-04 - val_loss: 5.4555e-04\n",
      "Epoch 1917/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7568e-04 - val_loss: 5.4570e-04\n",
      "Epoch 1918/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7555e-04 - val_loss: 5.4526e-04\n",
      "Epoch 1919/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7553e-04 - val_loss: 5.4502e-04\n",
      "Epoch 1920/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7552e-04 - val_loss: 5.4580e-04\n",
      "Epoch 1921/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7558e-04 - val_loss: 5.4594e-04\n",
      "Epoch 1922/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7544e-04 - val_loss: 5.4592e-04\n",
      "Epoch 1923/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7537e-04 - val_loss: 5.4555e-04\n",
      "Epoch 1924/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7537e-04 - val_loss: 5.4589e-04\n",
      "Epoch 1925/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7540e-04 - val_loss: 5.4602e-04\n",
      "Epoch 1926/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7539e-04 - val_loss: 5.4649e-04\n",
      "Epoch 1927/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7531e-04 - val_loss: 5.4577e-04\n",
      "Epoch 1928/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7542e-04 - val_loss: 5.4585e-04\n",
      "Epoch 1929/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7530e-04 - val_loss: 5.4573e-04\n",
      "Epoch 1930/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7531e-04 - val_loss: 5.4570e-04\n",
      "Epoch 1931/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7523e-04 - val_loss: 5.4544e-04\n",
      "Epoch 1932/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7542e-04 - val_loss: 5.4485e-04\n",
      "Epoch 1933/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7526e-04 - val_loss: 5.4558e-04\n",
      "Epoch 1934/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7537e-04 - val_loss: 5.4581e-04\n",
      "Epoch 1935/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7528e-04 - val_loss: 5.4526e-04\n",
      "Epoch 1936/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7528e-04 - val_loss: 5.4478e-04\n",
      "Epoch 1937/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7521e-04 - val_loss: 5.4557e-04\n",
      "Epoch 1938/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7530e-04 - val_loss: 5.4594e-04\n",
      "Epoch 1939/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7520e-04 - val_loss: 5.4547e-04\n",
      "Epoch 1940/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7513e-04 - val_loss: 5.4547e-04\n",
      "Epoch 1941/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7518e-04 - val_loss: 5.4560e-04\n",
      "Epoch 1942/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7513e-04 - val_loss: 5.4570e-04\n",
      "Epoch 1943/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7516e-04 - val_loss: 5.4618e-04\n",
      "Epoch 1944/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7511e-04 - val_loss: 5.4532e-04\n",
      "Epoch 1945/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7514e-04 - val_loss: 5.4513e-04\n",
      "Epoch 1946/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7523e-04 - val_loss: 5.4594e-04\n",
      "Epoch 1947/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7502e-04 - val_loss: 5.4514e-04\n",
      "Epoch 1948/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7506e-04 - val_loss: 5.4488e-04\n",
      "Epoch 1949/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7500e-04 - val_loss: 5.4497e-04\n",
      "Epoch 1950/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7512e-04 - val_loss: 5.4596e-04\n",
      "Epoch 1951/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7492e-04 - val_loss: 5.4599e-04\n",
      "Epoch 1952/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7493e-04 - val_loss: 5.4572e-04\n",
      "Epoch 1953/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7489e-04 - val_loss: 5.4584e-04\n",
      "Epoch 1954/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7498e-04 - val_loss: 5.4569e-04\n",
      "Epoch 1955/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7506e-04 - val_loss: 5.4584e-04\n",
      "Epoch 1956/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7490e-04 - val_loss: 5.4528e-04\n",
      "Epoch 1957/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7496e-04 - val_loss: 5.4541e-04\n",
      "Epoch 1958/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7479e-04 - val_loss: 5.4531e-04\n",
      "Epoch 1959/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7508e-04 - val_loss: 5.4581e-04\n",
      "Epoch 1960/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7488e-04 - val_loss: 5.4565e-04\n",
      "Epoch 1961/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7483e-04 - val_loss: 5.4560e-04\n",
      "Epoch 1962/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7484e-04 - val_loss: 5.4499e-04\n",
      "Epoch 1963/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7482e-04 - val_loss: 5.4530e-04\n",
      "Epoch 1964/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7472e-04 - val_loss: 5.4542e-04\n",
      "Epoch 1965/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7474e-04 - val_loss: 5.4513e-04\n",
      "Epoch 1966/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.7481e-04 - val_loss: 5.4526e-04\n",
      "Epoch 1967/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7479e-04 - val_loss: 5.4598e-04\n",
      "Epoch 1968/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7470e-04 - val_loss: 5.4487e-04\n",
      "Epoch 1969/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7469e-04 - val_loss: 5.4509e-04\n",
      "Epoch 1970/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7466e-04 - val_loss: 5.4497e-04\n",
      "Epoch 1971/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7483e-04 - val_loss: 5.4552e-04\n",
      "Epoch 1972/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7480e-04 - val_loss: 5.4554e-04\n",
      "Epoch 1973/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7470e-04 - val_loss: 5.4485e-04\n",
      "Epoch 1974/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7470e-04 - val_loss: 5.4573e-04\n",
      "Epoch 1975/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7455e-04 - val_loss: 5.4519e-04\n",
      "Epoch 1976/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7454e-04 - val_loss: 5.4473e-04\n",
      "Epoch 1977/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7461e-04 - val_loss: 5.4476e-04\n",
      "Epoch 1978/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7456e-04 - val_loss: 5.4576e-04\n",
      "Epoch 1979/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7468e-04 - val_loss: 5.4547e-04\n",
      "Epoch 1980/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7456e-04 - val_loss: 5.4505e-04\n",
      "Epoch 1981/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7445e-04 - val_loss: 5.4530e-04\n",
      "Epoch 1982/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7463e-04 - val_loss: 5.4585e-04\n",
      "Epoch 1983/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7453e-04 - val_loss: 5.4523e-04\n",
      "Epoch 1984/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7448e-04 - val_loss: 5.4448e-04\n",
      "Epoch 1985/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7449e-04 - val_loss: 5.4546e-04\n",
      "Epoch 1986/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7455e-04 - val_loss: 5.4465e-04\n",
      "Epoch 1987/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7448e-04 - val_loss: 5.4543e-04\n",
      "Epoch 1988/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7444e-04 - val_loss: 5.4590e-04\n",
      "Epoch 1989/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7451e-04 - val_loss: 5.4501e-04\n",
      "Epoch 1990/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7446e-04 - val_loss: 5.4489e-04\n",
      "Epoch 1991/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7436e-04 - val_loss: 5.4507e-04\n",
      "Epoch 1992/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7428e-04 - val_loss: 5.4494e-04\n",
      "Epoch 1993/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7433e-04 - val_loss: 5.4511e-04\n",
      "Epoch 1994/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7444e-04 - val_loss: 5.4509e-04\n",
      "Epoch 1995/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7438e-04 - val_loss: 5.4542e-04\n",
      "Epoch 1996/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7435e-04 - val_loss: 5.4489e-04\n",
      "Epoch 1997/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7434e-04 - val_loss: 5.4475e-04\n",
      "Epoch 1998/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7439e-04 - val_loss: 5.4485e-04\n",
      "Epoch 1999/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7432e-04 - val_loss: 5.4423e-04\n",
      "Epoch 2000/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7423e-04 - val_loss: 5.4544e-04\n",
      "Epoch 2001/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7435e-04 - val_loss: 5.4503e-04\n",
      "Epoch 2002/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7423e-04 - val_loss: 5.4502e-04\n",
      "Epoch 2003/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7427e-04 - val_loss: 5.4572e-04\n",
      "Epoch 2004/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7418e-04 - val_loss: 5.4485e-04\n",
      "Epoch 2005/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 5.7415e-04 - val_loss: 5.4478e-04\n",
      "Epoch 2006/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7413e-04 - val_loss: 5.4515e-04\n",
      "Epoch 2007/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7412e-04 - val_loss: 5.4482e-04\n",
      "Epoch 2008/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7422e-04 - val_loss: 5.4525e-04\n",
      "Epoch 2009/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7420e-04 - val_loss: 5.4559e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2010/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7406e-04 - val_loss: 5.4498e-04\n",
      "Epoch 2011/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7412e-04 - val_loss: 5.4541e-04\n",
      "Epoch 2012/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7416e-04 - val_loss: 5.4504e-04\n",
      "Epoch 2013/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7408e-04 - val_loss: 5.4437e-04\n",
      "Epoch 2014/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7410e-04 - val_loss: 5.4522e-04\n",
      "Epoch 2015/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7409e-04 - val_loss: 5.4450e-04\n",
      "Epoch 2016/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7403e-04 - val_loss: 5.4522e-04\n",
      "Epoch 2017/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7411e-04 - val_loss: 5.4502e-04\n",
      "Epoch 2018/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7396e-04 - val_loss: 5.4480e-04\n",
      "Epoch 2019/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7401e-04 - val_loss: 5.4429e-04\n",
      "Epoch 2020/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7405e-04 - val_loss: 5.4550e-04\n",
      "Epoch 2021/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7395e-04 - val_loss: 5.4437e-04\n",
      "Epoch 2022/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7400e-04 - val_loss: 5.4512e-04\n",
      "Epoch 2023/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7387e-04 - val_loss: 5.4460e-04\n",
      "Epoch 2024/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7388e-04 - val_loss: 5.4487e-04\n",
      "Epoch 2025/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7390e-04 - val_loss: 5.4523e-04\n",
      "Epoch 2026/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7406e-04 - val_loss: 5.4466e-04\n",
      "Epoch 2027/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7398e-04 - val_loss: 5.4486e-04\n",
      "Epoch 2028/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7376e-04 - val_loss: 5.4383e-04\n",
      "Epoch 2029/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7386e-04 - val_loss: 5.4442e-04\n",
      "Epoch 2030/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7388e-04 - val_loss: 5.4502e-04\n",
      "Epoch 2031/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7380e-04 - val_loss: 5.4512e-04\n",
      "Epoch 2032/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7392e-04 - val_loss: 5.4589e-04\n",
      "Epoch 2033/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7377e-04 - val_loss: 5.4486e-04\n",
      "Epoch 2034/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7373e-04 - val_loss: 5.4415e-04\n",
      "Epoch 2035/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7379e-04 - val_loss: 5.4527e-04\n",
      "Epoch 2036/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7382e-04 - val_loss: 5.4453e-04\n",
      "Epoch 2037/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7379e-04 - val_loss: 5.4537e-04\n",
      "Epoch 2038/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7375e-04 - val_loss: 5.4540e-04\n",
      "Epoch 2039/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7392e-04 - val_loss: 5.4528e-04\n",
      "Epoch 2040/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7378e-04 - val_loss: 5.4634e-04\n",
      "Epoch 2041/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7370e-04 - val_loss: 5.4533e-04\n",
      "Epoch 2042/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7375e-04 - val_loss: 5.4383e-04\n",
      "Epoch 2043/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7366e-04 - val_loss: 5.4438e-04\n",
      "Epoch 2044/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7372e-04 - val_loss: 5.4518e-04\n",
      "Epoch 2045/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7358e-04 - val_loss: 5.4485e-04\n",
      "Epoch 2046/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7376e-04 - val_loss: 5.4516e-04\n",
      "Epoch 2047/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7363e-04 - val_loss: 5.4450e-04\n",
      "Epoch 2048/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7356e-04 - val_loss: 5.4558e-04\n",
      "Epoch 2049/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7362e-04 - val_loss: 5.4448e-04\n",
      "Epoch 2050/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7369e-04 - val_loss: 5.4441e-04\n",
      "Epoch 2051/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7351e-04 - val_loss: 5.4510e-04\n",
      "Epoch 2052/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7361e-04 - val_loss: 5.4505e-04\n",
      "Epoch 2053/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7356e-04 - val_loss: 5.4481e-04\n",
      "Epoch 2054/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7351e-04 - val_loss: 5.4424e-04\n",
      "Epoch 2055/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7345e-04 - val_loss: 5.4525e-04\n",
      "Epoch 2056/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7347e-04 - val_loss: 5.4352e-04\n",
      "Epoch 2057/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7352e-04 - val_loss: 5.4539e-04\n",
      "Epoch 2058/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7347e-04 - val_loss: 5.4535e-04\n",
      "Epoch 2059/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7349e-04 - val_loss: 5.4526e-04\n",
      "Epoch 2060/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7343e-04 - val_loss: 5.4544e-04\n",
      "Epoch 2061/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7347e-04 - val_loss: 5.4384e-04\n",
      "Epoch 2062/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7348e-04 - val_loss: 5.4524e-04\n",
      "Epoch 2063/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7335e-04 - val_loss: 5.4467e-04\n",
      "Epoch 2064/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7347e-04 - val_loss: 5.4567e-04\n",
      "Epoch 2065/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7329e-04 - val_loss: 5.4464e-04\n",
      "Epoch 2066/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7352e-04 - val_loss: 5.4502e-04\n",
      "Epoch 2067/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7326e-04 - val_loss: 5.4398e-04\n",
      "Epoch 2068/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7332e-04 - val_loss: 5.4476e-04\n",
      "Epoch 2069/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7333e-04 - val_loss: 5.4423e-04\n",
      "Epoch 2070/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7329e-04 - val_loss: 5.4444e-04\n",
      "Epoch 2071/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7326e-04 - val_loss: 5.4455e-04\n",
      "Epoch 2072/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7338e-04 - val_loss: 5.4542e-04\n",
      "Epoch 2073/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7331e-04 - val_loss: 5.4494e-04\n",
      "Epoch 2074/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7323e-04 - val_loss: 5.4531e-04\n",
      "Epoch 2075/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7315e-04 - val_loss: 5.4485e-04\n",
      "Epoch 2076/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7318e-04 - val_loss: 5.4467e-04\n",
      "Epoch 2077/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7321e-04 - val_loss: 5.4570e-04\n",
      "Epoch 2078/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7315e-04 - val_loss: 5.4501e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2079/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7325e-04 - val_loss: 5.4438e-04\n",
      "Epoch 2080/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7324e-04 - val_loss: 5.4504e-04\n",
      "Epoch 2081/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7314e-04 - val_loss: 5.4469e-04\n",
      "Epoch 2082/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7311e-04 - val_loss: 5.4463e-04\n",
      "Epoch 2083/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7309e-04 - val_loss: 5.4488e-04\n",
      "Epoch 2084/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7313e-04 - val_loss: 5.4433e-04\n",
      "Epoch 2085/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7323e-04 - val_loss: 5.4476e-04\n",
      "Epoch 2086/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7304e-04 - val_loss: 5.4482e-04\n",
      "Epoch 2087/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7307e-04 - val_loss: 5.4363e-04\n",
      "Epoch 2088/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7311e-04 - val_loss: 5.4465e-04\n",
      "Epoch 2089/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7298e-04 - val_loss: 5.4398e-04\n",
      "Epoch 2090/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7305e-04 - val_loss: 5.4460e-04\n",
      "Epoch 2091/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7315e-04 - val_loss: 5.4452e-04\n",
      "Epoch 2092/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7303e-04 - val_loss: 5.4459e-04\n",
      "Epoch 2093/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7302e-04 - val_loss: 5.4431e-04\n",
      "Epoch 2094/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7300e-04 - val_loss: 5.4407e-04\n",
      "Epoch 2095/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7296e-04 - val_loss: 5.4423e-04\n",
      "Epoch 2096/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7300e-04 - val_loss: 5.4482e-04\n",
      "Epoch 2097/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7299e-04 - val_loss: 5.4420e-04\n",
      "Epoch 2098/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7290e-04 - val_loss: 5.4495e-04\n",
      "Epoch 2099/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7293e-04 - val_loss: 5.4438e-04\n",
      "Epoch 2100/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7295e-04 - val_loss: 5.4440e-04\n",
      "Epoch 2101/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7297e-04 - val_loss: 5.4457e-04\n",
      "Epoch 2102/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7293e-04 - val_loss: 5.4452e-04\n",
      "Epoch 2103/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7285e-04 - val_loss: 5.4402e-04\n",
      "Epoch 2104/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7289e-04 - val_loss: 5.4525e-04\n",
      "Epoch 2105/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7281e-04 - val_loss: 5.4465e-04\n",
      "Epoch 2106/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7281e-04 - val_loss: 5.4379e-04\n",
      "Epoch 2107/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7287e-04 - val_loss: 5.4425e-04\n",
      "Epoch 2108/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7276e-04 - val_loss: 5.4452e-04\n",
      "Epoch 2109/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7287e-04 - val_loss: 5.4468e-04\n",
      "Epoch 2110/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7270e-04 - val_loss: 5.4422e-04\n",
      "Epoch 2111/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7279e-04 - val_loss: 5.4516e-04\n",
      "Epoch 2112/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7278e-04 - val_loss: 5.4493e-04\n",
      "Epoch 2113/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7272e-04 - val_loss: 5.4493e-04\n",
      "Epoch 2114/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7269e-04 - val_loss: 5.4469e-04\n",
      "Epoch 2115/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7271e-04 - val_loss: 5.4459e-04\n",
      "Epoch 2116/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7267e-04 - val_loss: 5.4414e-04\n",
      "Epoch 2117/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7281e-04 - val_loss: 5.4452e-04\n",
      "Epoch 2118/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7275e-04 - val_loss: 5.4438e-04\n",
      "Epoch 2119/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7265e-04 - val_loss: 5.4429e-04\n",
      "Epoch 2120/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7269e-04 - val_loss: 5.4339e-04\n",
      "Epoch 2121/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7268e-04 - val_loss: 5.4438e-04\n",
      "Epoch 2122/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7270e-04 - val_loss: 5.4449e-04\n",
      "Epoch 2123/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7268e-04 - val_loss: 5.4492e-04\n",
      "Epoch 2124/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7264e-04 - val_loss: 5.4514e-04\n",
      "Epoch 2125/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7260e-04 - val_loss: 5.4540e-04\n",
      "Epoch 2126/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7257e-04 - val_loss: 5.4535e-04\n",
      "Epoch 2127/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7255e-04 - val_loss: 5.4359e-04\n",
      "Epoch 2128/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7261e-04 - val_loss: 5.4402e-04\n",
      "Epoch 2129/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7252e-04 - val_loss: 5.4459e-04\n",
      "Epoch 2130/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7260e-04 - val_loss: 5.4472e-04\n",
      "Epoch 2131/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7250e-04 - val_loss: 5.4426e-04\n",
      "Epoch 2132/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7247e-04 - val_loss: 5.4411e-04\n",
      "Epoch 2133/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7246e-04 - val_loss: 5.4442e-04\n",
      "Epoch 2134/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7242e-04 - val_loss: 5.4439e-04\n",
      "Epoch 2135/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7251e-04 - val_loss: 5.4347e-04\n",
      "Epoch 2136/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7256e-04 - val_loss: 5.4448e-04\n",
      "Epoch 2137/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7260e-04 - val_loss: 5.4395e-04\n",
      "Epoch 2138/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7239e-04 - val_loss: 5.4418e-04\n",
      "Epoch 2139/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7236e-04 - val_loss: 5.4351e-04\n",
      "Epoch 2140/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7245e-04 - val_loss: 5.4472e-04\n",
      "Epoch 2141/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7241e-04 - val_loss: 5.4459e-04\n",
      "Epoch 2142/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7241e-04 - val_loss: 5.4399e-04\n",
      "Epoch 2143/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7243e-04 - val_loss: 5.4487e-04\n",
      "Epoch 2144/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7235e-04 - val_loss: 5.4424e-04\n",
      "Epoch 2145/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7237e-04 - val_loss: 5.4439e-04\n",
      "Epoch 2146/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7232e-04 - val_loss: 5.4405e-04\n",
      "Epoch 2147/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7239e-04 - val_loss: 5.4429e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2148/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7236e-04 - val_loss: 5.4426e-04\n",
      "Epoch 2149/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7232e-04 - val_loss: 5.4349e-04\n",
      "Epoch 2150/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7226e-04 - val_loss: 5.4427e-04\n",
      "Epoch 2151/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7229e-04 - val_loss: 5.4440e-04\n",
      "Epoch 2152/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7225e-04 - val_loss: 5.4409e-04\n",
      "Epoch 2153/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7223e-04 - val_loss: 5.4282e-04\n",
      "Epoch 2154/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7228e-04 - val_loss: 5.4439e-04\n",
      "Epoch 2155/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7224e-04 - val_loss: 5.4415e-04\n",
      "Epoch 2156/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7224e-04 - val_loss: 5.4325e-04\n",
      "Epoch 2157/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7221e-04 - val_loss: 5.4423e-04\n",
      "Epoch 2158/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7226e-04 - val_loss: 5.4407e-04\n",
      "Epoch 2159/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7215e-04 - val_loss: 5.4421e-04\n",
      "Epoch 2160/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7224e-04 - val_loss: 5.4494e-04\n",
      "Epoch 2161/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7209e-04 - val_loss: 5.4451e-04\n",
      "Epoch 2162/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7223e-04 - val_loss: 5.4454e-04\n",
      "Epoch 2163/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7211e-04 - val_loss: 5.4400e-04\n",
      "Epoch 2164/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7215e-04 - val_loss: 5.4459e-04\n",
      "Epoch 2165/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7217e-04 - val_loss: 5.4409e-04\n",
      "Epoch 2166/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7205e-04 - val_loss: 5.4421e-04\n",
      "Epoch 2167/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7205e-04 - val_loss: 5.4364e-04\n",
      "Epoch 2168/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7214e-04 - val_loss: 5.4453e-04\n",
      "Epoch 2169/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7213e-04 - val_loss: 5.4461e-04\n",
      "Epoch 2170/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7203e-04 - val_loss: 5.4491e-04\n",
      "Epoch 2171/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7209e-04 - val_loss: 5.4425e-04\n",
      "Epoch 2172/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7203e-04 - val_loss: 5.4452e-04\n",
      "Epoch 2173/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7210e-04 - val_loss: 5.4431e-04\n",
      "Epoch 2174/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7208e-04 - val_loss: 5.4458e-04\n",
      "Epoch 2175/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7197e-04 - val_loss: 5.4383e-04\n",
      "Epoch 2176/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7206e-04 - val_loss: 5.4380e-04\n",
      "Epoch 2177/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7195e-04 - val_loss: 5.4442e-04\n",
      "Epoch 2178/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7199e-04 - val_loss: 5.4281e-04\n",
      "Epoch 2179/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7201e-04 - val_loss: 5.4431e-04\n",
      "Epoch 2180/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7207e-04 - val_loss: 5.4366e-04\n",
      "Epoch 2181/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7187e-04 - val_loss: 5.4444e-04\n",
      "Epoch 2182/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7204e-04 - val_loss: 5.4409e-04\n",
      "Epoch 2183/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7192e-04 - val_loss: 5.4357e-04\n",
      "Epoch 2184/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7191e-04 - val_loss: 5.4470e-04\n",
      "Epoch 2185/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7186e-04 - val_loss: 5.4407e-04\n",
      "Epoch 2186/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7191e-04 - val_loss: 5.4411e-04\n",
      "Epoch 2187/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7183e-04 - val_loss: 5.4368e-04\n",
      "Epoch 2188/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7182e-04 - val_loss: 5.4384e-04\n",
      "Epoch 2189/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7188e-04 - val_loss: 5.4386e-04\n",
      "Epoch 2190/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7193e-04 - val_loss: 5.4416e-04\n",
      "Epoch 2191/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7176e-04 - val_loss: 5.4395e-04\n",
      "Epoch 2192/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7174e-04 - val_loss: 5.4385e-04\n",
      "Epoch 2193/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7185e-04 - val_loss: 5.4310e-04\n",
      "Epoch 2194/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.7176e-04 - val_loss: 5.4413e-04\n",
      "Epoch 2195/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7178e-04 - val_loss: 5.4363e-04\n",
      "Epoch 2196/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7181e-04 - val_loss: 5.4331e-04\n",
      "Epoch 2197/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7180e-04 - val_loss: 5.4389e-04\n",
      "Epoch 2198/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7172e-04 - val_loss: 5.4400e-04\n",
      "Epoch 2199/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7183e-04 - val_loss: 5.4230e-04\n",
      "Epoch 2200/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7168e-04 - val_loss: 5.4442e-04\n",
      "Epoch 2201/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7178e-04 - val_loss: 5.4340e-04\n",
      "Epoch 2202/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7165e-04 - val_loss: 5.4358e-04\n",
      "Epoch 2203/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7175e-04 - val_loss: 5.4349e-04\n",
      "Epoch 2204/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7160e-04 - val_loss: 5.4406e-04\n",
      "Epoch 2205/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7179e-04 - val_loss: 5.4405e-04\n",
      "Epoch 2206/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7162e-04 - val_loss: 5.4458e-04\n",
      "Epoch 2207/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7171e-04 - val_loss: 5.4273e-04\n",
      "Epoch 2208/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7168e-04 - val_loss: 5.4382e-04\n",
      "Epoch 2209/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7165e-04 - val_loss: 5.4478e-04\n",
      "Epoch 2210/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7160e-04 - val_loss: 5.4331e-04\n",
      "Epoch 2211/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7163e-04 - val_loss: 5.4326e-04\n",
      "Epoch 2212/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7160e-04 - val_loss: 5.4375e-04\n",
      "Epoch 2213/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7167e-04 - val_loss: 5.4259e-04\n",
      "Epoch 2214/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7163e-04 - val_loss: 5.4366e-04\n",
      "Epoch 2215/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7153e-04 - val_loss: 5.4519e-04\n",
      "Epoch 2216/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7158e-04 - val_loss: 5.4226e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2217/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7158e-04 - val_loss: 5.4381e-04\n",
      "Epoch 2218/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7149e-04 - val_loss: 5.4427e-04\n",
      "Epoch 2219/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7157e-04 - val_loss: 5.4331e-04\n",
      "Epoch 2220/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7150e-04 - val_loss: 5.4447e-04\n",
      "Epoch 2221/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7155e-04 - val_loss: 5.4343e-04\n",
      "Epoch 2222/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7147e-04 - val_loss: 5.4397e-04\n",
      "Epoch 2223/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7151e-04 - val_loss: 5.4301e-04\n",
      "Epoch 2224/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7144e-04 - val_loss: 5.4435e-04\n",
      "Epoch 2225/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7150e-04 - val_loss: 5.4362e-04\n",
      "Epoch 2226/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7151e-04 - val_loss: 5.4388e-04\n",
      "Epoch 2227/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7148e-04 - val_loss: 5.4427e-04\n",
      "Epoch 2228/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7140e-04 - val_loss: 5.4335e-04\n",
      "Epoch 2229/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7143e-04 - val_loss: 5.4401e-04\n",
      "Epoch 2230/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7134e-04 - val_loss: 5.4381e-04\n",
      "Epoch 2231/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7135e-04 - val_loss: 5.4391e-04\n",
      "Epoch 2232/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7143e-04 - val_loss: 5.4316e-04\n",
      "Epoch 2233/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7141e-04 - val_loss: 5.4461e-04\n",
      "Epoch 2234/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7143e-04 - val_loss: 5.4319e-04\n",
      "Epoch 2235/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7141e-04 - val_loss: 5.4478e-04\n",
      "Epoch 2236/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7137e-04 - val_loss: 5.4358e-04\n",
      "Epoch 2237/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7134e-04 - val_loss: 5.4393e-04\n",
      "Epoch 2238/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7136e-04 - val_loss: 5.4291e-04\n",
      "Epoch 2239/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7140e-04 - val_loss: 5.4233e-04\n",
      "Epoch 2240/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7133e-04 - val_loss: 5.4365e-04\n",
      "Epoch 2241/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7134e-04 - val_loss: 5.4422e-04\n",
      "Epoch 2242/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7123e-04 - val_loss: 5.4372e-04\n",
      "Epoch 2243/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7126e-04 - val_loss: 5.4298e-04\n",
      "Epoch 2244/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7136e-04 - val_loss: 5.4445e-04\n",
      "Epoch 2245/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7126e-04 - val_loss: 5.4366e-04\n",
      "Epoch 2246/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7126e-04 - val_loss: 5.4436e-04\n",
      "Epoch 2247/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7132e-04 - val_loss: 5.4477e-04\n",
      "Epoch 2248/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7127e-04 - val_loss: 5.4422e-04\n",
      "Epoch 2249/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7122e-04 - val_loss: 5.4357e-04\n",
      "Epoch 2250/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.7113e-04 - val_loss: 5.4388e-04\n",
      "Epoch 2251/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7125e-04 - val_loss: 5.4254e-04\n",
      "Epoch 2252/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7124e-04 - val_loss: 5.4437e-04\n",
      "Epoch 2253/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7115e-04 - val_loss: 5.4253e-04\n",
      "Epoch 2254/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7120e-04 - val_loss: 5.4214e-04\n",
      "Epoch 2255/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7117e-04 - val_loss: 5.4301e-04\n",
      "Epoch 2256/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7113e-04 - val_loss: 5.4375e-04\n",
      "Epoch 2257/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7114e-04 - val_loss: 5.4393e-04\n",
      "Epoch 2258/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7114e-04 - val_loss: 5.4487e-04\n",
      "Epoch 2259/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7115e-04 - val_loss: 5.4276e-04\n",
      "Epoch 2260/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7112e-04 - val_loss: 5.4424e-04\n",
      "Epoch 2261/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7113e-04 - val_loss: 5.4398e-04\n",
      "Epoch 2262/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7109e-04 - val_loss: 5.4220e-04\n",
      "Epoch 2263/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7108e-04 - val_loss: 5.4440e-04\n",
      "Epoch 2264/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7108e-04 - val_loss: 5.4310e-04\n",
      "Epoch 2265/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7112e-04 - val_loss: 5.4364e-04\n",
      "Epoch 2266/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7101e-04 - val_loss: 5.4416e-04\n",
      "Epoch 2267/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7107e-04 - val_loss: 5.4383e-04\n",
      "Epoch 2268/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7100e-04 - val_loss: 5.4274e-04\n",
      "Epoch 2269/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7107e-04 - val_loss: 5.4364e-04\n",
      "Epoch 2270/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7102e-04 - val_loss: 5.4360e-04\n",
      "Epoch 2271/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7096e-04 - val_loss: 5.4475e-04\n",
      "Epoch 2272/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7097e-04 - val_loss: 5.4397e-04\n",
      "Epoch 2273/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7099e-04 - val_loss: 5.4435e-04\n",
      "Epoch 2274/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7097e-04 - val_loss: 5.4374e-04\n",
      "Epoch 2275/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7104e-04 - val_loss: 5.4195e-04\n",
      "Epoch 2276/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7095e-04 - val_loss: 5.4305e-04\n",
      "Epoch 2277/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7097e-04 - val_loss: 5.4370e-04\n",
      "Epoch 2278/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7090e-04 - val_loss: 5.4254e-04\n",
      "Epoch 2279/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7086e-04 - val_loss: 5.4380e-04\n",
      "Epoch 2280/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7092e-04 - val_loss: 5.4334e-04\n",
      "Epoch 2281/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7086e-04 - val_loss: 5.4295e-04\n",
      "Epoch 2282/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7087e-04 - val_loss: 5.4361e-04\n",
      "Epoch 2283/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7089e-04 - val_loss: 5.4165e-04\n",
      "Epoch 2284/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7087e-04 - val_loss: 5.4426e-04\n",
      "Epoch 2285/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7089e-04 - val_loss: 5.4294e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2286/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7084e-04 - val_loss: 5.4253e-04\n",
      "Epoch 2287/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7080e-04 - val_loss: 5.4349e-04\n",
      "Epoch 2288/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7084e-04 - val_loss: 5.4385e-04\n",
      "Epoch 2289/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7086e-04 - val_loss: 5.4304e-04\n",
      "Epoch 2290/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7084e-04 - val_loss: 5.4262e-04\n",
      "Epoch 2291/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7078e-04 - val_loss: 5.4386e-04\n",
      "Epoch 2292/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7084e-04 - val_loss: 5.4241e-04\n",
      "Epoch 2293/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7076e-04 - val_loss: 5.4321e-04\n",
      "Epoch 2294/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7076e-04 - val_loss: 5.4181e-04\n",
      "Epoch 2295/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7082e-04 - val_loss: 5.4377e-04\n",
      "Epoch 2296/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7074e-04 - val_loss: 5.4363e-04\n",
      "Epoch 2297/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7069e-04 - val_loss: 5.4403e-04\n",
      "Epoch 2298/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7076e-04 - val_loss: 5.4159e-04\n",
      "Epoch 2299/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7065e-04 - val_loss: 5.4350e-04\n",
      "Epoch 2300/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7073e-04 - val_loss: 5.4328e-04\n",
      "Epoch 2301/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.7074e-04 - val_loss: 5.4245e-04\n",
      "Epoch 2302/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7077e-04 - val_loss: 5.4438e-04\n",
      "Epoch 2303/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7072e-04 - val_loss: 5.4347e-04\n",
      "Epoch 2304/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7069e-04 - val_loss: 5.4358e-04\n",
      "Epoch 2305/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7068e-04 - val_loss: 5.4309e-04\n",
      "Epoch 2306/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7071e-04 - val_loss: 5.4216e-04\n",
      "Epoch 2307/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7068e-04 - val_loss: 5.4451e-04\n",
      "Epoch 2308/10000\n",
      "45507/45507 [==============================] - 1s 23us/step - loss: 5.7059e-04 - val_loss: 5.4422e-04\n",
      "Epoch 2309/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7059e-04 - val_loss: 5.4239e-04\n",
      "Epoch 2310/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7060e-04 - val_loss: 5.4161e-04\n",
      "Epoch 2311/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7069e-04 - val_loss: 5.4153e-04\n",
      "Epoch 2312/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7056e-04 - val_loss: 5.4348e-04\n",
      "Epoch 2313/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7065e-04 - val_loss: 5.4318e-04\n",
      "Epoch 2314/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7065e-04 - val_loss: 5.4354e-04\n",
      "Epoch 2315/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7059e-04 - val_loss: 5.4190e-04\n",
      "Epoch 2316/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7054e-04 - val_loss: 5.4392e-04\n",
      "Epoch 2317/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7063e-04 - val_loss: 5.4268e-04\n",
      "Epoch 2318/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7047e-04 - val_loss: 5.4392e-04\n",
      "Epoch 2319/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7053e-04 - val_loss: 5.4407e-04\n",
      "Epoch 2320/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7050e-04 - val_loss: 5.4468e-04\n",
      "Epoch 2321/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7056e-04 - val_loss: 5.4429e-04\n",
      "Epoch 2322/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7055e-04 - val_loss: 5.4315e-04\n",
      "Epoch 2323/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7054e-04 - val_loss: 5.4391e-04\n",
      "Epoch 2324/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7054e-04 - val_loss: 5.4355e-04\n",
      "Epoch 2325/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7049e-04 - val_loss: 5.4220e-04\n",
      "Epoch 2326/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7052e-04 - val_loss: 5.4420e-04\n",
      "Epoch 2327/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7040e-04 - val_loss: 5.4404e-04\n",
      "Epoch 2328/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7042e-04 - val_loss: 5.4403e-04\n",
      "Epoch 2329/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7039e-04 - val_loss: 5.4390e-04\n",
      "Epoch 2330/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7042e-04 - val_loss: 5.4312e-04\n",
      "Epoch 2331/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7036e-04 - val_loss: 5.4356e-04\n",
      "Epoch 2332/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7038e-04 - val_loss: 5.4337e-04\n",
      "Epoch 2333/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7036e-04 - val_loss: 5.4417e-04\n",
      "Epoch 2334/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7038e-04 - val_loss: 5.4320e-04\n",
      "Epoch 2335/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7038e-04 - val_loss: 5.4300e-04\n",
      "Epoch 2336/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7034e-04 - val_loss: 5.4178e-04\n",
      "Epoch 2337/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7040e-04 - val_loss: 5.4252e-04\n",
      "Epoch 2338/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7031e-04 - val_loss: 5.4307e-04\n",
      "Epoch 2339/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.7034e-04 - val_loss: 5.4226e-04\n",
      "Epoch 2340/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7034e-04 - val_loss: 5.4337e-04\n",
      "Epoch 2341/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7032e-04 - val_loss: 5.4190e-04\n",
      "Epoch 2342/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7030e-04 - val_loss: 5.4249e-04\n",
      "Epoch 2343/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7025e-04 - val_loss: 5.4129e-04\n",
      "Epoch 2344/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7027e-04 - val_loss: 5.4251e-04\n",
      "Epoch 2345/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7026e-04 - val_loss: 5.4340e-04\n",
      "Epoch 2346/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.7027e-04 - val_loss: 5.4334e-04\n",
      "Epoch 2347/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7025e-04 - val_loss: 5.4313e-04\n",
      "Epoch 2348/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7014e-04 - val_loss: 5.4212e-04\n",
      "Epoch 2349/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7026e-04 - val_loss: 5.4314e-04\n",
      "Epoch 2350/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7033e-04 - val_loss: 5.4275e-04\n",
      "Epoch 2351/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7020e-04 - val_loss: 5.4248e-04\n",
      "Epoch 2352/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7028e-04 - val_loss: 5.4174e-04\n",
      "Epoch 2353/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7023e-04 - val_loss: 5.4358e-04\n",
      "Epoch 2354/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7021e-04 - val_loss: 5.4304e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2355/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7020e-04 - val_loss: 5.4206e-04\n",
      "Epoch 2356/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7018e-04 - val_loss: 5.4336e-04\n",
      "Epoch 2357/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7012e-04 - val_loss: 5.4321e-04\n",
      "Epoch 2358/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.7017e-04 - val_loss: 5.4265e-04\n",
      "Epoch 2359/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7016e-04 - val_loss: 5.4179e-04\n",
      "Epoch 2360/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7022e-04 - val_loss: 5.4314e-04\n",
      "Epoch 2361/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7013e-04 - val_loss: 5.4281e-04\n",
      "Epoch 2362/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7013e-04 - val_loss: 5.4354e-04\n",
      "Epoch 2363/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7011e-04 - val_loss: 5.4093e-04\n",
      "Epoch 2364/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.7008e-04 - val_loss: 5.4421e-04\n",
      "Epoch 2365/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.7017e-04 - val_loss: 5.4176e-04\n",
      "Epoch 2366/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.7019e-04 - val_loss: 5.4366e-04\n",
      "Epoch 2367/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7010e-04 - val_loss: 5.4239e-04\n",
      "Epoch 2368/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7013e-04 - val_loss: 5.4269e-04\n",
      "Epoch 2369/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7014e-04 - val_loss: 5.4228e-04\n",
      "Epoch 2370/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7008e-04 - val_loss: 5.4346e-04\n",
      "Epoch 2371/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7009e-04 - val_loss: 5.4233e-04\n",
      "Epoch 2372/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7003e-04 - val_loss: 5.4316e-04\n",
      "Epoch 2373/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7012e-04 - val_loss: 5.4364e-04\n",
      "Epoch 2374/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.7003e-04 - val_loss: 5.4393e-04\n",
      "Epoch 2375/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7004e-04 - val_loss: 5.4384e-04\n",
      "Epoch 2376/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.7000e-04 - val_loss: 5.4261e-04\n",
      "Epoch 2377/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.7005e-04 - val_loss: 5.4222e-04\n",
      "Epoch 2378/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7003e-04 - val_loss: 5.4117e-04\n",
      "Epoch 2379/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.7006e-04 - val_loss: 5.4379e-04\n",
      "Epoch 2380/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6999e-04 - val_loss: 5.4370e-04\n",
      "Epoch 2381/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6992e-04 - val_loss: 5.4238e-04\n",
      "Epoch 2382/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6989e-04 - val_loss: 5.4340e-04\n",
      "Epoch 2383/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6993e-04 - val_loss: 5.4181e-04\n",
      "Epoch 2384/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6994e-04 - val_loss: 5.4198e-04\n",
      "Epoch 2385/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.7003e-04 - val_loss: 5.4215e-04\n",
      "Epoch 2386/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6984e-04 - val_loss: 5.4227e-04\n",
      "Epoch 2387/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6990e-04 - val_loss: 5.4283e-04\n",
      "Epoch 2388/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6992e-04 - val_loss: 5.4336e-04\n",
      "Epoch 2389/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6988e-04 - val_loss: 5.4261e-04\n",
      "Epoch 2390/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6992e-04 - val_loss: 5.4369e-04\n",
      "Epoch 2391/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6987e-04 - val_loss: 5.4161e-04\n",
      "Epoch 2392/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6989e-04 - val_loss: 5.4308e-04\n",
      "Epoch 2393/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6989e-04 - val_loss: 5.4331e-04\n",
      "Epoch 2394/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6980e-04 - val_loss: 5.4171e-04\n",
      "Epoch 2395/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6985e-04 - val_loss: 5.4310e-04\n",
      "Epoch 2396/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6984e-04 - val_loss: 5.4294e-04\n",
      "Epoch 2397/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6984e-04 - val_loss: 5.4161e-04\n",
      "Epoch 2398/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6981e-04 - val_loss: 5.4375e-04\n",
      "Epoch 2399/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6982e-04 - val_loss: 5.4152e-04\n",
      "Epoch 2400/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6977e-04 - val_loss: 5.4474e-04\n",
      "Epoch 2401/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6983e-04 - val_loss: 5.4270e-04\n",
      "Epoch 2402/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6988e-04 - val_loss: 5.4213e-04\n",
      "Epoch 2403/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6981e-04 - val_loss: 5.4327e-04\n",
      "Epoch 2404/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6979e-04 - val_loss: 5.4282e-04\n",
      "Epoch 2405/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6978e-04 - val_loss: 5.4169e-04\n",
      "Epoch 2406/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6975e-04 - val_loss: 5.4188e-04\n",
      "Epoch 2407/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6973e-04 - val_loss: 5.4304e-04\n",
      "Epoch 2408/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6977e-04 - val_loss: 5.4309e-04\n",
      "Epoch 2409/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6976e-04 - val_loss: 5.4410e-04\n",
      "Epoch 2410/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6967e-04 - val_loss: 5.4320e-04\n",
      "Epoch 2411/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6977e-04 - val_loss: 5.4263e-04\n",
      "Epoch 2412/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6973e-04 - val_loss: 5.4308e-04\n",
      "Epoch 2413/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6968e-04 - val_loss: 5.4178e-04\n",
      "Epoch 2414/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6970e-04 - val_loss: 5.4384e-04\n",
      "Epoch 2415/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6972e-04 - val_loss: 5.4236e-04\n",
      "Epoch 2416/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6971e-04 - val_loss: 5.4361e-04\n",
      "Epoch 2417/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6966e-04 - val_loss: 5.4352e-04\n",
      "Epoch 2418/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6972e-04 - val_loss: 5.4213e-04\n",
      "Epoch 2419/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6957e-04 - val_loss: 5.4398e-04\n",
      "Epoch 2420/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6970e-04 - val_loss: 5.4398e-04\n",
      "Epoch 2421/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6955e-04 - val_loss: 5.4294e-04\n",
      "Epoch 2422/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6968e-04 - val_loss: 5.4268e-04\n",
      "Epoch 2423/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6963e-04 - val_loss: 5.4244e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2424/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6960e-04 - val_loss: 5.4336e-04\n",
      "Epoch 2425/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6963e-04 - val_loss: 5.4218e-04\n",
      "Epoch 2426/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6957e-04 - val_loss: 5.4327e-04\n",
      "Epoch 2427/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6959e-04 - val_loss: 5.4234e-04\n",
      "Epoch 2428/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6959e-04 - val_loss: 5.4219e-04\n",
      "Epoch 2429/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6954e-04 - val_loss: 5.4355e-04\n",
      "Epoch 2430/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6953e-04 - val_loss: 5.4450e-04\n",
      "Epoch 2431/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6954e-04 - val_loss: 5.4257e-04\n",
      "Epoch 2432/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6953e-04 - val_loss: 5.4327e-04\n",
      "Epoch 2433/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6956e-04 - val_loss: 5.4210e-04\n",
      "Epoch 2434/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6953e-04 - val_loss: 5.4356e-04\n",
      "Epoch 2435/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6952e-04 - val_loss: 5.4191e-04\n",
      "Epoch 2436/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6944e-04 - val_loss: 5.4313e-04\n",
      "Epoch 2437/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6949e-04 - val_loss: 5.4183e-04\n",
      "Epoch 2438/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6950e-04 - val_loss: 5.4339e-04\n",
      "Epoch 2439/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6949e-04 - val_loss: 5.4407e-04\n",
      "Epoch 2440/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6949e-04 - val_loss: 5.4385e-04\n",
      "Epoch 2441/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.6945e-04 - val_loss: 5.4168e-04\n",
      "Epoch 2442/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6950e-04 - val_loss: 5.4254e-04\n",
      "Epoch 2443/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6945e-04 - val_loss: 5.4339e-04\n",
      "Epoch 2444/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6945e-04 - val_loss: 5.4242e-04\n",
      "Epoch 2445/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6943e-04 - val_loss: 5.4317e-04\n",
      "Epoch 2446/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6945e-04 - val_loss: 5.4390e-04\n",
      "Epoch 2447/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6942e-04 - val_loss: 5.4135e-04\n",
      "Epoch 2448/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6941e-04 - val_loss: 5.4285e-04\n",
      "Epoch 2449/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6943e-04 - val_loss: 5.4396e-04\n",
      "Epoch 2450/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6945e-04 - val_loss: 5.4192e-04\n",
      "Epoch 2451/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6937e-04 - val_loss: 5.4370e-04\n",
      "Epoch 2452/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6940e-04 - val_loss: 5.4295e-04\n",
      "Epoch 2453/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6933e-04 - val_loss: 5.4284e-04\n",
      "Epoch 2454/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6939e-04 - val_loss: 5.4236e-04\n",
      "Epoch 2455/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6935e-04 - val_loss: 5.4236e-04\n",
      "Epoch 2456/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6935e-04 - val_loss: 5.4127e-04\n",
      "Epoch 2457/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6938e-04 - val_loss: 5.4331e-04\n",
      "Epoch 2458/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6927e-04 - val_loss: 5.4140e-04\n",
      "Epoch 2459/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6936e-04 - val_loss: 5.4262e-04\n",
      "Epoch 2460/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6929e-04 - val_loss: 5.4178e-04\n",
      "Epoch 2461/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6930e-04 - val_loss: 5.4425e-04\n",
      "Epoch 2462/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6940e-04 - val_loss: 5.4293e-04\n",
      "Epoch 2463/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6933e-04 - val_loss: 5.4326e-04\n",
      "Epoch 2464/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6930e-04 - val_loss: 5.4172e-04\n",
      "Epoch 2465/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6932e-04 - val_loss: 5.4270e-04\n",
      "Epoch 2466/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6928e-04 - val_loss: 5.4194e-04\n",
      "Epoch 2467/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6931e-04 - val_loss: 5.4149e-04\n",
      "Epoch 2468/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6926e-04 - val_loss: 5.4268e-04\n",
      "Epoch 2469/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6921e-04 - val_loss: 5.4267e-04\n",
      "Epoch 2470/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6928e-04 - val_loss: 5.4320e-04\n",
      "Epoch 2471/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6921e-04 - val_loss: 5.4330e-04\n",
      "Epoch 2472/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6926e-04 - val_loss: 5.4210e-04\n",
      "Epoch 2473/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6925e-04 - val_loss: 5.4264e-04\n",
      "Epoch 2474/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6919e-04 - val_loss: 5.4322e-04\n",
      "Epoch 2475/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6926e-04 - val_loss: 5.4374e-04\n",
      "Epoch 2476/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6923e-04 - val_loss: 5.4342e-04\n",
      "Epoch 2477/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6926e-04 - val_loss: 5.4277e-04\n",
      "Epoch 2478/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6916e-04 - val_loss: 5.4179e-04\n",
      "Epoch 2479/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6922e-04 - val_loss: 5.4303e-04\n",
      "Epoch 2480/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 5.6922e-04 - val_loss: 5.4305e-04\n",
      "Epoch 2481/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6924e-04 - val_loss: 5.4199e-04\n",
      "Epoch 2482/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6917e-04 - val_loss: 5.4309e-04\n",
      "Epoch 2483/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6914e-04 - val_loss: 5.4319e-04\n",
      "Epoch 2484/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6913e-04 - val_loss: 5.4257e-04\n",
      "Epoch 2485/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6917e-04 - val_loss: 5.4304e-04\n",
      "Epoch 2486/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6914e-04 - val_loss: 5.4248e-04\n",
      "Epoch 2487/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6919e-04 - val_loss: 5.4305e-04\n",
      "Epoch 2488/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6908e-04 - val_loss: 5.4356e-04\n",
      "Epoch 2489/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6908e-04 - val_loss: 5.4334e-04\n",
      "Epoch 2490/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6912e-04 - val_loss: 5.4283e-04\n",
      "Epoch 2491/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6908e-04 - val_loss: 5.4284e-04\n",
      "Epoch 2492/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6913e-04 - val_loss: 5.4252e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2493/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6916e-04 - val_loss: 5.4266e-04\n",
      "Epoch 2494/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6908e-04 - val_loss: 5.4272e-04\n",
      "Epoch 2495/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6906e-04 - val_loss: 5.4122e-04\n",
      "Epoch 2496/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6906e-04 - val_loss: 5.4347e-04\n",
      "Epoch 2497/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6905e-04 - val_loss: 5.4235e-04\n",
      "Epoch 2498/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6910e-04 - val_loss: 5.4306e-04\n",
      "Epoch 2499/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6903e-04 - val_loss: 5.4357e-04\n",
      "Epoch 2500/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6904e-04 - val_loss: 5.4174e-04\n",
      "Epoch 2501/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6907e-04 - val_loss: 5.4298e-04\n",
      "Epoch 2502/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6898e-04 - val_loss: 5.4140e-04\n",
      "Epoch 2503/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6902e-04 - val_loss: 5.4432e-04\n",
      "Epoch 2504/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6904e-04 - val_loss: 5.4143e-04\n",
      "Epoch 2505/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6898e-04 - val_loss: 5.4322e-04\n",
      "Epoch 2506/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6902e-04 - val_loss: 5.4255e-04\n",
      "Epoch 2507/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6897e-04 - val_loss: 5.4297e-04\n",
      "Epoch 2508/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6893e-04 - val_loss: 5.4404e-04\n",
      "Epoch 2509/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6897e-04 - val_loss: 5.4163e-04\n",
      "Epoch 2510/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6900e-04 - val_loss: 5.4271e-04\n",
      "Epoch 2511/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6901e-04 - val_loss: 5.4390e-04\n",
      "Epoch 2512/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6899e-04 - val_loss: 5.4135e-04\n",
      "Epoch 2513/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6895e-04 - val_loss: 5.4304e-04\n",
      "Epoch 2514/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6893e-04 - val_loss: 5.4325e-04\n",
      "Epoch 2515/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6888e-04 - val_loss: 5.4345e-04\n",
      "Epoch 2516/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6892e-04 - val_loss: 5.4241e-04\n",
      "Epoch 2517/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6888e-04 - val_loss: 5.4314e-04\n",
      "Epoch 2518/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6898e-04 - val_loss: 5.4247e-04\n",
      "Epoch 2519/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6896e-04 - val_loss: 5.4276e-04\n",
      "Epoch 2520/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6887e-04 - val_loss: 5.4289e-04\n",
      "Epoch 2521/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6889e-04 - val_loss: 5.4139e-04\n",
      "Epoch 2522/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6889e-04 - val_loss: 5.4277e-04\n",
      "Epoch 2523/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6887e-04 - val_loss: 5.4298e-04\n",
      "Epoch 2524/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6887e-04 - val_loss: 5.4224e-04\n",
      "Epoch 2525/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6883e-04 - val_loss: 5.4304e-04\n",
      "Epoch 2526/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6880e-04 - val_loss: 5.4309e-04\n",
      "Epoch 2527/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6883e-04 - val_loss: 5.4223e-04\n",
      "Epoch 2528/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6877e-04 - val_loss: 5.4310e-04\n",
      "Epoch 2529/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6883e-04 - val_loss: 5.4308e-04\n",
      "Epoch 2530/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6880e-04 - val_loss: 5.4380e-04\n",
      "Epoch 2531/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6881e-04 - val_loss: 5.4216e-04\n",
      "Epoch 2532/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6881e-04 - val_loss: 5.4331e-04\n",
      "Epoch 2533/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6876e-04 - val_loss: 5.4394e-04\n",
      "Epoch 2534/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6879e-04 - val_loss: 5.4198e-04\n",
      "Epoch 2535/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6878e-04 - val_loss: 5.4311e-04\n",
      "Epoch 2536/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6878e-04 - val_loss: 5.4242e-04\n",
      "Epoch 2537/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6875e-04 - val_loss: 5.4258e-04\n",
      "Epoch 2538/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6880e-04 - val_loss: 5.4232e-04\n",
      "Epoch 2539/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6875e-04 - val_loss: 5.4228e-04\n",
      "Epoch 2540/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6869e-04 - val_loss: 5.4221e-04\n",
      "Epoch 2541/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6874e-04 - val_loss: 5.4291e-04\n",
      "Epoch 2542/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6868e-04 - val_loss: 5.4435e-04\n",
      "Epoch 2543/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6869e-04 - val_loss: 5.4251e-04\n",
      "Epoch 2544/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6871e-04 - val_loss: 5.4322e-04\n",
      "Epoch 2545/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6865e-04 - val_loss: 5.4301e-04\n",
      "Epoch 2546/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6868e-04 - val_loss: 5.4315e-04\n",
      "Epoch 2547/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6875e-04 - val_loss: 5.4229e-04\n",
      "Epoch 2548/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6878e-04 - val_loss: 5.4401e-04\n",
      "Epoch 2549/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6867e-04 - val_loss: 5.4318e-04\n",
      "Epoch 2550/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6876e-04 - val_loss: 5.4317e-04\n",
      "Epoch 2551/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6865e-04 - val_loss: 5.4309e-04\n",
      "Epoch 2552/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6864e-04 - val_loss: 5.4431e-04\n",
      "Epoch 2553/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6861e-04 - val_loss: 5.4449e-04\n",
      "Epoch 2554/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6868e-04 - val_loss: 5.4299e-04\n",
      "Epoch 2555/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6866e-04 - val_loss: 5.4376e-04\n",
      "Epoch 2556/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6861e-04 - val_loss: 5.4258e-04\n",
      "Epoch 2557/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6858e-04 - val_loss: 5.4261e-04\n",
      "Epoch 2558/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6860e-04 - val_loss: 5.4293e-04\n",
      "Epoch 2559/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6862e-04 - val_loss: 5.4297e-04\n",
      "Epoch 2560/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6864e-04 - val_loss: 5.4178e-04\n",
      "Epoch 2561/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6875e-04 - val_loss: 5.4307e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2562/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6860e-04 - val_loss: 5.4350e-04\n",
      "Epoch 2563/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6857e-04 - val_loss: 5.4286e-04\n",
      "Epoch 2564/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6864e-04 - val_loss: 5.4491e-04\n",
      "Epoch 2565/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6865e-04 - val_loss: 5.4326e-04\n",
      "Epoch 2566/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6855e-04 - val_loss: 5.4311e-04\n",
      "Epoch 2567/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6855e-04 - val_loss: 5.4372e-04\n",
      "Epoch 2568/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6854e-04 - val_loss: 5.4274e-04\n",
      "Epoch 2569/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6846e-04 - val_loss: 5.4328e-04\n",
      "Epoch 2570/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6863e-04 - val_loss: 5.4403e-04\n",
      "Epoch 2571/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6848e-04 - val_loss: 5.4270e-04\n",
      "Epoch 2572/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6848e-04 - val_loss: 5.4225e-04\n",
      "Epoch 2573/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6853e-04 - val_loss: 5.4399e-04\n",
      "Epoch 2574/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6851e-04 - val_loss: 5.4239e-04\n",
      "Epoch 2575/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.6850e-04 - val_loss: 5.4316e-04\n",
      "Epoch 2576/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6853e-04 - val_loss: 5.4342e-04\n",
      "Epoch 2577/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6853e-04 - val_loss: 5.4346e-04\n",
      "Epoch 2578/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6856e-04 - val_loss: 5.4279e-04\n",
      "Epoch 2579/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6849e-04 - val_loss: 5.4242e-04\n",
      "Epoch 2580/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6851e-04 - val_loss: 5.4193e-04\n",
      "Epoch 2581/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6853e-04 - val_loss: 5.4213e-04\n",
      "Epoch 2582/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6853e-04 - val_loss: 5.4228e-04\n",
      "Epoch 2583/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6838e-04 - val_loss: 5.4339e-04\n",
      "Epoch 2584/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6846e-04 - val_loss: 5.4360e-04\n",
      "Epoch 2585/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6835e-04 - val_loss: 5.4263e-04\n",
      "Epoch 2586/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6843e-04 - val_loss: 5.4253e-04\n",
      "Epoch 2587/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6846e-04 - val_loss: 5.4386e-04\n",
      "Epoch 2588/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6850e-04 - val_loss: 5.4327e-04\n",
      "Epoch 2589/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6840e-04 - val_loss: 5.4220e-04\n",
      "Epoch 2590/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6839e-04 - val_loss: 5.4437e-04\n",
      "Epoch 2591/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6837e-04 - val_loss: 5.4310e-04\n",
      "Epoch 2592/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6838e-04 - val_loss: 5.4343e-04\n",
      "Epoch 2593/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6836e-04 - val_loss: 5.4344e-04\n",
      "Epoch 2594/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6834e-04 - val_loss: 5.4386e-04\n",
      "Epoch 2595/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6839e-04 - val_loss: 5.4263e-04\n",
      "Epoch 2596/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6845e-04 - val_loss: 5.4362e-04\n",
      "Epoch 2597/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6841e-04 - val_loss: 5.4264e-04\n",
      "Epoch 2598/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6834e-04 - val_loss: 5.4309e-04\n",
      "Epoch 2599/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6829e-04 - val_loss: 5.4325e-04\n",
      "Epoch 2600/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6835e-04 - val_loss: 5.4204e-04\n",
      "Epoch 2601/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6830e-04 - val_loss: 5.4449e-04\n",
      "Epoch 2602/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6833e-04 - val_loss: 5.4397e-04\n",
      "Epoch 2603/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6829e-04 - val_loss: 5.4463e-04\n",
      "Epoch 2604/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6835e-04 - val_loss: 5.4140e-04\n",
      "Epoch 2605/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6828e-04 - val_loss: 5.4265e-04\n",
      "Epoch 2606/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6831e-04 - val_loss: 5.4255e-04\n",
      "Epoch 2607/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6823e-04 - val_loss: 5.4200e-04\n",
      "Epoch 2608/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6836e-04 - val_loss: 5.4291e-04\n",
      "Epoch 2609/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6825e-04 - val_loss: 5.4277e-04\n",
      "Epoch 2610/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6819e-04 - val_loss: 5.4336e-04\n",
      "Epoch 2611/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6834e-04 - val_loss: 5.4329e-04\n",
      "Epoch 2612/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6822e-04 - val_loss: 5.4316e-04\n",
      "Epoch 2613/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6821e-04 - val_loss: 5.4227e-04\n",
      "Epoch 2614/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6828e-04 - val_loss: 5.4187e-04\n",
      "Epoch 2615/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6819e-04 - val_loss: 5.4204e-04\n",
      "Epoch 2616/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6820e-04 - val_loss: 5.4331e-04\n",
      "Epoch 2617/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6813e-04 - val_loss: 5.4338e-04\n",
      "Epoch 2618/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6831e-04 - val_loss: 5.4288e-04\n",
      "Epoch 2619/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6827e-04 - val_loss: 5.4287e-04\n",
      "Epoch 2620/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6821e-04 - val_loss: 5.4378e-04\n",
      "Epoch 2621/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6818e-04 - val_loss: 5.4253e-04\n",
      "Epoch 2622/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6817e-04 - val_loss: 5.4302e-04\n",
      "Epoch 2623/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6817e-04 - val_loss: 5.4276e-04\n",
      "Epoch 2624/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6817e-04 - val_loss: 5.4306e-04\n",
      "Epoch 2625/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6824e-04 - val_loss: 5.4295e-04\n",
      "Epoch 2626/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6819e-04 - val_loss: 5.4368e-04\n",
      "Epoch 2627/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6813e-04 - val_loss: 5.4277e-04\n",
      "Epoch 2628/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6811e-04 - val_loss: 5.4300e-04\n",
      "Epoch 2629/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6813e-04 - val_loss: 5.4331e-04\n",
      "Epoch 2630/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6810e-04 - val_loss: 5.4339e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2631/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6816e-04 - val_loss: 5.4428e-04\n",
      "Epoch 2632/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 5.6810e-04 - val_loss: 5.4356e-04\n",
      "Epoch 2633/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6808e-04 - val_loss: 5.4312e-04\n",
      "Epoch 2634/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6814e-04 - val_loss: 5.4288e-04\n",
      "Epoch 2635/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6805e-04 - val_loss: 5.4297e-04\n",
      "Epoch 2636/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6805e-04 - val_loss: 5.4421e-04\n",
      "Epoch 2637/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6808e-04 - val_loss: 5.4267e-04\n",
      "Epoch 2638/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6809e-04 - val_loss: 5.4225e-04\n",
      "Epoch 2639/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6813e-04 - val_loss: 5.4389e-04\n",
      "Epoch 2640/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6814e-04 - val_loss: 5.4345e-04\n",
      "Epoch 2641/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6800e-04 - val_loss: 5.4437e-04\n",
      "Epoch 2642/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6806e-04 - val_loss: 5.4270e-04\n",
      "Epoch 2643/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6806e-04 - val_loss: 5.4292e-04\n",
      "Epoch 2644/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6804e-04 - val_loss: 5.4338e-04\n",
      "Epoch 2645/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6798e-04 - val_loss: 5.4228e-04\n",
      "Epoch 2646/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6802e-04 - val_loss: 5.4332e-04\n",
      "Epoch 2647/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6808e-04 - val_loss: 5.4297e-04\n",
      "Epoch 2648/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6803e-04 - val_loss: 5.4325e-04\n",
      "Epoch 2649/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6802e-04 - val_loss: 5.4303e-04\n",
      "Epoch 2650/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6810e-04 - val_loss: 5.4342e-04\n",
      "Epoch 2651/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6800e-04 - val_loss: 5.4272e-04\n",
      "Epoch 2652/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6803e-04 - val_loss: 5.4314e-04\n",
      "Epoch 2653/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6795e-04 - val_loss: 5.4457e-04\n",
      "Epoch 2654/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6804e-04 - val_loss: 5.4164e-04\n",
      "Epoch 2655/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6803e-04 - val_loss: 5.4176e-04\n",
      "Epoch 2656/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6796e-04 - val_loss: 5.4321e-04\n",
      "Epoch 2657/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6800e-04 - val_loss: 5.4348e-04\n",
      "Epoch 2658/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6795e-04 - val_loss: 5.4294e-04\n",
      "Epoch 2659/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6794e-04 - val_loss: 5.4338e-04\n",
      "Epoch 2660/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6787e-04 - val_loss: 5.4242e-04\n",
      "Epoch 2661/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6798e-04 - val_loss: 5.4222e-04\n",
      "Epoch 2662/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6799e-04 - val_loss: 5.4344e-04\n",
      "Epoch 2663/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6796e-04 - val_loss: 5.4130e-04\n",
      "Epoch 2664/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6792e-04 - val_loss: 5.4319e-04\n",
      "Epoch 2665/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6799e-04 - val_loss: 5.4334e-04\n",
      "Epoch 2666/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6787e-04 - val_loss: 5.4386e-04\n",
      "Epoch 2667/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6787e-04 - val_loss: 5.4243e-04\n",
      "Epoch 2668/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6788e-04 - val_loss: 5.4306e-04\n",
      "Epoch 2669/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6796e-04 - val_loss: 5.4223e-04\n",
      "Epoch 2670/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6789e-04 - val_loss: 5.4330e-04\n",
      "Epoch 2671/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6791e-04 - val_loss: 5.4395e-04\n",
      "Epoch 2672/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6785e-04 - val_loss: 5.4185e-04\n",
      "Epoch 2673/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6790e-04 - val_loss: 5.4438e-04\n",
      "Epoch 2674/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6786e-04 - val_loss: 5.4330e-04\n",
      "Epoch 2675/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6777e-04 - val_loss: 5.4203e-04\n",
      "Epoch 2676/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6787e-04 - val_loss: 5.4297e-04\n",
      "Epoch 2677/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6790e-04 - val_loss: 5.4348e-04\n",
      "Epoch 2678/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6781e-04 - val_loss: 5.4273e-04\n",
      "Epoch 2679/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6781e-04 - val_loss: 5.4325e-04\n",
      "Epoch 2680/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6787e-04 - val_loss: 5.4315e-04\n",
      "Epoch 2681/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6780e-04 - val_loss: 5.4424e-04\n",
      "Epoch 2682/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6782e-04 - val_loss: 5.4240e-04\n",
      "Epoch 2683/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6767e-04 - val_loss: 5.4264e-04\n",
      "Epoch 2684/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6776e-04 - val_loss: 5.4215e-04\n",
      "Epoch 2685/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6774e-04 - val_loss: 5.4350e-04\n",
      "Epoch 2686/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6779e-04 - val_loss: 5.4306e-04\n",
      "Epoch 2687/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6786e-04 - val_loss: 5.4273e-04\n",
      "Epoch 2688/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6776e-04 - val_loss: 5.4360e-04\n",
      "Epoch 2689/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6779e-04 - val_loss: 5.4362e-04\n",
      "Epoch 2690/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6779e-04 - val_loss: 5.4262e-04\n",
      "Epoch 2691/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6774e-04 - val_loss: 5.4270e-04\n",
      "Epoch 2692/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6765e-04 - val_loss: 5.4296e-04\n",
      "Epoch 2693/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6773e-04 - val_loss: 5.4189e-04\n",
      "Epoch 2694/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6772e-04 - val_loss: 5.4295e-04\n",
      "Epoch 2695/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6773e-04 - val_loss: 5.4294e-04\n",
      "Epoch 2696/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6778e-04 - val_loss: 5.4427e-04\n",
      "Epoch 2697/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6774e-04 - val_loss: 5.4464e-04\n",
      "Epoch 2698/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6772e-04 - val_loss: 5.4271e-04\n",
      "Epoch 2699/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6772e-04 - val_loss: 5.4253e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2700/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6769e-04 - val_loss: 5.4309e-04\n",
      "Epoch 2701/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6775e-04 - val_loss: 5.4307e-04\n",
      "Epoch 2702/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6766e-04 - val_loss: 5.4453e-04\n",
      "Epoch 2703/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6765e-04 - val_loss: 5.4206e-04\n",
      "Epoch 2704/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6762e-04 - val_loss: 5.4268e-04\n",
      "Epoch 2705/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6762e-04 - val_loss: 5.4228e-04\n",
      "Epoch 2706/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6771e-04 - val_loss: 5.4270e-04\n",
      "Epoch 2707/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6775e-04 - val_loss: 5.4187e-04\n",
      "Epoch 2708/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6763e-04 - val_loss: 5.4413e-04\n",
      "Epoch 2709/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6761e-04 - val_loss: 5.4208e-04\n",
      "Epoch 2710/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6768e-04 - val_loss: 5.4258e-04\n",
      "Epoch 2711/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6767e-04 - val_loss: 5.4283e-04\n",
      "Epoch 2712/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6766e-04 - val_loss: 5.4230e-04\n",
      "Epoch 2713/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6768e-04 - val_loss: 5.4432e-04\n",
      "Epoch 2714/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6767e-04 - val_loss: 5.4265e-04\n",
      "Epoch 2715/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6760e-04 - val_loss: 5.4233e-04\n",
      "Epoch 2716/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6761e-04 - val_loss: 5.4404e-04\n",
      "Epoch 2717/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6756e-04 - val_loss: 5.4236e-04\n",
      "Epoch 2718/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6750e-04 - val_loss: 5.4287e-04\n",
      "Epoch 2719/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6763e-04 - val_loss: 5.4293e-04\n",
      "Epoch 2720/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6754e-04 - val_loss: 5.4321e-04\n",
      "Epoch 2721/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6754e-04 - val_loss: 5.4273e-04\n",
      "Epoch 2722/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6757e-04 - val_loss: 5.4253e-04\n",
      "Epoch 2723/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6752e-04 - val_loss: 5.4280e-04\n",
      "Epoch 2724/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6760e-04 - val_loss: 5.4334e-04\n",
      "Epoch 2725/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6752e-04 - val_loss: 5.4351e-04\n",
      "Epoch 2726/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6756e-04 - val_loss: 5.4400e-04\n",
      "Epoch 2727/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6757e-04 - val_loss: 5.4285e-04\n",
      "Epoch 2728/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6754e-04 - val_loss: 5.4429e-04\n",
      "Epoch 2729/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6755e-04 - val_loss: 5.4328e-04\n",
      "Epoch 2730/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6744e-04 - val_loss: 5.4184e-04\n",
      "Epoch 2731/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6750e-04 - val_loss: 5.4214e-04\n",
      "Epoch 2732/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6749e-04 - val_loss: 5.4242e-04\n",
      "Epoch 2733/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6752e-04 - val_loss: 5.4370e-04\n",
      "Epoch 2734/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6749e-04 - val_loss: 5.4287e-04\n",
      "Epoch 2735/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6745e-04 - val_loss: 5.4376e-04\n",
      "Epoch 2736/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6742e-04 - val_loss: 5.4524e-04\n",
      "Epoch 2737/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6750e-04 - val_loss: 5.4247e-04\n",
      "Epoch 2738/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6741e-04 - val_loss: 5.4280e-04\n",
      "Epoch 2739/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6747e-04 - val_loss: 5.4365e-04\n",
      "Epoch 2740/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6744e-04 - val_loss: 5.4248e-04\n",
      "Epoch 2741/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6746e-04 - val_loss: 5.4258e-04\n",
      "Epoch 2742/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6741e-04 - val_loss: 5.4251e-04\n",
      "Epoch 2743/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6746e-04 - val_loss: 5.4327e-04\n",
      "Epoch 2744/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6740e-04 - val_loss: 5.4335e-04\n",
      "Epoch 2745/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6740e-04 - val_loss: 5.4274e-04\n",
      "Epoch 2746/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6739e-04 - val_loss: 5.4294e-04\n",
      "Epoch 2747/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6739e-04 - val_loss: 5.4388e-04\n",
      "Epoch 2748/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6740e-04 - val_loss: 5.4324e-04\n",
      "Epoch 2749/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6746e-04 - val_loss: 5.4396e-04\n",
      "Epoch 2750/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6738e-04 - val_loss: 5.4216e-04\n",
      "Epoch 2751/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6734e-04 - val_loss: 5.4313e-04\n",
      "Epoch 2752/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6739e-04 - val_loss: 5.4263e-04\n",
      "Epoch 2753/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6736e-04 - val_loss: 5.4406e-04\n",
      "Epoch 2754/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6732e-04 - val_loss: 5.4306e-04\n",
      "Epoch 2755/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6737e-04 - val_loss: 5.4409e-04\n",
      "Epoch 2756/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6736e-04 - val_loss: 5.4234e-04\n",
      "Epoch 2757/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6737e-04 - val_loss: 5.4385e-04\n",
      "Epoch 2758/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6739e-04 - val_loss: 5.4371e-04\n",
      "Epoch 2759/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6730e-04 - val_loss: 5.4341e-04\n",
      "Epoch 2760/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6744e-04 - val_loss: 5.4300e-04\n",
      "Epoch 2761/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6736e-04 - val_loss: 5.4287e-04\n",
      "Epoch 2762/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6733e-04 - val_loss: 5.4219e-04\n",
      "Epoch 2763/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6724e-04 - val_loss: 5.4331e-04\n",
      "Epoch 2764/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6732e-04 - val_loss: 5.4159e-04\n",
      "Epoch 2765/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6727e-04 - val_loss: 5.4311e-04\n",
      "Epoch 2766/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6722e-04 - val_loss: 5.4392e-04\n",
      "Epoch 2767/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6728e-04 - val_loss: 5.4266e-04\n",
      "Epoch 2768/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6727e-04 - val_loss: 5.4222e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2769/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6738e-04 - val_loss: 5.4270e-04\n",
      "Epoch 2770/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6723e-04 - val_loss: 5.4247e-04\n",
      "Epoch 2771/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6720e-04 - val_loss: 5.4291e-04\n",
      "Epoch 2772/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6724e-04 - val_loss: 5.4308e-04\n",
      "Epoch 2773/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6718e-04 - val_loss: 5.4344e-04\n",
      "Epoch 2774/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6720e-04 - val_loss: 5.4308e-04\n",
      "Epoch 2775/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6726e-04 - val_loss: 5.4307e-04\n",
      "Epoch 2776/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6717e-04 - val_loss: 5.4275e-04\n",
      "Epoch 2777/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6731e-04 - val_loss: 5.4277e-04\n",
      "Epoch 2778/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6721e-04 - val_loss: 5.4248e-04\n",
      "Epoch 2779/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6718e-04 - val_loss: 5.4410e-04\n",
      "Epoch 2780/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6725e-04 - val_loss: 5.4322e-04\n",
      "Epoch 2781/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6724e-04 - val_loss: 5.4146e-04\n",
      "Epoch 2782/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6712e-04 - val_loss: 5.4307e-04\n",
      "Epoch 2783/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6728e-04 - val_loss: 5.4359e-04\n",
      "Epoch 2784/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6718e-04 - val_loss: 5.4143e-04\n",
      "Epoch 2785/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.6728e-04 - val_loss: 5.4322e-04\n",
      "Epoch 2786/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6710e-04 - val_loss: 5.4261e-04\n",
      "Epoch 2787/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6714e-04 - val_loss: 5.4171e-04\n",
      "Epoch 2788/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6720e-04 - val_loss: 5.4232e-04\n",
      "Epoch 2789/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6721e-04 - val_loss: 5.4324e-04\n",
      "Epoch 2790/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6711e-04 - val_loss: 5.4438e-04\n",
      "Epoch 2791/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6718e-04 - val_loss: 5.4291e-04\n",
      "Epoch 2792/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6725e-04 - val_loss: 5.4309e-04\n",
      "Epoch 2793/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.6708e-04 - val_loss: 5.4305e-04\n",
      "Epoch 2794/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6712e-04 - val_loss: 5.4357e-04\n",
      "Epoch 2795/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6710e-04 - val_loss: 5.4290e-04\n",
      "Epoch 2796/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6710e-04 - val_loss: 5.4393e-04\n",
      "Epoch 2797/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6711e-04 - val_loss: 5.4346e-04\n",
      "Epoch 2798/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6708e-04 - val_loss: 5.4414e-04\n",
      "Epoch 2799/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6705e-04 - val_loss: 5.4276e-04\n",
      "Epoch 2800/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6710e-04 - val_loss: 5.4170e-04\n",
      "Epoch 2801/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6711e-04 - val_loss: 5.4160e-04\n",
      "Epoch 2802/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6706e-04 - val_loss: 5.4342e-04\n",
      "Epoch 2803/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6720e-04 - val_loss: 5.4287e-04\n",
      "Epoch 2804/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6704e-04 - val_loss: 5.4426e-04\n",
      "Epoch 2805/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6709e-04 - val_loss: 5.4308e-04\n",
      "Epoch 2806/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6710e-04 - val_loss: 5.4326e-04\n",
      "Epoch 2807/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6702e-04 - val_loss: 5.4373e-04\n",
      "Epoch 2808/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6709e-04 - val_loss: 5.4251e-04\n",
      "Epoch 2809/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6708e-04 - val_loss: 5.4213e-04\n",
      "Epoch 2810/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6709e-04 - val_loss: 5.4434e-04\n",
      "Epoch 2811/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6696e-04 - val_loss: 5.4521e-04\n",
      "Epoch 2812/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6697e-04 - val_loss: 5.4241e-04\n",
      "Epoch 2813/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6703e-04 - val_loss: 5.4605e-04\n",
      "Epoch 2814/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6698e-04 - val_loss: 5.4178e-04\n",
      "Epoch 2815/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6701e-04 - val_loss: 5.4512e-04\n",
      "Epoch 2816/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6704e-04 - val_loss: 5.4415e-04\n",
      "Epoch 2817/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6697e-04 - val_loss: 5.4248e-04\n",
      "Epoch 2818/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6687e-04 - val_loss: 5.4349e-04\n",
      "Epoch 2819/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6702e-04 - val_loss: 5.4204e-04\n",
      "Epoch 2820/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6695e-04 - val_loss: 5.4146e-04\n",
      "Epoch 2821/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6696e-04 - val_loss: 5.4273e-04\n",
      "Epoch 2822/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6700e-04 - val_loss: 5.4088e-04\n",
      "Epoch 2823/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6701e-04 - val_loss: 5.4331e-04\n",
      "Epoch 2824/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6693e-04 - val_loss: 5.4471e-04\n",
      "Epoch 2825/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6700e-04 - val_loss: 5.4281e-04\n",
      "Epoch 2826/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6701e-04 - val_loss: 5.4282e-04\n",
      "Epoch 2827/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6690e-04 - val_loss: 5.4470e-04\n",
      "Epoch 2828/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6694e-04 - val_loss: 5.4335e-04\n",
      "Epoch 2829/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6695e-04 - val_loss: 5.4161e-04\n",
      "Epoch 2830/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6685e-04 - val_loss: 5.4234e-04\n",
      "Epoch 2831/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6692e-04 - val_loss: 5.4235e-04\n",
      "Epoch 2832/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6692e-04 - val_loss: 5.4211e-04\n",
      "Epoch 2833/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6692e-04 - val_loss: 5.4148e-04\n",
      "Epoch 2834/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6695e-04 - val_loss: 5.4271e-04\n",
      "Epoch 2835/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6687e-04 - val_loss: 5.4208e-04\n",
      "Epoch 2836/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6687e-04 - val_loss: 5.4515e-04\n",
      "Epoch 2837/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6689e-04 - val_loss: 5.4270e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2838/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6681e-04 - val_loss: 5.4244e-04\n",
      "Epoch 2839/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6691e-04 - val_loss: 5.4307e-04\n",
      "Epoch 2840/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6686e-04 - val_loss: 5.4458e-04\n",
      "Epoch 2841/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6693e-04 - val_loss: 5.4267e-04\n",
      "Epoch 2842/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6686e-04 - val_loss: 5.4302e-04\n",
      "Epoch 2843/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6684e-04 - val_loss: 5.4321e-04\n",
      "Epoch 2844/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6690e-04 - val_loss: 5.4397e-04\n",
      "Epoch 2845/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6684e-04 - val_loss: 5.4394e-04\n",
      "Epoch 2846/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6681e-04 - val_loss: 5.4218e-04\n",
      "Epoch 2847/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6688e-04 - val_loss: 5.4229e-04\n",
      "Epoch 2848/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6696e-04 - val_loss: 5.4432e-04\n",
      "Epoch 2849/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6682e-04 - val_loss: 5.4306e-04\n",
      "Epoch 2850/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6680e-04 - val_loss: 5.4232e-04\n",
      "Epoch 2851/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6685e-04 - val_loss: 5.4370e-04\n",
      "Epoch 2852/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6675e-04 - val_loss: 5.4255e-04\n",
      "Epoch 2853/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6684e-04 - val_loss: 5.4314e-04\n",
      "Epoch 2854/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6677e-04 - val_loss: 5.4382e-04\n",
      "Epoch 2855/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6680e-04 - val_loss: 5.4371e-04\n",
      "Epoch 2856/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6679e-04 - val_loss: 5.4238e-04\n",
      "Epoch 2857/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6683e-04 - val_loss: 5.4333e-04\n",
      "Epoch 2858/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6674e-04 - val_loss: 5.4444e-04\n",
      "Epoch 2859/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6678e-04 - val_loss: 5.4251e-04\n",
      "Epoch 2860/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6672e-04 - val_loss: 5.4174e-04\n",
      "Epoch 2861/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6672e-04 - val_loss: 5.4436e-04\n",
      "Epoch 2862/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6671e-04 - val_loss: 5.4305e-04\n",
      "Epoch 2863/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6672e-04 - val_loss: 5.4174e-04\n",
      "Epoch 2864/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6673e-04 - val_loss: 5.4433e-04\n",
      "Epoch 2865/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6671e-04 - val_loss: 5.4289e-04\n",
      "Epoch 2866/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6668e-04 - val_loss: 5.4350e-04\n",
      "Epoch 2867/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6669e-04 - val_loss: 5.4372e-04\n",
      "Epoch 2868/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6677e-04 - val_loss: 5.4466e-04\n",
      "Epoch 2869/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6671e-04 - val_loss: 5.4380e-04\n",
      "Epoch 2870/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6670e-04 - val_loss: 5.4492e-04\n",
      "Epoch 2871/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6670e-04 - val_loss: 5.4451e-04\n",
      "Epoch 2872/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6674e-04 - val_loss: 5.4411e-04\n",
      "Epoch 2873/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6667e-04 - val_loss: 5.4279e-04\n",
      "Epoch 2874/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6661e-04 - val_loss: 5.4228e-04\n",
      "Epoch 2875/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6667e-04 - val_loss: 5.4310e-04\n",
      "Epoch 2876/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6667e-04 - val_loss: 5.4206e-04\n",
      "Epoch 2877/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6671e-04 - val_loss: 5.4413e-04\n",
      "Epoch 2878/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6665e-04 - val_loss: 5.4286e-04\n",
      "Epoch 2879/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6663e-04 - val_loss: 5.4344e-04\n",
      "Epoch 2880/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6670e-04 - val_loss: 5.4392e-04\n",
      "Epoch 2881/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6673e-04 - val_loss: 5.4314e-04\n",
      "Epoch 2882/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6662e-04 - val_loss: 5.4439e-04\n",
      "Epoch 2883/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6658e-04 - val_loss: 5.4297e-04\n",
      "Epoch 2884/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6667e-04 - val_loss: 5.4297e-04\n",
      "Epoch 2885/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6661e-04 - val_loss: 5.4338e-04\n",
      "Epoch 2886/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6661e-04 - val_loss: 5.4366e-04\n",
      "Epoch 2887/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6661e-04 - val_loss: 5.4399e-04\n",
      "Epoch 2888/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6658e-04 - val_loss: 5.4427e-04\n",
      "Epoch 2889/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6668e-04 - val_loss: 5.4332e-04\n",
      "Epoch 2890/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6655e-04 - val_loss: 5.4363e-04\n",
      "Epoch 2891/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6664e-04 - val_loss: 5.4416e-04\n",
      "Epoch 2892/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6664e-04 - val_loss: 5.4239e-04\n",
      "Epoch 2893/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6650e-04 - val_loss: 5.4566e-04\n",
      "Epoch 2894/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6655e-04 - val_loss: 5.4375e-04\n",
      "Epoch 2895/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6661e-04 - val_loss: 5.4452e-04\n",
      "Epoch 2896/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6653e-04 - val_loss: 5.4171e-04\n",
      "Epoch 2897/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6656e-04 - val_loss: 5.4270e-04\n",
      "Epoch 2898/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6659e-04 - val_loss: 5.4294e-04\n",
      "Epoch 2899/10000\n",
      "45507/45507 [==============================] - 1s 25us/step - loss: 5.6656e-04 - val_loss: 5.4295e-04\n",
      "Epoch 2900/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6651e-04 - val_loss: 5.4229e-04\n",
      "Epoch 2901/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6656e-04 - val_loss: 5.4391e-04\n",
      "Epoch 2902/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6648e-04 - val_loss: 5.4575e-04\n",
      "Epoch 2903/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6644e-04 - val_loss: 5.4129e-04\n",
      "Epoch 2904/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6649e-04 - val_loss: 5.4287e-04\n",
      "Epoch 2905/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6651e-04 - val_loss: 5.4347e-04\n",
      "Epoch 2906/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6655e-04 - val_loss: 5.4310e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2907/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6654e-04 - val_loss: 5.4184e-04\n",
      "Epoch 2908/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6657e-04 - val_loss: 5.4538e-04\n",
      "Epoch 2909/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6645e-04 - val_loss: 5.4352e-04\n",
      "Epoch 2910/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6649e-04 - val_loss: 5.4136e-04\n",
      "Epoch 2911/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6651e-04 - val_loss: 5.4288e-04\n",
      "Epoch 2912/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6652e-04 - val_loss: 5.4407e-04\n",
      "Epoch 2913/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6647e-04 - val_loss: 5.4231e-04\n",
      "Epoch 2914/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6653e-04 - val_loss: 5.4420e-04\n",
      "Epoch 2915/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6653e-04 - val_loss: 5.4471e-04\n",
      "Epoch 2916/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6649e-04 - val_loss: 5.4206e-04\n",
      "Epoch 2917/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6647e-04 - val_loss: 5.4395e-04\n",
      "Epoch 2918/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6645e-04 - val_loss: 5.4430e-04\n",
      "Epoch 2919/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6646e-04 - val_loss: 5.4256e-04\n",
      "Epoch 2920/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6643e-04 - val_loss: 5.4353e-04\n",
      "Epoch 2921/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6641e-04 - val_loss: 5.4591e-04\n",
      "Epoch 2922/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6645e-04 - val_loss: 5.4503e-04\n",
      "Epoch 2923/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6642e-04 - val_loss: 5.4137e-04\n",
      "Epoch 2924/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6640e-04 - val_loss: 5.4232e-04\n",
      "Epoch 2925/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6645e-04 - val_loss: 5.4235e-04\n",
      "Epoch 2926/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6647e-04 - val_loss: 5.4360e-04\n",
      "Epoch 2927/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6635e-04 - val_loss: 5.4302e-04\n",
      "Epoch 2928/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6638e-04 - val_loss: 5.4182e-04\n",
      "Epoch 2929/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6645e-04 - val_loss: 5.4389e-04\n",
      "Epoch 2930/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6632e-04 - val_loss: 5.4193e-04\n",
      "Epoch 2931/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6640e-04 - val_loss: 5.4458e-04\n",
      "Epoch 2932/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6636e-04 - val_loss: 5.4458e-04\n",
      "Epoch 2933/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6640e-04 - val_loss: 5.4252e-04\n",
      "Epoch 2934/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6636e-04 - val_loss: 5.4171e-04\n",
      "Epoch 2935/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6643e-04 - val_loss: 5.4187e-04\n",
      "Epoch 2936/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6627e-04 - val_loss: 5.4214e-04\n",
      "Epoch 2937/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6635e-04 - val_loss: 5.4322e-04\n",
      "Epoch 2938/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6631e-04 - val_loss: 5.4368e-04\n",
      "Epoch 2939/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6628e-04 - val_loss: 5.4420e-04\n",
      "Epoch 2940/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6639e-04 - val_loss: 5.4385e-04\n",
      "Epoch 2941/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6634e-04 - val_loss: 5.4487e-04\n",
      "Epoch 2942/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6633e-04 - val_loss: 5.4466e-04\n",
      "Epoch 2943/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6629e-04 - val_loss: 5.4343e-04\n",
      "Epoch 2944/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6628e-04 - val_loss: 5.4331e-04\n",
      "Epoch 2945/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6635e-04 - val_loss: 5.4416e-04\n",
      "Epoch 2946/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6632e-04 - val_loss: 5.4339e-04\n",
      "Epoch 2947/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6633e-04 - val_loss: 5.4519e-04\n",
      "Epoch 2948/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6628e-04 - val_loss: 5.4344e-04\n",
      "Epoch 2949/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6640e-04 - val_loss: 5.4204e-04\n",
      "Epoch 2950/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6629e-04 - val_loss: 5.4427e-04\n",
      "Epoch 2951/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6635e-04 - val_loss: 5.4254e-04\n",
      "Epoch 2952/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6629e-04 - val_loss: 5.4554e-04\n",
      "Epoch 2953/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6627e-04 - val_loss: 5.4427e-04\n",
      "Epoch 2954/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6622e-04 - val_loss: 5.4335e-04\n",
      "Epoch 2955/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6629e-04 - val_loss: 5.4331e-04\n",
      "Epoch 2956/10000\n",
      "45507/45507 [==============================] - 1s 23us/step - loss: 5.6624e-04 - val_loss: 5.4128e-04\n",
      "Epoch 2957/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6626e-04 - val_loss: 5.4250e-04\n",
      "Epoch 2958/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6623e-04 - val_loss: 5.4554e-04\n",
      "Epoch 2959/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6623e-04 - val_loss: 5.4273e-04\n",
      "Epoch 2960/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6623e-04 - val_loss: 5.4194e-04\n",
      "Epoch 2961/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6622e-04 - val_loss: 5.4437e-04\n",
      "Epoch 2962/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6625e-04 - val_loss: 5.4259e-04\n",
      "Epoch 2963/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6620e-04 - val_loss: 5.4258e-04\n",
      "Epoch 2964/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6628e-04 - val_loss: 5.4225e-04\n",
      "Epoch 2965/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6616e-04 - val_loss: 5.4249e-04\n",
      "Epoch 2966/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6626e-04 - val_loss: 5.4519e-04\n",
      "Epoch 2967/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6622e-04 - val_loss: 5.4522e-04\n",
      "Epoch 2968/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6620e-04 - val_loss: 5.4339e-04\n",
      "Epoch 2969/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6626e-04 - val_loss: 5.4237e-04\n",
      "Epoch 2970/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6617e-04 - val_loss: 5.4339e-04\n",
      "Epoch 2971/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6613e-04 - val_loss: 5.4339e-04\n",
      "Epoch 2972/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6621e-04 - val_loss: 5.4415e-04\n",
      "Epoch 2973/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6612e-04 - val_loss: 5.4468e-04\n",
      "Epoch 2974/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6616e-04 - val_loss: 5.4468e-04\n",
      "Epoch 2975/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6620e-04 - val_loss: 5.4394e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2976/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6612e-04 - val_loss: 5.4256e-04\n",
      "Epoch 2977/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6616e-04 - val_loss: 5.4444e-04\n",
      "Epoch 2978/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6613e-04 - val_loss: 5.4278e-04\n",
      "Epoch 2979/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6612e-04 - val_loss: 5.4445e-04\n",
      "Epoch 2980/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6615e-04 - val_loss: 5.4391e-04\n",
      "Epoch 2981/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6609e-04 - val_loss: 5.4483e-04\n",
      "Epoch 2982/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6611e-04 - val_loss: 5.4266e-04\n",
      "Epoch 2983/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6610e-04 - val_loss: 5.4478e-04\n",
      "Epoch 2984/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6611e-04 - val_loss: 5.4499e-04\n",
      "Epoch 2985/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6610e-04 - val_loss: 5.4537e-04\n",
      "Epoch 2986/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6611e-04 - val_loss: 5.4160e-04\n",
      "Epoch 2987/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6612e-04 - val_loss: 5.4354e-04\n",
      "Epoch 2988/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6612e-04 - val_loss: 5.4475e-04\n",
      "Epoch 2989/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6608e-04 - val_loss: 5.4373e-04\n",
      "Epoch 2990/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6600e-04 - val_loss: 5.4410e-04\n",
      "Epoch 2991/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6604e-04 - val_loss: 5.4378e-04\n",
      "Epoch 2992/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6604e-04 - val_loss: 5.4404e-04\n",
      "Epoch 2993/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6608e-04 - val_loss: 5.4186e-04\n",
      "Epoch 2994/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6609e-04 - val_loss: 5.4705e-04\n",
      "Epoch 2995/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6608e-04 - val_loss: 5.4403e-04\n",
      "Epoch 2996/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6605e-04 - val_loss: 5.4251e-04\n",
      "Epoch 2997/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6608e-04 - val_loss: 5.4482e-04\n",
      "Epoch 2998/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6604e-04 - val_loss: 5.4313e-04\n",
      "Epoch 2999/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6602e-04 - val_loss: 5.4311e-04\n",
      "Epoch 3000/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6609e-04 - val_loss: 5.4298e-04\n",
      "Epoch 3001/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6599e-04 - val_loss: 5.4392e-04\n",
      "Epoch 3002/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6598e-04 - val_loss: 5.4291e-04\n",
      "Epoch 3003/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6598e-04 - val_loss: 5.4407e-04\n",
      "Epoch 3004/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6599e-04 - val_loss: 5.4497e-04\n",
      "Epoch 3005/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6602e-04 - val_loss: 5.4409e-04\n",
      "Epoch 3006/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6599e-04 - val_loss: 5.4301e-04\n",
      "Epoch 3007/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6593e-04 - val_loss: 5.4532e-04\n",
      "Epoch 3008/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6597e-04 - val_loss: 5.4293e-04\n",
      "Epoch 3009/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6587e-04 - val_loss: 5.4289e-04\n",
      "Epoch 3010/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6600e-04 - val_loss: 5.4480e-04\n",
      "Epoch 3011/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6604e-04 - val_loss: 5.4429e-04\n",
      "Epoch 3012/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6597e-04 - val_loss: 5.4217e-04\n",
      "Epoch 3013/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6600e-04 - val_loss: 5.4536e-04\n",
      "Epoch 3014/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6592e-04 - val_loss: 5.4361e-04\n",
      "Epoch 3015/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6603e-04 - val_loss: 5.4405e-04\n",
      "Epoch 3016/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6586e-04 - val_loss: 5.4332e-04\n",
      "Epoch 3017/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6594e-04 - val_loss: 5.4190e-04\n",
      "Epoch 3018/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6599e-04 - val_loss: 5.4628e-04\n",
      "Epoch 3019/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6596e-04 - val_loss: 5.4405e-04\n",
      "Epoch 3020/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6594e-04 - val_loss: 5.4311e-04\n",
      "Epoch 3021/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6589e-04 - val_loss: 5.4320e-04\n",
      "Epoch 3022/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6591e-04 - val_loss: 5.4411e-04\n",
      "Epoch 3023/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6590e-04 - val_loss: 5.4467e-04\n",
      "Epoch 3024/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6585e-04 - val_loss: 5.4261e-04\n",
      "Epoch 3025/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6596e-04 - val_loss: 5.4482e-04\n",
      "Epoch 3026/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6585e-04 - val_loss: 5.4300e-04\n",
      "Epoch 3027/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6593e-04 - val_loss: 5.4543e-04\n",
      "Epoch 3028/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6591e-04 - val_loss: 5.4220e-04\n",
      "Epoch 3029/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6594e-04 - val_loss: 5.4490e-04\n",
      "Epoch 3030/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6592e-04 - val_loss: 5.4409e-04\n",
      "Epoch 3031/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6590e-04 - val_loss: 5.4553e-04\n",
      "Epoch 3032/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6587e-04 - val_loss: 5.4379e-04\n",
      "Epoch 3033/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6586e-04 - val_loss: 5.4306e-04\n",
      "Epoch 3034/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6596e-04 - val_loss: 5.4521e-04\n",
      "Epoch 3035/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6583e-04 - val_loss: 5.4249e-04\n",
      "Epoch 3036/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6587e-04 - val_loss: 5.4443e-04\n",
      "Epoch 3037/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6585e-04 - val_loss: 5.4378e-04\n",
      "Epoch 3038/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6587e-04 - val_loss: 5.4179e-04\n",
      "Epoch 3039/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6586e-04 - val_loss: 5.4394e-04\n",
      "Epoch 3040/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6588e-04 - val_loss: 5.4342e-04\n",
      "Epoch 3041/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6588e-04 - val_loss: 5.4578e-04\n",
      "Epoch 3042/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6585e-04 - val_loss: 5.4587e-04\n",
      "Epoch 3043/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6573e-04 - val_loss: 5.4244e-04\n",
      "Epoch 3044/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6582e-04 - val_loss: 5.4360e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3045/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6578e-04 - val_loss: 5.4469e-04\n",
      "Epoch 3046/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6582e-04 - val_loss: 5.4373e-04\n",
      "Epoch 3047/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6574e-04 - val_loss: 5.4446e-04\n",
      "Epoch 3048/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6577e-04 - val_loss: 5.4307e-04\n",
      "Epoch 3049/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6569e-04 - val_loss: 5.4487e-04\n",
      "Epoch 3050/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6580e-04 - val_loss: 5.4519e-04\n",
      "Epoch 3051/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6583e-04 - val_loss: 5.4370e-04\n",
      "Epoch 3052/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6575e-04 - val_loss: 5.4333e-04\n",
      "Epoch 3053/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6581e-04 - val_loss: 5.4260e-04\n",
      "Epoch 3054/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6574e-04 - val_loss: 5.4273e-04\n",
      "Epoch 3055/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6575e-04 - val_loss: 5.4206e-04\n",
      "Epoch 3056/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6575e-04 - val_loss: 5.4551e-04\n",
      "Epoch 3057/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6570e-04 - val_loss: 5.4480e-04\n",
      "Epoch 3058/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6566e-04 - val_loss: 5.4295e-04\n",
      "Epoch 3059/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6574e-04 - val_loss: 5.4511e-04\n",
      "Epoch 3060/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6576e-04 - val_loss: 5.4372e-04\n",
      "Epoch 3061/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6575e-04 - val_loss: 5.4343e-04\n",
      "Epoch 3062/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6570e-04 - val_loss: 5.4433e-04\n",
      "Epoch 3063/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6570e-04 - val_loss: 5.4271e-04\n",
      "Epoch 3064/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6568e-04 - val_loss: 5.4630e-04\n",
      "Epoch 3065/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6569e-04 - val_loss: 5.4359e-04\n",
      "Epoch 3066/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6565e-04 - val_loss: 5.4437e-04\n",
      "Epoch 3067/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6569e-04 - val_loss: 5.4347e-04\n",
      "Epoch 3068/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6572e-04 - val_loss: 5.4507e-04\n",
      "Epoch 3069/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 5.6568e-04 - val_loss: 5.4469e-04\n",
      "Epoch 3070/10000\n",
      "45507/45507 [==============================] - 1s 24us/step - loss: 5.6571e-04 - val_loss: 5.4434e-04\n",
      "Epoch 3071/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6559e-04 - val_loss: 5.4489e-04\n",
      "Epoch 3072/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6567e-04 - val_loss: 5.4501e-04\n",
      "Epoch 3073/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6570e-04 - val_loss: 5.4313e-04\n",
      "Epoch 3074/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6564e-04 - val_loss: 5.4633e-04\n",
      "Epoch 3075/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6568e-04 - val_loss: 5.4297e-04\n",
      "Epoch 3076/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6563e-04 - val_loss: 5.4409e-04\n",
      "Epoch 3077/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6561e-04 - val_loss: 5.4303e-04\n",
      "Epoch 3078/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6571e-04 - val_loss: 5.4282e-04\n",
      "Epoch 3079/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6566e-04 - val_loss: 5.4281e-04\n",
      "Epoch 3080/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6571e-04 - val_loss: 5.4472e-04\n",
      "Epoch 3081/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6562e-04 - val_loss: 5.4490e-04\n",
      "Epoch 3082/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6562e-04 - val_loss: 5.4595e-04\n",
      "Epoch 3083/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6569e-04 - val_loss: 5.4550e-04\n",
      "Epoch 3084/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6562e-04 - val_loss: 5.4313e-04\n",
      "Epoch 3085/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6564e-04 - val_loss: 5.4420e-04\n",
      "Epoch 3086/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6557e-04 - val_loss: 5.4375e-04\n",
      "Epoch 3087/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6557e-04 - val_loss: 5.4252e-04\n",
      "Epoch 3088/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6565e-04 - val_loss: 5.4413e-04\n",
      "Epoch 3089/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6561e-04 - val_loss: 5.4349e-04\n",
      "Epoch 3090/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6561e-04 - val_loss: 5.4565e-04\n",
      "Epoch 3091/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6556e-04 - val_loss: 5.4650e-04\n",
      "Epoch 3092/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6553e-04 - val_loss: 5.4785e-04\n",
      "Epoch 3093/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6563e-04 - val_loss: 5.4594e-04\n",
      "Epoch 3094/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6558e-04 - val_loss: 5.4610e-04\n",
      "Epoch 3095/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6557e-04 - val_loss: 5.4322e-04\n",
      "Epoch 3096/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6553e-04 - val_loss: 5.4194e-04\n",
      "Epoch 3097/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6558e-04 - val_loss: 5.4508e-04\n",
      "Epoch 3098/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6556e-04 - val_loss: 5.4529e-04\n",
      "Epoch 3099/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6558e-04 - val_loss: 5.4690e-04\n",
      "Epoch 3100/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6552e-04 - val_loss: 5.4201e-04\n",
      "Epoch 3101/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6557e-04 - val_loss: 5.4285e-04\n",
      "Epoch 3102/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6549e-04 - val_loss: 5.4472e-04\n",
      "Epoch 3103/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6552e-04 - val_loss: 5.4320e-04\n",
      "Epoch 3104/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6544e-04 - val_loss: 5.4571e-04\n",
      "Epoch 3105/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6556e-04 - val_loss: 5.4456e-04\n",
      "Epoch 3106/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6555e-04 - val_loss: 5.4416e-04\n",
      "Epoch 3107/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6560e-04 - val_loss: 5.4537e-04\n",
      "Epoch 3108/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6549e-04 - val_loss: 5.4741e-04\n",
      "Epoch 3109/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6548e-04 - val_loss: 5.4392e-04\n",
      "Epoch 3110/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6558e-04 - val_loss: 5.4404e-04\n",
      "Epoch 3111/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6550e-04 - val_loss: 5.4393e-04\n",
      "Epoch 3112/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6550e-04 - val_loss: 5.4474e-04\n",
      "Epoch 3113/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6545e-04 - val_loss: 5.4473e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3114/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6549e-04 - val_loss: 5.4486e-04\n",
      "Epoch 3115/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6551e-04 - val_loss: 5.4476e-04\n",
      "Epoch 3116/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6541e-04 - val_loss: 5.4599e-04\n",
      "Epoch 3117/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6560e-04 - val_loss: 5.4196e-04\n",
      "Epoch 3118/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6544e-04 - val_loss: 5.4573e-04\n",
      "Epoch 3119/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6544e-04 - val_loss: 5.4556e-04\n",
      "Epoch 3120/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6550e-04 - val_loss: 5.4315e-04\n",
      "Epoch 3121/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6551e-04 - val_loss: 5.4391e-04\n",
      "Epoch 3122/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6549e-04 - val_loss: 5.4489e-04\n",
      "Epoch 3123/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6542e-04 - val_loss: 5.4365e-04\n",
      "Epoch 3124/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6552e-04 - val_loss: 5.4462e-04\n",
      "Epoch 3125/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6545e-04 - val_loss: 5.4387e-04\n",
      "Epoch 3126/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6540e-04 - val_loss: 5.4588e-04\n",
      "Epoch 3127/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6540e-04 - val_loss: 5.4260e-04\n",
      "Epoch 3128/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6544e-04 - val_loss: 5.4554e-04\n",
      "Epoch 3129/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6543e-04 - val_loss: 5.4467e-04\n",
      "Epoch 3130/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6542e-04 - val_loss: 5.4335e-04\n",
      "Epoch 3131/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6539e-04 - val_loss: 5.4430e-04\n",
      "Epoch 3132/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6534e-04 - val_loss: 5.4407e-04\n",
      "Epoch 3133/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6542e-04 - val_loss: 5.4563e-04\n",
      "Epoch 3134/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6540e-04 - val_loss: 5.4566e-04\n",
      "Epoch 3135/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6541e-04 - val_loss: 5.4388e-04\n",
      "Epoch 3136/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6532e-04 - val_loss: 5.4582e-04\n",
      "Epoch 3137/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6533e-04 - val_loss: 5.4447e-04\n",
      "Epoch 3138/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6533e-04 - val_loss: 5.4430e-04\n",
      "Epoch 3139/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6536e-04 - val_loss: 5.4591e-04\n",
      "Epoch 3140/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6530e-04 - val_loss: 5.4411e-04\n",
      "Epoch 3141/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6537e-04 - val_loss: 5.4711e-04\n",
      "Epoch 3142/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6533e-04 - val_loss: 5.4501e-04\n",
      "Epoch 3143/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6532e-04 - val_loss: 5.4485e-04\n",
      "Epoch 3144/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6532e-04 - val_loss: 5.4253e-04\n",
      "Epoch 3145/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6529e-04 - val_loss: 5.4469e-04\n",
      "Epoch 3146/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6538e-04 - val_loss: 5.4829e-04\n",
      "Epoch 3147/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6539e-04 - val_loss: 5.4567e-04\n",
      "Epoch 3148/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6527e-04 - val_loss: 5.4306e-04\n",
      "Epoch 3149/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6542e-04 - val_loss: 5.4373e-04\n",
      "Epoch 3150/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6531e-04 - val_loss: 5.4365e-04\n",
      "Epoch 3151/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6528e-04 - val_loss: 5.4402e-04\n",
      "Epoch 3152/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6533e-04 - val_loss: 5.4647e-04\n",
      "Epoch 3153/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6534e-04 - val_loss: 5.4476e-04\n",
      "Epoch 3154/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6531e-04 - val_loss: 5.4473e-04\n",
      "Epoch 3155/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6539e-04 - val_loss: 5.4533e-04\n",
      "Epoch 3156/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6530e-04 - val_loss: 5.4407e-04\n",
      "Epoch 3157/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6524e-04 - val_loss: 5.4792e-04\n",
      "Epoch 3158/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6526e-04 - val_loss: 5.4482e-04\n",
      "Epoch 3159/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6529e-04 - val_loss: 5.4438e-04\n",
      "Epoch 3160/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6529e-04 - val_loss: 5.4544e-04\n",
      "Epoch 3161/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6516e-04 - val_loss: 5.4310e-04\n",
      "Epoch 3162/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6525e-04 - val_loss: 5.4596e-04\n",
      "Epoch 3163/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6521e-04 - val_loss: 5.4621e-04\n",
      "Epoch 3164/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6524e-04 - val_loss: 5.4456e-04\n",
      "Epoch 3165/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6529e-04 - val_loss: 5.4648e-04\n",
      "Epoch 3166/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6533e-04 - val_loss: 5.4427e-04\n",
      "Epoch 3167/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6517e-04 - val_loss: 5.4429e-04\n",
      "Epoch 3168/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6521e-04 - val_loss: 5.4473e-04\n",
      "Epoch 3169/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6524e-04 - val_loss: 5.4615e-04\n",
      "Epoch 3170/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6526e-04 - val_loss: 5.4433e-04\n",
      "Epoch 3171/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6518e-04 - val_loss: 5.4644e-04\n",
      "Epoch 3172/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6521e-04 - val_loss: 5.4327e-04\n",
      "Epoch 3173/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6518e-04 - val_loss: 5.4390e-04\n",
      "Epoch 3174/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6518e-04 - val_loss: 5.4303e-04\n",
      "Epoch 3175/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6519e-04 - val_loss: 5.4526e-04\n",
      "Epoch 3176/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6516e-04 - val_loss: 5.4673e-04\n",
      "Epoch 3177/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6523e-04 - val_loss: 5.4673e-04\n",
      "Epoch 3178/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6516e-04 - val_loss: 5.4299e-04\n",
      "Epoch 3179/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6515e-04 - val_loss: 5.4296e-04\n",
      "Epoch 3180/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6521e-04 - val_loss: 5.4548e-04\n",
      "Epoch 3181/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6519e-04 - val_loss: 5.4650e-04\n",
      "Epoch 3182/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6521e-04 - val_loss: 5.4400e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3183/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6518e-04 - val_loss: 5.4557e-04\n",
      "Epoch 3184/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6520e-04 - val_loss: 5.4375e-04\n",
      "Epoch 3185/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6510e-04 - val_loss: 5.4801e-04\n",
      "Epoch 3186/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6507e-04 - val_loss: 5.4423e-04\n",
      "Epoch 3187/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6524e-04 - val_loss: 5.4436e-04\n",
      "Epoch 3188/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6513e-04 - val_loss: 5.4536e-04\n",
      "Epoch 3189/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6515e-04 - val_loss: 5.4514e-04\n",
      "Epoch 3190/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6512e-04 - val_loss: 5.4676e-04\n",
      "Epoch 3191/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6520e-04 - val_loss: 5.4282e-04\n",
      "Epoch 3192/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6514e-04 - val_loss: 5.4767e-04\n",
      "Epoch 3193/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6517e-04 - val_loss: 5.4282e-04\n",
      "Epoch 3194/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6513e-04 - val_loss: 5.4541e-04\n",
      "Epoch 3195/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6513e-04 - val_loss: 5.4579e-04\n",
      "Epoch 3196/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6510e-04 - val_loss: 5.4727e-04\n",
      "Epoch 3197/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6515e-04 - val_loss: 5.4702e-04\n",
      "Epoch 3198/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6516e-04 - val_loss: 5.4441e-04\n",
      "Epoch 3199/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6508e-04 - val_loss: 5.4350e-04\n",
      "Epoch 3200/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6517e-04 - val_loss: 5.4498e-04\n",
      "Epoch 3201/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6507e-04 - val_loss: 5.4575e-04\n",
      "Epoch 3202/10000\n",
      "45507/45507 [==============================] - 1s 30us/step - loss: 5.6509e-04 - val_loss: 5.4530e-04\n",
      "Epoch 3203/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6501e-04 - val_loss: 5.4462e-04\n",
      "Epoch 3204/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6510e-04 - val_loss: 5.4413e-04\n",
      "Epoch 3205/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6503e-04 - val_loss: 5.4595e-04\n",
      "Epoch 3206/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6503e-04 - val_loss: 5.4353e-04\n",
      "Epoch 3207/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6516e-04 - val_loss: 5.4608e-04\n",
      "Epoch 3208/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6503e-04 - val_loss: 5.4382e-04\n",
      "Epoch 3209/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6503e-04 - val_loss: 5.4786e-04\n",
      "Epoch 3210/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6508e-04 - val_loss: 5.4562e-04\n",
      "Epoch 3211/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6503e-04 - val_loss: 5.4443e-04\n",
      "Epoch 3212/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6504e-04 - val_loss: 5.4614e-04\n",
      "Epoch 3213/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6510e-04 - val_loss: 5.4644e-04\n",
      "Epoch 3214/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6503e-04 - val_loss: 5.4530e-04\n",
      "Epoch 3215/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6505e-04 - val_loss: 5.4348e-04\n",
      "Epoch 3216/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6510e-04 - val_loss: 5.4553e-04\n",
      "Epoch 3217/10000\n",
      "45507/45507 [==============================] - 1s 27us/step - loss: 5.6496e-04 - val_loss: 5.4444e-04\n",
      "Epoch 3218/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6496e-04 - val_loss: 5.4706e-04\n",
      "Epoch 3219/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6503e-04 - val_loss: 5.4602e-04\n",
      "Epoch 3220/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6505e-04 - val_loss: 5.4569e-04\n",
      "Epoch 3221/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6501e-04 - val_loss: 5.4424e-04\n",
      "Epoch 3222/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6503e-04 - val_loss: 5.4599e-04\n",
      "Epoch 3223/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6500e-04 - val_loss: 5.4653e-04\n",
      "Epoch 3224/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6494e-04 - val_loss: 5.4376e-04\n",
      "Epoch 3225/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6496e-04 - val_loss: 5.4358e-04\n",
      "Epoch 3226/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6501e-04 - val_loss: 5.4528e-04\n",
      "Epoch 3227/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6502e-04 - val_loss: 5.4847e-04\n",
      "Epoch 3228/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6515e-04 - val_loss: 5.4632e-04\n",
      "Epoch 3229/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6493e-04 - val_loss: 5.4310e-04\n",
      "Epoch 3230/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6498e-04 - val_loss: 5.4571e-04\n",
      "Epoch 3231/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6498e-04 - val_loss: 5.4311e-04\n",
      "Epoch 3232/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6496e-04 - val_loss: 5.4604e-04\n",
      "Epoch 3233/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6496e-04 - val_loss: 5.4390e-04\n",
      "Epoch 3234/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6493e-04 - val_loss: 5.4391e-04\n",
      "Epoch 3235/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6492e-04 - val_loss: 5.4560e-04\n",
      "Epoch 3236/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6492e-04 - val_loss: 5.4339e-04\n",
      "Epoch 3237/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6495e-04 - val_loss: 5.4386e-04\n",
      "Epoch 3238/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6483e-04 - val_loss: 5.4426e-04\n",
      "Epoch 3239/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6495e-04 - val_loss: 5.4508e-04\n",
      "Epoch 3240/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6491e-04 - val_loss: 5.4675e-04\n",
      "Epoch 3241/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6494e-04 - val_loss: 5.4631e-04\n",
      "Epoch 3242/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6492e-04 - val_loss: 5.4590e-04\n",
      "Epoch 3243/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6492e-04 - val_loss: 5.4441e-04\n",
      "Epoch 3244/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6495e-04 - val_loss: 5.4734e-04\n",
      "Epoch 3245/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6488e-04 - val_loss: 5.4428e-04\n",
      "Epoch 3246/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6488e-04 - val_loss: 5.4762e-04\n",
      "Epoch 3247/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6486e-04 - val_loss: 5.4370e-04\n",
      "Epoch 3248/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6498e-04 - val_loss: 5.4580e-04\n",
      "Epoch 3249/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6484e-04 - val_loss: 5.4266e-04\n",
      "Epoch 3250/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6493e-04 - val_loss: 5.4808e-04\n",
      "Epoch 3251/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6492e-04 - val_loss: 5.4479e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3252/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6486e-04 - val_loss: 5.4706e-04\n",
      "Epoch 3253/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6492e-04 - val_loss: 5.4531e-04\n",
      "Epoch 3254/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6487e-04 - val_loss: 5.4470e-04\n",
      "Epoch 3255/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6487e-04 - val_loss: 5.4567e-04\n",
      "Epoch 3256/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6483e-04 - val_loss: 5.4507e-04\n",
      "Epoch 3257/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6495e-04 - val_loss: 5.4617e-04\n",
      "Epoch 3258/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6488e-04 - val_loss: 5.4362e-04\n",
      "Epoch 3259/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6482e-04 - val_loss: 5.4593e-04\n",
      "Epoch 3260/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6487e-04 - val_loss: 5.4489e-04\n",
      "Epoch 3261/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6481e-04 - val_loss: 5.4417e-04\n",
      "Epoch 3262/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6480e-04 - val_loss: 5.4792e-04\n",
      "Epoch 3263/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6484e-04 - val_loss: 5.4496e-04\n",
      "Epoch 3264/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6485e-04 - val_loss: 5.4565e-04\n",
      "Epoch 3265/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6480e-04 - val_loss: 5.4486e-04\n",
      "Epoch 3266/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6484e-04 - val_loss: 5.4517e-04\n",
      "Epoch 3267/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6481e-04 - val_loss: 5.4456e-04\n",
      "Epoch 3268/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6476e-04 - val_loss: 5.4767e-04\n",
      "Epoch 3269/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6477e-04 - val_loss: 5.4432e-04\n",
      "Epoch 3270/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6487e-04 - val_loss: 5.4539e-04\n",
      "Epoch 3271/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6481e-04 - val_loss: 5.4391e-04\n",
      "Epoch 3272/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6478e-04 - val_loss: 5.4551e-04\n",
      "Epoch 3273/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6481e-04 - val_loss: 5.4562e-04\n",
      "Epoch 3274/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6493e-04 - val_loss: 5.4549e-04\n",
      "Epoch 3275/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6477e-04 - val_loss: 5.4600e-04\n",
      "Epoch 3276/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6480e-04 - val_loss: 5.4745e-04\n",
      "Epoch 3277/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6485e-04 - val_loss: 5.4296e-04\n",
      "Epoch 3278/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6482e-04 - val_loss: 5.4732e-04\n",
      "Epoch 3279/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6474e-04 - val_loss: 5.4632e-04\n",
      "Epoch 3280/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6484e-04 - val_loss: 5.4526e-04\n",
      "Epoch 3281/10000\n",
      "45507/45507 [==============================] - 2s 33us/step - loss: 5.6480e-04 - val_loss: 5.4702e-04\n",
      "Epoch 3282/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6482e-04 - val_loss: 5.4431e-04\n",
      "Epoch 3283/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6475e-04 - val_loss: 5.4402e-04\n",
      "Epoch 3284/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6472e-04 - val_loss: 5.4630e-04\n",
      "Epoch 3285/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6474e-04 - val_loss: 5.4366e-04\n",
      "Epoch 3286/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6476e-04 - val_loss: 5.4839e-04\n",
      "Epoch 3287/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6473e-04 - val_loss: 5.4686e-04\n",
      "Epoch 3288/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6478e-04 - val_loss: 5.4445e-04\n",
      "Epoch 3289/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6479e-04 - val_loss: 5.4538e-04\n",
      "Epoch 3290/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6474e-04 - val_loss: 5.4442e-04\n",
      "Epoch 3291/10000\n",
      "45507/45507 [==============================] - 1s 31us/step - loss: 5.6471e-04 - val_loss: 5.4631e-04\n",
      "Epoch 3292/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6470e-04 - val_loss: 5.4594e-04\n",
      "Epoch 3293/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6465e-04 - val_loss: 5.4508e-04\n",
      "Epoch 3294/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6473e-04 - val_loss: 5.4631e-04\n",
      "Epoch 3295/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6462e-04 - val_loss: 5.4509e-04\n",
      "Epoch 3296/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6466e-04 - val_loss: 5.4562e-04\n",
      "Epoch 3297/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6473e-04 - val_loss: 5.4599e-04\n",
      "Epoch 3298/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6468e-04 - val_loss: 5.4813e-04\n",
      "Epoch 3299/10000\n",
      "45507/45507 [==============================] - 1s 26us/step - loss: 5.6467e-04 - val_loss: 5.4502e-04\n",
      "Epoch 3300/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6467e-04 - val_loss: 5.4547e-04\n",
      "Epoch 3301/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6468e-04 - val_loss: 5.4502e-04\n",
      "Epoch 3302/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6465e-04 - val_loss: 5.4473e-04\n",
      "Epoch 3303/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6480e-04 - val_loss: 5.4705e-04\n",
      "Epoch 3304/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6464e-04 - val_loss: 5.4503e-04\n",
      "Epoch 3305/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6463e-04 - val_loss: 5.4456e-04\n",
      "Epoch 3306/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6470e-04 - val_loss: 5.4559e-04\n",
      "Epoch 3307/10000\n",
      "45507/45507 [==============================] - 2s 34us/step - loss: 5.6468e-04 - val_loss: 5.4579e-04\n",
      "Epoch 3308/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6468e-04 - val_loss: 5.4573e-04\n",
      "Epoch 3309/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6465e-04 - val_loss: 5.4757e-04\n",
      "Epoch 3310/10000\n",
      "45507/45507 [==============================] - 1s 32us/step - loss: 5.6468e-04 - val_loss: 5.4642e-04\n",
      "Epoch 3311/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6464e-04 - val_loss: 5.4455e-04\n",
      "Epoch 3312/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6461e-04 - val_loss: 5.4501e-04\n",
      "Epoch 3313/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6465e-04 - val_loss: 5.4683e-04\n",
      "Epoch 3314/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6464e-04 - val_loss: 5.4349e-04\n",
      "Epoch 3315/10000\n",
      "45507/45507 [==============================] - 2s 37us/step - loss: 5.6466e-04 - val_loss: 5.4739e-04\n",
      "Epoch 3316/10000\n",
      "45507/45507 [==============================] - 2s 35us/step - loss: 5.6463e-04 - val_loss: 5.4570e-04\n",
      "Epoch 3317/10000\n",
      "45507/45507 [==============================] - 1s 28us/step - loss: 5.6463e-04 - val_loss: 5.4623e-04\n",
      "Epoch 3318/10000\n",
      "45507/45507 [==============================] - 1s 29us/step - loss: 5.6463e-04 - val_loss: 5.4445e-04\n",
      "Epoch 3319/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6461e-04 - val_loss: 5.4465e-04\n",
      "Epoch 3320/10000\n",
      "45507/45507 [==============================] - 1s 33us/step - loss: 5.6463e-04 - val_loss: 5.4513e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3321/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6464e-04 - val_loss: 5.4574e-04\n",
      "Epoch 3322/10000\n",
      "45507/45507 [==============================] - 2s 36us/step - loss: 5.6470e-04 - val_loss: 5.4641e-04\n",
      "Epoch 03322: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fef3c8936a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algoritmo='RMSprop'\n",
    "experimento=\"scaled_{}_encoder_without_bias_tanh_tanh_lr_{}\".format(supermax,factor_aprendizaje)\n",
    "tensorboard=TensorBoard(log_dir=\"/home/rgadea3/EXPERIMENTOS/nuevas_investigaciones_2018/experimentos/logs/{}{}{}{}\".format(encoding_dim,algoritmo,experimento,datetime.now()))\n",
    "#modelCheckpoint=ModelCheckpoint(\"/home/rgadea3/EXPERIMENTOS/nuevas_investigaciones_2018/experimentos/logs/\", monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "early_stop=EarlyStopping(monitor='val_loss', min_delta=0, patience=500, verbose=2, mode='auto', baseline=None)\n",
    "autoencoder.fit(x_train_scaled, x_train_scaled,\n",
    "                epochs=10000,\n",
    "                batch_size=200,\n",
    "                shuffle=False,\n",
    "                callbacks=[tensorboard, early_stop],\n",
    "                validation_data=(x_test_scaled, x_test_scaled))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15170/15170 [==============================] - 1s 70us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0005464059055702699"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.evaluate(x=x_test_scaled,y=x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save_weights('../redes_compresoras/compresor_python_{}{}{}{}'.format(encoding_dim,algoritmo,experimento,datetime.now()))\n",
    "#np.savez('../redes_compresoras/maxmin_python_ver_rms_prop_scaled_min_max_ver2', min_max_scaler.data_max_, min_max_scaler.data_min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fef3c893518>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "standard_scores = encoder.predict(x_test_scaled).ravel()\n",
    "#regularized_scores = encoded_regularized.predict(x_test).ravel()\n",
    "sns.distplot(standard_scores, hist=True, label='standard model')\n",
    "#sns.distplot(regularized_scores, hist=False, label='regularized model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some images\n",
    "# note that we take them from the *test* set\n",
    "# encoded_imgs = encoder.predict(x_test_min_max)\n",
    "# decoded_imgs_scaled = decoder.predict(encoded_imgs)\n",
    "#decoded_imgs_scaled = autoencoder.predict(x_test_min_max)\n",
    "decoded_imgs_scaled = autoencoder.predict(x_test_scaled)\n",
    "decoded_imgs = supermax*(decoded_imgs_scaled+1)/2\n",
    "#decoded_imgs = min_max_scaler.inverse_transform(decoded_imgs_scaled)\n",
    "#decoded_imgs = autoencoder.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1232\n"
     ]
    }
   ],
   "source": [
    "n = 6  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    idea=np.random.randint(1,x_test.shape[0])\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[idea].reshape(40, 16).transpose(),vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[idea].reshape(40, 16).transpose(),vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "print(idea)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6296, 3840)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filename = '../datos_octubre_2018/p_OF_5mm_161mm003.h5'\n",
    "conjunto_datos_test=pd.read_hdf(filename,'MC');\n",
    "conjunto_datos_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6296, 3840)\n",
      "(6296, 3840)\n"
     ]
    }
   ],
   "source": [
    "L1A=6;\n",
    "# hay tres L1 con 640 sensores (40*16)\n",
    "L1B=0;\n",
    "# hay dos L1 con 640 sensores (40*16)\n",
    "X_trained=conjunto_datos_test.values;\n",
    "x_trained=X_trained;\n",
    "\n",
    "for i in range (X_trained.shape[0]):\n",
    "    idea1=X_trained[i,:].reshape(img_rows,(L1A*img_cols));\n",
    "    ideat=idea1.transpose();\n",
    "    idea2=ideat.reshape(1,(L1A*img_cols)*img_rows);\n",
    "    x_trained[i,:] =idea2;\n",
    "x_tested = x_trained;\n",
    "print(x_trained.shape)\n",
    "print(x_tested.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vamos a procesar y comprimir con la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora los particionamos y pasamos por las redes de compresión. Hay una red la A que se utiliza 5 veces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(x, derivative=False):\n",
    "  return x*(1-x) if derivative else 1/(1+np.exp(-x))\n",
    "ideaA=np.zeros((L1A,input_output_dim_A))\n",
    "\n",
    "cara_externa=x_tested[:,0: L1A*input_output_dim_A] \n",
    "cara_externa_reconstruida=np.zeros((x_tested.shape[0],L1A*input_output_dim_A))\n",
    "for i in range(x_tested.shape[0]):\n",
    "    for k in range(L1A):\n",
    "        ideaA[k,:]=x_tested[i,k*input_output_dim_A:k*input_output_dim_A+input_output_dim_A]\n",
    "    #ideaA_scaled=min_max_scaler.transform(ideaA)\n",
    "    ideaA_scaled=(2*ideaA/(supermax)) -1\n",
    "    salida_reconstructed_1_scaled = autoencoder.predict(ideaA_scaled)    \n",
    "    salida_reconstructed_1 = supermax*(salida_reconstructed_1_scaled+1)/2\n",
    "    #salida_reconstructed_1 = min_max_scaler.inverse_transform(salida_reconstructed_1_scaled)     \n",
    "    #salida_reconstructed_1 = ideaA\n",
    "    \n",
    "    #entrada_imgs_A=(ideaA-min_A.transpose())/(max_A.transpose()-min_A.transpose())\n",
    "    #entrada_imgs_A=(ideaA) #he quitado el escalado\n",
    "    #encoded_imgs_A = sigmoid(np.dot(entrada_imgs_A, Encoder_weights_A) + Encoder_biases_A)\n",
    "    #decoded_imgs_A= (np.dot(encoded_imgs_A, Decoder_weights_A) + Decoder_biases_A)\n",
    "    #print(decoded_imgs_A.shape)\n",
    "    #salida_reconstructed_1 = decoded_imgs_A*(max_A.transpose()-min_A.transpose())+min_A.transpose();\n",
    "    #salida_reconstructed_1 = decoded_imgs_A #quito el escalado inverso    \n",
    " \n",
    "    hola1=np.reshape(salida_reconstructed_1,(L1A*input_output_dim_A))\n",
    "\n",
    "    #print(hola.shape)\n",
    "    salida_total=hola1\n",
    "    #salida_total[salida_total<0]=0\n",
    "    #print(salida_total.shape)\n",
    "    cara_externa_reconstruida[i]=salida_total\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizamos los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos todos los sensores: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 1  # how many digits we will display\n",
    "plt.figure(figsize=(40, 10))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    idea=np.random.randint(1,x_tested.shape[0])\n",
    "    idea=1890\n",
    "    idea= 4299\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(cara_externa[idea].reshape(L1A*img_cols, img_rows).transpose(), vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(cara_externa_reconstruida[idea].reshape(L1A*img_cols, img_rows).transpose(), vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos ahora L1 a L1, teniendo en cuenta que hay de dos tipos:\n",
    "L1A (con 36 columnas )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x720 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = L1A  # how many digits we will display\n",
    "plt.figure(figsize=(40, 10))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(cara_externa[idea].reshape(L1A*img_cols, img_rows).transpose()[:,i*img_cols:(i+1)*img_cols] ,vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax = plt.subplot(2, n, i + 1+n)\n",
    "    plt.imshow(cara_externa_reconstruida[idea].reshape(L1A*img_cols, img_rows).transpose()[:,i*img_cols:(i+1)*img_cols] ,vmin=0, vmax=30)\n",
    "    plt.viridis()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  1  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  1  0  1  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  0  3  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  2  2  2  0  1  1  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  3  3  7  4  1  0  0  0  1  0  0  0  0  0]\n",
      " [ 1  3  3  4  9  9  5  2  2  1  0  0  0  0  0  0]\n",
      " [ 3  2 12 21  9 10 11  2  1  1  0  0  0  0  0  1]\n",
      " [ 2  8 15 22 18 31 13  6  1  1  1  0  1  0  0  0]\n",
      " [ 2  9 14 23 28 27 15 11  4  0  0  1  1  1  0  0]\n",
      " [ 2  6  8 22 23 14 13  7  4  0  0  0  0  0  0  0]\n",
      " [ 2  3  6 14 18 14  8  4  1  0  0  0  0  0  0  0]\n",
      " [ 1  5  6  6  5  5  3  3  2  0  1  0  0  0  0  0]]\n",
      "630\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "print(cara_externa[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:])\n",
    "print(np.sum(cara_externa[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  1  3  1  2  1  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  1  5  5  3  2  1  1  0  0  0  0  0  0  0]\n",
      " [ 1  5  3  4  7  5  4  2  1  0  0  0  0  0  0  0]\n",
      " [ 1  3  9 19  9 13  6  2  1  0  0  0  0  0  0  0]\n",
      " [ 1  6 15 19 20 33  8  3  1  1  0  0  0  0  0  0]\n",
      " [ 2  5 15 22 33 32 13  6  2  1  0  0  0  0  0  0]\n",
      " [ 2  4  7 19 16 14  9  4  1  1  0  0  0  0  0  0]\n",
      " [ 1  5  5  8 21 11  4  1  1  0  0  0  0  0  0  0]\n",
      " [ 1  1  2  4  7  4  2  1  1  0  0  0  0  0  0  0]]\n",
      "596.1997437477112\n"
     ]
    }
   ],
   "source": [
    "print(cara_externa_reconstruida[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:].astype(int))\n",
    "print(np.sum(cara_externa_reconstruida[idea].reshape(L1A*img_cols,img_rows)[i*img_cols:(i+1)*img_cols,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 985.86481369, 1110.71094501, 1067.89227188, ..., 1013.54929888,\n",
       "       1063.12700355,  913.19185138])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(idea)\n",
    "np.sum(cara_externa_reconstruida,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgadea3/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,)\n",
      "(401,)\n",
      "[[Model]]\n",
      "    Model(gaussian)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 34\n",
      "    # data points      = 400\n",
      "    # variables        = 3\n",
      "    chi-square         = 17008.7529\n",
      "    reduced chi-square = 42.8432063\n",
      "    Akaike info crit   = 1506.00753\n",
      "    Bayesian info crit = 1517.98192\n",
      "[[Variables]]\n",
      "    amp:  483.517141 +/- 2.73454389 (0.57%) (init = 200)\n",
      "    cen:  128.023926 +/- 0.47851988 (0.37%) (init = 0)\n",
      "    wid:  103.622793 +/- 0.67672930 (0.65%) (init = 100)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(amp, wid) = -0.577\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "veamos_energia=(np.sum(cara_externa_reconstruida, axis=1))-(np.sum(cara_externa, axis=1))\n",
    "n, bins, patches = plt.hist(veamos_energia, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "plt.title(\"Histogram with 400 bins\")\n",
    "plt.show()\n",
    "x=bins[:400]\n",
    "y=n\n",
    "print(n.shape)\n",
    "print(bins.shape)\n",
    "from numpy import exp, loadtxt, pi, sqrt, log\n",
    "\n",
    "from lmfit import Model\n",
    "def gaussian(x, amp, cen, wid):\n",
    "    \"\"\"1-d gaussian: gaussian(x, amp, cen, wid)\"\"\"\n",
    "    return amp * exp(-((x-cen)/wid)**2 )\n",
    "\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=200, cen=0, wid=100)\n",
    "\n",
    "print(result.fit_report())\n",
    "\n",
    "plt.plot(x, y, 'bo')\n",
    "plt.plot(x, result.init_fit, 'k--')\n",
    "plt.plot(x, result.best_fit, 'r-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "495px",
    "left": "1249px",
    "right": "57px",
    "top": "240px",
    "width": "390px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
