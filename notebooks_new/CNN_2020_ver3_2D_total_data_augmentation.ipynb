{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple CNN for PETALO\n",
    "\n",
    "Esta red la vamos a utilizar para obtener el radio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/rgadea/anaconda3/envs/tensorflow3/lib/python36.zip', '/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6', '/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/lib-dynload', '', '/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages', '/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/IPython/extensions', '/volumedisk0/home/rgadea/.ipython', '/home/rgadea/lmfit-py/', '/home/rgadea/experimentos/viherbos/']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#np.random.seed(1337)  # for reproducibility\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/rgadea/lmfit-py/\")\n",
    "sys.path.append(\"/home/rgadea/experimentos/viherbos/\")\n",
    "\n",
    "print(sys.path)\n",
    "import json \n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# import seaborn as sns\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D,Conv3D, MaxPooling3D, MaxPooling2D,BatchNormalization\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam, Nadam, RMSprop, SGD\n",
    "from math import floor\n",
    "from lmfit.models import  GaussianModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos introducir los datos de petalo preprocesados en pyhton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conjunto_datos_entradas A shape: (29714, 20, 175)\n",
      "conjunto_datos_entradas B shape: (29714, 20, 175)\n",
      "conjunto_datos_salidas shape: (29714, 3)\n"
     ]
    }
   ],
   "source": [
    "filtro=2\n",
    "if filtro==1:\n",
    "    npzfile = np.load('../conjuntos_datos_nuevos_2020/20_12_2019_comptom_filt.npz')\n",
    "    npzfile.files\n",
    "    conjunto_datos_entradasA=npzfile['arr_0']\n",
    "    conjunto_datos_entradasB=npzfile['arr_1']\n",
    "    conjunto_datos_salidas=npzfile['arr_2']\n",
    "else:\n",
    "    if filtro==2:\n",
    "        npzfile = np.load('../conjuntos_datos_nuevos_2020/26_12_2019_filt4.npz')\n",
    "        npzfile.files\n",
    "        conjunto_datos_entradasA=npzfile['arr_0']\n",
    "        conjunto_datos_entradasB=npzfile['arr_1']\n",
    "        conjunto_datos_salidas=npzfile['arr_2']\n",
    "    else:\n",
    "        npzfile = np.load('../conjuntos_datos_nuevos_2020/11_12_2019.npz')\n",
    "        npzfile.files\n",
    "        entradas_sensorsA1=npzfile['arr_0']\n",
    "        entradas_sensorsB1=npzfile['arr_1']\n",
    "        coordenadas1=npzfile['arr_2']\n",
    "        entradas_sensorsA2=npzfile['arr_3']\n",
    "        entradas_sensorsB2=npzfile['arr_4']\n",
    "        coordenadas2=npzfile['arr_5']\n",
    "        conjunto_datos_entradasA=np.concatenate((entradas_sensorsA1,entradas_sensorsA2),axis=0)\n",
    "        conjunto_datos_entradasB=np.concatenate((entradas_sensorsB1,entradas_sensorsB2),axis=0)\n",
    "        conjunto_datos_salidas=np.concatenate((coordenadas1,coordenadas2),axis=0)\n",
    "\n",
    "\n",
    "print('conjunto_datos_entradas A shape:', conjunto_datos_entradasA.shape)\n",
    "print('conjunto_datos_entradas B shape:', conjunto_datos_entradasB.shape)\n",
    "print('conjunto_datos_salidas shape:', conjunto_datos_salidas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[180.75254359 203.26664279  23.06898499]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAABICAYAAADvR65LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAALg0lEQVR4nO2da4wdZRnHf8/usgttKb1D6Ta0lVLTmHCxCkVFBCoXEWLihyKJNaIk3uIlKm2amPjFABpDjAZssF4RrBWhaTANrYgfNKWAtBRoaZFCty20RWgRobd9/PC+Zzl7eq57zpnL6f+XnMzMO+/M/Pc5Z979zzPvO2PujhBCiPzRlbYAIYQQI0MNuBBC5BQ14EIIkVPUgAshRE5RAy6EEDlFDbgQQuSUphpwM7vKzLaa2XYzW9wqUUIIIWpjI+0HbmbdwPPAAmAA2ADc4O7Ptk6eEEKISjTjwD8IbHf3f7v7YeA+4PrWyBJCCFGLnia2nQbsLFoeAC4srWRmNwM3A3TT/f5RjK1v72ZhOtKRos1unyU66W9pFsVCnIC8yev73X1yaXkzDbiVKTvurHL3ZcAygLE2wS+0y5s/SpLbZ4lO+luapUYsrK8PAD90KAExQrSXtb7ypXLlzaRQBoDpRcv9wO4m9ieEEKIBmmnANwCzzWymmfUCC4FVVbcwG3JGaWJ9fWV1VCpPUkOrt2kVacZsJMfwQ4fkvkXHM+IUirsfNbOvAmuAbmC5uz/TMmVCCCGq0kwOHHd/CHiogQ0Sc0WVcqDW11dRQ6G8lfnTSvsqLHePHX5TdzCWD62fPJnBgwer6il1p+2Ica2YldPSqI5asRJCDEcjMYUQIqc05cCzSK1caTk3V+r82un4SvUdi+66e3LoIWSz+sM0rh987gW6Slz6sX37hu0rDYfaDrcspy1EY8iBCyFETuk4B14pJ1vN3VXKfTfqcLvHjh1y1LX21X32zFD+zmEA3plzBgC9r70NwJtnnwpA11nn8s64bgAmbjwAQE9fb9xX2Ja4z8Kxa9EK5y63LET6yIELIURO6TgHXko1p1gr992oEy92wBWdd8x1c+C/oXzy+LA4M7jqQ+eH+ocmhUGtk897ld67wza7PzoOgNN2jAFgzCNbjjtuPXrlnoXoDOTAhRAip3S8Ay+luB94vU60Fbniod4npwX3fOisCQAc6x3+P/St6YMALLzkHwCsGXgv3aNDnUmbw766Doc6xH329E8D4OjArrA+lh9rYz/2euol2UtGzz4RnUS9v2c5cCGEyCknnANvJCfeKNVGeQ7Vib1O+ja9DMCuz8wOy2+EnHfXkVDvB6dvGtpm2i2vA3DX8k8C0L/2DQCOzQw9V3p2/2fYMQZLXX+kWk6/MCK0dCRovb16yu27WTdc0FRP7xo5b9FJ1Pt7runAzWy5me01s81FZRPM7GEz2xan45vQKoQQYgTU48B/BfwU+E1R2WJgnbvfGt+FuRi4pVkxSecxGz3eSPQVtuka2vZwLA+9Ts58NLjpLV8ZDcAXL/w7AHPv/DIA8z+xiRXrLgbgjB3HAHh7aqg7+unw9N5C7rs0F16PWy7M19uHvB3Pi6lEvZqEOFGp652YZjYDWO3u74vLW4FL3X2PmU0F/ubuc2rtZ0QvdMgAjVzKVxrAU2BoWHwhRRGHzh+eeAoAOxeEhn2wJ3wvvQe6GPNymJ+04bWw7eGYZ9n7WlkNlQYTtZJa6Zmuvr5UGmDdzBSdyFpf+YS7zystH+lNzNPdfQ9AnE5pRpwQQojGaftNzOJ3Yp7MqOp1E3iM60i2bcRJ1rq5V8rgU88C0Df3HADGbp8IwMRNbwFw9NRejowJQ+mHnHdB59gw3L6QMqmlpRnqfeDXUMxScsBy3uJEYqQO/NWYOiFO91aq6O7L3H2eu887ifTfxiOEEJ3CSB34KmARcGucPtgKMWkNAqmmY6RUcqyFlzMUbmoWbjz6vtBVcMqKV8L20V33ACcXdB18c9i6Ss67HYwkJo3cO6hGtd+Cct7iRKaeboT3Av8E5pjZgJndRGi4F5jZNmBBXBZCCJEgNR24u99QYVVbu5M066iqvX6snd0G62XIlRZe6FAykKbrYJm6BV0jeGRuGrSqF0o9jwIW4kREQ+mFECKndOxQ+la88quVLzyo5ZJL3epgFQ3NvsYsKcee1SsDIbKOHmYlhBAdTiYdeCN56nr2Bem7wGo5+XL12qk3qVikHXMh8krLHmYlhBAim2TSgbfCueXF/eVFZ71k5YpHiBMBOXAhhMgpmXTgorUk+YyZZo7RDveuKwLRyciBCyFETpEDzxGV3GQ7XXE795XEvuW8RScjBy6EEDklkw68lf3AO4k85J2L+7V3Wl9+IbKGHLgQQuSUut6J2bKDme0D3gL2J3bQ+pmEdDVKVrVJV2NkVRdkV1vSus5y98mlhYk24ABm9ni5l3OmjXQ1Tla1SVdjZFUXZFdbVnQphSKEEDlFDbgQQuSUNBrwZSkcsx6kq3Gyqk26GiOruiC72jKhK/EcuBBCiNagFIoQQuQUNeBCCJFTEmvAzewqM9tqZtvNbHFSxy2jY7qZPWJmz5nZM2b29Vg+wcweNrNtcTo+JX3dZvYvM1sdl2ea2fqo6w9m1puSrnFmttLMtsTYzc9CzMzsm/F73Gxm95rZyWnFzMyWm9leM9tcVFY2Rhb4STwfNpnZBQnr+mH8LjeZ2Z/NbFzRuiVR11YzuzJJXUXrvm1mbmaT4nJi8aqmzcy+FuPyjJndXlSeSMyOw93b/gG6gReAWUAvsBGYm8Sxy2iZClwQ508FngfmArcDi2P5YuC2lPR9C/g9sDourwAWxvm7gC+lpOvXwBfifC8wLu2YAdOAF4FTimL1ubRiBlwCXABsLiorGyPgGuAvgAEXAesT1vVxoCfO31aka248P/uAmfG87U5KVyyfDqwBXgImJR2vKjH7GLAW6IvLU5KO2XE6EzkIzAfWFC0vAZYkcew6tD0ILAC2AlNj2VRgawpa+oF1wGXA6vhj3V90og2LY4K6xsaG0krKU41ZbMB3AhMIz/VZDVyZZsyAGSUnfdkYAT8HbihXLwldJes+BdwT54edm7EhnZ+kLmAlcC6wo6gBTzReFb7LFcAVZeolGrPiT1IplMKJVmAglqWKmc0AzgfWA6e7+x6AOJ2SgqQ7gO8Cg3F5IvCGux+Ny2nFbRawD/hlTO/cbWajSTlm7r4L+BHwMrAHOAA8QTZiVqBSjLJ0Tnye4G4hZV1mdh2wy903lqzKQrzOAT4S03OPmtkH0taWVANuZcpS7b9oZmOAPwHfcPeDaWqJeq4F9rr7E8XFZaqmEbcewuXkne5+PuF5NqndxygQ88nXEy5bzwRGA1eXqZrFvrKZ+G7NbClwFLinUFSmWiK6zGwUsBT4XrnVZcqSjlcPMJ6QwvkOsMLMjBS1JdWADxDyWgX6gd0JHfs4zOwkQuN9j7vfH4tfNbOpcf1UYG/Csj4EXGdmO4D7CGmUO4BxZlZ47G9acRsABtx9fVxeSWjQ047ZFcCL7r7P3Y8A9wMXk42YFagUo9TPCTNbBFwL3Ojx2j9lXe8h/DPeGM+DfuBJMzsjZV0FBoD7PfAY4Up5UprakmrANwCzY++AXmAhsCqhYw8j/sf8BfCcu/+4aNUqYFGcX0TIjSeGuy9x9353n0GIz1/d/UbgEeDTaemK2l4BdprZnFh0OfAsKceMkDq5yMxGxe+1oCv1mBVRKUargM/G3hUXAQcKqZYkMLOrgFuA69z9fyV6F5pZn5nNBGYDjyWhyd2fdvcp7j4jngcDhA4Hr5ByvCIPEIwVZnYO4Wb+flKMWduT7EWJ/WsIPT5eAJYmddwyOj5MuLzZBDwVP9cQ8s3rgG1xOiFFjZfybi+UWfHHsB34I/EOeAqazgMej3F7gHApmXrMgO8DW4DNwG8JPQFSiRlwLyEXf4TQ+NxUKUaEy+6fxfPhaWBewrq2E/K2hXPgrqL6S6OurcDVSeoqWb+Dd29iJhavKjHrBX4Xf2tPApclHbPSj4bSCyFETtFITCGEyClqwIUQIqeoARdCiJyiBlwIIXKKGnAhhMgpasCFECKnqAEXQoic8n/kGsogown3egAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[177.68615865  78.35639934 -11.69700813]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAABICAYAAADvR65LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAKXUlEQVR4nO3de4xcZRnH8e+vd4ou21KKlTa0NFCzMbFglVKVIFAuDZeY+EeBxBoxJCYa0ai0aTAx/ANoDDExYqMYL1ytCLXBVEDwH7XcLFAKS1sBu1BaqrZ4AS328Y/znu3sdGZ3dnf2nDnd3yfZzJz3nJ336TN73j7zzntmFBGYmVn1TCg7ADMzGxkP4GZmFeUB3MysojyAm5lVlAdwM7OK8gBuZlZRoxrAJV0kqVfSDkmr2xWUmZkNTSNdBy5pIvAisBzoAx4HroiIbe0Lz8zMmhlNBf5hYEdE/Dki/gvcBVzenrDMzGwok0bxuycBu2q2+4Az6w+SdA1wDcBEJn5wOl2j6NLMbPz5B3/fFxEn1LePZgBXg7Yj5mMiYh2wDqBLM+NMnTeKLs3Mxp+HYv0rjdpHM4XSB8yr2Z4LvDaKxzMzs2EYzQD+OHCqpAWSpgArgQ3tCaszTVjcw4TFPYPuNzMryoinUCLiHUmfBzYBE4HbIuK5tkVmZmaDGs0cOBHxAPBAm2IpXV5BH9rSeCVks/ZG+4d6rHYqsq92qFq8Zp3KV2KamVXUqCrw4dIx05jwvp6OrbxajevNK5cC0HXHHwe0T1h8+N9W/1hDVZ2jqUrz36lKZdvp8ZlVhStwM7OKKrQCj7fernT1lVe49ZV3bn9PF11bBh7brCKv1468jEV1b2adyxW4mVlFFVqBd7pWV6HUr/fO25tV5o0eeyznxM1sfHAFbmZWUa7Aawx35Uijajq//8ql3dlBly4D4ORf7R9w7P6e7EO9DqT98274fUt9joSreLOjkytwM7OKcgU+iLxK7qZn0Pa8wt11/bL+Svvthf8BYNEtbw343f5quCdbS55X3q3wvLiZ1RqyApd0m6S9krbWtM2U9KCk7el2xtiGaWZm9Yb8SjVJZwP/BH4SEe9PbTcDf4uIG9N3Yc6IiOuG6qzqnweeX4HZve1NAHqvPQY4XGXv7+nq35dX6fnKlE2vZQvEL15xJTD0ipaRcIVuVrwizruHYv2TEbGkvr2l78SUNB/YWDOA9wLnRMRuSXOARyNi0VCP0+kDeP0T0eyS+fqBPH/D8ridh9hzwUHgyKmT+gG91Se9doBvdQlis7jNrJqaDeAjfRPzxIjYDZBuZ48mODMzG74xfxOz9jsxpzF9rLsbkfppjPoKm7r9/ZVtaj9u5yEA9lxwkBN/MxmA3muzQ6btnDrgd49/dA4A/0v7d10/cJlhrra6rq+0h6ra87gPDXqUmVXdSCvwPWnqhHS7t9mBEbEuIpZExJLJTG12mJmZDdNIK/ANwCrgxnR7f9siKlCzueT8A6kONTmu2VenTds5lQMLs/t5JZ5v51X6wRt2AzD50ax93jmp70EutW/1jc5m/x6/uWl2dGplGeGdwB+ARZL6JF1NNnAvl7QdWJ62zcysQENW4BFxRZNdnbucpEWtVqSDXbgDtfPXXRxYOPj/iXk1/Nd16TEXzxjQR36BTz6PXfslEUNxhW02vvhSejOzijpqL6Vv51ro/DHqV3Xk89p55Xvg0mX9bXkF3Z2K4v7quO5LIfY3ibPTVpB4Ht2s87gCNzOrqJauxGyXql2J2Uxe3ef6111v2da/L58Lz+fH66/EHE0sw72Ks2pfemxmA7X7SkwzMyvZUTsH3g5N14kPMl+d7+uq29e/gqXusftXuNRU8bW3jVahjHRViitvs6OLK3Azs4oalxV4s8q6nRVr/SqYpp9wmNZ91/dVe9xw56491202PrgCNzOrKK9CYfSfIVJUxevK2mx88ioUM7OjzLicA6/XrKJtdf30WFTEjfp05W1mtVyBm5lVVKFz4JLeAP4F7Cus09bNwnENV6fG5riGp1Pjgs6Nrei4To6IE+obCx3AASQ90WgyvmyOa/g6NTbHNTydGhd0bmydEpenUMzMKsoDuJlZRZUxgK8roc9WOK7h69TYHNfwdGpc0LmxdURchc+Bm5lZe3gKxcysojyAm5lVVGEDuKSLJPVK2iFpdVH9NohjnqRHJD0v6TlJX0ztMyU9KGl7up1RUnwTJf1J0sa0vUDS5hTX3ZKmlBRXt6T1kl5IuTurE3Im6Uvpedwq6U5J08rKmaTbJO2VtLWmrWGOlPlOOh+ekXRGwXF9Mz2Xz0j6paTumn1rUly9ki4sMq6afV+RFJJmpe3C8jVYbJK+kPLynKSba9oLydkRImLMf4CJwE7gFGAK8DTQU0TfDWKZA5yR7r8beBHoAW4GVqf21cBNJcX3ZeAOYGPavgdYme7fCnyupLh+DHw23Z8CdJedM+Ak4CXgmJpcfbqsnAFnA2cAW2vaGuYIWAH8GhCwFNhccFwXAJPS/Ztq4upJ5+dUYEE6bycWFVdqnwdsAl4BZhWdr0Fy9nHgIWBq2p5ddM6OiLOQTuAsYFPN9hpgTRF9txDb/cByoBeYk9rmAL0lxDIXeBg4F9iY/lj31ZxoA/JYYFxdaaBUXXupOUsD+C5gJtnn+mwELiwzZ8D8upO+YY6A7wNXNDquiLjq9n0CuD3dH3BupoH0rCLjAtYDHwBerhnAC81Xk+fyHuD8BscVmrPan6KmUPITLdeX2kolaT5wOrAZODEidgOk29klhHQL8DUOf/Pa8cD+iHgnbZeVt1OAN4AfpemdH0g6lpJzFhGvAt8C/gLsBg4AT9IZOcs1y1EnnROfIatuoeS4JF0GvBoRT9ft6oR8nQZ8LE3P/U7Sh8qOragBXA3aSl2/KOldwC+AayPizTJjSfFcAuyNiCdrmxscWkbeJpG9nPxeRJxO9nk2pb2PkUvzyZeTvWx9L3AscHGDQztxrWxHPLeS1gLvALfnTQ0OKyQuSdOBtcDXG+1u0FZ0viYBM8imcL4K3CNJlBhbUQN4H9m8Vm4u8FpBfR9B0mSywfv2iLg3Ne+RNCftnwPsLTisjwCXSXoZuItsGuUWoFtS/rG/ZeWtD+iLiM1pez3ZgF52zs4HXoqINyLiIHAvsIzOyFmuWY5KPyckrQIuAa6K9Nq/5LgWkv1n/HQ6D+YCT0l6T8lx5fqAeyPzGNkr5VllxlbUAP44cGpaHTAFWAlsKKjvAdL/mD8Eno+Ib9fs2gCsSvdXkc2NFyYi1kTE3IiYT5af30bEVcAjwCfLiivF9jqwS9Ki1HQesI2Sc0Y2dbJU0vT0vOZxlZ6zGs1ytAH4VFpdsRQ4kE+1FEHSRcB1wGUR8e+6eFdKmippAXAq8FgRMUXEsxExOyLmp/Ogj2zBweuUnK/kPrLCCkmnkb2Zv48Sczbmk+w1E/sryFZ87ATWFtVvgzg+Svby5hlgS/pZQTbf/DCwPd3OLDHGczi8CuWU9MewA/g56R3wEmJaDDyR8nYf2UvJ0nMGfAN4AdgK/JRsJUApOQPuJJuLP0g2+FzdLEdkL7u/m86HZ4ElBce1g2zeNj8Hbq05fm2Kqxe4uMi46va/zOE3MQvL1yA5mwL8LP2tPQWcW3TO6n98Kb2ZWUX5Skwzs4ryAG5mVlEewM3MKsoDuJlZRXkANzOrKA/gZmYV5QHczKyi/g8SlRTeHRE9gQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[165.79331126  62.32125662  10.07481575]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[173.89957491 297.01229487  20.05840111]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[166.8477022  247.02668989  57.90563202]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[180.65271113 165.83122887  42.24821091]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[168.31129628 249.64725679 -38.37334442]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[171.11591241 298.42700618  26.94094849]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[180.66885194 297.8049114   13.55964661]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[182.80326309 304.68788083   8.70242691]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "    idea=np.random.randint(1,conjunto_datos_entradasB.shape[0])\n",
    "    plt.imshow(conjunto_datos_entradasB[idea], cmap='viridis')\n",
    "    plt.show()\n",
    "    print(conjunto_datos_salidas[idea,0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 250\n",
    "nb_classes = 10\n",
    "nb_epoch = 1000\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 20, 41\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (1,2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (2, 4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "muestras=conjunto_datos_entradasA.shape[0]\n",
    "# veamos=idea.reshape(idea.shape[0],175, 20)\n",
    "\n",
    "\n",
    "veamos2A=np.zeros([muestras,20,175])\n",
    "veamos2_3A=np.zeros([muestras,20,525])\n",
    "veamos2B=np.zeros([muestras,20,175])\n",
    "veamos2_3B=np.zeros([muestras,20,525])\n",
    "sector2A=np.zeros([muestras,20,img_cols])\n",
    "sector2B=np.zeros([muestras,20,img_cols])\n",
    "veamos3=np.zeros([muestras,175])\n",
    "# for i in range(idea.shape[0]):\n",
    "for i in range(muestras):\n",
    "    veamos2A[i]=conjunto_datos_entradasA[i]\n",
    "    veamos2B[i]=conjunto_datos_entradasB[i]\n",
    "    veamos3[i]=np.sum(veamos2A[i], axis=0)\n",
    "    indice=np.argmax(veamos3[i], axis=0)\n",
    "    indice_inferior=int(indice-((img_cols-1)/2)+175)\n",
    "    indice_superior=int(indice+((img_cols+1)/2)+175)\n",
    "    veamos2_3A[i]=np.concatenate((veamos2A[i],veamos2A[i],veamos2A[i]),axis=1) \n",
    "    veamos2_3B[i]=np.concatenate((veamos2B[i],veamos2B[i],veamos2B[i]),axis=1) \n",
    "    sector2A[i]=veamos2_3A[i,:,indice_inferior:indice_superior]\n",
    "    sector2B[i]=veamos2_3B[i,:,indice_inferior:indice_superior]      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data augmentation mediante flip horizontal y vertical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atencion: la z es copiada pero en realidad es incorrecta. Podemos asegurar que el radio y phi si que son las mismas; pero la z claramente al hacer un flip vertical no puede ser la misma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "veamosA=np.zeros([4*muestras,20,img_cols])\n",
    "veamosB=np.zeros([4*muestras,20,img_cols])\n",
    "conjunto_datos_salidas_nuevo=np.zeros([4*muestras,3])\n",
    "for i in range(muestras):\n",
    "    veamosA[i*4]=sector2A[i]  \n",
    "    caramba=np.flipud(sector2A[i]) \n",
    "    veamosA[i*4+1]=caramba  \n",
    "    veamosA[i*4+2]=np.fliplr(caramba)     \n",
    "    veamosA[i*4+3]=np.fliplr(sector2A[i])     \n",
    "    veamosB[i*4]=sector2B[i]   \n",
    "    caramba=np.flipud(sector2B[i]) \n",
    "    veamosB[i*4+1]=caramba   \n",
    "    veamosB[i*4+2]=np.fliplr(caramba)  \n",
    "    veamosB[i*4+3]=np.fliplr(sector2B[i])\n",
    "    conjunto_datos_salidas_nuevo[i*4]=conjunto_datos_salidas[i]\n",
    "    conjunto_datos_salidas_nuevo[i*4+1]=conjunto_datos_salidas[i]    \n",
    "    conjunto_datos_salidas_nuevo[i*4+2]=conjunto_datos_salidas[i]  \n",
    "    conjunto_datos_salidas_nuevo[i*4+3]=conjunto_datos_salidas[i]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sector A shape: (118856, 20, 41)\n",
      "conjunto_datos_nuevo A: (118856, 820)\n",
      "sector B shape: (118856, 20, 41)\n",
      "conjunto_datos_nuevo B: (118856, 820)\n",
      "conjunto_datos_salidas_nuevo: (118856, 3)\n"
     ]
    }
   ],
   "source": [
    "print('sector A shape:', veamosA.shape)\n",
    "conjunto_datos_nuevoA=veamosA.reshape(veamosA.shape[0], img_rows*img_cols)\n",
    "print('conjunto_datos_nuevo A:', conjunto_datos_nuevoA.shape)\n",
    "\n",
    "print('sector B shape:', veamosB.shape)\n",
    "conjunto_datos_nuevoB=veamosB.reshape(veamosB.shape[0], img_rows*img_cols)\n",
    "print('conjunto_datos_nuevo B:', conjunto_datos_nuevoB.shape)\n",
    "print('conjunto_datos_salidas_nuevo:', conjunto_datos_salidas_nuevo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 5  # how many digits we will display\n",
    "\n",
    "fig = plt.figure(figsize=(8,20))\n",
    "\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ideas=np.random.randint(1,muestras)\n",
    "    ax = fig.add_subplot(n, 2, (i)*2+1)\n",
    "    plt.imshow(sector2A[ideas], cmap='viridis')\n",
    "    plt.viridis()\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = fig.add_subplot(n, 2, (i)*2+2)\n",
    "    plt.imshow(sector2B[ideas], cmap='viridis')\n",
    "    plt.viridis()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# print(x_test[idea])\n",
    "# print(decoded_imgs[idea])\n",
    "# print(decoded_imgs_scaled[idea])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "#Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "#Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "for i in range(1,5):\n",
    "    idea=np.random.randint(1,sector2B.shape[0])\n",
    "    plt.imshow(sector2B[idea], cmap='viridis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71313\n",
      "23771\n",
      "23772\n",
      "(10668, 1640)\n",
      "(5748, 1640)\n",
      "(4372, 1640)\n",
      "(2048, 1640)\n",
      "(936, 1640)\n"
     ]
    }
   ],
   "source": [
    "numero_muestras=4*muestras\n",
    "tr_size=60\n",
    "val_size=20\n",
    "test_size=100-val_size-tr_size\n",
    "conjunto_datos_nuevo2=np.concatenate((conjunto_datos_salidas_nuevo,conjunto_datos_nuevoB, conjunto_datos_nuevoA), axis=1)\n",
    "\n",
    "tamanyo_tr=floor(tr_size*numero_muestras/100)\n",
    "tamanyo_val=floor(val_size*numero_muestras/100)\n",
    "tamanyo_test=numero_muestras-tamanyo_tr-tamanyo_val\n",
    "print(tamanyo_tr)\n",
    "print(tamanyo_val)\n",
    "print(tamanyo_test)\n",
    "\n",
    "\n",
    "XY_test=conjunto_datos_nuevo2[tamanyo_tr+tamanyo_val:numero_muestras,:]\n",
    "\n",
    "\n",
    "XY_test_bin0=XY_test[np.where((XY_test[:,0]>=164.9999) * (XY_test[:,0]<171.000))]\n",
    "XY_test_bin1=XY_test[np.where((XY_test[:,0]>=171.000) * (XY_test[:,0]<177.000))]\n",
    "XY_test_bin2=XY_test[np.where((XY_test[:,0]>=177.000) * (XY_test[:,0]<183.0000))]\n",
    "XY_test_bin3=XY_test[np.where((XY_test[:,0]>=183.000) * (XY_test[:,0]<189.0000))]\n",
    "XY_test_bin4=XY_test[np.where((XY_test[:,0]>=189.0000))]\n",
    "\n",
    "X_train=conjunto_datos_nuevo2[:tamanyo_tr,3:]\n",
    "X_val=conjunto_datos_nuevo2[tamanyo_tr:tamanyo_tr+tamanyo_val,3:]\n",
    "X_test=conjunto_datos_nuevo2[tamanyo_tr+tamanyo_val:numero_muestras,3:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_test_bin0=XY_test_bin0[:,3:]\n",
    "Y_test_bin0=XY_test_bin0[:,0]\n",
    "print(X_test_bin0.shape)\n",
    "X_test_bin1=XY_test_bin1[:,3:]\n",
    "Y_test_bin1=XY_test_bin1[:,0]\n",
    "print(X_test_bin1.shape)\n",
    "X_test_bin2=XY_test_bin2[:,3:]\n",
    "Y_test_bin2=XY_test_bin2[:,0]\n",
    "print(X_test_bin2.shape)\n",
    "X_test_bin3=XY_test_bin3[:,3:]\n",
    "Y_test_bin3=XY_test_bin3[:,0]\n",
    "print(X_test_bin3.shape)\n",
    "X_test_bin4=XY_test_bin4[:,3:]\n",
    "Y_test_bin4=XY_test_bin4[:,0]\n",
    "print(X_test_bin4.shape)\n",
    "\n",
    "Y_train=conjunto_datos_nuevo2[:tamanyo_tr,0] #elijo la coordenada radius\n",
    "Y_val=conjunto_datos_nuevo2[tamanyo_tr:tamanyo_tr+tamanyo_val,0] #elijo la corrdenada radius\n",
    "Y_test=conjunto_datos_nuevo2[tamanyo_tr+tamanyo_val:numero_muestras,0] #elijo la corrdenada radius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a normalizar las salidas por si luego nos interea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_total=conjunto_datos_nuevo2[:numero_muestras,0]\n",
    "min_max_scaler = preprocessing.MinMaxScaler().fit(Y_total.reshape(-1, 1))\n",
    "\n",
    "Y_train_scaled = min_max_scaler.transform(Y_train.reshape(-1, 1))\n",
    "Y_val_scaled = min_max_scaler.transform(Y_val.reshape(-1, 1))\n",
    "Y_test_scaled = min_max_scaler.transform(Y_test.reshape(-1, 1))\n",
    "\n",
    "Y_test_bin4_scaled=min_max_scaler.transform(Y_test_bin4.reshape(-1, 1))\n",
    "Y_test_bin3_scaled=min_max_scaler.transform(Y_test_bin3.reshape(-1, 1))\n",
    "Y_test_bin2_scaled=min_max_scaler.transform(Y_test_bin2.reshape(-1, 1))\n",
    "Y_test_bin1_scaled=min_max_scaler.transform(Y_test_bin1.reshape(-1, 1))\n",
    "Y_test_bin0_scaled=min_max_scaler.transform(Y_test_bin0.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],2, img_rows, img_cols,1)\n",
    "X_val = X_val.reshape(X_val.shape[0], 2, img_rows, img_cols,1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 2,img_rows, img_cols,1)\n",
    "\n",
    "X_test_bin0 = X_test_bin0.reshape(X_test_bin0.shape[0], 2, img_rows, img_cols,1)\n",
    "X_test_bin1 = X_test_bin1.reshape(X_test_bin1.shape[0], 2, img_rows, img_cols,1)\n",
    "X_test_bin2 = X_test_bin2.reshape(X_test_bin2.shape[0], 2, img_rows, img_cols,1)\n",
    "X_test_bin3 = X_test_bin3.reshape(X_test_bin3.shape[0], 2, img_rows, img_cols,1)\n",
    "X_test_bin4 = X_test_bin4.reshape(X_test_bin4.shape[0], 2, img_rows, img_cols,1)\n",
    "\n",
    "input_shape = (2, img_rows, img_cols,1)\n",
    "#input_shape=input_shape.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (71313, 2, 20, 41, 1)\n",
      "71313 train samples\n",
      "23771 validation samples\n",
      "23772 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_val= X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_val.shape[0], 'validation samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                            vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_regularizer = False\n",
    "my_regularizer = None\n",
    "# my_epochs = 50\n",
    "# hidden_size=320\n",
    "features_path = 'simple_autoe_features.pickle'\n",
    "labels_path = 'simple_autoe_labels.pickle'\n",
    "\n",
    "if use_regularizer:\n",
    "    # add a sparsity constraint on the encoded representations\n",
    "    # note use of 10e-5 leads to blurred results\n",
    "    my_regularizer = regularizers.l1(0.00001)\n",
    "    # and a larger number of epochs as the added regularization the model\n",
    "    # is less likely to overfit and can be trained longer\n",
    "    my_epochs = 100\n",
    "    features_path = 'sparse_autoe_features.pickle'\n",
    "    labels_path = 'sparse_autoe_labels.pickle'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the CNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(16, kernel_size=kernel_size,\n",
    "                        padding='same',\n",
    "                        activity_regularizer=my_regularizer,\n",
    "                        data_format='channels_last',\n",
    "                        input_shape=(2,img_rows,img_cols,1)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization(momentum=0.6))\n",
    "model.add(MaxPooling3D(pool_size=pool_size))\n",
    "\n",
    "model.add(Conv3D(16, kernel_size,  activity_regularizer=my_regularizer, padding='same'))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization(momentum=0.6))\n",
    "model.add(MaxPooling3D(pool_size=pool_size))\n",
    "\n",
    "model.add(Conv3D(32, kernel_size,  activity_regularizer=my_regularizer, padding='same'))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization(momentum=0.6))\n",
    "model.add(MaxPooling3D(pool_size=pool_size))\n",
    "\n",
    "model.add(Conv3D(32, kernel_size,  activity_regularizer=my_regularizer, padding='same'))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization(momentum=0.6))\n",
    "\n",
    "model.add(Conv3D(64, kernel_size, activity_regularizer=my_regularizer, padding='same'))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization(momentum=0.6))\n",
    "\n",
    "model.add(Conv3D(64, kernel_size, activity_regularizer=my_regularizer, padding='same'))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization(momentum=0.6))\n",
    "\n",
    "model.add(Conv3D(128, kernel_size,activity_regularizer=my_regularizer, padding='same'))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization(momentum=0.6))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(10))\n",
    "# model.add(Activation('tanh'))\n",
    "model.add(Dense(1,use_bias=True, \n",
    "                activity_regularizer=my_regularizer             \n",
    "               ))\n",
    "\n",
    "\n",
    "dt = datetime.now().replace(second=0, microsecond=0)\n",
    "experimento=\"CNN_kernel_{}x{}x{}_con_batchnormalization_sector_{}x{}x{}_elu\".format(kernel_size[0],kernel_size[1],kernel_size[2],img_rows,img_cols,1)\n",
    "algoritmo='Nadam'\n",
    "optimizador=Nadam(beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "tensorboard=TensorBoard(log_dir=\"../logs/defs/{}{}{}\".format(experimento,algoritmo,dt))\n",
    "best_model_name='../redes_CNN_R/models_best/CNN_regression_R_{}_{}_{}_{}_{}.h5'.format(nb_epoch,batch_size,experimento,algoritmo,dt)\n",
    "model_check=ModelCheckpoint(best_model_name, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='min', period=1)\n",
    "early_stop=EarlyStopping(monitor='val_loss', min_delta=0, patience=600, verbose=1, mode='auto', baseline=None)\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=optimizador)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a summary of the model parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 2, 20, 41, 16)     528       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2, 20, 41, 16)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2, 20, 41, 16)     64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 2, 10, 20, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 2, 10, 20, 16)     8208      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2, 10, 20, 16)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 2, 10, 20, 16)     64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 2, 5, 10, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 2, 5, 10, 32)      16416     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2, 5, 10, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2, 5, 10, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 2, 2, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 2, 2, 5, 32)       32800     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2, 2, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 2, 2, 5, 32)       128       \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 2, 2, 5, 64)       65600     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2, 2, 5, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 2, 2, 5, 64)       256       \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 2, 2, 5, 64)       131136    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 2, 2, 5, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 2, 2, 5, 64)       256       \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 2, 2, 5, 128)      262272    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 2, 2, 5, 128)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 2, 2, 5, 128)      512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 2, 5, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2561      \n",
      "=================================================================\n",
      "Total params: 520,929\n",
      "Trainable params: 520,225\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now train the model and evaluate on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rgadea/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 71313 samples, validate on 23771 samples\n",
      "Epoch 1/1000\n",
      "71313/71313 [==============================] - 14s 194us/step - loss: 748.8431 - val_loss: 14.7958\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 14.79580, saving model to ../redes_CNN_R/models_best/CNN_regression_R_1000_250_CNN_kernel_2x4x4_con_batchnormalization_sector_20x41x1_elu_Nadam_2019-12-30 08:26:00.h5\n",
      "Epoch 2/1000\n",
      "71313/71313 [==============================] - 10s 136us/step - loss: 11.1962 - val_loss: 9.2081\n",
      "\n",
      "Epoch 00002: val_loss improved from 14.79580 to 9.20812, saving model to ../redes_CNN_R/models_best/CNN_regression_R_1000_250_CNN_kernel_2x4x4_con_batchnormalization_sector_20x41x1_elu_Nadam_2019-12-30 08:26:00.h5\n",
      "Epoch 3/1000\n",
      "71313/71313 [==============================] - 10s 136us/step - loss: 10.5369 - val_loss: 8.1237\n",
      "\n",
      "Epoch 00003: val_loss improved from 9.20812 to 8.12369, saving model to ../redes_CNN_R/models_best/CNN_regression_R_1000_250_CNN_kernel_2x4x4_con_batchnormalization_sector_20x41x1_elu_Nadam_2019-12-30 08:26:00.h5\n",
      "Epoch 4/1000\n",
      "71313/71313 [==============================] - 9s 133us/step - loss: 10.2246 - val_loss: 6.3245\n",
      "\n",
      "Epoch 00004: val_loss improved from 8.12369 to 6.32448, saving model to ../redes_CNN_R/models_best/CNN_regression_R_1000_250_CNN_kernel_2x4x4_con_batchnormalization_sector_20x41x1_elu_Nadam_2019-12-30 08:26:00.h5\n",
      "Epoch 5/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 9.8554 - val_loss: 8.9210\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 6.32448\n",
      "Epoch 6/1000\n",
      "71313/71313 [==============================] - 9s 132us/step - loss: 9.6614 - val_loss: 6.3919\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 6.32448\n",
      "Epoch 7/1000\n",
      "71313/71313 [==============================] - 9s 133us/step - loss: 9.6112 - val_loss: 6.7207\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 6.32448\n",
      "Epoch 8/1000\n",
      "71313/71313 [==============================] - 9s 132us/step - loss: 9.3568 - val_loss: 13.4640\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 6.32448\n",
      "Epoch 9/1000\n",
      "71313/71313 [==============================] - 9s 132us/step - loss: 9.1538 - val_loss: 6.4841\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 6.32448\n",
      "Epoch 10/1000\n",
      "71313/71313 [==============================] - 9s 132us/step - loss: 9.0319 - val_loss: 7.2100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.32448\n",
      "Epoch 11/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 9.0353 - val_loss: 5.5804\n",
      "\n",
      "Epoch 00011: val_loss improved from 6.32448 to 5.58039, saving model to ../redes_CNN_R/models_best/CNN_regression_R_1000_250_CNN_kernel_2x4x4_con_batchnormalization_sector_20x41x1_elu_Nadam_2019-12-30 08:26:00.h5\n",
      "Epoch 12/1000\n",
      "71313/71313 [==============================] - 9s 133us/step - loss: 8.9383 - val_loss: 6.0148\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 5.58039\n",
      "Epoch 13/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 8.6491 - val_loss: 7.4134\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 5.58039\n",
      "Epoch 14/1000\n",
      "71313/71313 [==============================] - 9s 132us/step - loss: 8.7287 - val_loss: 9.0469\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 5.58039\n",
      "Epoch 15/1000\n",
      "71313/71313 [==============================] - 9s 133us/step - loss: 8.6501 - val_loss: 8.3368\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 5.58039\n",
      "Epoch 16/1000\n",
      "71313/71313 [==============================] - 9s 133us/step - loss: 8.9346 - val_loss: 23.6678\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 5.58039\n",
      "Epoch 17/1000\n",
      "71313/71313 [==============================] - 9s 132us/step - loss: 8.7220 - val_loss: 5.1868\n",
      "\n",
      "Epoch 00017: val_loss improved from 5.58039 to 5.18675, saving model to ../redes_CNN_R/models_best/CNN_regression_R_1000_250_CNN_kernel_2x4x4_con_batchnormalization_sector_20x41x1_elu_Nadam_2019-12-30 08:26:00.h5\n",
      "Epoch 18/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 9.0228 - val_loss: 7.7196\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 5.18675\n",
      "Epoch 19/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 8.4480 - val_loss: 6.1449\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 5.18675\n",
      "Epoch 20/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 8.4842 - val_loss: 5.4647\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 5.18675\n",
      "Epoch 21/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 8.3560 - val_loss: 12.0835\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 5.18675\n",
      "Epoch 22/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 8.3463 - val_loss: 6.5506\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 5.18675\n",
      "Epoch 23/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 8.3810 - val_loss: 5.5863\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 5.18675\n",
      "Epoch 24/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 8.0951 - val_loss: 5.5869\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 5.18675\n",
      "Epoch 25/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 8.1708 - val_loss: 6.4351\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 5.18675\n",
      "Epoch 26/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 7.6519 - val_loss: 9.2110\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 5.18675\n",
      "Epoch 27/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 7.7994 - val_loss: 12.7991\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 5.18675\n",
      "Epoch 28/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 7.8506 - val_loss: 6.6510\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 5.18675\n",
      "Epoch 29/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 7.6806 - val_loss: 21.3826\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 5.18675\n",
      "Epoch 30/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 7.5470 - val_loss: 10.4598\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 5.18675\n",
      "Epoch 31/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 7.6152 - val_loss: 6.0152\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 5.18675\n",
      "Epoch 32/1000\n",
      "71313/71313 [==============================] - 9s 132us/step - loss: 7.2925 - val_loss: 5.3400\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 5.18675\n",
      "Epoch 33/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 7.4128 - val_loss: 13.0573\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 5.18675\n",
      "Epoch 34/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 7.1333 - val_loss: 5.6224\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 5.18675\n",
      "Epoch 35/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 7.1637 - val_loss: 8.1812\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 5.18675\n",
      "Epoch 36/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 7.0396 - val_loss: 5.4215\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 5.18675\n",
      "Epoch 37/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 6.9952 - val_loss: 5.4938\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 5.18675\n",
      "Epoch 38/1000\n",
      "71313/71313 [==============================] - 9s 130us/step - loss: 6.9405 - val_loss: 8.6266\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 5.18675\n",
      "Epoch 39/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 6.9107 - val_loss: 6.0731\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 5.18675\n",
      "Epoch 40/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 6.8450 - val_loss: 6.3353\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 5.18675\n",
      "Epoch 41/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 6.8787 - val_loss: 8.2556\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 5.18675\n",
      "Epoch 42/1000\n",
      "71313/71313 [==============================] - 9s 131us/step - loss: 6.7220 - val_loss: 6.0768\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 5.18675\n",
      "Epoch 43/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 6.5814 - val_loss: 5.9666\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 5.18675\n",
      "Epoch 44/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 6.3726 - val_loss: 5.3260\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 5.18675\n",
      "Epoch 45/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 6.4536 - val_loss: 5.8605\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 5.18675\n",
      "Epoch 46/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 6.4858 - val_loss: 6.5364\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 5.18675\n",
      "Epoch 47/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 6.2933 - val_loss: 5.4431\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 5.18675\n",
      "Epoch 48/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 6.2037 - val_loss: 6.4547\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 5.18675\n",
      "Epoch 49/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 6.1131 - val_loss: 5.4137\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 5.18675\n",
      "Epoch 50/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 6.0773 - val_loss: 7.0449\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 5.18675\n",
      "Epoch 51/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 6.1370 - val_loss: 7.9806\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 5.18675\n",
      "Epoch 52/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 5.9050 - val_loss: 5.5990\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 5.18675\n",
      "Epoch 53/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 6.0112 - val_loss: 6.0281\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 5.18675\n",
      "Epoch 54/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 5.9616 - val_loss: 5.3269\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 5.18675\n",
      "Epoch 55/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 5.8594 - val_loss: 7.1789\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 5.18675\n",
      "Epoch 56/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 5.8138 - val_loss: 6.7257\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 5.18675\n",
      "Epoch 57/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 5.8635 - val_loss: 6.7518\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 5.18675\n",
      "Epoch 58/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 5.7161 - val_loss: 10.3365\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 5.18675\n",
      "Epoch 59/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 5.8825 - val_loss: 12.2609\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 5.18675\n",
      "Epoch 60/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 5.5977 - val_loss: 5.5767\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 5.18675\n",
      "Epoch 61/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 5.5384 - val_loss: 8.1872\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 5.18675\n",
      "Epoch 62/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 5.5140 - val_loss: 5.9566\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 5.18675\n",
      "Epoch 63/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 5.5045 - val_loss: 7.4340\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 5.18675\n",
      "Epoch 64/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 5.5499 - val_loss: 6.4003\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 5.18675\n",
      "Epoch 65/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 5.6220 - val_loss: 6.5994\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 5.18675\n",
      "Epoch 66/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 5.4778 - val_loss: 5.7981\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 5.18675\n",
      "Epoch 67/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 5.3766 - val_loss: 6.1660\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 5.18675\n",
      "Epoch 68/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 5.4289 - val_loss: 6.2456\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 5.18675\n",
      "Epoch 69/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 5.3610 - val_loss: 8.8956\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 5.18675\n",
      "Epoch 70/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 5.3174 - val_loss: 6.2115\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 5.18675\n",
      "Epoch 71/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 5.2946 - val_loss: 10.5584\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 5.18675\n",
      "Epoch 72/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 5.2864 - val_loss: 5.9587\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 5.18675\n",
      "Epoch 73/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 5.1595 - val_loss: 5.6119\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 5.18675\n",
      "Epoch 74/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 5.2275 - val_loss: 6.3895\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 5.18675\n",
      "Epoch 75/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 5.2013 - val_loss: 6.3327\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 5.18675\n",
      "Epoch 76/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 5.1640 - val_loss: 5.6421\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 5.18675\n",
      "Epoch 77/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 5.1904 - val_loss: 5.5086\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 5.18675\n",
      "Epoch 78/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 5.0961 - val_loss: 6.1321\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 5.18675\n",
      "Epoch 79/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 5.0390 - val_loss: 5.3554\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 5.18675\n",
      "Epoch 80/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 5.0672 - val_loss: 5.5936\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 5.18675\n",
      "Epoch 81/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 5.0830 - val_loss: 5.7590\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 5.18675\n",
      "Epoch 82/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 4.9609 - val_loss: 5.5881\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 5.18675\n",
      "Epoch 83/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 5.0609 - val_loss: 5.7226\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 5.18675\n",
      "Epoch 84/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 5.0201 - val_loss: 5.8814\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 5.18675\n",
      "Epoch 85/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.9640 - val_loss: 5.6740\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 5.18675\n",
      "Epoch 86/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 5.0285 - val_loss: 6.0486\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 5.18675\n",
      "Epoch 87/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 4.8915 - val_loss: 6.0938\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 5.18675\n",
      "Epoch 88/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.7848 - val_loss: 5.6661\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 5.18675\n",
      "Epoch 89/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.9118 - val_loss: 6.2086\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 5.18675\n",
      "Epoch 90/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.8383 - val_loss: 6.7938\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 5.18675\n",
      "Epoch 91/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.7926 - val_loss: 5.6694\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 5.18675\n",
      "Epoch 92/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 4.7571 - val_loss: 6.0638\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 5.18675\n",
      "Epoch 93/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 4.8060 - val_loss: 7.7100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 5.18675\n",
      "Epoch 94/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 4.8129 - val_loss: 5.8152\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 5.18675\n",
      "Epoch 95/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 4.7904 - val_loss: 5.6942\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 5.18675\n",
      "Epoch 96/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 4.7665 - val_loss: 6.1682\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 5.18675\n",
      "Epoch 97/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 4.7037 - val_loss: 6.6954\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 5.18675\n",
      "Epoch 98/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.6753 - val_loss: 7.4378\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 5.18675\n",
      "Epoch 99/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 4.7495 - val_loss: 7.0925\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 5.18675\n",
      "Epoch 100/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 4.6972 - val_loss: 6.4235\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 5.18675\n",
      "Epoch 101/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.6503 - val_loss: 5.6743\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 5.18675\n",
      "Epoch 102/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 4.5764 - val_loss: 5.6899\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 5.18675\n",
      "Epoch 103/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.6029 - val_loss: 5.6044\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 5.18675\n",
      "Epoch 104/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 4.5873 - val_loss: 5.7740\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 5.18675\n",
      "Epoch 105/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.6612 - val_loss: 5.9305\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 5.18675\n",
      "Epoch 106/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 4.5164 - val_loss: 5.9745\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 5.18675\n",
      "Epoch 107/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.6091 - val_loss: 6.9008\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 5.18675\n",
      "Epoch 108/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 4.4674 - val_loss: 5.8841\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 5.18675\n",
      "Epoch 109/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.5343 - val_loss: 5.5627\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 5.18675\n",
      "Epoch 110/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.4948 - val_loss: 5.6989\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 5.18675\n",
      "Epoch 111/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.4406 - val_loss: 5.8196\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 5.18675\n",
      "Epoch 112/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.4198 - val_loss: 5.7859\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 5.18675\n",
      "Epoch 113/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.5288 - val_loss: 6.0277\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 5.18675\n",
      "Epoch 114/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 4.4444 - val_loss: 5.9475\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 5.18675\n",
      "Epoch 115/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 4.4956 - val_loss: 5.8425\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 5.18675\n",
      "Epoch 116/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 4.3808 - val_loss: 5.7578\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 5.18675\n",
      "Epoch 117/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 4.3647 - val_loss: 5.9299\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 5.18675\n",
      "Epoch 118/1000\n",
      "71313/71313 [==============================] - 8s 118us/step - loss: 4.4188 - val_loss: 6.2963\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 5.18675\n",
      "Epoch 119/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 4.3292 - val_loss: 5.9935\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 5.18675\n",
      "Epoch 120/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.4100 - val_loss: 7.1982\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 5.18675\n",
      "Epoch 121/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.4233 - val_loss: 6.0618\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 5.18675\n",
      "Epoch 122/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.3309 - val_loss: 7.0121\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 5.18675\n",
      "Epoch 123/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 4.3776 - val_loss: 9.5940\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 5.18675\n",
      "Epoch 124/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 4.3529 - val_loss: 7.3621\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 5.18675\n",
      "Epoch 125/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.2944 - val_loss: 6.9810\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 5.18675\n",
      "Epoch 126/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.3049 - val_loss: 5.6916\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 5.18675\n",
      "Epoch 127/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 4.2835 - val_loss: 6.2402\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 5.18675\n",
      "Epoch 128/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.2927 - val_loss: 5.9423\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 5.18675\n",
      "Epoch 129/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.2841 - val_loss: 7.7110\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 5.18675\n",
      "Epoch 130/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 4.2896 - val_loss: 5.8804\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 5.18675\n",
      "Epoch 131/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.2953 - val_loss: 5.9962\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 5.18675\n",
      "Epoch 132/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 4.2457 - val_loss: 5.7433\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 5.18675\n",
      "Epoch 133/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.2665 - val_loss: 6.1921\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 5.18675\n",
      "Epoch 134/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.2918 - val_loss: 6.4043\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 5.18675\n",
      "Epoch 135/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 4.2490 - val_loss: 5.8808\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 5.18675\n",
      "Epoch 136/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 4.1968 - val_loss: 6.2475\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 5.18675\n",
      "Epoch 137/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 4.2032 - val_loss: 5.9182\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 5.18675\n",
      "Epoch 138/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.1582 - val_loss: 6.2214\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 5.18675\n",
      "Epoch 139/1000\n",
      "71313/71313 [==============================] - 9s 119us/step - loss: 4.1892 - val_loss: 5.8109\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 5.18675\n",
      "Epoch 140/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.1415 - val_loss: 5.8526\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 5.18675\n",
      "Epoch 141/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.1356 - val_loss: 5.9660\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 5.18675\n",
      "Epoch 142/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.2178 - val_loss: 5.8534\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 5.18675\n",
      "Epoch 143/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.1610 - val_loss: 6.4221\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 5.18675\n",
      "Epoch 144/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 4.1352 - val_loss: 6.8766\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 5.18675\n",
      "Epoch 145/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 4.1371 - val_loss: 5.9362\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 5.18675\n",
      "Epoch 146/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 4.1361 - val_loss: 5.9734\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 5.18675\n",
      "Epoch 147/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.1075 - val_loss: 10.6770\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 5.18675\n",
      "Epoch 148/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.1353 - val_loss: 7.1973\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 5.18675\n",
      "Epoch 149/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 4.1019 - val_loss: 5.9144\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 5.18675\n",
      "Epoch 150/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.1866 - val_loss: 6.0556\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 5.18675\n",
      "Epoch 151/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 4.1103 - val_loss: 5.7335\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 5.18675\n",
      "Epoch 152/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 4.0375 - val_loss: 6.1225\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 5.18675\n",
      "Epoch 153/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 4.1187 - val_loss: 5.7484\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 5.18675\n",
      "Epoch 154/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 4.0168 - val_loss: 5.6105\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 5.18675\n",
      "Epoch 155/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 4.0947 - val_loss: 6.0161\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 5.18675\n",
      "Epoch 156/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.9849 - val_loss: 6.0511\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 5.18675\n",
      "Epoch 157/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 4.0030 - val_loss: 6.1955\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 5.18675\n",
      "Epoch 158/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 4.1201 - val_loss: 6.3102\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 5.18675\n",
      "Epoch 159/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 4.0188 - val_loss: 9.1380\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 5.18675\n",
      "Epoch 160/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.9865 - val_loss: 6.8415\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 5.18675\n",
      "Epoch 161/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 4.0070 - val_loss: 6.4579\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 5.18675\n",
      "Epoch 162/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 4.0897 - val_loss: 5.8401\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 5.18675\n",
      "Epoch 163/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.9787 - val_loss: 5.7976\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 5.18675\n",
      "Epoch 164/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.9857 - val_loss: 6.6047\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 5.18675\n",
      "Epoch 165/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.9608 - val_loss: 5.6439\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 5.18675\n",
      "Epoch 166/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.9015 - val_loss: 6.6737\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 5.18675\n",
      "Epoch 167/1000\n",
      "71313/71313 [==============================] - 9s 119us/step - loss: 4.0119 - val_loss: 5.8757\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 5.18675\n",
      "Epoch 168/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.9615 - val_loss: 7.1251\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 5.18675\n",
      "Epoch 169/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.9783 - val_loss: 5.9250\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 5.18675\n",
      "Epoch 170/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.9648 - val_loss: 5.7786\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 5.18675\n",
      "Epoch 171/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.9244 - val_loss: 6.1659\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 5.18675\n",
      "Epoch 172/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.9681 - val_loss: 6.2626\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 5.18675\n",
      "Epoch 173/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.9643 - val_loss: 6.0156\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 5.18675\n",
      "Epoch 174/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.9536 - val_loss: 7.2778\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 5.18675\n",
      "Epoch 175/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.9263 - val_loss: 6.0155\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 5.18675\n",
      "Epoch 176/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.9255 - val_loss: 6.1027\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 5.18675\n",
      "Epoch 177/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.9723 - val_loss: 6.0848\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 5.18675\n",
      "Epoch 178/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.9179 - val_loss: 6.0611\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 5.18675\n",
      "Epoch 179/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.9462 - val_loss: 8.3584\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 5.18675\n",
      "Epoch 180/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.9181 - val_loss: 5.9263\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 5.18675\n",
      "Epoch 181/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 3.8774 - val_loss: 6.2790\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 5.18675\n",
      "Epoch 182/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.8528 - val_loss: 5.8471\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 5.18675\n",
      "Epoch 183/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.9134 - val_loss: 5.8070\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 5.18675\n",
      "Epoch 184/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.8788 - val_loss: 5.7674\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 5.18675\n",
      "Epoch 185/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.9177 - val_loss: 5.9227\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 5.18675\n",
      "Epoch 186/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.8710 - val_loss: 5.9299\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 5.18675\n",
      "Epoch 187/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.8615 - val_loss: 5.8238\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 5.18675\n",
      "Epoch 188/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.8490 - val_loss: 5.9388\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 5.18675\n",
      "Epoch 189/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.8651 - val_loss: 8.5516\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 5.18675\n",
      "Epoch 190/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 3.8625 - val_loss: 5.8647\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 5.18675\n",
      "Epoch 191/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.8367 - val_loss: 5.8761\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 5.18675\n",
      "Epoch 192/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.8691 - val_loss: 5.6258\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 5.18675\n",
      "Epoch 193/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.8713 - val_loss: 6.0032\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 5.18675\n",
      "Epoch 194/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.8481 - val_loss: 6.0728\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 5.18675\n",
      "Epoch 195/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.8090 - val_loss: 5.9536\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 5.18675\n",
      "Epoch 196/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.9132 - val_loss: 5.9032\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 5.18675\n",
      "Epoch 197/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.7797 - val_loss: 7.2419\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 5.18675\n",
      "Epoch 198/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.8825 - val_loss: 6.0364\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 5.18675\n",
      "Epoch 199/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.8573 - val_loss: 5.9456\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 5.18675\n",
      "Epoch 200/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.8134 - val_loss: 7.2219\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 5.18675\n",
      "Epoch 201/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.8192 - val_loss: 7.6174\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 5.18675\n",
      "Epoch 202/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.7543 - val_loss: 6.2762\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 5.18675\n",
      "Epoch 203/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.7966 - val_loss: 5.8736\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 5.18675\n",
      "Epoch 204/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.8229 - val_loss: 5.7895\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 5.18675\n",
      "Epoch 205/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.8149 - val_loss: 6.0927\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 5.18675\n",
      "Epoch 206/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.7633 - val_loss: 5.8249\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 5.18675\n",
      "Epoch 207/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.8123 - val_loss: 5.9695\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 5.18675\n",
      "Epoch 208/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.7831 - val_loss: 6.1322\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 5.18675\n",
      "Epoch 209/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.7546 - val_loss: 6.3214\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 5.18675\n",
      "Epoch 210/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.8336 - val_loss: 7.6434\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 5.18675\n",
      "Epoch 211/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.7926 - val_loss: 6.1963\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 5.18675\n",
      "Epoch 212/1000\n",
      "71313/71313 [==============================] - 9s 129us/step - loss: 3.7688 - val_loss: 5.7108\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 5.18675\n",
      "Epoch 213/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.7477 - val_loss: 8.9528\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 5.18675\n",
      "Epoch 214/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.7641 - val_loss: 7.4926\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 5.18675\n",
      "Epoch 215/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.7974 - val_loss: 7.3070\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 5.18675\n",
      "Epoch 216/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.7259 - val_loss: 6.8051\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 5.18675\n",
      "Epoch 217/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.7105 - val_loss: 5.8062\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 5.18675\n",
      "Epoch 218/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.7627 - val_loss: 5.8815\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 5.18675\n",
      "Epoch 219/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.7723 - val_loss: 9.4515\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 5.18675\n",
      "Epoch 220/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.7698 - val_loss: 5.9375\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 5.18675\n",
      "Epoch 221/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.6771 - val_loss: 7.0985\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 5.18675\n",
      "Epoch 222/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.7510 - val_loss: 5.9135\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 5.18675\n",
      "Epoch 223/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.7524 - val_loss: 5.8863\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 5.18675\n",
      "Epoch 224/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.7347 - val_loss: 6.1068\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 5.18675\n",
      "Epoch 225/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.7388 - val_loss: 8.3073\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 5.18675\n",
      "Epoch 226/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.6992 - val_loss: 6.0133\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 5.18675\n",
      "Epoch 227/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.7319 - val_loss: 6.0473\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 5.18675\n",
      "Epoch 228/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.7000 - val_loss: 6.0194\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 5.18675\n",
      "Epoch 229/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.7065 - val_loss: 5.5926\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 5.18675\n",
      "Epoch 230/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.7335 - val_loss: 6.0682\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 5.18675\n",
      "Epoch 231/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.7063 - val_loss: 6.9198\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 5.18675\n",
      "Epoch 232/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.7023 - val_loss: 5.9425\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 5.18675\n",
      "Epoch 233/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.6973 - val_loss: 6.2228\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 5.18675\n",
      "Epoch 234/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.7007 - val_loss: 6.1571\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 5.18675\n",
      "Epoch 235/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.6589 - val_loss: 5.7472\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 5.18675\n",
      "Epoch 236/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.6399 - val_loss: 6.6187\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 5.18675\n",
      "Epoch 237/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.6879 - val_loss: 5.8802\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 5.18675\n",
      "Epoch 238/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.6471 - val_loss: 6.1139\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 5.18675\n",
      "Epoch 239/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.6607 - val_loss: 5.8589\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 5.18675\n",
      "Epoch 240/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.6273 - val_loss: 6.7740\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 5.18675\n",
      "Epoch 241/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.6569 - val_loss: 6.8406\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 5.18675\n",
      "Epoch 242/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.7014 - val_loss: 5.9370\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 5.18675\n",
      "Epoch 243/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.6348 - val_loss: 6.7331\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 5.18675\n",
      "Epoch 244/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.6388 - val_loss: 5.7833\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 5.18675\n",
      "Epoch 245/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.6566 - val_loss: 6.1534\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 5.18675\n",
      "Epoch 246/1000\n",
      "71313/71313 [==============================] - 9s 127us/step - loss: 3.7043 - val_loss: 5.8248\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 5.18675\n",
      "Epoch 247/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.6071 - val_loss: 5.8648\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 5.18675\n",
      "Epoch 248/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.6264 - val_loss: 6.3955\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 5.18675\n",
      "Epoch 249/1000\n",
      "71313/71313 [==============================] - 9s 128us/step - loss: 3.6943 - val_loss: 5.8131\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 5.18675\n",
      "Epoch 250/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.6169 - val_loss: 6.9500\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 5.18675\n",
      "Epoch 251/1000\n",
      "71313/71313 [==============================] - 9s 126us/step - loss: 3.6735 - val_loss: 5.8825\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 5.18675\n",
      "Epoch 252/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.6791 - val_loss: 6.0815\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 5.18675\n",
      "Epoch 253/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.6420 - val_loss: 6.8335\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 5.18675\n",
      "Epoch 254/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 3.6064 - val_loss: 7.2179\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 5.18675\n",
      "Epoch 255/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.6194 - val_loss: 6.9565\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 5.18675\n",
      "Epoch 256/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.6379 - val_loss: 6.4289\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 5.18675\n",
      "Epoch 257/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 3.6568 - val_loss: 8.4733\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 5.18675\n",
      "Epoch 258/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.5812 - val_loss: 5.7844\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 5.18675\n",
      "Epoch 259/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.5906 - val_loss: 6.4905\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 5.18675\n",
      "Epoch 260/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 3.6084 - val_loss: 5.8876\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 5.18675\n",
      "Epoch 261/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.6251 - val_loss: 5.9825\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 5.18675\n",
      "Epoch 262/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.6412 - val_loss: 6.0051\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 5.18675\n",
      "Epoch 263/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.6216 - val_loss: 5.8576\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 5.18675\n",
      "Epoch 264/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 3.6043 - val_loss: 6.3496\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 5.18675\n",
      "Epoch 265/1000\n",
      "71313/71313 [==============================] - 9s 120us/step - loss: 3.5664 - val_loss: 6.1048\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 5.18675\n",
      "Epoch 266/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 3.5340 - val_loss: 6.0106\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 5.18675\n",
      "Epoch 267/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.6002 - val_loss: 6.7088\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 5.18675\n",
      "Epoch 268/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.5692 - val_loss: 5.9013\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 5.18675\n",
      "Epoch 269/1000\n",
      "71313/71313 [==============================] - 9s 124us/step - loss: 3.6317 - val_loss: 6.1803\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 5.18675\n",
      "Epoch 270/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.5782 - val_loss: 6.5675\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 5.18675\n",
      "Epoch 271/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.5622 - val_loss: 6.7897\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 5.18675\n",
      "Epoch 272/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.5717 - val_loss: 6.0390\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 5.18675\n",
      "Epoch 273/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 3.5536 - val_loss: 5.8875\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 5.18675\n",
      "Epoch 274/1000\n",
      "71313/71313 [==============================] - 9s 120us/step - loss: 3.6721 - val_loss: 5.9300\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 5.18675\n",
      "Epoch 275/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.6303 - val_loss: 5.9675\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 5.18675\n",
      "Epoch 276/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.5447 - val_loss: 6.0815\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 5.18675\n",
      "Epoch 277/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.5732 - val_loss: 5.8898\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 5.18675\n",
      "Epoch 278/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 3.5319 - val_loss: 5.9906\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 5.18675\n",
      "Epoch 279/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.6014 - val_loss: 6.2937\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 5.18675\n",
      "Epoch 280/1000\n",
      "71313/71313 [==============================] - 9s 120us/step - loss: 3.5580 - val_loss: 6.0217\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 5.18675\n",
      "Epoch 281/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.4995 - val_loss: 5.7479\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 5.18675\n",
      "Epoch 282/1000\n",
      "71313/71313 [==============================] - 9s 123us/step - loss: 3.5729 - val_loss: 8.0231\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 5.18675\n",
      "Epoch 283/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.6229 - val_loss: 6.3424\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 5.18675\n",
      "Epoch 284/1000\n",
      "71313/71313 [==============================] - 9s 122us/step - loss: 3.5168 - val_loss: 8.3989\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 5.18675\n",
      "Epoch 285/1000\n",
      "71313/71313 [==============================] - 9s 125us/step - loss: 3.5619 - val_loss: 6.8382\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 5.18675\n",
      "Epoch 286/1000\n",
      "71313/71313 [==============================] - 9s 121us/step - loss: 3.5326 - val_loss: 6.1386\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 5.18675\n",
      "Epoch 287/1000\n",
      "11250/71313 [===>..........................] - ETA: 6s - loss: 3.5064"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-64860ef5b59c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch,\n\u001b[1;32m      2\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                      callbacks=[tensorboard,model_check,early_stop])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch,\n",
    "          verbose=1, validation_data=(X_val, Y_val),\n",
    "                     callbacks=[tensorboard,model_check,early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.now().replace(second=0, microsecond=0)\n",
    "model.save_weights('../redes_CNN_R/defs/CNN_regression_R_{}_{}_{}_{}_{}'.format(nb_epoch,batch_size,experimento,algoritmo,dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "best_model = load_model(best_model_name)\n",
    "# best_model = model\n",
    "score = best_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test mse:', score)\n",
    "# print('Test mae:', score[1])\n",
    "Y_test_predicted=best_model.predict(X_test)\n",
    "print(Y_test_predicted[:10].flatten())\n",
    "print(Y_test[:10])\n",
    "\n",
    "error_prediction=Y_test-Y_test_predicted.flatten()\n",
    "\n",
    "print(error_prediction[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model error')\n",
    "plt.ylabel('error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(error_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "n, bins, patches = plt.hist(error_prediction, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "plt.title(\"Histogram with 400 bins\")\n",
    "plt.show()\n",
    "x=bins[:400]\n",
    "y=n\n",
    "print(n.shape)\n",
    "print(bins.shape)\n",
    "from numpy import exp, loadtxt, pi, sqrt, log\n",
    "\n",
    "from lmfit import Model\n",
    "def gaussian(x, amp, cen, wid):\n",
    "    \"\"\"1-d gaussian: gaussian(x, amp, cen, wid)\"\"\"\n",
    "    return amp * exp(-((x-cen)/wid)**2 )\n",
    "\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "\n",
    "print(result.fit_report())\n",
    "\n",
    "plt.plot(x, y, 'bo')\n",
    "plt.plot(x, result.init_fit, 'k--')\n",
    "plt.plot(x, result.best_fit, 'r-')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWHM=result.params['wid'].value*2*sqrt(log(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FWHM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_bin0_predicted=best_model.predict(X_test_bin0)\n",
    "print(Y_test_bin0_predicted)\n",
    "error_prediction_bin0=Y_test_bin0-Y_test_bin0_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin0, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin0=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_bin1_predicted=best_model.predict(X_test_bin1)\n",
    "#print(Y_test_bin1_predicted)\n",
    "error_prediction_bin1=Y_test_bin1-Y_test_bin1_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin1, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin1=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_test_bin2_predicted=best_model.predict(X_test_bin2)\n",
    "#print(Y_test_bin2_predicted)\n",
    "error_prediction_bin2=Y_test_bin2-Y_test_bin2_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin2, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin2=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_test_bin3_predicted=best_model.predict(X_test_bin3)\n",
    "#print(Y_test_bin3_predicted)\n",
    "error_prediction_bin3=Y_test_bin3-Y_test_bin3_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin3, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin3=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_test_bin4_predicted=best_model.predict(X_test_bin4)\n",
    "#print(Y_test_bin4_predicted)\n",
    "error_prediction_bin4=Y_test_bin4-Y_test_bin4_predicted.flatten()\n",
    "n, bins, patches = plt.hist(error_prediction_bin4, 400, normed=0, facecolor='green', alpha=0.75)\n",
    "\n",
    "x=bins[:400]\n",
    "y=n\n",
    "\n",
    "gmodel = Model(gaussian)\n",
    "result = gmodel.fit(y, x=x, amp=1000, cen=0, wid=1)\n",
    "FWHM_bin4=result.params['wid'].value*2*sqrt(log(2))\n",
    "print(FWHM_bin4)\n",
    "print(FWHM_bin3)\n",
    "print(FWHM_bin2)\n",
    "print(FWHM_bin1)\n",
    "print(FWHM_bin0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos ahora los histogramnas 2d que nos interesan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow3] *",
   "language": "python",
   "name": "conda-env-tensorflow3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "495px",
    "left": "909px",
    "right": "57px",
    "top": "246px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
